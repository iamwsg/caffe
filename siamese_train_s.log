I0711 12:34:56.722167 32652 caffe.cpp:185] Using GPUs 0
I0711 12:34:56.735503 32652 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0711 12:34:57.077102 32652 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0
snapshot: 50000
snapshot_prefix: "examples/siamese/My_mnist_siamese_0to6"
solver_mode: GPU
device_id: 0
net: "examples/siamese/mnist_siamese_train_test.prototxt"
I0711 12:34:57.077278 32652 solver.cpp:91] Creating training net from net file: examples/siamese/mnist_siamese_train_test.prototxt
I0711 12:34:57.078256 32652 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer pair_data
I0711 12:34:57.078510 32652 net.cpp:49] Initializing net from parameters: 
name: "mnist_siamese_train_test"
state {
  phase: TRAIN
}
layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/siamese/mnist_siamese_train_leveldb_0to6"
    batch_size: 64
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "pool2_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "ip2_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "ip2_p"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip2_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I0711 12:34:57.078668 32652 layer_factory.hpp:77] Creating layer pair_data
I0711 12:34:57.079092 32652 net.cpp:91] Creating Layer pair_data
I0711 12:34:57.079104 32652 net.cpp:399] pair_data -> pair_data
I0711 12:34:57.079133 32652 net.cpp:399] pair_data -> sim
I0711 12:34:57.298326 32658 db_leveldb.cpp:18] Opened leveldb examples/siamese/mnist_siamese_train_leveldb_0to6
I0711 12:34:57.317960 32652 data_layer.cpp:41] output data size: 64,2,28,28
I0711 12:34:57.320003 32652 net.cpp:141] Setting up pair_data
I0711 12:34:57.320026 32652 net.cpp:148] Top shape: 64 2 28 28 (100352)
I0711 12:34:57.320039 32652 net.cpp:148] Top shape: 64 (64)
I0711 12:34:57.320044 32652 net.cpp:156] Memory required for data: 401664
I0711 12:34:57.320058 32652 layer_factory.hpp:77] Creating layer slice_pair
I0711 12:34:57.320083 32652 net.cpp:91] Creating Layer slice_pair
I0711 12:34:57.320091 32652 net.cpp:425] slice_pair <- pair_data
I0711 12:34:57.320106 32652 net.cpp:399] slice_pair -> data
I0711 12:34:57.320122 32652 net.cpp:399] slice_pair -> data_p
I0711 12:34:57.320170 32652 net.cpp:141] Setting up slice_pair
I0711 12:34:57.320181 32652 net.cpp:148] Top shape: 64 1 28 28 (50176)
I0711 12:34:57.320188 32652 net.cpp:148] Top shape: 64 1 28 28 (50176)
I0711 12:34:57.320194 32652 net.cpp:156] Memory required for data: 803072
I0711 12:34:57.320200 32652 layer_factory.hpp:77] Creating layer conv1
I0711 12:34:57.320219 32652 net.cpp:91] Creating Layer conv1
I0711 12:34:57.320225 32652 net.cpp:425] conv1 <- data
I0711 12:34:57.320237 32652 net.cpp:399] conv1 -> conv1
I0711 12:34:57.321352 32652 net.cpp:141] Setting up conv1
I0711 12:34:57.321368 32652 net.cpp:148] Top shape: 64 20 24 24 (737280)
I0711 12:34:57.321374 32652 net.cpp:156] Memory required for data: 3752192
I0711 12:34:57.321390 32652 layer_factory.hpp:77] Creating layer pool1
I0711 12:34:57.321403 32652 net.cpp:91] Creating Layer pool1
I0711 12:34:57.321409 32652 net.cpp:425] pool1 <- conv1
I0711 12:34:57.321418 32652 net.cpp:399] pool1 -> pool1
I0711 12:34:57.321475 32652 net.cpp:141] Setting up pool1
I0711 12:34:57.321483 32652 net.cpp:148] Top shape: 64 20 12 12 (184320)
I0711 12:34:57.321488 32652 net.cpp:156] Memory required for data: 4489472
I0711 12:34:57.321493 32652 layer_factory.hpp:77] Creating layer conv2
I0711 12:34:57.321508 32652 net.cpp:91] Creating Layer conv2
I0711 12:34:57.321514 32652 net.cpp:425] conv2 <- pool1
I0711 12:34:57.321527 32652 net.cpp:399] conv2 -> conv2
I0711 12:34:57.322671 32652 net.cpp:141] Setting up conv2
I0711 12:34:57.322690 32652 net.cpp:148] Top shape: 64 50 8 8 (204800)
I0711 12:34:57.322695 32652 net.cpp:156] Memory required for data: 5308672
I0711 12:34:57.322707 32652 layer_factory.hpp:77] Creating layer pool2
I0711 12:34:57.322739 32652 net.cpp:91] Creating Layer pool2
I0711 12:34:57.322746 32652 net.cpp:425] pool2 <- conv2
I0711 12:34:57.322756 32652 net.cpp:399] pool2 -> pool2
I0711 12:34:57.322804 32652 net.cpp:141] Setting up pool2
I0711 12:34:57.322814 32652 net.cpp:148] Top shape: 64 50 4 4 (51200)
I0711 12:34:57.322820 32652 net.cpp:156] Memory required for data: 5513472
I0711 12:34:57.322826 32652 layer_factory.hpp:77] Creating layer ip1
I0711 12:34:57.322839 32652 net.cpp:91] Creating Layer ip1
I0711 12:34:57.322844 32652 net.cpp:425] ip1 <- pool2
I0711 12:34:57.322854 32652 net.cpp:399] ip1 -> ip1
I0711 12:34:57.327056 32652 net.cpp:141] Setting up ip1
I0711 12:34:57.327080 32652 net.cpp:148] Top shape: 64 500 (32000)
I0711 12:34:57.327087 32652 net.cpp:156] Memory required for data: 5641472
I0711 12:34:57.327101 32652 layer_factory.hpp:77] Creating layer relu1
I0711 12:34:57.327112 32652 net.cpp:91] Creating Layer relu1
I0711 12:34:57.327119 32652 net.cpp:425] relu1 <- ip1
I0711 12:34:57.327128 32652 net.cpp:386] relu1 -> ip1 (in-place)
I0711 12:34:57.327142 32652 net.cpp:141] Setting up relu1
I0711 12:34:57.327149 32652 net.cpp:148] Top shape: 64 500 (32000)
I0711 12:34:57.327155 32652 net.cpp:156] Memory required for data: 5769472
I0711 12:34:57.327162 32652 layer_factory.hpp:77] Creating layer ip2
I0711 12:34:57.327178 32652 net.cpp:91] Creating Layer ip2
I0711 12:34:57.327184 32652 net.cpp:425] ip2 <- ip1
I0711 12:34:57.327196 32652 net.cpp:399] ip2 -> ip2
I0711 12:34:57.328254 32652 net.cpp:141] Setting up ip2
I0711 12:34:57.328277 32652 net.cpp:148] Top shape: 64 10 (640)
I0711 12:34:57.328287 32652 net.cpp:156] Memory required for data: 5772032
I0711 12:34:57.328301 32652 layer_factory.hpp:77] Creating layer feat
I0711 12:34:57.328320 32652 net.cpp:91] Creating Layer feat
I0711 12:34:57.328330 32652 net.cpp:425] feat <- ip2
I0711 12:34:57.328347 32652 net.cpp:399] feat -> feat
I0711 12:34:57.328514 32652 net.cpp:141] Setting up feat
I0711 12:34:57.328528 32652 net.cpp:148] Top shape: 64 2 (128)
I0711 12:34:57.328536 32652 net.cpp:156] Memory required for data: 5772544
I0711 12:34:57.328552 32652 layer_factory.hpp:77] Creating layer conv1_p
I0711 12:34:57.328573 32652 net.cpp:91] Creating Layer conv1_p
I0711 12:34:57.328583 32652 net.cpp:425] conv1_p <- data_p
I0711 12:34:57.328596 32652 net.cpp:399] conv1_p -> conv1_p
I0711 12:34:57.328918 32652 net.cpp:141] Setting up conv1_p
I0711 12:34:57.328933 32652 net.cpp:148] Top shape: 64 20 24 24 (737280)
I0711 12:34:57.328940 32652 net.cpp:156] Memory required for data: 8721664
I0711 12:34:57.328949 32652 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I0711 12:34:57.328958 32652 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'conv1', param index 1
I0711 12:34:57.328966 32652 layer_factory.hpp:77] Creating layer pool1_p
I0711 12:34:57.328982 32652 net.cpp:91] Creating Layer pool1_p
I0711 12:34:57.328990 32652 net.cpp:425] pool1_p <- conv1_p
I0711 12:34:57.329001 32652 net.cpp:399] pool1_p -> pool1_p
I0711 12:34:57.329059 32652 net.cpp:141] Setting up pool1_p
I0711 12:34:57.329074 32652 net.cpp:148] Top shape: 64 20 12 12 (184320)
I0711 12:34:57.329082 32652 net.cpp:156] Memory required for data: 9458944
I0711 12:34:57.329089 32652 layer_factory.hpp:77] Creating layer conv2_p
I0711 12:34:57.329107 32652 net.cpp:91] Creating Layer conv2_p
I0711 12:34:57.329114 32652 net.cpp:425] conv2_p <- pool1_p
I0711 12:34:57.329130 32652 net.cpp:399] conv2_p -> conv2_p
I0711 12:34:57.329649 32652 net.cpp:141] Setting up conv2_p
I0711 12:34:57.329664 32652 net.cpp:148] Top shape: 64 50 8 8 (204800)
I0711 12:34:57.329673 32652 net.cpp:156] Memory required for data: 10278144
I0711 12:34:57.329687 32652 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I0711 12:34:57.329699 32652 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'conv2', param index 1
I0711 12:34:57.329706 32652 layer_factory.hpp:77] Creating layer pool2_p
I0711 12:34:57.329716 32652 net.cpp:91] Creating Layer pool2_p
I0711 12:34:57.329741 32652 net.cpp:425] pool2_p <- conv2_p
I0711 12:34:57.329756 32652 net.cpp:399] pool2_p -> pool2_p
I0711 12:34:57.329810 32652 net.cpp:141] Setting up pool2_p
I0711 12:34:57.329823 32652 net.cpp:148] Top shape: 64 50 4 4 (51200)
I0711 12:34:57.329831 32652 net.cpp:156] Memory required for data: 10482944
I0711 12:34:57.329839 32652 layer_factory.hpp:77] Creating layer ip1_p
I0711 12:34:57.329855 32652 net.cpp:91] Creating Layer ip1_p
I0711 12:34:57.329864 32652 net.cpp:425] ip1_p <- pool2_p
I0711 12:34:57.329879 32652 net.cpp:399] ip1_p -> ip1_p
I0711 12:34:57.334013 32652 net.cpp:141] Setting up ip1_p
I0711 12:34:57.334035 32652 net.cpp:148] Top shape: 64 500 (32000)
I0711 12:34:57.334043 32652 net.cpp:156] Memory required for data: 10610944
I0711 12:34:57.334053 32652 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'ip1', param index 0
I0711 12:34:57.334062 32652 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'ip1', param index 1
I0711 12:34:57.334069 32652 layer_factory.hpp:77] Creating layer relu1_p
I0711 12:34:57.334084 32652 net.cpp:91] Creating Layer relu1_p
I0711 12:34:57.334091 32652 net.cpp:425] relu1_p <- ip1_p
I0711 12:34:57.334102 32652 net.cpp:386] relu1_p -> ip1_p (in-place)
I0711 12:34:57.334115 32652 net.cpp:141] Setting up relu1_p
I0711 12:34:57.334125 32652 net.cpp:148] Top shape: 64 500 (32000)
I0711 12:34:57.334132 32652 net.cpp:156] Memory required for data: 10738944
I0711 12:34:57.334139 32652 layer_factory.hpp:77] Creating layer ip2_p
I0711 12:34:57.334157 32652 net.cpp:91] Creating Layer ip2_p
I0711 12:34:57.334166 32652 net.cpp:425] ip2_p <- ip1_p
I0711 12:34:57.334177 32652 net.cpp:399] ip2_p -> ip2_p
I0711 12:34:57.334352 32652 net.cpp:141] Setting up ip2_p
I0711 12:34:57.334367 32652 net.cpp:148] Top shape: 64 10 (640)
I0711 12:34:57.334373 32652 net.cpp:156] Memory required for data: 10741504
I0711 12:34:57.334388 32652 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'ip2', param index 0
I0711 12:34:57.334398 32652 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'ip2', param index 1
I0711 12:34:57.334406 32652 layer_factory.hpp:77] Creating layer feat_p
I0711 12:34:57.334417 32652 net.cpp:91] Creating Layer feat_p
I0711 12:34:57.334427 32652 net.cpp:425] feat_p <- ip2_p
I0711 12:34:57.334439 32652 net.cpp:399] feat_p -> feat_p
I0711 12:34:57.334569 32652 net.cpp:141] Setting up feat_p
I0711 12:34:57.334583 32652 net.cpp:148] Top shape: 64 2 (128)
I0711 12:34:57.334590 32652 net.cpp:156] Memory required for data: 10742016
I0711 12:34:57.334597 32652 net.cpp:484] Sharing parameters 'feat_w' owned by layer 'feat', param index 0
I0711 12:34:57.334606 32652 net.cpp:484] Sharing parameters 'feat_b' owned by layer 'feat', param index 1
I0711 12:34:57.334614 32652 layer_factory.hpp:77] Creating layer loss
I0711 12:34:57.334626 32652 net.cpp:91] Creating Layer loss
I0711 12:34:57.334633 32652 net.cpp:425] loss <- feat
I0711 12:34:57.334642 32652 net.cpp:425] loss <- feat_p
I0711 12:34:57.334650 32652 net.cpp:425] loss <- sim
I0711 12:34:57.334666 32652 net.cpp:399] loss -> loss
I0711 12:34:57.334784 32652 net.cpp:141] Setting up loss
I0711 12:34:57.334799 32652 net.cpp:148] Top shape: (1)
I0711 12:34:57.334805 32652 net.cpp:151]     with loss weight 1
I0711 12:34:57.334832 32652 net.cpp:156] Memory required for data: 10742020
I0711 12:34:57.334839 32652 net.cpp:217] loss needs backward computation.
I0711 12:34:57.334847 32652 net.cpp:217] feat_p needs backward computation.
I0711 12:34:57.334856 32652 net.cpp:217] ip2_p needs backward computation.
I0711 12:34:57.334862 32652 net.cpp:217] relu1_p needs backward computation.
I0711 12:34:57.334869 32652 net.cpp:217] ip1_p needs backward computation.
I0711 12:34:57.334877 32652 net.cpp:217] pool2_p needs backward computation.
I0711 12:34:57.334884 32652 net.cpp:217] conv2_p needs backward computation.
I0711 12:34:57.334892 32652 net.cpp:217] pool1_p needs backward computation.
I0711 12:34:57.334899 32652 net.cpp:217] conv1_p needs backward computation.
I0711 12:34:57.334908 32652 net.cpp:217] feat needs backward computation.
I0711 12:34:57.334930 32652 net.cpp:217] ip2 needs backward computation.
I0711 12:34:57.334939 32652 net.cpp:217] relu1 needs backward computation.
I0711 12:34:57.334946 32652 net.cpp:217] ip1 needs backward computation.
I0711 12:34:57.334954 32652 net.cpp:217] pool2 needs backward computation.
I0711 12:34:57.334961 32652 net.cpp:217] conv2 needs backward computation.
I0711 12:34:57.334969 32652 net.cpp:217] pool1 needs backward computation.
I0711 12:34:57.334976 32652 net.cpp:217] conv1 needs backward computation.
I0711 12:34:57.334985 32652 net.cpp:219] slice_pair does not need backward computation.
I0711 12:34:57.334993 32652 net.cpp:219] pair_data does not need backward computation.
I0711 12:34:57.335000 32652 net.cpp:261] This network produces output loss
I0711 12:34:57.335628 32652 net.cpp:274] Network initialization done.
I0711 12:34:57.336680 32652 solver.cpp:181] Creating test net (#0) specified by net file: examples/siamese/mnist_siamese_train_test.prototxt
I0711 12:34:57.336743 32652 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer pair_data
I0711 12:34:57.336997 32652 net.cpp:49] Initializing net from parameters: 
name: "mnist_siamese_train_test"
state {
  phase: TEST
}
layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/siamese/mnist_siamese_test_leveldb_0to6"
    batch_size: 100
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "pool2_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "ip2_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "ip2_p"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip2_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I0711 12:34:57.337152 32652 layer_factory.hpp:77] Creating layer pair_data
I0711 12:34:57.337332 32652 net.cpp:91] Creating Layer pair_data
I0711 12:34:57.337344 32652 net.cpp:399] pair_data -> pair_data
I0711 12:34:57.337359 32652 net.cpp:399] pair_data -> sim
I0711 12:34:57.625644 32660 db_leveldb.cpp:18] Opened leveldb examples/siamese/mnist_siamese_test_leveldb_0to6
I0711 12:34:57.626533 32652 data_layer.cpp:41] output data size: 100,2,28,28
I0711 12:34:57.631371 32652 net.cpp:141] Setting up pair_data
I0711 12:34:57.631430 32652 net.cpp:148] Top shape: 100 2 28 28 (156800)
I0711 12:34:57.631458 32652 net.cpp:148] Top shape: 100 (100)
I0711 12:34:57.631484 32652 net.cpp:156] Memory required for data: 627600
I0711 12:34:57.631503 32652 layer_factory.hpp:77] Creating layer slice_pair
I0711 12:34:57.631546 32652 net.cpp:91] Creating Layer slice_pair
I0711 12:34:57.631563 32652 net.cpp:425] slice_pair <- pair_data
I0711 12:34:57.631592 32652 net.cpp:399] slice_pair -> data
I0711 12:34:57.631628 32652 net.cpp:399] slice_pair -> data_p
I0711 12:34:57.631778 32652 net.cpp:141] Setting up slice_pair
I0711 12:34:57.631803 32652 net.cpp:148] Top shape: 100 1 28 28 (78400)
I0711 12:34:57.631825 32652 net.cpp:148] Top shape: 100 1 28 28 (78400)
I0711 12:34:57.631839 32652 net.cpp:156] Memory required for data: 1254800
I0711 12:34:57.631855 32652 layer_factory.hpp:77] Creating layer conv1
I0711 12:34:57.631896 32652 net.cpp:91] Creating Layer conv1
I0711 12:34:57.631913 32652 net.cpp:425] conv1 <- data
I0711 12:34:57.631944 32652 net.cpp:399] conv1 -> conv1
I0711 12:34:57.632978 32652 net.cpp:141] Setting up conv1
I0711 12:34:57.633011 32652 net.cpp:148] Top shape: 100 20 24 24 (1152000)
I0711 12:34:57.633029 32652 net.cpp:156] Memory required for data: 5862800
I0711 12:34:57.633064 32652 layer_factory.hpp:77] Creating layer pool1
I0711 12:34:57.633095 32652 net.cpp:91] Creating Layer pool1
I0711 12:34:57.633124 32652 net.cpp:425] pool1 <- conv1
I0711 12:34:57.633148 32652 net.cpp:399] pool1 -> pool1
I0711 12:34:57.633275 32652 net.cpp:141] Setting up pool1
I0711 12:34:57.633303 32652 net.cpp:148] Top shape: 100 20 12 12 (288000)
I0711 12:34:57.633321 32652 net.cpp:156] Memory required for data: 7014800
I0711 12:34:57.633337 32652 layer_factory.hpp:77] Creating layer conv2
I0711 12:34:57.633420 32652 net.cpp:91] Creating Layer conv2
I0711 12:34:57.633446 32652 net.cpp:425] conv2 <- pool1
I0711 12:34:57.633476 32652 net.cpp:399] conv2 -> conv2
I0711 12:34:57.634678 32652 net.cpp:141] Setting up conv2
I0711 12:34:57.634708 32652 net.cpp:148] Top shape: 100 50 8 8 (320000)
I0711 12:34:57.634732 32652 net.cpp:156] Memory required for data: 8294800
I0711 12:34:57.634773 32652 layer_factory.hpp:77] Creating layer pool2
I0711 12:34:57.634802 32652 net.cpp:91] Creating Layer pool2
I0711 12:34:57.634820 32652 net.cpp:425] pool2 <- conv2
I0711 12:34:57.634843 32652 net.cpp:399] pool2 -> pool2
I0711 12:34:57.634965 32652 net.cpp:141] Setting up pool2
I0711 12:34:57.634999 32652 net.cpp:148] Top shape: 100 50 4 4 (80000)
I0711 12:34:57.635016 32652 net.cpp:156] Memory required for data: 8614800
I0711 12:34:57.635035 32652 layer_factory.hpp:77] Creating layer ip1
I0711 12:34:57.635068 32652 net.cpp:91] Creating Layer ip1
I0711 12:34:57.635085 32652 net.cpp:425] ip1 <- pool2
I0711 12:34:57.635118 32652 net.cpp:399] ip1 -> ip1
I0711 12:34:57.641376 32652 net.cpp:141] Setting up ip1
I0711 12:34:57.641402 32652 net.cpp:148] Top shape: 100 500 (50000)
I0711 12:34:57.641410 32652 net.cpp:156] Memory required for data: 8814800
I0711 12:34:57.641429 32652 layer_factory.hpp:77] Creating layer relu1
I0711 12:34:57.641443 32652 net.cpp:91] Creating Layer relu1
I0711 12:34:57.641451 32652 net.cpp:425] relu1 <- ip1
I0711 12:34:57.641465 32652 net.cpp:386] relu1 -> ip1 (in-place)
I0711 12:34:57.641480 32652 net.cpp:141] Setting up relu1
I0711 12:34:57.641490 32652 net.cpp:148] Top shape: 100 500 (50000)
I0711 12:34:57.641499 32652 net.cpp:156] Memory required for data: 9014800
I0711 12:34:57.641506 32652 layer_factory.hpp:77] Creating layer ip2
I0711 12:34:57.641525 32652 net.cpp:91] Creating Layer ip2
I0711 12:34:57.641532 32652 net.cpp:425] ip2 <- ip1
I0711 12:34:57.641543 32652 net.cpp:399] ip2 -> ip2
I0711 12:34:57.641722 32652 net.cpp:141] Setting up ip2
I0711 12:34:57.641736 32652 net.cpp:148] Top shape: 100 10 (1000)
I0711 12:34:57.641743 32652 net.cpp:156] Memory required for data: 9018800
I0711 12:34:57.641754 32652 layer_factory.hpp:77] Creating layer feat
I0711 12:34:57.641768 32652 net.cpp:91] Creating Layer feat
I0711 12:34:57.641777 32652 net.cpp:425] feat <- ip2
I0711 12:34:57.641789 32652 net.cpp:399] feat -> feat
I0711 12:34:57.641928 32652 net.cpp:141] Setting up feat
I0711 12:34:57.641942 32652 net.cpp:148] Top shape: 100 2 (200)
I0711 12:34:57.641949 32652 net.cpp:156] Memory required for data: 9019600
I0711 12:34:57.641964 32652 layer_factory.hpp:77] Creating layer conv1_p
I0711 12:34:57.642030 32652 net.cpp:91] Creating Layer conv1_p
I0711 12:34:57.642041 32652 net.cpp:425] conv1_p <- data_p
I0711 12:34:57.642055 32652 net.cpp:399] conv1_p -> conv1_p
I0711 12:34:57.642393 32652 net.cpp:141] Setting up conv1_p
I0711 12:34:57.642405 32652 net.cpp:148] Top shape: 100 20 24 24 (1152000)
I0711 12:34:57.642411 32652 net.cpp:156] Memory required for data: 13627600
I0711 12:34:57.642417 32652 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I0711 12:34:57.642424 32652 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'conv1', param index 1
I0711 12:34:57.642431 32652 layer_factory.hpp:77] Creating layer pool1_p
I0711 12:34:57.642442 32652 net.cpp:91] Creating Layer pool1_p
I0711 12:34:57.642448 32652 net.cpp:425] pool1_p <- conv1_p
I0711 12:34:57.642457 32652 net.cpp:399] pool1_p -> pool1_p
I0711 12:34:57.642508 32652 net.cpp:141] Setting up pool1_p
I0711 12:34:57.642518 32652 net.cpp:148] Top shape: 100 20 12 12 (288000)
I0711 12:34:57.642524 32652 net.cpp:156] Memory required for data: 14779600
I0711 12:34:57.642529 32652 layer_factory.hpp:77] Creating layer conv2_p
I0711 12:34:57.642542 32652 net.cpp:91] Creating Layer conv2_p
I0711 12:34:57.642549 32652 net.cpp:425] conv2_p <- pool1_p
I0711 12:34:57.642560 32652 net.cpp:399] conv2_p -> conv2_p
I0711 12:34:57.643056 32652 net.cpp:141] Setting up conv2_p
I0711 12:34:57.643066 32652 net.cpp:148] Top shape: 100 50 8 8 (320000)
I0711 12:34:57.643088 32652 net.cpp:156] Memory required for data: 16059600
I0711 12:34:57.643095 32652 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I0711 12:34:57.643101 32652 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'conv2', param index 1
I0711 12:34:57.643107 32652 layer_factory.hpp:77] Creating layer pool2_p
I0711 12:34:57.643115 32652 net.cpp:91] Creating Layer pool2_p
I0711 12:34:57.643121 32652 net.cpp:425] pool2_p <- conv2_p
I0711 12:34:57.643131 32652 net.cpp:399] pool2_p -> pool2_p
I0711 12:34:57.643179 32652 net.cpp:141] Setting up pool2_p
I0711 12:34:57.643187 32652 net.cpp:148] Top shape: 100 50 4 4 (80000)
I0711 12:34:57.643193 32652 net.cpp:156] Memory required for data: 16379600
I0711 12:34:57.643206 32652 layer_factory.hpp:77] Creating layer ip1_p
I0711 12:34:57.643226 32652 net.cpp:91] Creating Layer ip1_p
I0711 12:34:57.643234 32652 net.cpp:425] ip1_p <- pool2_p
I0711 12:34:57.643244 32652 net.cpp:399] ip1_p -> ip1_p
I0711 12:34:57.647409 32652 net.cpp:141] Setting up ip1_p
I0711 12:34:57.647429 32652 net.cpp:148] Top shape: 100 500 (50000)
I0711 12:34:57.647436 32652 net.cpp:156] Memory required for data: 16579600
I0711 12:34:57.647444 32652 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'ip1', param index 0
I0711 12:34:57.647451 32652 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'ip1', param index 1
I0711 12:34:57.647457 32652 layer_factory.hpp:77] Creating layer relu1_p
I0711 12:34:57.647469 32652 net.cpp:91] Creating Layer relu1_p
I0711 12:34:57.647475 32652 net.cpp:425] relu1_p <- ip1_p
I0711 12:34:57.647485 32652 net.cpp:386] relu1_p -> ip1_p (in-place)
I0711 12:34:57.647495 32652 net.cpp:141] Setting up relu1_p
I0711 12:34:57.647502 32652 net.cpp:148] Top shape: 100 500 (50000)
I0711 12:34:57.647508 32652 net.cpp:156] Memory required for data: 16779600
I0711 12:34:57.647513 32652 layer_factory.hpp:77] Creating layer ip2_p
I0711 12:34:57.647528 32652 net.cpp:91] Creating Layer ip2_p
I0711 12:34:57.647534 32652 net.cpp:425] ip2_p <- ip1_p
I0711 12:34:57.647543 32652 net.cpp:399] ip2_p -> ip2_p
I0711 12:34:57.647712 32652 net.cpp:141] Setting up ip2_p
I0711 12:34:57.647722 32652 net.cpp:148] Top shape: 100 10 (1000)
I0711 12:34:57.647728 32652 net.cpp:156] Memory required for data: 16783600
I0711 12:34:57.647740 32652 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'ip2', param index 0
I0711 12:34:57.647748 32652 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'ip2', param index 1
I0711 12:34:57.647754 32652 layer_factory.hpp:77] Creating layer feat_p
I0711 12:34:57.647763 32652 net.cpp:91] Creating Layer feat_p
I0711 12:34:57.647769 32652 net.cpp:425] feat_p <- ip2_p
I0711 12:34:57.647780 32652 net.cpp:399] feat_p -> feat_p
I0711 12:34:57.647905 32652 net.cpp:141] Setting up feat_p
I0711 12:34:57.647915 32652 net.cpp:148] Top shape: 100 2 (200)
I0711 12:34:57.647920 32652 net.cpp:156] Memory required for data: 16784400
I0711 12:34:57.647927 32652 net.cpp:484] Sharing parameters 'feat_w' owned by layer 'feat', param index 0
I0711 12:34:57.647933 32652 net.cpp:484] Sharing parameters 'feat_b' owned by layer 'feat', param index 1
I0711 12:34:57.647939 32652 layer_factory.hpp:77] Creating layer loss
I0711 12:34:57.647948 32652 net.cpp:91] Creating Layer loss
I0711 12:34:57.647954 32652 net.cpp:425] loss <- feat
I0711 12:34:57.647961 32652 net.cpp:425] loss <- feat_p
I0711 12:34:57.647967 32652 net.cpp:425] loss <- sim
I0711 12:34:57.647979 32652 net.cpp:399] loss -> loss
I0711 12:34:57.648088 32652 net.cpp:141] Setting up loss
I0711 12:34:57.648097 32652 net.cpp:148] Top shape: (1)
I0711 12:34:57.648103 32652 net.cpp:151]     with loss weight 1
I0711 12:34:57.648118 32652 net.cpp:156] Memory required for data: 16784404
I0711 12:34:57.648123 32652 net.cpp:217] loss needs backward computation.
I0711 12:34:57.648130 32652 net.cpp:217] feat_p needs backward computation.
I0711 12:34:57.648136 32652 net.cpp:217] ip2_p needs backward computation.
I0711 12:34:57.648141 32652 net.cpp:217] relu1_p needs backward computation.
I0711 12:34:57.648164 32652 net.cpp:217] ip1_p needs backward computation.
I0711 12:34:57.648170 32652 net.cpp:217] pool2_p needs backward computation.
I0711 12:34:57.648175 32652 net.cpp:217] conv2_p needs backward computation.
I0711 12:34:57.648181 32652 net.cpp:217] pool1_p needs backward computation.
I0711 12:34:57.648187 32652 net.cpp:217] conv1_p needs backward computation.
I0711 12:34:57.648193 32652 net.cpp:217] feat needs backward computation.
I0711 12:34:57.648200 32652 net.cpp:217] ip2 needs backward computation.
I0711 12:34:57.648205 32652 net.cpp:217] relu1 needs backward computation.
I0711 12:34:57.648211 32652 net.cpp:217] ip1 needs backward computation.
I0711 12:34:57.648216 32652 net.cpp:217] pool2 needs backward computation.
I0711 12:34:57.648222 32652 net.cpp:217] conv2 needs backward computation.
I0711 12:34:57.648228 32652 net.cpp:217] pool1 needs backward computation.
I0711 12:34:57.648233 32652 net.cpp:217] conv1 needs backward computation.
I0711 12:34:57.648241 32652 net.cpp:219] slice_pair does not need backward computation.
I0711 12:34:57.648247 32652 net.cpp:219] pair_data does not need backward computation.
I0711 12:34:57.648252 32652 net.cpp:261] This network produces output loss
I0711 12:34:57.648849 32652 net.cpp:274] Network initialization done.
I0711 12:34:57.649013 32652 solver.cpp:60] Solver scaffolding done.
I0711 12:34:57.649512 32652 caffe.cpp:219] Starting Optimization
I0711 12:34:57.649519 32652 solver.cpp:279] Solving mnist_siamese_train_test
I0711 12:34:57.649528 32652 solver.cpp:280] Learning Rate Policy: inv
I0711 12:34:57.650146 32652 solver.cpp:337] Iteration 0, Testing net (#0)
I0711 12:34:59.769172 32652 solver.cpp:404]     Test net output #0: loss = 0.255507 (* 1 = 0.255507 loss)
I0711 12:34:59.795303 32652 solver.cpp:228] Iteration 0, loss = 0.273391
I0711 12:34:59.795337 32652 solver.cpp:244]     Train net output #0: loss = 0.273391 (* 1 = 0.273391 loss)
I0711 12:34:59.795358 32652 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0711 12:35:02.948283 32652 solver.cpp:228] Iteration 100, loss = 0.0196779
I0711 12:35:02.948329 32652 solver.cpp:244]     Train net output #0: loss = 0.0196779 (* 1 = 0.0196779 loss)
I0711 12:35:02.948340 32652 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0711 12:35:06.083432 32652 solver.cpp:228] Iteration 200, loss = 0.0360882
I0711 12:35:06.083480 32652 solver.cpp:244]     Train net output #0: loss = 0.0360882 (* 1 = 0.0360882 loss)
I0711 12:35:06.083492 32652 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0711 12:35:09.214609 32652 solver.cpp:228] Iteration 300, loss = 0.0409191
I0711 12:35:09.214663 32652 solver.cpp:244]     Train net output #0: loss = 0.0409191 (* 1 = 0.0409191 loss)
I0711 12:35:09.214673 32652 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0711 12:35:12.354111 32652 solver.cpp:228] Iteration 400, loss = 0.0350098
I0711 12:35:12.354156 32652 solver.cpp:244]     Train net output #0: loss = 0.0350098 (* 1 = 0.0350098 loss)
I0711 12:35:12.354166 32652 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0711 12:35:15.456099 32652 solver.cpp:337] Iteration 500, Testing net (#0)
I0711 12:35:17.551687 32652 solver.cpp:404]     Test net output #0: loss = 0.0230076 (* 1 = 0.0230076 loss)
I0711 12:35:17.574369 32652 solver.cpp:228] Iteration 500, loss = 0.022709
I0711 12:35:17.574407 32652 solver.cpp:244]     Train net output #0: loss = 0.022709 (* 1 = 0.022709 loss)
I0711 12:35:17.574419 32652 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0711 12:35:20.711017 32652 solver.cpp:228] Iteration 600, loss = 0.00923561
I0711 12:35:20.711062 32652 solver.cpp:244]     Train net output #0: loss = 0.00923562 (* 1 = 0.00923562 loss)
I0711 12:35:20.711073 32652 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0711 12:35:23.867040 32652 solver.cpp:228] Iteration 700, loss = 0.02195
I0711 12:35:23.867094 32652 solver.cpp:244]     Train net output #0: loss = 0.02195 (* 1 = 0.02195 loss)
I0711 12:35:23.867103 32652 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0711 12:35:27.032626 32652 solver.cpp:228] Iteration 800, loss = 0.0118684
I0711 12:35:27.032791 32652 solver.cpp:244]     Train net output #0: loss = 0.0118684 (* 1 = 0.0118684 loss)
I0711 12:35:27.032804 32652 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0711 12:35:30.190147 32652 solver.cpp:228] Iteration 900, loss = 0.0162464
I0711 12:35:30.190193 32652 solver.cpp:244]     Train net output #0: loss = 0.0162464 (* 1 = 0.0162464 loss)
I0711 12:35:30.190203 32652 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0711 12:35:33.293463 32652 solver.cpp:337] Iteration 1000, Testing net (#0)
I0711 12:35:35.392633 32652 solver.cpp:404]     Test net output #0: loss = 0.0174167 (* 1 = 0.0174167 loss)
I0711 12:35:35.415287 32652 solver.cpp:228] Iteration 1000, loss = 0.0149228
I0711 12:35:35.415315 32652 solver.cpp:244]     Train net output #0: loss = 0.0149228 (* 1 = 0.0149228 loss)
I0711 12:35:35.415328 32652 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0711 12:35:38.552973 32652 solver.cpp:228] Iteration 1100, loss = 0.0220577
I0711 12:35:38.553020 32652 solver.cpp:244]     Train net output #0: loss = 0.0220577 (* 1 = 0.0220577 loss)
I0711 12:35:38.553031 32652 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0711 12:35:41.689115 32652 solver.cpp:228] Iteration 1200, loss = 0.044777
I0711 12:35:41.689168 32652 solver.cpp:244]     Train net output #0: loss = 0.044777 (* 1 = 0.044777 loss)
I0711 12:35:41.689177 32652 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0711 12:35:44.833835 32652 solver.cpp:228] Iteration 1300, loss = 0.0299777
I0711 12:35:44.833889 32652 solver.cpp:244]     Train net output #0: loss = 0.0299777 (* 1 = 0.0299777 loss)
I0711 12:35:44.833899 32652 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0711 12:35:47.992322 32652 solver.cpp:228] Iteration 1400, loss = 0.00550237
I0711 12:35:47.992367 32652 solver.cpp:244]     Train net output #0: loss = 0.00550237 (* 1 = 0.00550237 loss)
I0711 12:35:47.992377 32652 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0711 12:35:51.120332 32652 solver.cpp:337] Iteration 1500, Testing net (#0)
I0711 12:35:53.230350 32652 solver.cpp:404]     Test net output #0: loss = 0.0151721 (* 1 = 0.0151721 loss)
I0711 12:35:53.252840 32652 solver.cpp:228] Iteration 1500, loss = 0.0238753
I0711 12:35:53.252878 32652 solver.cpp:244]     Train net output #0: loss = 0.0238753 (* 1 = 0.0238753 loss)
I0711 12:35:53.252890 32652 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0711 12:35:56.390661 32652 solver.cpp:228] Iteration 1600, loss = 0.010761
I0711 12:35:56.390707 32652 solver.cpp:244]     Train net output #0: loss = 0.010761 (* 1 = 0.010761 loss)
I0711 12:35:56.390717 32652 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0711 12:35:59.530773 32652 solver.cpp:228] Iteration 1700, loss = 0.0119096
I0711 12:35:59.530879 32652 solver.cpp:244]     Train net output #0: loss = 0.0119096 (* 1 = 0.0119096 loss)
I0711 12:35:59.530890 32652 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0711 12:36:02.674299 32652 solver.cpp:228] Iteration 1800, loss = 0.012534
I0711 12:36:02.674351 32652 solver.cpp:244]     Train net output #0: loss = 0.012534 (* 1 = 0.012534 loss)
I0711 12:36:02.674361 32652 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0711 12:36:05.832950 32652 solver.cpp:228] Iteration 1900, loss = 0.0100401
I0711 12:36:05.833003 32652 solver.cpp:244]     Train net output #0: loss = 0.0100401 (* 1 = 0.0100401 loss)
I0711 12:36:05.833012 32652 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0711 12:36:08.952539 32652 solver.cpp:337] Iteration 2000, Testing net (#0)
I0711 12:36:11.047116 32652 solver.cpp:404]     Test net output #0: loss = 0.0144291 (* 1 = 0.0144291 loss)
I0711 12:36:11.069861 32652 solver.cpp:228] Iteration 2000, loss = 0.00558212
I0711 12:36:11.069893 32652 solver.cpp:244]     Train net output #0: loss = 0.00558211 (* 1 = 0.00558211 loss)
I0711 12:36:11.069914 32652 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0711 12:36:14.215562 32652 solver.cpp:228] Iteration 2100, loss = 0.00994473
I0711 12:36:14.215610 32652 solver.cpp:244]     Train net output #0: loss = 0.00994472 (* 1 = 0.00994472 loss)
I0711 12:36:14.215620 32652 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0711 12:36:17.374804 32652 solver.cpp:228] Iteration 2200, loss = 0.00989514
I0711 12:36:17.374848 32652 solver.cpp:244]     Train net output #0: loss = 0.00989513 (* 1 = 0.00989513 loss)
I0711 12:36:17.374861 32652 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0711 12:36:20.533742 32652 solver.cpp:228] Iteration 2300, loss = 0.010291
I0711 12:36:20.533789 32652 solver.cpp:244]     Train net output #0: loss = 0.010291 (* 1 = 0.010291 loss)
I0711 12:36:20.533800 32652 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0711 12:36:23.679500 32652 solver.cpp:228] Iteration 2400, loss = 0.0119637
I0711 12:36:23.679550 32652 solver.cpp:244]     Train net output #0: loss = 0.0119637 (* 1 = 0.0119637 loss)
I0711 12:36:23.679560 32652 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0711 12:36:26.816408 32652 solver.cpp:337] Iteration 2500, Testing net (#0)
I0711 12:36:28.918180 32652 solver.cpp:404]     Test net output #0: loss = 0.0125302 (* 1 = 0.0125302 loss)
I0711 12:36:28.940866 32652 solver.cpp:228] Iteration 2500, loss = 0.0106198
I0711 12:36:28.940899 32652 solver.cpp:244]     Train net output #0: loss = 0.0106198 (* 1 = 0.0106198 loss)
I0711 12:36:28.940920 32652 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0711 12:36:32.105623 32652 solver.cpp:228] Iteration 2600, loss = 0.0327728
I0711 12:36:32.105844 32652 solver.cpp:244]     Train net output #0: loss = 0.0327728 (* 1 = 0.0327728 loss)
I0711 12:36:32.105859 32652 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0711 12:36:35.264257 32652 solver.cpp:228] Iteration 2700, loss = 0.0120225
I0711 12:36:35.264300 32652 solver.cpp:244]     Train net output #0: loss = 0.0120225 (* 1 = 0.0120225 loss)
I0711 12:36:35.264312 32652 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0711 12:36:38.422662 32652 solver.cpp:228] Iteration 2800, loss = 0.0121103
I0711 12:36:38.422713 32652 solver.cpp:244]     Train net output #0: loss = 0.0121103 (* 1 = 0.0121103 loss)
I0711 12:36:38.422724 32652 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0711 12:36:41.565819 32652 solver.cpp:228] Iteration 2900, loss = 0.013
I0711 12:36:41.565865 32652 solver.cpp:244]     Train net output #0: loss = 0.013 (* 1 = 0.013 loss)
I0711 12:36:41.565876 32652 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0711 12:36:44.675843 32652 solver.cpp:337] Iteration 3000, Testing net (#0)
I0711 12:36:46.772747 32652 solver.cpp:404]     Test net output #0: loss = 0.0119746 (* 1 = 0.0119746 loss)
I0711 12:36:46.795514 32652 solver.cpp:228] Iteration 3000, loss = 0.0045188
I0711 12:36:46.795539 32652 solver.cpp:244]     Train net output #0: loss = 0.00451877 (* 1 = 0.00451877 loss)
I0711 12:36:46.795552 32652 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0711 12:36:49.955340 32652 solver.cpp:228] Iteration 3100, loss = 0.00842477
I0711 12:36:49.955394 32652 solver.cpp:244]     Train net output #0: loss = 0.00842474 (* 1 = 0.00842474 loss)
I0711 12:36:49.955404 32652 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0711 12:36:53.114738 32652 solver.cpp:228] Iteration 3200, loss = 0.00496381
I0711 12:36:53.114790 32652 solver.cpp:244]     Train net output #0: loss = 0.00496378 (* 1 = 0.00496378 loss)
I0711 12:36:53.114800 32652 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0711 12:36:56.279052 32652 solver.cpp:228] Iteration 3300, loss = 0.00685379
I0711 12:36:56.279104 32652 solver.cpp:244]     Train net output #0: loss = 0.00685375 (* 1 = 0.00685375 loss)
I0711 12:36:56.279115 32652 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0711 12:36:59.457514 32652 solver.cpp:228] Iteration 3400, loss = 0.00946194
I0711 12:36:59.457556 32652 solver.cpp:244]     Train net output #0: loss = 0.00946191 (* 1 = 0.00946191 loss)
I0711 12:36:59.457566 32652 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0711 12:37:02.609653 32652 solver.cpp:337] Iteration 3500, Testing net (#0)
I0711 12:37:04.725384 32652 solver.cpp:404]     Test net output #0: loss = 0.0119746 (* 1 = 0.0119746 loss)
I0711 12:37:04.748241 32652 solver.cpp:228] Iteration 3500, loss = 0.00983391
I0711 12:37:04.748271 32652 solver.cpp:244]     Train net output #0: loss = 0.00983388 (* 1 = 0.00983388 loss)
I0711 12:37:04.748286 32652 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0711 12:37:07.907517 32652 solver.cpp:228] Iteration 3600, loss = 0.00146143
I0711 12:37:07.907564 32652 solver.cpp:244]     Train net output #0: loss = 0.0014614 (* 1 = 0.0014614 loss)
I0711 12:37:07.907575 32652 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0711 12:37:11.071928 32652 solver.cpp:228] Iteration 3700, loss = 0.00315601
I0711 12:37:11.071972 32652 solver.cpp:244]     Train net output #0: loss = 0.00315598 (* 1 = 0.00315598 loss)
I0711 12:37:11.071984 32652 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0711 12:37:14.232841 32652 solver.cpp:228] Iteration 3800, loss = 0.00848104
I0711 12:37:14.232888 32652 solver.cpp:244]     Train net output #0: loss = 0.008481 (* 1 = 0.008481 loss)
I0711 12:37:14.232898 32652 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0711 12:37:17.393992 32652 solver.cpp:228] Iteration 3900, loss = 0.00855265
I0711 12:37:17.394047 32652 solver.cpp:244]     Train net output #0: loss = 0.00855261 (* 1 = 0.00855261 loss)
I0711 12:37:17.394057 32652 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0711 12:37:20.524962 32652 solver.cpp:337] Iteration 4000, Testing net (#0)
I0711 12:37:22.650475 32652 solver.cpp:404]     Test net output #0: loss = 0.0113093 (* 1 = 0.0113093 loss)
I0711 12:37:22.673254 32652 solver.cpp:228] Iteration 4000, loss = 0.00328932
I0711 12:37:22.673292 32652 solver.cpp:244]     Train net output #0: loss = 0.00328929 (* 1 = 0.00328929 loss)
I0711 12:37:22.673305 32652 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0711 12:37:25.842327 32652 solver.cpp:228] Iteration 4100, loss = 0.00529023
I0711 12:37:25.842372 32652 solver.cpp:244]     Train net output #0: loss = 0.0052902 (* 1 = 0.0052902 loss)
I0711 12:37:25.842382 32652 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0711 12:37:29.005637 32652 solver.cpp:228] Iteration 4200, loss = 0.00295331
I0711 12:37:29.005691 32652 solver.cpp:244]     Train net output #0: loss = 0.00295328 (* 1 = 0.00295328 loss)
I0711 12:37:29.005700 32652 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0711 12:37:32.173872 32652 solver.cpp:228] Iteration 4300, loss = 0.00667594
I0711 12:37:32.173918 32652 solver.cpp:244]     Train net output #0: loss = 0.00667591 (* 1 = 0.00667591 loss)
I0711 12:37:32.173929 32652 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0711 12:37:35.342062 32652 solver.cpp:228] Iteration 4400, loss = 0.0087548
I0711 12:37:35.342180 32652 solver.cpp:244]     Train net output #0: loss = 0.00875476 (* 1 = 0.00875476 loss)
I0711 12:37:35.342195 32652 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0711 12:37:38.473742 32652 solver.cpp:337] Iteration 4500, Testing net (#0)
I0711 12:37:40.594785 32652 solver.cpp:404]     Test net output #0: loss = 0.0112009 (* 1 = 0.0112009 loss)
I0711 12:37:40.617799 32652 solver.cpp:228] Iteration 4500, loss = 0.00400161
I0711 12:37:40.617835 32652 solver.cpp:244]     Train net output #0: loss = 0.00400158 (* 1 = 0.00400158 loss)
I0711 12:37:40.617847 32652 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0711 12:37:43.782430 32652 solver.cpp:228] Iteration 4600, loss = 0.00814904
I0711 12:37:43.782477 32652 solver.cpp:244]     Train net output #0: loss = 0.00814901 (* 1 = 0.00814901 loss)
I0711 12:37:43.782487 32652 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0711 12:37:46.962411 32652 solver.cpp:228] Iteration 4700, loss = 0.00721577
I0711 12:37:46.962465 32652 solver.cpp:244]     Train net output #0: loss = 0.00721574 (* 1 = 0.00721574 loss)
I0711 12:37:46.962474 32652 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0711 12:37:50.144814 32652 solver.cpp:228] Iteration 4800, loss = 0.00424298
I0711 12:37:50.144867 32652 solver.cpp:244]     Train net output #0: loss = 0.00424295 (* 1 = 0.00424295 loss)
I0711 12:37:50.144877 32652 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0711 12:37:53.311772 32652 solver.cpp:228] Iteration 4900, loss = 0.00245152
I0711 12:37:53.311825 32652 solver.cpp:244]     Train net output #0: loss = 0.00245149 (* 1 = 0.00245149 loss)
I0711 12:37:53.311835 32652 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0711 12:37:56.459785 32652 solver.cpp:337] Iteration 5000, Testing net (#0)
I0711 12:37:58.576100 32652 solver.cpp:404]     Test net output #0: loss = 0.0109512 (* 1 = 0.0109512 loss)
I0711 12:37:58.599313 32652 solver.cpp:228] Iteration 5000, loss = 0.0100788
I0711 12:37:58.599354 32652 solver.cpp:244]     Train net output #0: loss = 0.0100788 (* 1 = 0.0100788 loss)
I0711 12:37:58.599366 32652 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0711 12:38:01.768616 32652 solver.cpp:228] Iteration 5100, loss = 0.00353494
I0711 12:38:01.768669 32652 solver.cpp:244]     Train net output #0: loss = 0.00353492 (* 1 = 0.00353492 loss)
I0711 12:38:01.768679 32652 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0711 12:38:04.936632 32652 solver.cpp:228] Iteration 5200, loss = 0.00663319
I0711 12:38:04.936686 32652 solver.cpp:244]     Train net output #0: loss = 0.00663316 (* 1 = 0.00663316 loss)
I0711 12:38:04.936696 32652 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0711 12:38:08.101372 32652 solver.cpp:228] Iteration 5300, loss = 0.00572059
I0711 12:38:08.101521 32652 solver.cpp:244]     Train net output #0: loss = 0.00572056 (* 1 = 0.00572056 loss)
I0711 12:38:08.101532 32652 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0711 12:38:11.261221 32652 solver.cpp:228] Iteration 5400, loss = 0.00285085
I0711 12:38:11.261271 32652 solver.cpp:244]     Train net output #0: loss = 0.00285083 (* 1 = 0.00285083 loss)
I0711 12:38:11.261281 32652 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0711 12:38:14.389410 32652 solver.cpp:337] Iteration 5500, Testing net (#0)
I0711 12:38:16.516492 32652 solver.cpp:404]     Test net output #0: loss = 0.0104916 (* 1 = 0.0104916 loss)
I0711 12:38:16.539039 32652 solver.cpp:228] Iteration 5500, loss = 0.0036742
I0711 12:38:16.539070 32652 solver.cpp:244]     Train net output #0: loss = 0.00367417 (* 1 = 0.00367417 loss)
I0711 12:38:16.539083 32652 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0711 12:38:19.698122 32652 solver.cpp:228] Iteration 5600, loss = 0.0112175
I0711 12:38:19.698169 32652 solver.cpp:244]     Train net output #0: loss = 0.0112175 (* 1 = 0.0112175 loss)
I0711 12:38:19.698180 32652 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0711 12:38:22.877277 32652 solver.cpp:228] Iteration 5700, loss = 0.00287891
I0711 12:38:22.877331 32652 solver.cpp:244]     Train net output #0: loss = 0.00287889 (* 1 = 0.00287889 loss)
I0711 12:38:22.877341 32652 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0711 12:38:26.064558 32652 solver.cpp:228] Iteration 5800, loss = 0.00530303
I0711 12:38:26.064605 32652 solver.cpp:244]     Train net output #0: loss = 0.005303 (* 1 = 0.005303 loss)
I0711 12:38:26.064615 32652 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0711 12:38:29.238689 32652 solver.cpp:228] Iteration 5900, loss = 0.00389293
I0711 12:38:29.238735 32652 solver.cpp:244]     Train net output #0: loss = 0.0038929 (* 1 = 0.0038929 loss)
I0711 12:38:29.238745 32652 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0711 12:38:32.377065 32652 solver.cpp:337] Iteration 6000, Testing net (#0)
I0711 12:38:34.510412 32652 solver.cpp:404]     Test net output #0: loss = 0.0104846 (* 1 = 0.0104846 loss)
I0711 12:38:34.533331 32652 solver.cpp:228] Iteration 6000, loss = 0.00485628
I0711 12:38:34.533367 32652 solver.cpp:244]     Train net output #0: loss = 0.00485625 (* 1 = 0.00485625 loss)
I0711 12:38:34.533380 32652 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0711 12:38:37.695636 32652 solver.cpp:228] Iteration 6100, loss = 0.0276246
I0711 12:38:37.695682 32652 solver.cpp:244]     Train net output #0: loss = 0.0276246 (* 1 = 0.0276246 loss)
I0711 12:38:37.695691 32652 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0711 12:38:40.857426 32652 solver.cpp:228] Iteration 6200, loss = 0.0032302
I0711 12:38:40.857640 32652 solver.cpp:244]     Train net output #0: loss = 0.00323017 (* 1 = 0.00323017 loss)
I0711 12:38:40.857650 32652 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0711 12:38:44.015861 32652 solver.cpp:228] Iteration 6300, loss = 0.0105791
I0711 12:38:44.015897 32652 solver.cpp:244]     Train net output #0: loss = 0.0105791 (* 1 = 0.0105791 loss)
I0711 12:38:44.015908 32652 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0711 12:38:47.178870 32652 solver.cpp:228] Iteration 6400, loss = 0.00833849
I0711 12:38:47.178917 32652 solver.cpp:244]     Train net output #0: loss = 0.00833846 (* 1 = 0.00833846 loss)
I0711 12:38:47.178927 32652 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0711 12:38:50.309939 32652 solver.cpp:337] Iteration 6500, Testing net (#0)
I0711 12:38:52.428481 32652 solver.cpp:404]     Test net output #0: loss = 0.0101298 (* 1 = 0.0101298 loss)
I0711 12:38:52.452347 32652 solver.cpp:228] Iteration 6500, loss = 0.00628565
I0711 12:38:52.452383 32652 solver.cpp:244]     Train net output #0: loss = 0.00628562 (* 1 = 0.00628562 loss)
I0711 12:38:52.452404 32652 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0711 12:38:55.612633 32652 solver.cpp:228] Iteration 6600, loss = 0.00595323
I0711 12:38:55.612678 32652 solver.cpp:244]     Train net output #0: loss = 0.00595321 (* 1 = 0.00595321 loss)
I0711 12:38:55.612689 32652 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0711 12:38:58.773530 32652 solver.cpp:228] Iteration 6700, loss = 0.00308336
I0711 12:38:58.773577 32652 solver.cpp:244]     Train net output #0: loss = 0.00308333 (* 1 = 0.00308333 loss)
I0711 12:38:58.773587 32652 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0711 12:39:01.948801 32652 solver.cpp:228] Iteration 6800, loss = 0.00820572
I0711 12:39:01.948853 32652 solver.cpp:244]     Train net output #0: loss = 0.00820569 (* 1 = 0.00820569 loss)
I0711 12:39:01.948864 32652 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0711 12:39:05.126446 32652 solver.cpp:228] Iteration 6900, loss = 0.00578249
I0711 12:39:05.126500 32652 solver.cpp:244]     Train net output #0: loss = 0.00578246 (* 1 = 0.00578246 loss)
I0711 12:39:05.126510 32652 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0711 12:39:08.258848 32652 solver.cpp:337] Iteration 7000, Testing net (#0)
I0711 12:39:10.380314 32652 solver.cpp:404]     Test net output #0: loss = 0.0099172 (* 1 = 0.0099172 loss)
I0711 12:39:10.403206 32652 solver.cpp:228] Iteration 7000, loss = 0.00506359
I0711 12:39:10.403240 32652 solver.cpp:244]     Train net output #0: loss = 0.00506357 (* 1 = 0.00506357 loss)
I0711 12:39:10.403254 32652 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0711 12:39:13.566000 32652 solver.cpp:228] Iteration 7100, loss = 0.00358469
I0711 12:39:13.566108 32652 solver.cpp:244]     Train net output #0: loss = 0.00358467 (* 1 = 0.00358467 loss)
I0711 12:39:13.566119 32652 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0711 12:39:16.725653 32652 solver.cpp:228] Iteration 7200, loss = 0.00531797
I0711 12:39:16.725700 32652 solver.cpp:244]     Train net output #0: loss = 0.00531794 (* 1 = 0.00531794 loss)
I0711 12:39:16.725710 32652 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0711 12:39:19.886175 32652 solver.cpp:228] Iteration 7300, loss = 0.00332552
I0711 12:39:19.886224 32652 solver.cpp:244]     Train net output #0: loss = 0.0033255 (* 1 = 0.0033255 loss)
I0711 12:39:19.886234 32652 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0711 12:39:23.047569 32652 solver.cpp:228] Iteration 7400, loss = 0.00490358
I0711 12:39:23.047622 32652 solver.cpp:244]     Train net output #0: loss = 0.00490355 (* 1 = 0.00490355 loss)
I0711 12:39:23.047634 32652 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0711 12:39:26.183588 32652 solver.cpp:337] Iteration 7500, Testing net (#0)
I0711 12:39:28.331714 32652 solver.cpp:404]     Test net output #0: loss = 0.00962389 (* 1 = 0.00962389 loss)
I0711 12:39:28.354923 32652 solver.cpp:228] Iteration 7500, loss = 0.00390531
I0711 12:39:28.354964 32652 solver.cpp:244]     Train net output #0: loss = 0.00390528 (* 1 = 0.00390528 loss)
I0711 12:39:28.354975 32652 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0711 12:39:31.589251 32652 solver.cpp:228] Iteration 7600, loss = 0.00165262
I0711 12:39:31.589296 32652 solver.cpp:244]     Train net output #0: loss = 0.0016526 (* 1 = 0.0016526 loss)
I0711 12:39:31.589308 32652 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0711 12:39:34.763793 32652 solver.cpp:228] Iteration 7700, loss = 0.00539727
I0711 12:39:34.763840 32652 solver.cpp:244]     Train net output #0: loss = 0.00539725 (* 1 = 0.00539725 loss)
I0711 12:39:34.763850 32652 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0711 12:39:37.923077 32652 solver.cpp:228] Iteration 7800, loss = 0.004826
I0711 12:39:37.923125 32652 solver.cpp:244]     Train net output #0: loss = 0.00482598 (* 1 = 0.00482598 loss)
I0711 12:39:37.923136 32652 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0711 12:39:41.079231 32652 solver.cpp:228] Iteration 7900, loss = 0.0101333
I0711 12:39:41.079284 32652 solver.cpp:244]     Train net output #0: loss = 0.0101332 (* 1 = 0.0101332 loss)
I0711 12:39:41.079298 32652 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0711 12:39:44.244403 32652 solver.cpp:337] Iteration 8000, Testing net (#0)
I0711 12:39:46.398370 32652 solver.cpp:404]     Test net output #0: loss = 0.00982194 (* 1 = 0.00982194 loss)
I0711 12:39:46.421397 32652 solver.cpp:228] Iteration 8000, loss = 0.00461485
I0711 12:39:46.421434 32652 solver.cpp:244]     Train net output #0: loss = 0.00461482 (* 1 = 0.00461482 loss)
I0711 12:39:46.421447 32652 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0711 12:39:49.599333 32652 solver.cpp:228] Iteration 8100, loss = 0.000681352
I0711 12:39:49.599385 32652 solver.cpp:244]     Train net output #0: loss = 0.000681329 (* 1 = 0.000681329 loss)
I0711 12:39:49.599395 32652 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0711 12:39:52.846271 32652 solver.cpp:228] Iteration 8200, loss = 0.00649892
I0711 12:39:52.846324 32652 solver.cpp:244]     Train net output #0: loss = 0.0064989 (* 1 = 0.0064989 loss)
I0711 12:39:52.846335 32652 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0711 12:39:56.147423 32652 solver.cpp:228] Iteration 8300, loss = 0.00352732
I0711 12:39:56.147472 32652 solver.cpp:244]     Train net output #0: loss = 0.00352729 (* 1 = 0.00352729 loss)
I0711 12:39:56.147485 32652 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0711 12:39:59.439383 32652 solver.cpp:228] Iteration 8400, loss = 0.00447846
I0711 12:39:59.439425 32652 solver.cpp:244]     Train net output #0: loss = 0.00447844 (* 1 = 0.00447844 loss)
I0711 12:39:59.439436 32652 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0711 12:40:02.578927 32652 solver.cpp:337] Iteration 8500, Testing net (#0)
I0711 12:40:04.831409 32652 solver.cpp:404]     Test net output #0: loss = 0.00949726 (* 1 = 0.00949726 loss)
I0711 12:40:04.854312 32652 solver.cpp:228] Iteration 8500, loss = 0.00560751
I0711 12:40:04.854351 32652 solver.cpp:244]     Train net output #0: loss = 0.00560748 (* 1 = 0.00560748 loss)
I0711 12:40:04.854362 32652 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0711 12:40:08.098033 32652 solver.cpp:228] Iteration 8600, loss = 0.0073379
I0711 12:40:08.098079 32652 solver.cpp:244]     Train net output #0: loss = 0.00733788 (* 1 = 0.00733788 loss)
I0711 12:40:08.098089 32652 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0711 12:40:11.502889 32652 solver.cpp:228] Iteration 8700, loss = 0.0197957
I0711 12:40:11.502936 32652 solver.cpp:244]     Train net output #0: loss = 0.0197957 (* 1 = 0.0197957 loss)
I0711 12:40:11.502950 32652 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0711 12:40:14.912778 32652 solver.cpp:228] Iteration 8800, loss = 0.00732217
I0711 12:40:14.913002 32652 solver.cpp:244]     Train net output #0: loss = 0.00732215 (* 1 = 0.00732215 loss)
I0711 12:40:14.913017 32652 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0711 12:40:18.082197 32652 solver.cpp:228] Iteration 8900, loss = 0.00207669
I0711 12:40:18.082245 32652 solver.cpp:244]     Train net output #0: loss = 0.00207666 (* 1 = 0.00207666 loss)
I0711 12:40:18.082255 32652 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0711 12:40:21.231376 32652 solver.cpp:337] Iteration 9000, Testing net (#0)
I0711 12:40:23.362099 32652 solver.cpp:404]     Test net output #0: loss = 0.00970556 (* 1 = 0.00970556 loss)
I0711 12:40:23.384884 32652 solver.cpp:228] Iteration 9000, loss = 0.00796262
I0711 12:40:23.384929 32652 solver.cpp:244]     Train net output #0: loss = 0.0079626 (* 1 = 0.0079626 loss)
I0711 12:40:23.384943 32652 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0711 12:40:26.611948 32652 solver.cpp:228] Iteration 9100, loss = 0.00338953
I0711 12:40:26.611995 32652 solver.cpp:244]     Train net output #0: loss = 0.00338951 (* 1 = 0.00338951 loss)
I0711 12:40:26.612006 32652 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0711 12:40:29.822705 32652 solver.cpp:228] Iteration 9200, loss = 0.00253213
I0711 12:40:29.822751 32652 solver.cpp:244]     Train net output #0: loss = 0.00253211 (* 1 = 0.00253211 loss)
I0711 12:40:29.822762 32652 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0711 12:40:33.010568 32652 solver.cpp:228] Iteration 9300, loss = 0.00437275
I0711 12:40:33.010622 32652 solver.cpp:244]     Train net output #0: loss = 0.00437273 (* 1 = 0.00437273 loss)
I0711 12:40:33.010632 32652 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0711 12:40:36.190212 32652 solver.cpp:228] Iteration 9400, loss = 0.00204997
I0711 12:40:36.190258 32652 solver.cpp:244]     Train net output #0: loss = 0.00204995 (* 1 = 0.00204995 loss)
I0711 12:40:36.190270 32652 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0711 12:40:39.410760 32652 solver.cpp:337] Iteration 9500, Testing net (#0)
I0711 12:40:41.531642 32652 solver.cpp:404]     Test net output #0: loss = 0.00986191 (* 1 = 0.00986191 loss)
I0711 12:40:41.554491 32652 solver.cpp:228] Iteration 9500, loss = 0.00216577
I0711 12:40:41.554512 32652 solver.cpp:244]     Train net output #0: loss = 0.00216575 (* 1 = 0.00216575 loss)
I0711 12:40:41.554524 32652 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0711 12:40:44.773510 32652 solver.cpp:228] Iteration 9600, loss = 0.00574554
I0711 12:40:44.773558 32652 solver.cpp:244]     Train net output #0: loss = 0.00574551 (* 1 = 0.00574551 loss)
I0711 12:40:44.773569 32652 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0711 12:40:47.980120 32652 solver.cpp:228] Iteration 9700, loss = 0.0046921
I0711 12:40:47.980311 32652 solver.cpp:244]     Train net output #0: loss = 0.00469207 (* 1 = 0.00469207 loss)
I0711 12:40:47.980322 32652 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0711 12:40:51.250696 32652 solver.cpp:228] Iteration 9800, loss = 0.00403281
I0711 12:40:51.250744 32652 solver.cpp:244]     Train net output #0: loss = 0.00403279 (* 1 = 0.00403279 loss)
I0711 12:40:51.250756 32652 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0711 12:40:54.488333 32652 solver.cpp:228] Iteration 9900, loss = 0.00624535
I0711 12:40:54.488379 32652 solver.cpp:244]     Train net output #0: loss = 0.00624533 (* 1 = 0.00624533 loss)
I0711 12:40:54.488390 32652 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0711 12:40:57.698930 32652 solver.cpp:337] Iteration 10000, Testing net (#0)
I0711 12:40:59.852882 32652 solver.cpp:404]     Test net output #0: loss = 0.00936903 (* 1 = 0.00936903 loss)
I0711 12:40:59.875520 32652 solver.cpp:228] Iteration 10000, loss = 0.00268007
I0711 12:40:59.875545 32652 solver.cpp:244]     Train net output #0: loss = 0.00268005 (* 1 = 0.00268005 loss)
I0711 12:40:59.875558 32652 sgd_solver.cpp:106] Iteration 10000, lr = 0.00594604
I0711 12:41:03.083251 32652 solver.cpp:228] Iteration 10100, loss = 0.0128842
I0711 12:41:03.083299 32652 solver.cpp:244]     Train net output #0: loss = 0.0128842 (* 1 = 0.0128842 loss)
I0711 12:41:03.083312 32652 sgd_solver.cpp:106] Iteration 10100, lr = 0.00592384
I0711 12:41:06.256425 32652 solver.cpp:228] Iteration 10200, loss = 0.00574406
I0711 12:41:06.256480 32652 solver.cpp:244]     Train net output #0: loss = 0.00574405 (* 1 = 0.00574405 loss)
I0711 12:41:06.256490 32652 sgd_solver.cpp:106] Iteration 10200, lr = 0.00590183
I0711 12:41:09.438990 32652 solver.cpp:228] Iteration 10300, loss = 0.00415092
I0711 12:41:09.439036 32652 solver.cpp:244]     Train net output #0: loss = 0.0041509 (* 1 = 0.0041509 loss)
I0711 12:41:09.439048 32652 sgd_solver.cpp:106] Iteration 10300, lr = 0.00588001
I0711 12:41:12.605901 32652 solver.cpp:228] Iteration 10400, loss = 0.00847537
I0711 12:41:12.605957 32652 solver.cpp:244]     Train net output #0: loss = 0.00847535 (* 1 = 0.00847535 loss)
I0711 12:41:12.605967 32652 sgd_solver.cpp:106] Iteration 10400, lr = 0.00585838
I0711 12:41:15.794651 32652 solver.cpp:337] Iteration 10500, Testing net (#0)
I0711 12:41:17.951036 32652 solver.cpp:404]     Test net output #0: loss = 0.00922702 (* 1 = 0.00922702 loss)
I0711 12:41:17.974093 32652 solver.cpp:228] Iteration 10500, loss = 0.00196812
I0711 12:41:17.974133 32652 solver.cpp:244]     Train net output #0: loss = 0.0019681 (* 1 = 0.0019681 loss)
I0711 12:41:17.974146 32652 sgd_solver.cpp:106] Iteration 10500, lr = 0.00583693
I0711 12:41:21.154052 32652 solver.cpp:228] Iteration 10600, loss = 0.00334924
I0711 12:41:21.154197 32652 solver.cpp:244]     Train net output #0: loss = 0.00334922 (* 1 = 0.00334922 loss)
I0711 12:41:21.154209 32652 sgd_solver.cpp:106] Iteration 10600, lr = 0.00581567
I0711 12:41:24.328347 32652 solver.cpp:228] Iteration 10700, loss = 0.00389423
I0711 12:41:24.328392 32652 solver.cpp:244]     Train net output #0: loss = 0.00389421 (* 1 = 0.00389421 loss)
I0711 12:41:24.328407 32652 sgd_solver.cpp:106] Iteration 10700, lr = 0.00579458
I0711 12:41:27.497043 32652 solver.cpp:228] Iteration 10800, loss = 0.00318568
I0711 12:41:27.497092 32652 solver.cpp:244]     Train net output #0: loss = 0.00318566 (* 1 = 0.00318566 loss)
I0711 12:41:27.497108 32652 sgd_solver.cpp:106] Iteration 10800, lr = 0.00577368
I0711 12:41:30.682507 32652 solver.cpp:228] Iteration 10900, loss = 0.00287388
I0711 12:41:30.682552 32652 solver.cpp:244]     Train net output #0: loss = 0.00287386 (* 1 = 0.00287386 loss)
I0711 12:41:30.682569 32652 sgd_solver.cpp:106] Iteration 10900, lr = 0.00575295
I0711 12:41:33.827596 32652 solver.cpp:337] Iteration 11000, Testing net (#0)
I0711 12:41:35.939860 32652 solver.cpp:404]     Test net output #0: loss = 0.00957444 (* 1 = 0.00957444 loss)
I0711 12:41:35.962591 32652 solver.cpp:228] Iteration 11000, loss = 0.00600041
I0711 12:41:35.962630 32652 solver.cpp:244]     Train net output #0: loss = 0.00600039 (* 1 = 0.00600039 loss)
I0711 12:41:35.962641 32652 sgd_solver.cpp:106] Iteration 11000, lr = 0.00573239
I0711 12:41:39.135320 32652 solver.cpp:228] Iteration 11100, loss = 0.00131326
I0711 12:41:39.135363 32652 solver.cpp:244]     Train net output #0: loss = 0.00131324 (* 1 = 0.00131324 loss)
I0711 12:41:39.135375 32652 sgd_solver.cpp:106] Iteration 11100, lr = 0.005712
I0711 12:41:42.374028 32652 solver.cpp:228] Iteration 11200, loss = 0.00157938
I0711 12:41:42.374083 32652 solver.cpp:244]     Train net output #0: loss = 0.00157935 (* 1 = 0.00157935 loss)
I0711 12:41:42.374092 32652 sgd_solver.cpp:106] Iteration 11200, lr = 0.00569178
I0711 12:41:45.677242 32652 solver.cpp:228] Iteration 11300, loss = 0.00269595
I0711 12:41:45.677294 32652 solver.cpp:244]     Train net output #0: loss = 0.00269593 (* 1 = 0.00269593 loss)
I0711 12:41:45.677304 32652 sgd_solver.cpp:106] Iteration 11300, lr = 0.00567173
I0711 12:41:48.931375 32652 solver.cpp:228] Iteration 11400, loss = 0.00365393
I0711 12:41:48.931422 32652 solver.cpp:244]     Train net output #0: loss = 0.0036539 (* 1 = 0.0036539 loss)
I0711 12:41:48.931432 32652 sgd_solver.cpp:106] Iteration 11400, lr = 0.00565184
I0711 12:41:52.311679 32652 solver.cpp:337] Iteration 11500, Testing net (#0)
I0711 12:41:54.458032 32652 solver.cpp:404]     Test net output #0: loss = 0.00911981 (* 1 = 0.00911981 loss)
I0711 12:41:54.481323 32652 solver.cpp:228] Iteration 11500, loss = 0.00109579
I0711 12:41:54.481355 32652 solver.cpp:244]     Train net output #0: loss = 0.00109577 (* 1 = 0.00109577 loss)
I0711 12:41:54.481375 32652 sgd_solver.cpp:106] Iteration 11500, lr = 0.00563211
I0711 12:41:57.808986 32652 solver.cpp:228] Iteration 11600, loss = 0.00357548
I0711 12:41:57.809034 32652 solver.cpp:244]     Train net output #0: loss = 0.00357546 (* 1 = 0.00357546 loss)
I0711 12:41:57.809046 32652 sgd_solver.cpp:106] Iteration 11600, lr = 0.00561254
I0711 12:42:00.993722 32652 solver.cpp:228] Iteration 11700, loss = 0.00139135
I0711 12:42:00.993768 32652 solver.cpp:244]     Train net output #0: loss = 0.00139133 (* 1 = 0.00139133 loss)
I0711 12:42:00.993785 32652 sgd_solver.cpp:106] Iteration 11700, lr = 0.00559313
I0711 12:42:04.186959 32652 solver.cpp:228] Iteration 11800, loss = 0.00430898
I0711 12:42:04.187005 32652 solver.cpp:244]     Train net output #0: loss = 0.00430896 (* 1 = 0.00430896 loss)
I0711 12:42:04.187017 32652 sgd_solver.cpp:106] Iteration 11800, lr = 0.00557388
I0711 12:42:07.477700 32652 solver.cpp:228] Iteration 11900, loss = 0.0031065
I0711 12:42:07.477754 32652 solver.cpp:244]     Train net output #0: loss = 0.00310648 (* 1 = 0.00310648 loss)
I0711 12:42:07.477764 32652 sgd_solver.cpp:106] Iteration 11900, lr = 0.00555478
I0711 12:42:10.672924 32652 solver.cpp:337] Iteration 12000, Testing net (#0)
I0711 12:42:12.822769 32652 solver.cpp:404]     Test net output #0: loss = 0.00916145 (* 1 = 0.00916145 loss)
I0711 12:42:12.846657 32652 solver.cpp:228] Iteration 12000, loss = 0.00210926
I0711 12:42:12.846704 32652 solver.cpp:244]     Train net output #0: loss = 0.00210924 (* 1 = 0.00210924 loss)
I0711 12:42:12.846720 32652 sgd_solver.cpp:106] Iteration 12000, lr = 0.00553583
I0711 12:42:16.034024 32652 solver.cpp:228] Iteration 12100, loss = 0.00501322
I0711 12:42:16.034070 32652 solver.cpp:244]     Train net output #0: loss = 0.0050132 (* 1 = 0.0050132 loss)
I0711 12:42:16.034085 32652 sgd_solver.cpp:106] Iteration 12100, lr = 0.00551704
I0711 12:42:19.195992 32652 solver.cpp:228] Iteration 12200, loss = 0.0028368
I0711 12:42:19.196038 32652 solver.cpp:244]     Train net output #0: loss = 0.00283677 (* 1 = 0.00283677 loss)
I0711 12:42:19.196053 32652 sgd_solver.cpp:106] Iteration 12200, lr = 0.00549839
I0711 12:42:22.369086 32652 solver.cpp:228] Iteration 12300, loss = 0.00211154
I0711 12:42:22.369272 32652 solver.cpp:244]     Train net output #0: loss = 0.00211151 (* 1 = 0.00211151 loss)
I0711 12:42:22.369283 32652 sgd_solver.cpp:106] Iteration 12300, lr = 0.00547988
I0711 12:42:25.529742 32652 solver.cpp:228] Iteration 12400, loss = 0.000601374
I0711 12:42:25.529788 32652 solver.cpp:244]     Train net output #0: loss = 0.00060135 (* 1 = 0.00060135 loss)
I0711 12:42:25.529799 32652 sgd_solver.cpp:106] Iteration 12400, lr = 0.00546153
I0711 12:42:28.662430 32652 solver.cpp:337] Iteration 12500, Testing net (#0)
I0711 12:42:30.778408 32652 solver.cpp:404]     Test net output #0: loss = 0.00938778 (* 1 = 0.00938778 loss)
I0711 12:42:30.801223 32652 solver.cpp:228] Iteration 12500, loss = 0.0046278
I0711 12:42:30.801267 32652 solver.cpp:244]     Train net output #0: loss = 0.00462777 (* 1 = 0.00462777 loss)
I0711 12:42:30.801280 32652 sgd_solver.cpp:106] Iteration 12500, lr = 0.00544331
I0711 12:42:33.959141 32652 solver.cpp:228] Iteration 12600, loss = 0.00178636
I0711 12:42:33.959183 32652 solver.cpp:244]     Train net output #0: loss = 0.00178633 (* 1 = 0.00178633 loss)
I0711 12:42:33.959193 32652 sgd_solver.cpp:106] Iteration 12600, lr = 0.00542524
I0711 12:42:37.137475 32652 solver.cpp:228] Iteration 12700, loss = 0.00388338
I0711 12:42:37.137522 32652 solver.cpp:244]     Train net output #0: loss = 0.00388335 (* 1 = 0.00388335 loss)
I0711 12:42:37.137533 32652 sgd_solver.cpp:106] Iteration 12700, lr = 0.0054073
I0711 12:42:40.316052 32652 solver.cpp:228] Iteration 12800, loss = 0.00243088
I0711 12:42:40.316107 32652 solver.cpp:244]     Train net output #0: loss = 0.00243086 (* 1 = 0.00243086 loss)
I0711 12:42:40.316117 32652 sgd_solver.cpp:106] Iteration 12800, lr = 0.0053895
I0711 12:42:43.495062 32652 solver.cpp:228] Iteration 12900, loss = 0.00115119
I0711 12:42:43.495115 32652 solver.cpp:244]     Train net output #0: loss = 0.00115116 (* 1 = 0.00115116 loss)
I0711 12:42:43.495124 32652 sgd_solver.cpp:106] Iteration 12900, lr = 0.00537184
I0711 12:42:46.642010 32652 solver.cpp:337] Iteration 13000, Testing net (#0)
I0711 12:42:48.779727 32652 solver.cpp:404]     Test net output #0: loss = 0.00921645 (* 1 = 0.00921645 loss)
I0711 12:42:48.803733 32652 solver.cpp:228] Iteration 13000, loss = 0.00135698
I0711 12:42:48.803771 32652 solver.cpp:244]     Train net output #0: loss = 0.00135696 (* 1 = 0.00135696 loss)
I0711 12:42:48.803784 32652 sgd_solver.cpp:106] Iteration 13000, lr = 0.00535432
I0711 12:42:51.980314 32652 solver.cpp:228] Iteration 13100, loss = 0.0063021
I0711 12:42:51.980360 32652 solver.cpp:244]     Train net output #0: loss = 0.00630207 (* 1 = 0.00630207 loss)
I0711 12:42:51.980372 32652 sgd_solver.cpp:106] Iteration 13100, lr = 0.00533692
I0711 12:42:55.149611 32652 solver.cpp:228] Iteration 13200, loss = 0.00131161
I0711 12:42:55.149823 32652 solver.cpp:244]     Train net output #0: loss = 0.00131159 (* 1 = 0.00131159 loss)
I0711 12:42:55.149834 32652 sgd_solver.cpp:106] Iteration 13200, lr = 0.00531966
I0711 12:42:58.355161 32652 solver.cpp:228] Iteration 13300, loss = 0.00240443
I0711 12:42:58.355216 32652 solver.cpp:244]     Train net output #0: loss = 0.0024044 (* 1 = 0.0024044 loss)
I0711 12:42:58.355227 32652 sgd_solver.cpp:106] Iteration 13300, lr = 0.00530253
I0711 12:43:01.546442 32652 solver.cpp:228] Iteration 13400, loss = 0.00301104
I0711 12:43:01.546494 32652 solver.cpp:244]     Train net output #0: loss = 0.00301101 (* 1 = 0.00301101 loss)
I0711 12:43:01.546504 32652 sgd_solver.cpp:106] Iteration 13400, lr = 0.00528552
I0711 12:43:04.676513 32652 solver.cpp:337] Iteration 13500, Testing net (#0)
I0711 12:43:06.800081 32652 solver.cpp:404]     Test net output #0: loss = 0.00922206 (* 1 = 0.00922206 loss)
I0711 12:43:06.823148 32652 solver.cpp:228] Iteration 13500, loss = 0.00210636
I0711 12:43:06.823187 32652 solver.cpp:244]     Train net output #0: loss = 0.00210633 (* 1 = 0.00210633 loss)
I0711 12:43:06.823202 32652 sgd_solver.cpp:106] Iteration 13500, lr = 0.00526865
I0711 12:43:09.984836 32652 solver.cpp:228] Iteration 13600, loss = 0.0145574
I0711 12:43:09.984889 32652 solver.cpp:244]     Train net output #0: loss = 0.0145573 (* 1 = 0.0145573 loss)
I0711 12:43:09.984899 32652 sgd_solver.cpp:106] Iteration 13600, lr = 0.00525189
I0711 12:43:13.146462 32652 solver.cpp:228] Iteration 13700, loss = 0.00234124
I0711 12:43:13.146513 32652 solver.cpp:244]     Train net output #0: loss = 0.00234121 (* 1 = 0.00234121 loss)
I0711 12:43:13.146523 32652 sgd_solver.cpp:106] Iteration 13700, lr = 0.00523527
I0711 12:43:16.307044 32652 solver.cpp:228] Iteration 13800, loss = 0.00633552
I0711 12:43:16.307088 32652 solver.cpp:244]     Train net output #0: loss = 0.00633549 (* 1 = 0.00633549 loss)
I0711 12:43:16.307098 32652 sgd_solver.cpp:106] Iteration 13800, lr = 0.00521876
I0711 12:43:19.468466 32652 solver.cpp:228] Iteration 13900, loss = 0.00393002
I0711 12:43:19.468513 32652 solver.cpp:244]     Train net output #0: loss = 0.00393 (* 1 = 0.00393 loss)
I0711 12:43:19.468523 32652 sgd_solver.cpp:106] Iteration 13900, lr = 0.00520237
I0711 12:43:22.606431 32652 solver.cpp:337] Iteration 14000, Testing net (#0)
I0711 12:43:24.737018 32652 solver.cpp:404]     Test net output #0: loss = 0.00904263 (* 1 = 0.00904263 loss)
I0711 12:43:24.760004 32652 solver.cpp:228] Iteration 14000, loss = 0.00210334
I0711 12:43:24.760032 32652 solver.cpp:244]     Train net output #0: loss = 0.00210332 (* 1 = 0.00210332 loss)
I0711 12:43:24.760048 32652 sgd_solver.cpp:106] Iteration 14000, lr = 0.00518611
I0711 12:43:27.927759 32652 solver.cpp:228] Iteration 14100, loss = 0.00289675
I0711 12:43:27.927940 32652 solver.cpp:244]     Train net output #0: loss = 0.00289673 (* 1 = 0.00289673 loss)
I0711 12:43:27.927954 32652 sgd_solver.cpp:106] Iteration 14100, lr = 0.00516996
I0711 12:43:31.092722 32652 solver.cpp:228] Iteration 14200, loss = 0.00276769
I0711 12:43:31.092770 32652 solver.cpp:244]     Train net output #0: loss = 0.00276766 (* 1 = 0.00276766 loss)
I0711 12:43:31.092782 32652 sgd_solver.cpp:106] Iteration 14200, lr = 0.00515393
I0711 12:43:34.252899 32652 solver.cpp:228] Iteration 14300, loss = 0.00393025
I0711 12:43:34.252951 32652 solver.cpp:244]     Train net output #0: loss = 0.00393023 (* 1 = 0.00393023 loss)
I0711 12:43:34.252962 32652 sgd_solver.cpp:106] Iteration 14300, lr = 0.00513801
I0711 12:43:37.424500 32652 solver.cpp:228] Iteration 14400, loss = 0.0035093
I0711 12:43:37.424546 32652 solver.cpp:244]     Train net output #0: loss = 0.00350927 (* 1 = 0.00350927 loss)
I0711 12:43:37.424557 32652 sgd_solver.cpp:106] Iteration 14400, lr = 0.00512221
I0711 12:43:40.550468 32652 solver.cpp:337] Iteration 14500, Testing net (#0)
I0711 12:43:42.666996 32652 solver.cpp:404]     Test net output #0: loss = 0.00923585 (* 1 = 0.00923585 loss)
I0711 12:43:42.690062 32652 solver.cpp:228] Iteration 14500, loss = 0.00268216
I0711 12:43:42.690100 32652 solver.cpp:244]     Train net output #0: loss = 0.00268214 (* 1 = 0.00268214 loss)
I0711 12:43:42.690114 32652 sgd_solver.cpp:106] Iteration 14500, lr = 0.00510653
I0711 12:43:45.848271 32652 solver.cpp:228] Iteration 14600, loss = 0.00241054
I0711 12:43:45.848317 32652 solver.cpp:244]     Train net output #0: loss = 0.00241052 (* 1 = 0.00241052 loss)
I0711 12:43:45.848328 32652 sgd_solver.cpp:106] Iteration 14600, lr = 0.00509095
I0711 12:43:49.005743 32652 solver.cpp:228] Iteration 14700, loss = 0.00300044
I0711 12:43:49.005789 32652 solver.cpp:244]     Train net output #0: loss = 0.00300042 (* 1 = 0.00300042 loss)
I0711 12:43:49.005800 32652 sgd_solver.cpp:106] Iteration 14700, lr = 0.00507548
I0711 12:43:52.171772 32652 solver.cpp:228] Iteration 14800, loss = 0.00295739
I0711 12:43:52.171818 32652 solver.cpp:244]     Train net output #0: loss = 0.00295737 (* 1 = 0.00295737 loss)
I0711 12:43:52.171835 32652 sgd_solver.cpp:106] Iteration 14800, lr = 0.00506012
I0711 12:43:55.349727 32652 solver.cpp:228] Iteration 14900, loss = 0.00316693
I0711 12:43:55.349779 32652 solver.cpp:244]     Train net output #0: loss = 0.00316691 (* 1 = 0.00316691 loss)
I0711 12:43:55.349789 32652 sgd_solver.cpp:106] Iteration 14900, lr = 0.00504488
I0711 12:43:58.480823 32652 solver.cpp:337] Iteration 15000, Testing net (#0)
I0711 12:44:00.600172 32652 solver.cpp:404]     Test net output #0: loss = 0.00888264 (* 1 = 0.00888264 loss)
I0711 12:44:00.623095 32652 solver.cpp:228] Iteration 15000, loss = 0.00252518
I0711 12:44:00.623134 32652 solver.cpp:244]     Train net output #0: loss = 0.00252516 (* 1 = 0.00252516 loss)
I0711 12:44:00.623147 32652 sgd_solver.cpp:106] Iteration 15000, lr = 0.00502973
I0711 12:44:03.788172 32652 solver.cpp:228] Iteration 15100, loss = 0.0017083
I0711 12:44:03.788216 32652 solver.cpp:244]     Train net output #0: loss = 0.00170827 (* 1 = 0.00170827 loss)
I0711 12:44:03.788240 32652 sgd_solver.cpp:106] Iteration 15100, lr = 0.0050147
I0711 12:44:06.944887 32652 solver.cpp:228] Iteration 15200, loss = 0.00316219
I0711 12:44:06.944931 32652 solver.cpp:244]     Train net output #0: loss = 0.00316217 (* 1 = 0.00316217 loss)
I0711 12:44:06.944944 32652 sgd_solver.cpp:106] Iteration 15200, lr = 0.00499976
I0711 12:44:10.102157 32652 solver.cpp:228] Iteration 15300, loss = 0.00264494
I0711 12:44:10.102205 32652 solver.cpp:244]     Train net output #0: loss = 0.00264492 (* 1 = 0.00264492 loss)
I0711 12:44:10.102218 32652 sgd_solver.cpp:106] Iteration 15300, lr = 0.00498494
I0711 12:44:13.260762 32652 solver.cpp:228] Iteration 15400, loss = 0.00696927
I0711 12:44:13.260815 32652 solver.cpp:244]     Train net output #0: loss = 0.00696925 (* 1 = 0.00696925 loss)
I0711 12:44:13.260825 32652 sgd_solver.cpp:106] Iteration 15400, lr = 0.00497021
I0711 12:44:16.387115 32652 solver.cpp:337] Iteration 15500, Testing net (#0)
I0711 12:44:18.503232 32652 solver.cpp:404]     Test net output #0: loss = 0.00903504 (* 1 = 0.00903504 loss)
I0711 12:44:18.526123 32652 solver.cpp:228] Iteration 15500, loss = 0.00227294
I0711 12:44:18.526165 32652 solver.cpp:244]     Train net output #0: loss = 0.00227292 (* 1 = 0.00227292 loss)
I0711 12:44:18.526177 32652 sgd_solver.cpp:106] Iteration 15500, lr = 0.00495558
I0711 12:44:21.684108 32652 solver.cpp:228] Iteration 15600, loss = 0.000144802
I0711 12:44:21.684155 32652 solver.cpp:244]     Train net output #0: loss = 0.00014478 (* 1 = 0.00014478 loss)
I0711 12:44:21.684165 32652 sgd_solver.cpp:106] Iteration 15600, lr = 0.00494106
I0711 12:44:24.850255 32652 solver.cpp:228] Iteration 15700, loss = 0.00392789
I0711 12:44:24.850302 32652 solver.cpp:244]     Train net output #0: loss = 0.00392786 (* 1 = 0.00392786 loss)
I0711 12:44:24.850316 32652 sgd_solver.cpp:106] Iteration 15700, lr = 0.00492663
I0711 12:44:28.019994 32652 solver.cpp:228] Iteration 15800, loss = 0.00185384
I0711 12:44:28.020043 32652 solver.cpp:244]     Train net output #0: loss = 0.00185382 (* 1 = 0.00185382 loss)
I0711 12:44:28.020054 32652 sgd_solver.cpp:106] Iteration 15800, lr = 0.0049123
I0711 12:44:31.186983 32652 solver.cpp:228] Iteration 15900, loss = 0.0017374
I0711 12:44:31.187129 32652 solver.cpp:244]     Train net output #0: loss = 0.00173737 (* 1 = 0.00173737 loss)
I0711 12:44:31.187139 32652 sgd_solver.cpp:106] Iteration 15900, lr = 0.00489807
I0711 12:44:34.314587 32652 solver.cpp:337] Iteration 16000, Testing net (#0)
I0711 12:44:36.431164 32652 solver.cpp:404]     Test net output #0: loss = 0.00895399 (* 1 = 0.00895399 loss)
I0711 12:44:36.453878 32652 solver.cpp:228] Iteration 16000, loss = 0.00442856
I0711 12:44:36.453912 32652 solver.cpp:244]     Train net output #0: loss = 0.00442853 (* 1 = 0.00442853 loss)
I0711 12:44:36.453938 32652 sgd_solver.cpp:106] Iteration 16000, lr = 0.00488394
I0711 12:44:39.613734 32652 solver.cpp:228] Iteration 16100, loss = 0.00498216
I0711 12:44:39.613780 32652 solver.cpp:244]     Train net output #0: loss = 0.00498214 (* 1 = 0.00498214 loss)
I0711 12:44:39.613790 32652 sgd_solver.cpp:106] Iteration 16100, lr = 0.0048699
I0711 12:44:42.785521 32652 solver.cpp:228] Iteration 16200, loss = 0.0117536
I0711 12:44:42.785574 32652 solver.cpp:244]     Train net output #0: loss = 0.0117536 (* 1 = 0.0117536 loss)
I0711 12:44:42.785584 32652 sgd_solver.cpp:106] Iteration 16200, lr = 0.00485595
I0711 12:44:45.964071 32652 solver.cpp:228] Iteration 16300, loss = 0.00371744
I0711 12:44:45.964126 32652 solver.cpp:244]     Train net output #0: loss = 0.00371742 (* 1 = 0.00371742 loss)
I0711 12:44:45.964135 32652 sgd_solver.cpp:106] Iteration 16300, lr = 0.00484209
I0711 12:44:49.139849 32652 solver.cpp:228] Iteration 16400, loss = 0.000967329
I0711 12:44:49.139897 32652 solver.cpp:244]     Train net output #0: loss = 0.000967304 (* 1 = 0.000967304 loss)
I0711 12:44:49.139907 32652 sgd_solver.cpp:106] Iteration 16400, lr = 0.00482833
I0711 12:44:52.284291 32652 solver.cpp:337] Iteration 16500, Testing net (#0)
I0711 12:44:54.397976 32652 solver.cpp:404]     Test net output #0: loss = 0.00919259 (* 1 = 0.00919259 loss)
I0711 12:44:54.421139 32652 solver.cpp:228] Iteration 16500, loss = 0.00515094
I0711 12:44:54.421181 32652 solver.cpp:244]     Train net output #0: loss = 0.00515092 (* 1 = 0.00515092 loss)
I0711 12:44:54.421193 32652 sgd_solver.cpp:106] Iteration 16500, lr = 0.00481466
I0711 12:44:57.579051 32652 solver.cpp:228] Iteration 16600, loss = 0.00231959
I0711 12:44:57.579097 32652 solver.cpp:244]     Train net output #0: loss = 0.00231957 (* 1 = 0.00231957 loss)
I0711 12:44:57.579107 32652 sgd_solver.cpp:106] Iteration 16600, lr = 0.00480108
I0711 12:45:00.737447 32652 solver.cpp:228] Iteration 16700, loss = 0.000955315
I0711 12:45:00.737498 32652 solver.cpp:244]     Train net output #0: loss = 0.00095529 (* 1 = 0.00095529 loss)
I0711 12:45:00.737507 32652 sgd_solver.cpp:106] Iteration 16700, lr = 0.00478759
I0711 12:45:03.896528 32652 solver.cpp:228] Iteration 16800, loss = 0.002574
I0711 12:45:03.896687 32652 solver.cpp:244]     Train net output #0: loss = 0.00257397 (* 1 = 0.00257397 loss)
I0711 12:45:03.896698 32652 sgd_solver.cpp:106] Iteration 16800, lr = 0.00477418
I0711 12:45:07.059905 32652 solver.cpp:228] Iteration 16900, loss = 0.00143879
I0711 12:45:07.059952 32652 solver.cpp:244]     Train net output #0: loss = 0.00143876 (* 1 = 0.00143876 loss)
I0711 12:45:07.059965 32652 sgd_solver.cpp:106] Iteration 16900, lr = 0.00476086
I0711 12:45:10.197556 32652 solver.cpp:337] Iteration 17000, Testing net (#0)
I0711 12:45:12.324501 32652 solver.cpp:404]     Test net output #0: loss = 0.00928425 (* 1 = 0.00928425 loss)
I0711 12:45:12.347162 32652 solver.cpp:228] Iteration 17000, loss = 0.00120653
I0711 12:45:12.347189 32652 solver.cpp:244]     Train net output #0: loss = 0.00120651 (* 1 = 0.00120651 loss)
I0711 12:45:12.347205 32652 sgd_solver.cpp:106] Iteration 17000, lr = 0.00474763
I0711 12:45:15.512140 32652 solver.cpp:228] Iteration 17100, loss = 0.00355668
I0711 12:45:15.512192 32652 solver.cpp:244]     Train net output #0: loss = 0.00355666 (* 1 = 0.00355666 loss)
I0711 12:45:15.512202 32652 sgd_solver.cpp:106] Iteration 17100, lr = 0.00473449
I0711 12:45:18.675142 32652 solver.cpp:228] Iteration 17200, loss = 0.00347296
I0711 12:45:18.675184 32652 solver.cpp:244]     Train net output #0: loss = 0.00347293 (* 1 = 0.00347293 loss)
I0711 12:45:18.675194 32652 sgd_solver.cpp:106] Iteration 17200, lr = 0.00472143
I0711 12:45:21.837067 32652 solver.cpp:228] Iteration 17300, loss = 0.00234458
I0711 12:45:21.837112 32652 solver.cpp:244]     Train net output #0: loss = 0.00234455 (* 1 = 0.00234455 loss)
I0711 12:45:21.837122 32652 sgd_solver.cpp:106] Iteration 17300, lr = 0.00470845
I0711 12:45:24.999083 32652 solver.cpp:228] Iteration 17400, loss = 0.0046821
I0711 12:45:24.999135 32652 solver.cpp:244]     Train net output #0: loss = 0.00468208 (* 1 = 0.00468208 loss)
I0711 12:45:24.999145 32652 sgd_solver.cpp:106] Iteration 17400, lr = 0.00469556
I0711 12:45:28.132601 32652 solver.cpp:337] Iteration 17500, Testing net (#0)
I0711 12:45:30.266192 32652 solver.cpp:404]     Test net output #0: loss = 0.0090002 (* 1 = 0.0090002 loss)
I0711 12:45:30.288930 32652 solver.cpp:228] Iteration 17500, loss = 0.00152816
I0711 12:45:30.288971 32652 solver.cpp:244]     Train net output #0: loss = 0.00152813 (* 1 = 0.00152813 loss)
I0711 12:45:30.288983 32652 sgd_solver.cpp:106] Iteration 17500, lr = 0.00468274
I0711 12:45:33.463331 32652 solver.cpp:228] Iteration 17600, loss = 0.00622036
I0711 12:45:33.463383 32652 solver.cpp:244]     Train net output #0: loss = 0.00622033 (* 1 = 0.00622033 loss)
I0711 12:45:33.463393 32652 sgd_solver.cpp:106] Iteration 17600, lr = 0.00467001
I0711 12:45:36.641746 32652 solver.cpp:228] Iteration 17700, loss = 0.00444319
I0711 12:45:36.641855 32652 solver.cpp:244]     Train net output #0: loss = 0.00444316 (* 1 = 0.00444316 loss)
I0711 12:45:36.641865 32652 sgd_solver.cpp:106] Iteration 17700, lr = 0.00465736
I0711 12:45:39.814564 32652 solver.cpp:228] Iteration 17800, loss = 0.00258838
I0711 12:45:39.814611 32652 solver.cpp:244]     Train net output #0: loss = 0.00258835 (* 1 = 0.00258835 loss)
I0711 12:45:39.814621 32652 sgd_solver.cpp:106] Iteration 17800, lr = 0.00464479
I0711 12:45:42.972313 32652 solver.cpp:228] Iteration 17900, loss = 0.00613513
I0711 12:45:42.972359 32652 solver.cpp:244]     Train net output #0: loss = 0.0061351 (* 1 = 0.0061351 loss)
I0711 12:45:42.972370 32652 sgd_solver.cpp:106] Iteration 17900, lr = 0.0046323
I0711 12:45:46.100522 32652 solver.cpp:337] Iteration 18000, Testing net (#0)
I0711 12:45:48.228487 32652 solver.cpp:404]     Test net output #0: loss = 0.00898943 (* 1 = 0.00898943 loss)
I0711 12:45:48.251370 32652 solver.cpp:228] Iteration 18000, loss = 0.00133114
I0711 12:45:48.251405 32652 solver.cpp:244]     Train net output #0: loss = 0.00133111 (* 1 = 0.00133111 loss)
I0711 12:45:48.251420 32652 sgd_solver.cpp:106] Iteration 18000, lr = 0.00461989
I0711 12:45:51.424432 32652 solver.cpp:228] Iteration 18100, loss = 0.00218707
I0711 12:45:51.424485 32652 solver.cpp:244]     Train net output #0: loss = 0.00218704 (* 1 = 0.00218704 loss)
I0711 12:45:51.424495 32652 sgd_solver.cpp:106] Iteration 18100, lr = 0.00460755
I0711 12:45:54.606765 32652 solver.cpp:228] Iteration 18200, loss = 0.002996
I0711 12:45:54.606811 32652 solver.cpp:244]     Train net output #0: loss = 0.00299598 (* 1 = 0.00299598 loss)
I0711 12:45:54.606833 32652 sgd_solver.cpp:106] Iteration 18200, lr = 0.00459529
I0711 12:45:57.813226 32652 solver.cpp:228] Iteration 18300, loss = 0.00237306
I0711 12:45:57.813280 32652 solver.cpp:244]     Train net output #0: loss = 0.00237303 (* 1 = 0.00237303 loss)
I0711 12:45:57.813290 32652 sgd_solver.cpp:106] Iteration 18300, lr = 0.00458311
I0711 12:46:00.992916 32652 solver.cpp:228] Iteration 18400, loss = 0.00171461
I0711 12:46:00.992961 32652 solver.cpp:244]     Train net output #0: loss = 0.00171458 (* 1 = 0.00171458 loss)
I0711 12:46:00.992972 32652 sgd_solver.cpp:106] Iteration 18400, lr = 0.004571
I0711 12:46:04.142470 32652 solver.cpp:337] Iteration 18500, Testing net (#0)
I0711 12:46:06.393576 32652 solver.cpp:404]     Test net output #0: loss = 0.00906473 (* 1 = 0.00906473 loss)
I0711 12:46:06.416306 32652 solver.cpp:228] Iteration 18500, loss = 0.00350741
I0711 12:46:06.416342 32652 solver.cpp:244]     Train net output #0: loss = 0.00350738 (* 1 = 0.00350738 loss)
I0711 12:46:06.416357 32652 sgd_solver.cpp:106] Iteration 18500, lr = 0.00455897
I0711 12:46:09.586308 32652 solver.cpp:228] Iteration 18600, loss = 0.00124537
I0711 12:46:09.586484 32652 solver.cpp:244]     Train net output #0: loss = 0.00124534 (* 1 = 0.00124534 loss)
I0711 12:46:09.586498 32652 sgd_solver.cpp:106] Iteration 18600, lr = 0.00454701
I0711 12:46:12.850213 32652 solver.cpp:228] Iteration 18700, loss = 0.00108309
I0711 12:46:12.850255 32652 solver.cpp:244]     Train net output #0: loss = 0.00108306 (* 1 = 0.00108306 loss)
I0711 12:46:12.850265 32652 sgd_solver.cpp:106] Iteration 18700, lr = 0.00453512
I0711 12:46:16.038835 32652 solver.cpp:228] Iteration 18800, loss = 0.00175901
I0711 12:46:16.038880 32652 solver.cpp:244]     Train net output #0: loss = 0.00175898 (* 1 = 0.00175898 loss)
I0711 12:46:16.038897 32652 sgd_solver.cpp:106] Iteration 18800, lr = 0.0045233
I0711 12:46:19.214687 32652 solver.cpp:228] Iteration 18900, loss = 0.00247544
I0711 12:46:19.214740 32652 solver.cpp:244]     Train net output #0: loss = 0.00247541 (* 1 = 0.00247541 loss)
I0711 12:46:19.214750 32652 sgd_solver.cpp:106] Iteration 18900, lr = 0.00451156
I0711 12:46:22.357102 32652 solver.cpp:337] Iteration 19000, Testing net (#0)
I0711 12:46:24.508767 32652 solver.cpp:404]     Test net output #0: loss = 0.00876176 (* 1 = 0.00876176 loss)
I0711 12:46:24.531688 32652 solver.cpp:228] Iteration 19000, loss = 0.00056551
I0711 12:46:24.531718 32652 solver.cpp:244]     Train net output #0: loss = 0.000565486 (* 1 = 0.000565486 loss)
I0711 12:46:24.531733 32652 sgd_solver.cpp:106] Iteration 19000, lr = 0.00449989
I0711 12:46:27.759037 32652 solver.cpp:228] Iteration 19100, loss = 0.0023378
I0711 12:46:27.759083 32652 solver.cpp:244]     Train net output #0: loss = 0.00233778 (* 1 = 0.00233778 loss)
I0711 12:46:27.759095 32652 sgd_solver.cpp:106] Iteration 19100, lr = 0.00448828
I0711 12:46:30.943588 32652 solver.cpp:228] Iteration 19200, loss = 0.00123421
I0711 12:46:30.943642 32652 solver.cpp:244]     Train net output #0: loss = 0.00123419 (* 1 = 0.00123419 loss)
I0711 12:46:30.943652 32652 sgd_solver.cpp:106] Iteration 19200, lr = 0.00447675
I0711 12:46:34.158443 32652 solver.cpp:228] Iteration 19300, loss = 0.00301856
I0711 12:46:34.158488 32652 solver.cpp:244]     Train net output #0: loss = 0.00301853 (* 1 = 0.00301853 loss)
I0711 12:46:34.158499 32652 sgd_solver.cpp:106] Iteration 19300, lr = 0.00446529
I0711 12:46:37.360115 32652 solver.cpp:228] Iteration 19400, loss = 0.00192669
I0711 12:46:37.360159 32652 solver.cpp:244]     Train net output #0: loss = 0.00192667 (* 1 = 0.00192667 loss)
I0711 12:46:37.360182 32652 sgd_solver.cpp:106] Iteration 19400, lr = 0.00445389
I0711 12:46:40.554474 32652 solver.cpp:337] Iteration 19500, Testing net (#0)
I0711 12:46:42.695374 32652 solver.cpp:404]     Test net output #0: loss = 0.00879236 (* 1 = 0.00879236 loss)
I0711 12:46:42.718122 32652 solver.cpp:228] Iteration 19500, loss = 0.00190742
I0711 12:46:42.718173 32652 solver.cpp:244]     Train net output #0: loss = 0.0019074 (* 1 = 0.0019074 loss)
I0711 12:46:42.718185 32652 sgd_solver.cpp:106] Iteration 19500, lr = 0.00444256
I0711 12:46:45.957989 32652 solver.cpp:228] Iteration 19600, loss = 0.00359063
I0711 12:46:45.958088 32652 solver.cpp:244]     Train net output #0: loss = 0.00359061 (* 1 = 0.00359061 loss)
I0711 12:46:45.958127 32652 sgd_solver.cpp:106] Iteration 19600, lr = 0.0044313
I0711 12:46:49.177656 32652 solver.cpp:228] Iteration 19700, loss = 0.00156315
I0711 12:46:49.177708 32652 solver.cpp:244]     Train net output #0: loss = 0.00156313 (* 1 = 0.00156313 loss)
I0711 12:46:49.177718 32652 sgd_solver.cpp:106] Iteration 19700, lr = 0.00442011
I0711 12:46:52.552665 32652 solver.cpp:228] Iteration 19800, loss = 0.00137639
I0711 12:46:52.552711 32652 solver.cpp:244]     Train net output #0: loss = 0.00137636 (* 1 = 0.00137636 loss)
I0711 12:46:52.552721 32652 sgd_solver.cpp:106] Iteration 19800, lr = 0.00440898
I0711 12:46:55.738687 32652 solver.cpp:228] Iteration 19900, loss = 0.000443974
I0711 12:46:55.738739 32652 solver.cpp:244]     Train net output #0: loss = 0.000443953 (* 1 = 0.000443953 loss)
I0711 12:46:55.738749 32652 sgd_solver.cpp:106] Iteration 19900, lr = 0.00439791
I0711 12:46:58.967926 32652 solver.cpp:337] Iteration 20000, Testing net (#0)
I0711 12:47:01.090682 32652 solver.cpp:404]     Test net output #0: loss = 0.00910716 (* 1 = 0.00910716 loss)
I0711 12:47:01.113142 32652 solver.cpp:228] Iteration 20000, loss = 0.0032187
I0711 12:47:01.113176 32652 solver.cpp:244]     Train net output #0: loss = 0.00321868 (* 1 = 0.00321868 loss)
I0711 12:47:01.113188 32652 sgd_solver.cpp:106] Iteration 20000, lr = 0.00438691
I0711 12:47:04.343750 32652 solver.cpp:228] Iteration 20100, loss = 0.00136695
I0711 12:47:04.343792 32652 solver.cpp:244]     Train net output #0: loss = 0.00136693 (* 1 = 0.00136693 loss)
I0711 12:47:04.343804 32652 sgd_solver.cpp:106] Iteration 20100, lr = 0.00437598
I0711 12:47:07.517843 32652 solver.cpp:228] Iteration 20200, loss = 0.00242727
I0711 12:47:07.517894 32652 solver.cpp:244]     Train net output #0: loss = 0.00242725 (* 1 = 0.00242725 loss)
I0711 12:47:07.517904 32652 sgd_solver.cpp:106] Iteration 20200, lr = 0.00436511
I0711 12:47:10.680033 32652 solver.cpp:228] Iteration 20300, loss = 0.00170236
I0711 12:47:10.680151 32652 solver.cpp:244]     Train net output #0: loss = 0.00170234 (* 1 = 0.00170234 loss)
I0711 12:47:10.680166 32652 sgd_solver.cpp:106] Iteration 20300, lr = 0.0043543
I0711 12:47:13.900789 32652 solver.cpp:228] Iteration 20400, loss = 0.000862946
I0711 12:47:13.900841 32652 solver.cpp:244]     Train net output #0: loss = 0.000862924 (* 1 = 0.000862924 loss)
I0711 12:47:13.900851 32652 sgd_solver.cpp:106] Iteration 20400, lr = 0.00434355
I0711 12:47:17.083151 32652 solver.cpp:337] Iteration 20500, Testing net (#0)
I0711 12:47:19.207187 32652 solver.cpp:404]     Test net output #0: loss = 0.00894254 (* 1 = 0.00894254 loss)
I0711 12:47:19.229995 32652 solver.cpp:228] Iteration 20500, loss = 0.000788955
I0711 12:47:19.230032 32652 solver.cpp:244]     Train net output #0: loss = 0.000788933 (* 1 = 0.000788933 loss)
I0711 12:47:19.230046 32652 sgd_solver.cpp:106] Iteration 20500, lr = 0.00433286
I0711 12:47:22.410138 32652 solver.cpp:228] Iteration 20600, loss = 0.00439402
I0711 12:47:22.410192 32652 solver.cpp:244]     Train net output #0: loss = 0.004394 (* 1 = 0.004394 loss)
I0711 12:47:22.410202 32652 sgd_solver.cpp:106] Iteration 20600, lr = 0.00432224
I0711 12:47:25.652875 32652 solver.cpp:228] Iteration 20700, loss = 0.000711093
I0711 12:47:25.652922 32652 solver.cpp:244]     Train net output #0: loss = 0.000711072 (* 1 = 0.000711072 loss)
I0711 12:47:25.652935 32652 sgd_solver.cpp:106] Iteration 20700, lr = 0.00431168
I0711 12:47:28.937417 32652 solver.cpp:228] Iteration 20800, loss = 0.00181051
I0711 12:47:28.937469 32652 solver.cpp:244]     Train net output #0: loss = 0.00181049 (* 1 = 0.00181049 loss)
I0711 12:47:28.937479 32652 sgd_solver.cpp:106] Iteration 20800, lr = 0.00430117
I0711 12:47:32.127425 32652 solver.cpp:228] Iteration 20900, loss = 0.00266541
I0711 12:47:32.127477 32652 solver.cpp:244]     Train net output #0: loss = 0.00266539 (* 1 = 0.00266539 loss)
I0711 12:47:32.127487 32652 sgd_solver.cpp:106] Iteration 20900, lr = 0.00429073
I0711 12:47:35.301594 32652 solver.cpp:337] Iteration 21000, Testing net (#0)
I0711 12:47:37.479840 32652 solver.cpp:404]     Test net output #0: loss = 0.00904523 (* 1 = 0.00904523 loss)
I0711 12:47:37.502722 32652 solver.cpp:228] Iteration 21000, loss = 0.00125593
I0711 12:47:37.502755 32652 solver.cpp:244]     Train net output #0: loss = 0.00125591 (* 1 = 0.00125591 loss)
I0711 12:47:37.502768 32652 sgd_solver.cpp:106] Iteration 21000, lr = 0.00428034
I0711 12:47:40.738112 32652 solver.cpp:228] Iteration 21100, loss = 0.0076635
I0711 12:47:40.738353 32652 solver.cpp:244]     Train net output #0: loss = 0.00766348 (* 1 = 0.00766348 loss)
I0711 12:47:40.738364 32652 sgd_solver.cpp:106] Iteration 21100, lr = 0.00427002
I0711 12:47:43.921283 32652 solver.cpp:228] Iteration 21200, loss = 0.00187692
I0711 12:47:43.921337 32652 solver.cpp:244]     Train net output #0: loss = 0.0018769 (* 1 = 0.0018769 loss)
I0711 12:47:43.921347 32652 sgd_solver.cpp:106] Iteration 21200, lr = 0.00425975
I0711 12:47:47.094074 32652 solver.cpp:228] Iteration 21300, loss = 0.00412252
I0711 12:47:47.094126 32652 solver.cpp:244]     Train net output #0: loss = 0.0041225 (* 1 = 0.0041225 loss)
I0711 12:47:47.094136 32652 sgd_solver.cpp:106] Iteration 21300, lr = 0.00424954
I0711 12:47:50.255071 32652 solver.cpp:228] Iteration 21400, loss = 0.0026026
I0711 12:47:50.255117 32652 solver.cpp:244]     Train net output #0: loss = 0.00260259 (* 1 = 0.00260259 loss)
I0711 12:47:50.255127 32652 sgd_solver.cpp:106] Iteration 21400, lr = 0.00423938
I0711 12:47:53.395491 32652 solver.cpp:337] Iteration 21500, Testing net (#0)
I0711 12:47:55.509215 32652 solver.cpp:404]     Test net output #0: loss = 0.00882344 (* 1 = 0.00882344 loss)
I0711 12:47:55.532795 32652 solver.cpp:228] Iteration 21500, loss = 0.000893163
I0711 12:47:55.532835 32652 solver.cpp:244]     Train net output #0: loss = 0.000893145 (* 1 = 0.000893145 loss)
I0711 12:47:55.532847 32652 sgd_solver.cpp:106] Iteration 21500, lr = 0.00422929
I0711 12:47:58.689532 32652 solver.cpp:228] Iteration 21600, loss = 0.00178537
I0711 12:47:58.689579 32652 solver.cpp:244]     Train net output #0: loss = 0.00178535 (* 1 = 0.00178535 loss)
I0711 12:47:58.689589 32652 sgd_solver.cpp:106] Iteration 21600, lr = 0.00421924
I0711 12:48:01.849347 32652 solver.cpp:228] Iteration 21700, loss = 0.0025543
I0711 12:48:01.849388 32652 solver.cpp:244]     Train net output #0: loss = 0.00255428 (* 1 = 0.00255428 loss)
I0711 12:48:01.849400 32652 sgd_solver.cpp:106] Iteration 21700, lr = 0.00420926
I0711 12:48:05.007575 32652 solver.cpp:228] Iteration 21800, loss = 0.00279733
I0711 12:48:05.007616 32652 solver.cpp:244]     Train net output #0: loss = 0.00279731 (* 1 = 0.00279731 loss)
I0711 12:48:05.007627 32652 sgd_solver.cpp:106] Iteration 21800, lr = 0.00419933
I0711 12:48:08.177038 32652 solver.cpp:228] Iteration 21900, loss = 0.00226055
I0711 12:48:08.177093 32652 solver.cpp:244]     Train net output #0: loss = 0.00226053 (* 1 = 0.00226053 loss)
I0711 12:48:08.177103 32652 sgd_solver.cpp:106] Iteration 21900, lr = 0.00418945
I0711 12:48:11.322742 32652 solver.cpp:337] Iteration 22000, Testing net (#0)
I0711 12:48:13.455366 32652 solver.cpp:404]     Test net output #0: loss = 0.008967 (* 1 = 0.008967 loss)
I0711 12:48:13.478282 32652 solver.cpp:228] Iteration 22000, loss = 0.00142345
I0711 12:48:13.478313 32652 solver.cpp:244]     Train net output #0: loss = 0.00142343 (* 1 = 0.00142343 loss)
I0711 12:48:13.478325 32652 sgd_solver.cpp:106] Iteration 22000, lr = 0.00417963
I0711 12:48:16.655211 32652 solver.cpp:228] Iteration 22100, loss = 0.00186294
I0711 12:48:16.655257 32652 solver.cpp:244]     Train net output #0: loss = 0.00186293 (* 1 = 0.00186293 loss)
I0711 12:48:16.655268 32652 sgd_solver.cpp:106] Iteration 22100, lr = 0.00416986
I0711 12:48:19.833046 32652 solver.cpp:228] Iteration 22200, loss = 0.00242094
I0711 12:48:19.833099 32652 solver.cpp:244]     Train net output #0: loss = 0.00242093 (* 1 = 0.00242093 loss)
I0711 12:48:19.833109 32652 sgd_solver.cpp:106] Iteration 22200, lr = 0.00416014
I0711 12:48:23.011138 32652 solver.cpp:228] Iteration 22300, loss = 0.00275985
I0711 12:48:23.011186 32652 solver.cpp:244]     Train net output #0: loss = 0.00275983 (* 1 = 0.00275983 loss)
I0711 12:48:23.011200 32652 sgd_solver.cpp:106] Iteration 22300, lr = 0.00415048
I0711 12:48:26.198716 32652 solver.cpp:228] Iteration 22400, loss = 0.00225987
I0711 12:48:26.198770 32652 solver.cpp:244]     Train net output #0: loss = 0.00225985 (* 1 = 0.00225985 loss)
I0711 12:48:26.198779 32652 sgd_solver.cpp:106] Iteration 22400, lr = 0.00414087
I0711 12:48:29.325498 32652 solver.cpp:337] Iteration 22500, Testing net (#0)
I0711 12:48:31.439127 32652 solver.cpp:404]     Test net output #0: loss = 0.00868785 (* 1 = 0.00868785 loss)
I0711 12:48:31.461987 32652 solver.cpp:228] Iteration 22500, loss = 0.00199592
I0711 12:48:31.462028 32652 solver.cpp:244]     Train net output #0: loss = 0.0019959 (* 1 = 0.0019959 loss)
I0711 12:48:31.462040 32652 sgd_solver.cpp:106] Iteration 22500, lr = 0.00413131
I0711 12:48:34.629603 32652 solver.cpp:228] Iteration 22600, loss = 0.00136693
I0711 12:48:34.629668 32652 solver.cpp:244]     Train net output #0: loss = 0.00136691 (* 1 = 0.00136691 loss)
I0711 12:48:34.629685 32652 sgd_solver.cpp:106] Iteration 22600, lr = 0.0041218
I0711 12:48:37.786721 32652 solver.cpp:228] Iteration 22700, loss = 0.001819
I0711 12:48:37.786767 32652 solver.cpp:244]     Train net output #0: loss = 0.00181898 (* 1 = 0.00181898 loss)
I0711 12:48:37.786777 32652 sgd_solver.cpp:106] Iteration 22700, lr = 0.00411234
I0711 12:48:40.956348 32652 solver.cpp:228] Iteration 22800, loss = 0.00189358
I0711 12:48:40.956395 32652 solver.cpp:244]     Train net output #0: loss = 0.00189356 (* 1 = 0.00189356 loss)
I0711 12:48:40.956406 32652 sgd_solver.cpp:106] Iteration 22800, lr = 0.00410293
I0711 12:48:44.113987 32652 solver.cpp:228] Iteration 22900, loss = 0.0049088
I0711 12:48:44.114107 32652 solver.cpp:244]     Train net output #0: loss = 0.00490879 (* 1 = 0.00490879 loss)
I0711 12:48:44.114118 32652 sgd_solver.cpp:106] Iteration 22900, lr = 0.00409358
I0711 12:48:47.240576 32652 solver.cpp:337] Iteration 23000, Testing net (#0)
I0711 12:48:49.353981 32652 solver.cpp:404]     Test net output #0: loss = 0.00888359 (* 1 = 0.00888359 loss)
I0711 12:48:49.376571 32652 solver.cpp:228] Iteration 23000, loss = 0.00133832
I0711 12:48:49.376605 32652 solver.cpp:244]     Train net output #0: loss = 0.0013383 (* 1 = 0.0013383 loss)
I0711 12:48:49.376617 32652 sgd_solver.cpp:106] Iteration 23000, lr = 0.00408427
I0711 12:48:52.538501 32652 solver.cpp:228] Iteration 23100, loss = 0.000105568
I0711 12:48:52.538544 32652 solver.cpp:244]     Train net output #0: loss = 0.000105551 (* 1 = 0.000105551 loss)
I0711 12:48:52.538555 32652 sgd_solver.cpp:106] Iteration 23100, lr = 0.00407501
I0711 12:48:55.695986 32652 solver.cpp:228] Iteration 23200, loss = 0.00222469
I0711 12:48:55.696038 32652 solver.cpp:244]     Train net output #0: loss = 0.00222468 (* 1 = 0.00222468 loss)
I0711 12:48:55.696046 32652 sgd_solver.cpp:106] Iteration 23200, lr = 0.0040658
I0711 12:48:58.852639 32652 solver.cpp:228] Iteration 23300, loss = 0.001011
I0711 12:48:58.852685 32652 solver.cpp:244]     Train net output #0: loss = 0.00101098 (* 1 = 0.00101098 loss)
I0711 12:48:58.852695 32652 sgd_solver.cpp:106] Iteration 23300, lr = 0.00405664
I0711 12:49:02.013734 32652 solver.cpp:228] Iteration 23400, loss = 0.00110099
I0711 12:49:02.013780 32652 solver.cpp:244]     Train net output #0: loss = 0.00110098 (* 1 = 0.00110098 loss)
I0711 12:49:02.013790 32652 sgd_solver.cpp:106] Iteration 23400, lr = 0.00404753
I0711 12:49:05.140311 32652 solver.cpp:337] Iteration 23500, Testing net (#0)
I0711 12:49:07.260449 32652 solver.cpp:404]     Test net output #0: loss = 0.00878 (* 1 = 0.00878 loss)
I0711 12:49:07.283493 32652 solver.cpp:228] Iteration 23500, loss = 0.00336298
I0711 12:49:07.283535 32652 solver.cpp:244]     Train net output #0: loss = 0.00336296 (* 1 = 0.00336296 loss)
I0711 12:49:07.283547 32652 sgd_solver.cpp:106] Iteration 23500, lr = 0.00403847
I0711 12:49:10.442262 32652 solver.cpp:228] Iteration 23600, loss = 0.0035697
I0711 12:49:10.442308 32652 solver.cpp:244]     Train net output #0: loss = 0.00356968 (* 1 = 0.00356968 loss)
I0711 12:49:10.442318 32652 sgd_solver.cpp:106] Iteration 23600, lr = 0.00402945
I0711 12:49:13.599859 32652 solver.cpp:228] Iteration 23700, loss = 0.00782324
I0711 12:49:13.599903 32652 solver.cpp:244]     Train net output #0: loss = 0.00782322 (* 1 = 0.00782322 loss)
I0711 12:49:13.599915 32652 sgd_solver.cpp:106] Iteration 23700, lr = 0.00402048
I0711 12:49:16.757884 32652 solver.cpp:228] Iteration 23800, loss = 0.00248561
I0711 12:49:16.758205 32652 solver.cpp:244]     Train net output #0: loss = 0.00248559 (* 1 = 0.00248559 loss)
I0711 12:49:16.758216 32652 sgd_solver.cpp:106] Iteration 23800, lr = 0.00401155
I0711 12:49:19.915946 32652 solver.cpp:228] Iteration 23900, loss = 0.000705209
I0711 12:49:19.915992 32652 solver.cpp:244]     Train net output #0: loss = 0.000705189 (* 1 = 0.000705189 loss)
I0711 12:49:19.916002 32652 sgd_solver.cpp:106] Iteration 23900, lr = 0.00400267
I0711 12:49:23.043812 32652 solver.cpp:337] Iteration 24000, Testing net (#0)
I0711 12:49:25.160747 32652 solver.cpp:404]     Test net output #0: loss = 0.00898832 (* 1 = 0.00898832 loss)
I0711 12:49:25.183194 32652 solver.cpp:228] Iteration 24000, loss = 0.00368813
I0711 12:49:25.183228 32652 solver.cpp:244]     Train net output #0: loss = 0.00368811 (* 1 = 0.00368811 loss)
I0711 12:49:25.183238 32652 sgd_solver.cpp:106] Iteration 24000, lr = 0.00399384
I0711 12:49:28.345742 32652 solver.cpp:228] Iteration 24100, loss = 0.00187555
I0711 12:49:28.345795 32652 solver.cpp:244]     Train net output #0: loss = 0.00187553 (* 1 = 0.00187553 loss)
I0711 12:49:28.345805 32652 sgd_solver.cpp:106] Iteration 24100, lr = 0.00398505
I0711 12:49:31.517807 32652 solver.cpp:228] Iteration 24200, loss = 0.000515286
I0711 12:49:31.517859 32652 solver.cpp:244]     Train net output #0: loss = 0.000515266 (* 1 = 0.000515266 loss)
I0711 12:49:31.517869 32652 sgd_solver.cpp:106] Iteration 24200, lr = 0.00397631
I0711 12:49:34.678074 32652 solver.cpp:228] Iteration 24300, loss = 0.00144607
I0711 12:49:34.678119 32652 solver.cpp:244]     Train net output #0: loss = 0.00144605 (* 1 = 0.00144605 loss)
I0711 12:49:34.678130 32652 sgd_solver.cpp:106] Iteration 24300, lr = 0.00396761
I0711 12:49:37.847268 32652 solver.cpp:228] Iteration 24400, loss = 0.00123195
I0711 12:49:37.847319 32652 solver.cpp:244]     Train net output #0: loss = 0.00123193 (* 1 = 0.00123193 loss)
I0711 12:49:37.847331 32652 sgd_solver.cpp:106] Iteration 24400, lr = 0.00395896
I0711 12:49:40.976605 32652 solver.cpp:337] Iteration 24500, Testing net (#0)
I0711 12:49:43.087505 32652 solver.cpp:404]     Test net output #0: loss = 0.00894877 (* 1 = 0.00894877 loss)
I0711 12:49:43.110083 32652 solver.cpp:228] Iteration 24500, loss = 0.000970405
I0711 12:49:43.110115 32652 solver.cpp:244]     Train net output #0: loss = 0.000970386 (* 1 = 0.000970386 loss)
I0711 12:49:43.110126 32652 sgd_solver.cpp:106] Iteration 24500, lr = 0.00395035
I0711 12:49:46.272598 32652 solver.cpp:228] Iteration 24600, loss = 0.00257368
I0711 12:49:46.272650 32652 solver.cpp:244]     Train net output #0: loss = 0.00257366 (* 1 = 0.00257366 loss)
I0711 12:49:46.272660 32652 sgd_solver.cpp:106] Iteration 24600, lr = 0.00394178
I0711 12:49:49.435931 32652 solver.cpp:228] Iteration 24700, loss = 0.00248257
I0711 12:49:49.436049 32652 solver.cpp:244]     Train net output #0: loss = 0.00248255 (* 1 = 0.00248255 loss)
I0711 12:49:49.436063 32652 sgd_solver.cpp:106] Iteration 24700, lr = 0.00393326
I0711 12:49:52.603864 32652 solver.cpp:228] Iteration 24800, loss = 0.00171888
I0711 12:49:52.603906 32652 solver.cpp:244]     Train net output #0: loss = 0.00171886 (* 1 = 0.00171886 loss)
I0711 12:49:52.603929 32652 sgd_solver.cpp:106] Iteration 24800, lr = 0.00392478
I0711 12:49:55.770201 32652 solver.cpp:228] Iteration 24900, loss = 0.00345071
I0711 12:49:55.770246 32652 solver.cpp:244]     Train net output #0: loss = 0.0034507 (* 1 = 0.0034507 loss)
I0711 12:49:55.770256 32652 sgd_solver.cpp:106] Iteration 24900, lr = 0.00391634
I0711 12:49:58.901674 32652 solver.cpp:337] Iteration 25000, Testing net (#0)
I0711 12:50:01.037178 32652 solver.cpp:404]     Test net output #0: loss = 0.00884268 (* 1 = 0.00884268 loss)
I0711 12:50:01.060231 32652 solver.cpp:228] Iteration 25000, loss = 0.00098735
I0711 12:50:01.060261 32652 solver.cpp:244]     Train net output #0: loss = 0.000987331 (* 1 = 0.000987331 loss)
I0711 12:50:01.060284 32652 sgd_solver.cpp:106] Iteration 25000, lr = 0.00390795
I0711 12:50:04.222741 32652 solver.cpp:228] Iteration 25100, loss = 0.00376486
I0711 12:50:04.222784 32652 solver.cpp:244]     Train net output #0: loss = 0.00376484 (* 1 = 0.00376484 loss)
I0711 12:50:04.222806 32652 sgd_solver.cpp:106] Iteration 25100, lr = 0.0038996
I0711 12:50:07.382825 32652 solver.cpp:228] Iteration 25200, loss = 0.00332357
I0711 12:50:07.382870 32652 solver.cpp:244]     Train net output #0: loss = 0.00332356 (* 1 = 0.00332356 loss)
I0711 12:50:07.382884 32652 sgd_solver.cpp:106] Iteration 25200, lr = 0.00389128
I0711 12:50:10.540472 32652 solver.cpp:228] Iteration 25300, loss = 0.00178709
I0711 12:50:10.540520 32652 solver.cpp:244]     Train net output #0: loss = 0.00178707 (* 1 = 0.00178707 loss)
I0711 12:50:10.540534 32652 sgd_solver.cpp:106] Iteration 25300, lr = 0.00388301
I0711 12:50:13.710000 32652 solver.cpp:228] Iteration 25400, loss = 0.00416352
I0711 12:50:13.710052 32652 solver.cpp:244]     Train net output #0: loss = 0.0041635 (* 1 = 0.0041635 loss)
I0711 12:50:13.710062 32652 sgd_solver.cpp:106] Iteration 25400, lr = 0.00387478
I0711 12:50:16.835242 32652 solver.cpp:337] Iteration 25500, Testing net (#0)
I0711 12:50:18.946678 32652 solver.cpp:404]     Test net output #0: loss = 0.00886112 (* 1 = 0.00886112 loss)
I0711 12:50:18.969482 32652 solver.cpp:228] Iteration 25500, loss = 0.00110301
I0711 12:50:18.969522 32652 solver.cpp:244]     Train net output #0: loss = 0.00110299 (* 1 = 0.00110299 loss)
I0711 12:50:18.969535 32652 sgd_solver.cpp:106] Iteration 25500, lr = 0.0038666
I0711 12:50:22.124723 32652 solver.cpp:228] Iteration 25600, loss = 0.00150333
I0711 12:50:22.124855 32652 solver.cpp:244]     Train net output #0: loss = 0.00150332 (* 1 = 0.00150332 loss)
I0711 12:50:22.124866 32652 sgd_solver.cpp:106] Iteration 25600, lr = 0.00385845
I0711 12:50:25.294317 32652 solver.cpp:228] Iteration 25700, loss = 0.00245307
I0711 12:50:25.294370 32652 solver.cpp:244]     Train net output #0: loss = 0.00245305 (* 1 = 0.00245305 loss)
I0711 12:50:25.294380 32652 sgd_solver.cpp:106] Iteration 25700, lr = 0.00385034
I0711 12:50:28.453788 32652 solver.cpp:228] Iteration 25800, loss = 0.00172774
I0711 12:50:28.453833 32652 solver.cpp:244]     Train net output #0: loss = 0.00172772 (* 1 = 0.00172772 loss)
I0711 12:50:28.453845 32652 sgd_solver.cpp:106] Iteration 25800, lr = 0.00384227
I0711 12:50:31.618825 32652 solver.cpp:228] Iteration 25900, loss = 0.00128676
I0711 12:50:31.618877 32652 solver.cpp:244]     Train net output #0: loss = 0.00128674 (* 1 = 0.00128674 loss)
I0711 12:50:31.618887 32652 sgd_solver.cpp:106] Iteration 25900, lr = 0.00383424
I0711 12:50:34.750154 32652 solver.cpp:337] Iteration 26000, Testing net (#0)
I0711 12:50:36.874377 32652 solver.cpp:404]     Test net output #0: loss = 0.00890322 (* 1 = 0.00890322 loss)
I0711 12:50:36.897153 32652 solver.cpp:228] Iteration 26000, loss = 0.00232221
I0711 12:50:36.897186 32652 solver.cpp:244]     Train net output #0: loss = 0.00232219 (* 1 = 0.00232219 loss)
I0711 12:50:36.897197 32652 sgd_solver.cpp:106] Iteration 26000, lr = 0.00382625
I0711 12:50:40.055502 32652 solver.cpp:228] Iteration 26100, loss = 0.000963988
I0711 12:50:40.055551 32652 solver.cpp:244]     Train net output #0: loss = 0.00096397 (* 1 = 0.00096397 loss)
I0711 12:50:40.055560 32652 sgd_solver.cpp:106] Iteration 26100, lr = 0.0038183
I0711 12:50:43.217599 32652 solver.cpp:228] Iteration 26200, loss = 0.000706406
I0711 12:50:43.217653 32652 solver.cpp:244]     Train net output #0: loss = 0.000706387 (* 1 = 0.000706387 loss)
I0711 12:50:43.217663 32652 sgd_solver.cpp:106] Iteration 26200, lr = 0.00381038
I0711 12:50:46.379334 32652 solver.cpp:228] Iteration 26300, loss = 0.00138127
I0711 12:50:46.379380 32652 solver.cpp:244]     Train net output #0: loss = 0.00138125 (* 1 = 0.00138125 loss)
I0711 12:50:46.379390 32652 sgd_solver.cpp:106] Iteration 26300, lr = 0.00380251
I0711 12:50:49.554648 32652 solver.cpp:228] Iteration 26400, loss = 0.00172579
I0711 12:50:49.554699 32652 solver.cpp:244]     Train net output #0: loss = 0.00172578 (* 1 = 0.00172578 loss)
I0711 12:50:49.554709 32652 sgd_solver.cpp:106] Iteration 26400, lr = 0.00379467
I0711 12:50:52.686120 32652 solver.cpp:337] Iteration 26500, Testing net (#0)
I0711 12:50:54.813469 32652 solver.cpp:404]     Test net output #0: loss = 0.00868283 (* 1 = 0.00868283 loss)
I0711 12:50:54.836133 32652 solver.cpp:228] Iteration 26500, loss = 0.000380542
I0711 12:50:54.836168 32652 solver.cpp:244]     Train net output #0: loss = 0.000380523 (* 1 = 0.000380523 loss)
I0711 12:50:54.836179 32652 sgd_solver.cpp:106] Iteration 26500, lr = 0.00378687
I0711 12:50:57.997885 32652 solver.cpp:228] Iteration 26600, loss = 0.00174736
I0711 12:50:57.997937 32652 solver.cpp:244]     Train net output #0: loss = 0.00174734 (* 1 = 0.00174734 loss)
I0711 12:50:57.997947 32652 sgd_solver.cpp:106] Iteration 26600, lr = 0.00377911
I0711 12:51:01.169471 32652 solver.cpp:228] Iteration 26700, loss = 0.00103785
I0711 12:51:01.169517 32652 solver.cpp:244]     Train net output #0: loss = 0.00103783 (* 1 = 0.00103783 loss)
I0711 12:51:01.169528 32652 sgd_solver.cpp:106] Iteration 26700, lr = 0.00377138
I0711 12:51:04.327354 32652 solver.cpp:228] Iteration 26800, loss = 0.00248364
I0711 12:51:04.327406 32652 solver.cpp:244]     Train net output #0: loss = 0.00248363 (* 1 = 0.00248363 loss)
I0711 12:51:04.327416 32652 sgd_solver.cpp:106] Iteration 26800, lr = 0.00376369
I0711 12:51:07.498934 32652 solver.cpp:228] Iteration 26900, loss = 0.00148963
I0711 12:51:07.498978 32652 solver.cpp:244]     Train net output #0: loss = 0.00148961 (* 1 = 0.00148961 loss)
I0711 12:51:07.499001 32652 sgd_solver.cpp:106] Iteration 26900, lr = 0.00375604
I0711 12:51:10.630789 32652 solver.cpp:337] Iteration 27000, Testing net (#0)
I0711 12:51:12.753041 32652 solver.cpp:404]     Test net output #0: loss = 0.00866191 (* 1 = 0.00866191 loss)
I0711 12:51:12.776924 32652 solver.cpp:228] Iteration 27000, loss = 0.00161895
I0711 12:51:12.776975 32652 solver.cpp:244]     Train net output #0: loss = 0.00161893 (* 1 = 0.00161893 loss)
I0711 12:51:12.776989 32652 sgd_solver.cpp:106] Iteration 27000, lr = 0.00374842
I0711 12:51:15.940145 32652 solver.cpp:228] Iteration 27100, loss = 0.00292263
I0711 12:51:15.940196 32652 solver.cpp:244]     Train net output #0: loss = 0.00292261 (* 1 = 0.00292261 loss)
I0711 12:51:15.940206 32652 sgd_solver.cpp:106] Iteration 27100, lr = 0.00374084
I0711 12:51:19.116818 32652 solver.cpp:228] Iteration 27200, loss = 0.00112093
I0711 12:51:19.116865 32652 solver.cpp:244]     Train net output #0: loss = 0.00112091 (* 1 = 0.00112091 loss)
I0711 12:51:19.116876 32652 sgd_solver.cpp:106] Iteration 27200, lr = 0.0037333
I0711 12:51:22.274405 32652 solver.cpp:228] Iteration 27300, loss = 0.00112356
I0711 12:51:22.274452 32652 solver.cpp:244]     Train net output #0: loss = 0.00112354 (* 1 = 0.00112354 loss)
I0711 12:51:22.274463 32652 sgd_solver.cpp:106] Iteration 27300, lr = 0.00372579
I0711 12:51:25.440635 32652 solver.cpp:228] Iteration 27400, loss = 0.00042011
I0711 12:51:25.440747 32652 solver.cpp:244]     Train net output #0: loss = 0.000420091 (* 1 = 0.000420091 loss)
I0711 12:51:25.440757 32652 sgd_solver.cpp:106] Iteration 27400, lr = 0.00371832
I0711 12:51:28.567858 32652 solver.cpp:337] Iteration 27500, Testing net (#0)
I0711 12:51:30.682796 32652 solver.cpp:404]     Test net output #0: loss = 0.00892916 (* 1 = 0.00892916 loss)
I0711 12:51:30.705502 32652 solver.cpp:228] Iteration 27500, loss = 0.00232629
I0711 12:51:30.705540 32652 solver.cpp:244]     Train net output #0: loss = 0.00232627 (* 1 = 0.00232627 loss)
I0711 12:51:30.705554 32652 sgd_solver.cpp:106] Iteration 27500, lr = 0.00371088
I0711 12:51:33.863327 32652 solver.cpp:228] Iteration 27600, loss = 0.00109451
I0711 12:51:33.863379 32652 solver.cpp:244]     Train net output #0: loss = 0.00109449 (* 1 = 0.00109449 loss)
I0711 12:51:33.863389 32652 sgd_solver.cpp:106] Iteration 27600, lr = 0.00370347
I0711 12:51:37.021199 32652 solver.cpp:228] Iteration 27700, loss = 0.00186155
I0711 12:51:37.021245 32652 solver.cpp:244]     Train net output #0: loss = 0.00186153 (* 1 = 0.00186153 loss)
I0711 12:51:37.021255 32652 sgd_solver.cpp:106] Iteration 27700, lr = 0.0036961
I0711 12:51:40.179394 32652 solver.cpp:228] Iteration 27800, loss = 0.00128636
I0711 12:51:40.179440 32652 solver.cpp:244]     Train net output #0: loss = 0.00128634 (* 1 = 0.00128634 loss)
I0711 12:51:40.179451 32652 sgd_solver.cpp:106] Iteration 27800, lr = 0.00368877
I0711 12:51:43.348995 32652 solver.cpp:228] Iteration 27900, loss = 0.000685553
I0711 12:51:43.349041 32652 solver.cpp:244]     Train net output #0: loss = 0.000685535 (* 1 = 0.000685535 loss)
I0711 12:51:43.349052 32652 sgd_solver.cpp:106] Iteration 27900, lr = 0.00368146
I0711 12:51:46.475934 32652 solver.cpp:337] Iteration 28000, Testing net (#0)
I0711 12:51:48.587611 32652 solver.cpp:404]     Test net output #0: loss = 0.00884746 (* 1 = 0.00884746 loss)
I0711 12:51:48.610327 32652 solver.cpp:228] Iteration 28000, loss = 0.000665641
I0711 12:51:48.610357 32652 solver.cpp:244]     Train net output #0: loss = 0.000665623 (* 1 = 0.000665623 loss)
I0711 12:51:48.610369 32652 sgd_solver.cpp:106] Iteration 28000, lr = 0.0036742
I0711 12:51:51.767102 32652 solver.cpp:228] Iteration 28100, loss = 0.0032265
I0711 12:51:51.767149 32652 solver.cpp:244]     Train net output #0: loss = 0.00322648 (* 1 = 0.00322648 loss)
I0711 12:51:51.767159 32652 sgd_solver.cpp:106] Iteration 28100, lr = 0.00366696
I0711 12:51:54.923588 32652 solver.cpp:228] Iteration 28200, loss = 0.000484486
I0711 12:51:54.923632 32652 solver.cpp:244]     Train net output #0: loss = 0.000484467 (* 1 = 0.000484467 loss)
I0711 12:51:54.923642 32652 sgd_solver.cpp:106] Iteration 28200, lr = 0.00365976
I0711 12:51:58.082387 32652 solver.cpp:228] Iteration 28300, loss = 0.0014391
I0711 12:51:58.082597 32652 solver.cpp:244]     Train net output #0: loss = 0.00143908 (* 1 = 0.00143908 loss)
I0711 12:51:58.082608 32652 sgd_solver.cpp:106] Iteration 28300, lr = 0.00365259
I0711 12:52:01.245085 32652 solver.cpp:228] Iteration 28400, loss = 0.00217203
I0711 12:52:01.245128 32652 solver.cpp:244]     Train net output #0: loss = 0.00217201 (* 1 = 0.00217201 loss)
I0711 12:52:01.245139 32652 sgd_solver.cpp:106] Iteration 28400, lr = 0.00364545
I0711 12:52:04.378278 32652 solver.cpp:337] Iteration 28500, Testing net (#0)
I0711 12:52:06.515203 32652 solver.cpp:404]     Test net output #0: loss = 0.0089448 (* 1 = 0.0089448 loss)
I0711 12:52:06.537973 32652 solver.cpp:228] Iteration 28500, loss = 0.0008308
I0711 12:52:06.538012 32652 solver.cpp:244]     Train net output #0: loss = 0.000830782 (* 1 = 0.000830782 loss)
I0711 12:52:06.538023 32652 sgd_solver.cpp:106] Iteration 28500, lr = 0.00363835
I0711 12:52:09.716967 32652 solver.cpp:228] Iteration 28600, loss = 0.00465461
I0711 12:52:09.717021 32652 solver.cpp:244]     Train net output #0: loss = 0.00465459 (* 1 = 0.00465459 loss)
I0711 12:52:09.717031 32652 sgd_solver.cpp:106] Iteration 28600, lr = 0.00363128
I0711 12:52:12.880755 32652 solver.cpp:228] Iteration 28700, loss = 0.00166194
I0711 12:52:12.880803 32652 solver.cpp:244]     Train net output #0: loss = 0.00166193 (* 1 = 0.00166193 loss)
I0711 12:52:12.880813 32652 sgd_solver.cpp:106] Iteration 28700, lr = 0.00362424
I0711 12:52:16.040009 32652 solver.cpp:228] Iteration 28800, loss = 0.00281111
I0711 12:52:16.040053 32652 solver.cpp:244]     Train net output #0: loss = 0.00281109 (* 1 = 0.00281109 loss)
I0711 12:52:16.040071 32652 sgd_solver.cpp:106] Iteration 28800, lr = 0.00361723
I0711 12:52:19.198835 32652 solver.cpp:228] Iteration 28900, loss = 0.00183494
I0711 12:52:19.198881 32652 solver.cpp:244]     Train net output #0: loss = 0.00183493 (* 1 = 0.00183493 loss)
I0711 12:52:19.198894 32652 sgd_solver.cpp:106] Iteration 28900, lr = 0.00361025
I0711 12:52:22.326882 32652 solver.cpp:337] Iteration 29000, Testing net (#0)
I0711 12:52:24.452299 32652 solver.cpp:404]     Test net output #0: loss = 0.00877512 (* 1 = 0.00877512 loss)
I0711 12:52:24.475406 32652 solver.cpp:228] Iteration 29000, loss = 0.000499632
I0711 12:52:24.475441 32652 solver.cpp:244]     Train net output #0: loss = 0.000499615 (* 1 = 0.000499615 loss)
I0711 12:52:24.475457 32652 sgd_solver.cpp:106] Iteration 29000, lr = 0.00360331
I0711 12:52:27.641800 32652 solver.cpp:228] Iteration 29100, loss = 0.00135714
I0711 12:52:27.641847 32652 solver.cpp:244]     Train net output #0: loss = 0.00135712 (* 1 = 0.00135712 loss)
I0711 12:52:27.641861 32652 sgd_solver.cpp:106] Iteration 29100, lr = 0.0035964
I0711 12:52:30.799669 32652 solver.cpp:228] Iteration 29200, loss = 0.00231758
I0711 12:52:30.799872 32652 solver.cpp:244]     Train net output #0: loss = 0.00231757 (* 1 = 0.00231757 loss)
I0711 12:52:30.799890 32652 sgd_solver.cpp:106] Iteration 29200, lr = 0.00358951
I0711 12:52:33.959039 32652 solver.cpp:228] Iteration 29300, loss = 0.00216828
I0711 12:52:33.959095 32652 solver.cpp:244]     Train net output #0: loss = 0.00216826 (* 1 = 0.00216826 loss)
I0711 12:52:33.959108 32652 sgd_solver.cpp:106] Iteration 29300, lr = 0.00358266
I0711 12:52:37.121425 32652 solver.cpp:228] Iteration 29400, loss = 0.00160245
I0711 12:52:37.121470 32652 solver.cpp:244]     Train net output #0: loss = 0.00160243 (* 1 = 0.00160243 loss)
I0711 12:52:37.121481 32652 sgd_solver.cpp:106] Iteration 29400, lr = 0.00357584
I0711 12:52:40.252701 32652 solver.cpp:337] Iteration 29500, Testing net (#0)
I0711 12:52:42.376266 32652 solver.cpp:404]     Test net output #0: loss = 0.00884109 (* 1 = 0.00884109 loss)
I0711 12:52:42.398854 32652 solver.cpp:228] Iteration 29500, loss = 0.000946753
I0711 12:52:42.398888 32652 solver.cpp:244]     Train net output #0: loss = 0.000946736 (* 1 = 0.000946736 loss)
I0711 12:52:42.398900 32652 sgd_solver.cpp:106] Iteration 29500, lr = 0.00356905
I0711 12:52:45.562855 32652 solver.cpp:228] Iteration 29600, loss = 0.00134226
I0711 12:52:45.562906 32652 solver.cpp:244]     Train net output #0: loss = 0.00134225 (* 1 = 0.00134225 loss)
I0711 12:52:45.562916 32652 sgd_solver.cpp:106] Iteration 29600, lr = 0.00356228
I0711 12:52:48.720191 32652 solver.cpp:228] Iteration 29700, loss = 0.00187831
I0711 12:52:48.720237 32652 solver.cpp:244]     Train net output #0: loss = 0.00187829 (* 1 = 0.00187829 loss)
I0711 12:52:48.720247 32652 sgd_solver.cpp:106] Iteration 29700, lr = 0.00355555
I0711 12:52:51.879583 32652 solver.cpp:228] Iteration 29800, loss = 0.00236343
I0711 12:52:51.879628 32652 solver.cpp:244]     Train net output #0: loss = 0.00236341 (* 1 = 0.00236341 loss)
I0711 12:52:51.879644 32652 sgd_solver.cpp:106] Iteration 29800, lr = 0.00354885
I0711 12:52:55.038481 32652 solver.cpp:228] Iteration 29900, loss = 0.00165779
I0711 12:52:55.038525 32652 solver.cpp:244]     Train net output #0: loss = 0.00165778 (* 1 = 0.00165778 loss)
I0711 12:52:55.038543 32652 sgd_solver.cpp:106] Iteration 29900, lr = 0.00354218
I0711 12:52:58.163926 32652 solver.cpp:337] Iteration 30000, Testing net (#0)
I0711 12:53:00.282048 32652 solver.cpp:404]     Test net output #0: loss = 0.0086583 (* 1 = 0.0086583 loss)
I0711 12:53:00.304719 32652 solver.cpp:228] Iteration 30000, loss = 0.00160796
I0711 12:53:00.304744 32652 solver.cpp:244]     Train net output #0: loss = 0.00160794 (* 1 = 0.00160794 loss)
I0711 12:53:00.304769 32652 sgd_solver.cpp:106] Iteration 30000, lr = 0.00353553
I0711 12:53:03.462438 32652 solver.cpp:228] Iteration 30100, loss = 0.00109858
I0711 12:53:03.462589 32652 solver.cpp:244]     Train net output #0: loss = 0.00109857 (* 1 = 0.00109857 loss)
I0711 12:53:03.462604 32652 sgd_solver.cpp:106] Iteration 30100, lr = 0.00352892
I0711 12:53:06.621366 32652 solver.cpp:228] Iteration 30200, loss = 0.00126522
I0711 12:53:06.621410 32652 solver.cpp:244]     Train net output #0: loss = 0.00126521 (* 1 = 0.00126521 loss)
I0711 12:53:06.621434 32652 sgd_solver.cpp:106] Iteration 30200, lr = 0.00352233
I0711 12:53:09.779000 32652 solver.cpp:228] Iteration 30300, loss = 0.00142825
I0711 12:53:09.779045 32652 solver.cpp:244]     Train net output #0: loss = 0.00142823 (* 1 = 0.00142823 loss)
I0711 12:53:09.779057 32652 sgd_solver.cpp:106] Iteration 30300, lr = 0.00351578
I0711 12:53:12.936944 32652 solver.cpp:228] Iteration 30400, loss = 0.00388704
I0711 12:53:12.936997 32652 solver.cpp:244]     Train net output #0: loss = 0.00388702 (* 1 = 0.00388702 loss)
I0711 12:53:12.937007 32652 sgd_solver.cpp:106] Iteration 30400, lr = 0.00350925
I0711 12:53:16.062888 32652 solver.cpp:337] Iteration 30500, Testing net (#0)
I0711 12:53:18.192965 32652 solver.cpp:404]     Test net output #0: loss = 0.00885535 (* 1 = 0.00885535 loss)
I0711 12:53:18.216925 32652 solver.cpp:228] Iteration 30500, loss = 0.000874942
I0711 12:53:18.216964 32652 solver.cpp:244]     Train net output #0: loss = 0.000874925 (* 1 = 0.000874925 loss)
I0711 12:53:18.216989 32652 sgd_solver.cpp:106] Iteration 30500, lr = 0.00350275
I0711 12:53:21.394032 32652 solver.cpp:228] Iteration 30600, loss = 0.000107759
I0711 12:53:21.394085 32652 solver.cpp:244]     Train net output #0: loss = 0.000107744 (* 1 = 0.000107744 loss)
I0711 12:53:21.394095 32652 sgd_solver.cpp:106] Iteration 30600, lr = 0.00349627
I0711 12:53:24.568665 32652 solver.cpp:228] Iteration 30700, loss = 0.00151939
I0711 12:53:24.568719 32652 solver.cpp:244]     Train net output #0: loss = 0.00151937 (* 1 = 0.00151937 loss)
I0711 12:53:24.568729 32652 sgd_solver.cpp:106] Iteration 30700, lr = 0.00348983
I0711 12:53:27.730300 32652 solver.cpp:228] Iteration 30800, loss = 0.000648791
I0711 12:53:27.730348 32652 solver.cpp:244]     Train net output #0: loss = 0.000648775 (* 1 = 0.000648775 loss)
I0711 12:53:27.730358 32652 sgd_solver.cpp:106] Iteration 30800, lr = 0.00348341
I0711 12:53:30.906194 32652 solver.cpp:228] Iteration 30900, loss = 0.000831231
I0711 12:53:30.906249 32652 solver.cpp:244]     Train net output #0: loss = 0.000831214 (* 1 = 0.000831214 loss)
I0711 12:53:30.906258 32652 sgd_solver.cpp:106] Iteration 30900, lr = 0.00347702
I0711 12:53:34.053282 32652 solver.cpp:337] Iteration 31000, Testing net (#0)
I0711 12:53:36.173316 32652 solver.cpp:404]     Test net output #0: loss = 0.00877806 (* 1 = 0.00877806 loss)
I0711 12:53:36.195910 32652 solver.cpp:228] Iteration 31000, loss = 0.0025135
I0711 12:53:36.195945 32652 solver.cpp:244]     Train net output #0: loss = 0.00251348 (* 1 = 0.00251348 loss)
I0711 12:53:36.195956 32652 sgd_solver.cpp:106] Iteration 31000, lr = 0.00347066
I0711 12:53:39.367507 32652 solver.cpp:228] Iteration 31100, loss = 0.0029408
I0711 12:53:39.367554 32652 solver.cpp:244]     Train net output #0: loss = 0.00294079 (* 1 = 0.00294079 loss)
I0711 12:53:39.367564 32652 sgd_solver.cpp:106] Iteration 31100, lr = 0.00346433
I0711 12:53:42.525501 32652 solver.cpp:228] Iteration 31200, loss = 0.00584508
I0711 12:53:42.525543 32652 solver.cpp:244]     Train net output #0: loss = 0.00584506 (* 1 = 0.00584506 loss)
I0711 12:53:42.525553 32652 sgd_solver.cpp:106] Iteration 31200, lr = 0.00345802
I0711 12:53:45.692605 32652 solver.cpp:228] Iteration 31300, loss = 0.00181444
I0711 12:53:45.692648 32652 solver.cpp:244]     Train net output #0: loss = 0.00181442 (* 1 = 0.00181442 loss)
I0711 12:53:45.692662 32652 sgd_solver.cpp:106] Iteration 31300, lr = 0.00345174
I0711 12:53:48.869204 32652 solver.cpp:228] Iteration 31400, loss = 0.000590672
I0711 12:53:48.869249 32652 solver.cpp:244]     Train net output #0: loss = 0.000590654 (* 1 = 0.000590654 loss)
I0711 12:53:48.869273 32652 sgd_solver.cpp:106] Iteration 31400, lr = 0.00344548
I0711 12:53:52.012974 32652 solver.cpp:337] Iteration 31500, Testing net (#0)
I0711 12:53:54.133232 32652 solver.cpp:404]     Test net output #0: loss = 0.00892154 (* 1 = 0.00892154 loss)
I0711 12:53:54.156247 32652 solver.cpp:228] Iteration 31500, loss = 0.00286577
I0711 12:53:54.156275 32652 solver.cpp:244]     Train net output #0: loss = 0.00286575 (* 1 = 0.00286575 loss)
I0711 12:53:54.156301 32652 sgd_solver.cpp:106] Iteration 31500, lr = 0.00343925
I0711 12:53:57.332311 32652 solver.cpp:228] Iteration 31600, loss = 0.00154706
I0711 12:53:57.332358 32652 solver.cpp:244]     Train net output #0: loss = 0.00154704 (* 1 = 0.00154704 loss)
I0711 12:53:57.332370 32652 sgd_solver.cpp:106] Iteration 31600, lr = 0.00343305
I0711 12:54:00.492995 32652 solver.cpp:228] Iteration 31700, loss = 0.000348675
I0711 12:54:00.493046 32652 solver.cpp:244]     Train net output #0: loss = 0.000348658 (* 1 = 0.000348658 loss)
I0711 12:54:00.493057 32652 sgd_solver.cpp:106] Iteration 31700, lr = 0.00342687
I0711 12:54:03.649715 32652 solver.cpp:228] Iteration 31800, loss = 0.00105143
I0711 12:54:03.649761 32652 solver.cpp:244]     Train net output #0: loss = 0.00105141 (* 1 = 0.00105141 loss)
I0711 12:54:03.649771 32652 sgd_solver.cpp:106] Iteration 31800, lr = 0.00342072
I0711 12:54:06.805331 32652 solver.cpp:228] Iteration 31900, loss = 0.00102294
I0711 12:54:06.805474 32652 solver.cpp:244]     Train net output #0: loss = 0.00102292 (* 1 = 0.00102292 loss)
I0711 12:54:06.805485 32652 sgd_solver.cpp:106] Iteration 31900, lr = 0.0034146
I0711 12:54:09.930168 32652 solver.cpp:337] Iteration 32000, Testing net (#0)
I0711 12:54:12.044595 32652 solver.cpp:404]     Test net output #0: loss = 0.00883951 (* 1 = 0.00883951 loss)
I0711 12:54:12.067422 32652 solver.cpp:228] Iteration 32000, loss = 0.000810892
I0711 12:54:12.067463 32652 solver.cpp:244]     Train net output #0: loss = 0.000810875 (* 1 = 0.000810875 loss)
I0711 12:54:12.067476 32652 sgd_solver.cpp:106] Iteration 32000, lr = 0.0034085
I0711 12:54:15.248553 32652 solver.cpp:228] Iteration 32100, loss = 0.00217313
I0711 12:54:15.248605 32652 solver.cpp:244]     Train net output #0: loss = 0.00217312 (* 1 = 0.00217312 loss)
I0711 12:54:15.248615 32652 sgd_solver.cpp:106] Iteration 32100, lr = 0.00340242
I0711 12:54:18.459880 32652 solver.cpp:228] Iteration 32200, loss = 0.00197451
I0711 12:54:18.459933 32652 solver.cpp:244]     Train net output #0: loss = 0.0019745 (* 1 = 0.0019745 loss)
I0711 12:54:18.459944 32652 sgd_solver.cpp:106] Iteration 32200, lr = 0.00339637
I0711 12:54:21.706696 32652 solver.cpp:228] Iteration 32300, loss = 0.00130619
I0711 12:54:21.706737 32652 solver.cpp:244]     Train net output #0: loss = 0.00130618 (* 1 = 0.00130618 loss)
I0711 12:54:21.706748 32652 sgd_solver.cpp:106] Iteration 32300, lr = 0.00339035
I0711 12:54:24.891634 32652 solver.cpp:228] Iteration 32400, loss = 0.00267667
I0711 12:54:24.891687 32652 solver.cpp:244]     Train net output #0: loss = 0.00267666 (* 1 = 0.00267666 loss)
I0711 12:54:24.891702 32652 sgd_solver.cpp:106] Iteration 32400, lr = 0.00338435
I0711 12:54:28.025616 32652 solver.cpp:337] Iteration 32500, Testing net (#0)
I0711 12:54:30.138578 32652 solver.cpp:404]     Test net output #0: loss = 0.00880998 (* 1 = 0.00880998 loss)
I0711 12:54:30.161690 32652 solver.cpp:228] Iteration 32500, loss = 0.000778296
I0711 12:54:30.161736 32652 solver.cpp:244]     Train net output #0: loss = 0.000778279 (* 1 = 0.000778279 loss)
I0711 12:54:30.161752 32652 sgd_solver.cpp:106] Iteration 32500, lr = 0.00337838
I0711 12:54:33.328683 32652 solver.cpp:228] Iteration 32600, loss = 0.00246823
I0711 12:54:33.328729 32652 solver.cpp:244]     Train net output #0: loss = 0.00246822 (* 1 = 0.00246822 loss)
I0711 12:54:33.328745 32652 sgd_solver.cpp:106] Iteration 32600, lr = 0.00337243
I0711 12:54:36.489157 32652 solver.cpp:228] Iteration 32700, loss = 0.0025459
I0711 12:54:36.489210 32652 solver.cpp:244]     Train net output #0: loss = 0.00254589 (* 1 = 0.00254589 loss)
I0711 12:54:36.489220 32652 sgd_solver.cpp:106] Iteration 32700, lr = 0.0033665
I0711 12:54:39.651952 32652 solver.cpp:228] Iteration 32800, loss = 0.00144446
I0711 12:54:39.652117 32652 solver.cpp:244]     Train net output #0: loss = 0.00144444 (* 1 = 0.00144444 loss)
I0711 12:54:39.652129 32652 sgd_solver.cpp:106] Iteration 32800, lr = 0.0033606
I0711 12:54:42.825660 32652 solver.cpp:228] Iteration 32900, loss = 0.00268635
I0711 12:54:42.825705 32652 solver.cpp:244]     Train net output #0: loss = 0.00268634 (* 1 = 0.00268634 loss)
I0711 12:54:42.825714 32652 sgd_solver.cpp:106] Iteration 32900, lr = 0.00335473
I0711 12:54:45.975610 32652 solver.cpp:337] Iteration 33000, Testing net (#0)
I0711 12:54:48.090834 32652 solver.cpp:404]     Test net output #0: loss = 0.00887123 (* 1 = 0.00887123 loss)
I0711 12:54:48.113674 32652 solver.cpp:228] Iteration 33000, loss = 0.000964317
I0711 12:54:48.113715 32652 solver.cpp:244]     Train net output #0: loss = 0.0009643 (* 1 = 0.0009643 loss)
I0711 12:54:48.113728 32652 sgd_solver.cpp:106] Iteration 33000, lr = 0.00334887
I0711 12:54:51.284958 32652 solver.cpp:228] Iteration 33100, loss = 0.00124788
I0711 12:54:51.285003 32652 solver.cpp:244]     Train net output #0: loss = 0.00124787 (* 1 = 0.00124787 loss)
I0711 12:54:51.285014 32652 sgd_solver.cpp:106] Iteration 33100, lr = 0.00334304
I0711 12:54:54.455473 32652 solver.cpp:228] Iteration 33200, loss = 0.00197742
I0711 12:54:54.455526 32652 solver.cpp:244]     Train net output #0: loss = 0.0019774 (* 1 = 0.0019774 loss)
I0711 12:54:54.455536 32652 sgd_solver.cpp:106] Iteration 33200, lr = 0.00333724
I0711 12:54:57.622417 32652 solver.cpp:228] Iteration 33300, loss = 0.00131006
I0711 12:54:57.622463 32652 solver.cpp:244]     Train net output #0: loss = 0.00131004 (* 1 = 0.00131004 loss)
I0711 12:54:57.622474 32652 sgd_solver.cpp:106] Iteration 33300, lr = 0.00333146
I0711 12:55:00.794981 32652 solver.cpp:228] Iteration 33400, loss = 0.00111256
I0711 12:55:00.795034 32652 solver.cpp:244]     Train net output #0: loss = 0.00111254 (* 1 = 0.00111254 loss)
I0711 12:55:00.795044 32652 sgd_solver.cpp:106] Iteration 33400, lr = 0.0033257
I0711 12:55:03.945966 32652 solver.cpp:337] Iteration 33500, Testing net (#0)
I0711 12:55:06.061652 32652 solver.cpp:404]     Test net output #0: loss = 0.00887102 (* 1 = 0.00887102 loss)
I0711 12:55:06.084831 32652 solver.cpp:228] Iteration 33500, loss = 0.00170904
I0711 12:55:06.084877 32652 solver.cpp:244]     Train net output #0: loss = 0.00170902 (* 1 = 0.00170902 loss)
I0711 12:55:06.084889 32652 sgd_solver.cpp:106] Iteration 33500, lr = 0.00331996
I0711 12:55:09.264542 32652 solver.cpp:228] Iteration 33600, loss = 0.000822958
I0711 12:55:09.264585 32652 solver.cpp:244]     Train net output #0: loss = 0.000822942 (* 1 = 0.000822942 loss)
I0711 12:55:09.264595 32652 sgd_solver.cpp:106] Iteration 33600, lr = 0.00331425
I0711 12:55:12.446110 32652 solver.cpp:228] Iteration 33700, loss = 0.000617069
I0711 12:55:12.446301 32652 solver.cpp:244]     Train net output #0: loss = 0.000617052 (* 1 = 0.000617052 loss)
I0711 12:55:12.446311 32652 sgd_solver.cpp:106] Iteration 33700, lr = 0.00330856
I0711 12:55:15.623591 32652 solver.cpp:228] Iteration 33800, loss = 0.00105298
I0711 12:55:15.623637 32652 solver.cpp:244]     Train net output #0: loss = 0.00105296 (* 1 = 0.00105296 loss)
I0711 12:55:15.623648 32652 sgd_solver.cpp:106] Iteration 33800, lr = 0.00330289
I0711 12:55:18.791923 32652 solver.cpp:228] Iteration 33900, loss = 0.00139893
I0711 12:55:18.791971 32652 solver.cpp:244]     Train net output #0: loss = 0.00139892 (* 1 = 0.00139892 loss)
I0711 12:55:18.791982 32652 sgd_solver.cpp:106] Iteration 33900, lr = 0.00329725
I0711 12:55:21.920336 32652 solver.cpp:337] Iteration 34000, Testing net (#0)
I0711 12:55:24.054097 32652 solver.cpp:404]     Test net output #0: loss = 0.00870108 (* 1 = 0.00870108 loss)
I0711 12:55:24.077266 32652 solver.cpp:228] Iteration 34000, loss = 0.000325258
I0711 12:55:24.077307 32652 solver.cpp:244]     Train net output #0: loss = 0.000325241 (* 1 = 0.000325241 loss)
I0711 12:55:24.077328 32652 sgd_solver.cpp:106] Iteration 34000, lr = 0.00329163
I0711 12:55:27.260413 32652 solver.cpp:228] Iteration 34100, loss = 0.00141102
I0711 12:55:27.260458 32652 solver.cpp:244]     Train net output #0: loss = 0.00141101 (* 1 = 0.00141101 loss)
I0711 12:55:27.260473 32652 sgd_solver.cpp:106] Iteration 34100, lr = 0.00328603
I0711 12:55:30.423516 32652 solver.cpp:228] Iteration 34200, loss = 0.000849259
I0711 12:55:30.423573 32652 solver.cpp:244]     Train net output #0: loss = 0.000849243 (* 1 = 0.000849243 loss)
I0711 12:55:30.423588 32652 sgd_solver.cpp:106] Iteration 34200, lr = 0.00328045
I0711 12:55:33.588675 32652 solver.cpp:228] Iteration 34300, loss = 0.00213747
I0711 12:55:33.588721 32652 solver.cpp:244]     Train net output #0: loss = 0.00213745 (* 1 = 0.00213745 loss)
I0711 12:55:33.588742 32652 sgd_solver.cpp:106] Iteration 34300, lr = 0.00327489
I0711 12:55:36.750314 32652 solver.cpp:228] Iteration 34400, loss = 0.00121613
I0711 12:55:36.750360 32652 solver.cpp:244]     Train net output #0: loss = 0.00121611 (* 1 = 0.00121611 loss)
I0711 12:55:36.750383 32652 sgd_solver.cpp:106] Iteration 34400, lr = 0.00326936
I0711 12:55:39.884958 32652 solver.cpp:337] Iteration 34500, Testing net (#0)
I0711 12:55:42.005455 32652 solver.cpp:404]     Test net output #0: loss = 0.00866672 (* 1 = 0.00866672 loss)
I0711 12:55:42.028149 32652 solver.cpp:228] Iteration 34500, loss = 0.00142626
I0711 12:55:42.028172 32652 solver.cpp:244]     Train net output #0: loss = 0.00142624 (* 1 = 0.00142624 loss)
I0711 12:55:42.028189 32652 sgd_solver.cpp:106] Iteration 34500, lr = 0.00326385
I0711 12:55:45.196967 32652 solver.cpp:228] Iteration 34600, loss = 0.00250539
I0711 12:55:45.197182 32652 solver.cpp:244]     Train net output #0: loss = 0.00250537 (* 1 = 0.00250537 loss)
I0711 12:55:45.197196 32652 sgd_solver.cpp:106] Iteration 34600, lr = 0.00325836
I0711 12:55:48.372380 32652 solver.cpp:228] Iteration 34700, loss = 0.000907549
I0711 12:55:48.372426 32652 solver.cpp:244]     Train net output #0: loss = 0.000907533 (* 1 = 0.000907533 loss)
I0711 12:55:48.372436 32652 sgd_solver.cpp:106] Iteration 34700, lr = 0.00325289
I0711 12:55:51.543193 32652 solver.cpp:228] Iteration 34800, loss = 0.00092283
I0711 12:55:51.543251 32652 solver.cpp:244]     Train net output #0: loss = 0.000922814 (* 1 = 0.000922814 loss)
I0711 12:55:51.543262 32652 sgd_solver.cpp:106] Iteration 34800, lr = 0.00324744
I0711 12:55:54.711529 32652 solver.cpp:228] Iteration 34900, loss = 0.00040871
I0711 12:55:54.711582 32652 solver.cpp:244]     Train net output #0: loss = 0.000408694 (* 1 = 0.000408694 loss)
I0711 12:55:54.711592 32652 sgd_solver.cpp:106] Iteration 34900, lr = 0.00324202
I0711 12:55:57.840782 32652 solver.cpp:337] Iteration 35000, Testing net (#0)
I0711 12:55:59.966661 32652 solver.cpp:404]     Test net output #0: loss = 0.00889187 (* 1 = 0.00889187 loss)
I0711 12:55:59.989331 32652 solver.cpp:228] Iteration 35000, loss = 0.0017221
I0711 12:55:59.989352 32652 solver.cpp:244]     Train net output #0: loss = 0.00172208 (* 1 = 0.00172208 loss)
I0711 12:55:59.989368 32652 sgd_solver.cpp:106] Iteration 35000, lr = 0.00323661
I0711 12:56:03.153230 32652 solver.cpp:228] Iteration 35100, loss = 0.000987138
I0711 12:56:03.153276 32652 solver.cpp:244]     Train net output #0: loss = 0.000987121 (* 1 = 0.000987121 loss)
I0711 12:56:03.153287 32652 sgd_solver.cpp:106] Iteration 35100, lr = 0.00323123
I0711 12:56:06.316249 32652 solver.cpp:228] Iteration 35200, loss = 0.00152204
I0711 12:56:06.316295 32652 solver.cpp:244]     Train net output #0: loss = 0.00152202 (* 1 = 0.00152202 loss)
I0711 12:56:06.316308 32652 sgd_solver.cpp:106] Iteration 35200, lr = 0.00322586
I0711 12:56:09.477377 32652 solver.cpp:228] Iteration 35300, loss = 0.00107399
I0711 12:56:09.477423 32652 solver.cpp:244]     Train net output #0: loss = 0.00107398 (* 1 = 0.00107398 loss)
I0711 12:56:09.477433 32652 sgd_solver.cpp:106] Iteration 35300, lr = 0.00322052
I0711 12:56:12.640588 32652 solver.cpp:228] Iteration 35400, loss = 0.000531837
I0711 12:56:12.640633 32652 solver.cpp:244]     Train net output #0: loss = 0.000531821 (* 1 = 0.000531821 loss)
I0711 12:56:12.640645 32652 sgd_solver.cpp:106] Iteration 35400, lr = 0.0032152
I0711 12:56:15.771559 32652 solver.cpp:337] Iteration 35500, Testing net (#0)
I0711 12:56:17.903991 32652 solver.cpp:404]     Test net output #0: loss = 0.00887787 (* 1 = 0.00887787 loss)
I0711 12:56:17.926772 32652 solver.cpp:228] Iteration 35500, loss = 0.000525132
I0711 12:56:17.926802 32652 solver.cpp:244]     Train net output #0: loss = 0.000525116 (* 1 = 0.000525116 loss)
I0711 12:56:17.926820 32652 sgd_solver.cpp:106] Iteration 35500, lr = 0.0032099
I0711 12:56:21.105415 32652 solver.cpp:228] Iteration 35600, loss = 0.00242585
I0711 12:56:21.105461 32652 solver.cpp:244]     Train net output #0: loss = 0.00242584 (* 1 = 0.00242584 loss)
I0711 12:56:21.105473 32652 sgd_solver.cpp:106] Iteration 35600, lr = 0.00320462
I0711 12:56:24.268038 32652 solver.cpp:228] Iteration 35700, loss = 0.000385666
I0711 12:56:24.268088 32652 solver.cpp:244]     Train net output #0: loss = 0.00038565 (* 1 = 0.00038565 loss)
I0711 12:56:24.268102 32652 sgd_solver.cpp:106] Iteration 35700, lr = 0.00319936
I0711 12:56:27.452486 32652 solver.cpp:228] Iteration 35800, loss = 0.00123531
I0711 12:56:27.452540 32652 solver.cpp:244]     Train net output #0: loss = 0.00123529 (* 1 = 0.00123529 loss)
I0711 12:56:27.452550 32652 sgd_solver.cpp:106] Iteration 35800, lr = 0.00319412
I0711 12:56:30.628743 32652 solver.cpp:228] Iteration 35900, loss = 0.00172376
I0711 12:56:30.628790 32652 solver.cpp:244]     Train net output #0: loss = 0.00172375 (* 1 = 0.00172375 loss)
I0711 12:56:30.628800 32652 sgd_solver.cpp:106] Iteration 35900, lr = 0.0031889
I0711 12:56:33.761332 32652 solver.cpp:337] Iteration 36000, Testing net (#0)
I0711 12:56:35.887998 32652 solver.cpp:404]     Test net output #0: loss = 0.00892984 (* 1 = 0.00892984 loss)
I0711 12:56:35.910497 32652 solver.cpp:228] Iteration 36000, loss = 0.000618874
I0711 12:56:35.910517 32652 solver.cpp:244]     Train net output #0: loss = 0.000618858 (* 1 = 0.000618858 loss)
I0711 12:56:35.910531 32652 sgd_solver.cpp:106] Iteration 36000, lr = 0.0031837
I0711 12:56:39.073688 32652 solver.cpp:228] Iteration 36100, loss = 0.00315314
I0711 12:56:39.073741 32652 solver.cpp:244]     Train net output #0: loss = 0.00315312 (* 1 = 0.00315312 loss)
I0711 12:56:39.073751 32652 sgd_solver.cpp:106] Iteration 36100, lr = 0.00317852
I0711 12:56:42.242260 32652 solver.cpp:228] Iteration 36200, loss = 0.00132629
I0711 12:56:42.242306 32652 solver.cpp:244]     Train net output #0: loss = 0.00132627 (* 1 = 0.00132627 loss)
I0711 12:56:42.242324 32652 sgd_solver.cpp:106] Iteration 36200, lr = 0.00317335
I0711 12:56:45.407441 32652 solver.cpp:228] Iteration 36300, loss = 0.0021225
I0711 12:56:45.407485 32652 solver.cpp:244]     Train net output #0: loss = 0.00212248 (* 1 = 0.00212248 loss)
I0711 12:56:45.407502 32652 sgd_solver.cpp:106] Iteration 36300, lr = 0.00316821
I0711 12:56:48.568531 32652 solver.cpp:228] Iteration 36400, loss = 0.00144082
I0711 12:56:48.568650 32652 solver.cpp:244]     Train net output #0: loss = 0.0014408 (* 1 = 0.0014408 loss)
I0711 12:56:48.568665 32652 sgd_solver.cpp:106] Iteration 36400, lr = 0.00316309
I0711 12:56:51.708233 32652 solver.cpp:337] Iteration 36500, Testing net (#0)
I0711 12:56:53.842738 32652 solver.cpp:404]     Test net output #0: loss = 0.00878696 (* 1 = 0.00878696 loss)
I0711 12:56:53.865551 32652 solver.cpp:228] Iteration 36500, loss = 0.000425702
I0711 12:56:53.865576 32652 solver.cpp:244]     Train net output #0: loss = 0.000425687 (* 1 = 0.000425687 loss)
I0711 12:56:53.865589 32652 sgd_solver.cpp:106] Iteration 36500, lr = 0.00315799
I0711 12:56:57.029326 32652 solver.cpp:228] Iteration 36600, loss = 0.00114479
I0711 12:56:57.029373 32652 solver.cpp:244]     Train net output #0: loss = 0.00114478 (* 1 = 0.00114478 loss)
I0711 12:56:57.029386 32652 sgd_solver.cpp:106] Iteration 36600, lr = 0.0031529
I0711 12:57:00.205909 32652 solver.cpp:228] Iteration 36700, loss = 0.00206615
I0711 12:57:00.205961 32652 solver.cpp:244]     Train net output #0: loss = 0.00206613 (* 1 = 0.00206613 loss)
I0711 12:57:00.205972 32652 sgd_solver.cpp:106] Iteration 36700, lr = 0.00314784
I0711 12:57:03.389879 32652 solver.cpp:228] Iteration 36800, loss = 0.00178107
I0711 12:57:03.389932 32652 solver.cpp:244]     Train net output #0: loss = 0.00178105 (* 1 = 0.00178105 loss)
I0711 12:57:03.389942 32652 sgd_solver.cpp:106] Iteration 36800, lr = 0.00314279
I0711 12:57:06.551376 32652 solver.cpp:228] Iteration 36900, loss = 0.00116098
I0711 12:57:06.551422 32652 solver.cpp:244]     Train net output #0: loss = 0.00116097 (* 1 = 0.00116097 loss)
I0711 12:57:06.551434 32652 sgd_solver.cpp:106] Iteration 36900, lr = 0.00313776
I0711 12:57:09.681808 32652 solver.cpp:337] Iteration 37000, Testing net (#0)
I0711 12:57:11.800828 32652 solver.cpp:404]     Test net output #0: loss = 0.00881453 (* 1 = 0.00881453 loss)
I0711 12:57:11.823480 32652 solver.cpp:228] Iteration 37000, loss = 0.000717351
I0711 12:57:11.823508 32652 solver.cpp:244]     Train net output #0: loss = 0.000717336 (* 1 = 0.000717336 loss)
I0711 12:57:11.823521 32652 sgd_solver.cpp:106] Iteration 37000, lr = 0.00313276
I0711 12:57:14.996776 32652 solver.cpp:228] Iteration 37100, loss = 0.00103948
I0711 12:57:14.996829 32652 solver.cpp:244]     Train net output #0: loss = 0.00103946 (* 1 = 0.00103946 loss)
I0711 12:57:14.996840 32652 sgd_solver.cpp:106] Iteration 37100, lr = 0.00312777
I0711 12:57:18.160320 32652 solver.cpp:228] Iteration 37200, loss = 0.00154284
I0711 12:57:18.160365 32652 solver.cpp:244]     Train net output #0: loss = 0.00154283 (* 1 = 0.00154283 loss)
I0711 12:57:18.160377 32652 sgd_solver.cpp:106] Iteration 37200, lr = 0.0031228
I0711 12:57:21.328383 32652 solver.cpp:228] Iteration 37300, loss = 0.00197753
I0711 12:57:21.328534 32652 solver.cpp:244]     Train net output #0: loss = 0.00197752 (* 1 = 0.00197752 loss)
I0711 12:57:21.328546 32652 sgd_solver.cpp:106] Iteration 37300, lr = 0.00311784
I0711 12:57:24.496260 32652 solver.cpp:228] Iteration 37400, loss = 0.00125181
I0711 12:57:24.496305 32652 solver.cpp:244]     Train net output #0: loss = 0.00125179 (* 1 = 0.00125179 loss)
I0711 12:57:24.496316 32652 sgd_solver.cpp:106] Iteration 37400, lr = 0.00311291
I0711 12:57:27.635422 32652 solver.cpp:337] Iteration 37500, Testing net (#0)
I0711 12:57:29.761740 32652 solver.cpp:404]     Test net output #0: loss = 0.00867979 (* 1 = 0.00867979 loss)
I0711 12:57:29.785075 32652 solver.cpp:228] Iteration 37500, loss = 0.0013285
I0711 12:57:29.785109 32652 solver.cpp:244]     Train net output #0: loss = 0.00132849 (* 1 = 0.00132849 loss)
I0711 12:57:29.785122 32652 sgd_solver.cpp:106] Iteration 37500, lr = 0.00310799
I0711 12:57:32.948611 32652 solver.cpp:228] Iteration 37600, loss = 0.000929885
I0711 12:57:32.948663 32652 solver.cpp:244]     Train net output #0: loss = 0.00092987 (* 1 = 0.00092987 loss)
I0711 12:57:32.948673 32652 sgd_solver.cpp:106] Iteration 37600, lr = 0.00310309
I0711 12:57:36.120815 32652 solver.cpp:228] Iteration 37700, loss = 0.000934053
I0711 12:57:36.120868 32652 solver.cpp:244]     Train net output #0: loss = 0.000934038 (* 1 = 0.000934038 loss)
I0711 12:57:36.120878 32652 sgd_solver.cpp:106] Iteration 37700, lr = 0.00309821
I0711 12:57:39.286586 32652 solver.cpp:228] Iteration 37800, loss = 0.00113564
I0711 12:57:39.286633 32652 solver.cpp:244]     Train net output #0: loss = 0.00113562 (* 1 = 0.00113562 loss)
I0711 12:57:39.286643 32652 sgd_solver.cpp:106] Iteration 37800, lr = 0.00309335
I0711 12:57:42.446406 32652 solver.cpp:228] Iteration 37900, loss = 0.00306179
I0711 12:57:42.446458 32652 solver.cpp:244]     Train net output #0: loss = 0.00306177 (* 1 = 0.00306177 loss)
I0711 12:57:42.446468 32652 sgd_solver.cpp:106] Iteration 37900, lr = 0.00308851
I0711 12:57:45.575176 32652 solver.cpp:337] Iteration 38000, Testing net (#0)
I0711 12:57:47.690179 32652 solver.cpp:404]     Test net output #0: loss = 0.00887299 (* 1 = 0.00887299 loss)
I0711 12:57:47.712998 32652 solver.cpp:228] Iteration 38000, loss = 0.000655331
I0711 12:57:47.713033 32652 solver.cpp:244]     Train net output #0: loss = 0.000655317 (* 1 = 0.000655317 loss)
I0711 12:57:47.713047 32652 sgd_solver.cpp:106] Iteration 38000, lr = 0.00308368
I0711 12:57:50.873502 32652 solver.cpp:228] Iteration 38100, loss = 0.000107053
I0711 12:57:50.873548 32652 solver.cpp:244]     Train net output #0: loss = 0.000107038 (* 1 = 0.000107038 loss)
I0711 12:57:50.873559 32652 sgd_solver.cpp:106] Iteration 38100, lr = 0.00307887
I0711 12:57:54.035751 32652 solver.cpp:228] Iteration 38200, loss = 0.00117201
I0711 12:57:54.035966 32652 solver.cpp:244]     Train net output #0: loss = 0.001172 (* 1 = 0.001172 loss)
I0711 12:57:54.035979 32652 sgd_solver.cpp:106] Iteration 38200, lr = 0.00307408
I0711 12:57:57.195884 32652 solver.cpp:228] Iteration 38300, loss = 0.000452593
I0711 12:57:57.195936 32652 solver.cpp:244]     Train net output #0: loss = 0.000452579 (* 1 = 0.000452579 loss)
I0711 12:57:57.195946 32652 sgd_solver.cpp:106] Iteration 38300, lr = 0.0030693
I0711 12:58:00.360205 32652 solver.cpp:228] Iteration 38400, loss = 0.000705287
I0711 12:58:00.360258 32652 solver.cpp:244]     Train net output #0: loss = 0.000705272 (* 1 = 0.000705272 loss)
I0711 12:58:00.360268 32652 sgd_solver.cpp:106] Iteration 38400, lr = 0.00306454
I0711 12:58:03.490895 32652 solver.cpp:337] Iteration 38500, Testing net (#0)
I0711 12:58:05.611238 32652 solver.cpp:404]     Test net output #0: loss = 0.00881787 (* 1 = 0.00881787 loss)
I0711 12:58:05.634150 32652 solver.cpp:228] Iteration 38500, loss = 0.00200133
I0711 12:58:05.634172 32652 solver.cpp:244]     Train net output #0: loss = 0.00200131 (* 1 = 0.00200131 loss)
I0711 12:58:05.634186 32652 sgd_solver.cpp:106] Iteration 38500, lr = 0.0030598
I0711 12:58:08.795215 32652 solver.cpp:228] Iteration 38600, loss = 0.00232576
I0711 12:58:08.795256 32652 solver.cpp:244]     Train net output #0: loss = 0.00232574 (* 1 = 0.00232574 loss)
I0711 12:58:08.795267 32652 sgd_solver.cpp:106] Iteration 38600, lr = 0.00305508
I0711 12:58:11.953985 32652 solver.cpp:228] Iteration 38700, loss = 0.00436446
I0711 12:58:11.954030 32652 solver.cpp:244]     Train net output #0: loss = 0.00436444 (* 1 = 0.00436444 loss)
I0711 12:58:11.954040 32652 sgd_solver.cpp:106] Iteration 38700, lr = 0.00305038
I0711 12:58:15.115603 32652 solver.cpp:228] Iteration 38800, loss = 0.00137049
I0711 12:58:15.115649 32652 solver.cpp:244]     Train net output #0: loss = 0.00137048 (* 1 = 0.00137048 loss)
I0711 12:58:15.115660 32652 sgd_solver.cpp:106] Iteration 38800, lr = 0.00304569
I0711 12:58:18.278961 32652 solver.cpp:228] Iteration 38900, loss = 0.000541096
I0711 12:58:18.279008 32652 solver.cpp:244]     Train net output #0: loss = 0.000541081 (* 1 = 0.000541081 loss)
I0711 12:58:18.279019 32652 sgd_solver.cpp:106] Iteration 38900, lr = 0.00304101
I0711 12:58:21.419937 32652 solver.cpp:337] Iteration 39000, Testing net (#0)
I0711 12:58:23.534458 32652 solver.cpp:404]     Test net output #0: loss = 0.00890837 (* 1 = 0.00890837 loss)
I0711 12:58:23.557270 32652 solver.cpp:228] Iteration 39000, loss = 0.00229997
I0711 12:58:23.557308 32652 solver.cpp:244]     Train net output #0: loss = 0.00229996 (* 1 = 0.00229996 loss)
I0711 12:58:23.557319 32652 sgd_solver.cpp:106] Iteration 39000, lr = 0.00303636
I0711 12:58:26.726995 32652 solver.cpp:228] Iteration 39100, loss = 0.00130181
I0711 12:58:26.727179 32652 solver.cpp:244]     Train net output #0: loss = 0.0013018 (* 1 = 0.0013018 loss)
I0711 12:58:26.727188 32652 sgd_solver.cpp:106] Iteration 39100, lr = 0.00303172
I0711 12:58:29.907537 32652 solver.cpp:228] Iteration 39200, loss = 0.000244349
I0711 12:58:29.907584 32652 solver.cpp:244]     Train net output #0: loss = 0.000244335 (* 1 = 0.000244335 loss)
I0711 12:58:29.907595 32652 sgd_solver.cpp:106] Iteration 39200, lr = 0.0030271
I0711 12:58:33.076016 32652 solver.cpp:228] Iteration 39300, loss = 0.00081592
I0711 12:58:33.076064 32652 solver.cpp:244]     Train net output #0: loss = 0.000815906 (* 1 = 0.000815906 loss)
I0711 12:58:33.076074 32652 sgd_solver.cpp:106] Iteration 39300, lr = 0.00302249
I0711 12:58:36.237606 32652 solver.cpp:228] Iteration 39400, loss = 0.000879848
I0711 12:58:36.237651 32652 solver.cpp:244]     Train net output #0: loss = 0.000879834 (* 1 = 0.000879834 loss)
I0711 12:58:36.237661 32652 sgd_solver.cpp:106] Iteration 39400, lr = 0.0030179
I0711 12:58:39.376004 32652 solver.cpp:337] Iteration 39500, Testing net (#0)
I0711 12:58:41.506180 32652 solver.cpp:404]     Test net output #0: loss = 0.00880682 (* 1 = 0.00880682 loss)
I0711 12:58:41.529228 32652 solver.cpp:228] Iteration 39500, loss = 0.000609213
I0711 12:58:41.529268 32652 solver.cpp:244]     Train net output #0: loss = 0.0006092 (* 1 = 0.0006092 loss)
I0711 12:58:41.529294 32652 sgd_solver.cpp:106] Iteration 39500, lr = 0.00301333
I0711 12:58:44.713512 32652 solver.cpp:228] Iteration 39600, loss = 0.00192135
I0711 12:58:44.713558 32652 solver.cpp:244]     Train net output #0: loss = 0.00192134 (* 1 = 0.00192134 loss)
I0711 12:58:44.713568 32652 sgd_solver.cpp:106] Iteration 39600, lr = 0.00300877
I0711 12:58:47.875514 32652 solver.cpp:228] Iteration 39700, loss = 0.0016738
I0711 12:58:47.875566 32652 solver.cpp:244]     Train net output #0: loss = 0.00167378 (* 1 = 0.00167378 loss)
I0711 12:58:47.875577 32652 sgd_solver.cpp:106] Iteration 39700, lr = 0.00300423
I0711 12:58:51.054945 32652 solver.cpp:228] Iteration 39800, loss = 0.00105365
I0711 12:58:51.054992 32652 solver.cpp:244]     Train net output #0: loss = 0.00105364 (* 1 = 0.00105364 loss)
I0711 12:58:51.055002 32652 sgd_solver.cpp:106] Iteration 39800, lr = 0.0029997
I0711 12:58:54.216908 32652 solver.cpp:228] Iteration 39900, loss = 0.00216121
I0711 12:58:54.216955 32652 solver.cpp:244]     Train net output #0: loss = 0.00216119 (* 1 = 0.00216119 loss)
I0711 12:58:54.216966 32652 sgd_solver.cpp:106] Iteration 39900, lr = 0.00299519
I0711 12:58:57.347098 32652 solver.cpp:337] Iteration 40000, Testing net (#0)
I0711 12:58:59.461467 32652 solver.cpp:404]     Test net output #0: loss = 0.00880975 (* 1 = 0.00880975 loss)
I0711 12:58:59.484040 32652 solver.cpp:228] Iteration 40000, loss = 0.000638062
I0711 12:58:59.484071 32652 solver.cpp:244]     Train net output #0: loss = 0.000638048 (* 1 = 0.000638048 loss)
I0711 12:58:59.484084 32652 sgd_solver.cpp:106] Iteration 40000, lr = 0.0029907
I0711 12:59:02.646446 32652 solver.cpp:228] Iteration 40100, loss = 0.00180011
I0711 12:59:02.646492 32652 solver.cpp:244]     Train net output #0: loss = 0.0018001 (* 1 = 0.0018001 loss)
I0711 12:59:02.646502 32652 sgd_solver.cpp:106] Iteration 40100, lr = 0.00298622
I0711 12:59:05.807551 32652 solver.cpp:228] Iteration 40200, loss = 0.00201644
I0711 12:59:05.807598 32652 solver.cpp:244]     Train net output #0: loss = 0.00201643 (* 1 = 0.00201643 loss)
I0711 12:59:05.807610 32652 sgd_solver.cpp:106] Iteration 40200, lr = 0.00298176
I0711 12:59:08.967221 32652 solver.cpp:228] Iteration 40300, loss = 0.00121324
I0711 12:59:08.967273 32652 solver.cpp:244]     Train net output #0: loss = 0.00121323 (* 1 = 0.00121323 loss)
I0711 12:59:08.967283 32652 sgd_solver.cpp:106] Iteration 40300, lr = 0.00297731
I0711 12:59:12.141862 32652 solver.cpp:228] Iteration 40400, loss = 0.00194486
I0711 12:59:12.141908 32652 solver.cpp:244]     Train net output #0: loss = 0.00194485 (* 1 = 0.00194485 loss)
I0711 12:59:12.141921 32652 sgd_solver.cpp:106] Iteration 40400, lr = 0.00297288
I0711 12:59:15.293964 32652 solver.cpp:337] Iteration 40500, Testing net (#0)
I0711 12:59:17.429761 32652 solver.cpp:404]     Test net output #0: loss = 0.00889882 (* 1 = 0.00889882 loss)
I0711 12:59:17.452312 32652 solver.cpp:228] Iteration 40500, loss = 0.000858482
I0711 12:59:17.452352 32652 solver.cpp:244]     Train net output #0: loss = 0.000858469 (* 1 = 0.000858469 loss)
I0711 12:59:17.452363 32652 sgd_solver.cpp:106] Iteration 40500, lr = 0.00296846
I0711 12:59:20.631454 32652 solver.cpp:228] Iteration 40600, loss = 0.0010256
I0711 12:59:20.631499 32652 solver.cpp:244]     Train net output #0: loss = 0.00102559 (* 1 = 0.00102559 loss)
I0711 12:59:20.631521 32652 sgd_solver.cpp:106] Iteration 40600, lr = 0.00296406
I0711 12:59:23.799168 32652 solver.cpp:228] Iteration 40700, loss = 0.00160158
I0711 12:59:23.799228 32652 solver.cpp:244]     Train net output #0: loss = 0.00160157 (* 1 = 0.00160157 loss)
I0711 12:59:23.799238 32652 sgd_solver.cpp:106] Iteration 40700, lr = 0.00295968
I0711 12:59:26.968137 32652 solver.cpp:228] Iteration 40800, loss = 0.00104728
I0711 12:59:26.968183 32652 solver.cpp:244]     Train net output #0: loss = 0.00104727 (* 1 = 0.00104727 loss)
I0711 12:59:26.968194 32652 sgd_solver.cpp:106] Iteration 40800, lr = 0.0029553
I0711 12:59:30.130498 32652 solver.cpp:228] Iteration 40900, loss = 0.00099842
I0711 12:59:30.131762 32652 solver.cpp:244]     Train net output #0: loss = 0.000998408 (* 1 = 0.000998408 loss)
I0711 12:59:30.131775 32652 sgd_solver.cpp:106] Iteration 40900, lr = 0.00295095
I0711 12:59:33.271334 32652 solver.cpp:337] Iteration 41000, Testing net (#0)
I0711 12:59:35.405241 32652 solver.cpp:404]     Test net output #0: loss = 0.00887434 (* 1 = 0.00887434 loss)
I0711 12:59:35.428050 32652 solver.cpp:228] Iteration 41000, loss = 0.00136632
I0711 12:59:35.428088 32652 solver.cpp:244]     Train net output #0: loss = 0.00136631 (* 1 = 0.00136631 loss)
I0711 12:59:35.428100 32652 sgd_solver.cpp:106] Iteration 41000, lr = 0.00294661
I0711 12:59:38.597738 32652 solver.cpp:228] Iteration 41100, loss = 0.000736244
I0711 12:59:38.597790 32652 solver.cpp:244]     Train net output #0: loss = 0.000736233 (* 1 = 0.000736233 loss)
I0711 12:59:38.597800 32652 sgd_solver.cpp:106] Iteration 41100, lr = 0.00294228
I0711 12:59:41.765357 32652 solver.cpp:228] Iteration 41200, loss = 0.000569311
I0711 12:59:41.765411 32652 solver.cpp:244]     Train net output #0: loss = 0.000569299 (* 1 = 0.000569299 loss)
I0711 12:59:41.765421 32652 sgd_solver.cpp:106] Iteration 41200, lr = 0.00293797
I0711 12:59:44.926898 32652 solver.cpp:228] Iteration 41300, loss = 0.000823096
I0711 12:59:44.926944 32652 solver.cpp:244]     Train net output #0: loss = 0.000823084 (* 1 = 0.000823084 loss)
I0711 12:59:44.926955 32652 sgd_solver.cpp:106] Iteration 41300, lr = 0.00293367
I0711 12:59:48.088222 32652 solver.cpp:228] Iteration 41400, loss = 0.00118043
I0711 12:59:48.088268 32652 solver.cpp:244]     Train net output #0: loss = 0.00118041 (* 1 = 0.00118041 loss)
I0711 12:59:48.088279 32652 sgd_solver.cpp:106] Iteration 41400, lr = 0.00292939
I0711 12:59:51.216729 32652 solver.cpp:337] Iteration 41500, Testing net (#0)
I0711 12:59:53.340967 32652 solver.cpp:404]     Test net output #0: loss = 0.00873923 (* 1 = 0.00873923 loss)
I0711 12:59:53.363626 32652 solver.cpp:228] Iteration 41500, loss = 0.000316405
I0711 12:59:53.363662 32652 solver.cpp:244]     Train net output #0: loss = 0.000316392 (* 1 = 0.000316392 loss)
I0711 12:59:53.363674 32652 sgd_solver.cpp:106] Iteration 41500, lr = 0.00292513
I0711 12:59:56.545598 32652 solver.cpp:228] Iteration 41600, loss = 0.00121092
I0711 12:59:56.545641 32652 solver.cpp:244]     Train net output #0: loss = 0.00121091 (* 1 = 0.00121091 loss)
I0711 12:59:56.545652 32652 sgd_solver.cpp:106] Iteration 41600, lr = 0.00292087
I0711 12:59:59.722796 32652 solver.cpp:228] Iteration 41700, loss = 0.000719014
I0711 12:59:59.722839 32652 solver.cpp:244]     Train net output #0: loss = 0.000719002 (* 1 = 0.000719002 loss)
I0711 12:59:59.722856 32652 sgd_solver.cpp:106] Iteration 41700, lr = 0.00291664
I0711 13:00:02.885570 32652 solver.cpp:228] Iteration 41800, loss = 0.00185612
I0711 13:00:02.885669 32652 solver.cpp:244]     Train net output #0: loss = 0.0018561 (* 1 = 0.0018561 loss)
I0711 13:00:02.885682 32652 sgd_solver.cpp:106] Iteration 41800, lr = 0.00291241
I0711 13:00:06.046397 32652 solver.cpp:228] Iteration 41900, loss = 0.00102608
I0711 13:00:06.046442 32652 solver.cpp:244]     Train net output #0: loss = 0.00102607 (* 1 = 0.00102607 loss)
I0711 13:00:06.046459 32652 sgd_solver.cpp:106] Iteration 41900, lr = 0.0029082
I0711 13:00:09.175380 32652 solver.cpp:337] Iteration 42000, Testing net (#0)
I0711 13:00:11.309227 32652 solver.cpp:404]     Test net output #0: loss = 0.00870629 (* 1 = 0.00870629 loss)
I0711 13:00:11.331909 32652 solver.cpp:228] Iteration 42000, loss = 0.00123154
I0711 13:00:11.331950 32652 solver.cpp:244]     Train net output #0: loss = 0.00123152 (* 1 = 0.00123152 loss)
I0711 13:00:11.331962 32652 sgd_solver.cpp:106] Iteration 42000, lr = 0.00290401
I0711 13:00:14.514744 32652 solver.cpp:228] Iteration 42100, loss = 0.00219226
I0711 13:00:14.514787 32652 solver.cpp:244]     Train net output #0: loss = 0.00219224 (* 1 = 0.00219224 loss)
I0711 13:00:14.514806 32652 sgd_solver.cpp:106] Iteration 42100, lr = 0.00289982
I0711 13:00:17.678942 32652 solver.cpp:228] Iteration 42200, loss = 0.000810541
I0711 13:00:17.678987 32652 solver.cpp:244]     Train net output #0: loss = 0.000810528 (* 1 = 0.000810528 loss)
I0711 13:00:17.679003 32652 sgd_solver.cpp:106] Iteration 42200, lr = 0.00289566
I0711 13:00:20.837579 32652 solver.cpp:228] Iteration 42300, loss = 0.000781492
I0711 13:00:20.837626 32652 solver.cpp:244]     Train net output #0: loss = 0.000781479 (* 1 = 0.000781479 loss)
I0711 13:00:20.837637 32652 sgd_solver.cpp:106] Iteration 42300, lr = 0.0028915
I0711 13:00:24.007616 32652 solver.cpp:228] Iteration 42400, loss = 0.000409414
I0711 13:00:24.007663 32652 solver.cpp:244]     Train net output #0: loss = 0.000409401 (* 1 = 0.000409401 loss)
I0711 13:00:24.007685 32652 sgd_solver.cpp:106] Iteration 42400, lr = 0.00288736
I0711 13:00:27.152541 32652 solver.cpp:337] Iteration 42500, Testing net (#0)
I0711 13:00:29.273437 32652 solver.cpp:404]     Test net output #0: loss = 0.00887718 (* 1 = 0.00887718 loss)
I0711 13:00:29.296337 32652 solver.cpp:228] Iteration 42500, loss = 0.00137623
I0711 13:00:29.296372 32652 solver.cpp:244]     Train net output #0: loss = 0.00137621 (* 1 = 0.00137621 loss)
I0711 13:00:29.296397 32652 sgd_solver.cpp:106] Iteration 42500, lr = 0.00288324
I0711 13:00:32.470089 32652 solver.cpp:228] Iteration 42600, loss = 0.000855378
I0711 13:00:32.470134 32652 solver.cpp:244]     Train net output #0: loss = 0.000855365 (* 1 = 0.000855365 loss)
I0711 13:00:32.470151 32652 sgd_solver.cpp:106] Iteration 42600, lr = 0.00287913
I0711 13:00:35.637949 32652 solver.cpp:228] Iteration 42700, loss = 0.00132454
I0711 13:00:35.638162 32652 solver.cpp:244]     Train net output #0: loss = 0.00132453 (* 1 = 0.00132453 loss)
I0711 13:00:35.638173 32652 sgd_solver.cpp:106] Iteration 42700, lr = 0.00287503
I0711 13:00:38.803819 32652 solver.cpp:228] Iteration 42800, loss = 0.000909621
I0711 13:00:38.803874 32652 solver.cpp:244]     Train net output #0: loss = 0.000909608 (* 1 = 0.000909608 loss)
I0711 13:00:38.803884 32652 sgd_solver.cpp:106] Iteration 42800, lr = 0.00287094
I0711 13:00:41.968464 32652 solver.cpp:228] Iteration 42900, loss = 0.000395053
I0711 13:00:41.968508 32652 solver.cpp:244]     Train net output #0: loss = 0.000395041 (* 1 = 0.000395041 loss)
I0711 13:00:41.968524 32652 sgd_solver.cpp:106] Iteration 42900, lr = 0.00286687
I0711 13:00:45.112684 32652 solver.cpp:337] Iteration 43000, Testing net (#0)
I0711 13:00:47.237128 32652 solver.cpp:404]     Test net output #0: loss = 0.00891418 (* 1 = 0.00891418 loss)
I0711 13:00:47.259969 32652 solver.cpp:228] Iteration 43000, loss = 0.000447797
I0711 13:00:47.260000 32652 solver.cpp:244]     Train net output #0: loss = 0.000447784 (* 1 = 0.000447784 loss)
I0711 13:00:47.260011 32652 sgd_solver.cpp:106] Iteration 43000, lr = 0.00286281
I0711 13:00:50.439062 32652 solver.cpp:228] Iteration 43100, loss = 0.0019054
I0711 13:00:50.439116 32652 solver.cpp:244]     Train net output #0: loss = 0.00190539 (* 1 = 0.00190539 loss)
I0711 13:00:50.439126 32652 sgd_solver.cpp:106] Iteration 43100, lr = 0.00285877
I0711 13:00:53.602104 32652 solver.cpp:228] Iteration 43200, loss = 0.00030657
I0711 13:00:53.602149 32652 solver.cpp:244]     Train net output #0: loss = 0.000306558 (* 1 = 0.000306558 loss)
I0711 13:00:53.602165 32652 sgd_solver.cpp:106] Iteration 43200, lr = 0.00285474
I0711 13:00:56.763361 32652 solver.cpp:228] Iteration 43300, loss = 0.0010607
I0711 13:00:56.763406 32652 solver.cpp:244]     Train net output #0: loss = 0.00106069 (* 1 = 0.00106069 loss)
I0711 13:00:56.763420 32652 sgd_solver.cpp:106] Iteration 43300, lr = 0.00285072
I0711 13:00:59.923789 32652 solver.cpp:228] Iteration 43400, loss = 0.00141503
I0711 13:00:59.923835 32652 solver.cpp:244]     Train net output #0: loss = 0.00141501 (* 1 = 0.00141501 loss)
I0711 13:00:59.923846 32652 sgd_solver.cpp:106] Iteration 43400, lr = 0.00284672
I0711 13:01:03.056955 32652 solver.cpp:337] Iteration 43500, Testing net (#0)
I0711 13:01:05.184512 32652 solver.cpp:404]     Test net output #0: loss = 0.00891973 (* 1 = 0.00891973 loss)
I0711 13:01:05.207056 32652 solver.cpp:228] Iteration 43500, loss = 0.000473276
I0711 13:01:05.207078 32652 solver.cpp:244]     Train net output #0: loss = 0.000473263 (* 1 = 0.000473263 loss)
I0711 13:01:05.207092 32652 sgd_solver.cpp:106] Iteration 43500, lr = 0.00284272
I0711 13:01:08.367148 32652 solver.cpp:228] Iteration 43600, loss = 0.00232816
I0711 13:01:08.367388 32652 solver.cpp:244]     Train net output #0: loss = 0.00232815 (* 1 = 0.00232815 loss)
I0711 13:01:08.367398 32652 sgd_solver.cpp:106] Iteration 43600, lr = 0.00283875
I0711 13:01:11.528489 32652 solver.cpp:228] Iteration 43700, loss = 0.00109343
I0711 13:01:11.528535 32652 solver.cpp:244]     Train net output #0: loss = 0.00109342 (* 1 = 0.00109342 loss)
I0711 13:01:11.528547 32652 sgd_solver.cpp:106] Iteration 43700, lr = 0.00283478
I0711 13:01:14.689045 32652 solver.cpp:228] Iteration 43800, loss = 0.00160845
I0711 13:01:14.689090 32652 solver.cpp:244]     Train net output #0: loss = 0.00160844 (* 1 = 0.00160844 loss)
I0711 13:01:14.689101 32652 sgd_solver.cpp:106] Iteration 43800, lr = 0.00283083
I0711 13:01:17.848176 32652 solver.cpp:228] Iteration 43900, loss = 0.00113277
I0711 13:01:17.848222 32652 solver.cpp:244]     Train net output #0: loss = 0.00113276 (* 1 = 0.00113276 loss)
I0711 13:01:17.848233 32652 sgd_solver.cpp:106] Iteration 43900, lr = 0.00282689
I0711 13:01:20.976721 32652 solver.cpp:337] Iteration 44000, Testing net (#0)
I0711 13:01:23.099257 32652 solver.cpp:404]     Test net output #0: loss = 0.00879783 (* 1 = 0.00879783 loss)
I0711 13:01:23.122047 32652 solver.cpp:228] Iteration 44000, loss = 0.000373658
I0711 13:01:23.122076 32652 solver.cpp:244]     Train net output #0: loss = 0.000373646 (* 1 = 0.000373646 loss)
I0711 13:01:23.122095 32652 sgd_solver.cpp:106] Iteration 44000, lr = 0.00282296
I0711 13:01:26.293491 32652 solver.cpp:228] Iteration 44100, loss = 0.00104767
I0711 13:01:26.293540 32652 solver.cpp:244]     Train net output #0: loss = 0.00104766 (* 1 = 0.00104766 loss)
I0711 13:01:26.293555 32652 sgd_solver.cpp:106] Iteration 44100, lr = 0.00281905
I0711 13:01:29.456042 32652 solver.cpp:228] Iteration 44200, loss = 0.00180559
I0711 13:01:29.456087 32652 solver.cpp:244]     Train net output #0: loss = 0.00180558 (* 1 = 0.00180558 loss)
I0711 13:01:29.456099 32652 sgd_solver.cpp:106] Iteration 44200, lr = 0.00281514
I0711 13:01:32.623687 32652 solver.cpp:228] Iteration 44300, loss = 0.00150817
I0711 13:01:32.623740 32652 solver.cpp:244]     Train net output #0: loss = 0.00150816 (* 1 = 0.00150816 loss)
I0711 13:01:32.623750 32652 sgd_solver.cpp:106] Iteration 44300, lr = 0.00281125
I0711 13:01:35.804324 32652 solver.cpp:228] Iteration 44400, loss = 0.000878098
I0711 13:01:35.804368 32652 solver.cpp:244]     Train net output #0: loss = 0.000878085 (* 1 = 0.000878085 loss)
I0711 13:01:35.804378 32652 sgd_solver.cpp:106] Iteration 44400, lr = 0.00280738
I0711 13:01:38.953963 32652 solver.cpp:337] Iteration 44500, Testing net (#0)
I0711 13:01:41.091466 32652 solver.cpp:404]     Test net output #0: loss = 0.00881655 (* 1 = 0.00881655 loss)
I0711 13:01:41.114652 32652 solver.cpp:228] Iteration 44500, loss = 0.000571823
I0711 13:01:41.114693 32652 solver.cpp:244]     Train net output #0: loss = 0.00057181 (* 1 = 0.00057181 loss)
I0711 13:01:41.114706 32652 sgd_solver.cpp:106] Iteration 44500, lr = 0.00280351
I0711 13:01:44.291463 32652 solver.cpp:228] Iteration 44600, loss = 0.000832697
I0711 13:01:44.291508 32652 solver.cpp:244]     Train net output #0: loss = 0.000832683 (* 1 = 0.000832683 loss)
I0711 13:01:44.291522 32652 sgd_solver.cpp:106] Iteration 44600, lr = 0.00279966
I0711 13:01:47.472196 32652 solver.cpp:228] Iteration 44700, loss = 0.00131011
I0711 13:01:47.472249 32652 solver.cpp:244]     Train net output #0: loss = 0.00131009 (* 1 = 0.00131009 loss)
I0711 13:01:47.472259 32652 sgd_solver.cpp:106] Iteration 44700, lr = 0.00279582
I0711 13:01:50.647565 32652 solver.cpp:228] Iteration 44800, loss = 0.00164551
I0711 13:01:50.647617 32652 solver.cpp:244]     Train net output #0: loss = 0.0016455 (* 1 = 0.0016455 loss)
I0711 13:01:50.647627 32652 sgd_solver.cpp:106] Iteration 44800, lr = 0.00279199
I0711 13:01:53.813863 32652 solver.cpp:228] Iteration 44900, loss = 0.000985143
I0711 13:01:53.813915 32652 solver.cpp:244]     Train net output #0: loss = 0.00098513 (* 1 = 0.00098513 loss)
I0711 13:01:53.813925 32652 sgd_solver.cpp:106] Iteration 44900, lr = 0.00278818
I0711 13:01:56.948606 32652 solver.cpp:337] Iteration 45000, Testing net (#0)
I0711 13:01:59.076036 32652 solver.cpp:404]     Test net output #0: loss = 0.0087122 (* 1 = 0.0087122 loss)
I0711 13:01:59.098532 32652 solver.cpp:228] Iteration 45000, loss = 0.00110624
I0711 13:01:59.098562 32652 solver.cpp:244]     Train net output #0: loss = 0.00110623 (* 1 = 0.00110623 loss)
I0711 13:01:59.098587 32652 sgd_solver.cpp:106] Iteration 45000, lr = 0.00278438
I0711 13:02:02.268472 32652 solver.cpp:228] Iteration 45100, loss = 0.000779489
I0711 13:02:02.268518 32652 solver.cpp:244]     Train net output #0: loss = 0.000779475 (* 1 = 0.000779475 loss)
I0711 13:02:02.268532 32652 sgd_solver.cpp:106] Iteration 45100, lr = 0.00278059
I0711 13:02:05.431977 32652 solver.cpp:228] Iteration 45200, loss = 0.000819031
I0711 13:02:05.432023 32652 solver.cpp:244]     Train net output #0: loss = 0.000819017 (* 1 = 0.000819017 loss)
I0711 13:02:05.432034 32652 sgd_solver.cpp:106] Iteration 45200, lr = 0.00277681
I0711 13:02:08.591673 32652 solver.cpp:228] Iteration 45300, loss = 0.00093854
I0711 13:02:08.591716 32652 solver.cpp:244]     Train net output #0: loss = 0.000938526 (* 1 = 0.000938526 loss)
I0711 13:02:08.591727 32652 sgd_solver.cpp:106] Iteration 45300, lr = 0.00277304
I0711 13:02:11.750885 32652 solver.cpp:228] Iteration 45400, loss = 0.00248334
I0711 13:02:11.751034 32652 solver.cpp:244]     Train net output #0: loss = 0.00248333 (* 1 = 0.00248333 loss)
I0711 13:02:11.751044 32652 sgd_solver.cpp:106] Iteration 45400, lr = 0.00276929
I0711 13:02:14.880803 32652 solver.cpp:337] Iteration 45500, Testing net (#0)
I0711 13:02:17.015183 32652 solver.cpp:404]     Test net output #0: loss = 0.00888147 (* 1 = 0.00888147 loss)
I0711 13:02:17.038050 32652 solver.cpp:228] Iteration 45500, loss = 0.000505866
I0711 13:02:17.038079 32652 solver.cpp:244]     Train net output #0: loss = 0.000505852 (* 1 = 0.000505852 loss)
I0711 13:02:17.038094 32652 sgd_solver.cpp:106] Iteration 45500, lr = 0.00276554
I0711 13:02:20.198843 32652 solver.cpp:228] Iteration 45600, loss = 0.000115619
I0711 13:02:20.198886 32652 solver.cpp:244]     Train net output #0: loss = 0.000115605 (* 1 = 0.000115605 loss)
I0711 13:02:20.198896 32652 sgd_solver.cpp:106] Iteration 45600, lr = 0.00276181
I0711 13:02:23.361713 32652 solver.cpp:228] Iteration 45700, loss = 0.000891544
I0711 13:02:23.361766 32652 solver.cpp:244]     Train net output #0: loss = 0.00089153 (* 1 = 0.00089153 loss)
I0711 13:02:23.361776 32652 sgd_solver.cpp:106] Iteration 45700, lr = 0.00275809
I0711 13:02:26.543756 32652 solver.cpp:228] Iteration 45800, loss = 0.000341236
I0711 13:02:26.543803 32652 solver.cpp:244]     Train net output #0: loss = 0.000341222 (* 1 = 0.000341222 loss)
I0711 13:02:26.543813 32652 sgd_solver.cpp:106] Iteration 45800, lr = 0.00275438
I0711 13:02:29.712119 32652 solver.cpp:228] Iteration 45900, loss = 0.000634995
I0711 13:02:29.712172 32652 solver.cpp:244]     Train net output #0: loss = 0.000634981 (* 1 = 0.000634981 loss)
I0711 13:02:29.712182 32652 sgd_solver.cpp:106] Iteration 45900, lr = 0.00275069
I0711 13:02:32.862251 32652 solver.cpp:337] Iteration 46000, Testing net (#0)
I0711 13:02:34.993511 32652 solver.cpp:404]     Test net output #0: loss = 0.00884804 (* 1 = 0.00884804 loss)
I0711 13:02:35.016402 32652 solver.cpp:228] Iteration 46000, loss = 0.00162137
I0711 13:02:35.016438 32652 solver.cpp:244]     Train net output #0: loss = 0.00162135 (* 1 = 0.00162135 loss)
I0711 13:02:35.016450 32652 sgd_solver.cpp:106] Iteration 46000, lr = 0.002747
I0711 13:02:38.182929 32652 solver.cpp:228] Iteration 46100, loss = 0.00192435
I0711 13:02:38.182973 32652 solver.cpp:244]     Train net output #0: loss = 0.00192434 (* 1 = 0.00192434 loss)
I0711 13:02:38.182996 32652 sgd_solver.cpp:106] Iteration 46100, lr = 0.00274333
I0711 13:02:41.347323 32652 solver.cpp:228] Iteration 46200, loss = 0.00336897
I0711 13:02:41.347369 32652 solver.cpp:244]     Train net output #0: loss = 0.00336895 (* 1 = 0.00336895 loss)
I0711 13:02:41.347380 32652 sgd_solver.cpp:106] Iteration 46200, lr = 0.00273967
I0711 13:02:44.508882 32652 solver.cpp:228] Iteration 46300, loss = 0.00112094
I0711 13:02:44.509014 32652 solver.cpp:244]     Train net output #0: loss = 0.00112093 (* 1 = 0.00112093 loss)
I0711 13:02:44.509027 32652 sgd_solver.cpp:106] Iteration 46300, lr = 0.00273602
I0711 13:02:47.670474 32652 solver.cpp:228] Iteration 46400, loss = 0.00051822
I0711 13:02:47.670521 32652 solver.cpp:244]     Train net output #0: loss = 0.000518207 (* 1 = 0.000518207 loss)
I0711 13:02:47.670531 32652 sgd_solver.cpp:106] Iteration 46400, lr = 0.00273238
I0711 13:02:50.799176 32652 solver.cpp:337] Iteration 46500, Testing net (#0)
I0711 13:02:52.926939 32652 solver.cpp:404]     Test net output #0: loss = 0.00890613 (* 1 = 0.00890613 loss)
I0711 13:02:52.949509 32652 solver.cpp:228] Iteration 46500, loss = 0.0019394
I0711 13:02:52.949535 32652 solver.cpp:244]     Train net output #0: loss = 0.00193939 (* 1 = 0.00193939 loss)
I0711 13:02:52.949549 32652 sgd_solver.cpp:106] Iteration 46500, lr = 0.00272875
I0711 13:02:56.110934 32652 solver.cpp:228] Iteration 46600, loss = 0.00113643
I0711 13:02:56.110980 32652 solver.cpp:244]     Train net output #0: loss = 0.00113642 (* 1 = 0.00113642 loss)
I0711 13:02:56.110991 32652 sgd_solver.cpp:106] Iteration 46600, lr = 0.00272513
I0711 13:02:59.293092 32652 solver.cpp:228] Iteration 46700, loss = 0.000180294
I0711 13:02:59.293135 32652 solver.cpp:244]     Train net output #0: loss = 0.000180281 (* 1 = 0.000180281 loss)
I0711 13:02:59.293145 32652 sgd_solver.cpp:106] Iteration 46700, lr = 0.00272153
I0711 13:03:02.475646 32652 solver.cpp:228] Iteration 46800, loss = 0.000642717
I0711 13:03:02.475688 32652 solver.cpp:244]     Train net output #0: loss = 0.000642704 (* 1 = 0.000642704 loss)
I0711 13:03:02.475699 32652 sgd_solver.cpp:106] Iteration 46800, lr = 0.00271793
I0711 13:03:05.653772 32652 solver.cpp:228] Iteration 46900, loss = 0.000736559
I0711 13:03:05.653825 32652 solver.cpp:244]     Train net output #0: loss = 0.000736545 (* 1 = 0.000736545 loss)
I0711 13:03:05.653834 32652 sgd_solver.cpp:106] Iteration 46900, lr = 0.00271435
I0711 13:03:08.801462 32652 solver.cpp:337] Iteration 47000, Testing net (#0)
I0711 13:03:10.917954 32652 solver.cpp:404]     Test net output #0: loss = 0.00879979 (* 1 = 0.00879979 loss)
I0711 13:03:10.940616 32652 solver.cpp:228] Iteration 47000, loss = 0.000521721
I0711 13:03:10.940642 32652 solver.cpp:244]     Train net output #0: loss = 0.000521707 (* 1 = 0.000521707 loss)
I0711 13:03:10.940655 32652 sgd_solver.cpp:106] Iteration 47000, lr = 0.00271078
I0711 13:03:14.101976 32652 solver.cpp:228] Iteration 47100, loss = 0.00168599
I0711 13:03:14.102023 32652 solver.cpp:244]     Train net output #0: loss = 0.00168597 (* 1 = 0.00168597 loss)
I0711 13:03:14.102033 32652 sgd_solver.cpp:106] Iteration 47100, lr = 0.00270722
I0711 13:03:17.263639 32652 solver.cpp:228] Iteration 47200, loss = 0.0014472
I0711 13:03:17.263736 32652 solver.cpp:244]     Train net output #0: loss = 0.00144719 (* 1 = 0.00144719 loss)
I0711 13:03:17.263746 32652 sgd_solver.cpp:106] Iteration 47200, lr = 0.00270367
I0711 13:03:20.432065 32652 solver.cpp:228] Iteration 47300, loss = 0.000844231
I0711 13:03:20.432111 32652 solver.cpp:244]     Train net output #0: loss = 0.000844219 (* 1 = 0.000844219 loss)
I0711 13:03:20.432121 32652 sgd_solver.cpp:106] Iteration 47300, lr = 0.00270013
I0711 13:03:23.592949 32652 solver.cpp:228] Iteration 47400, loss = 0.00180048
I0711 13:03:23.593001 32652 solver.cpp:244]     Train net output #0: loss = 0.00180046 (* 1 = 0.00180046 loss)
I0711 13:03:23.593011 32652 sgd_solver.cpp:106] Iteration 47400, lr = 0.0026966
I0711 13:03:26.731426 32652 solver.cpp:337] Iteration 47500, Testing net (#0)
I0711 13:03:28.853685 32652 solver.cpp:404]     Test net output #0: loss = 0.00882547 (* 1 = 0.00882547 loss)
I0711 13:03:28.876288 32652 solver.cpp:228] Iteration 47500, loss = 0.000562899
I0711 13:03:28.876317 32652 solver.cpp:244]     Train net output #0: loss = 0.000562886 (* 1 = 0.000562886 loss)
I0711 13:03:28.876332 32652 sgd_solver.cpp:106] Iteration 47500, lr = 0.00269308
I0711 13:03:32.059094 32652 solver.cpp:228] Iteration 47600, loss = 0.00133862
I0711 13:03:32.059149 32652 solver.cpp:244]     Train net output #0: loss = 0.00133861 (* 1 = 0.00133861 loss)
I0711 13:03:32.059159 32652 sgd_solver.cpp:106] Iteration 47600, lr = 0.00268957
I0711 13:03:35.234042 32652 solver.cpp:228] Iteration 47700, loss = 0.00165008
I0711 13:03:35.234089 32652 solver.cpp:244]     Train net output #0: loss = 0.00165007 (* 1 = 0.00165007 loss)
I0711 13:03:35.234113 32652 sgd_solver.cpp:106] Iteration 47700, lr = 0.00268607
I0711 13:03:38.398391 32652 solver.cpp:228] Iteration 47800, loss = 0.00104141
I0711 13:03:38.398437 32652 solver.cpp:244]     Train net output #0: loss = 0.00104139 (* 1 = 0.00104139 loss)
I0711 13:03:38.398452 32652 sgd_solver.cpp:106] Iteration 47800, lr = 0.00268259
I0711 13:03:41.560554 32652 solver.cpp:228] Iteration 47900, loss = 0.00149551
I0711 13:03:41.560600 32652 solver.cpp:244]     Train net output #0: loss = 0.0014955 (* 1 = 0.0014955 loss)
I0711 13:03:41.560612 32652 sgd_solver.cpp:106] Iteration 47900, lr = 0.00267911
I0711 13:03:44.692492 32652 solver.cpp:337] Iteration 48000, Testing net (#0)
I0711 13:03:46.810245 32652 solver.cpp:404]     Test net output #0: loss = 0.00892902 (* 1 = 0.00892902 loss)
I0711 13:03:46.833531 32652 solver.cpp:228] Iteration 48000, loss = 0.000727813
I0711 13:03:46.833561 32652 solver.cpp:244]     Train net output #0: loss = 0.0007278 (* 1 = 0.0007278 loss)
I0711 13:03:46.833575 32652 sgd_solver.cpp:106] Iteration 48000, lr = 0.00267565
I0711 13:03:50.013579 32652 solver.cpp:228] Iteration 48100, loss = 0.000883664
I0711 13:03:50.013795 32652 solver.cpp:244]     Train net output #0: loss = 0.000883651 (* 1 = 0.000883651 loss)
I0711 13:03:50.013808 32652 sgd_solver.cpp:106] Iteration 48100, lr = 0.00267219
I0711 13:03:53.186314 32652 solver.cpp:228] Iteration 48200, loss = 0.00132181
I0711 13:03:53.186367 32652 solver.cpp:244]     Train net output #0: loss = 0.0013218 (* 1 = 0.0013218 loss)
I0711 13:03:53.186377 32652 sgd_solver.cpp:106] Iteration 48200, lr = 0.00266875
I0711 13:03:56.366719 32652 solver.cpp:228] Iteration 48300, loss = 0.000904819
I0711 13:03:56.366772 32652 solver.cpp:244]     Train net output #0: loss = 0.000904807 (* 1 = 0.000904807 loss)
I0711 13:03:56.366781 32652 sgd_solver.cpp:106] Iteration 48300, lr = 0.00266532
I0711 13:03:59.542255 32652 solver.cpp:228] Iteration 48400, loss = 0.000881726
I0711 13:03:59.542309 32652 solver.cpp:244]     Train net output #0: loss = 0.000881713 (* 1 = 0.000881713 loss)
I0711 13:03:59.542320 32652 sgd_solver.cpp:106] Iteration 48400, lr = 0.00266189
I0711 13:04:02.673609 32652 solver.cpp:337] Iteration 48500, Testing net (#0)
I0711 13:04:04.800469 32652 solver.cpp:404]     Test net output #0: loss = 0.00886686 (* 1 = 0.00886686 loss)
I0711 13:04:04.823396 32652 solver.cpp:228] Iteration 48500, loss = 0.00112916
I0711 13:04:04.823437 32652 solver.cpp:244]     Train net output #0: loss = 0.00112915 (* 1 = 0.00112915 loss)
I0711 13:04:04.823449 32652 sgd_solver.cpp:106] Iteration 48500, lr = 0.00265848
I0711 13:04:07.984184 32652 solver.cpp:228] Iteration 48600, loss = 0.000694284
I0711 13:04:07.984230 32652 solver.cpp:244]     Train net output #0: loss = 0.000694272 (* 1 = 0.000694272 loss)
I0711 13:04:07.984241 32652 sgd_solver.cpp:106] Iteration 48600, lr = 0.00265507
I0711 13:04:11.145066 32652 solver.cpp:228] Iteration 48700, loss = 0.000506719
I0711 13:04:11.145107 32652 solver.cpp:244]     Train net output #0: loss = 0.000506707 (* 1 = 0.000506707 loss)
I0711 13:04:11.145117 32652 sgd_solver.cpp:106] Iteration 48700, lr = 0.00265168
I0711 13:04:14.306718 32652 solver.cpp:228] Iteration 48800, loss = 0.000675869
I0711 13:04:14.306766 32652 solver.cpp:244]     Train net output #0: loss = 0.000675858 (* 1 = 0.000675858 loss)
I0711 13:04:14.306777 32652 sgd_solver.cpp:106] Iteration 48800, lr = 0.0026483
I0711 13:04:17.480360 32652 solver.cpp:228] Iteration 48900, loss = 0.00104908
I0711 13:04:17.480406 32652 solver.cpp:244]     Train net output #0: loss = 0.00104907 (* 1 = 0.00104907 loss)
I0711 13:04:17.480423 32652 sgd_solver.cpp:106] Iteration 48900, lr = 0.00264493
I0711 13:04:20.617086 32652 solver.cpp:337] Iteration 49000, Testing net (#0)
I0711 13:04:22.736390 32652 solver.cpp:404]     Test net output #0: loss = 0.00877374 (* 1 = 0.00877374 loss)
I0711 13:04:22.759265 32652 solver.cpp:228] Iteration 49000, loss = 0.000285003
I0711 13:04:22.759305 32652 solver.cpp:244]     Train net output #0: loss = 0.000284991 (* 1 = 0.000284991 loss)
I0711 13:04:22.759330 32652 sgd_solver.cpp:106] Iteration 49000, lr = 0.00264156
I0711 13:04:25.942167 32652 solver.cpp:228] Iteration 49100, loss = 0.00107005
I0711 13:04:25.942210 32652 solver.cpp:244]     Train net output #0: loss = 0.00107004 (* 1 = 0.00107004 loss)
I0711 13:04:25.942221 32652 sgd_solver.cpp:106] Iteration 49100, lr = 0.00263821
I0711 13:04:29.112431 32652 solver.cpp:228] Iteration 49200, loss = 0.000615549
I0711 13:04:29.112483 32652 solver.cpp:244]     Train net output #0: loss = 0.000615536 (* 1 = 0.000615536 loss)
I0711 13:04:29.112493 32652 sgd_solver.cpp:106] Iteration 49200, lr = 0.00263487
I0711 13:04:32.274157 32652 solver.cpp:228] Iteration 49300, loss = 0.00159342
I0711 13:04:32.274207 32652 solver.cpp:244]     Train net output #0: loss = 0.00159341 (* 1 = 0.00159341 loss)
I0711 13:04:32.274217 32652 sgd_solver.cpp:106] Iteration 49300, lr = 0.00263153
I0711 13:04:35.441115 32652 solver.cpp:228] Iteration 49400, loss = 0.000886205
I0711 13:04:35.441159 32652 solver.cpp:244]     Train net output #0: loss = 0.000886192 (* 1 = 0.000886192 loss)
I0711 13:04:35.441170 32652 sgd_solver.cpp:106] Iteration 49400, lr = 0.00262821
I0711 13:04:38.588215 32652 solver.cpp:337] Iteration 49500, Testing net (#0)
I0711 13:04:40.708608 32652 solver.cpp:404]     Test net output #0: loss = 0.00875511 (* 1 = 0.00875511 loss)
I0711 13:04:40.731307 32652 solver.cpp:228] Iteration 49500, loss = 0.00105095
I0711 13:04:40.731335 32652 solver.cpp:244]     Train net output #0: loss = 0.00105094 (* 1 = 0.00105094 loss)
I0711 13:04:40.731348 32652 sgd_solver.cpp:106] Iteration 49500, lr = 0.0026249
I0711 13:04:43.910506 32652 solver.cpp:228] Iteration 49600, loss = 0.00199408
I0711 13:04:43.910550 32652 solver.cpp:244]     Train net output #0: loss = 0.00199406 (* 1 = 0.00199406 loss)
I0711 13:04:43.910562 32652 sgd_solver.cpp:106] Iteration 49600, lr = 0.00262159
I0711 13:04:47.072962 32652 solver.cpp:228] Iteration 49700, loss = 0.0007403
I0711 13:04:47.073015 32652 solver.cpp:244]     Train net output #0: loss = 0.000740286 (* 1 = 0.000740286 loss)
I0711 13:04:47.073025 32652 sgd_solver.cpp:106] Iteration 49700, lr = 0.0026183
I0711 13:04:50.236415 32652 solver.cpp:228] Iteration 49800, loss = 0.000639752
I0711 13:04:50.236461 32652 solver.cpp:244]     Train net output #0: loss = 0.000639739 (* 1 = 0.000639739 loss)
I0711 13:04:50.236471 32652 sgd_solver.cpp:106] Iteration 49800, lr = 0.00261501
I0711 13:04:53.397677 32652 solver.cpp:228] Iteration 49900, loss = 0.00040167
I0711 13:04:53.397792 32652 solver.cpp:244]     Train net output #0: loss = 0.000401657 (* 1 = 0.000401657 loss)
I0711 13:04:53.397804 32652 sgd_solver.cpp:106] Iteration 49900, lr = 0.00261174
I0711 13:04:56.525575 32652 solver.cpp:454] Snapshotting to binary proto file examples/siamese/My_mnist_siamese_0to6_iter_50000.caffemodel
I0711 13:04:56.553120 32652 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/siamese/My_mnist_siamese_0to6_iter_50000.solverstate
I0711 13:04:56.571270 32652 solver.cpp:317] Iteration 50000, loss = 0.00116662
I0711 13:04:56.571310 32652 solver.cpp:337] Iteration 50000, Testing net (#0)
I0711 13:04:58.685091 32652 solver.cpp:404]     Test net output #0: loss = 0.00887935 (* 1 = 0.00887935 loss)
I0711 13:04:58.685122 32652 solver.cpp:322] Optimization Done.
I0711 13:04:58.685127 32652 caffe.cpp:222] Optimization Done.
