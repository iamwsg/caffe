I0813 08:28:00.786546 18283 caffe.cpp:178] Use CPU.
I0813 08:28:00.787021 18283 solver.cpp:48] Initializing solver from parameters: 
train_net: "examples/scene/metNetTrain.prototxt"
test_net: "examples/scene/metNetTest.prototxt"
test_iter: 10
test_interval: 100
base_lr: 0.01
display: 50
max_iter: 300000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.002
snapshot: 5000
snapshot_prefix: "examples/scene/scene_met"
solver_mode: CPU
I0813 08:28:00.787205 18283 solver.cpp:81] Creating training net from train_net file: examples/scene/metNetTrain.prototxt
I0813 08:28:00.796303 18283 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 1
    mirror: false
  }
  data_param {
    source: "/home/shaogang/Datasets/FeatsDB/featsTrain20k"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "th"
  type: "Threshold"
  bottom: "label"
  top: "th"
  threshold_param {
    threshold: 0
  }
}
layer {
  name: "i1"
  type: "Slice"
  bottom: "data"
  top: "i1"
  top: "i2"
  top: "i3"
  top: "i4"
  top: "i5"
  top: "i6"
  top: "i7"
  top: "i8"
  top: "i9"
  top: "i10"
  top: "i11"
  top: "i12"
  top: "i13"
  top: "i14"
  top: "i15"
  top: "i16"
  top: "i17"
  top: "i18"
  top: "i19"
  top: "i20"
  slice_param {
    slice_dim: 2
    slice_point: 1
    slice_point: 2
    slice_point: 3
    slice_point: 4
    slice_point: 5
    slice_point: 6
    slice_point: 7
    slice_point: 8
    slice_point: 9
    slice_point: 10
    slice_point: 11
    slice_point: 12
    slice_point: 13
    slice_point: 14
    slice_point: 15
    slice_point: 16
    slice_point: 17
    slice_point: 18
    slice_point: 19
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "i1"
  bottom: "i11"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Concat1"
  top: "InnerProduct1"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct1"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "Dropout1"
  top: "InnerProduct2"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "InnerProduct2"
  top: "InnerProduct2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct2"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m1"
  type: "InnerProduct"
  bottom: "Dropout2"
  top: "m1"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "i1"
  bottom: "i12"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "Concat2"
  top: "InnerProduct3"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct3"
  top: "InnerProduct3"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct3"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "Dropout3"
  top: "InnerProduct4"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "InnerProduct4"
  top: "InnerProduct4"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct4"
  top: "Dropout4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m2"
  type: "InnerProduct"
  bottom: "Dropout4"
  top: "m2"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "i1"
  bottom: "i13"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct5"
  type: "InnerProduct"
  bottom: "Concat3"
  top: "InnerProduct5"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "InnerProduct5"
  top: "InnerProduct5"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct5"
  top: "Dropout5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct6"
  type: "InnerProduct"
  bottom: "Dropout5"
  top: "InnerProduct6"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "InnerProduct6"
  top: "InnerProduct6"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct6"
  top: "Dropout6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m3"
  type: "InnerProduct"
  bottom: "Dropout6"
  top: "m3"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "i1"
  bottom: "i14"
  top: "Concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct7"
  type: "InnerProduct"
  bottom: "Concat4"
  top: "InnerProduct7"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "InnerProduct7"
  top: "InnerProduct7"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct7"
  top: "Dropout7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct8"
  type: "InnerProduct"
  bottom: "Dropout7"
  top: "InnerProduct8"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "InnerProduct8"
  top: "InnerProduct8"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct8"
  top: "Dropout8"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m4"
  type: "InnerProduct"
  bottom: "Dropout8"
  top: "m4"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "i1"
  bottom: "i15"
  top: "Concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct9"
  type: "InnerProduct"
  bottom: "Concat5"
  top: "InnerProduct9"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "InnerProduct9"
  top: "InnerProduct9"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct9"
  top: "Dropout9"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct10"
  type: "InnerProduct"
  bottom: "Dropout9"
  top: "InnerProduct10"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "InnerProduct10"
  top: "InnerProduct10"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct10"
  top: "Dropout10"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m5"
  type: "InnerProduct"
  bottom: "Dropout10"
  top: "m5"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "i1"
  bottom: "i16"
  top: "Concat6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct11"
  type: "InnerProduct"
  bottom: "Concat6"
  top: "InnerProduct11"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "InnerProduct11"
  top: "InnerProduct11"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct11"
  top: "Dropout11"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct12"
  type: "InnerProduct"
  bottom: "Dropout11"
  top: "InnerProduct12"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "InnerProduct12"
  top: "InnerProduct12"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct12"
  top: "Dropout12"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m6"
  type: "InnerProduct"
  bottom: "Dropout12"
  top: "m6"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "i1"
  bottom: "i17"
  top: "Concat7"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct13"
  type: "InnerProduct"
  bottom: "Concat7"
  top: "InnerProduct13"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "InnerProduct13"
  top: "InnerProduct13"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct13"
  top: "Dropout13"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct14"
  type: "InnerProduct"
  bottom: "Dropout13"
  top: "InnerProduct14"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "InnerProduct14"
  top: "InnerProduct14"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct14"
  top: "Dropout14"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m7"
  type: "InnerProduct"
  bottom: "Dropout14"
  top: "m7"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "i1"
  bottom: "i18"
  top: "Concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct15"
  type: "InnerProduct"
  bottom: "Concat8"
  top: "InnerProduct15"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "InnerProduct15"
  top: "InnerProduct15"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct15"
  top: "Dropout15"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct16"
  type: "InnerProduct"
  bottom: "Dropout15"
  top: "InnerProduct16"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "InnerProduct16"
  top: "InnerProduct16"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct16"
  top: "Dropout16"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m8"
  type: "InnerProduct"
  bottom: "Dropout16"
  top: "m8"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "i1"
  bottom: "i19"
  top: "Concat9"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct17"
  type: "InnerProduct"
  bottom: "Concat9"
  top: "InnerProduct17"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "InnerProduct17"
  top: "InnerProduct17"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct17"
  top: "Dropout17"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct18"
  type: "InnerProduct"
  bottom: "Dropout17"
  top: "InnerProduct18"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "InnerProduct18"
  top: "InnerProduct18"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct18"
  top: "Dropout18"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m9"
  type: "InnerProduct"
  bottom: "Dropout18"
  top: "m9"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat10"
  type: "Concat"
  bottom: "i1"
  bottom: "i20"
  top: "Concat10"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct19"
  type: "InnerProduct"
  bottom: "Concat10"
  top: "InnerProduct19"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "InnerProduct19"
  top: "InnerProduct19"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct19"
  top: "Dropout19"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct20"
  type: "InnerProduct"
  bottom: "Dropout19"
  top: "InnerProduct20"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "InnerProduct20"
  top: "InnerProduct20"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct20"
  top: "Dropout20"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m10"
  type: "InnerProduct"
  bottom: "Dropout20"
  top: "m10"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat11"
  type: "Concat"
  bottom: "i2"
  bottom: "i11"
  top: "Concat11"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct21"
  type: "InnerProduct"
  bottom: "Concat11"
  top: "InnerProduct21"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "InnerProduct21"
  top: "InnerProduct21"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct21"
  top: "Dropout21"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct22"
  type: "InnerProduct"
  bottom: "Dropout21"
  top: "InnerProduct22"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "InnerProduct22"
  top: "InnerProduct22"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct22"
  top: "Dropout22"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m11"
  type: "InnerProduct"
  bottom: "Dropout22"
  top: "m11"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat12"
  type: "Concat"
  bottom: "i3"
  bottom: "i11"
  top: "Concat12"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct23"
  type: "InnerProduct"
  bottom: "Concat12"
  top: "InnerProduct23"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "InnerProduct23"
  top: "InnerProduct23"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct23"
  top: "Dropout23"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct24"
  type: "InnerProduct"
  bottom: "Dropout23"
  top: "InnerProduct24"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "InnerProduct24"
  top: "InnerProduct24"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct24"
  top: "Dropout24"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m12"
  type: "InnerProduct"
  bottom: "Dropout24"
  top: "m12"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat13"
  type: "Concat"
  bottom: "i4"
  bottom: "i11"
  top: "Concat13"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct25"
  type: "InnerProduct"
  bottom: "Concat13"
  top: "InnerProduct25"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "InnerProduct25"
  top: "InnerProduct25"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct25"
  top: "Dropout25"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct26"
  type: "InnerProduct"
  bottom: "Dropout25"
  top: "InnerProduct26"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "InnerProduct26"
  top: "InnerProduct26"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct26"
  top: "Dropout26"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m13"
  type: "InnerProduct"
  bottom: "Dropout26"
  top: "m13"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat14"
  type: "Concat"
  bottom: "i5"
  bottom: "i11"
  top: "Concat14"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct27"
  type: "InnerProduct"
  bottom: "Concat14"
  top: "InnerProduct27"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "InnerProduct27"
  top: "InnerProduct27"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct27"
  top: "Dropout27"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct28"
  type: "InnerProduct"
  bottom: "Dropout27"
  top: "InnerProduct28"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "InnerProduct28"
  top: "InnerProduct28"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct28"
  top: "Dropout28"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m14"
  type: "InnerProduct"
  bottom: "Dropout28"
  top: "m14"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat15"
  type: "Concat"
  bottom: "i6"
  bottom: "i11"
  top: "Concat15"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct29"
  type: "InnerProduct"
  bottom: "Concat15"
  top: "InnerProduct29"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "InnerProduct29"
  top: "InnerProduct29"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct29"
  top: "Dropout29"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct30"
  type: "InnerProduct"
  bottom: "Dropout29"
  top: "InnerProduct30"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "InnerProduct30"
  top: "InnerProduct30"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct30"
  top: "Dropout30"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m15"
  type: "InnerProduct"
  bottom: "Dropout30"
  top: "m15"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat16"
  type: "Concat"
  bottom: "i7"
  bottom: "i11"
  top: "Concat16"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct31"
  type: "InnerProduct"
  bottom: "Concat16"
  top: "InnerProduct31"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "InnerProduct31"
  top: "InnerProduct31"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct31"
  top: "Dropout31"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct32"
  type: "InnerProduct"
  bottom: "Dropout31"
  top: "InnerProduct32"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "InnerProduct32"
  top: "InnerProduct32"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct32"
  top: "Dropout32"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m16"
  type: "InnerProduct"
  bottom: "Dropout32"
  top: "m16"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat17"
  type: "Concat"
  bottom: "i8"
  bottom: "i11"
  top: "Concat17"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct33"
  type: "InnerProduct"
  bottom: "Concat17"
  top: "InnerProduct33"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "InnerProduct33"
  top: "InnerProduct33"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct33"
  top: "Dropout33"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct34"
  type: "InnerProduct"
  bottom: "Dropout33"
  top: "InnerProduct34"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "InnerProduct34"
  top: "InnerProduct34"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct34"
  top: "Dropout34"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m17"
  type: "InnerProduct"
  bottom: "Dropout34"
  top: "m17"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat18"
  type: "Concat"
  bottom: "i9"
  bottom: "i11"
  top: "Concat18"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct35"
  type: "InnerProduct"
  bottom: "Concat18"
  top: "InnerProduct35"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "InnerProduct35"
  top: "InnerProduct35"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct35"
  top: "Dropout35"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct36"
  type: "InnerProduct"
  bottom: "Dropout35"
  top: "InnerProduct36"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "InnerProduct36"
  top: "InnerProduct36"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct36"
  top: "Dropout36"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m18"
  type: "InnerProduct"
  bottom: "Dropout36"
  top: "m18"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat19"
  type: "Concat"
  bottom: "i10"
  bottom: "i11"
  top: "Concat19"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct37"
  type: "InnerProduct"
  bottom: "Concat19"
  top: "InnerProduct37"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU3
I0813 08:28:00.798604 18283 layer_factory.hpp:77] Creating layer data
I0813 08:28:00.799871 18283 net.cpp:91] Creating Layer data
I0813 08:28:00.799950 18283 net.cpp:399] data -> data
I0813 08:28:00.800040 18283 net.cpp:399] data -> label
I0813 08:28:00.800103 18287 db_lmdb.cpp:35] Opened lmdb /home/shaogang/Datasets/FeatsDB/featsTrain20k
I0813 08:28:00.801668 18283 data_layer.cpp:41] output data size: 100,1,20,4096
I0813 08:28:00.853773 18283 net.cpp:141] Setting up data
I0813 08:28:00.853842 18283 net.cpp:148] Top shape: 100 1 20 4096 (8192000)
I0813 08:28:00.853859 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:00.853870 18283 net.cpp:156] Memory required for data: 32768400
I0813 08:28:00.853895 18283 layer_factory.hpp:77] Creating layer label_data_1_split
I0813 08:28:00.853965 18283 net.cpp:91] Creating Layer label_data_1_split
I0813 08:28:00.853984 18283 net.cpp:425] label_data_1_split <- label
I0813 08:28:00.854013 18283 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0813 08:28:00.854051 18283 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0813 08:28:00.854092 18283 net.cpp:141] Setting up label_data_1_split
I0813 08:28:00.854110 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:00.854125 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:00.854135 18283 net.cpp:156] Memory required for data: 32769200
I0813 08:28:00.854146 18283 layer_factory.hpp:77] Creating layer th
I0813 08:28:00.854171 18283 net.cpp:91] Creating Layer th
I0813 08:28:00.854184 18283 net.cpp:425] th <- label_data_1_split_0
I0813 08:28:00.854203 18283 net.cpp:399] th -> th
I0813 08:28:00.854238 18283 net.cpp:141] Setting up th
I0813 08:28:00.854256 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:00.854267 18283 net.cpp:156] Memory required for data: 32769600
I0813 08:28:00.854279 18283 layer_factory.hpp:77] Creating layer th_th_0_split
I0813 08:28:00.854297 18283 net.cpp:91] Creating Layer th_th_0_split
I0813 08:28:00.854310 18283 net.cpp:425] th_th_0_split <- th
I0813 08:28:00.854327 18283 net.cpp:399] th_th_0_split -> th_th_0_split_0
I0813 08:28:00.854347 18283 net.cpp:399] th_th_0_split -> th_th_0_split_1
I0813 08:28:00.854370 18283 net.cpp:141] Setting up th_th_0_split
I0813 08:28:00.854388 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:00.854434 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:00.854444 18283 net.cpp:156] Memory required for data: 32770400
I0813 08:28:00.854455 18283 layer_factory.hpp:77] Creating layer i1
I0813 08:28:00.854488 18283 net.cpp:91] Creating Layer i1
I0813 08:28:00.854501 18283 net.cpp:425] i1 <- data
I0813 08:28:00.854522 18283 net.cpp:399] i1 -> i1
I0813 08:28:00.854559 18283 net.cpp:399] i1 -> i2
I0813 08:28:00.854598 18283 net.cpp:399] i1 -> i3
I0813 08:28:00.854624 18283 net.cpp:399] i1 -> i4
I0813 08:28:00.854650 18283 net.cpp:399] i1 -> i5
I0813 08:28:00.854677 18283 net.cpp:399] i1 -> i6
I0813 08:28:00.854704 18283 net.cpp:399] i1 -> i7
I0813 08:28:00.854729 18283 net.cpp:399] i1 -> i8
I0813 08:28:00.854753 18283 net.cpp:399] i1 -> i9
I0813 08:28:00.854791 18283 net.cpp:399] i1 -> i10
I0813 08:28:00.854820 18283 net.cpp:399] i1 -> i11
I0813 08:28:00.854846 18283 net.cpp:399] i1 -> i12
I0813 08:28:00.854872 18283 net.cpp:399] i1 -> i13
I0813 08:28:00.854898 18283 net.cpp:399] i1 -> i14
I0813 08:28:00.854924 18283 net.cpp:399] i1 -> i15
I0813 08:28:00.854954 18283 net.cpp:399] i1 -> i16
I0813 08:28:00.854981 18283 net.cpp:399] i1 -> i17
I0813 08:28:00.855012 18283 net.cpp:399] i1 -> i18
I0813 08:28:00.855036 18283 net.cpp:399] i1 -> i19
I0813 08:28:00.855063 18283 net.cpp:399] i1 -> i20
I0813 08:28:00.855118 18283 net.cpp:141] Setting up i1
I0813 08:28:00.855134 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855149 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855162 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855175 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855192 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855211 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855226 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855239 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855252 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855264 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855278 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855295 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855309 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855322 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855335 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855348 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855360 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855373 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855474 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855487 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855499 18283 net.cpp:156] Memory required for data: 65538400
I0813 08:28:00.855509 18283 layer_factory.hpp:77] Creating layer i1_i1_0_split
I0813 08:28:00.855530 18283 net.cpp:91] Creating Layer i1_i1_0_split
I0813 08:28:00.855543 18283 net.cpp:425] i1_i1_0_split <- i1
I0813 08:28:00.855564 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_0
I0813 08:28:00.855589 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_1
I0813 08:28:00.855618 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_2
I0813 08:28:00.855641 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_3
I0813 08:28:00.855664 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_4
I0813 08:28:00.855687 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_5
I0813 08:28:00.855716 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_6
I0813 08:28:00.855737 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_7
I0813 08:28:00.855759 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_8
I0813 08:28:00.855782 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_9
I0813 08:28:00.855823 18283 net.cpp:141] Setting up i1_i1_0_split
I0813 08:28:00.855837 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855851 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855885 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855898 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855911 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855927 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855942 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855955 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855968 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855981 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.855990 18283 net.cpp:156] Memory required for data: 81922400
I0813 08:28:00.856003 18283 layer_factory.hpp:77] Creating layer i11_i1_10_split
I0813 08:28:00.856022 18283 net.cpp:91] Creating Layer i11_i1_10_split
I0813 08:28:00.856070 18283 net.cpp:425] i11_i1_10_split <- i11
I0813 08:28:00.856091 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_0
I0813 08:28:00.856117 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_1
I0813 08:28:00.856143 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_2
I0813 08:28:00.856165 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_3
I0813 08:28:00.856187 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_4
I0813 08:28:00.856220 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_5
I0813 08:28:00.856245 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_6
I0813 08:28:00.856268 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_7
I0813 08:28:00.856290 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_8
I0813 08:28:00.856312 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_9
I0813 08:28:00.856344 18283 net.cpp:141] Setting up i11_i1_10_split
I0813 08:28:00.856359 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.856377 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.856391 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.856402 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.856415 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.856426 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.856438 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.856451 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.856465 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.856477 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:00.856492 18283 net.cpp:156] Memory required for data: 98306400
I0813 08:28:00.856503 18283 layer_factory.hpp:77] Creating layer Concat1
I0813 08:28:00.856523 18283 net.cpp:91] Creating Layer Concat1
I0813 08:28:00.856535 18283 net.cpp:425] Concat1 <- i1_i1_0_split_0
I0813 08:28:00.856549 18283 net.cpp:425] Concat1 <- i11_i1_10_split_0
I0813 08:28:00.856566 18283 net.cpp:399] Concat1 -> Concat1
I0813 08:28:00.856595 18283 net.cpp:141] Setting up Concat1
I0813 08:28:00.856613 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:00.856624 18283 net.cpp:156] Memory required for data: 101583200
I0813 08:28:00.856634 18283 layer_factory.hpp:77] Creating layer InnerProduct1
I0813 08:28:00.856663 18283 net.cpp:91] Creating Layer InnerProduct1
I0813 08:28:00.856674 18283 net.cpp:425] InnerProduct1 <- Concat1
I0813 08:28:00.856693 18283 net.cpp:399] InnerProduct1 -> InnerProduct1
I0813 08:28:00.875891 18288 blocking_queue.cpp:50] Waiting for data
I0813 08:28:00.882659 18283 net.cpp:141] Setting up InnerProduct1
I0813 08:28:00.882707 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.882717 18283 net.cpp:156] Memory required for data: 101685600
I0813 08:28:00.882755 18283 layer_factory.hpp:77] Creating layer ReLU1
I0813 08:28:00.882796 18283 net.cpp:91] Creating Layer ReLU1
I0813 08:28:00.882810 18283 net.cpp:425] ReLU1 <- InnerProduct1
I0813 08:28:00.882830 18283 net.cpp:386] ReLU1 -> InnerProduct1 (in-place)
I0813 08:28:00.882856 18283 net.cpp:141] Setting up ReLU1
I0813 08:28:00.882870 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.882910 18283 net.cpp:156] Memory required for data: 101788000
I0813 08:28:00.882921 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:00.882954 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:00.882967 18283 net.cpp:425] drop1 <- InnerProduct1
I0813 08:28:00.882982 18283 net.cpp:399] drop1 -> Dropout1
I0813 08:28:00.883009 18283 net.cpp:141] Setting up drop1
I0813 08:28:00.883023 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.883031 18283 net.cpp:156] Memory required for data: 101890400
I0813 08:28:00.883041 18283 layer_factory.hpp:77] Creating layer InnerProduct2
I0813 08:28:00.883064 18283 net.cpp:91] Creating Layer InnerProduct2
I0813 08:28:00.883076 18283 net.cpp:425] InnerProduct2 <- Dropout1
I0813 08:28:00.883095 18283 net.cpp:399] InnerProduct2 -> InnerProduct2
I0813 08:28:00.883478 18283 net.cpp:141] Setting up InnerProduct2
I0813 08:28:00.883494 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.883503 18283 net.cpp:156] Memory required for data: 101941600
I0813 08:28:00.883522 18283 layer_factory.hpp:77] Creating layer ReLU2
I0813 08:28:00.883539 18283 net.cpp:91] Creating Layer ReLU2
I0813 08:28:00.883549 18283 net.cpp:425] ReLU2 <- InnerProduct2
I0813 08:28:00.883565 18283 net.cpp:386] ReLU2 -> InnerProduct2 (in-place)
I0813 08:28:00.883581 18283 net.cpp:141] Setting up ReLU2
I0813 08:28:00.883594 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.883604 18283 net.cpp:156] Memory required for data: 101992800
I0813 08:28:00.883613 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:00.883630 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:00.883641 18283 net.cpp:425] drop2 <- InnerProduct2
I0813 08:28:00.883654 18283 net.cpp:399] drop2 -> Dropout2
I0813 08:28:00.883673 18283 net.cpp:141] Setting up drop2
I0813 08:28:00.883688 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.883697 18283 net.cpp:156] Memory required for data: 102044000
I0813 08:28:00.883708 18283 layer_factory.hpp:77] Creating layer m1
I0813 08:28:00.883728 18283 net.cpp:91] Creating Layer m1
I0813 08:28:00.883738 18283 net.cpp:425] m1 <- Dropout2
I0813 08:28:00.883759 18283 net.cpp:399] m1 -> m1
I0813 08:28:00.883793 18283 net.cpp:141] Setting up m1
I0813 08:28:00.883805 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:00.883816 18283 net.cpp:156] Memory required for data: 102044400
I0813 08:28:00.883832 18283 layer_factory.hpp:77] Creating layer Concat2
I0813 08:28:00.883852 18283 net.cpp:91] Creating Layer Concat2
I0813 08:28:00.883864 18283 net.cpp:425] Concat2 <- i1_i1_0_split_1
I0813 08:28:00.883879 18283 net.cpp:425] Concat2 <- i12
I0813 08:28:00.883898 18283 net.cpp:399] Concat2 -> Concat2
I0813 08:28:00.883920 18283 net.cpp:141] Setting up Concat2
I0813 08:28:00.883934 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:00.883944 18283 net.cpp:156] Memory required for data: 105321200
I0813 08:28:00.883952 18283 layer_factory.hpp:77] Creating layer InnerProduct3
I0813 08:28:00.883977 18283 net.cpp:91] Creating Layer InnerProduct3
I0813 08:28:00.883988 18283 net.cpp:425] InnerProduct3 <- Concat2
I0813 08:28:00.884006 18283 net.cpp:399] InnerProduct3 -> InnerProduct3
I0813 08:28:00.904278 18283 net.cpp:141] Setting up InnerProduct3
I0813 08:28:00.904322 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.904330 18283 net.cpp:156] Memory required for data: 105423600
I0813 08:28:00.904345 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:00.904357 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:00.904366 18283 layer_factory.hpp:77] Creating layer ReLU3
I0813 08:28:00.904392 18283 net.cpp:91] Creating Layer ReLU3
I0813 08:28:00.904404 18283 net.cpp:425] ReLU3 <- InnerProduct3
I0813 08:28:00.904428 18283 net.cpp:386] ReLU3 -> InnerProduct3 (in-place)
I0813 08:28:00.904451 18283 net.cpp:141] Setting up ReLU3
I0813 08:28:00.904464 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.904471 18283 net.cpp:156] Memory required for data: 105526000
I0813 08:28:00.904508 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:00.904527 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:00.904538 18283 net.cpp:425] drop1 <- InnerProduct3
I0813 08:28:00.904552 18283 net.cpp:399] drop1 -> Dropout3
I0813 08:28:00.904579 18283 net.cpp:141] Setting up drop1
I0813 08:28:00.904593 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.904602 18283 net.cpp:156] Memory required for data: 105628400
I0813 08:28:00.904609 18283 layer_factory.hpp:77] Creating layer InnerProduct4
I0813 08:28:00.904631 18283 net.cpp:91] Creating Layer InnerProduct4
I0813 08:28:00.904641 18283 net.cpp:425] InnerProduct4 <- Dropout3
I0813 08:28:00.904657 18283 net.cpp:399] InnerProduct4 -> InnerProduct4
I0813 08:28:00.904968 18283 net.cpp:141] Setting up InnerProduct4
I0813 08:28:00.904981 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.904989 18283 net.cpp:156] Memory required for data: 105679600
I0813 08:28:00.905006 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:00.905019 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:00.905026 18283 layer_factory.hpp:77] Creating layer ReLU4
I0813 08:28:00.905040 18283 net.cpp:91] Creating Layer ReLU4
I0813 08:28:00.905052 18283 net.cpp:425] ReLU4 <- InnerProduct4
I0813 08:28:00.905066 18283 net.cpp:386] ReLU4 -> InnerProduct4 (in-place)
I0813 08:28:00.905079 18283 net.cpp:141] Setting up ReLU4
I0813 08:28:00.905091 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.905097 18283 net.cpp:156] Memory required for data: 105730800
I0813 08:28:00.905104 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:00.905118 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:00.905127 18283 net.cpp:425] drop2 <- InnerProduct4
I0813 08:28:00.905139 18283 net.cpp:399] drop2 -> Dropout4
I0813 08:28:00.905158 18283 net.cpp:141] Setting up drop2
I0813 08:28:00.905170 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.905179 18283 net.cpp:156] Memory required for data: 105782000
I0813 08:28:00.905186 18283 layer_factory.hpp:77] Creating layer m2
I0813 08:28:00.905205 18283 net.cpp:91] Creating Layer m2
I0813 08:28:00.905215 18283 net.cpp:425] m2 <- Dropout4
I0813 08:28:00.905230 18283 net.cpp:399] m2 -> m2
I0813 08:28:00.905261 18283 net.cpp:141] Setting up m2
I0813 08:28:00.905275 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:00.905283 18283 net.cpp:156] Memory required for data: 105782400
I0813 08:28:00.905292 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:00.905303 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:00.905311 18283 layer_factory.hpp:77] Creating layer Concat3
I0813 08:28:00.905328 18283 net.cpp:91] Creating Layer Concat3
I0813 08:28:00.905340 18283 net.cpp:425] Concat3 <- i1_i1_0_split_2
I0813 08:28:00.905354 18283 net.cpp:425] Concat3 <- i13
I0813 08:28:00.905369 18283 net.cpp:399] Concat3 -> Concat3
I0813 08:28:00.905390 18283 net.cpp:141] Setting up Concat3
I0813 08:28:00.905401 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:00.905410 18283 net.cpp:156] Memory required for data: 109059200
I0813 08:28:00.905416 18283 layer_factory.hpp:77] Creating layer InnerProduct5
I0813 08:28:00.905434 18283 net.cpp:91] Creating Layer InnerProduct5
I0813 08:28:00.905444 18283 net.cpp:425] InnerProduct5 <- Concat3
I0813 08:28:00.905460 18283 net.cpp:399] InnerProduct5 -> InnerProduct5
I0813 08:28:00.925454 18283 net.cpp:141] Setting up InnerProduct5
I0813 08:28:00.925496 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.925504 18283 net.cpp:156] Memory required for data: 109161600
I0813 08:28:00.925518 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:00.925529 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:00.925536 18283 layer_factory.hpp:77] Creating layer ReLU5
I0813 08:28:00.925596 18283 net.cpp:91] Creating Layer ReLU5
I0813 08:28:00.925613 18283 net.cpp:425] ReLU5 <- InnerProduct5
I0813 08:28:00.925631 18283 net.cpp:386] ReLU5 -> InnerProduct5 (in-place)
I0813 08:28:00.925653 18283 net.cpp:141] Setting up ReLU5
I0813 08:28:00.925667 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.925673 18283 net.cpp:156] Memory required for data: 109264000
I0813 08:28:00.925681 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:00.925698 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:00.925709 18283 net.cpp:425] drop1 <- InnerProduct5
I0813 08:28:00.925721 18283 net.cpp:399] drop1 -> Dropout5
I0813 08:28:00.925742 18283 net.cpp:141] Setting up drop1
I0813 08:28:00.925755 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.925761 18283 net.cpp:156] Memory required for data: 109366400
I0813 08:28:00.925770 18283 layer_factory.hpp:77] Creating layer InnerProduct6
I0813 08:28:00.925792 18283 net.cpp:91] Creating Layer InnerProduct6
I0813 08:28:00.925801 18283 net.cpp:425] InnerProduct6 <- Dropout5
I0813 08:28:00.925817 18283 net.cpp:399] InnerProduct6 -> InnerProduct6
I0813 08:28:00.926118 18283 net.cpp:141] Setting up InnerProduct6
I0813 08:28:00.926131 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.926138 18283 net.cpp:156] Memory required for data: 109417600
I0813 08:28:00.926147 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:00.926157 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:00.926165 18283 layer_factory.hpp:77] Creating layer ReLU6
I0813 08:28:00.926177 18283 net.cpp:91] Creating Layer ReLU6
I0813 08:28:00.926187 18283 net.cpp:425] ReLU6 <- InnerProduct6
I0813 08:28:00.926199 18283 net.cpp:386] ReLU6 -> InnerProduct6 (in-place)
I0813 08:28:00.926214 18283 net.cpp:141] Setting up ReLU6
I0813 08:28:00.926224 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.926231 18283 net.cpp:156] Memory required for data: 109468800
I0813 08:28:00.926239 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:00.926252 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:00.926261 18283 net.cpp:425] drop2 <- InnerProduct6
I0813 08:28:00.926273 18283 net.cpp:399] drop2 -> Dropout6
I0813 08:28:00.926288 18283 net.cpp:141] Setting up drop2
I0813 08:28:00.926301 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.926307 18283 net.cpp:156] Memory required for data: 109520000
I0813 08:28:00.926316 18283 layer_factory.hpp:77] Creating layer m3
I0813 08:28:00.926333 18283 net.cpp:91] Creating Layer m3
I0813 08:28:00.926343 18283 net.cpp:425] m3 <- Dropout6
I0813 08:28:00.926358 18283 net.cpp:399] m3 -> m3
I0813 08:28:00.926403 18283 net.cpp:141] Setting up m3
I0813 08:28:00.926416 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:00.926424 18283 net.cpp:156] Memory required for data: 109520400
I0813 08:28:00.926440 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:00.926451 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:00.926460 18283 layer_factory.hpp:77] Creating layer Concat4
I0813 08:28:00.926476 18283 net.cpp:91] Creating Layer Concat4
I0813 08:28:00.926486 18283 net.cpp:425] Concat4 <- i1_i1_0_split_3
I0813 08:28:00.926498 18283 net.cpp:425] Concat4 <- i14
I0813 08:28:00.926512 18283 net.cpp:399] Concat4 -> Concat4
I0813 08:28:00.926532 18283 net.cpp:141] Setting up Concat4
I0813 08:28:00.926544 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:00.926551 18283 net.cpp:156] Memory required for data: 112797200
I0813 08:28:00.926558 18283 layer_factory.hpp:77] Creating layer InnerProduct7
I0813 08:28:00.926584 18283 net.cpp:91] Creating Layer InnerProduct7
I0813 08:28:00.926594 18283 net.cpp:425] InnerProduct7 <- Concat4
I0813 08:28:00.926609 18283 net.cpp:399] InnerProduct7 -> InnerProduct7
I0813 08:28:00.945246 18283 net.cpp:141] Setting up InnerProduct7
I0813 08:28:00.945287 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.945332 18283 net.cpp:156] Memory required for data: 112899600
I0813 08:28:00.945351 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:00.945366 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:00.945375 18283 layer_factory.hpp:77] Creating layer ReLU7
I0813 08:28:00.945401 18283 net.cpp:91] Creating Layer ReLU7
I0813 08:28:00.945415 18283 net.cpp:425] ReLU7 <- InnerProduct7
I0813 08:28:00.945430 18283 net.cpp:386] ReLU7 -> InnerProduct7 (in-place)
I0813 08:28:00.945457 18283 net.cpp:141] Setting up ReLU7
I0813 08:28:00.945469 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.945475 18283 net.cpp:156] Memory required for data: 113002000
I0813 08:28:00.945483 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:00.945499 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:00.945510 18283 net.cpp:425] drop1 <- InnerProduct7
I0813 08:28:00.945529 18283 net.cpp:399] drop1 -> Dropout7
I0813 08:28:00.945550 18283 net.cpp:141] Setting up drop1
I0813 08:28:00.945564 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.945571 18283 net.cpp:156] Memory required for data: 113104400
I0813 08:28:00.945579 18283 layer_factory.hpp:77] Creating layer InnerProduct8
I0813 08:28:00.945600 18283 net.cpp:91] Creating Layer InnerProduct8
I0813 08:28:00.945611 18283 net.cpp:425] InnerProduct8 <- Dropout7
I0813 08:28:00.945631 18283 net.cpp:399] InnerProduct8 -> InnerProduct8
I0813 08:28:00.945924 18283 net.cpp:141] Setting up InnerProduct8
I0813 08:28:00.945937 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.945945 18283 net.cpp:156] Memory required for data: 113155600
I0813 08:28:00.945955 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:00.945965 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:00.945976 18283 layer_factory.hpp:77] Creating layer ReLU8
I0813 08:28:00.945989 18283 net.cpp:91] Creating Layer ReLU8
I0813 08:28:00.945999 18283 net.cpp:425] ReLU8 <- InnerProduct8
I0813 08:28:00.946010 18283 net.cpp:386] ReLU8 -> InnerProduct8 (in-place)
I0813 08:28:00.946023 18283 net.cpp:141] Setting up ReLU8
I0813 08:28:00.946033 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.946039 18283 net.cpp:156] Memory required for data: 113206800
I0813 08:28:00.946048 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:00.946059 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:00.946070 18283 net.cpp:425] drop2 <- InnerProduct8
I0813 08:28:00.946081 18283 net.cpp:399] drop2 -> Dropout8
I0813 08:28:00.946097 18283 net.cpp:141] Setting up drop2
I0813 08:28:00.946110 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.946116 18283 net.cpp:156] Memory required for data: 113258000
I0813 08:28:00.946123 18283 layer_factory.hpp:77] Creating layer m4
I0813 08:28:00.946141 18283 net.cpp:91] Creating Layer m4
I0813 08:28:00.946151 18283 net.cpp:425] m4 <- Dropout8
I0813 08:28:00.946167 18283 net.cpp:399] m4 -> m4
I0813 08:28:00.946269 18283 net.cpp:141] Setting up m4
I0813 08:28:00.946281 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:00.946288 18283 net.cpp:156] Memory required for data: 113258400
I0813 08:28:00.946297 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:00.946307 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:00.946316 18283 layer_factory.hpp:77] Creating layer Concat5
I0813 08:28:00.946331 18283 net.cpp:91] Creating Layer Concat5
I0813 08:28:00.946342 18283 net.cpp:425] Concat5 <- i1_i1_0_split_4
I0813 08:28:00.946355 18283 net.cpp:425] Concat5 <- i15
I0813 08:28:00.946369 18283 net.cpp:399] Concat5 -> Concat5
I0813 08:28:00.946388 18283 net.cpp:141] Setting up Concat5
I0813 08:28:00.946400 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:00.946408 18283 net.cpp:156] Memory required for data: 116535200
I0813 08:28:00.946414 18283 layer_factory.hpp:77] Creating layer InnerProduct9
I0813 08:28:00.946446 18283 net.cpp:91] Creating Layer InnerProduct9
I0813 08:28:00.946457 18283 net.cpp:425] InnerProduct9 <- Concat5
I0813 08:28:00.946471 18283 net.cpp:399] InnerProduct9 -> InnerProduct9
I0813 08:28:00.964457 18283 net.cpp:141] Setting up InnerProduct9
I0813 08:28:00.964496 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.964504 18283 net.cpp:156] Memory required for data: 116637600
I0813 08:28:00.964517 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:00.964529 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:00.964535 18283 layer_factory.hpp:77] Creating layer ReLU9
I0813 08:28:00.964557 18283 net.cpp:91] Creating Layer ReLU9
I0813 08:28:00.964570 18283 net.cpp:425] ReLU9 <- InnerProduct9
I0813 08:28:00.964593 18283 net.cpp:386] ReLU9 -> InnerProduct9 (in-place)
I0813 08:28:00.964615 18283 net.cpp:141] Setting up ReLU9
I0813 08:28:00.964627 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.964632 18283 net.cpp:156] Memory required for data: 116740000
I0813 08:28:00.964640 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:00.964655 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:00.964665 18283 net.cpp:425] drop1 <- InnerProduct9
I0813 08:28:00.964679 18283 net.cpp:399] drop1 -> Dropout9
I0813 08:28:00.964701 18283 net.cpp:141] Setting up drop1
I0813 08:28:00.964712 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.964720 18283 net.cpp:156] Memory required for data: 116842400
I0813 08:28:00.964726 18283 layer_factory.hpp:77] Creating layer InnerProduct10
I0813 08:28:00.964746 18283 net.cpp:91] Creating Layer InnerProduct10
I0813 08:28:00.964754 18283 net.cpp:425] InnerProduct10 <- Dropout9
I0813 08:28:00.964768 18283 net.cpp:399] InnerProduct10 -> InnerProduct10
I0813 08:28:00.965028 18283 net.cpp:141] Setting up InnerProduct10
I0813 08:28:00.965039 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.965045 18283 net.cpp:156] Memory required for data: 116893600
I0813 08:28:00.965054 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:00.965064 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:00.965071 18283 layer_factory.hpp:77] Creating layer ReLU10
I0813 08:28:00.965081 18283 net.cpp:91] Creating Layer ReLU10
I0813 08:28:00.965090 18283 net.cpp:425] ReLU10 <- InnerProduct10
I0813 08:28:00.965101 18283 net.cpp:386] ReLU10 -> InnerProduct10 (in-place)
I0813 08:28:00.965113 18283 net.cpp:141] Setting up ReLU10
I0813 08:28:00.965123 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.965131 18283 net.cpp:156] Memory required for data: 116944800
I0813 08:28:00.965137 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:00.965148 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:00.965157 18283 net.cpp:425] drop2 <- InnerProduct10
I0813 08:28:00.965169 18283 net.cpp:399] drop2 -> Dropout10
I0813 08:28:00.965183 18283 net.cpp:141] Setting up drop2
I0813 08:28:00.965193 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.965199 18283 net.cpp:156] Memory required for data: 116996000
I0813 08:28:00.965206 18283 layer_factory.hpp:77] Creating layer m5
I0813 08:28:00.965224 18283 net.cpp:91] Creating Layer m5
I0813 08:28:00.965232 18283 net.cpp:425] m5 <- Dropout10
I0813 08:28:00.965245 18283 net.cpp:399] m5 -> m5
I0813 08:28:00.965273 18283 net.cpp:141] Setting up m5
I0813 08:28:00.965283 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:00.965289 18283 net.cpp:156] Memory required for data: 116996400
I0813 08:28:00.965297 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:00.965307 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:00.965314 18283 layer_factory.hpp:77] Creating layer Concat6
I0813 08:28:00.965332 18283 net.cpp:91] Creating Layer Concat6
I0813 08:28:00.965340 18283 net.cpp:425] Concat6 <- i1_i1_0_split_5
I0813 08:28:00.965373 18283 net.cpp:425] Concat6 <- i16
I0813 08:28:00.965387 18283 net.cpp:399] Concat6 -> Concat6
I0813 08:28:00.965406 18283 net.cpp:141] Setting up Concat6
I0813 08:28:00.965417 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:00.965425 18283 net.cpp:156] Memory required for data: 120273200
I0813 08:28:00.965431 18283 layer_factory.hpp:77] Creating layer InnerProduct11
I0813 08:28:00.965445 18283 net.cpp:91] Creating Layer InnerProduct11
I0813 08:28:00.965454 18283 net.cpp:425] InnerProduct11 <- Concat6
I0813 08:28:00.965502 18283 net.cpp:399] InnerProduct11 -> InnerProduct11
I0813 08:28:00.982592 18283 net.cpp:141] Setting up InnerProduct11
I0813 08:28:00.982635 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.982642 18283 net.cpp:156] Memory required for data: 120375600
I0813 08:28:00.982655 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:00.982664 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:00.982671 18283 layer_factory.hpp:77] Creating layer ReLU11
I0813 08:28:00.982692 18283 net.cpp:91] Creating Layer ReLU11
I0813 08:28:00.982719 18283 net.cpp:425] ReLU11 <- InnerProduct11
I0813 08:28:00.982734 18283 net.cpp:386] ReLU11 -> InnerProduct11 (in-place)
I0813 08:28:00.982755 18283 net.cpp:141] Setting up ReLU11
I0813 08:28:00.982766 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.982772 18283 net.cpp:156] Memory required for data: 120478000
I0813 08:28:00.982779 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:00.982795 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:00.982805 18283 net.cpp:425] drop1 <- InnerProduct11
I0813 08:28:00.982817 18283 net.cpp:399] drop1 -> Dropout11
I0813 08:28:00.982836 18283 net.cpp:141] Setting up drop1
I0813 08:28:00.982846 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:00.982852 18283 net.cpp:156] Memory required for data: 120580400
I0813 08:28:00.982859 18283 layer_factory.hpp:77] Creating layer InnerProduct12
I0813 08:28:00.982877 18283 net.cpp:91] Creating Layer InnerProduct12
I0813 08:28:00.982887 18283 net.cpp:425] InnerProduct12 <- Dropout11
I0813 08:28:00.982902 18283 net.cpp:399] InnerProduct12 -> InnerProduct12
I0813 08:28:00.983176 18283 net.cpp:141] Setting up InnerProduct12
I0813 08:28:00.983188 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.983194 18283 net.cpp:156] Memory required for data: 120631600
I0813 08:28:00.983216 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:00.983227 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:00.983233 18283 layer_factory.hpp:77] Creating layer ReLU12
I0813 08:28:00.983248 18283 net.cpp:91] Creating Layer ReLU12
I0813 08:28:00.983258 18283 net.cpp:425] ReLU12 <- InnerProduct12
I0813 08:28:00.983271 18283 net.cpp:386] ReLU12 -> InnerProduct12 (in-place)
I0813 08:28:00.983283 18283 net.cpp:141] Setting up ReLU12
I0813 08:28:00.983294 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.983299 18283 net.cpp:156] Memory required for data: 120682800
I0813 08:28:00.983306 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:00.983322 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:00.983331 18283 net.cpp:425] drop2 <- InnerProduct12
I0813 08:28:00.983341 18283 net.cpp:399] drop2 -> Dropout12
I0813 08:28:00.983361 18283 net.cpp:141] Setting up drop2
I0813 08:28:00.983371 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:00.983377 18283 net.cpp:156] Memory required for data: 120734000
I0813 08:28:00.983384 18283 layer_factory.hpp:77] Creating layer m6
I0813 08:28:00.983403 18283 net.cpp:91] Creating Layer m6
I0813 08:28:00.983412 18283 net.cpp:425] m6 <- Dropout12
I0813 08:28:00.983425 18283 net.cpp:399] m6 -> m6
I0813 08:28:00.983455 18283 net.cpp:141] Setting up m6
I0813 08:28:00.983464 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:00.983470 18283 net.cpp:156] Memory required for data: 120734400
I0813 08:28:00.983502 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:00.983513 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:00.983521 18283 layer_factory.hpp:77] Creating layer Concat7
I0813 08:28:00.983541 18283 net.cpp:91] Creating Layer Concat7
I0813 08:28:00.983551 18283 net.cpp:425] Concat7 <- i1_i1_0_split_6
I0813 08:28:00.983561 18283 net.cpp:425] Concat7 <- i17
I0813 08:28:00.983572 18283 net.cpp:399] Concat7 -> Concat7
I0813 08:28:00.983590 18283 net.cpp:141] Setting up Concat7
I0813 08:28:00.983600 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:00.983610 18283 net.cpp:156] Memory required for data: 124011200
I0813 08:28:00.983618 18283 layer_factory.hpp:77] Creating layer InnerProduct13
I0813 08:28:00.983634 18283 net.cpp:91] Creating Layer InnerProduct13
I0813 08:28:00.983642 18283 net.cpp:425] InnerProduct13 <- Concat7
I0813 08:28:00.983652 18283 net.cpp:399] InnerProduct13 -> InnerProduct13
I0813 08:28:01.000309 18283 net.cpp:141] Setting up InnerProduct13
I0813 08:28:01.000356 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.000362 18283 net.cpp:156] Memory required for data: 124113600
I0813 08:28:01.000375 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.000385 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.000392 18283 layer_factory.hpp:77] Creating layer ReLU13
I0813 08:28:01.000413 18283 net.cpp:91] Creating Layer ReLU13
I0813 08:28:01.000424 18283 net.cpp:425] ReLU13 <- InnerProduct13
I0813 08:28:01.000447 18283 net.cpp:386] ReLU13 -> InnerProduct13 (in-place)
I0813 08:28:01.000469 18283 net.cpp:141] Setting up ReLU13
I0813 08:28:01.000478 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.000485 18283 net.cpp:156] Memory required for data: 124216000
I0813 08:28:01.000494 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.000505 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.000515 18283 net.cpp:425] drop1 <- InnerProduct13
I0813 08:28:01.000531 18283 net.cpp:399] drop1 -> Dropout13
I0813 08:28:01.000550 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.000560 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.000567 18283 net.cpp:156] Memory required for data: 124318400
I0813 08:28:01.000574 18283 layer_factory.hpp:77] Creating layer InnerProduct14
I0813 08:28:01.000594 18283 net.cpp:91] Creating Layer InnerProduct14
I0813 08:28:01.000602 18283 net.cpp:425] InnerProduct14 <- Dropout13
I0813 08:28:01.000612 18283 net.cpp:399] InnerProduct14 -> InnerProduct14
I0813 08:28:01.000915 18283 net.cpp:141] Setting up InnerProduct14
I0813 08:28:01.000926 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.000932 18283 net.cpp:156] Memory required for data: 124369600
I0813 08:28:01.000941 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.000949 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.000957 18283 layer_factory.hpp:77] Creating layer ReLU14
I0813 08:28:01.000969 18283 net.cpp:91] Creating Layer ReLU14
I0813 08:28:01.000978 18283 net.cpp:425] ReLU14 <- InnerProduct14
I0813 08:28:01.000988 18283 net.cpp:386] ReLU14 -> InnerProduct14 (in-place)
I0813 08:28:01.000998 18283 net.cpp:141] Setting up ReLU14
I0813 08:28:01.001008 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.001014 18283 net.cpp:156] Memory required for data: 124420800
I0813 08:28:01.001021 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.001031 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.001039 18283 net.cpp:425] drop2 <- InnerProduct14
I0813 08:28:01.001051 18283 net.cpp:399] drop2 -> Dropout14
I0813 08:28:01.001066 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.001076 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.001083 18283 net.cpp:156] Memory required for data: 124472000
I0813 08:28:01.001107 18283 layer_factory.hpp:77] Creating layer m7
I0813 08:28:01.001124 18283 net.cpp:91] Creating Layer m7
I0813 08:28:01.001133 18283 net.cpp:425] m7 <- Dropout14
I0813 08:28:01.001147 18283 net.cpp:399] m7 -> m7
I0813 08:28:01.001173 18283 net.cpp:141] Setting up m7
I0813 08:28:01.001184 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.001190 18283 net.cpp:156] Memory required for data: 124472400
I0813 08:28:01.001199 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.001206 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.001214 18283 layer_factory.hpp:77] Creating layer Concat8
I0813 08:28:01.001230 18283 net.cpp:91] Creating Layer Concat8
I0813 08:28:01.001240 18283 net.cpp:425] Concat8 <- i1_i1_0_split_7
I0813 08:28:01.001251 18283 net.cpp:425] Concat8 <- i18
I0813 08:28:01.001265 18283 net.cpp:399] Concat8 -> Concat8
I0813 08:28:01.001282 18283 net.cpp:141] Setting up Concat8
I0813 08:28:01.001292 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.001298 18283 net.cpp:156] Memory required for data: 127749200
I0813 08:28:01.001305 18283 layer_factory.hpp:77] Creating layer InnerProduct15
I0813 08:28:01.001337 18283 net.cpp:91] Creating Layer InnerProduct15
I0813 08:28:01.001344 18283 net.cpp:425] InnerProduct15 <- Concat8
I0813 08:28:01.001355 18283 net.cpp:399] InnerProduct15 -> InnerProduct15
I0813 08:28:01.017762 18283 net.cpp:141] Setting up InnerProduct15
I0813 08:28:01.017803 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.017809 18283 net.cpp:156] Memory required for data: 127851600
I0813 08:28:01.017822 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.017830 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.017839 18283 layer_factory.hpp:77] Creating layer ReLU15
I0813 08:28:01.017863 18283 net.cpp:91] Creating Layer ReLU15
I0813 08:28:01.017884 18283 net.cpp:425] ReLU15 <- InnerProduct15
I0813 08:28:01.017896 18283 net.cpp:386] ReLU15 -> InnerProduct15 (in-place)
I0813 08:28:01.017915 18283 net.cpp:141] Setting up ReLU15
I0813 08:28:01.017925 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.017931 18283 net.cpp:156] Memory required for data: 127954000
I0813 08:28:01.017938 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.017951 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.017962 18283 net.cpp:425] drop1 <- InnerProduct15
I0813 08:28:01.017978 18283 net.cpp:399] drop1 -> Dropout15
I0813 08:28:01.017997 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.018007 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.018014 18283 net.cpp:156] Memory required for data: 128056400
I0813 08:28:01.018021 18283 layer_factory.hpp:77] Creating layer InnerProduct16
I0813 08:28:01.018041 18283 net.cpp:91] Creating Layer InnerProduct16
I0813 08:28:01.018049 18283 net.cpp:425] InnerProduct16 <- Dropout15
I0813 08:28:01.018059 18283 net.cpp:399] InnerProduct16 -> InnerProduct16
I0813 08:28:01.018344 18283 net.cpp:141] Setting up InnerProduct16
I0813 08:28:01.018357 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.018362 18283 net.cpp:156] Memory required for data: 128107600
I0813 08:28:01.018370 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.018378 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.018386 18283 layer_factory.hpp:77] Creating layer ReLU16
I0813 08:28:01.018396 18283 net.cpp:91] Creating Layer ReLU16
I0813 08:28:01.018405 18283 net.cpp:425] ReLU16 <- InnerProduct16
I0813 08:28:01.018417 18283 net.cpp:386] ReLU16 -> InnerProduct16 (in-place)
I0813 08:28:01.018429 18283 net.cpp:141] Setting up ReLU16
I0813 08:28:01.018438 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.018445 18283 net.cpp:156] Memory required for data: 128158800
I0813 08:28:01.018473 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.018484 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.018491 18283 net.cpp:425] drop2 <- InnerProduct16
I0813 08:28:01.018501 18283 net.cpp:399] drop2 -> Dropout16
I0813 08:28:01.018515 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.018532 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.018542 18283 net.cpp:156] Memory required for data: 128210000
I0813 08:28:01.018548 18283 layer_factory.hpp:77] Creating layer m8
I0813 08:28:01.018560 18283 net.cpp:91] Creating Layer m8
I0813 08:28:01.018569 18283 net.cpp:425] m8 <- Dropout16
I0813 08:28:01.018584 18283 net.cpp:399] m8 -> m8
I0813 08:28:01.018612 18283 net.cpp:141] Setting up m8
I0813 08:28:01.018622 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.018628 18283 net.cpp:156] Memory required for data: 128210400
I0813 08:28:01.018635 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.018645 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.018651 18283 layer_factory.hpp:77] Creating layer Concat9
I0813 08:28:01.018663 18283 net.cpp:91] Creating Layer Concat9
I0813 08:28:01.018673 18283 net.cpp:425] Concat9 <- i1_i1_0_split_8
I0813 08:28:01.018684 18283 net.cpp:425] Concat9 <- i19
I0813 08:28:01.018699 18283 net.cpp:399] Concat9 -> Concat9
I0813 08:28:01.018718 18283 net.cpp:141] Setting up Concat9
I0813 08:28:01.018728 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.018733 18283 net.cpp:156] Memory required for data: 131487200
I0813 08:28:01.018740 18283 layer_factory.hpp:77] Creating layer InnerProduct17
I0813 08:28:01.018753 18283 net.cpp:91] Creating Layer InnerProduct17
I0813 08:28:01.018761 18283 net.cpp:425] InnerProduct17 <- Concat9
I0813 08:28:01.018775 18283 net.cpp:399] InnerProduct17 -> InnerProduct17
I0813 08:28:01.034945 18283 net.cpp:141] Setting up InnerProduct17
I0813 08:28:01.034992 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.034998 18283 net.cpp:156] Memory required for data: 131589600
I0813 08:28:01.035012 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.035022 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.035029 18283 layer_factory.hpp:77] Creating layer ReLU17
I0813 08:28:01.035050 18283 net.cpp:91] Creating Layer ReLU17
I0813 08:28:01.035063 18283 net.cpp:425] ReLU17 <- InnerProduct17
I0813 08:28:01.035095 18283 net.cpp:386] ReLU17 -> InnerProduct17 (in-place)
I0813 08:28:01.035117 18283 net.cpp:141] Setting up ReLU17
I0813 08:28:01.035127 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.035135 18283 net.cpp:156] Memory required for data: 131692000
I0813 08:28:01.035141 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.035156 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.035164 18283 net.cpp:425] drop1 <- InnerProduct17
I0813 08:28:01.035182 18283 net.cpp:399] drop1 -> Dropout17
I0813 08:28:01.035202 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.035213 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.035219 18283 net.cpp:156] Memory required for data: 131794400
I0813 08:28:01.035226 18283 layer_factory.hpp:77] Creating layer InnerProduct18
I0813 08:28:01.035244 18283 net.cpp:91] Creating Layer InnerProduct18
I0813 08:28:01.035251 18283 net.cpp:425] InnerProduct18 <- Dropout17
I0813 08:28:01.035266 18283 net.cpp:399] InnerProduct18 -> InnerProduct18
I0813 08:28:01.035581 18283 net.cpp:141] Setting up InnerProduct18
I0813 08:28:01.035596 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.035603 18283 net.cpp:156] Memory required for data: 131845600
I0813 08:28:01.035612 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.035621 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.035629 18283 layer_factory.hpp:77] Creating layer ReLU18
I0813 08:28:01.035666 18283 net.cpp:91] Creating Layer ReLU18
I0813 08:28:01.035676 18283 net.cpp:425] ReLU18 <- InnerProduct18
I0813 08:28:01.035691 18283 net.cpp:386] ReLU18 -> InnerProduct18 (in-place)
I0813 08:28:01.035706 18283 net.cpp:141] Setting up ReLU18
I0813 08:28:01.035715 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.035723 18283 net.cpp:156] Memory required for data: 131896800
I0813 08:28:01.035729 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.035742 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.035750 18283 net.cpp:425] drop2 <- InnerProduct18
I0813 08:28:01.035760 18283 net.cpp:399] drop2 -> Dropout18
I0813 08:28:01.035780 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.035790 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.035797 18283 net.cpp:156] Memory required for data: 131948000
I0813 08:28:01.035804 18283 layer_factory.hpp:77] Creating layer m9
I0813 08:28:01.035820 18283 net.cpp:91] Creating Layer m9
I0813 08:28:01.035828 18283 net.cpp:425] m9 <- Dropout18
I0813 08:28:01.035843 18283 net.cpp:399] m9 -> m9
I0813 08:28:01.035876 18283 net.cpp:141] Setting up m9
I0813 08:28:01.035886 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.035892 18283 net.cpp:156] Memory required for data: 131948400
I0813 08:28:01.035900 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.035908 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.035917 18283 layer_factory.hpp:77] Creating layer Concat10
I0813 08:28:01.035928 18283 net.cpp:91] Creating Layer Concat10
I0813 08:28:01.035938 18283 net.cpp:425] Concat10 <- i1_i1_0_split_9
I0813 08:28:01.035949 18283 net.cpp:425] Concat10 <- i20
I0813 08:28:01.035965 18283 net.cpp:399] Concat10 -> Concat10
I0813 08:28:01.035984 18283 net.cpp:141] Setting up Concat10
I0813 08:28:01.035995 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.036000 18283 net.cpp:156] Memory required for data: 135225200
I0813 08:28:01.036007 18283 layer_factory.hpp:77] Creating layer InnerProduct19
I0813 08:28:01.036022 18283 net.cpp:91] Creating Layer InnerProduct19
I0813 08:28:01.036053 18283 net.cpp:425] InnerProduct19 <- Concat10
I0813 08:28:01.036068 18283 net.cpp:399] InnerProduct19 -> InnerProduct19
I0813 08:28:01.052986 18283 net.cpp:141] Setting up InnerProduct19
I0813 08:28:01.053028 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.053035 18283 net.cpp:156] Memory required for data: 135327600
I0813 08:28:01.053047 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.053056 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.053063 18283 layer_factory.hpp:77] Creating layer ReLU19
I0813 08:28:01.053083 18283 net.cpp:91] Creating Layer ReLU19
I0813 08:28:01.053095 18283 net.cpp:425] ReLU19 <- InnerProduct19
I0813 08:28:01.053120 18283 net.cpp:386] ReLU19 -> InnerProduct19 (in-place)
I0813 08:28:01.053143 18283 net.cpp:141] Setting up ReLU19
I0813 08:28:01.053153 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.053158 18283 net.cpp:156] Memory required for data: 135430000
I0813 08:28:01.053165 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.053179 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.053189 18283 net.cpp:425] drop1 <- InnerProduct19
I0813 08:28:01.053202 18283 net.cpp:399] drop1 -> Dropout19
I0813 08:28:01.053222 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.053232 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.053239 18283 net.cpp:156] Memory required for data: 135532400
I0813 08:28:01.053246 18283 layer_factory.hpp:77] Creating layer InnerProduct20
I0813 08:28:01.053267 18283 net.cpp:91] Creating Layer InnerProduct20
I0813 08:28:01.053274 18283 net.cpp:425] InnerProduct20 <- Dropout19
I0813 08:28:01.053288 18283 net.cpp:399] InnerProduct20 -> InnerProduct20
I0813 08:28:01.053586 18283 net.cpp:141] Setting up InnerProduct20
I0813 08:28:01.053597 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.053628 18283 net.cpp:156] Memory required for data: 135583600
I0813 08:28:01.053637 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.053650 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.053659 18283 layer_factory.hpp:77] Creating layer ReLU20
I0813 08:28:01.053669 18283 net.cpp:91] Creating Layer ReLU20
I0813 08:28:01.053678 18283 net.cpp:425] ReLU20 <- InnerProduct20
I0813 08:28:01.053689 18283 net.cpp:386] ReLU20 -> InnerProduct20 (in-place)
I0813 08:28:01.053704 18283 net.cpp:141] Setting up ReLU20
I0813 08:28:01.053712 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.053719 18283 net.cpp:156] Memory required for data: 135634800
I0813 08:28:01.053725 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.053741 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.053750 18283 net.cpp:425] drop2 <- InnerProduct20
I0813 08:28:01.053761 18283 net.cpp:399] drop2 -> Dropout20
I0813 08:28:01.053774 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.053784 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.053791 18283 net.cpp:156] Memory required for data: 135686000
I0813 08:28:01.053797 18283 layer_factory.hpp:77] Creating layer m10
I0813 08:28:01.053814 18283 net.cpp:91] Creating Layer m10
I0813 08:28:01.053828 18283 net.cpp:425] m10 <- Dropout20
I0813 08:28:01.053841 18283 net.cpp:399] m10 -> m10
I0813 08:28:01.053876 18283 net.cpp:141] Setting up m10
I0813 08:28:01.053886 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.053891 18283 net.cpp:156] Memory required for data: 135686400
I0813 08:28:01.053900 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.053911 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.053918 18283 layer_factory.hpp:77] Creating layer Concat11
I0813 08:28:01.053931 18283 net.cpp:91] Creating Layer Concat11
I0813 08:28:01.053941 18283 net.cpp:425] Concat11 <- i2
I0813 08:28:01.053952 18283 net.cpp:425] Concat11 <- i11_i1_10_split_1
I0813 08:28:01.053968 18283 net.cpp:399] Concat11 -> Concat11
I0813 08:28:01.053987 18283 net.cpp:141] Setting up Concat11
I0813 08:28:01.053999 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.054005 18283 net.cpp:156] Memory required for data: 138963200
I0813 08:28:01.054013 18283 layer_factory.hpp:77] Creating layer InnerProduct21
I0813 08:28:01.054028 18283 net.cpp:91] Creating Layer InnerProduct21
I0813 08:28:01.054035 18283 net.cpp:425] InnerProduct21 <- Concat11
I0813 08:28:01.054050 18283 net.cpp:399] InnerProduct21 -> InnerProduct21
I0813 08:28:01.070482 18283 net.cpp:141] Setting up InnerProduct21
I0813 08:28:01.070524 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.070530 18283 net.cpp:156] Memory required for data: 139065600
I0813 08:28:01.070543 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.070552 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.070559 18283 layer_factory.hpp:77] Creating layer ReLU21
I0813 08:28:01.070577 18283 net.cpp:91] Creating Layer ReLU21
I0813 08:28:01.070590 18283 net.cpp:425] ReLU21 <- InnerProduct21
I0813 08:28:01.070607 18283 net.cpp:386] ReLU21 -> InnerProduct21 (in-place)
I0813 08:28:01.070631 18283 net.cpp:141] Setting up ReLU21
I0813 08:28:01.070642 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.070649 18283 net.cpp:156] Memory required for data: 139168000
I0813 08:28:01.070657 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.070669 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.070680 18283 net.cpp:425] drop1 <- InnerProduct21
I0813 08:28:01.070703 18283 net.cpp:399] drop1 -> Dropout21
I0813 08:28:01.070722 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.070734 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.070740 18283 net.cpp:156] Memory required for data: 139270400
I0813 08:28:01.070772 18283 layer_factory.hpp:77] Creating layer InnerProduct22
I0813 08:28:01.070790 18283 net.cpp:91] Creating Layer InnerProduct22
I0813 08:28:01.070799 18283 net.cpp:425] InnerProduct22 <- Dropout21
I0813 08:28:01.070814 18283 net.cpp:399] InnerProduct22 -> InnerProduct22
I0813 08:28:01.071107 18283 net.cpp:141] Setting up InnerProduct22
I0813 08:28:01.071118 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.071125 18283 net.cpp:156] Memory required for data: 139321600
I0813 08:28:01.071133 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.071142 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.071149 18283 layer_factory.hpp:77] Creating layer ReLU22
I0813 08:28:01.071159 18283 net.cpp:91] Creating Layer ReLU22
I0813 08:28:01.071166 18283 net.cpp:425] ReLU22 <- InnerProduct22
I0813 08:28:01.071176 18283 net.cpp:386] ReLU22 -> InnerProduct22 (in-place)
I0813 08:28:01.071187 18283 net.cpp:141] Setting up ReLU22
I0813 08:28:01.071197 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.071202 18283 net.cpp:156] Memory required for data: 139372800
I0813 08:28:01.071209 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.071223 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.071231 18283 net.cpp:425] drop2 <- InnerProduct22
I0813 08:28:01.071241 18283 net.cpp:399] drop2 -> Dropout22
I0813 08:28:01.071254 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.071269 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.071276 18283 net.cpp:156] Memory required for data: 139424000
I0813 08:28:01.071282 18283 layer_factory.hpp:77] Creating layer m11
I0813 08:28:01.071295 18283 net.cpp:91] Creating Layer m11
I0813 08:28:01.071305 18283 net.cpp:425] m11 <- Dropout22
I0813 08:28:01.071319 18283 net.cpp:399] m11 -> m11
I0813 08:28:01.071346 18283 net.cpp:141] Setting up m11
I0813 08:28:01.071355 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.071362 18283 net.cpp:156] Memory required for data: 139424400
I0813 08:28:01.071388 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.071398 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.071404 18283 layer_factory.hpp:77] Creating layer Concat12
I0813 08:28:01.071419 18283 net.cpp:91] Creating Layer Concat12
I0813 08:28:01.071429 18283 net.cpp:425] Concat12 <- i3
I0813 08:28:01.071440 18283 net.cpp:425] Concat12 <- i11_i1_10_split_2
I0813 08:28:01.071452 18283 net.cpp:399] Concat12 -> Concat12
I0813 08:28:01.071470 18283 net.cpp:141] Setting up Concat12
I0813 08:28:01.071478 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.071485 18283 net.cpp:156] Memory required for data: 142701200
I0813 08:28:01.071491 18283 layer_factory.hpp:77] Creating layer InnerProduct23
I0813 08:28:01.071504 18283 net.cpp:91] Creating Layer InnerProduct23
I0813 08:28:01.071513 18283 net.cpp:425] InnerProduct23 <- Concat12
I0813 08:28:01.071527 18283 net.cpp:399] InnerProduct23 -> InnerProduct23
I0813 08:28:01.088199 18283 net.cpp:141] Setting up InnerProduct23
I0813 08:28:01.088244 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.088250 18283 net.cpp:156] Memory required for data: 142803600
I0813 08:28:01.088263 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.088273 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.088280 18283 layer_factory.hpp:77] Creating layer ReLU23
I0813 08:28:01.088304 18283 net.cpp:91] Creating Layer ReLU23
I0813 08:28:01.088316 18283 net.cpp:425] ReLU23 <- InnerProduct23
I0813 08:28:01.088342 18283 net.cpp:386] ReLU23 -> InnerProduct23 (in-place)
I0813 08:28:01.088361 18283 net.cpp:141] Setting up ReLU23
I0813 08:28:01.088371 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.088378 18283 net.cpp:156] Memory required for data: 142906000
I0813 08:28:01.088410 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.088424 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.088438 18283 net.cpp:425] drop1 <- InnerProduct23
I0813 08:28:01.088451 18283 net.cpp:399] drop1 -> Dropout23
I0813 08:28:01.088471 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.088481 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.088487 18283 net.cpp:156] Memory required for data: 143008400
I0813 08:28:01.088495 18283 layer_factory.hpp:77] Creating layer InnerProduct24
I0813 08:28:01.088510 18283 net.cpp:91] Creating Layer InnerProduct24
I0813 08:28:01.088518 18283 net.cpp:425] InnerProduct24 <- Dropout23
I0813 08:28:01.088533 18283 net.cpp:399] InnerProduct24 -> InnerProduct24
I0813 08:28:01.088832 18283 net.cpp:141] Setting up InnerProduct24
I0813 08:28:01.088845 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.088850 18283 net.cpp:156] Memory required for data: 143059600
I0813 08:28:01.088858 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.088867 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.088874 18283 layer_factory.hpp:77] Creating layer ReLU24
I0813 08:28:01.088886 18283 net.cpp:91] Creating Layer ReLU24
I0813 08:28:01.088893 18283 net.cpp:425] ReLU24 <- InnerProduct24
I0813 08:28:01.088906 18283 net.cpp:386] ReLU24 -> InnerProduct24 (in-place)
I0813 08:28:01.088917 18283 net.cpp:141] Setting up ReLU24
I0813 08:28:01.088925 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.088932 18283 net.cpp:156] Memory required for data: 143110800
I0813 08:28:01.088937 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.088946 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.088953 18283 net.cpp:425] drop2 <- InnerProduct24
I0813 08:28:01.088965 18283 net.cpp:399] drop2 -> Dropout24
I0813 08:28:01.088982 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.088991 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.088997 18283 net.cpp:156] Memory required for data: 143162000
I0813 08:28:01.089004 18283 layer_factory.hpp:77] Creating layer m12
I0813 08:28:01.089017 18283 net.cpp:91] Creating Layer m12
I0813 08:28:01.089025 18283 net.cpp:425] m12 <- Dropout24
I0813 08:28:01.089040 18283 net.cpp:399] m12 -> m12
I0813 08:28:01.089064 18283 net.cpp:141] Setting up m12
I0813 08:28:01.089073 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.089079 18283 net.cpp:156] Memory required for data: 143162400
I0813 08:28:01.089087 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.089095 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.089102 18283 layer_factory.hpp:77] Creating layer Concat13
I0813 08:28:01.089114 18283 net.cpp:91] Creating Layer Concat13
I0813 08:28:01.089123 18283 net.cpp:425] Concat13 <- i4
I0813 08:28:01.089133 18283 net.cpp:425] Concat13 <- i11_i1_10_split_3
I0813 08:28:01.089148 18283 net.cpp:399] Concat13 -> Concat13
I0813 08:28:01.089164 18283 net.cpp:141] Setting up Concat13
I0813 08:28:01.089174 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.089181 18283 net.cpp:156] Memory required for data: 146439200
I0813 08:28:01.089189 18283 layer_factory.hpp:77] Creating layer InnerProduct25
I0813 08:28:01.089206 18283 net.cpp:91] Creating Layer InnerProduct25
I0813 08:28:01.089215 18283 net.cpp:425] InnerProduct25 <- Concat13
I0813 08:28:01.089224 18283 net.cpp:399] InnerProduct25 -> InnerProduct25
I0813 08:28:01.105451 18283 net.cpp:141] Setting up InnerProduct25
I0813 08:28:01.105494 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.105500 18283 net.cpp:156] Memory required for data: 146541600
I0813 08:28:01.105512 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.105522 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.105530 18283 layer_factory.hpp:77] Creating layer ReLU25
I0813 08:28:01.105589 18283 net.cpp:91] Creating Layer ReLU25
I0813 08:28:01.105602 18283 net.cpp:425] ReLU25 <- InnerProduct25
I0813 08:28:01.105617 18283 net.cpp:386] ReLU25 -> InnerProduct25 (in-place)
I0813 08:28:01.105640 18283 net.cpp:141] Setting up ReLU25
I0813 08:28:01.105650 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.105656 18283 net.cpp:156] Memory required for data: 146644000
I0813 08:28:01.105667 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.105681 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.105692 18283 net.cpp:425] drop1 <- InnerProduct25
I0813 08:28:01.105708 18283 net.cpp:399] drop1 -> Dropout25
I0813 08:28:01.105729 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.105741 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.105751 18283 net.cpp:156] Memory required for data: 146746400
I0813 08:28:01.105757 18283 layer_factory.hpp:77] Creating layer InnerProduct26
I0813 08:28:01.105777 18283 net.cpp:91] Creating Layer InnerProduct26
I0813 08:28:01.105784 18283 net.cpp:425] InnerProduct26 <- Dropout25
I0813 08:28:01.105795 18283 net.cpp:399] InnerProduct26 -> InnerProduct26
I0813 08:28:01.106084 18283 net.cpp:141] Setting up InnerProduct26
I0813 08:28:01.106096 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.106102 18283 net.cpp:156] Memory required for data: 146797600
I0813 08:28:01.106111 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.106118 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.106125 18283 layer_factory.hpp:77] Creating layer ReLU26
I0813 08:28:01.106137 18283 net.cpp:91] Creating Layer ReLU26
I0813 08:28:01.106145 18283 net.cpp:425] ReLU26 <- InnerProduct26
I0813 08:28:01.106154 18283 net.cpp:386] ReLU26 -> InnerProduct26 (in-place)
I0813 08:28:01.106165 18283 net.cpp:141] Setting up ReLU26
I0813 08:28:01.106175 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.106181 18283 net.cpp:156] Memory required for data: 146848800
I0813 08:28:01.106189 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.106199 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.106206 18283 net.cpp:425] drop2 <- InnerProduct26
I0813 08:28:01.106220 18283 net.cpp:399] drop2 -> Dropout26
I0813 08:28:01.106235 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.106245 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.106251 18283 net.cpp:156] Memory required for data: 146900000
I0813 08:28:01.106257 18283 layer_factory.hpp:77] Creating layer m13
I0813 08:28:01.106273 18283 net.cpp:91] Creating Layer m13
I0813 08:28:01.106281 18283 net.cpp:425] m13 <- Dropout26
I0813 08:28:01.106293 18283 net.cpp:399] m13 -> m13
I0813 08:28:01.106317 18283 net.cpp:141] Setting up m13
I0813 08:28:01.106326 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.106333 18283 net.cpp:156] Memory required for data: 146900400
I0813 08:28:01.106340 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.106348 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.106355 18283 layer_factory.hpp:77] Creating layer Concat14
I0813 08:28:01.106371 18283 net.cpp:91] Creating Layer Concat14
I0813 08:28:01.106379 18283 net.cpp:425] Concat14 <- i5
I0813 08:28:01.106390 18283 net.cpp:425] Concat14 <- i11_i1_10_split_4
I0813 08:28:01.106403 18283 net.cpp:399] Concat14 -> Concat14
I0813 08:28:01.106420 18283 net.cpp:141] Setting up Concat14
I0813 08:28:01.106429 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.106436 18283 net.cpp:156] Memory required for data: 150177200
I0813 08:28:01.106442 18283 layer_factory.hpp:77] Creating layer InnerProduct27
I0813 08:28:01.106458 18283 net.cpp:91] Creating Layer InnerProduct27
I0813 08:28:01.106467 18283 net.cpp:425] InnerProduct27 <- Concat14
I0813 08:28:01.106477 18283 net.cpp:399] InnerProduct27 -> InnerProduct27
I0813 08:28:01.122503 18283 net.cpp:141] Setting up InnerProduct27
I0813 08:28:01.122572 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.122586 18283 net.cpp:156] Memory required for data: 150279600
I0813 08:28:01.122598 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.122608 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.122617 18283 layer_factory.hpp:77] Creating layer ReLU27
I0813 08:28:01.122642 18283 net.cpp:91] Creating Layer ReLU27
I0813 08:28:01.122658 18283 net.cpp:425] ReLU27 <- InnerProduct27
I0813 08:28:01.122670 18283 net.cpp:386] ReLU27 -> InnerProduct27 (in-place)
I0813 08:28:01.122692 18283 net.cpp:141] Setting up ReLU27
I0813 08:28:01.122702 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.122709 18283 net.cpp:156] Memory required for data: 150382000
I0813 08:28:01.122715 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.122732 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.122740 18283 net.cpp:425] drop1 <- InnerProduct27
I0813 08:28:01.122751 18283 net.cpp:399] drop1 -> Dropout27
I0813 08:28:01.122773 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.122782 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.122788 18283 net.cpp:156] Memory required for data: 150484400
I0813 08:28:01.122794 18283 layer_factory.hpp:77] Creating layer InnerProduct28
I0813 08:28:01.122814 18283 net.cpp:91] Creating Layer InnerProduct28
I0813 08:28:01.122822 18283 net.cpp:425] InnerProduct28 <- Dropout27
I0813 08:28:01.122836 18283 net.cpp:399] InnerProduct28 -> InnerProduct28
I0813 08:28:01.123152 18283 net.cpp:141] Setting up InnerProduct28
I0813 08:28:01.123165 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.123172 18283 net.cpp:156] Memory required for data: 150535600
I0813 08:28:01.123179 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.123188 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.123196 18283 layer_factory.hpp:77] Creating layer ReLU28
I0813 08:28:01.123206 18283 net.cpp:91] Creating Layer ReLU28
I0813 08:28:01.123214 18283 net.cpp:425] ReLU28 <- InnerProduct28
I0813 08:28:01.123226 18283 net.cpp:386] ReLU28 -> InnerProduct28 (in-place)
I0813 08:28:01.123239 18283 net.cpp:141] Setting up ReLU28
I0813 08:28:01.123247 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.123253 18283 net.cpp:156] Memory required for data: 150586800
I0813 08:28:01.123260 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.123270 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.123277 18283 net.cpp:425] drop2 <- InnerProduct28
I0813 08:28:01.123289 18283 net.cpp:399] drop2 -> Dropout28
I0813 08:28:01.123304 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.123313 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.123319 18283 net.cpp:156] Memory required for data: 150638000
I0813 08:28:01.123327 18283 layer_factory.hpp:77] Creating layer m14
I0813 08:28:01.123339 18283 net.cpp:91] Creating Layer m14
I0813 08:28:01.123347 18283 net.cpp:425] m14 <- Dropout28
I0813 08:28:01.123360 18283 net.cpp:399] m14 -> m14
I0813 08:28:01.123386 18283 net.cpp:141] Setting up m14
I0813 08:28:01.123395 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.123401 18283 net.cpp:156] Memory required for data: 150638400
I0813 08:28:01.123409 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.123417 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.123425 18283 layer_factory.hpp:77] Creating layer Concat15
I0813 08:28:01.123437 18283 net.cpp:91] Creating Layer Concat15
I0813 08:28:01.123446 18283 net.cpp:425] Concat15 <- i6
I0813 08:28:01.123456 18283 net.cpp:425] Concat15 <- i11_i1_10_split_5
I0813 08:28:01.123471 18283 net.cpp:399] Concat15 -> Concat15
I0813 08:28:01.123488 18283 net.cpp:141] Setting up Concat15
I0813 08:28:01.123497 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.123517 18283 net.cpp:156] Memory required for data: 153915200
I0813 08:28:01.123524 18283 layer_factory.hpp:77] Creating layer InnerProduct29
I0813 08:28:01.123540 18283 net.cpp:91] Creating Layer InnerProduct29
I0813 08:28:01.123548 18283 net.cpp:425] InnerProduct29 <- Concat15
I0813 08:28:01.123559 18283 net.cpp:399] InnerProduct29 -> InnerProduct29
I0813 08:28:01.139685 18283 net.cpp:141] Setting up InnerProduct29
I0813 08:28:01.139729 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.139736 18283 net.cpp:156] Memory required for data: 154017600
I0813 08:28:01.139750 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.139758 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.139766 18283 layer_factory.hpp:77] Creating layer ReLU29
I0813 08:28:01.139787 18283 net.cpp:91] Creating Layer ReLU29
I0813 08:28:01.139799 18283 net.cpp:425] ReLU29 <- InnerProduct29
I0813 08:28:01.139817 18283 net.cpp:386] ReLU29 -> InnerProduct29 (in-place)
I0813 08:28:01.139838 18283 net.cpp:141] Setting up ReLU29
I0813 08:28:01.139847 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.139853 18283 net.cpp:156] Memory required for data: 154120000
I0813 08:28:01.139860 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.139873 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.139884 18283 net.cpp:425] drop1 <- InnerProduct29
I0813 08:28:01.139900 18283 net.cpp:399] drop1 -> Dropout29
I0813 08:28:01.139919 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.139930 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.139936 18283 net.cpp:156] Memory required for data: 154222400
I0813 08:28:01.139942 18283 layer_factory.hpp:77] Creating layer InnerProduct30
I0813 08:28:01.139962 18283 net.cpp:91] Creating Layer InnerProduct30
I0813 08:28:01.139971 18283 net.cpp:425] InnerProduct30 <- Dropout29
I0813 08:28:01.139983 18283 net.cpp:399] InnerProduct30 -> InnerProduct30
I0813 08:28:01.140287 18283 net.cpp:141] Setting up InnerProduct30
I0813 08:28:01.140367 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.140377 18283 net.cpp:156] Memory required for data: 154273600
I0813 08:28:01.140385 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.140394 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.140403 18283 layer_factory.hpp:77] Creating layer ReLU30
I0813 08:28:01.140415 18283 net.cpp:91] Creating Layer ReLU30
I0813 08:28:01.140425 18283 net.cpp:425] ReLU30 <- InnerProduct30
I0813 08:28:01.140434 18283 net.cpp:386] ReLU30 -> InnerProduct30 (in-place)
I0813 08:28:01.140446 18283 net.cpp:141] Setting up ReLU30
I0813 08:28:01.140455 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.140462 18283 net.cpp:156] Memory required for data: 154324800
I0813 08:28:01.140470 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.140480 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.140486 18283 net.cpp:425] drop2 <- InnerProduct30
I0813 08:28:01.140499 18283 net.cpp:399] drop2 -> Dropout30
I0813 08:28:01.140514 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.140524 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.140530 18283 net.cpp:156] Memory required for data: 154376000
I0813 08:28:01.140537 18283 layer_factory.hpp:77] Creating layer m15
I0813 08:28:01.140552 18283 net.cpp:91] Creating Layer m15
I0813 08:28:01.140560 18283 net.cpp:425] m15 <- Dropout30
I0813 08:28:01.140573 18283 net.cpp:399] m15 -> m15
I0813 08:28:01.140597 18283 net.cpp:141] Setting up m15
I0813 08:28:01.140606 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.140614 18283 net.cpp:156] Memory required for data: 154376400
I0813 08:28:01.140620 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.140630 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.140657 18283 layer_factory.hpp:77] Creating layer Concat16
I0813 08:28:01.140674 18283 net.cpp:91] Creating Layer Concat16
I0813 08:28:01.140683 18283 net.cpp:425] Concat16 <- i7
I0813 08:28:01.140693 18283 net.cpp:425] Concat16 <- i11_i1_10_split_6
I0813 08:28:01.140707 18283 net.cpp:399] Concat16 -> Concat16
I0813 08:28:01.140727 18283 net.cpp:141] Setting up Concat16
I0813 08:28:01.140735 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.140741 18283 net.cpp:156] Memory required for data: 157653200
I0813 08:28:01.140748 18283 layer_factory.hpp:77] Creating layer InnerProduct31
I0813 08:28:01.140789 18283 net.cpp:91] Creating Layer InnerProduct31
I0813 08:28:01.140796 18283 net.cpp:425] InnerProduct31 <- Concat16
I0813 08:28:01.140810 18283 net.cpp:399] InnerProduct31 -> InnerProduct31
I0813 08:28:01.156802 18283 net.cpp:141] Setting up InnerProduct31
I0813 08:28:01.156841 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.156847 18283 net.cpp:156] Memory required for data: 157755600
I0813 08:28:01.156859 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.156869 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.156878 18283 layer_factory.hpp:77] Creating layer ReLU31
I0813 08:28:01.156899 18283 net.cpp:91] Creating Layer ReLU31
I0813 08:28:01.156918 18283 net.cpp:425] ReLU31 <- InnerProduct31
I0813 08:28:01.156941 18283 net.cpp:386] ReLU31 -> InnerProduct31 (in-place)
I0813 08:28:01.156962 18283 net.cpp:141] Setting up ReLU31
I0813 08:28:01.156972 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.156980 18283 net.cpp:156] Memory required for data: 157858000
I0813 08:28:01.156986 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.157001 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.157009 18283 net.cpp:425] drop1 <- InnerProduct31
I0813 08:28:01.157024 18283 net.cpp:399] drop1 -> Dropout31
I0813 08:28:01.157045 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.157055 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.157061 18283 net.cpp:156] Memory required for data: 157960400
I0813 08:28:01.157068 18283 layer_factory.hpp:77] Creating layer InnerProduct32
I0813 08:28:01.157086 18283 net.cpp:91] Creating Layer InnerProduct32
I0813 08:28:01.157096 18283 net.cpp:425] InnerProduct32 <- Dropout31
I0813 08:28:01.157111 18283 net.cpp:399] InnerProduct32 -> InnerProduct32
I0813 08:28:01.157405 18283 net.cpp:141] Setting up InnerProduct32
I0813 08:28:01.157416 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.157423 18283 net.cpp:156] Memory required for data: 158011600
I0813 08:28:01.157430 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.157439 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.157447 18283 layer_factory.hpp:77] Creating layer ReLU32
I0813 08:28:01.157459 18283 net.cpp:91] Creating Layer ReLU32
I0813 08:28:01.157466 18283 net.cpp:425] ReLU32 <- InnerProduct32
I0813 08:28:01.157475 18283 net.cpp:386] ReLU32 -> InnerProduct32 (in-place)
I0813 08:28:01.157487 18283 net.cpp:141] Setting up ReLU32
I0813 08:28:01.157498 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.157505 18283 net.cpp:156] Memory required for data: 158062800
I0813 08:28:01.157511 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.157528 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.157538 18283 net.cpp:425] drop2 <- InnerProduct32
I0813 08:28:01.157548 18283 net.cpp:399] drop2 -> Dropout32
I0813 08:28:01.157562 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.157575 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.157584 18283 net.cpp:156] Memory required for data: 158114000
I0813 08:28:01.157591 18283 layer_factory.hpp:77] Creating layer m16
I0813 08:28:01.157604 18283 net.cpp:91] Creating Layer m16
I0813 08:28:01.157613 18283 net.cpp:425] m16 <- Dropout32
I0813 08:28:01.157629 18283 net.cpp:399] m16 -> m16
I0813 08:28:01.157675 18283 net.cpp:141] Setting up m16
I0813 08:28:01.157686 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.157692 18283 net.cpp:156] Memory required for data: 158114400
I0813 08:28:01.157701 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.157708 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.157716 18283 layer_factory.hpp:77] Creating layer Concat17
I0813 08:28:01.157729 18283 net.cpp:91] Creating Layer Concat17
I0813 08:28:01.157739 18283 net.cpp:425] Concat17 <- i8
I0813 08:28:01.157750 18283 net.cpp:425] Concat17 <- i11_i1_10_split_7
I0813 08:28:01.157763 18283 net.cpp:399] Concat17 -> Concat17
I0813 08:28:01.157780 18283 net.cpp:141] Setting up Concat17
I0813 08:28:01.157789 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.157795 18283 net.cpp:156] Memory required for data: 161391200
I0813 08:28:01.157802 18283 layer_factory.hpp:77] Creating layer InnerProduct33
I0813 08:28:01.157819 18283 net.cpp:91] Creating Layer InnerProduct33
I0813 08:28:01.157826 18283 net.cpp:425] InnerProduct33 <- Concat17
I0813 08:28:01.157840 18283 net.cpp:399] InnerProduct33 -> InnerProduct33
I0813 08:28:01.174221 18283 net.cpp:141] Setting up InnerProduct33
I0813 08:28:01.174262 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.174268 18283 net.cpp:156] Memory required for data: 161493600
I0813 08:28:01.174280 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.174289 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.174299 18283 layer_factory.hpp:77] Creating layer ReLU33
I0813 08:28:01.174321 18283 net.cpp:91] Creating Layer ReLU33
I0813 08:28:01.174340 18283 net.cpp:425] ReLU33 <- InnerProduct33
I0813 08:28:01.174360 18283 net.cpp:386] ReLU33 -> InnerProduct33 (in-place)
I0813 08:28:01.174382 18283 net.cpp:141] Setting up ReLU33
I0813 08:28:01.174393 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.174399 18283 net.cpp:156] Memory required for data: 161596000
I0813 08:28:01.174407 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.174422 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.174430 18283 net.cpp:425] drop1 <- InnerProduct33
I0813 08:28:01.174444 18283 net.cpp:399] drop1 -> Dropout33
I0813 08:28:01.174463 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.174481 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.174489 18283 net.cpp:156] Memory required for data: 161698400
I0813 08:28:01.174495 18283 layer_factory.hpp:77] Creating layer InnerProduct34
I0813 08:28:01.174512 18283 net.cpp:91] Creating Layer InnerProduct34
I0813 08:28:01.174522 18283 net.cpp:425] InnerProduct34 <- Dropout33
I0813 08:28:01.174537 18283 net.cpp:399] InnerProduct34 -> InnerProduct34
I0813 08:28:01.174829 18283 net.cpp:141] Setting up InnerProduct34
I0813 08:28:01.174839 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.174846 18283 net.cpp:156] Memory required for data: 161749600
I0813 08:28:01.174855 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.174865 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.174871 18283 layer_factory.hpp:77] Creating layer ReLU34
I0813 08:28:01.174881 18283 net.cpp:91] Creating Layer ReLU34
I0813 08:28:01.174892 18283 net.cpp:425] ReLU34 <- InnerProduct34
I0813 08:28:01.174906 18283 net.cpp:386] ReLU34 -> InnerProduct34 (in-place)
I0813 08:28:01.174922 18283 net.cpp:141] Setting up ReLU34
I0813 08:28:01.174934 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.174942 18283 net.cpp:156] Memory required for data: 161800800
I0813 08:28:01.174949 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.174959 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.174967 18283 net.cpp:425] drop2 <- InnerProduct34
I0813 08:28:01.174978 18283 net.cpp:399] drop2 -> Dropout34
I0813 08:28:01.175014 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.175027 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.175034 18283 net.cpp:156] Memory required for data: 161852000
I0813 08:28:01.175040 18283 layer_factory.hpp:77] Creating layer m17
I0813 08:28:01.175057 18283 net.cpp:91] Creating Layer m17
I0813 08:28:01.175068 18283 net.cpp:425] m17 <- Dropout34
I0813 08:28:01.175084 18283 net.cpp:399] m17 -> m17
I0813 08:28:01.175114 18283 net.cpp:141] Setting up m17
I0813 08:28:01.175124 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.175130 18283 net.cpp:156] Memory required for data: 161852400
I0813 08:28:01.175137 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.175145 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.175153 18283 layer_factory.hpp:77] Creating layer Concat18
I0813 08:28:01.175165 18283 net.cpp:91] Creating Layer Concat18
I0813 08:28:01.175175 18283 net.cpp:425] Concat18 <- i9
I0813 08:28:01.175186 18283 net.cpp:425] Concat18 <- i11_i1_10_split_8
I0813 08:28:01.175202 18283 net.cpp:399] Concat18 -> Concat18
I0813 08:28:01.175220 18283 net.cpp:141] Setting up Concat18
I0813 08:28:01.175230 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.175236 18283 net.cpp:156] Memory required for data: 165129200
I0813 08:28:01.175243 18283 layer_factory.hpp:77] Creating layer InnerProduct35
I0813 08:28:01.175256 18283 net.cpp:91] Creating Layer InnerProduct35
I0813 08:28:01.175264 18283 net.cpp:425] InnerProduct35 <- Concat18
I0813 08:28:01.175278 18283 net.cpp:399] InnerProduct35 -> InnerProduct35
I0813 08:28:01.191346 18283 net.cpp:141] Setting up InnerProduct35
I0813 08:28:01.191387 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.191395 18283 net.cpp:156] Memory required for data: 165231600
I0813 08:28:01.191406 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.191416 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.191424 18283 layer_factory.hpp:77] Creating layer ReLU35
I0813 08:28:01.191444 18283 net.cpp:91] Creating Layer ReLU35
I0813 08:28:01.191457 18283 net.cpp:425] ReLU35 <- InnerProduct35
I0813 08:28:01.191475 18283 net.cpp:386] ReLU35 -> InnerProduct35 (in-place)
I0813 08:28:01.191498 18283 net.cpp:141] Setting up ReLU35
I0813 08:28:01.191507 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.191514 18283 net.cpp:156] Memory required for data: 165334000
I0813 08:28:01.191521 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.191535 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.191545 18283 net.cpp:425] drop1 <- InnerProduct35
I0813 08:28:01.191560 18283 net.cpp:399] drop1 -> Dropout35
I0813 08:28:01.191581 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.191591 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.191598 18283 net.cpp:156] Memory required for data: 165436400
I0813 08:28:01.191606 18283 layer_factory.hpp:77] Creating layer InnerProduct36
I0813 08:28:01.191622 18283 net.cpp:91] Creating Layer InnerProduct36
I0813 08:28:01.191632 18283 net.cpp:425] InnerProduct36 <- Dropout35
I0813 08:28:01.191648 18283 net.cpp:399] InnerProduct36 -> InnerProduct36
I0813 08:28:01.191946 18283 net.cpp:141] Setting up InnerProduct36
I0813 08:28:01.191957 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.191963 18283 net.cpp:156] Memory required for data: 165487600
I0813 08:28:01.191972 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.191982 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.191989 18283 layer_factory.hpp:77] Creating layer ReLU36
I0813 08:28:01.192000 18283 net.cpp:91] Creating Layer ReLU36
I0813 08:28:01.192008 18283 net.cpp:425] ReLU36 <- InnerProduct36
I0813 08:28:01.192021 18283 net.cpp:386] ReLU36 -> InnerProduct36 (in-place)
I0813 08:28:01.192052 18283 net.cpp:141] Setting up ReLU36
I0813 08:28:01.192090 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.192097 18283 net.cpp:156] Memory required for data: 165538800
I0813 08:28:01.192104 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.192116 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.192126 18283 net.cpp:425] drop2 <- InnerProduct36
I0813 08:28:01.192139 18283 net.cpp:399] drop2 -> Dropout36
I0813 08:28:01.192157 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.192167 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.192173 18283 net.cpp:156] Memory required for data: 165590000
I0813 08:28:01.192179 18283 layer_factory.hpp:77] Creating layer m18
I0813 08:28:01.192193 18283 net.cpp:91] Creating Layer m18
I0813 08:28:01.192203 18283 net.cpp:425] m18 <- Dropout36
I0813 08:28:01.192217 18283 net.cpp:399] m18 -> m18
I0813 08:28:01.192246 18283 net.cpp:141] Setting up m18
I0813 08:28:01.192255 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.192261 18283 net.cpp:156] Memory required for data: 165590400
I0813 08:28:01.192270 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.192277 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.192286 18283 layer_factory.hpp:77] Creating layer Concat19
I0813 08:28:01.192298 18283 net.cpp:91] Creating Layer Concat19
I0813 08:28:01.192306 18283 net.cpp:425] Concat19 <- i10
I0813 08:28:01.192317 18283 net.cpp:425] Concat19 <- i11_i1_10_split_9
I0813 08:28:01.192332 18283 net.cpp:399] Concat19 -> Concat19
I0813 08:28:01.192348 18283 net.cpp:141] Setting up Concat19
I0813 08:28:01.192358 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.192364 18283 net.cpp:156] Memory required for data: 168867200
I0813 08:28:01.192371 18283 layer_factory.hpp:77] Creating layer InnerProduct37
I0813 08:28:01.192384 18283 net.cpp:91] Creating Layer InnerProduct37
I0813 08:28:01.192396 18283 net.cpp:425] InnerProduct37 <- Concat19
I0813 08:28:01.192407 18283 net.cpp:399] InnerProduct37 -> InnerProduct37
I0813 08:28:01.208822 18283 net.cpp:141] Setting up InnerProduct37
I0813 08:28:01.208868 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.208875 18283 net.cpp:156] Memory required for data: 168969600
I0813 08:28:01.208887 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.208897 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.208905 18283 layer_factory.hpp:77] Creating layer ReLU37
I0813 08:28:01.208930 18283 net.cpp:91] Creating Layer ReLU37
I0813 08:28:01.208945 18283 net.cpp:425] ReLU37 <- InnerProduct37
I0813 08:28:01.208958 18283 net.cpp:386] ReLU37 -> InnerProduct37 (in-place)
I0813 08:28:01.208978 18283 net.cpp:141] Setting up ReLU37
I0813 08:28:01.208988 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.208994 18283 net.cpp:156] Memory required for data: 169072000
I0813 08:28:01.209002 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.209015 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.209024 18283 net.cpp:425] drop1 <- InnerProduct37
I0813 08:28:01.209039 18283 net.cpp:399] drop1 -> Dropout37
I0813 08:28:01.209059 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.209069 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.209076 18283 net.cpp:156] Memory required for data: 169174400
I0813 08:28:01.209084 18283 layer_factory.hpp:77] Creating layer InnerProduct38
I0813 08:28:01.209108 18283 net.cpp:91] Creating Layer InnerProduct38
I0813 08:28:01.209116 18283 net.cpp:425] InnerProduct38 <- Dropout37
I0813 08:28:01.209128 18283 net.cpp:399] InnerProduct38 -> InnerProduct38
I0813 08:28:01.209431 18283 net.cpp:141] Setting up InnerProduct38
I0813 08:28:01.209444 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.209450 18283 net.cpp:156] Memory required for data: 169225600
I0813 08:28:01.209458 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.209489 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.209498 18283 layer_factory.hpp:77] Creating layer ReLU38
I0813 08:28:01.209517 18283 net.cpp:91] Creating Layer ReLU38
I0813 08:28:01.209527 18283 net.cpp:425] ReLU38 <- InnerProduct38
I0813 08:28:01.209537 18283 net.cpp:386] ReLU38 -> InnerProduct38 (in-place)
I0813 08:28:01.209548 18283 net.cpp:141] Setting up ReLU38
I0813 08:28:01.209558 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.209565 18283 net.cpp:156] Memory required for data: 169276800
I0813 08:28:01.209573 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.209583 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.209590 18283 net.cpp:425] drop2 <- InnerProduct38
I0813 08:28:01.209607 18283 net.cpp:399] drop2 -> Dropout38
I0813 08:28:01.209625 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.209635 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.209640 18283 net.cpp:156] Memory required for data: 169328000
I0813 08:28:01.209647 18283 layer_factory.hpp:77] Creating layer m19
I0813 08:28:01.209659 18283 net.cpp:91] Creating Layer m19
I0813 08:28:01.209671 18283 net.cpp:425] m19 <- Dropout38
I0813 08:28:01.209688 18283 net.cpp:399] m19 -> m19
I0813 08:28:01.209717 18283 net.cpp:141] Setting up m19
I0813 08:28:01.209727 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.209731 18283 net.cpp:156] Memory required for data: 169328400
I0813 08:28:01.209739 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.209748 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.209755 18283 layer_factory.hpp:77] Creating layer con
I0813 08:28:01.209779 18283 net.cpp:91] Creating Layer con
I0813 08:28:01.209786 18283 net.cpp:425] con <- m1
I0813 08:28:01.209795 18283 net.cpp:425] con <- m2
I0813 08:28:01.209805 18283 net.cpp:425] con <- m3
I0813 08:28:01.209813 18283 net.cpp:425] con <- m4
I0813 08:28:01.209823 18283 net.cpp:425] con <- m5
I0813 08:28:01.209830 18283 net.cpp:425] con <- m6
I0813 08:28:01.209838 18283 net.cpp:425] con <- m7
I0813 08:28:01.209846 18283 net.cpp:425] con <- m8
I0813 08:28:01.209856 18283 net.cpp:425] con <- m9
I0813 08:28:01.209866 18283 net.cpp:425] con <- m10
I0813 08:28:01.209873 18283 net.cpp:425] con <- m11
I0813 08:28:01.209880 18283 net.cpp:425] con <- m12
I0813 08:28:01.209887 18283 net.cpp:425] con <- m13
I0813 08:28:01.209894 18283 net.cpp:425] con <- m14
I0813 08:28:01.209903 18283 net.cpp:425] con <- m15
I0813 08:28:01.209909 18283 net.cpp:425] con <- m16
I0813 08:28:01.209918 18283 net.cpp:425] con <- m17
I0813 08:28:01.209925 18283 net.cpp:425] con <- m18
I0813 08:28:01.209933 18283 net.cpp:425] con <- m19
I0813 08:28:01.209945 18283 net.cpp:399] con -> con
I0813 08:28:01.209970 18283 net.cpp:141] Setting up con
I0813 08:28:01.209980 18283 net.cpp:148] Top shape: 100 19 (1900)
I0813 08:28:01.209985 18283 net.cpp:156] Memory required for data: 169336000
I0813 08:28:01.209992 18283 layer_factory.hpp:77] Creating layer r1
I0813 08:28:01.210011 18283 net.cpp:91] Creating Layer r1
I0813 08:28:01.210021 18283 net.cpp:425] r1 <- con
I0813 08:28:01.210031 18283 net.cpp:399] r1 -> r1
I0813 08:28:01.210060 18283 net.cpp:141] Setting up r1
I0813 08:28:01.210072 18283 net.cpp:148] Top shape: 100 1 1 19 (1900)
I0813 08:28:01.210078 18283 net.cpp:156] Memory required for data: 169343600
I0813 08:28:01.210083 18283 layer_factory.hpp:77] Creating layer p
I0813 08:28:01.210099 18283 net.cpp:91] Creating Layer p
I0813 08:28:01.210109 18283 net.cpp:425] p <- r1
I0813 08:28:01.210124 18283 net.cpp:399] p -> p
I0813 08:28:01.210161 18283 net.cpp:141] Setting up p
I0813 08:28:01.210172 18283 net.cpp:148] Top shape: 100 1 1 1 (100)
I0813 08:28:01.210178 18283 net.cpp:156] Memory required for data: 169344000
I0813 08:28:01.210185 18283 layer_factory.hpp:77] Creating layer r2
I0813 08:28:01.210196 18283 net.cpp:91] Creating Layer r2
I0813 08:28:01.210203 18283 net.cpp:425] r2 <- p
I0813 08:28:01.210232 18283 net.cpp:399] r2 -> r2
I0813 08:28:01.210250 18283 net.cpp:141] Setting up r2
I0813 08:28:01.210261 18283 net.cpp:148] Top shape: 100 1 1 1 (100)
I0813 08:28:01.210268 18283 net.cpp:156] Memory required for data: 169344400
I0813 08:28:01.210274 18283 layer_factory.hpp:77] Creating layer padL
I0813 08:28:01.210285 18283 net.cpp:91] Creating Layer padL
I0813 08:28:01.210292 18283 net.cpp:425] padL <- label_data_1_split_1
I0813 08:28:01.210309 18283 net.cpp:399] padL -> padL
I0813 08:28:01.210325 18283 net.cpp:141] Setting up padL
I0813 08:28:01.210335 18283 net.cpp:148] Top shape: 100 1 1 1 (100)
I0813 08:28:01.210340 18283 net.cpp:156] Memory required for data: 169344800
I0813 08:28:01.210347 18283 layer_factory.hpp:77] Creating layer pad
I0813 08:28:01.210358 18283 net.cpp:91] Creating Layer pad
I0813 08:28:01.210371 18283 net.cpp:425] pad <- r2
I0813 08:28:01.210379 18283 net.cpp:425] pad <- padL
I0813 08:28:01.210392 18283 net.cpp:399] pad -> pad
I0813 08:28:01.210407 18283 net.cpp:141] Setting up pad
I0813 08:28:01.210418 18283 net.cpp:148] Top shape: 100 2 1 1 (200)
I0813 08:28:01.210424 18283 net.cpp:156] Memory required for data: 169345600
I0813 08:28:01.210432 18283 layer_factory.hpp:77] Creating layer pad_pad_0_split
I0813 08:28:01.210443 18283 net.cpp:91] Creating Layer pad_pad_0_split
I0813 08:28:01.210450 18283 net.cpp:425] pad_pad_0_split <- pad
I0813 08:28:01.210463 18283 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_0
I0813 08:28:01.210479 18283 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_1
I0813 08:28:01.210492 18283 net.cpp:141] Setting up pad_pad_0_split
I0813 08:28:01.210503 18283 net.cpp:148] Top shape: 100 2 1 1 (200)
I0813 08:28:01.210511 18283 net.cpp:148] Top shape: 100 2 1 1 (200)
I0813 08:28:01.210517 18283 net.cpp:156] Memory required for data: 169347200
I0813 08:28:01.210525 18283 layer_factory.hpp:77] Creating layer loss
I0813 08:28:01.210536 18283 net.cpp:91] Creating Layer loss
I0813 08:28:01.210544 18283 net.cpp:425] loss <- pad_pad_0_split_0
I0813 08:28:01.210556 18283 net.cpp:425] loss <- th_th_0_split_0
I0813 08:28:01.210566 18283 net.cpp:399] loss -> loss
I0813 08:28:01.210584 18283 net.cpp:141] Setting up loss
I0813 08:28:01.210594 18283 net.cpp:148] Top shape: (1)
I0813 08:28:01.210600 18283 net.cpp:151]     with loss weight 1
I0813 08:28:01.210629 18283 net.cpp:156] Memory required for data: 169347204
I0813 08:28:01.210636 18283 layer_factory.hpp:77] Creating layer accuracy
I0813 08:28:01.210657 18283 net.cpp:91] Creating Layer accuracy
I0813 08:28:01.210667 18283 net.cpp:425] accuracy <- pad_pad_0_split_1
I0813 08:28:01.210675 18283 net.cpp:425] accuracy <- th_th_0_split_1
I0813 08:28:01.210687 18283 net.cpp:399] accuracy -> accuracy
I0813 08:28:01.210702 18283 net.cpp:141] Setting up accuracy
I0813 08:28:01.210714 18283 net.cpp:148] Top shape: (1)
I0813 08:28:01.210721 18283 net.cpp:156] Memory required for data: 169347208
I0813 08:28:01.210727 18283 net.cpp:219] accuracy does not need backward computation.
I0813 08:28:01.210738 18283 net.cpp:217] loss needs backward computation.
I0813 08:28:01.210748 18283 net.cpp:217] pad_pad_0_split needs backward computation.
I0813 08:28:01.210754 18283 net.cpp:217] pad needs backward computation.
I0813 08:28:01.210762 18283 net.cpp:219] padL does not need backward computation.
I0813 08:28:01.210769 18283 net.cpp:217] r2 needs backward computation.
I0813 08:28:01.210775 18283 net.cpp:217] p needs backward computation.
I0813 08:28:01.210783 18283 net.cpp:217] r1 needs backward computation.
I0813 08:28:01.210788 18283 net.cpp:217] con needs backward computation.
I0813 08:28:01.210804 18283 net.cpp:217] m19 needs backward computation.
I0813 08:28:01.210818 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.210824 18283 net.cpp:217] ReLU38 needs backward computation.
I0813 08:28:01.210830 18283 net.cpp:217] InnerProduct38 needs backward computation.
I0813 08:28:01.210836 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.210844 18283 net.cpp:217] ReLU37 needs backward computation.
I0813 08:28:01.210865 18283 net.cpp:217] InnerProduct37 needs backward computation.
I0813 08:28:01.210872 18283 net.cpp:219] Concat19 does not need backward computation.
I0813 08:28:01.210881 18283 net.cpp:217] m18 needs backward computation.
I0813 08:28:01.210888 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.210896 18283 net.cpp:217] ReLU36 needs backward computation.
I0813 08:28:01.210906 18283 net.cpp:217] InnerProduct36 needs backward computation.
I0813 08:28:01.210913 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.210922 18283 net.cpp:217] ReLU35 needs backward computation.
I0813 08:28:01.210929 18283 net.cpp:217] InnerProduct35 needs backward computation.
I0813 08:28:01.210938 18283 net.cpp:219] Concat18 does not need backward computation.
I0813 08:28:01.210952 18283 net.cpp:217] m17 needs backward computation.
I0813 08:28:01.210963 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.210971 18283 net.cpp:217] ReLU34 needs backward computation.
I0813 08:28:01.210978 18283 net.cpp:217] InnerProduct34 needs backward computation.
I0813 08:28:01.210985 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.210995 18283 net.cpp:217] ReLU33 needs backward computation.
I0813 08:28:01.211006 18283 net.cpp:217] InnerProduct33 needs backward computation.
I0813 08:28:01.211014 18283 net.cpp:219] Concat17 does not need backward computation.
I0813 08:28:01.211022 18283 net.cpp:217] m16 needs backward computation.
I0813 08:28:01.211030 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211037 18283 net.cpp:217] ReLU32 needs backward computation.
I0813 08:28:01.211045 18283 net.cpp:217] InnerProduct32 needs backward computation.
I0813 08:28:01.211052 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211058 18283 net.cpp:217] ReLU31 needs backward computation.
I0813 08:28:01.211066 18283 net.cpp:217] InnerProduct31 needs backward computation.
I0813 08:28:01.211073 18283 net.cpp:219] Concat16 does not need backward computation.
I0813 08:28:01.211083 18283 net.cpp:217] m15 needs backward computation.
I0813 08:28:01.211096 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211103 18283 net.cpp:217] ReLU30 needs backward computation.
I0813 08:28:01.211110 18283 net.cpp:217] InnerProduct30 needs backward computation.
I0813 08:28:01.211118 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211127 18283 net.cpp:217] ReLU29 needs backward computation.
I0813 08:28:01.211133 18283 net.cpp:217] InnerProduct29 needs backward computation.
I0813 08:28:01.211141 18283 net.cpp:219] Concat15 does not need backward computation.
I0813 08:28:01.211151 18283 net.cpp:217] m14 needs backward computation.
I0813 08:28:01.211163 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211170 18283 net.cpp:217] ReLU28 needs backward computation.
I0813 08:28:01.211177 18283 net.cpp:217] InnerProduct28 needs backward computation.
I0813 08:28:01.211184 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211191 18283 net.cpp:217] ReLU27 needs backward computation.
I0813 08:28:01.211199 18283 net.cpp:217] InnerProduct27 needs backward computation.
I0813 08:28:01.211207 18283 net.cpp:219] Concat14 does not need backward computation.
I0813 08:28:01.211217 18283 net.cpp:217] m13 needs backward computation.
I0813 08:28:01.211225 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211233 18283 net.cpp:217] ReLU26 needs backward computation.
I0813 08:28:01.211241 18283 net.cpp:217] InnerProduct26 needs backward computation.
I0813 08:28:01.211252 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211262 18283 net.cpp:217] ReLU25 needs backward computation.
I0813 08:28:01.211268 18283 net.cpp:217] InnerProduct25 needs backward computation.
I0813 08:28:01.211277 18283 net.cpp:219] Concat13 does not need backward computation.
I0813 08:28:01.211284 18283 net.cpp:217] m12 needs backward computation.
I0813 08:28:01.211292 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211313 18283 net.cpp:217] ReLU24 needs backward computation.
I0813 08:28:01.211319 18283 net.cpp:217] InnerProduct24 needs backward computation.
I0813 08:28:01.211328 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211334 18283 net.cpp:217] ReLU23 needs backward computation.
I0813 08:28:01.211344 18283 net.cpp:217] InnerProduct23 needs backward computation.
I0813 08:28:01.211354 18283 net.cpp:219] Concat12 does not need backward computation.
I0813 08:28:01.211362 18283 net.cpp:217] m11 needs backward computation.
I0813 08:28:01.211370 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211377 18283 net.cpp:217] ReLU22 needs backward computation.
I0813 08:28:01.211385 18283 net.cpp:217] InnerProduct22 needs backward computation.
I0813 08:28:01.211391 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211398 18283 net.cpp:217] ReLU21 needs backward computation.
I0813 08:28:01.211405 18283 net.cpp:217] InnerProduct21 needs backward computation.
I0813 08:28:01.211413 18283 net.cpp:219] Concat11 does not need backward computation.
I0813 08:28:01.211422 18283 net.cpp:217] m10 needs backward computation.
I0813 08:28:01.211434 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211441 18283 net.cpp:217] ReLU20 needs backward computation.
I0813 08:28:01.211449 18283 net.cpp:217] InnerProduct20 needs backward computation.
I0813 08:28:01.211457 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211464 18283 net.cpp:217] ReLU19 needs backward computation.
I0813 08:28:01.211472 18283 net.cpp:217] InnerProduct19 needs backward computation.
I0813 08:28:01.211480 18283 net.cpp:219] Concat10 does not need backward computation.
I0813 08:28:01.211491 18283 net.cpp:217] m9 needs backward computation.
I0813 08:28:01.211500 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211508 18283 net.cpp:217] ReLU18 needs backward computation.
I0813 08:28:01.211519 18283 net.cpp:217] InnerProduct18 needs backward computation.
I0813 08:28:01.211526 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211534 18283 net.cpp:217] ReLU17 needs backward computation.
I0813 08:28:01.211540 18283 net.cpp:217] InnerProduct17 needs backward computation.
I0813 08:28:01.211554 18283 net.cpp:219] Concat9 does not need backward computation.
I0813 08:28:01.211563 18283 net.cpp:217] m8 needs backward computation.
I0813 08:28:01.211572 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211581 18283 net.cpp:217] ReLU16 needs backward computation.
I0813 08:28:01.211588 18283 net.cpp:217] InnerProduct16 needs backward computation.
I0813 08:28:01.211601 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211608 18283 net.cpp:217] ReLU15 needs backward computation.
I0813 08:28:01.211616 18283 net.cpp:217] InnerProduct15 needs backward computation.
I0813 08:28:01.211624 18283 net.cpp:219] Concat8 does not need backward computation.
I0813 08:28:01.211634 18283 net.cpp:217] m7 needs backward computation.
I0813 08:28:01.211644 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211654 18283 net.cpp:217] ReLU14 needs backward computation.
I0813 08:28:01.211661 18283 net.cpp:217] InnerProduct14 needs backward computation.
I0813 08:28:01.211668 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211675 18283 net.cpp:217] ReLU13 needs backward computation.
I0813 08:28:01.211683 18283 net.cpp:217] InnerProduct13 needs backward computation.
I0813 08:28:01.211690 18283 net.cpp:219] Concat7 does not need backward computation.
I0813 08:28:01.211704 18283 net.cpp:217] m6 needs backward computation.
I0813 08:28:01.211712 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211720 18283 net.cpp:217] ReLU12 needs backward computation.
I0813 08:28:01.211726 18283 net.cpp:217] InnerProduct12 needs backward computation.
I0813 08:28:01.211735 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211741 18283 net.cpp:217] ReLU11 needs backward computation.
I0813 08:28:01.211748 18283 net.cpp:217] InnerProduct11 needs backward computation.
I0813 08:28:01.211772 18283 net.cpp:219] Concat6 does not need backward computation.
I0813 08:28:01.211782 18283 net.cpp:217] m5 needs backward computation.
I0813 08:28:01.211791 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211802 18283 net.cpp:217] ReLU10 needs backward computation.
I0813 08:28:01.211808 18283 net.cpp:217] InnerProduct10 needs backward computation.
I0813 08:28:01.211817 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211827 18283 net.cpp:217] ReLU9 needs backward computation.
I0813 08:28:01.211834 18283 net.cpp:217] InnerProduct9 needs backward computation.
I0813 08:28:01.211843 18283 net.cpp:219] Concat5 does not need backward computation.
I0813 08:28:01.211855 18283 net.cpp:217] m4 needs backward computation.
I0813 08:28:01.211864 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211874 18283 net.cpp:217] ReLU8 needs backward computation.
I0813 08:28:01.211881 18283 net.cpp:217] InnerProduct8 needs backward computation.
I0813 08:28:01.211889 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211895 18283 net.cpp:217] ReLU7 needs backward computation.
I0813 08:28:01.211904 18283 net.cpp:217] InnerProduct7 needs backward computation.
I0813 08:28:01.211912 18283 net.cpp:219] Concat4 does not need backward computation.
I0813 08:28:01.211921 18283 net.cpp:217] m3 needs backward computation.
I0813 08:28:01.211928 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.211938 18283 net.cpp:217] ReLU6 needs backward computation.
I0813 08:28:01.211947 18283 net.cpp:217] InnerProduct6 needs backward computation.
I0813 08:28:01.211957 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.211964 18283 net.cpp:217] ReLU5 needs backward computation.
I0813 08:28:01.211971 18283 net.cpp:217] InnerProduct5 needs backward computation.
I0813 08:28:01.211979 18283 net.cpp:219] Concat3 does not need backward computation.
I0813 08:28:01.211988 18283 net.cpp:217] m2 needs backward computation.
I0813 08:28:01.211997 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.212005 18283 net.cpp:217] ReLU4 needs backward computation.
I0813 08:28:01.212013 18283 net.cpp:217] InnerProduct4 needs backward computation.
I0813 08:28:01.212021 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.212056 18283 net.cpp:217] ReLU3 needs backward computation.
I0813 08:28:01.212064 18283 net.cpp:217] InnerProduct3 needs backward computation.
I0813 08:28:01.212072 18283 net.cpp:219] Concat2 does not need backward computation.
I0813 08:28:01.212081 18283 net.cpp:217] m1 needs backward computation.
I0813 08:28:01.212090 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.212097 18283 net.cpp:217] ReLU2 needs backward computation.
I0813 08:28:01.212105 18283 net.cpp:217] InnerProduct2 needs backward computation.
I0813 08:28:01.212111 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.212119 18283 net.cpp:217] ReLU1 needs backward computation.
I0813 08:28:01.212131 18283 net.cpp:217] InnerProduct1 needs backward computation.
I0813 08:28:01.212139 18283 net.cpp:219] Concat1 does not need backward computation.
I0813 08:28:01.212152 18283 net.cpp:219] i11_i1_10_split does not need backward computation.
I0813 08:28:01.212168 18283 net.cpp:219] i1_i1_0_split does not need backward computation.
I0813 08:28:01.212183 18283 net.cpp:219] i1 does not need backward computation.
I0813 08:28:01.212193 18283 net.cpp:219] th_th_0_split does not need backward computation.
I0813 08:28:01.212200 18283 net.cpp:219] th does not need backward computation.
I0813 08:28:01.212208 18283 net.cpp:219] label_data_1_split does not need backward computation.
I0813 08:28:01.212220 18283 net.cpp:219] data does not need backward computation.
I0813 08:28:01.212229 18283 net.cpp:261] This network produces output accuracy
I0813 08:28:01.212239 18283 net.cpp:261] This network produces output loss
I0813 08:28:01.214238 18283 net.cpp:274] Network initialization done.
I0813 08:28:01.218164 18283 solver.cpp:181] Creating test net (#0) specified by test_net file: examples/scene/metNetTest.prototxt
I0813 08:28:01.219264 18283 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 1
    mirror: false
  }
  data_param {
    source: "/home/shaogang/Datasets/FeatsDB/featsTest1k"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "th"
  type: "Threshold"
  bottom: "label"
  top: "th"
  threshold_param {
    threshold: 0
  }
}
layer {
  name: "i1"
  type: "Slice"
  bottom: "data"
  top: "i1"
  top: "i2"
  top: "i3"
  top: "i4"
  top: "i5"
  top: "i6"
  top: "i7"
  top: "i8"
  top: "i9"
  top: "i10"
  top: "i11"
  top: "i12"
  top: "i13"
  top: "i14"
  top: "i15"
  top: "i16"
  top: "i17"
  top: "i18"
  top: "i19"
  top: "i20"
  slice_param {
    slice_dim: 2
    slice_point: 1
    slice_point: 2
    slice_point: 3
    slice_point: 4
    slice_point: 5
    slice_point: 6
    slice_point: 7
    slice_point: 8
    slice_point: 9
    slice_point: 10
    slice_point: 11
    slice_point: 12
    slice_point: 13
    slice_point: 14
    slice_point: 15
    slice_point: 16
    slice_point: 17
    slice_point: 18
    slice_point: 19
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "i1"
  bottom: "i11"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Concat1"
  top: "InnerProduct1"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct1"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "Dropout1"
  top: "InnerProduct2"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "InnerProduct2"
  top: "InnerProduct2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct2"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m1"
  type: "InnerProduct"
  bottom: "Dropout2"
  top: "m1"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "i1"
  bottom: "i12"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "Concat2"
  top: "InnerProduct3"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct3"
  top: "InnerProduct3"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct3"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "Dropout3"
  top: "InnerProduct4"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "InnerProduct4"
  top: "InnerProduct4"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct4"
  top: "Dropout4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m2"
  type: "InnerProduct"
  bottom: "Dropout4"
  top: "m2"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "i1"
  bottom: "i13"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct5"
  type: "InnerProduct"
  bottom: "Concat3"
  top: "InnerProduct5"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "InnerProduct5"
  top: "InnerProduct5"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct5"
  top: "Dropout5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct6"
  type: "InnerProduct"
  bottom: "Dropout5"
  top: "InnerProduct6"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "InnerProduct6"
  top: "InnerProduct6"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct6"
  top: "Dropout6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m3"
  type: "InnerProduct"
  bottom: "Dropout6"
  top: "m3"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "i1"
  bottom: "i14"
  top: "Concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct7"
  type: "InnerProduct"
  bottom: "Concat4"
  top: "InnerProduct7"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "InnerProduct7"
  top: "InnerProduct7"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct7"
  top: "Dropout7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct8"
  type: "InnerProduct"
  bottom: "Dropout7"
  top: "InnerProduct8"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "InnerProduct8"
  top: "InnerProduct8"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct8"
  top: "Dropout8"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m4"
  type: "InnerProduct"
  bottom: "Dropout8"
  top: "m4"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "i1"
  bottom: "i15"
  top: "Concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct9"
  type: "InnerProduct"
  bottom: "Concat5"
  top: "InnerProduct9"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "InnerProduct9"
  top: "InnerProduct9"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct9"
  top: "Dropout9"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct10"
  type: "InnerProduct"
  bottom: "Dropout9"
  top: "InnerProduct10"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "InnerProduct10"
  top: "InnerProduct10"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct10"
  top: "Dropout10"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m5"
  type: "InnerProduct"
  bottom: "Dropout10"
  top: "m5"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "i1"
  bottom: "i16"
  top: "Concat6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct11"
  type: "InnerProduct"
  bottom: "Concat6"
  top: "InnerProduct11"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "InnerProduct11"
  top: "InnerProduct11"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct11"
  top: "Dropout11"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct12"
  type: "InnerProduct"
  bottom: "Dropout11"
  top: "InnerProduct12"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "InnerProduct12"
  top: "InnerProduct12"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct12"
  top: "Dropout12"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m6"
  type: "InnerProduct"
  bottom: "Dropout12"
  top: "m6"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "i1"
  bottom: "i17"
  top: "Concat7"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct13"
  type: "InnerProduct"
  bottom: "Concat7"
  top: "InnerProduct13"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "InnerProduct13"
  top: "InnerProduct13"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct13"
  top: "Dropout13"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct14"
  type: "InnerProduct"
  bottom: "Dropout13"
  top: "InnerProduct14"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "InnerProduct14"
  top: "InnerProduct14"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct14"
  top: "Dropout14"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m7"
  type: "InnerProduct"
  bottom: "Dropout14"
  top: "m7"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "i1"
  bottom: "i18"
  top: "Concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct15"
  type: "InnerProduct"
  bottom: "Concat8"
  top: "InnerProduct15"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "InnerProduct15"
  top: "InnerProduct15"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct15"
  top: "Dropout15"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct16"
  type: "InnerProduct"
  bottom: "Dropout15"
  top: "InnerProduct16"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "InnerProduct16"
  top: "InnerProduct16"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct16"
  top: "Dropout16"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m8"
  type: "InnerProduct"
  bottom: "Dropout16"
  top: "m8"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "i1"
  bottom: "i19"
  top: "Concat9"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct17"
  type: "InnerProduct"
  bottom: "Concat9"
  top: "InnerProduct17"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "InnerProduct17"
  top: "InnerProduct17"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct17"
  top: "Dropout17"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct18"
  type: "InnerProduct"
  bottom: "Dropout17"
  top: "InnerProduct18"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "InnerProduct18"
  top: "InnerProduct18"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct18"
  top: "Dropout18"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m9"
  type: "InnerProduct"
  bottom: "Dropout18"
  top: "m9"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat10"
  type: "Concat"
  bottom: "i1"
  bottom: "i20"
  top: "Concat10"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct19"
  type: "InnerProduct"
  bottom: "Concat10"
  top: "InnerProduct19"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "InnerProduct19"
  top: "InnerProduct19"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct19"
  top: "Dropout19"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct20"
  type: "InnerProduct"
  bottom: "Dropout19"
  top: "InnerProduct20"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "InnerProduct20"
  top: "InnerProduct20"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct20"
  top: "Dropout20"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m10"
  type: "InnerProduct"
  bottom: "Dropout20"
  top: "m10"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat11"
  type: "Concat"
  bottom: "i2"
  bottom: "i11"
  top: "Concat11"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct21"
  type: "InnerProduct"
  bottom: "Concat11"
  top: "InnerProduct21"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "InnerProduct21"
  top: "InnerProduct21"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct21"
  top: "Dropout21"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct22"
  type: "InnerProduct"
  bottom: "Dropout21"
  top: "InnerProduct22"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "InnerProduct22"
  top: "InnerProduct22"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct22"
  top: "Dropout22"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m11"
  type: "InnerProduct"
  bottom: "Dropout22"
  top: "m11"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat12"
  type: "Concat"
  bottom: "i3"
  bottom: "i11"
  top: "Concat12"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct23"
  type: "InnerProduct"
  bottom: "Concat12"
  top: "InnerProduct23"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "InnerProduct23"
  top: "InnerProduct23"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct23"
  top: "Dropout23"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct24"
  type: "InnerProduct"
  bottom: "Dropout23"
  top: "InnerProduct24"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "InnerProduct24"
  top: "InnerProduct24"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct24"
  top: "Dropout24"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m12"
  type: "InnerProduct"
  bottom: "Dropout24"
  top: "m12"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat13"
  type: "Concat"
  bottom: "i4"
  bottom: "i11"
  top: "Concat13"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct25"
  type: "InnerProduct"
  bottom: "Concat13"
  top: "InnerProduct25"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "InnerProduct25"
  top: "InnerProduct25"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct25"
  top: "Dropout25"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct26"
  type: "InnerProduct"
  bottom: "Dropout25"
  top: "InnerProduct26"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "InnerProduct26"
  top: "InnerProduct26"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct26"
  top: "Dropout26"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m13"
  type: "InnerProduct"
  bottom: "Dropout26"
  top: "m13"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat14"
  type: "Concat"
  bottom: "i5"
  bottom: "i11"
  top: "Concat14"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct27"
  type: "InnerProduct"
  bottom: "Concat14"
  top: "InnerProduct27"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "InnerProduct27"
  top: "InnerProduct27"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct27"
  top: "Dropout27"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct28"
  type: "InnerProduct"
  bottom: "Dropout27"
  top: "InnerProduct28"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "InnerProduct28"
  top: "InnerProduct28"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct28"
  top: "Dropout28"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m14"
  type: "InnerProduct"
  bottom: "Dropout28"
  top: "m14"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat15"
  type: "Concat"
  bottom: "i6"
  bottom: "i11"
  top: "Concat15"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct29"
  type: "InnerProduct"
  bottom: "Concat15"
  top: "InnerProduct29"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "InnerProduct29"
  top: "InnerProduct29"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct29"
  top: "Dropout29"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct30"
  type: "InnerProduct"
  bottom: "Dropout29"
  top: "InnerProduct30"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "InnerProduct30"
  top: "InnerProduct30"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct30"
  top: "Dropout30"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m15"
  type: "InnerProduct"
  bottom: "Dropout30"
  top: "m15"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat16"
  type: "Concat"
  bottom: "i7"
  bottom: "i11"
  top: "Concat16"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct31"
  type: "InnerProduct"
  bottom: "Concat16"
  top: "InnerProduct31"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "InnerProduct31"
  top: "InnerProduct31"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct31"
  top: "Dropout31"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct32"
  type: "InnerProduct"
  bottom: "Dropout31"
  top: "InnerProduct32"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "InnerProduct32"
  top: "InnerProduct32"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct32"
  top: "Dropout32"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m16"
  type: "InnerProduct"
  bottom: "Dropout32"
  top: "m16"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat17"
  type: "Concat"
  bottom: "i8"
  bottom: "i11"
  top: "Concat17"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct33"
  type: "InnerProduct"
  bottom: "Concat17"
  top: "InnerProduct33"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "InnerProduct33"
  top: "InnerProduct33"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct33"
  top: "Dropout33"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct34"
  type: "InnerProduct"
  bottom: "Dropout33"
  top: "InnerProduct34"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "InnerProduct34"
  top: "InnerProduct34"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct34"
  top: "Dropout34"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m17"
  type: "InnerProduct"
  bottom: "Dropout34"
  top: "m17"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat18"
  type: "Concat"
  bottom: "i9"
  bottom: "i11"
  top: "Concat18"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct35"
  type: "InnerProduct"
  bottom: "Concat18"
  top: "InnerProduct35"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "InnerProduct35"
  top: "InnerProduct35"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct35"
  top: "Dropout35"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct36"
  type: "InnerProduct"
  bottom: "Dropout35"
  top: "InnerProduct36"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "InnerProduct36"
  top: "InnerProduct36"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct36"
  top: "Dropout36"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m18"
  type: "InnerProduct"
  bottom: "Dropout36"
  top: "m18"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat19"
  type: "Concat"
  bottom: "i10"
  bottom: "i11"
  top: "Concat19"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct37"
  type: "InnerProduct"
  bottom: "Concat19"
  top: "InnerProduct37"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU37"
 
I0813 08:28:01.220595 18283 layer_factory.hpp:77] Creating layer data
I0813 08:28:01.220780 18283 net.cpp:91] Creating Layer data
I0813 08:28:01.220795 18283 net.cpp:399] data -> data
I0813 08:28:01.220814 18283 net.cpp:399] data -> label
I0813 08:28:01.221042 18289 db_lmdb.cpp:35] Opened lmdb /home/shaogang/Datasets/FeatsDB/featsTest1k
I0813 08:28:01.222523 18283 data_layer.cpp:41] output data size: 100,1,20,4096
I0813 08:28:01.255857 18283 net.cpp:141] Setting up data
I0813 08:28:01.255903 18283 net.cpp:148] Top shape: 100 1 20 4096 (8192000)
I0813 08:28:01.255911 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:01.255916 18283 net.cpp:156] Memory required for data: 32768400
I0813 08:28:01.255928 18283 layer_factory.hpp:77] Creating layer label_data_1_split
I0813 08:28:01.255949 18283 net.cpp:91] Creating Layer label_data_1_split
I0813 08:28:01.255957 18283 net.cpp:425] label_data_1_split <- label
I0813 08:28:01.255966 18283 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0813 08:28:01.255981 18283 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0813 08:28:01.255995 18283 net.cpp:141] Setting up label_data_1_split
I0813 08:28:01.256001 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:01.256011 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:01.256014 18283 net.cpp:156] Memory required for data: 32769200
I0813 08:28:01.256019 18283 layer_factory.hpp:77] Creating layer th
I0813 08:28:01.256049 18283 net.cpp:91] Creating Layer th
I0813 08:28:01.256057 18283 net.cpp:425] th <- label_data_1_split_0
I0813 08:28:01.256062 18283 net.cpp:399] th -> th
I0813 08:28:01.256072 18283 net.cpp:141] Setting up th
I0813 08:28:01.256080 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:01.256084 18283 net.cpp:156] Memory required for data: 32769600
I0813 08:28:01.256093 18283 layer_factory.hpp:77] Creating layer th_th_0_split
I0813 08:28:01.256099 18283 net.cpp:91] Creating Layer th_th_0_split
I0813 08:28:01.256106 18283 net.cpp:425] th_th_0_split <- th
I0813 08:28:01.256114 18283 net.cpp:399] th_th_0_split -> th_th_0_split_0
I0813 08:28:01.256120 18283 net.cpp:399] th_th_0_split -> th_th_0_split_1
I0813 08:28:01.256129 18283 net.cpp:141] Setting up th_th_0_split
I0813 08:28:01.256135 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:01.256141 18283 net.cpp:148] Top shape: 100 (100)
I0813 08:28:01.256145 18283 net.cpp:156] Memory required for data: 32770400
I0813 08:28:01.256151 18283 layer_factory.hpp:77] Creating layer i1
I0813 08:28:01.256167 18283 net.cpp:91] Creating Layer i1
I0813 08:28:01.256173 18283 net.cpp:425] i1 <- data
I0813 08:28:01.256181 18283 net.cpp:399] i1 -> i1
I0813 08:28:01.256209 18283 net.cpp:399] i1 -> i2
I0813 08:28:01.256222 18283 net.cpp:399] i1 -> i3
I0813 08:28:01.256232 18283 net.cpp:399] i1 -> i4
I0813 08:28:01.256242 18283 net.cpp:399] i1 -> i5
I0813 08:28:01.256252 18283 net.cpp:399] i1 -> i6
I0813 08:28:01.256260 18283 net.cpp:399] i1 -> i7
I0813 08:28:01.256270 18283 net.cpp:399] i1 -> i8
I0813 08:28:01.256279 18283 net.cpp:399] i1 -> i9
I0813 08:28:01.256289 18283 net.cpp:399] i1 -> i10
I0813 08:28:01.256300 18283 net.cpp:399] i1 -> i11
I0813 08:28:01.256310 18283 net.cpp:399] i1 -> i12
I0813 08:28:01.256319 18283 net.cpp:399] i1 -> i13
I0813 08:28:01.256328 18283 net.cpp:399] i1 -> i14
I0813 08:28:01.256337 18283 net.cpp:399] i1 -> i15
I0813 08:28:01.256347 18283 net.cpp:399] i1 -> i16
I0813 08:28:01.256356 18283 net.cpp:399] i1 -> i17
I0813 08:28:01.256366 18283 net.cpp:399] i1 -> i18
I0813 08:28:01.256376 18283 net.cpp:399] i1 -> i19
I0813 08:28:01.256384 18283 net.cpp:399] i1 -> i20
I0813 08:28:01.256405 18283 net.cpp:141] Setting up i1
I0813 08:28:01.256412 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256418 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256424 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256428 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256435 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256439 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256445 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256450 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256456 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256463 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256469 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256472 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256479 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256484 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256489 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256494 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256500 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256505 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256510 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256515 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256520 18283 net.cpp:156] Memory required for data: 65538400
I0813 08:28:01.256525 18283 layer_factory.hpp:77] Creating layer i1_i1_0_split
I0813 08:28:01.256531 18283 net.cpp:91] Creating Layer i1_i1_0_split
I0813 08:28:01.256537 18283 net.cpp:425] i1_i1_0_split <- i1
I0813 08:28:01.256546 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_0
I0813 08:28:01.256554 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_1
I0813 08:28:01.256563 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_2
I0813 08:28:01.256572 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_3
I0813 08:28:01.256579 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_4
I0813 08:28:01.256588 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_5
I0813 08:28:01.256599 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_6
I0813 08:28:01.256608 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_7
I0813 08:28:01.256615 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_8
I0813 08:28:01.256624 18283 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_9
I0813 08:28:01.256636 18283 net.cpp:141] Setting up i1_i1_0_split
I0813 08:28:01.256642 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256647 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256654 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256659 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256664 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256669 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256675 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256690 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256695 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256700 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256703 18283 net.cpp:156] Memory required for data: 81922400
I0813 08:28:01.256710 18283 layer_factory.hpp:77] Creating layer i11_i1_10_split
I0813 08:28:01.256716 18283 net.cpp:91] Creating Layer i11_i1_10_split
I0813 08:28:01.256721 18283 net.cpp:425] i11_i1_10_split <- i11
I0813 08:28:01.256727 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_0
I0813 08:28:01.256736 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_1
I0813 08:28:01.256742 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_2
I0813 08:28:01.256750 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_3
I0813 08:28:01.256758 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_4
I0813 08:28:01.256767 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_5
I0813 08:28:01.256774 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_6
I0813 08:28:01.256783 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_7
I0813 08:28:01.256790 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_8
I0813 08:28:01.256799 18283 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_9
I0813 08:28:01.256811 18283 net.cpp:141] Setting up i11_i1_10_split
I0813 08:28:01.256817 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256822 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256829 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256832 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256839 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256844 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256849 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256853 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256860 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256863 18283 net.cpp:148] Top shape: 100 1 1 4096 (409600)
I0813 08:28:01.256870 18283 net.cpp:156] Memory required for data: 98306400
I0813 08:28:01.256873 18283 layer_factory.hpp:77] Creating layer Concat1
I0813 08:28:01.256886 18283 net.cpp:91] Creating Layer Concat1
I0813 08:28:01.256892 18283 net.cpp:425] Concat1 <- i1_i1_0_split_0
I0813 08:28:01.256897 18283 net.cpp:425] Concat1 <- i11_i1_10_split_0
I0813 08:28:01.256906 18283 net.cpp:399] Concat1 -> Concat1
I0813 08:28:01.256917 18283 net.cpp:141] Setting up Concat1
I0813 08:28:01.256924 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.256928 18283 net.cpp:156] Memory required for data: 101583200
I0813 08:28:01.256933 18283 layer_factory.hpp:77] Creating layer InnerProduct1
I0813 08:28:01.256953 18283 net.cpp:91] Creating Layer InnerProduct1
I0813 08:28:01.256958 18283 net.cpp:425] InnerProduct1 <- Concat1
I0813 08:28:01.256965 18283 net.cpp:399] InnerProduct1 -> InnerProduct1
I0813 08:28:01.273458 18283 net.cpp:141] Setting up InnerProduct1
I0813 08:28:01.273495 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.273501 18283 net.cpp:156] Memory required for data: 101685600
I0813 08:28:01.273522 18283 layer_factory.hpp:77] Creating layer ReLU1
I0813 08:28:01.273538 18283 net.cpp:91] Creating Layer ReLU1
I0813 08:28:01.273546 18283 net.cpp:425] ReLU1 <- InnerProduct1
I0813 08:28:01.273557 18283 net.cpp:386] ReLU1 -> InnerProduct1 (in-place)
I0813 08:28:01.273571 18283 net.cpp:141] Setting up ReLU1
I0813 08:28:01.273579 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.273584 18283 net.cpp:156] Memory required for data: 101788000
I0813 08:28:01.273588 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.273599 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.273607 18283 net.cpp:425] drop1 <- InnerProduct1
I0813 08:28:01.273614 18283 net.cpp:399] drop1 -> Dropout1
I0813 08:28:01.273627 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.273634 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.273660 18283 net.cpp:156] Memory required for data: 101890400
I0813 08:28:01.273665 18283 layer_factory.hpp:77] Creating layer InnerProduct2
I0813 08:28:01.273679 18283 net.cpp:91] Creating Layer InnerProduct2
I0813 08:28:01.273685 18283 net.cpp:425] InnerProduct2 <- Dropout1
I0813 08:28:01.273694 18283 net.cpp:399] InnerProduct2 -> InnerProduct2
I0813 08:28:01.273942 18283 net.cpp:141] Setting up InnerProduct2
I0813 08:28:01.273952 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.273957 18283 net.cpp:156] Memory required for data: 101941600
I0813 08:28:01.273968 18283 layer_factory.hpp:77] Creating layer ReLU2
I0813 08:28:01.273978 18283 net.cpp:91] Creating Layer ReLU2
I0813 08:28:01.273985 18283 net.cpp:425] ReLU2 <- InnerProduct2
I0813 08:28:01.273993 18283 net.cpp:386] ReLU2 -> InnerProduct2 (in-place)
I0813 08:28:01.274001 18283 net.cpp:141] Setting up ReLU2
I0813 08:28:01.274008 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.274011 18283 net.cpp:156] Memory required for data: 101992800
I0813 08:28:01.274015 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.274024 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.274029 18283 net.cpp:425] drop2 <- InnerProduct2
I0813 08:28:01.274035 18283 net.cpp:399] drop2 -> Dropout2
I0813 08:28:01.274045 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.274052 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.274056 18283 net.cpp:156] Memory required for data: 102044000
I0813 08:28:01.274060 18283 layer_factory.hpp:77] Creating layer m1
I0813 08:28:01.274072 18283 net.cpp:91] Creating Layer m1
I0813 08:28:01.274078 18283 net.cpp:425] m1 <- Dropout2
I0813 08:28:01.274088 18283 net.cpp:399] m1 -> m1
I0813 08:28:01.274106 18283 net.cpp:141] Setting up m1
I0813 08:28:01.274113 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.274117 18283 net.cpp:156] Memory required for data: 102044400
I0813 08:28:01.274127 18283 layer_factory.hpp:77] Creating layer Concat2
I0813 08:28:01.274138 18283 net.cpp:91] Creating Layer Concat2
I0813 08:28:01.274145 18283 net.cpp:425] Concat2 <- i1_i1_0_split_1
I0813 08:28:01.274154 18283 net.cpp:425] Concat2 <- i12
I0813 08:28:01.274163 18283 net.cpp:399] Concat2 -> Concat2
I0813 08:28:01.274175 18283 net.cpp:141] Setting up Concat2
I0813 08:28:01.274183 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.274186 18283 net.cpp:156] Memory required for data: 105321200
I0813 08:28:01.274191 18283 layer_factory.hpp:77] Creating layer InnerProduct3
I0813 08:28:01.274204 18283 net.cpp:91] Creating Layer InnerProduct3
I0813 08:28:01.274210 18283 net.cpp:425] InnerProduct3 <- Concat2
I0813 08:28:01.274219 18283 net.cpp:399] InnerProduct3 -> InnerProduct3
I0813 08:28:01.290971 18283 net.cpp:141] Setting up InnerProduct3
I0813 08:28:01.291014 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.291021 18283 net.cpp:156] Memory required for data: 105423600
I0813 08:28:01.291034 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.291052 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.291061 18283 layer_factory.hpp:77] Creating layer ReLU3
I0813 08:28:01.291082 18283 net.cpp:91] Creating Layer ReLU3
I0813 08:28:01.291096 18283 net.cpp:425] ReLU3 <- InnerProduct3
I0813 08:28:01.291112 18283 net.cpp:386] ReLU3 -> InnerProduct3 (in-place)
I0813 08:28:01.291142 18283 net.cpp:141] Setting up ReLU3
I0813 08:28:01.291152 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.291158 18283 net.cpp:156] Memory required for data: 105526000
I0813 08:28:01.291167 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.291184 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.291193 18283 net.cpp:425] drop1 <- InnerProduct3
I0813 08:28:01.291204 18283 net.cpp:399] drop1 -> Dropout3
I0813 08:28:01.291227 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.291237 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.291244 18283 net.cpp:156] Memory required for data: 105628400
I0813 08:28:01.291273 18283 layer_factory.hpp:77] Creating layer InnerProduct4
I0813 08:28:01.291295 18283 net.cpp:91] Creating Layer InnerProduct4
I0813 08:28:01.291303 18283 net.cpp:425] InnerProduct4 <- Dropout3
I0813 08:28:01.291321 18283 net.cpp:399] InnerProduct4 -> InnerProduct4
I0813 08:28:01.291581 18283 net.cpp:141] Setting up InnerProduct4
I0813 08:28:01.291592 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.291599 18283 net.cpp:156] Memory required for data: 105679600
I0813 08:28:01.291612 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.291621 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.291630 18283 layer_factory.hpp:77] Creating layer ReLU4
I0813 08:28:01.291641 18283 net.cpp:91] Creating Layer ReLU4
I0813 08:28:01.291651 18283 net.cpp:425] ReLU4 <- InnerProduct4
I0813 08:28:01.291661 18283 net.cpp:386] ReLU4 -> InnerProduct4 (in-place)
I0813 08:28:01.291672 18283 net.cpp:141] Setting up ReLU4
I0813 08:28:01.291682 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.291688 18283 net.cpp:156] Memory required for data: 105730800
I0813 08:28:01.291694 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.291705 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.291714 18283 net.cpp:425] drop2 <- InnerProduct4
I0813 08:28:01.291724 18283 net.cpp:399] drop2 -> Dropout4
I0813 08:28:01.291739 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.291749 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.291756 18283 net.cpp:156] Memory required for data: 105782000
I0813 08:28:01.291762 18283 layer_factory.hpp:77] Creating layer m2
I0813 08:28:01.291777 18283 net.cpp:91] Creating Layer m2
I0813 08:28:01.291785 18283 net.cpp:425] m2 <- Dropout4
I0813 08:28:01.291800 18283 net.cpp:399] m2 -> m2
I0813 08:28:01.291824 18283 net.cpp:141] Setting up m2
I0813 08:28:01.291836 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.291842 18283 net.cpp:156] Memory required for data: 105782400
I0813 08:28:01.291849 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.291858 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.291867 18283 layer_factory.hpp:77] Creating layer Concat3
I0813 08:28:01.291879 18283 net.cpp:91] Creating Layer Concat3
I0813 08:28:01.291889 18283 net.cpp:425] Concat3 <- i1_i1_0_split_2
I0813 08:28:01.291899 18283 net.cpp:425] Concat3 <- i13
I0813 08:28:01.291913 18283 net.cpp:399] Concat3 -> Concat3
I0813 08:28:01.291930 18283 net.cpp:141] Setting up Concat3
I0813 08:28:01.291940 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.291946 18283 net.cpp:156] Memory required for data: 109059200
I0813 08:28:01.291954 18283 layer_factory.hpp:77] Creating layer InnerProduct5
I0813 08:28:01.291968 18283 net.cpp:91] Creating Layer InnerProduct5
I0813 08:28:01.291978 18283 net.cpp:425] InnerProduct5 <- Concat3
I0813 08:28:01.291990 18283 net.cpp:399] InnerProduct5 -> InnerProduct5
I0813 08:28:01.308439 18283 net.cpp:141] Setting up InnerProduct5
I0813 08:28:01.308476 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.308482 18283 net.cpp:156] Memory required for data: 109161600
I0813 08:28:01.308495 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.308506 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.308512 18283 layer_factory.hpp:77] Creating layer ReLU5
I0813 08:28:01.308534 18283 net.cpp:91] Creating Layer ReLU5
I0813 08:28:01.308547 18283 net.cpp:425] ReLU5 <- InnerProduct5
I0813 08:28:01.308565 18283 net.cpp:386] ReLU5 -> InnerProduct5 (in-place)
I0813 08:28:01.308586 18283 net.cpp:141] Setting up ReLU5
I0813 08:28:01.308596 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.308603 18283 net.cpp:156] Memory required for data: 109264000
I0813 08:28:01.308609 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.308648 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.308660 18283 net.cpp:425] drop1 <- InnerProduct5
I0813 08:28:01.308672 18283 net.cpp:399] drop1 -> Dropout5
I0813 08:28:01.308692 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.308702 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.308708 18283 net.cpp:156] Memory required for data: 109366400
I0813 08:28:01.308715 18283 layer_factory.hpp:77] Creating layer InnerProduct6
I0813 08:28:01.308733 18283 net.cpp:91] Creating Layer InnerProduct6
I0813 08:28:01.308742 18283 net.cpp:425] InnerProduct6 <- Dropout5
I0813 08:28:01.308754 18283 net.cpp:399] InnerProduct6 -> InnerProduct6
I0813 08:28:01.309006 18283 net.cpp:141] Setting up InnerProduct6
I0813 08:28:01.309018 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.309025 18283 net.cpp:156] Memory required for data: 109417600
I0813 08:28:01.309032 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.309041 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.309048 18283 layer_factory.hpp:77] Creating layer ReLU6
I0813 08:28:01.309062 18283 net.cpp:91] Creating Layer ReLU6
I0813 08:28:01.309069 18283 net.cpp:425] ReLU6 <- InnerProduct6
I0813 08:28:01.309080 18283 net.cpp:386] ReLU6 -> InnerProduct6 (in-place)
I0813 08:28:01.309093 18283 net.cpp:141] Setting up ReLU6
I0813 08:28:01.309103 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.309108 18283 net.cpp:156] Memory required for data: 109468800
I0813 08:28:01.309115 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.309126 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.309134 18283 net.cpp:425] drop2 <- InnerProduct6
I0813 08:28:01.309144 18283 net.cpp:399] drop2 -> Dropout6
I0813 08:28:01.309159 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.309170 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.309176 18283 net.cpp:156] Memory required for data: 109520000
I0813 08:28:01.309182 18283 layer_factory.hpp:77] Creating layer m3
I0813 08:28:01.309197 18283 net.cpp:91] Creating Layer m3
I0813 08:28:01.309207 18283 net.cpp:425] m3 <- Dropout6
I0813 08:28:01.309222 18283 net.cpp:399] m3 -> m3
I0813 08:28:01.309259 18283 net.cpp:141] Setting up m3
I0813 08:28:01.309272 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.309279 18283 net.cpp:156] Memory required for data: 109520400
I0813 08:28:01.309293 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.309303 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.309311 18283 layer_factory.hpp:77] Creating layer Concat4
I0813 08:28:01.309326 18283 net.cpp:91] Creating Layer Concat4
I0813 08:28:01.309335 18283 net.cpp:425] Concat4 <- i1_i1_0_split_3
I0813 08:28:01.309345 18283 net.cpp:425] Concat4 <- i14
I0813 08:28:01.309356 18283 net.cpp:399] Concat4 -> Concat4
I0813 08:28:01.309373 18283 net.cpp:141] Setting up Concat4
I0813 08:28:01.309383 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.309391 18283 net.cpp:156] Memory required for data: 112797200
I0813 08:28:01.309396 18283 layer_factory.hpp:77] Creating layer InnerProduct7
I0813 08:28:01.309418 18283 net.cpp:91] Creating Layer InnerProduct7
I0813 08:28:01.309427 18283 net.cpp:425] InnerProduct7 <- Concat4
I0813 08:28:01.309439 18283 net.cpp:399] InnerProduct7 -> InnerProduct7
I0813 08:28:01.326488 18283 net.cpp:141] Setting up InnerProduct7
I0813 08:28:01.326531 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.326539 18283 net.cpp:156] Memory required for data: 112899600
I0813 08:28:01.326553 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.326563 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.326572 18283 layer_factory.hpp:77] Creating layer ReLU7
I0813 08:28:01.326594 18283 net.cpp:91] Creating Layer ReLU7
I0813 08:28:01.326632 18283 net.cpp:425] ReLU7 <- InnerProduct7
I0813 08:28:01.326650 18283 net.cpp:386] ReLU7 -> InnerProduct7 (in-place)
I0813 08:28:01.326671 18283 net.cpp:141] Setting up ReLU7
I0813 08:28:01.326681 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.326689 18283 net.cpp:156] Memory required for data: 113002000
I0813 08:28:01.326695 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.326709 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.326717 18283 net.cpp:425] drop1 <- InnerProduct7
I0813 08:28:01.326730 18283 net.cpp:399] drop1 -> Dropout7
I0813 08:28:01.326751 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.326761 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.326767 18283 net.cpp:156] Memory required for data: 113104400
I0813 08:28:01.326773 18283 layer_factory.hpp:77] Creating layer InnerProduct8
I0813 08:28:01.326793 18283 net.cpp:91] Creating Layer InnerProduct8
I0813 08:28:01.326800 18283 net.cpp:425] InnerProduct8 <- Dropout7
I0813 08:28:01.326813 18283 net.cpp:399] InnerProduct8 -> InnerProduct8
I0813 08:28:01.327057 18283 net.cpp:141] Setting up InnerProduct8
I0813 08:28:01.327069 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.327075 18283 net.cpp:156] Memory required for data: 113155600
I0813 08:28:01.327082 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.327091 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.327098 18283 layer_factory.hpp:77] Creating layer ReLU8
I0813 08:28:01.327108 18283 net.cpp:91] Creating Layer ReLU8
I0813 08:28:01.327116 18283 net.cpp:425] ReLU8 <- InnerProduct8
I0813 08:28:01.327126 18283 net.cpp:386] ReLU8 -> InnerProduct8 (in-place)
I0813 08:28:01.327139 18283 net.cpp:141] Setting up ReLU8
I0813 08:28:01.327148 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.327154 18283 net.cpp:156] Memory required for data: 113206800
I0813 08:28:01.327162 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.327172 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.327179 18283 net.cpp:425] drop2 <- InnerProduct8
I0813 08:28:01.327188 18283 net.cpp:399] drop2 -> Dropout8
I0813 08:28:01.327203 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.327211 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.327217 18283 net.cpp:156] Memory required for data: 113258000
I0813 08:28:01.327224 18283 layer_factory.hpp:77] Creating layer m4
I0813 08:28:01.327240 18283 net.cpp:91] Creating Layer m4
I0813 08:28:01.327249 18283 net.cpp:425] m4 <- Dropout8
I0813 08:28:01.327260 18283 net.cpp:399] m4 -> m4
I0813 08:28:01.327286 18283 net.cpp:141] Setting up m4
I0813 08:28:01.327294 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.327301 18283 net.cpp:156] Memory required for data: 113258400
I0813 08:28:01.327308 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.327316 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.327324 18283 layer_factory.hpp:77] Creating layer Concat5
I0813 08:28:01.327338 18283 net.cpp:91] Creating Layer Concat5
I0813 08:28:01.327348 18283 net.cpp:425] Concat5 <- i1_i1_0_split_4
I0813 08:28:01.327358 18283 net.cpp:425] Concat5 <- i15
I0813 08:28:01.327370 18283 net.cpp:399] Concat5 -> Concat5
I0813 08:28:01.327388 18283 net.cpp:141] Setting up Concat5
I0813 08:28:01.327396 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.327402 18283 net.cpp:156] Memory required for data: 116535200
I0813 08:28:01.327409 18283 layer_factory.hpp:77] Creating layer InnerProduct9
I0813 08:28:01.327424 18283 net.cpp:91] Creating Layer InnerProduct9
I0813 08:28:01.327432 18283 net.cpp:425] InnerProduct9 <- Concat5
I0813 08:28:01.327443 18283 net.cpp:399] InnerProduct9 -> InnerProduct9
I0813 08:28:01.343822 18283 net.cpp:141] Setting up InnerProduct9
I0813 08:28:01.343863 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.343870 18283 net.cpp:156] Memory required for data: 116637600
I0813 08:28:01.343929 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.343943 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.343955 18283 layer_factory.hpp:77] Creating layer ReLU9
I0813 08:28:01.343978 18283 net.cpp:91] Creating Layer ReLU9
I0813 08:28:01.343991 18283 net.cpp:425] ReLU9 <- InnerProduct9
I0813 08:28:01.344004 18283 net.cpp:386] ReLU9 -> InnerProduct9 (in-place)
I0813 08:28:01.344036 18283 net.cpp:141] Setting up ReLU9
I0813 08:28:01.344048 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.344055 18283 net.cpp:156] Memory required for data: 116740000
I0813 08:28:01.344063 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.344079 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.344087 18283 net.cpp:425] drop1 <- InnerProduct9
I0813 08:28:01.344099 18283 net.cpp:399] drop1 -> Dropout9
I0813 08:28:01.344117 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.344126 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.344133 18283 net.cpp:156] Memory required for data: 116842400
I0813 08:28:01.344141 18283 layer_factory.hpp:77] Creating layer InnerProduct10
I0813 08:28:01.344158 18283 net.cpp:91] Creating Layer InnerProduct10
I0813 08:28:01.344166 18283 net.cpp:425] InnerProduct10 <- Dropout9
I0813 08:28:01.344178 18283 net.cpp:399] InnerProduct10 -> InnerProduct10
I0813 08:28:01.344424 18283 net.cpp:141] Setting up InnerProduct10
I0813 08:28:01.344436 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.344442 18283 net.cpp:156] Memory required for data: 116893600
I0813 08:28:01.344449 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.344458 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.344465 18283 layer_factory.hpp:77] Creating layer ReLU10
I0813 08:28:01.344476 18283 net.cpp:91] Creating Layer ReLU10
I0813 08:28:01.344485 18283 net.cpp:425] ReLU10 <- InnerProduct10
I0813 08:28:01.344496 18283 net.cpp:386] ReLU10 -> InnerProduct10 (in-place)
I0813 08:28:01.344506 18283 net.cpp:141] Setting up ReLU10
I0813 08:28:01.344516 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.344521 18283 net.cpp:156] Memory required for data: 116944800
I0813 08:28:01.344528 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.344539 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.344548 18283 net.cpp:425] drop2 <- InnerProduct10
I0813 08:28:01.344558 18283 net.cpp:399] drop2 -> Dropout10
I0813 08:28:01.344571 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.344581 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.344588 18283 net.cpp:156] Memory required for data: 116996000
I0813 08:28:01.344594 18283 layer_factory.hpp:77] Creating layer m5
I0813 08:28:01.344609 18283 net.cpp:91] Creating Layer m5
I0813 08:28:01.344617 18283 net.cpp:425] m5 <- Dropout10
I0813 08:28:01.344630 18283 net.cpp:399] m5 -> m5
I0813 08:28:01.344655 18283 net.cpp:141] Setting up m5
I0813 08:28:01.344665 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.344671 18283 net.cpp:156] Memory required for data: 116996400
I0813 08:28:01.344678 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.344687 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.344694 18283 layer_factory.hpp:77] Creating layer Concat6
I0813 08:28:01.344707 18283 net.cpp:91] Creating Layer Concat6
I0813 08:28:01.344717 18283 net.cpp:425] Concat6 <- i1_i1_0_split_5
I0813 08:28:01.344727 18283 net.cpp:425] Concat6 <- i16
I0813 08:28:01.344738 18283 net.cpp:399] Concat6 -> Concat6
I0813 08:28:01.344756 18283 net.cpp:141] Setting up Concat6
I0813 08:28:01.344766 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.344772 18283 net.cpp:156] Memory required for data: 120273200
I0813 08:28:01.344779 18283 layer_factory.hpp:77] Creating layer InnerProduct11
I0813 08:28:01.344808 18283 net.cpp:91] Creating Layer InnerProduct11
I0813 08:28:01.344816 18283 net.cpp:425] InnerProduct11 <- Concat6
I0813 08:28:01.344830 18283 net.cpp:399] InnerProduct11 -> InnerProduct11
I0813 08:28:01.361505 18283 net.cpp:141] Setting up InnerProduct11
I0813 08:28:01.361544 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.361552 18283 net.cpp:156] Memory required for data: 120375600
I0813 08:28:01.361564 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.361574 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.361582 18283 layer_factory.hpp:77] Creating layer ReLU11
I0813 08:28:01.361603 18283 net.cpp:91] Creating Layer ReLU11
I0813 08:28:01.361614 18283 net.cpp:425] ReLU11 <- InnerProduct11
I0813 08:28:01.361637 18283 net.cpp:386] ReLU11 -> InnerProduct11 (in-place)
I0813 08:28:01.361661 18283 net.cpp:141] Setting up ReLU11
I0813 08:28:01.361678 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.361685 18283 net.cpp:156] Memory required for data: 120478000
I0813 08:28:01.361692 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.361706 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.361716 18283 net.cpp:425] drop1 <- InnerProduct11
I0813 08:28:01.361727 18283 net.cpp:399] drop1 -> Dropout11
I0813 08:28:01.361747 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.361757 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.361773 18283 net.cpp:156] Memory required for data: 120580400
I0813 08:28:01.361780 18283 layer_factory.hpp:77] Creating layer InnerProduct12
I0813 08:28:01.361799 18283 net.cpp:91] Creating Layer InnerProduct12
I0813 08:28:01.361807 18283 net.cpp:425] InnerProduct12 <- Dropout11
I0813 08:28:01.361820 18283 net.cpp:399] InnerProduct12 -> InnerProduct12
I0813 08:28:01.362076 18283 net.cpp:141] Setting up InnerProduct12
I0813 08:28:01.362088 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.362095 18283 net.cpp:156] Memory required for data: 120631600
I0813 08:28:01.362118 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.362128 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.362135 18283 layer_factory.hpp:77] Creating layer ReLU12
I0813 08:28:01.362148 18283 net.cpp:91] Creating Layer ReLU12
I0813 08:28:01.362156 18283 net.cpp:425] ReLU12 <- InnerProduct12
I0813 08:28:01.362167 18283 net.cpp:386] ReLU12 -> InnerProduct12 (in-place)
I0813 08:28:01.362179 18283 net.cpp:141] Setting up ReLU12
I0813 08:28:01.362188 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.362198 18283 net.cpp:156] Memory required for data: 120682800
I0813 08:28:01.362205 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.362217 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.362226 18283 net.cpp:425] drop2 <- InnerProduct12
I0813 08:28:01.362236 18283 net.cpp:399] drop2 -> Dropout12
I0813 08:28:01.362251 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.362262 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.362268 18283 net.cpp:156] Memory required for data: 120734000
I0813 08:28:01.362275 18283 layer_factory.hpp:77] Creating layer m6
I0813 08:28:01.362289 18283 net.cpp:91] Creating Layer m6
I0813 08:28:01.362298 18283 net.cpp:425] m6 <- Dropout12
I0813 08:28:01.362313 18283 net.cpp:399] m6 -> m6
I0813 08:28:01.362337 18283 net.cpp:141] Setting up m6
I0813 08:28:01.362346 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.362354 18283 net.cpp:156] Memory required for data: 120734400
I0813 08:28:01.362360 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.362370 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.362377 18283 layer_factory.hpp:77] Creating layer Concat7
I0813 08:28:01.362390 18283 net.cpp:91] Creating Layer Concat7
I0813 08:28:01.362399 18283 net.cpp:425] Concat7 <- i1_i1_0_split_6
I0813 08:28:01.362429 18283 net.cpp:425] Concat7 <- i17
I0813 08:28:01.362442 18283 net.cpp:399] Concat7 -> Concat7
I0813 08:28:01.362460 18283 net.cpp:141] Setting up Concat7
I0813 08:28:01.362470 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.362476 18283 net.cpp:156] Memory required for data: 124011200
I0813 08:28:01.362483 18283 layer_factory.hpp:77] Creating layer InnerProduct13
I0813 08:28:01.362498 18283 net.cpp:91] Creating Layer InnerProduct13
I0813 08:28:01.362509 18283 net.cpp:425] InnerProduct13 <- Concat7
I0813 08:28:01.362520 18283 net.cpp:399] InnerProduct13 -> InnerProduct13
I0813 08:28:01.379020 18283 net.cpp:141] Setting up InnerProduct13
I0813 08:28:01.379060 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.379067 18283 net.cpp:156] Memory required for data: 124113600
I0813 08:28:01.379079 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.379089 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.379097 18283 layer_factory.hpp:77] Creating layer ReLU13
I0813 08:28:01.379118 18283 net.cpp:91] Creating Layer ReLU13
I0813 08:28:01.379140 18283 net.cpp:425] ReLU13 <- InnerProduct13
I0813 08:28:01.379155 18283 net.cpp:386] ReLU13 -> InnerProduct13 (in-place)
I0813 08:28:01.379176 18283 net.cpp:141] Setting up ReLU13
I0813 08:28:01.379185 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.379192 18283 net.cpp:156] Memory required for data: 124216000
I0813 08:28:01.379199 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.379215 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.379222 18283 net.cpp:425] drop1 <- InnerProduct13
I0813 08:28:01.379235 18283 net.cpp:399] drop1 -> Dropout13
I0813 08:28:01.379256 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.379266 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.379272 18283 net.cpp:156] Memory required for data: 124318400
I0813 08:28:01.379279 18283 layer_factory.hpp:77] Creating layer InnerProduct14
I0813 08:28:01.379297 18283 net.cpp:91] Creating Layer InnerProduct14
I0813 08:28:01.379305 18283 net.cpp:425] InnerProduct14 <- Dropout13
I0813 08:28:01.379318 18283 net.cpp:399] InnerProduct14 -> InnerProduct14
I0813 08:28:01.379570 18283 net.cpp:141] Setting up InnerProduct14
I0813 08:28:01.379580 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.379587 18283 net.cpp:156] Memory required for data: 124369600
I0813 08:28:01.379595 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.379603 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.379611 18283 layer_factory.hpp:77] Creating layer ReLU14
I0813 08:28:01.379621 18283 net.cpp:91] Creating Layer ReLU14
I0813 08:28:01.379631 18283 net.cpp:425] ReLU14 <- InnerProduct14
I0813 08:28:01.379640 18283 net.cpp:386] ReLU14 -> InnerProduct14 (in-place)
I0813 08:28:01.379652 18283 net.cpp:141] Setting up ReLU14
I0813 08:28:01.379660 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.379667 18283 net.cpp:156] Memory required for data: 124420800
I0813 08:28:01.379673 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.379685 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.379693 18283 net.cpp:425] drop2 <- InnerProduct14
I0813 08:28:01.379704 18283 net.cpp:399] drop2 -> Dropout14
I0813 08:28:01.379719 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.379729 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.379735 18283 net.cpp:156] Memory required for data: 124472000
I0813 08:28:01.379742 18283 layer_factory.hpp:77] Creating layer m7
I0813 08:28:01.379757 18283 net.cpp:91] Creating Layer m7
I0813 08:28:01.379765 18283 net.cpp:425] m7 <- Dropout14
I0813 08:28:01.379779 18283 net.cpp:399] m7 -> m7
I0813 08:28:01.379804 18283 net.cpp:141] Setting up m7
I0813 08:28:01.379813 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.379820 18283 net.cpp:156] Memory required for data: 124472400
I0813 08:28:01.379849 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.379859 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.379866 18283 layer_factory.hpp:77] Creating layer Concat8
I0813 08:28:01.379881 18283 net.cpp:91] Creating Layer Concat8
I0813 08:28:01.379891 18283 net.cpp:425] Concat8 <- i1_i1_0_split_7
I0813 08:28:01.379902 18283 net.cpp:425] Concat8 <- i18
I0813 08:28:01.379915 18283 net.cpp:399] Concat8 -> Concat8
I0813 08:28:01.379933 18283 net.cpp:141] Setting up Concat8
I0813 08:28:01.379942 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.379950 18283 net.cpp:156] Memory required for data: 127749200
I0813 08:28:01.379956 18283 layer_factory.hpp:77] Creating layer InnerProduct15
I0813 08:28:01.379982 18283 net.cpp:91] Creating Layer InnerProduct15
I0813 08:28:01.379990 18283 net.cpp:425] InnerProduct15 <- Concat8
I0813 08:28:01.380002 18283 net.cpp:399] InnerProduct15 -> InnerProduct15
I0813 08:28:01.396442 18283 net.cpp:141] Setting up InnerProduct15
I0813 08:28:01.396487 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.396494 18283 net.cpp:156] Memory required for data: 127851600
I0813 08:28:01.396507 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.396517 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.396527 18283 layer_factory.hpp:77] Creating layer ReLU15
I0813 08:28:01.396549 18283 net.cpp:91] Creating Layer ReLU15
I0813 08:28:01.396569 18283 net.cpp:425] ReLU15 <- InnerProduct15
I0813 08:28:01.396584 18283 net.cpp:386] ReLU15 -> InnerProduct15 (in-place)
I0813 08:28:01.396605 18283 net.cpp:141] Setting up ReLU15
I0813 08:28:01.396615 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.396621 18283 net.cpp:156] Memory required for data: 127954000
I0813 08:28:01.396628 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.396643 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.396652 18283 net.cpp:425] drop1 <- InnerProduct15
I0813 08:28:01.396664 18283 net.cpp:399] drop1 -> Dropout15
I0813 08:28:01.396682 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.396692 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.396698 18283 net.cpp:156] Memory required for data: 128056400
I0813 08:28:01.396705 18283 layer_factory.hpp:77] Creating layer InnerProduct16
I0813 08:28:01.396723 18283 net.cpp:91] Creating Layer InnerProduct16
I0813 08:28:01.396733 18283 net.cpp:425] InnerProduct16 <- Dropout15
I0813 08:28:01.396745 18283 net.cpp:399] InnerProduct16 -> InnerProduct16
I0813 08:28:01.396996 18283 net.cpp:141] Setting up InnerProduct16
I0813 08:28:01.397006 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.397012 18283 net.cpp:156] Memory required for data: 128107600
I0813 08:28:01.397020 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.397029 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.397037 18283 layer_factory.hpp:77] Creating layer ReLU16
I0813 08:28:01.397047 18283 net.cpp:91] Creating Layer ReLU16
I0813 08:28:01.397056 18283 net.cpp:425] ReLU16 <- InnerProduct16
I0813 08:28:01.397066 18283 net.cpp:386] ReLU16 -> InnerProduct16 (in-place)
I0813 08:28:01.397078 18283 net.cpp:141] Setting up ReLU16
I0813 08:28:01.397088 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.397094 18283 net.cpp:156] Memory required for data: 128158800
I0813 08:28:01.397100 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.397112 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.397120 18283 net.cpp:425] drop2 <- InnerProduct16
I0813 08:28:01.397131 18283 net.cpp:399] drop2 -> Dropout16
I0813 08:28:01.397145 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.397156 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.397161 18283 net.cpp:156] Memory required for data: 128210000
I0813 08:28:01.397192 18283 layer_factory.hpp:77] Creating layer m8
I0813 08:28:01.397208 18283 net.cpp:91] Creating Layer m8
I0813 08:28:01.397217 18283 net.cpp:425] m8 <- Dropout16
I0813 08:28:01.397233 18283 net.cpp:399] m8 -> m8
I0813 08:28:01.397260 18283 net.cpp:141] Setting up m8
I0813 08:28:01.397269 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.397276 18283 net.cpp:156] Memory required for data: 128210400
I0813 08:28:01.397284 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.397292 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.397300 18283 layer_factory.hpp:77] Creating layer Concat9
I0813 08:28:01.397315 18283 net.cpp:91] Creating Layer Concat9
I0813 08:28:01.397325 18283 net.cpp:425] Concat9 <- i1_i1_0_split_8
I0813 08:28:01.397335 18283 net.cpp:425] Concat9 <- i19
I0813 08:28:01.397348 18283 net.cpp:399] Concat9 -> Concat9
I0813 08:28:01.397366 18283 net.cpp:141] Setting up Concat9
I0813 08:28:01.397374 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.397380 18283 net.cpp:156] Memory required for data: 131487200
I0813 08:28:01.397387 18283 layer_factory.hpp:77] Creating layer InnerProduct17
I0813 08:28:01.397403 18283 net.cpp:91] Creating Layer InnerProduct17
I0813 08:28:01.397411 18283 net.cpp:425] InnerProduct17 <- Concat9
I0813 08:28:01.397423 18283 net.cpp:399] InnerProduct17 -> InnerProduct17
I0813 08:28:01.414264 18283 net.cpp:141] Setting up InnerProduct17
I0813 08:28:01.414311 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.414319 18283 net.cpp:156] Memory required for data: 131589600
I0813 08:28:01.414330 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.414340 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.414347 18283 layer_factory.hpp:77] Creating layer ReLU17
I0813 08:28:01.414373 18283 net.cpp:91] Creating Layer ReLU17
I0813 08:28:01.414397 18283 net.cpp:425] ReLU17 <- InnerProduct17
I0813 08:28:01.414412 18283 net.cpp:386] ReLU17 -> InnerProduct17 (in-place)
I0813 08:28:01.414433 18283 net.cpp:141] Setting up ReLU17
I0813 08:28:01.414444 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.414455 18283 net.cpp:156] Memory required for data: 131692000
I0813 08:28:01.414463 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.414482 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.414491 18283 net.cpp:425] drop1 <- InnerProduct17
I0813 08:28:01.414504 18283 net.cpp:399] drop1 -> Dropout17
I0813 08:28:01.414525 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.414537 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.414548 18283 net.cpp:156] Memory required for data: 131794400
I0813 08:28:01.414556 18283 layer_factory.hpp:77] Creating layer InnerProduct18
I0813 08:28:01.414577 18283 net.cpp:91] Creating Layer InnerProduct18
I0813 08:28:01.414589 18283 net.cpp:425] InnerProduct18 <- Dropout17
I0813 08:28:01.414602 18283 net.cpp:399] InnerProduct18 -> InnerProduct18
I0813 08:28:01.414857 18283 net.cpp:141] Setting up InnerProduct18
I0813 08:28:01.414870 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.414880 18283 net.cpp:156] Memory required for data: 131845600
I0813 08:28:01.414890 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.414897 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.414906 18283 layer_factory.hpp:77] Creating layer ReLU18
I0813 08:28:01.414918 18283 net.cpp:91] Creating Layer ReLU18
I0813 08:28:01.414928 18283 net.cpp:425] ReLU18 <- InnerProduct18
I0813 08:28:01.414938 18283 net.cpp:386] ReLU18 -> InnerProduct18 (in-place)
I0813 08:28:01.414950 18283 net.cpp:141] Setting up ReLU18
I0813 08:28:01.414959 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.414969 18283 net.cpp:156] Memory required for data: 131896800
I0813 08:28:01.414976 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.415010 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.415019 18283 net.cpp:425] drop2 <- InnerProduct18
I0813 08:28:01.415030 18283 net.cpp:399] drop2 -> Dropout18
I0813 08:28:01.415046 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.415060 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.415066 18283 net.cpp:156] Memory required for data: 131948000
I0813 08:28:01.415073 18283 layer_factory.hpp:77] Creating layer m9
I0813 08:28:01.415089 18283 net.cpp:91] Creating Layer m9
I0813 08:28:01.415098 18283 net.cpp:425] m9 <- Dropout18
I0813 08:28:01.415112 18283 net.cpp:399] m9 -> m9
I0813 08:28:01.415138 18283 net.cpp:141] Setting up m9
I0813 08:28:01.415148 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.415154 18283 net.cpp:156] Memory required for data: 131948400
I0813 08:28:01.415163 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.415171 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.415179 18283 layer_factory.hpp:77] Creating layer Concat10
I0813 08:28:01.415191 18283 net.cpp:91] Creating Layer Concat10
I0813 08:28:01.415201 18283 net.cpp:425] Concat10 <- i1_i1_0_split_9
I0813 08:28:01.415210 18283 net.cpp:425] Concat10 <- i20
I0813 08:28:01.415222 18283 net.cpp:399] Concat10 -> Concat10
I0813 08:28:01.415241 18283 net.cpp:141] Setting up Concat10
I0813 08:28:01.415251 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.415257 18283 net.cpp:156] Memory required for data: 135225200
I0813 08:28:01.415264 18283 layer_factory.hpp:77] Creating layer InnerProduct19
I0813 08:28:01.415278 18283 net.cpp:91] Creating Layer InnerProduct19
I0813 08:28:01.415287 18283 net.cpp:425] InnerProduct19 <- Concat10
I0813 08:28:01.415299 18283 net.cpp:399] InnerProduct19 -> InnerProduct19
I0813 08:28:01.431543 18283 net.cpp:141] Setting up InnerProduct19
I0813 08:28:01.431592 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.431601 18283 net.cpp:156] Memory required for data: 135327600
I0813 08:28:01.431614 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.431624 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.431632 18283 layer_factory.hpp:77] Creating layer ReLU19
I0813 08:28:01.431653 18283 net.cpp:91] Creating Layer ReLU19
I0813 08:28:01.431666 18283 net.cpp:425] ReLU19 <- InnerProduct19
I0813 08:28:01.431685 18283 net.cpp:386] ReLU19 -> InnerProduct19 (in-place)
I0813 08:28:01.431710 18283 net.cpp:141] Setting up ReLU19
I0813 08:28:01.431720 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.431726 18283 net.cpp:156] Memory required for data: 135430000
I0813 08:28:01.431733 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.431748 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.431757 18283 net.cpp:425] drop1 <- InnerProduct19
I0813 08:28:01.431769 18283 net.cpp:399] drop1 -> Dropout19
I0813 08:28:01.431787 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.431797 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.431803 18283 net.cpp:156] Memory required for data: 135532400
I0813 08:28:01.431812 18283 layer_factory.hpp:77] Creating layer InnerProduct20
I0813 08:28:01.431830 18283 net.cpp:91] Creating Layer InnerProduct20
I0813 08:28:01.431838 18283 net.cpp:425] InnerProduct20 <- Dropout19
I0813 08:28:01.431851 18283 net.cpp:399] InnerProduct20 -> InnerProduct20
I0813 08:28:01.432129 18283 net.cpp:141] Setting up InnerProduct20
I0813 08:28:01.432142 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.432149 18283 net.cpp:156] Memory required for data: 135583600
I0813 08:28:01.432158 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.432168 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.432174 18283 layer_factory.hpp:77] Creating layer ReLU20
I0813 08:28:01.432188 18283 net.cpp:91] Creating Layer ReLU20
I0813 08:28:01.432217 18283 net.cpp:425] ReLU20 <- InnerProduct20
I0813 08:28:01.432229 18283 net.cpp:386] ReLU20 -> InnerProduct20 (in-place)
I0813 08:28:01.432245 18283 net.cpp:141] Setting up ReLU20
I0813 08:28:01.432255 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.432260 18283 net.cpp:156] Memory required for data: 135634800
I0813 08:28:01.432267 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.432281 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.432288 18283 net.cpp:425] drop2 <- InnerProduct20
I0813 08:28:01.432298 18283 net.cpp:399] drop2 -> Dropout20
I0813 08:28:01.432313 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.432323 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.432329 18283 net.cpp:156] Memory required for data: 135686000
I0813 08:28:01.432337 18283 layer_factory.hpp:77] Creating layer m10
I0813 08:28:01.432353 18283 net.cpp:91] Creating Layer m10
I0813 08:28:01.432361 18283 net.cpp:425] m10 <- Dropout20
I0813 08:28:01.432374 18283 net.cpp:399] m10 -> m10
I0813 08:28:01.432401 18283 net.cpp:141] Setting up m10
I0813 08:28:01.432410 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.432416 18283 net.cpp:156] Memory required for data: 135686400
I0813 08:28:01.432425 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.432433 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.432440 18283 layer_factory.hpp:77] Creating layer Concat11
I0813 08:28:01.432456 18283 net.cpp:91] Creating Layer Concat11
I0813 08:28:01.432464 18283 net.cpp:425] Concat11 <- i2
I0813 08:28:01.432473 18283 net.cpp:425] Concat11 <- i11_i1_10_split_1
I0813 08:28:01.432487 18283 net.cpp:399] Concat11 -> Concat11
I0813 08:28:01.432503 18283 net.cpp:141] Setting up Concat11
I0813 08:28:01.432515 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.432523 18283 net.cpp:156] Memory required for data: 138963200
I0813 08:28:01.432529 18283 layer_factory.hpp:77] Creating layer InnerProduct21
I0813 08:28:01.432543 18283 net.cpp:91] Creating Layer InnerProduct21
I0813 08:28:01.432551 18283 net.cpp:425] InnerProduct21 <- Concat11
I0813 08:28:01.432564 18283 net.cpp:399] InnerProduct21 -> InnerProduct21
I0813 08:28:01.449324 18283 net.cpp:141] Setting up InnerProduct21
I0813 08:28:01.449367 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.449373 18283 net.cpp:156] Memory required for data: 139065600
I0813 08:28:01.449385 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.449395 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.449403 18283 layer_factory.hpp:77] Creating layer ReLU21
I0813 08:28:01.449424 18283 net.cpp:91] Creating Layer ReLU21
I0813 08:28:01.449435 18283 net.cpp:425] ReLU21 <- InnerProduct21
I0813 08:28:01.449460 18283 net.cpp:386] ReLU21 -> InnerProduct21 (in-place)
I0813 08:28:01.449483 18283 net.cpp:141] Setting up ReLU21
I0813 08:28:01.449492 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.449499 18283 net.cpp:156] Memory required for data: 139168000
I0813 08:28:01.449506 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.449522 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.449529 18283 net.cpp:425] drop1 <- InnerProduct21
I0813 08:28:01.449542 18283 net.cpp:399] drop1 -> Dropout21
I0813 08:28:01.449563 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.449573 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.449579 18283 net.cpp:156] Memory required for data: 139270400
I0813 08:28:01.449586 18283 layer_factory.hpp:77] Creating layer InnerProduct22
I0813 08:28:01.449604 18283 net.cpp:91] Creating Layer InnerProduct22
I0813 08:28:01.449611 18283 net.cpp:425] InnerProduct22 <- Dropout21
I0813 08:28:01.449625 18283 net.cpp:399] InnerProduct22 -> InnerProduct22
I0813 08:28:01.449872 18283 net.cpp:141] Setting up InnerProduct22
I0813 08:28:01.449883 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.449913 18283 net.cpp:156] Memory required for data: 139321600
I0813 08:28:01.449923 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.449931 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.449939 18283 layer_factory.hpp:77] Creating layer ReLU22
I0813 08:28:01.449949 18283 net.cpp:91] Creating Layer ReLU22
I0813 08:28:01.449957 18283 net.cpp:425] ReLU22 <- InnerProduct22
I0813 08:28:01.449967 18283 net.cpp:386] ReLU22 -> InnerProduct22 (in-place)
I0813 08:28:01.449980 18283 net.cpp:141] Setting up ReLU22
I0813 08:28:01.449990 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.449998 18283 net.cpp:156] Memory required for data: 139372800
I0813 08:28:01.450004 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.450016 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.450026 18283 net.cpp:425] drop2 <- InnerProduct22
I0813 08:28:01.450037 18283 net.cpp:399] drop2 -> Dropout22
I0813 08:28:01.450050 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.450060 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.450067 18283 net.cpp:156] Memory required for data: 139424000
I0813 08:28:01.450073 18283 layer_factory.hpp:77] Creating layer m11
I0813 08:28:01.450088 18283 net.cpp:91] Creating Layer m11
I0813 08:28:01.450095 18283 net.cpp:425] m11 <- Dropout22
I0813 08:28:01.450109 18283 net.cpp:399] m11 -> m11
I0813 08:28:01.450134 18283 net.cpp:141] Setting up m11
I0813 08:28:01.450145 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.450151 18283 net.cpp:156] Memory required for data: 139424400
I0813 08:28:01.450176 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.450187 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.450194 18283 layer_factory.hpp:77] Creating layer Concat12
I0813 08:28:01.450208 18283 net.cpp:91] Creating Layer Concat12
I0813 08:28:01.450217 18283 net.cpp:425] Concat12 <- i3
I0813 08:28:01.450227 18283 net.cpp:425] Concat12 <- i11_i1_10_split_2
I0813 08:28:01.450238 18283 net.cpp:399] Concat12 -> Concat12
I0813 08:28:01.450254 18283 net.cpp:141] Setting up Concat12
I0813 08:28:01.450264 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.450271 18283 net.cpp:156] Memory required for data: 142701200
I0813 08:28:01.450278 18283 layer_factory.hpp:77] Creating layer InnerProduct23
I0813 08:28:01.450290 18283 net.cpp:91] Creating Layer InnerProduct23
I0813 08:28:01.450299 18283 net.cpp:425] InnerProduct23 <- Concat12
I0813 08:28:01.450311 18283 net.cpp:399] InnerProduct23 -> InnerProduct23
I0813 08:28:01.466701 18283 net.cpp:141] Setting up InnerProduct23
I0813 08:28:01.466745 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.466753 18283 net.cpp:156] Memory required for data: 142803600
I0813 08:28:01.466764 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.466774 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.466781 18283 layer_factory.hpp:77] Creating layer ReLU23
I0813 08:28:01.466802 18283 net.cpp:91] Creating Layer ReLU23
I0813 08:28:01.466815 18283 net.cpp:425] ReLU23 <- InnerProduct23
I0813 08:28:01.466836 18283 net.cpp:386] ReLU23 -> InnerProduct23 (in-place)
I0813 08:28:01.466859 18283 net.cpp:141] Setting up ReLU23
I0813 08:28:01.466868 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.466874 18283 net.cpp:156] Memory required for data: 142906000
I0813 08:28:01.466881 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.466897 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.466905 18283 net.cpp:425] drop1 <- InnerProduct23
I0813 08:28:01.466918 18283 net.cpp:399] drop1 -> Dropout23
I0813 08:28:01.466938 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.466948 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.466954 18283 net.cpp:156] Memory required for data: 143008400
I0813 08:28:01.466987 18283 layer_factory.hpp:77] Creating layer InnerProduct24
I0813 08:28:01.467006 18283 net.cpp:91] Creating Layer InnerProduct24
I0813 08:28:01.467015 18283 net.cpp:425] InnerProduct24 <- Dropout23
I0813 08:28:01.467028 18283 net.cpp:399] InnerProduct24 -> InnerProduct24
I0813 08:28:01.467283 18283 net.cpp:141] Setting up InnerProduct24
I0813 08:28:01.467293 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.467300 18283 net.cpp:156] Memory required for data: 143059600
I0813 08:28:01.467308 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.467316 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.467324 18283 layer_factory.hpp:77] Creating layer ReLU24
I0813 08:28:01.467334 18283 net.cpp:91] Creating Layer ReLU24
I0813 08:28:01.467344 18283 net.cpp:425] ReLU24 <- InnerProduct24
I0813 08:28:01.467355 18283 net.cpp:386] ReLU24 -> InnerProduct24 (in-place)
I0813 08:28:01.467365 18283 net.cpp:141] Setting up ReLU24
I0813 08:28:01.467375 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.467381 18283 net.cpp:156] Memory required for data: 143110800
I0813 08:28:01.467386 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.467397 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.467406 18283 net.cpp:425] drop2 <- InnerProduct24
I0813 08:28:01.467417 18283 net.cpp:399] drop2 -> Dropout24
I0813 08:28:01.467429 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.467438 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.467444 18283 net.cpp:156] Memory required for data: 143162000
I0813 08:28:01.467452 18283 layer_factory.hpp:77] Creating layer m12
I0813 08:28:01.467466 18283 net.cpp:91] Creating Layer m12
I0813 08:28:01.467475 18283 net.cpp:425] m12 <- Dropout24
I0813 08:28:01.467489 18283 net.cpp:399] m12 -> m12
I0813 08:28:01.467514 18283 net.cpp:141] Setting up m12
I0813 08:28:01.467524 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.467530 18283 net.cpp:156] Memory required for data: 143162400
I0813 08:28:01.467537 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.467546 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.467553 18283 layer_factory.hpp:77] Creating layer Concat13
I0813 08:28:01.467567 18283 net.cpp:91] Creating Layer Concat13
I0813 08:28:01.467576 18283 net.cpp:425] Concat13 <- i4
I0813 08:28:01.467586 18283 net.cpp:425] Concat13 <- i11_i1_10_split_3
I0813 08:28:01.467598 18283 net.cpp:399] Concat13 -> Concat13
I0813 08:28:01.467615 18283 net.cpp:141] Setting up Concat13
I0813 08:28:01.467625 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.467631 18283 net.cpp:156] Memory required for data: 146439200
I0813 08:28:01.467638 18283 layer_factory.hpp:77] Creating layer InnerProduct25
I0813 08:28:01.467653 18283 net.cpp:91] Creating Layer InnerProduct25
I0813 08:28:01.467660 18283 net.cpp:425] InnerProduct25 <- Concat13
I0813 08:28:01.467672 18283 net.cpp:399] InnerProduct25 -> InnerProduct25
I0813 08:28:01.484562 18283 net.cpp:141] Setting up InnerProduct25
I0813 08:28:01.484606 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.484612 18283 net.cpp:156] Memory required for data: 146541600
I0813 08:28:01.484625 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.484634 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.484642 18283 layer_factory.hpp:77] Creating layer ReLU25
I0813 08:28:01.484663 18283 net.cpp:91] Creating Layer ReLU25
I0813 08:28:01.484681 18283 net.cpp:425] ReLU25 <- InnerProduct25
I0813 08:28:01.484696 18283 net.cpp:386] ReLU25 -> InnerProduct25 (in-place)
I0813 08:28:01.484717 18283 net.cpp:141] Setting up ReLU25
I0813 08:28:01.484727 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.484733 18283 net.cpp:156] Memory required for data: 146644000
I0813 08:28:01.484766 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.484781 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.484789 18283 net.cpp:425] drop1 <- InnerProduct25
I0813 08:28:01.484802 18283 net.cpp:399] drop1 -> Dropout25
I0813 08:28:01.484822 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.484833 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.484839 18283 net.cpp:156] Memory required for data: 146746400
I0813 08:28:01.484845 18283 layer_factory.hpp:77] Creating layer InnerProduct26
I0813 08:28:01.484864 18283 net.cpp:91] Creating Layer InnerProduct26
I0813 08:28:01.484871 18283 net.cpp:425] InnerProduct26 <- Dropout25
I0813 08:28:01.484884 18283 net.cpp:399] InnerProduct26 -> InnerProduct26
I0813 08:28:01.485137 18283 net.cpp:141] Setting up InnerProduct26
I0813 08:28:01.485148 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.485154 18283 net.cpp:156] Memory required for data: 146797600
I0813 08:28:01.485162 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.485172 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.485178 18283 layer_factory.hpp:77] Creating layer ReLU26
I0813 08:28:01.485189 18283 net.cpp:91] Creating Layer ReLU26
I0813 08:28:01.485196 18283 net.cpp:425] ReLU26 <- InnerProduct26
I0813 08:28:01.485208 18283 net.cpp:386] ReLU26 -> InnerProduct26 (in-place)
I0813 08:28:01.485221 18283 net.cpp:141] Setting up ReLU26
I0813 08:28:01.485229 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.485235 18283 net.cpp:156] Memory required for data: 146848800
I0813 08:28:01.485242 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.485252 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.485260 18283 net.cpp:425] drop2 <- InnerProduct26
I0813 08:28:01.485270 18283 net.cpp:399] drop2 -> Dropout26
I0813 08:28:01.485285 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.485296 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.485301 18283 net.cpp:156] Memory required for data: 146900000
I0813 08:28:01.485308 18283 layer_factory.hpp:77] Creating layer m13
I0813 08:28:01.485324 18283 net.cpp:91] Creating Layer m13
I0813 08:28:01.485332 18283 net.cpp:425] m13 <- Dropout26
I0813 08:28:01.485345 18283 net.cpp:399] m13 -> m13
I0813 08:28:01.485370 18283 net.cpp:141] Setting up m13
I0813 08:28:01.485378 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.485385 18283 net.cpp:156] Memory required for data: 146900400
I0813 08:28:01.485393 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.485401 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.485409 18283 layer_factory.hpp:77] Creating layer Concat14
I0813 08:28:01.485420 18283 net.cpp:91] Creating Layer Concat14
I0813 08:28:01.485430 18283 net.cpp:425] Concat14 <- i5
I0813 08:28:01.485440 18283 net.cpp:425] Concat14 <- i11_i1_10_split_4
I0813 08:28:01.485452 18283 net.cpp:399] Concat14 -> Concat14
I0813 08:28:01.485471 18283 net.cpp:141] Setting up Concat14
I0813 08:28:01.485481 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.485486 18283 net.cpp:156] Memory required for data: 150177200
I0813 08:28:01.485493 18283 layer_factory.hpp:77] Creating layer InnerProduct27
I0813 08:28:01.485507 18283 net.cpp:91] Creating Layer InnerProduct27
I0813 08:28:01.485517 18283 net.cpp:425] InnerProduct27 <- Concat14
I0813 08:28:01.485529 18283 net.cpp:399] InnerProduct27 -> InnerProduct27
I0813 08:28:01.501966 18283 net.cpp:141] Setting up InnerProduct27
I0813 08:28:01.502008 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.502015 18283 net.cpp:156] Memory required for data: 150279600
I0813 08:28:01.502027 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.502037 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.502044 18283 layer_factory.hpp:77] Creating layer ReLU27
I0813 08:28:01.502100 18283 net.cpp:91] Creating Layer ReLU27
I0813 08:28:01.502115 18283 net.cpp:425] ReLU27 <- InnerProduct27
I0813 08:28:01.502130 18283 net.cpp:386] ReLU27 -> InnerProduct27 (in-place)
I0813 08:28:01.502151 18283 net.cpp:141] Setting up ReLU27
I0813 08:28:01.502161 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.502167 18283 net.cpp:156] Memory required for data: 150382000
I0813 08:28:01.502174 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.502189 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.502197 18283 net.cpp:425] drop1 <- InnerProduct27
I0813 08:28:01.502209 18283 net.cpp:399] drop1 -> Dropout27
I0813 08:28:01.502226 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.502235 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.502241 18283 net.cpp:156] Memory required for data: 150484400
I0813 08:28:01.502249 18283 layer_factory.hpp:77] Creating layer InnerProduct28
I0813 08:28:01.502265 18283 net.cpp:91] Creating Layer InnerProduct28
I0813 08:28:01.502274 18283 net.cpp:425] InnerProduct28 <- Dropout27
I0813 08:28:01.502287 18283 net.cpp:399] InnerProduct28 -> InnerProduct28
I0813 08:28:01.502563 18283 net.cpp:141] Setting up InnerProduct28
I0813 08:28:01.502578 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.502583 18283 net.cpp:156] Memory required for data: 150535600
I0813 08:28:01.502591 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.502600 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.502607 18283 layer_factory.hpp:77] Creating layer ReLU28
I0813 08:28:01.502619 18283 net.cpp:91] Creating Layer ReLU28
I0813 08:28:01.502627 18283 net.cpp:425] ReLU28 <- InnerProduct28
I0813 08:28:01.502638 18283 net.cpp:386] ReLU28 -> InnerProduct28 (in-place)
I0813 08:28:01.502648 18283 net.cpp:141] Setting up ReLU28
I0813 08:28:01.502658 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.502665 18283 net.cpp:156] Memory required for data: 150586800
I0813 08:28:01.502671 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.502681 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.502688 18283 net.cpp:425] drop2 <- InnerProduct28
I0813 08:28:01.502699 18283 net.cpp:399] drop2 -> Dropout28
I0813 08:28:01.502712 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.502722 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.502728 18283 net.cpp:156] Memory required for data: 150638000
I0813 08:28:01.502734 18283 layer_factory.hpp:77] Creating layer m14
I0813 08:28:01.502750 18283 net.cpp:91] Creating Layer m14
I0813 08:28:01.502758 18283 net.cpp:425] m14 <- Dropout28
I0813 08:28:01.502770 18283 net.cpp:399] m14 -> m14
I0813 08:28:01.502794 18283 net.cpp:141] Setting up m14
I0813 08:28:01.502802 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.502810 18283 net.cpp:156] Memory required for data: 150638400
I0813 08:28:01.502816 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.502825 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.502831 18283 layer_factory.hpp:77] Creating layer Concat15
I0813 08:28:01.502845 18283 net.cpp:91] Creating Layer Concat15
I0813 08:28:01.502853 18283 net.cpp:425] Concat15 <- i6
I0813 08:28:01.502863 18283 net.cpp:425] Concat15 <- i11_i1_10_split_5
I0813 08:28:01.502876 18283 net.cpp:399] Concat15 -> Concat15
I0813 08:28:01.502892 18283 net.cpp:141] Setting up Concat15
I0813 08:28:01.502902 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.502908 18283 net.cpp:156] Memory required for data: 153915200
I0813 08:28:01.502914 18283 layer_factory.hpp:77] Creating layer InnerProduct29
I0813 08:28:01.502929 18283 net.cpp:91] Creating Layer InnerProduct29
I0813 08:28:01.502938 18283 net.cpp:425] InnerProduct29 <- Concat15
I0813 08:28:01.502951 18283 net.cpp:399] InnerProduct29 -> InnerProduct29
I0813 08:28:01.519086 18283 net.cpp:141] Setting up InnerProduct29
I0813 08:28:01.519165 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.519173 18283 net.cpp:156] Memory required for data: 154017600
I0813 08:28:01.519186 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.519196 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.519204 18283 layer_factory.hpp:77] Creating layer ReLU29
I0813 08:28:01.519227 18283 net.cpp:91] Creating Layer ReLU29
I0813 08:28:01.519240 18283 net.cpp:425] ReLU29 <- InnerProduct29
I0813 08:28:01.519261 18283 net.cpp:386] ReLU29 -> InnerProduct29 (in-place)
I0813 08:28:01.519284 18283 net.cpp:141] Setting up ReLU29
I0813 08:28:01.519294 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.519299 18283 net.cpp:156] Memory required for data: 154120000
I0813 08:28:01.519306 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.519321 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.519330 18283 net.cpp:425] drop1 <- InnerProduct29
I0813 08:28:01.519341 18283 net.cpp:399] drop1 -> Dropout29
I0813 08:28:01.519358 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.519368 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.519374 18283 net.cpp:156] Memory required for data: 154222400
I0813 08:28:01.519381 18283 layer_factory.hpp:77] Creating layer InnerProduct30
I0813 08:28:01.519400 18283 net.cpp:91] Creating Layer InnerProduct30
I0813 08:28:01.519407 18283 net.cpp:425] InnerProduct30 <- Dropout29
I0813 08:28:01.519421 18283 net.cpp:399] InnerProduct30 -> InnerProduct30
I0813 08:28:01.519717 18283 net.cpp:141] Setting up InnerProduct30
I0813 08:28:01.519728 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.519734 18283 net.cpp:156] Memory required for data: 154273600
I0813 08:28:01.519742 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.519752 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.519758 18283 layer_factory.hpp:77] Creating layer ReLU30
I0813 08:28:01.519769 18283 net.cpp:91] Creating Layer ReLU30
I0813 08:28:01.519778 18283 net.cpp:425] ReLU30 <- InnerProduct30
I0813 08:28:01.519788 18283 net.cpp:386] ReLU30 -> InnerProduct30 (in-place)
I0813 08:28:01.519798 18283 net.cpp:141] Setting up ReLU30
I0813 08:28:01.519807 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.519814 18283 net.cpp:156] Memory required for data: 154324800
I0813 08:28:01.519820 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.519830 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.519837 18283 net.cpp:425] drop2 <- InnerProduct30
I0813 08:28:01.519847 18283 net.cpp:399] drop2 -> Dropout30
I0813 08:28:01.519860 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.519870 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.519877 18283 net.cpp:156] Memory required for data: 154376000
I0813 08:28:01.519883 18283 layer_factory.hpp:77] Creating layer m15
I0813 08:28:01.519898 18283 net.cpp:91] Creating Layer m15
I0813 08:28:01.519906 18283 net.cpp:425] m15 <- Dropout30
I0813 08:28:01.519922 18283 net.cpp:399] m15 -> m15
I0813 08:28:01.519948 18283 net.cpp:141] Setting up m15
I0813 08:28:01.519956 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.519963 18283 net.cpp:156] Memory required for data: 154376400
I0813 08:28:01.519969 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.519979 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.519985 18283 layer_factory.hpp:77] Creating layer Concat16
I0813 08:28:01.519999 18283 net.cpp:91] Creating Layer Concat16
I0813 08:28:01.520007 18283 net.cpp:425] Concat16 <- i7
I0813 08:28:01.520017 18283 net.cpp:425] Concat16 <- i11_i1_10_split_6
I0813 08:28:01.520059 18283 net.cpp:399] Concat16 -> Concat16
I0813 08:28:01.520079 18283 net.cpp:141] Setting up Concat16
I0813 08:28:01.520089 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.520112 18283 net.cpp:156] Memory required for data: 157653200
I0813 08:28:01.520118 18283 layer_factory.hpp:77] Creating layer InnerProduct31
I0813 08:28:01.520159 18283 net.cpp:91] Creating Layer InnerProduct31
I0813 08:28:01.520166 18283 net.cpp:425] InnerProduct31 <- Concat16
I0813 08:28:01.520179 18283 net.cpp:399] InnerProduct31 -> InnerProduct31
I0813 08:28:01.536702 18283 net.cpp:141] Setting up InnerProduct31
I0813 08:28:01.536751 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.536759 18283 net.cpp:156] Memory required for data: 157755600
I0813 08:28:01.536772 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.536782 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.536792 18283 layer_factory.hpp:77] Creating layer ReLU31
I0813 08:28:01.536813 18283 net.cpp:91] Creating Layer ReLU31
I0813 08:28:01.536833 18283 net.cpp:425] ReLU31 <- InnerProduct31
I0813 08:28:01.536846 18283 net.cpp:386] ReLU31 -> InnerProduct31 (in-place)
I0813 08:28:01.536869 18283 net.cpp:141] Setting up ReLU31
I0813 08:28:01.536877 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.536883 18283 net.cpp:156] Memory required for data: 157858000
I0813 08:28:01.536891 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.536906 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.536914 18283 net.cpp:425] drop1 <- InnerProduct31
I0813 08:28:01.536927 18283 net.cpp:399] drop1 -> Dropout31
I0813 08:28:01.536947 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.536957 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.536962 18283 net.cpp:156] Memory required for data: 157960400
I0813 08:28:01.536969 18283 layer_factory.hpp:77] Creating layer InnerProduct32
I0813 08:28:01.536988 18283 net.cpp:91] Creating Layer InnerProduct32
I0813 08:28:01.536996 18283 net.cpp:425] InnerProduct32 <- Dropout31
I0813 08:28:01.537009 18283 net.cpp:399] InnerProduct32 -> InnerProduct32
I0813 08:28:01.537307 18283 net.cpp:141] Setting up InnerProduct32
I0813 08:28:01.537318 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.537325 18283 net.cpp:156] Memory required for data: 158011600
I0813 08:28:01.537333 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.537341 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.537349 18283 layer_factory.hpp:77] Creating layer ReLU32
I0813 08:28:01.537360 18283 net.cpp:91] Creating Layer ReLU32
I0813 08:28:01.537369 18283 net.cpp:425] ReLU32 <- InnerProduct32
I0813 08:28:01.537380 18283 net.cpp:386] ReLU32 -> InnerProduct32 (in-place)
I0813 08:28:01.537394 18283 net.cpp:141] Setting up ReLU32
I0813 08:28:01.537402 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.537410 18283 net.cpp:156] Memory required for data: 158062800
I0813 08:28:01.537415 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.537427 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.537436 18283 net.cpp:425] drop2 <- InnerProduct32
I0813 08:28:01.537446 18283 net.cpp:399] drop2 -> Dropout32
I0813 08:28:01.537459 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.537468 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.537475 18283 net.cpp:156] Memory required for data: 158114000
I0813 08:28:01.537482 18283 layer_factory.hpp:77] Creating layer m16
I0813 08:28:01.537497 18283 net.cpp:91] Creating Layer m16
I0813 08:28:01.537506 18283 net.cpp:425] m16 <- Dropout32
I0813 08:28:01.537520 18283 net.cpp:399] m16 -> m16
I0813 08:28:01.537544 18283 net.cpp:141] Setting up m16
I0813 08:28:01.537554 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.537560 18283 net.cpp:156] Memory required for data: 158114400
I0813 08:28:01.537569 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.537576 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.537585 18283 layer_factory.hpp:77] Creating layer Concat17
I0813 08:28:01.537616 18283 net.cpp:91] Creating Layer Concat17
I0813 08:28:01.537627 18283 net.cpp:425] Concat17 <- i8
I0813 08:28:01.537638 18283 net.cpp:425] Concat17 <- i11_i1_10_split_7
I0813 08:28:01.537652 18283 net.cpp:399] Concat17 -> Concat17
I0813 08:28:01.537669 18283 net.cpp:141] Setting up Concat17
I0813 08:28:01.537679 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.537685 18283 net.cpp:156] Memory required for data: 161391200
I0813 08:28:01.537693 18283 layer_factory.hpp:77] Creating layer InnerProduct33
I0813 08:28:01.537706 18283 net.cpp:91] Creating Layer InnerProduct33
I0813 08:28:01.537714 18283 net.cpp:425] InnerProduct33 <- Concat17
I0813 08:28:01.537727 18283 net.cpp:399] InnerProduct33 -> InnerProduct33
I0813 08:28:01.553774 18283 net.cpp:141] Setting up InnerProduct33
I0813 08:28:01.553817 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.553824 18283 net.cpp:156] Memory required for data: 161493600
I0813 08:28:01.553838 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.553848 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.553854 18283 layer_factory.hpp:77] Creating layer ReLU33
I0813 08:28:01.553876 18283 net.cpp:91] Creating Layer ReLU33
I0813 08:28:01.553894 18283 net.cpp:425] ReLU33 <- InnerProduct33
I0813 08:28:01.553908 18283 net.cpp:386] ReLU33 -> InnerProduct33 (in-place)
I0813 08:28:01.553930 18283 net.cpp:141] Setting up ReLU33
I0813 08:28:01.553939 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.553946 18283 net.cpp:156] Memory required for data: 161596000
I0813 08:28:01.553952 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.553966 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.553977 18283 net.cpp:425] drop1 <- InnerProduct33
I0813 08:28:01.553989 18283 net.cpp:399] drop1 -> Dropout33
I0813 08:28:01.554009 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.554019 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.554025 18283 net.cpp:156] Memory required for data: 161698400
I0813 08:28:01.554033 18283 layer_factory.hpp:77] Creating layer InnerProduct34
I0813 08:28:01.554050 18283 net.cpp:91] Creating Layer InnerProduct34
I0813 08:28:01.554059 18283 net.cpp:425] InnerProduct34 <- Dropout33
I0813 08:28:01.554071 18283 net.cpp:399] InnerProduct34 -> InnerProduct34
I0813 08:28:01.554369 18283 net.cpp:141] Setting up InnerProduct34
I0813 08:28:01.554380 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.554386 18283 net.cpp:156] Memory required for data: 161749600
I0813 08:28:01.554394 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.554404 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.554410 18283 layer_factory.hpp:77] Creating layer ReLU34
I0813 08:28:01.554420 18283 net.cpp:91] Creating Layer ReLU34
I0813 08:28:01.554430 18283 net.cpp:425] ReLU34 <- InnerProduct34
I0813 08:28:01.554440 18283 net.cpp:386] ReLU34 -> InnerProduct34 (in-place)
I0813 08:28:01.554451 18283 net.cpp:141] Setting up ReLU34
I0813 08:28:01.554461 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.554467 18283 net.cpp:156] Memory required for data: 161800800
I0813 08:28:01.554473 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.554484 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.554493 18283 net.cpp:425] drop2 <- InnerProduct34
I0813 08:28:01.554503 18283 net.cpp:399] drop2 -> Dropout34
I0813 08:28:01.554517 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.554527 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.554533 18283 net.cpp:156] Memory required for data: 161852000
I0813 08:28:01.554540 18283 layer_factory.hpp:77] Creating layer m17
I0813 08:28:01.554554 18283 net.cpp:91] Creating Layer m17
I0813 08:28:01.554563 18283 net.cpp:425] m17 <- Dropout34
I0813 08:28:01.554579 18283 net.cpp:399] m17 -> m17
I0813 08:28:01.554622 18283 net.cpp:141] Setting up m17
I0813 08:28:01.554632 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.554638 18283 net.cpp:156] Memory required for data: 161852400
I0813 08:28:01.554646 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.554656 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.554662 18283 layer_factory.hpp:77] Creating layer Concat18
I0813 08:28:01.554675 18283 net.cpp:91] Creating Layer Concat18
I0813 08:28:01.554692 18283 net.cpp:425] Concat18 <- i9
I0813 08:28:01.554702 18283 net.cpp:425] Concat18 <- i11_i1_10_split_8
I0813 08:28:01.554716 18283 net.cpp:399] Concat18 -> Concat18
I0813 08:28:01.554734 18283 net.cpp:141] Setting up Concat18
I0813 08:28:01.554744 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.554750 18283 net.cpp:156] Memory required for data: 165129200
I0813 08:28:01.554757 18283 layer_factory.hpp:77] Creating layer InnerProduct35
I0813 08:28:01.554785 18283 net.cpp:91] Creating Layer InnerProduct35
I0813 08:28:01.554793 18283 net.cpp:425] InnerProduct35 <- Concat18
I0813 08:28:01.554805 18283 net.cpp:399] InnerProduct35 -> InnerProduct35
I0813 08:28:01.570926 18283 net.cpp:141] Setting up InnerProduct35
I0813 08:28:01.570969 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.570976 18283 net.cpp:156] Memory required for data: 165231600
I0813 08:28:01.570988 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.570997 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.571005 18283 layer_factory.hpp:77] Creating layer ReLU35
I0813 08:28:01.571027 18283 net.cpp:91] Creating Layer ReLU35
I0813 08:28:01.571049 18283 net.cpp:425] ReLU35 <- InnerProduct35
I0813 08:28:01.571065 18283 net.cpp:386] ReLU35 -> InnerProduct35 (in-place)
I0813 08:28:01.571087 18283 net.cpp:141] Setting up ReLU35
I0813 08:28:01.571096 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.571102 18283 net.cpp:156] Memory required for data: 165334000
I0813 08:28:01.571110 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.571123 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.571133 18283 net.cpp:425] drop1 <- InnerProduct35
I0813 08:28:01.571146 18283 net.cpp:399] drop1 -> Dropout35
I0813 08:28:01.571163 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.571173 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.571179 18283 net.cpp:156] Memory required for data: 165436400
I0813 08:28:01.571187 18283 layer_factory.hpp:77] Creating layer InnerProduct36
I0813 08:28:01.571204 18283 net.cpp:91] Creating Layer InnerProduct36
I0813 08:28:01.571213 18283 net.cpp:425] InnerProduct36 <- Dropout35
I0813 08:28:01.571224 18283 net.cpp:399] InnerProduct36 -> InnerProduct36
I0813 08:28:01.571529 18283 net.cpp:141] Setting up InnerProduct36
I0813 08:28:01.571540 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.571547 18283 net.cpp:156] Memory required for data: 165487600
I0813 08:28:01.571554 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.571563 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.571570 18283 layer_factory.hpp:77] Creating layer ReLU36
I0813 08:28:01.571581 18283 net.cpp:91] Creating Layer ReLU36
I0813 08:28:01.571589 18283 net.cpp:425] ReLU36 <- InnerProduct36
I0813 08:28:01.571599 18283 net.cpp:386] ReLU36 -> InnerProduct36 (in-place)
I0813 08:28:01.571610 18283 net.cpp:141] Setting up ReLU36
I0813 08:28:01.571619 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.571625 18283 net.cpp:156] Memory required for data: 165538800
I0813 08:28:01.571632 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.571642 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.571650 18283 net.cpp:425] drop2 <- InnerProduct36
I0813 08:28:01.571660 18283 net.cpp:399] drop2 -> Dropout36
I0813 08:28:01.571696 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.571705 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.571712 18283 net.cpp:156] Memory required for data: 165590000
I0813 08:28:01.571717 18283 layer_factory.hpp:77] Creating layer m18
I0813 08:28:01.571732 18283 net.cpp:91] Creating Layer m18
I0813 08:28:01.571739 18283 net.cpp:425] m18 <- Dropout36
I0813 08:28:01.571753 18283 net.cpp:399] m18 -> m18
I0813 08:28:01.571779 18283 net.cpp:141] Setting up m18
I0813 08:28:01.571787 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.571794 18283 net.cpp:156] Memory required for data: 165590400
I0813 08:28:01.571801 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.571810 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.571817 18283 layer_factory.hpp:77] Creating layer Concat19
I0813 08:28:01.571830 18283 net.cpp:91] Creating Layer Concat19
I0813 08:28:01.571840 18283 net.cpp:425] Concat19 <- i10
I0813 08:28:01.571849 18283 net.cpp:425] Concat19 <- i11_i1_10_split_9
I0813 08:28:01.571862 18283 net.cpp:399] Concat19 -> Concat19
I0813 08:28:01.571879 18283 net.cpp:141] Setting up Concat19
I0813 08:28:01.571889 18283 net.cpp:148] Top shape: 100 2 1 4096 (819200)
I0813 08:28:01.571895 18283 net.cpp:156] Memory required for data: 168867200
I0813 08:28:01.571902 18283 layer_factory.hpp:77] Creating layer InnerProduct37
I0813 08:28:01.571915 18283 net.cpp:91] Creating Layer InnerProduct37
I0813 08:28:01.571924 18283 net.cpp:425] InnerProduct37 <- Concat19
I0813 08:28:01.571936 18283 net.cpp:399] InnerProduct37 -> InnerProduct37
I0813 08:28:01.587937 18283 net.cpp:141] Setting up InnerProduct37
I0813 08:28:01.587980 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.587987 18283 net.cpp:156] Memory required for data: 168969600
I0813 08:28:01.588001 18283 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 08:28:01.588011 18283 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 08:28:01.588019 18283 layer_factory.hpp:77] Creating layer ReLU37
I0813 08:28:01.588060 18283 net.cpp:91] Creating Layer ReLU37
I0813 08:28:01.588078 18283 net.cpp:425] ReLU37 <- InnerProduct37
I0813 08:28:01.588098 18283 net.cpp:386] ReLU37 -> InnerProduct37 (in-place)
I0813 08:28:01.588119 18283 net.cpp:141] Setting up ReLU37
I0813 08:28:01.588127 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.588137 18283 net.cpp:156] Memory required for data: 169072000
I0813 08:28:01.588151 18283 layer_factory.hpp:77] Creating layer drop1
I0813 08:28:01.588165 18283 net.cpp:91] Creating Layer drop1
I0813 08:28:01.588173 18283 net.cpp:425] drop1 <- InnerProduct37
I0813 08:28:01.588186 18283 net.cpp:399] drop1 -> Dropout37
I0813 08:28:01.588208 18283 net.cpp:141] Setting up drop1
I0813 08:28:01.588218 18283 net.cpp:148] Top shape: 100 256 (25600)
I0813 08:28:01.588225 18283 net.cpp:156] Memory required for data: 169174400
I0813 08:28:01.588232 18283 layer_factory.hpp:77] Creating layer InnerProduct38
I0813 08:28:01.588254 18283 net.cpp:91] Creating Layer InnerProduct38
I0813 08:28:01.588263 18283 net.cpp:425] InnerProduct38 <- Dropout37
I0813 08:28:01.588276 18283 net.cpp:399] InnerProduct38 -> InnerProduct38
I0813 08:28:01.588575 18283 net.cpp:141] Setting up InnerProduct38
I0813 08:28:01.588588 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.588594 18283 net.cpp:156] Memory required for data: 169225600
I0813 08:28:01.588603 18283 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 08:28:01.588613 18283 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 08:28:01.588620 18283 layer_factory.hpp:77] Creating layer ReLU38
I0813 08:28:01.588630 18283 net.cpp:91] Creating Layer ReLU38
I0813 08:28:01.588639 18283 net.cpp:425] ReLU38 <- InnerProduct38
I0813 08:28:01.588654 18283 net.cpp:386] ReLU38 -> InnerProduct38 (in-place)
I0813 08:28:01.588667 18283 net.cpp:141] Setting up ReLU38
I0813 08:28:01.588696 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.588702 18283 net.cpp:156] Memory required for data: 169276800
I0813 08:28:01.588708 18283 layer_factory.hpp:77] Creating layer drop2
I0813 08:28:01.588718 18283 net.cpp:91] Creating Layer drop2
I0813 08:28:01.588726 18283 net.cpp:425] drop2 <- InnerProduct38
I0813 08:28:01.588735 18283 net.cpp:399] drop2 -> Dropout38
I0813 08:28:01.588749 18283 net.cpp:141] Setting up drop2
I0813 08:28:01.588758 18283 net.cpp:148] Top shape: 100 128 (12800)
I0813 08:28:01.588765 18283 net.cpp:156] Memory required for data: 169328000
I0813 08:28:01.588773 18283 layer_factory.hpp:77] Creating layer m19
I0813 08:28:01.588788 18283 net.cpp:91] Creating Layer m19
I0813 08:28:01.588796 18283 net.cpp:425] m19 <- Dropout38
I0813 08:28:01.588811 18283 net.cpp:399] m19 -> m19
I0813 08:28:01.588838 18283 net.cpp:141] Setting up m19
I0813 08:28:01.588847 18283 net.cpp:148] Top shape: 100 1 (100)
I0813 08:28:01.588853 18283 net.cpp:156] Memory required for data: 169328400
I0813 08:28:01.588860 18283 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 08:28:01.588870 18283 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 08:28:01.588876 18283 layer_factory.hpp:77] Creating layer con
I0813 08:28:01.588896 18283 net.cpp:91] Creating Layer con
I0813 08:28:01.588904 18283 net.cpp:425] con <- m1
I0813 08:28:01.588913 18283 net.cpp:425] con <- m2
I0813 08:28:01.588923 18283 net.cpp:425] con <- m3
I0813 08:28:01.588932 18283 net.cpp:425] con <- m4
I0813 08:28:01.588940 18283 net.cpp:425] con <- m5
I0813 08:28:01.588948 18283 net.cpp:425] con <- m6
I0813 08:28:01.588956 18283 net.cpp:425] con <- m7
I0813 08:28:01.588963 18283 net.cpp:425] con <- m8
I0813 08:28:01.588971 18283 net.cpp:425] con <- m9
I0813 08:28:01.588980 18283 net.cpp:425] con <- m10
I0813 08:28:01.588990 18283 net.cpp:425] con <- m11
I0813 08:28:01.588997 18283 net.cpp:425] con <- m12
I0813 08:28:01.589006 18283 net.cpp:425] con <- m13
I0813 08:28:01.589015 18283 net.cpp:425] con <- m14
I0813 08:28:01.589021 18283 net.cpp:425] con <- m15
I0813 08:28:01.589027 18283 net.cpp:425] con <- m16
I0813 08:28:01.589035 18283 net.cpp:425] con <- m17
I0813 08:28:01.589043 18283 net.cpp:425] con <- m18
I0813 08:28:01.589051 18283 net.cpp:425] con <- m19
I0813 08:28:01.589063 18283 net.cpp:399] con -> con
I0813 08:28:01.589085 18283 net.cpp:141] Setting up con
I0813 08:28:01.589094 18283 net.cpp:148] Top shape: 100 19 (1900)
I0813 08:28:01.589100 18283 net.cpp:156] Memory required for data: 169336000
I0813 08:28:01.589107 18283 layer_factory.hpp:77] Creating layer r1
I0813 08:28:01.589123 18283 net.cpp:91] Creating Layer r1
I0813 08:28:01.589131 18283 net.cpp:425] r1 <- con
I0813 08:28:01.589144 18283 net.cpp:399] r1 -> r1
I0813 08:28:01.589165 18283 net.cpp:141] Setting up r1
I0813 08:28:01.589174 18283 net.cpp:148] Top shape: 100 1 1 19 (1900)
I0813 08:28:01.589180 18283 net.cpp:156] Memory required for data: 169343600
I0813 08:28:01.589186 18283 layer_factory.hpp:77] Creating layer p
I0813 08:28:01.589200 18283 net.cpp:91] Creating Layer p
I0813 08:28:01.589207 18283 net.cpp:425] p <- r1
I0813 08:28:01.589220 18283 net.cpp:399] p -> p
I0813 08:28:01.589241 18283 net.cpp:141] Setting up p
I0813 08:28:01.589251 18283 net.cpp:148] Top shape: 100 1 1 1 (100)
I0813 08:28:01.589257 18283 net.cpp:156] Memory required for data: 169344000
I0813 08:28:01.589262 18283 layer_factory.hpp:77] Creating layer r2
I0813 08:28:01.589273 18283 net.cpp:91] Creating Layer r2
I0813 08:28:01.589280 18283 net.cpp:425] r2 <- p
I0813 08:28:01.589293 18283 net.cpp:399] r2 -> r2
I0813 08:28:01.589308 18283 net.cpp:141] Setting up r2
I0813 08:28:01.589318 18283 net.cpp:148] Top shape: 100 1 1 1 (100)
I0813 08:28:01.589324 18283 net.cpp:156] Memory required for data: 169344400
I0813 08:28:01.589331 18283 layer_factory.hpp:77] Creating layer padL
I0813 08:28:01.589341 18283 net.cpp:91] Creating Layer padL
I0813 08:28:01.589349 18283 net.cpp:425] padL <- label_data_1_split_1
I0813 08:28:01.589375 18283 net.cpp:399] padL -> padL
I0813 08:28:01.589390 18283 net.cpp:141] Setting up padL
I0813 08:28:01.589401 18283 net.cpp:148] Top shape: 100 1 1 1 (100)
I0813 08:28:01.589407 18283 net.cpp:156] Memory required for data: 169344800
I0813 08:28:01.589414 18283 layer_factory.hpp:77] Creating layer pad
I0813 08:28:01.589426 18283 net.cpp:91] Creating Layer pad
I0813 08:28:01.589432 18283 net.cpp:425] pad <- r2
I0813 08:28:01.589442 18283 net.cpp:425] pad <- padL
I0813 08:28:01.589452 18283 net.cpp:399] pad -> pad
I0813 08:28:01.589465 18283 net.cpp:141] Setting up pad
I0813 08:28:01.589475 18283 net.cpp:148] Top shape: 100 2 1 1 (200)
I0813 08:28:01.589481 18283 net.cpp:156] Memory required for data: 169345600
I0813 08:28:01.589488 18283 layer_factory.hpp:77] Creating layer pad_pad_0_split
I0813 08:28:01.589503 18283 net.cpp:91] Creating Layer pad_pad_0_split
I0813 08:28:01.589511 18283 net.cpp:425] pad_pad_0_split <- pad
I0813 08:28:01.589520 18283 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_0
I0813 08:28:01.589531 18283 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_1
I0813 08:28:01.589545 18283 net.cpp:141] Setting up pad_pad_0_split
I0813 08:28:01.589558 18283 net.cpp:148] Top shape: 100 2 1 1 (200)
I0813 08:28:01.589566 18283 net.cpp:148] Top shape: 100 2 1 1 (200)
I0813 08:28:01.589572 18283 net.cpp:156] Memory required for data: 169347200
I0813 08:28:01.589579 18283 layer_factory.hpp:77] Creating layer loss
I0813 08:28:01.589591 18283 net.cpp:91] Creating Layer loss
I0813 08:28:01.589597 18283 net.cpp:425] loss <- pad_pad_0_split_0
I0813 08:28:01.589607 18283 net.cpp:425] loss <- th_th_0_split_0
I0813 08:28:01.589615 18283 net.cpp:399] loss -> loss
I0813 08:28:01.589633 18283 net.cpp:141] Setting up loss
I0813 08:28:01.589642 18283 net.cpp:148] Top shape: (1)
I0813 08:28:01.589648 18283 net.cpp:151]     with loss weight 1
I0813 08:28:01.589671 18283 net.cpp:156] Memory required for data: 169347204
I0813 08:28:01.589679 18283 layer_factory.hpp:77] Creating layer accuracy
I0813 08:28:01.589697 18283 net.cpp:91] Creating Layer accuracy
I0813 08:28:01.589704 18283 net.cpp:425] accuracy <- pad_pad_0_split_1
I0813 08:28:01.589712 18283 net.cpp:425] accuracy <- th_th_0_split_1
I0813 08:28:01.589722 18283 net.cpp:399] accuracy -> accuracy
I0813 08:28:01.589737 18283 net.cpp:141] Setting up accuracy
I0813 08:28:01.589746 18283 net.cpp:148] Top shape: (1)
I0813 08:28:01.589752 18283 net.cpp:156] Memory required for data: 169347208
I0813 08:28:01.589759 18283 net.cpp:219] accuracy does not need backward computation.
I0813 08:28:01.589767 18283 net.cpp:217] loss needs backward computation.
I0813 08:28:01.589774 18283 net.cpp:217] pad_pad_0_split needs backward computation.
I0813 08:28:01.589781 18283 net.cpp:217] pad needs backward computation.
I0813 08:28:01.589788 18283 net.cpp:219] padL does not need backward computation.
I0813 08:28:01.589798 18283 net.cpp:217] r2 needs backward computation.
I0813 08:28:01.589805 18283 net.cpp:217] p needs backward computation.
I0813 08:28:01.589812 18283 net.cpp:217] r1 needs backward computation.
I0813 08:28:01.589818 18283 net.cpp:217] con needs backward computation.
I0813 08:28:01.589831 18283 net.cpp:217] m19 needs backward computation.
I0813 08:28:01.589839 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.589846 18283 net.cpp:217] ReLU38 needs backward computation.
I0813 08:28:01.589853 18283 net.cpp:217] InnerProduct38 needs backward computation.
I0813 08:28:01.589859 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.589866 18283 net.cpp:217] ReLU37 needs backward computation.
I0813 08:28:01.589872 18283 net.cpp:217] InnerProduct37 needs backward computation.
I0813 08:28:01.589879 18283 net.cpp:219] Concat19 does not need backward computation.
I0813 08:28:01.589889 18283 net.cpp:217] m18 needs backward computation.
I0813 08:28:01.589895 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.589903 18283 net.cpp:217] ReLU36 needs backward computation.
I0813 08:28:01.589911 18283 net.cpp:217] InnerProduct36 needs backward computation.
I0813 08:28:01.589931 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.589939 18283 net.cpp:217] ReLU35 needs backward computation.
I0813 08:28:01.589946 18283 net.cpp:217] InnerProduct35 needs backward computation.
I0813 08:28:01.589953 18283 net.cpp:219] Concat18 does not need backward computation.
I0813 08:28:01.589962 18283 net.cpp:217] m17 needs backward computation.
I0813 08:28:01.589969 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.589977 18283 net.cpp:217] ReLU34 needs backward computation.
I0813 08:28:01.589985 18283 net.cpp:217] InnerProduct34 needs backward computation.
I0813 08:28:01.589993 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590000 18283 net.cpp:217] ReLU33 needs backward computation.
I0813 08:28:01.590008 18283 net.cpp:217] InnerProduct33 needs backward computation.
I0813 08:28:01.590015 18283 net.cpp:219] Concat17 does not need backward computation.
I0813 08:28:01.590024 18283 net.cpp:217] m16 needs backward computation.
I0813 08:28:01.590035 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590044 18283 net.cpp:217] ReLU32 needs backward computation.
I0813 08:28:01.590052 18283 net.cpp:217] InnerProduct32 needs backward computation.
I0813 08:28:01.590059 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590068 18283 net.cpp:217] ReLU31 needs backward computation.
I0813 08:28:01.590075 18283 net.cpp:217] InnerProduct31 needs backward computation.
I0813 08:28:01.590082 18283 net.cpp:219] Concat16 does not need backward computation.
I0813 08:28:01.590091 18283 net.cpp:217] m15 needs backward computation.
I0813 08:28:01.590100 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590106 18283 net.cpp:217] ReLU30 needs backward computation.
I0813 08:28:01.590114 18283 net.cpp:217] InnerProduct30 needs backward computation.
I0813 08:28:01.590122 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590131 18283 net.cpp:217] ReLU29 needs backward computation.
I0813 08:28:01.590137 18283 net.cpp:217] InnerProduct29 needs backward computation.
I0813 08:28:01.590145 18283 net.cpp:219] Concat15 does not need backward computation.
I0813 08:28:01.590157 18283 net.cpp:217] m14 needs backward computation.
I0813 08:28:01.590164 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590173 18283 net.cpp:217] ReLU28 needs backward computation.
I0813 08:28:01.590179 18283 net.cpp:217] InnerProduct28 needs backward computation.
I0813 08:28:01.590186 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590194 18283 net.cpp:217] ReLU27 needs backward computation.
I0813 08:28:01.590203 18283 net.cpp:217] InnerProduct27 needs backward computation.
I0813 08:28:01.590210 18283 net.cpp:219] Concat14 does not need backward computation.
I0813 08:28:01.590221 18283 net.cpp:217] m13 needs backward computation.
I0813 08:28:01.590229 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590239 18283 net.cpp:217] ReLU26 needs backward computation.
I0813 08:28:01.590245 18283 net.cpp:217] InnerProduct26 needs backward computation.
I0813 08:28:01.590255 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590262 18283 net.cpp:217] ReLU25 needs backward computation.
I0813 08:28:01.590268 18283 net.cpp:217] InnerProduct25 needs backward computation.
I0813 08:28:01.590276 18283 net.cpp:219] Concat13 does not need backward computation.
I0813 08:28:01.590286 18283 net.cpp:217] m12 needs backward computation.
I0813 08:28:01.590293 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590301 18283 net.cpp:217] ReLU24 needs backward computation.
I0813 08:28:01.590308 18283 net.cpp:217] InnerProduct24 needs backward computation.
I0813 08:28:01.590315 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590322 18283 net.cpp:217] ReLU23 needs backward computation.
I0813 08:28:01.590412 18283 net.cpp:217] InnerProduct23 needs backward computation.
I0813 08:28:01.590422 18283 net.cpp:219] Concat12 does not need backward computation.
I0813 08:28:01.590445 18283 net.cpp:217] m11 needs backward computation.
I0813 08:28:01.590453 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590461 18283 net.cpp:217] ReLU22 needs backward computation.
I0813 08:28:01.590467 18283 net.cpp:217] InnerProduct22 needs backward computation.
I0813 08:28:01.590474 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590481 18283 net.cpp:217] ReLU21 needs backward computation.
I0813 08:28:01.590488 18283 net.cpp:217] InnerProduct21 needs backward computation.
I0813 08:28:01.590495 18283 net.cpp:219] Concat11 does not need backward computation.
I0813 08:28:01.590504 18283 net.cpp:217] m10 needs backward computation.
I0813 08:28:01.590513 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590522 18283 net.cpp:217] ReLU20 needs backward computation.
I0813 08:28:01.590528 18283 net.cpp:217] InnerProduct20 needs backward computation.
I0813 08:28:01.590535 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590543 18283 net.cpp:217] ReLU19 needs backward computation.
I0813 08:28:01.590551 18283 net.cpp:217] InnerProduct19 needs backward computation.
I0813 08:28:01.590559 18283 net.cpp:219] Concat10 does not need backward computation.
I0813 08:28:01.590569 18283 net.cpp:217] m9 needs backward computation.
I0813 08:28:01.590577 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590584 18283 net.cpp:217] ReLU18 needs backward computation.
I0813 08:28:01.590593 18283 net.cpp:217] InnerProduct18 needs backward computation.
I0813 08:28:01.590600 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590608 18283 net.cpp:217] ReLU17 needs backward computation.
I0813 08:28:01.590616 18283 net.cpp:217] InnerProduct17 needs backward computation.
I0813 08:28:01.590625 18283 net.cpp:219] Concat9 does not need backward computation.
I0813 08:28:01.590634 18283 net.cpp:217] m8 needs backward computation.
I0813 08:28:01.590642 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590651 18283 net.cpp:217] ReLU16 needs backward computation.
I0813 08:28:01.590657 18283 net.cpp:217] InnerProduct16 needs backward computation.
I0813 08:28:01.590664 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590672 18283 net.cpp:217] ReLU15 needs backward computation.
I0813 08:28:01.590678 18283 net.cpp:217] InnerProduct15 needs backward computation.
I0813 08:28:01.590690 18283 net.cpp:219] Concat8 does not need backward computation.
I0813 08:28:01.590701 18283 net.cpp:217] m7 needs backward computation.
I0813 08:28:01.590709 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590718 18283 net.cpp:217] ReLU14 needs backward computation.
I0813 08:28:01.590725 18283 net.cpp:217] InnerProduct14 needs backward computation.
I0813 08:28:01.590733 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590740 18283 net.cpp:217] ReLU13 needs backward computation.
I0813 08:28:01.590747 18283 net.cpp:217] InnerProduct13 needs backward computation.
I0813 08:28:01.590755 18283 net.cpp:219] Concat7 does not need backward computation.
I0813 08:28:01.590764 18283 net.cpp:217] m6 needs backward computation.
I0813 08:28:01.590771 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590780 18283 net.cpp:217] ReLU12 needs backward computation.
I0813 08:28:01.590786 18283 net.cpp:217] InnerProduct12 needs backward computation.
I0813 08:28:01.590795 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590801 18283 net.cpp:217] ReLU11 needs backward computation.
I0813 08:28:01.590808 18283 net.cpp:217] InnerProduct11 needs backward computation.
I0813 08:28:01.590816 18283 net.cpp:219] Concat6 does not need backward computation.
I0813 08:28:01.590824 18283 net.cpp:217] m5 needs backward computation.
I0813 08:28:01.590834 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590842 18283 net.cpp:217] ReLU10 needs backward computation.
I0813 08:28:01.590848 18283 net.cpp:217] InnerProduct10 needs backward computation.
I0813 08:28:01.590867 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590876 18283 net.cpp:217] ReLU9 needs backward computation.
I0813 08:28:01.590883 18283 net.cpp:217] InnerProduct9 needs backward computation.
I0813 08:28:01.590891 18283 net.cpp:219] Concat5 does not need backward computation.
I0813 08:28:01.590900 18283 net.cpp:217] m4 needs backward computation.
I0813 08:28:01.590909 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590915 18283 net.cpp:217] ReLU8 needs backward computation.
I0813 08:28:01.590924 18283 net.cpp:217] InnerProduct8 needs backward computation.
I0813 08:28:01.590932 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590939 18283 net.cpp:217] ReLU7 needs backward computation.
I0813 08:28:01.590947 18283 net.cpp:217] InnerProduct7 needs backward computation.
I0813 08:28:01.590955 18283 net.cpp:219] Concat4 does not need backward computation.
I0813 08:28:01.590963 18283 net.cpp:217] m3 needs backward computation.
I0813 08:28:01.590971 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.590978 18283 net.cpp:217] ReLU6 needs backward computation.
I0813 08:28:01.590986 18283 net.cpp:217] InnerProduct6 needs backward computation.
I0813 08:28:01.590992 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.590999 18283 net.cpp:217] ReLU5 needs backward computation.
I0813 08:28:01.591006 18283 net.cpp:217] InnerProduct5 needs backward computation.
I0813 08:28:01.591014 18283 net.cpp:219] Concat3 does not need backward computation.
I0813 08:28:01.591024 18283 net.cpp:217] m2 needs backward computation.
I0813 08:28:01.591033 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.591039 18283 net.cpp:217] ReLU4 needs backward computation.
I0813 08:28:01.591047 18283 net.cpp:217] InnerProduct4 needs backward computation.
I0813 08:28:01.591053 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.591061 18283 net.cpp:217] ReLU3 needs backward computation.
I0813 08:28:01.591068 18283 net.cpp:217] InnerProduct3 needs backward computation.
I0813 08:28:01.591075 18283 net.cpp:219] Concat2 does not need backward computation.
I0813 08:28:01.591084 18283 net.cpp:217] m1 needs backward computation.
I0813 08:28:01.591092 18283 net.cpp:217] drop2 needs backward computation.
I0813 08:28:01.591099 18283 net.cpp:217] ReLU2 needs backward computation.
I0813 08:28:01.591107 18283 net.cpp:217] InnerProduct2 needs backward computation.
I0813 08:28:01.591114 18283 net.cpp:217] drop1 needs backward computation.
I0813 08:28:01.591122 18283 net.cpp:217] ReLU1 needs backward computation.
I0813 08:28:01.591128 18283 net.cpp:217] InnerProduct1 needs backward computation.
I0813 08:28:01.591137 18283 net.cpp:219] Concat1 does not need backward computation.
I0813 08:28:01.591148 18283 net.cpp:219] i11_i1_10_split does not need backward computation.
I0813 08:28:01.591161 18283 net.cpp:219] i1_i1_0_split does not need backward computation.
I0813 08:28:01.591173 18283 net.cpp:219] i1 does not need backward computation.
I0813 08:28:01.591183 18283 net.cpp:219] th_th_0_split does not need backward computation.
I0813 08:28:01.591190 18283 net.cpp:219] th does not need backward computation.
I0813 08:28:01.591199 18283 net.cpp:219] label_data_1_split does not need backward computation.
I0813 08:28:01.591210 18283 net.cpp:219] data does not need backward computation.
I0813 08:28:01.591219 18283 net.cpp:261] This network produces output accuracy
I0813 08:28:01.591228 18283 net.cpp:261] This network produces output loss
I0813 08:28:01.591673 18283 net.cpp:274] Network initialization done.
I0813 08:28:01.592881 18283 solver.cpp:60] Solver scaffolding done.
I0813 08:28:01.592953 18283 caffe.cpp:219] Starting Optimization
I0813 08:28:01.592964 18283 solver.cpp:279] Solving 
I0813 08:28:01.592970 18283 solver.cpp:280] Learning Rate Policy: inv
I0813 08:28:01.594905 18283 solver.cpp:337] Iteration 0, Testing net (#0)
I0813 08:28:05.801056 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 08:28:05.801143 18283 solver.cpp:404]     Test net output #1: loss = 1.08121 (* 1 = 1.08121 loss)
I0813 08:28:06.672384 18283 solver.cpp:228] Iteration 0, loss = 1.58542
I0813 08:28:06.672441 18283 solver.cpp:244]     Train net output #0: accuracy = 0.84
I0813 08:28:06.672458 18283 solver.cpp:244]     Train net output #1: loss = 1.58542 (* 1 = 1.58542 loss)
I0813 08:28:06.672508 18283 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0813 08:28:49.454422 18283 solver.cpp:228] Iteration 50, loss = 0.302529
I0813 08:28:49.454565 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 08:28:49.454586 18283 solver.cpp:244]     Train net output #1: loss = 0.302529 (* 1 = 0.302529 loss)
I0813 08:28:49.454605 18283 sgd_solver.cpp:106] Iteration 50, lr = 0.00996266
I0813 08:29:30.514977 18283 solver.cpp:337] Iteration 100, Testing net (#0)
I0813 08:29:34.839277 18283 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0813 08:29:34.839342 18283 solver.cpp:404]     Test net output #1: loss = 0.718407 (* 1 = 0.718407 loss)
I0813 08:29:35.671154 18283 solver.cpp:228] Iteration 100, loss = 0.224648
I0813 08:29:35.671202 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 08:29:35.671213 18283 solver.cpp:244]     Train net output #1: loss = 0.224648 (* 1 = 0.224648 loss)
I0813 08:29:35.671232 18283 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0813 08:30:18.124094 18283 solver.cpp:228] Iteration 150, loss = 0.187053
I0813 08:30:18.124302 18283 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0813 08:30:18.124361 18283 solver.cpp:244]     Train net output #1: loss = 0.187053 (* 1 = 0.187053 loss)
I0813 08:30:18.124389 18283 sgd_solver.cpp:106] Iteration 150, lr = 0.00988896
I0813 08:31:02.582160 18283 solver.cpp:337] Iteration 200, Testing net (#0)
I0813 08:31:06.994863 18283 solver.cpp:404]     Test net output #0: accuracy = 0.995
I0813 08:31:06.994925 18283 solver.cpp:404]     Test net output #1: loss = 0.691642 (* 1 = 0.691642 loss)
I0813 08:31:07.847272 18283 solver.cpp:228] Iteration 200, loss = 0.243385
I0813 08:31:07.847326 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 08:31:07.847337 18283 solver.cpp:244]     Train net output #1: loss = 0.243385 (* 1 = 0.243385 loss)
I0813 08:31:07.847355 18283 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0813 08:31:50.067965 18283 solver.cpp:228] Iteration 250, loss = 0.245466
I0813 08:31:50.068168 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 08:31:50.068233 18283 solver.cpp:244]     Train net output #1: loss = 0.245466 (* 1 = 0.245466 loss)
I0813 08:31:50.068259 18283 sgd_solver.cpp:106] Iteration 250, lr = 0.00981651
I0813 08:32:31.294636 18283 solver.cpp:337] Iteration 300, Testing net (#0)
I0813 08:32:35.427182 18283 solver.cpp:404]     Test net output #0: accuracy = 0.979
I0813 08:32:35.427249 18283 solver.cpp:404]     Test net output #1: loss = 0.689199 (* 1 = 0.689199 loss)
I0813 08:32:36.266592 18283 solver.cpp:228] Iteration 300, loss = 0.203122
I0813 08:32:36.266664 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 08:32:36.266679 18283 solver.cpp:244]     Train net output #1: loss = 0.203122 (* 1 = 0.203122 loss)
I0813 08:32:36.266693 18283 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0813 08:33:18.141407 18283 solver.cpp:228] Iteration 350, loss = 0.181631
I0813 08:33:18.141525 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 08:33:18.141538 18283 solver.cpp:244]     Train net output #1: loss = 0.18163 (* 1 = 0.18163 loss)
I0813 08:33:18.141551 18283 sgd_solver.cpp:106] Iteration 350, lr = 0.00974529
I0813 08:33:58.912459 18283 solver.cpp:337] Iteration 400, Testing net (#0)
I0813 08:34:02.995404 18283 solver.cpp:404]     Test net output #0: accuracy = 0.738
I0813 08:34:02.995471 18283 solver.cpp:404]     Test net output #1: loss = 0.688406 (* 1 = 0.688406 loss)
I0813 08:34:03.816943 18283 solver.cpp:228] Iteration 400, loss = 0.242005
I0813 08:34:03.816993 18283 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0813 08:34:03.817005 18283 solver.cpp:244]     Train net output #1: loss = 0.242005 (* 1 = 0.242005 loss)
I0813 08:34:03.817024 18283 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0813 08:34:45.493005 18283 solver.cpp:228] Iteration 450, loss = 0.241253
I0813 08:34:45.493247 18283 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0813 08:34:45.493297 18283 solver.cpp:244]     Train net output #1: loss = 0.241252 (* 1 = 0.241252 loss)
I0813 08:34:45.493324 18283 sgd_solver.cpp:106] Iteration 450, lr = 0.00967526
I0813 08:35:26.526201 18283 solver.cpp:337] Iteration 500, Testing net (#0)
I0813 08:35:30.611187 18283 solver.cpp:404]     Test net output #0: accuracy = 0.893
I0813 08:35:30.611249 18283 solver.cpp:404]     Test net output #1: loss = 0.688287 (* 1 = 0.688287 loss)
I0813 08:35:31.433715 18283 solver.cpp:228] Iteration 500, loss = 0.200735
I0813 08:35:31.433775 18283 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0813 08:35:31.433787 18283 solver.cpp:244]     Train net output #1: loss = 0.200735 (* 1 = 0.200735 loss)
I0813 08:35:31.433806 18283 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0813 08:36:13.024164 18283 solver.cpp:228] Iteration 550, loss = 0.180455
I0813 08:36:13.024411 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 08:36:13.024469 18283 solver.cpp:244]     Train net output #1: loss = 0.180455 (* 1 = 0.180455 loss)
I0813 08:36:13.024495 18283 sgd_solver.cpp:106] Iteration 550, lr = 0.0096064
I0813 08:36:54.050662 18283 solver.cpp:337] Iteration 600, Testing net (#0)
I0813 08:36:58.145040 18283 solver.cpp:404]     Test net output #0: accuracy = 0.978
I0813 08:36:58.145103 18283 solver.cpp:404]     Test net output #1: loss = 0.688479 (* 1 = 0.688479 loss)
I0813 08:36:58.963767 18283 solver.cpp:228] Iteration 600, loss = 0.241125
I0813 08:36:58.963827 18283 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0813 08:36:58.963840 18283 solver.cpp:244]     Train net output #1: loss = 0.241125 (* 1 = 0.241125 loss)
I0813 08:36:58.963853 18283 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0813 08:37:40.385613 18283 solver.cpp:228] Iteration 650, loss = 0.241632
I0813 08:37:40.385757 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 08:37:40.385773 18283 solver.cpp:244]     Train net output #1: loss = 0.241632 (* 1 = 0.241632 loss)
I0813 08:37:40.385787 18283 sgd_solver.cpp:106] Iteration 650, lr = 0.00953867
I0813 08:38:21.695283 18283 solver.cpp:337] Iteration 700, Testing net (#0)
I0813 08:38:25.838037 18283 solver.cpp:404]     Test net output #0: accuracy = 0.658
I0813 08:38:25.838104 18283 solver.cpp:404]     Test net output #1: loss = 0.68851 (* 1 = 0.68851 loss)
I0813 08:38:26.670444 18283 solver.cpp:228] Iteration 700, loss = 0.200352
I0813 08:38:26.670495 18283 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0813 08:38:26.670506 18283 solver.cpp:244]     Train net output #1: loss = 0.200352 (* 1 = 0.200352 loss)
I0813 08:38:26.670524 18283 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0813 08:39:08.455620 18283 solver.cpp:228] Iteration 750, loss = 0.18036
I0813 08:39:08.455767 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 08:39:08.455783 18283 solver.cpp:244]     Train net output #1: loss = 0.18036 (* 1 = 0.18036 loss)
I0813 08:39:08.455796 18283 sgd_solver.cpp:106] Iteration 750, lr = 0.00947204
I0813 08:39:49.268509 18283 solver.cpp:337] Iteration 800, Testing net (#0)
I0813 08:39:53.363847 18283 solver.cpp:404]     Test net output #0: accuracy = 0.792
I0813 08:39:53.363911 18283 solver.cpp:404]     Test net output #1: loss = 0.688124 (* 1 = 0.688124 loss)
I0813 08:39:54.182014 18283 solver.cpp:228] Iteration 800, loss = 0.240781
I0813 08:39:54.182063 18283 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0813 08:39:54.182075 18283 solver.cpp:244]     Train net output #1: loss = 0.240781 (* 1 = 0.240781 loss)
I0813 08:39:54.182086 18283 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0813 08:40:35.808656 18283 solver.cpp:228] Iteration 850, loss = 0.240578
I0813 08:40:35.808846 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 08:40:35.808863 18283 solver.cpp:244]     Train net output #1: loss = 0.240578 (* 1 = 0.240578 loss)
I0813 08:40:35.808876 18283 sgd_solver.cpp:106] Iteration 850, lr = 0.00940649
I0813 08:41:16.817773 18283 solver.cpp:337] Iteration 900, Testing net (#0)
I0813 08:41:21.119536 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 08:41:21.119603 18283 solver.cpp:404]     Test net output #1: loss = 0.688982 (* 1 = 0.688982 loss)
I0813 08:41:21.944989 18283 solver.cpp:228] Iteration 900, loss = 0.200543
I0813 08:41:21.945044 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 08:41:21.945055 18283 solver.cpp:244]     Train net output #1: loss = 0.200543 (* 1 = 0.200543 loss)
I0813 08:41:21.945073 18283 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0813 08:42:03.647097 18283 solver.cpp:228] Iteration 950, loss = 0.180412
I0813 08:42:03.647318 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 08:42:03.647383 18283 solver.cpp:244]     Train net output #1: loss = 0.180412 (* 1 = 0.180412 loss)
I0813 08:42:03.647405 18283 sgd_solver.cpp:106] Iteration 950, lr = 0.00934199
I0813 08:42:44.528304 18283 solver.cpp:337] Iteration 1000, Testing net (#0)
I0813 08:42:48.828636 18283 solver.cpp:404]     Test net output #0: accuracy = 0.971
I0813 08:42:48.828702 18283 solver.cpp:404]     Test net output #1: loss = 0.68815 (* 1 = 0.68815 loss)
I0813 08:42:49.648376 18283 solver.cpp:228] Iteration 1000, loss = 0.240768
I0813 08:42:49.648427 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 08:42:49.648437 18283 solver.cpp:244]     Train net output #1: loss = 0.240768 (* 1 = 0.240768 loss)
I0813 08:42:49.648454 18283 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0813 08:43:31.986701 18283 solver.cpp:228] Iteration 1050, loss = 0.240694
I0813 08:43:31.986850 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 08:43:31.986865 18283 solver.cpp:244]     Train net output #1: loss = 0.240694 (* 1 = 0.240694 loss)
I0813 08:43:31.986876 18283 sgd_solver.cpp:106] Iteration 1050, lr = 0.00927851
I0813 08:44:12.998947 18283 solver.cpp:337] Iteration 1100, Testing net (#0)
I0813 08:44:17.306316 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 08:44:17.306381 18283 solver.cpp:404]     Test net output #1: loss = 0.688989 (* 1 = 0.688989 loss)
I0813 08:44:18.132731 18283 solver.cpp:228] Iteration 1100, loss = 0.200524
I0813 08:44:18.132783 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 08:44:18.132802 18283 solver.cpp:244]     Train net output #1: loss = 0.200524 (* 1 = 0.200524 loss)
I0813 08:44:18.132813 18283 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0813 08:45:00.121855 18283 solver.cpp:228] Iteration 1150, loss = 0.180951
I0813 08:45:00.122056 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 08:45:00.122129 18283 solver.cpp:244]     Train net output #1: loss = 0.180951 (* 1 = 0.180951 loss)
I0813 08:45:00.122169 18283 sgd_solver.cpp:106] Iteration 1150, lr = 0.00921603
I0813 08:45:41.447341 18283 solver.cpp:337] Iteration 1200, Testing net (#0)
I0813 08:45:45.542845 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 08:45:45.542912 18283 solver.cpp:404]     Test net output #1: loss = 0.689039 (* 1 = 0.689039 loss)
I0813 08:45:46.364177 18283 solver.cpp:228] Iteration 1200, loss = 0.240577
I0813 08:45:46.364238 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 08:45:46.364251 18283 solver.cpp:244]     Train net output #1: loss = 0.240577 (* 1 = 0.240577 loss)
I0813 08:45:46.364266 18283 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0813 08:46:28.559243 18283 solver.cpp:228] Iteration 1250, loss = 0.240699
I0813 08:46:28.559454 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 08:46:28.559512 18283 solver.cpp:244]     Train net output #1: loss = 0.240699 (* 1 = 0.240699 loss)
I0813 08:46:28.559548 18283 sgd_solver.cpp:106] Iteration 1250, lr = 0.00915452
I0813 08:47:09.698014 18283 solver.cpp:337] Iteration 1300, Testing net (#0)
I0813 08:47:14.072288 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 08:47:14.072352 18283 solver.cpp:404]     Test net output #1: loss = 0.691041 (* 1 = 0.691041 loss)
I0813 08:47:14.898404 18283 solver.cpp:228] Iteration 1300, loss = 0.201247
I0813 08:47:14.898469 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 08:47:14.898483 18283 solver.cpp:244]     Train net output #1: loss = 0.201247 (* 1 = 0.201247 loss)
I0813 08:47:14.898499 18283 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0813 08:47:57.824813 18283 solver.cpp:228] Iteration 1350, loss = 0.180537
I0813 08:47:57.825023 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 08:47:57.825089 18283 solver.cpp:244]     Train net output #1: loss = 0.180537 (* 1 = 0.180537 loss)
I0813 08:47:57.825119 18283 sgd_solver.cpp:106] Iteration 1350, lr = 0.00909396
I0813 08:48:38.921402 18283 solver.cpp:337] Iteration 1400, Testing net (#0)
I0813 08:48:43.022831 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 08:48:43.022910 18283 solver.cpp:404]     Test net output #1: loss = 0.688442 (* 1 = 0.688442 loss)
I0813 08:48:43.848742 18283 solver.cpp:228] Iteration 1400, loss = 0.240408
I0813 08:48:43.848793 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 08:48:43.848803 18283 solver.cpp:244]     Train net output #1: loss = 0.240408 (* 1 = 0.240408 loss)
I0813 08:48:43.848821 18283 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0813 08:49:25.592844 18283 solver.cpp:228] Iteration 1450, loss = 0.240357
I0813 08:49:25.593008 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 08:49:25.593022 18283 solver.cpp:244]     Train net output #1: loss = 0.240357 (* 1 = 0.240357 loss)
I0813 08:49:25.593034 18283 sgd_solver.cpp:106] Iteration 1450, lr = 0.00903433
I0813 08:50:06.565181 18283 solver.cpp:337] Iteration 1500, Testing net (#0)
I0813 08:50:10.875941 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 08:50:10.876016 18283 solver.cpp:404]     Test net output #1: loss = 0.688711 (* 1 = 0.688711 loss)
I0813 08:50:11.699229 18283 solver.cpp:228] Iteration 1500, loss = 0.200526
I0813 08:50:11.699280 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 08:50:11.699291 18283 solver.cpp:244]     Train net output #1: loss = 0.200525 (* 1 = 0.200525 loss)
I0813 08:50:11.699303 18283 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0813 08:50:53.704515 18283 solver.cpp:228] Iteration 1550, loss = 0.180564
I0813 08:50:53.704746 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 08:50:53.704807 18283 solver.cpp:244]     Train net output #1: loss = 0.180563 (* 1 = 0.180563 loss)
I0813 08:50:53.704828 18283 sgd_solver.cpp:106] Iteration 1550, lr = 0.0089756
I0813 08:51:34.936100 18283 solver.cpp:337] Iteration 1600, Testing net (#0)
I0813 08:51:39.238334 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 08:51:39.238414 18283 solver.cpp:404]     Test net output #1: loss = 0.688331 (* 1 = 0.688331 loss)
I0813 08:51:40.061578 18283 solver.cpp:228] Iteration 1600, loss = 0.240353
I0813 08:51:40.061640 18283 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0813 08:51:40.061650 18283 solver.cpp:244]     Train net output #1: loss = 0.240353 (* 1 = 0.240353 loss)
I0813 08:51:40.061666 18283 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0813 08:52:21.739631 18283 solver.cpp:228] Iteration 1650, loss = 0.240352
I0813 08:52:21.739785 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 08:52:21.739800 18283 solver.cpp:244]     Train net output #1: loss = 0.240352 (* 1 = 0.240352 loss)
I0813 08:52:21.739810 18283 sgd_solver.cpp:106] Iteration 1650, lr = 0.00891776
I0813 08:53:02.510630 18283 solver.cpp:337] Iteration 1700, Testing net (#0)
I0813 08:53:06.620260 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 08:53:06.620323 18283 solver.cpp:404]     Test net output #1: loss = 0.689073 (* 1 = 0.689073 loss)
I0813 08:53:07.441298 18283 solver.cpp:228] Iteration 1700, loss = 0.200481
I0813 08:53:07.441349 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 08:53:07.441361 18283 solver.cpp:244]     Train net output #1: loss = 0.200481 (* 1 = 0.200481 loss)
I0813 08:53:07.441378 18283 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0813 08:53:49.244335 18283 solver.cpp:228] Iteration 1750, loss = 0.180968
I0813 08:53:49.244519 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 08:53:49.244535 18283 solver.cpp:244]     Train net output #1: loss = 0.180968 (* 1 = 0.180968 loss)
I0813 08:53:49.244547 18283 sgd_solver.cpp:106] Iteration 1750, lr = 0.00886077
I0813 08:54:30.194995 18283 solver.cpp:337] Iteration 1800, Testing net (#0)
I0813 08:54:34.289605 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 08:54:34.289670 18283 solver.cpp:404]     Test net output #1: loss = 0.690292 (* 1 = 0.690292 loss)
I0813 08:54:35.107219 18283 solver.cpp:228] Iteration 1800, loss = 0.243528
I0813 08:54:35.107278 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 08:54:35.107290 18283 solver.cpp:244]     Train net output #1: loss = 0.243527 (* 1 = 0.243527 loss)
I0813 08:54:35.107303 18283 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0813 08:55:16.879029 18283 solver.cpp:228] Iteration 1850, loss = 0.240707
I0813 08:55:16.879176 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 08:55:16.879192 18283 solver.cpp:244]     Train net output #1: loss = 0.240707 (* 1 = 0.240707 loss)
I0813 08:55:16.879204 18283 sgd_solver.cpp:106] Iteration 1850, lr = 0.00880463
I0813 08:55:57.862082 18283 solver.cpp:337] Iteration 1900, Testing net (#0)
I0813 08:56:02.122004 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 08:56:02.122069 18283 solver.cpp:404]     Test net output #1: loss = 0.692725 (* 1 = 0.692725 loss)
I0813 08:56:02.951337 18283 solver.cpp:228] Iteration 1900, loss = 0.201622
I0813 08:56:02.951398 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 08:56:02.951411 18283 solver.cpp:244]     Train net output #1: loss = 0.201622 (* 1 = 0.201622 loss)
I0813 08:56:02.951431 18283 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0813 08:56:44.739830 18283 solver.cpp:228] Iteration 1950, loss = 0.180913
I0813 08:56:44.739977 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 08:56:44.739995 18283 solver.cpp:244]     Train net output #1: loss = 0.180913 (* 1 = 0.180913 loss)
I0813 08:56:44.740006 18283 sgd_solver.cpp:106] Iteration 1950, lr = 0.00874932
I0813 08:57:25.741756 18283 solver.cpp:337] Iteration 2000, Testing net (#0)
I0813 08:57:29.829035 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 08:57:29.829098 18283 solver.cpp:404]     Test net output #1: loss = 0.688271 (* 1 = 0.688271 loss)
I0813 08:57:30.656620 18283 solver.cpp:228] Iteration 2000, loss = 0.240169
I0813 08:57:30.656690 18283 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0813 08:57:30.656704 18283 solver.cpp:244]     Train net output #1: loss = 0.240169 (* 1 = 0.240169 loss)
I0813 08:57:30.656718 18283 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0813 08:58:12.262228 18283 solver.cpp:228] Iteration 2050, loss = 0.240665
I0813 08:58:12.262431 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 08:58:12.262487 18283 solver.cpp:244]     Train net output #1: loss = 0.240665 (* 1 = 0.240665 loss)
I0813 08:58:12.262516 18283 sgd_solver.cpp:106] Iteration 2050, lr = 0.0086948
I0813 08:58:53.419122 18283 solver.cpp:337] Iteration 2100, Testing net (#0)
I0813 08:58:57.703508 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 08:58:57.703577 18283 solver.cpp:404]     Test net output #1: loss = 0.690764 (* 1 = 0.690764 loss)
I0813 08:58:58.530818 18283 solver.cpp:228] Iteration 2100, loss = 0.201056
I0813 08:58:58.530869 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 08:58:58.530879 18283 solver.cpp:244]     Train net output #1: loss = 0.201056 (* 1 = 0.201056 loss)
I0813 08:58:58.530899 18283 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0813 08:59:40.304607 18283 solver.cpp:228] Iteration 2150, loss = 0.180714
I0813 08:59:40.304872 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 08:59:40.304930 18283 solver.cpp:244]     Train net output #1: loss = 0.180714 (* 1 = 0.180714 loss)
I0813 08:59:40.304955 18283 sgd_solver.cpp:106] Iteration 2150, lr = 0.00864108
I0813 09:00:21.431569 18283 solver.cpp:337] Iteration 2200, Testing net (#0)
I0813 09:00:25.538058 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:00:25.538121 18283 solver.cpp:404]     Test net output #1: loss = 0.688284 (* 1 = 0.688284 loss)
I0813 09:00:26.355386 18283 solver.cpp:228] Iteration 2200, loss = 0.240284
I0813 09:00:26.355434 18283 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0813 09:00:26.355446 18283 solver.cpp:244]     Train net output #1: loss = 0.240284 (* 1 = 0.240284 loss)
I0813 09:00:26.355463 18283 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0813 09:01:07.891647 18283 solver.cpp:228] Iteration 2250, loss = 0.240195
I0813 09:01:07.891808 18283 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0813 09:01:07.891824 18283 solver.cpp:244]     Train net output #1: loss = 0.240195 (* 1 = 0.240195 loss)
I0813 09:01:07.891837 18283 sgd_solver.cpp:106] Iteration 2250, lr = 0.00858812
I0813 09:01:48.740281 18283 solver.cpp:337] Iteration 2300, Testing net (#0)
I0813 09:01:52.817425 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:01:52.817492 18283 solver.cpp:404]     Test net output #1: loss = 0.688632 (* 1 = 0.688632 loss)
I0813 09:01:53.636729 18283 solver.cpp:228] Iteration 2300, loss = 0.200363
I0813 09:01:53.636790 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:01:53.636801 18283 solver.cpp:244]     Train net output #1: loss = 0.200362 (* 1 = 0.200362 loss)
I0813 09:01:53.636814 18283 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0813 09:02:35.220366 18283 solver.cpp:228] Iteration 2350, loss = 0.181077
I0813 09:02:35.220507 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 09:02:35.220522 18283 solver.cpp:244]     Train net output #1: loss = 0.181077 (* 1 = 0.181077 loss)
I0813 09:02:35.220535 18283 sgd_solver.cpp:106] Iteration 2350, lr = 0.00853591
I0813 09:03:16.011533 18283 solver.cpp:337] Iteration 2400, Testing net (#0)
I0813 09:03:20.098481 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:03:20.098549 18283 solver.cpp:404]     Test net output #1: loss = 0.688177 (* 1 = 0.688177 loss)
I0813 09:03:20.919916 18283 solver.cpp:228] Iteration 2400, loss = 0.240259
I0813 09:03:20.919968 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:03:20.919981 18283 solver.cpp:244]     Train net output #1: loss = 0.240259 (* 1 = 0.240259 loss)
I0813 09:03:20.919998 18283 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0813 09:04:02.542603 18283 solver.cpp:228] Iteration 2450, loss = 0.240507
I0813 09:04:02.542791 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:04:02.542867 18283 solver.cpp:244]     Train net output #1: loss = 0.240507 (* 1 = 0.240507 loss)
I0813 09:04:02.542907 18283 sgd_solver.cpp:106] Iteration 2450, lr = 0.00848444
I0813 09:04:43.847136 18283 solver.cpp:337] Iteration 2500, Testing net (#0)
I0813 09:04:47.940729 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:04:47.940793 18283 solver.cpp:404]     Test net output #1: loss = 0.688875 (* 1 = 0.688875 loss)
I0813 09:04:48.776660 18283 solver.cpp:228] Iteration 2500, loss = 0.200475
I0813 09:04:48.776720 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:04:48.776731 18283 solver.cpp:244]     Train net output #1: loss = 0.200475 (* 1 = 0.200475 loss)
I0813 09:04:48.776744 18283 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0813 09:05:30.455716 18283 solver.cpp:228] Iteration 2550, loss = 0.180398
I0813 09:05:30.455987 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 09:05:30.456071 18283 solver.cpp:244]     Train net output #1: loss = 0.180398 (* 1 = 0.180398 loss)
I0813 09:05:30.456100 18283 sgd_solver.cpp:106] Iteration 2550, lr = 0.00843368
I0813 09:06:11.535189 18283 solver.cpp:337] Iteration 2600, Testing net (#0)
I0813 09:06:15.629287 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 09:06:15.629357 18283 solver.cpp:404]     Test net output #1: loss = 0.689301 (* 1 = 0.689301 loss)
I0813 09:06:16.450794 18283 solver.cpp:228] Iteration 2600, loss = 0.241145
I0813 09:06:16.450857 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 09:06:16.450870 18283 solver.cpp:244]     Train net output #1: loss = 0.241144 (* 1 = 0.241144 loss)
I0813 09:06:16.450891 18283 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0813 09:06:58.113415 18283 solver.cpp:228] Iteration 2650, loss = 0.240221
I0813 09:06:58.113570 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:06:58.113585 18283 solver.cpp:244]     Train net output #1: loss = 0.240221 (* 1 = 0.240221 loss)
I0813 09:06:58.113598 18283 sgd_solver.cpp:106] Iteration 2650, lr = 0.00838363
I0813 09:07:38.969249 18283 solver.cpp:337] Iteration 2700, Testing net (#0)
I0813 09:07:43.261801 18283 solver.cpp:404]     Test net output #0: accuracy = 0.886
I0813 09:07:43.261869 18283 solver.cpp:404]     Test net output #1: loss = 0.688053 (* 1 = 0.688053 loss)
I0813 09:07:44.089702 18283 solver.cpp:228] Iteration 2700, loss = 0.200188
I0813 09:07:44.089761 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 09:07:44.089773 18283 solver.cpp:244]     Train net output #1: loss = 0.200187 (* 1 = 0.200187 loss)
I0813 09:07:44.089787 18283 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0813 09:08:25.885635 18283 solver.cpp:228] Iteration 2750, loss = 0.180198
I0813 09:08:25.885864 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 09:08:25.885936 18283 solver.cpp:244]     Train net output #1: loss = 0.180197 (* 1 = 0.180197 loss)
I0813 09:08:25.885964 18283 sgd_solver.cpp:106] Iteration 2750, lr = 0.00833427
I0813 09:09:07.027909 18283 solver.cpp:337] Iteration 2800, Testing net (#0)
I0813 09:09:11.139502 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:09:11.139562 18283 solver.cpp:404]     Test net output #1: loss = 0.692963 (* 1 = 0.692963 loss)
I0813 09:09:11.962471 18283 solver.cpp:228] Iteration 2800, loss = 0.241906
I0813 09:09:11.962519 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:09:11.962530 18283 solver.cpp:244]     Train net output #1: loss = 0.241905 (* 1 = 0.241905 loss)
I0813 09:09:11.962549 18283 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0813 09:09:53.686241 18283 solver.cpp:228] Iteration 2850, loss = 0.240112
I0813 09:09:53.686470 18283 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0813 09:09:53.686523 18283 solver.cpp:244]     Train net output #1: loss = 0.240111 (* 1 = 0.240111 loss)
I0813 09:09:53.686547 18283 sgd_solver.cpp:106] Iteration 2850, lr = 0.00828557
I0813 09:10:34.638870 18283 solver.cpp:337] Iteration 2900, Testing net (#0)
I0813 09:10:38.746847 18283 solver.cpp:404]     Test net output #0: accuracy = 0.664
I0813 09:10:38.746908 18283 solver.cpp:404]     Test net output #1: loss = 0.688151 (* 1 = 0.688151 loss)
I0813 09:10:39.572235 18283 solver.cpp:228] Iteration 2900, loss = 0.200229
I0813 09:10:39.572291 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:10:39.572304 18283 solver.cpp:244]     Train net output #1: loss = 0.200229 (* 1 = 0.200229 loss)
I0813 09:10:39.572317 18283 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0813 09:11:21.279839 18283 solver.cpp:228] Iteration 2950, loss = 0.180327
I0813 09:11:21.280102 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 09:11:21.280164 18283 solver.cpp:244]     Train net output #1: loss = 0.180327 (* 1 = 0.180327 loss)
I0813 09:11:21.280190 18283 sgd_solver.cpp:106] Iteration 2950, lr = 0.00823754
I0813 09:12:02.270390 18283 solver.cpp:337] Iteration 3000, Testing net (#0)
I0813 09:12:06.397881 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 09:12:06.397953 18283 solver.cpp:404]     Test net output #1: loss = 0.689254 (* 1 = 0.689254 loss)
I0813 09:12:07.220016 18283 solver.cpp:228] Iteration 3000, loss = 0.24086
I0813 09:12:07.220072 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 09:12:07.220085 18283 solver.cpp:244]     Train net output #1: loss = 0.24086 (* 1 = 0.24086 loss)
I0813 09:12:07.220104 18283 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0813 09:12:48.949352 18283 solver.cpp:228] Iteration 3050, loss = 0.24036
I0813 09:12:48.949590 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:12:48.949641 18283 solver.cpp:244]     Train net output #1: loss = 0.24036 (* 1 = 0.24036 loss)
I0813 09:12:48.949667 18283 sgd_solver.cpp:106] Iteration 3050, lr = 0.00819015
I0813 09:13:30.174281 18283 solver.cpp:337] Iteration 3100, Testing net (#0)
I0813 09:13:34.274293 18283 solver.cpp:404]     Test net output #0: accuracy = 0.978
I0813 09:13:34.274358 18283 solver.cpp:404]     Test net output #1: loss = 0.688065 (* 1 = 0.688065 loss)
I0813 09:13:35.097105 18283 solver.cpp:228] Iteration 3100, loss = 0.200137
I0813 09:13:35.097167 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 09:13:35.097179 18283 solver.cpp:244]     Train net output #1: loss = 0.200137 (* 1 = 0.200137 loss)
I0813 09:13:35.097193 18283 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0813 09:14:16.893803 18283 solver.cpp:228] Iteration 3150, loss = 0.180542
I0813 09:14:16.893955 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 09:14:16.893971 18283 solver.cpp:244]     Train net output #1: loss = 0.180542 (* 1 = 0.180542 loss)
I0813 09:14:16.893983 18283 sgd_solver.cpp:106] Iteration 3150, lr = 0.0081434
I0813 09:14:57.911272 18283 solver.cpp:337] Iteration 3200, Testing net (#0)
I0813 09:15:02.024325 18283 solver.cpp:404]     Test net output #0: accuracy = 0.81
I0813 09:15:02.024400 18283 solver.cpp:404]     Test net output #1: loss = 0.688062 (* 1 = 0.688062 loss)
I0813 09:15:02.850880 18283 solver.cpp:228] Iteration 3200, loss = 0.240261
I0813 09:15:02.850931 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:15:02.850944 18283 solver.cpp:244]     Train net output #1: loss = 0.240261 (* 1 = 0.240261 loss)
I0813 09:15:02.850960 18283 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0813 09:15:44.660507 18283 solver.cpp:228] Iteration 3250, loss = 0.240804
I0813 09:15:44.660738 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 09:15:44.660799 18283 solver.cpp:244]     Train net output #1: loss = 0.240804 (* 1 = 0.240804 loss)
I0813 09:15:44.660840 18283 sgd_solver.cpp:106] Iteration 3250, lr = 0.00809726
I0813 09:16:25.811000 18283 solver.cpp:337] Iteration 3300, Testing net (#0)
I0813 09:16:29.890055 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 09:16:29.890122 18283 solver.cpp:404]     Test net output #1: loss = 0.688652 (* 1 = 0.688652 loss)
I0813 09:16:30.715201 18283 solver.cpp:228] Iteration 3300, loss = 0.200298
I0813 09:16:30.715273 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 09:16:30.715286 18283 solver.cpp:244]     Train net output #1: loss = 0.200298 (* 1 = 0.200298 loss)
I0813 09:16:30.715301 18283 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0813 09:17:12.525049 18283 solver.cpp:228] Iteration 3350, loss = 0.180308
I0813 09:17:12.525218 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 09:17:12.525271 18283 solver.cpp:244]     Train net output #1: loss = 0.180308 (* 1 = 0.180308 loss)
I0813 09:17:12.525300 18283 sgd_solver.cpp:106] Iteration 3350, lr = 0.00805173
I0813 09:17:53.706730 18283 solver.cpp:337] Iteration 3400, Testing net (#0)
I0813 09:17:57.823120 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:17:57.823184 18283 solver.cpp:404]     Test net output #1: loss = 0.68879 (* 1 = 0.68879 loss)
I0813 09:17:58.642786 18283 solver.cpp:228] Iteration 3400, loss = 0.240483
I0813 09:17:58.642848 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:17:58.642859 18283 solver.cpp:244]     Train net output #1: loss = 0.240483 (* 1 = 0.240483 loss)
I0813 09:17:58.642876 18283 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0813 09:18:40.397203 18283 solver.cpp:228] Iteration 3450, loss = 0.242213
I0813 09:18:40.397390 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:18:40.397405 18283 solver.cpp:244]     Train net output #1: loss = 0.242213 (* 1 = 0.242213 loss)
I0813 09:18:40.397418 18283 sgd_solver.cpp:106] Iteration 3450, lr = 0.00800679
I0813 09:19:21.416728 18283 solver.cpp:337] Iteration 3500, Testing net (#0)
I0813 09:19:25.525401 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:19:25.525470 18283 solver.cpp:404]     Test net output #1: loss = 0.689082 (* 1 = 0.689082 loss)
I0813 09:19:26.351008 18283 solver.cpp:228] Iteration 3500, loss = 0.200537
I0813 09:19:26.351058 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:19:26.351068 18283 solver.cpp:244]     Train net output #1: loss = 0.200537 (* 1 = 0.200537 loss)
I0813 09:19:26.351089 18283 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0813 09:20:08.147588 18283 solver.cpp:228] Iteration 3550, loss = 0.180108
I0813 09:20:08.147794 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 09:20:08.147850 18283 solver.cpp:244]     Train net output #1: loss = 0.180108 (* 1 = 0.180108 loss)
I0813 09:20:08.147876 18283 sgd_solver.cpp:106] Iteration 3550, lr = 0.00796243
I0813 09:20:49.244748 18283 solver.cpp:337] Iteration 3600, Testing net (#0)
I0813 09:20:53.357964 18283 solver.cpp:404]     Test net output #0: accuracy = 0.998
I0813 09:20:53.358037 18283 solver.cpp:404]     Test net output #1: loss = 0.688307 (* 1 = 0.688307 loss)
I0813 09:20:54.181450 18283 solver.cpp:228] Iteration 3600, loss = 0.240099
I0813 09:20:54.181514 18283 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0813 09:20:54.181527 18283 solver.cpp:244]     Train net output #1: loss = 0.240099 (* 1 = 0.240099 loss)
I0813 09:20:54.181547 18283 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0813 09:21:35.822232 18283 solver.cpp:228] Iteration 3650, loss = 0.240175
I0813 09:21:35.822394 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:21:35.822409 18283 solver.cpp:244]     Train net output #1: loss = 0.240175 (* 1 = 0.240175 loss)
I0813 09:21:35.822422 18283 sgd_solver.cpp:106] Iteration 3650, lr = 0.00791864
I0813 09:22:16.621713 18283 solver.cpp:337] Iteration 3700, Testing net (#0)
I0813 09:22:20.740432 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:22:20.740499 18283 solver.cpp:404]     Test net output #1: loss = 0.688348 (* 1 = 0.688348 loss)
I0813 09:22:21.566777 18283 solver.cpp:228] Iteration 3700, loss = 0.200279
I0813 09:22:21.566838 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:22:21.566849 18283 solver.cpp:244]     Train net output #1: loss = 0.200279 (* 1 = 0.200279 loss)
I0813 09:22:21.566864 18283 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0813 09:23:03.323004 18283 solver.cpp:228] Iteration 3750, loss = 0.180152
I0813 09:23:03.323165 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 09:23:03.323180 18283 solver.cpp:244]     Train net output #1: loss = 0.180152 (* 1 = 0.180152 loss)
I0813 09:23:03.323192 18283 sgd_solver.cpp:106] Iteration 3750, lr = 0.00787541
I0813 09:23:44.274550 18283 solver.cpp:337] Iteration 3800, Testing net (#0)
I0813 09:23:48.692656 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:23:48.692723 18283 solver.cpp:404]     Test net output #1: loss = 0.692113 (* 1 = 0.692113 loss)
I0813 09:23:49.587388 18283 solver.cpp:228] Iteration 3800, loss = 0.241628
I0813 09:23:49.587451 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:23:49.587463 18283 solver.cpp:244]     Train net output #1: loss = 0.241628 (* 1 = 0.241628 loss)
I0813 09:23:49.587478 18283 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0813 09:24:31.698079 18283 solver.cpp:228] Iteration 3850, loss = 0.240264
I0813 09:24:31.698315 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:24:31.698371 18283 solver.cpp:244]     Train net output #1: loss = 0.240263 (* 1 = 0.240263 loss)
I0813 09:24:31.698396 18283 sgd_solver.cpp:106] Iteration 3850, lr = 0.00783272
I0813 09:25:12.997714 18283 solver.cpp:337] Iteration 3900, Testing net (#0)
I0813 09:25:17.354785 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:25:17.354857 18283 solver.cpp:404]     Test net output #1: loss = 0.688404 (* 1 = 0.688404 loss)
I0813 09:25:18.180549 18283 solver.cpp:228] Iteration 3900, loss = 0.200313
I0813 09:25:18.180601 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:25:18.180613 18283 solver.cpp:244]     Train net output #1: loss = 0.200313 (* 1 = 0.200313 loss)
I0813 09:25:18.180632 18283 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0813 09:26:00.151374 18283 solver.cpp:228] Iteration 3950, loss = 0.180585
I0813 09:26:00.151533 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 09:26:00.151547 18283 solver.cpp:244]     Train net output #1: loss = 0.180585 (* 1 = 0.180585 loss)
I0813 09:26:00.151561 18283 sgd_solver.cpp:106] Iteration 3950, lr = 0.00779057
I0813 09:26:41.042027 18283 solver.cpp:337] Iteration 4000, Testing net (#0)
I0813 09:26:45.370700 18283 solver.cpp:404]     Test net output #0: accuracy = 0.788
I0813 09:26:45.370757 18283 solver.cpp:404]     Test net output #1: loss = 0.688107 (* 1 = 0.688107 loss)
I0813 09:26:46.198966 18283 solver.cpp:228] Iteration 4000, loss = 0.240236
I0813 09:26:46.199015 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:26:46.199026 18283 solver.cpp:244]     Train net output #1: loss = 0.240236 (* 1 = 0.240236 loss)
I0813 09:26:46.199043 18283 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0813 09:27:27.938978 18283 solver.cpp:228] Iteration 4050, loss = 0.24039
I0813 09:27:27.939180 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:27:27.939246 18283 solver.cpp:244]     Train net output #1: loss = 0.240389 (* 1 = 0.240389 loss)
I0813 09:27:27.939270 18283 sgd_solver.cpp:106] Iteration 4050, lr = 0.00774895
I0813 09:28:08.974498 18283 solver.cpp:337] Iteration 4100, Testing net (#0)
I0813 09:28:13.104701 18283 solver.cpp:404]     Test net output #0: accuracy = 0.679
I0813 09:28:13.104768 18283 solver.cpp:404]     Test net output #1: loss = 0.688195 (* 1 = 0.688195 loss)
I0813 09:28:13.927875 18283 solver.cpp:228] Iteration 4100, loss = 0.200266
I0813 09:28:13.927927 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:28:13.927938 18283 solver.cpp:244]     Train net output #1: loss = 0.200266 (* 1 = 0.200266 loss)
I0813 09:28:13.927950 18283 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0813 09:28:55.645473 18283 solver.cpp:228] Iteration 4150, loss = 0.180481
I0813 09:28:55.645619 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 09:28:55.645633 18283 solver.cpp:244]     Train net output #1: loss = 0.180481 (* 1 = 0.180481 loss)
I0813 09:28:55.645645 18283 sgd_solver.cpp:106] Iteration 4150, lr = 0.00770784
I0813 09:29:36.634157 18283 solver.cpp:337] Iteration 4200, Testing net (#0)
I0813 09:29:40.733469 18283 solver.cpp:404]     Test net output #0: accuracy = 0.994
I0813 09:29:40.733533 18283 solver.cpp:404]     Test net output #1: loss = 0.68809 (* 1 = 0.68809 loss)
I0813 09:29:41.551759 18283 solver.cpp:228] Iteration 4200, loss = 0.240047
I0813 09:29:41.551811 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 09:29:41.551822 18283 solver.cpp:244]     Train net output #1: loss = 0.240047 (* 1 = 0.240047 loss)
I0813 09:29:41.551841 18283 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0813 09:30:22.818439 18283 solver.cpp:228] Iteration 4250, loss = 0.240779
I0813 09:30:22.818702 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:30:22.818750 18283 solver.cpp:244]     Train net output #1: loss = 0.240779 (* 1 = 0.240779 loss)
I0813 09:30:22.818769 18283 sgd_solver.cpp:106] Iteration 4250, lr = 0.00766724
I0813 09:31:03.868131 18283 solver.cpp:337] Iteration 4300, Testing net (#0)
I0813 09:31:07.921705 18283 solver.cpp:404]     Test net output #0: accuracy = 0.776
I0813 09:31:07.921775 18283 solver.cpp:404]     Test net output #1: loss = 0.688118 (* 1 = 0.688118 loss)
I0813 09:31:08.733579 18283 solver.cpp:228] Iteration 4300, loss = 0.200206
I0813 09:31:08.733634 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:31:08.733646 18283 solver.cpp:244]     Train net output #1: loss = 0.200206 (* 1 = 0.200206 loss)
I0813 09:31:08.733659 18283 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0813 09:31:49.824472 18283 solver.cpp:228] Iteration 4350, loss = 0.1801
I0813 09:31:49.824684 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 09:31:49.824738 18283 solver.cpp:244]     Train net output #1: loss = 0.1801 (* 1 = 0.1801 loss)
I0813 09:31:49.824771 18283 sgd_solver.cpp:106] Iteration 4350, lr = 0.00762713
I0813 09:32:30.158627 18283 solver.cpp:337] Iteration 4400, Testing net (#0)
I0813 09:32:34.194262 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:32:34.194335 18283 solver.cpp:404]     Test net output #1: loss = 0.689405 (* 1 = 0.689405 loss)
I0813 09:32:35.005638 18283 solver.cpp:228] Iteration 4400, loss = 0.240639
I0813 09:32:35.005688 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:32:35.005698 18283 solver.cpp:244]     Train net output #1: loss = 0.240639 (* 1 = 0.240639 loss)
I0813 09:32:35.005715 18283 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0813 09:33:16.112622 18283 solver.cpp:228] Iteration 4450, loss = 0.240109
I0813 09:33:16.112823 18283 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0813 09:33:16.112876 18283 solver.cpp:244]     Train net output #1: loss = 0.240109 (* 1 = 0.240109 loss)
I0813 09:33:16.112897 18283 sgd_solver.cpp:106] Iteration 4450, lr = 0.00758751
I0813 09:33:56.386337 18283 solver.cpp:337] Iteration 4500, Testing net (#0)
I0813 09:34:00.439177 18283 solver.cpp:404]     Test net output #0: accuracy = 0.661
I0813 09:34:00.439244 18283 solver.cpp:404]     Test net output #1: loss = 0.688294 (* 1 = 0.688294 loss)
I0813 09:34:01.249655 18283 solver.cpp:228] Iteration 4500, loss = 0.200197
I0813 09:34:01.249701 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:34:01.249713 18283 solver.cpp:244]     Train net output #1: loss = 0.200197 (* 1 = 0.200197 loss)
I0813 09:34:01.249732 18283 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0813 09:34:42.379343 18283 solver.cpp:228] Iteration 4550, loss = 0.180205
I0813 09:34:42.379490 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 09:34:42.379505 18283 solver.cpp:244]     Train net output #1: loss = 0.180204 (* 1 = 0.180204 loss)
I0813 09:34:42.379516 18283 sgd_solver.cpp:106] Iteration 4550, lr = 0.00754836
I0813 09:35:22.683464 18283 solver.cpp:337] Iteration 4600, Testing net (#0)
I0813 09:35:26.727630 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:35:26.727697 18283 solver.cpp:404]     Test net output #1: loss = 0.689485 (* 1 = 0.689485 loss)
I0813 09:35:27.539656 18283 solver.cpp:228] Iteration 4600, loss = 0.240615
I0813 09:35:27.539712 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:35:27.539722 18283 solver.cpp:244]     Train net output #1: loss = 0.240615 (* 1 = 0.240615 loss)
I0813 09:35:27.539739 18283 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0813 09:36:08.664317 18283 solver.cpp:228] Iteration 4650, loss = 0.241559
I0813 09:36:08.664474 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:36:08.664489 18283 solver.cpp:244]     Train net output #1: loss = 0.241559 (* 1 = 0.241559 loss)
I0813 09:36:08.664501 18283 sgd_solver.cpp:106] Iteration 4650, lr = 0.00750969
I0813 09:36:48.968334 18283 solver.cpp:337] Iteration 4700, Testing net (#0)
I0813 09:36:53.014328 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:36:53.014408 18283 solver.cpp:404]     Test net output #1: loss = 0.688618 (* 1 = 0.688618 loss)
I0813 09:36:53.825419 18283 solver.cpp:228] Iteration 4700, loss = 0.200235
I0813 09:36:53.825465 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:36:53.825477 18283 solver.cpp:244]     Train net output #1: loss = 0.200235 (* 1 = 0.200235 loss)
I0813 09:36:53.825489 18283 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0813 09:37:34.953003 18283 solver.cpp:228] Iteration 4750, loss = 0.180191
I0813 09:37:34.953214 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 09:37:34.953274 18283 solver.cpp:244]     Train net output #1: loss = 0.180191 (* 1 = 0.180191 loss)
I0813 09:37:34.953307 18283 sgd_solver.cpp:106] Iteration 4750, lr = 0.00747147
I0813 09:38:15.292735 18283 solver.cpp:337] Iteration 4800, Testing net (#0)
I0813 09:38:19.536149 18283 solver.cpp:404]     Test net output #0: accuracy = 0.971
I0813 09:38:19.536213 18283 solver.cpp:404]     Test net output #1: loss = 0.687996 (* 1 = 0.687996 loss)
I0813 09:38:20.347800 18283 solver.cpp:228] Iteration 4800, loss = 0.24007
I0813 09:38:20.347858 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 09:38:20.347872 18283 solver.cpp:244]     Train net output #1: loss = 0.24007 (* 1 = 0.24007 loss)
I0813 09:38:20.347889 18283 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0813 09:39:01.460299 18283 solver.cpp:228] Iteration 4850, loss = 0.240143
I0813 09:39:01.460458 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:39:01.460471 18283 solver.cpp:244]     Train net output #1: loss = 0.240143 (* 1 = 0.240143 loss)
I0813 09:39:01.460484 18283 sgd_solver.cpp:106] Iteration 4850, lr = 0.0074337
I0813 09:39:41.764358 18283 solver.cpp:337] Iteration 4900, Testing net (#0)
I0813 09:39:45.813141 18283 solver.cpp:404]     Test net output #0: accuracy = 0.984
I0813 09:39:45.813217 18283 solver.cpp:404]     Test net output #1: loss = 0.688047 (* 1 = 0.688047 loss)
I0813 09:39:46.624629 18283 solver.cpp:228] Iteration 4900, loss = 0.200043
I0813 09:39:46.624682 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 09:39:46.624694 18283 solver.cpp:244]     Train net output #1: loss = 0.200043 (* 1 = 0.200043 loss)
I0813 09:39:46.624712 18283 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0813 09:40:27.728163 18283 solver.cpp:228] Iteration 4950, loss = 0.180105
I0813 09:40:27.728332 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 09:40:27.728348 18283 solver.cpp:244]     Train net output #1: loss = 0.180105 (* 1 = 0.180105 loss)
I0813 09:40:27.728358 18283 sgd_solver.cpp:106] Iteration 4950, lr = 0.00739638
I0813 09:41:08.020858 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_5000.caffemodel
I0813 09:41:08.365449 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_5000.solverstate
I0813 09:41:08.379444 18283 solver.cpp:337] Iteration 5000, Testing net (#0)
I0813 09:41:12.438169 18283 solver.cpp:404]     Test net output #0: accuracy = 0.748
I0813 09:41:12.438235 18283 solver.cpp:404]     Test net output #1: loss = 0.688142 (* 1 = 0.688142 loss)
I0813 09:41:13.249815 18283 solver.cpp:228] Iteration 5000, loss = 0.240142
I0813 09:41:13.249879 18283 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0813 09:41:13.249891 18283 solver.cpp:244]     Train net output #1: loss = 0.240142 (* 1 = 0.240142 loss)
I0813 09:41:13.249904 18283 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0813 09:41:54.366719 18283 solver.cpp:228] Iteration 5050, loss = 0.240069
I0813 09:41:54.366885 18283 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0813 09:41:54.366901 18283 solver.cpp:244]     Train net output #1: loss = 0.240069 (* 1 = 0.240069 loss)
I0813 09:41:54.366914 18283 sgd_solver.cpp:106] Iteration 5050, lr = 0.00735949
I0813 09:42:34.695358 18283 solver.cpp:337] Iteration 5100, Testing net (#0)
I0813 09:42:38.952582 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:42:38.952648 18283 solver.cpp:404]     Test net output #1: loss = 0.689541 (* 1 = 0.689541 loss)
I0813 09:42:39.764420 18283 solver.cpp:228] Iteration 5100, loss = 0.200526
I0813 09:42:39.764474 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:42:39.764487 18283 solver.cpp:244]     Train net output #1: loss = 0.200526 (* 1 = 0.200526 loss)
I0813 09:42:39.764505 18283 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0813 09:43:20.911422 18283 solver.cpp:228] Iteration 5150, loss = 0.180073
I0813 09:43:20.911590 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 09:43:20.911605 18283 solver.cpp:244]     Train net output #1: loss = 0.180073 (* 1 = 0.180073 loss)
I0813 09:43:20.911617 18283 sgd_solver.cpp:106] Iteration 5150, lr = 0.00732303
I0813 09:44:01.260617 18283 solver.cpp:337] Iteration 5200, Testing net (#0)
I0813 09:44:05.528645 18283 solver.cpp:404]     Test net output #0: accuracy = 0.993
I0813 09:44:05.528712 18283 solver.cpp:404]     Test net output #1: loss = 0.687998 (* 1 = 0.687998 loss)
I0813 09:44:06.341320 18283 solver.cpp:228] Iteration 5200, loss = 0.239978
I0813 09:44:06.341377 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 09:44:06.341389 18283 solver.cpp:244]     Train net output #1: loss = 0.239978 (* 1 = 0.239978 loss)
I0813 09:44:06.341406 18283 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0813 09:44:47.936347 18283 solver.cpp:228] Iteration 5250, loss = 0.240132
I0813 09:44:47.936509 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:44:47.936532 18283 solver.cpp:244]     Train net output #1: loss = 0.240132 (* 1 = 0.240132 loss)
I0813 09:44:47.936545 18283 sgd_solver.cpp:106] Iteration 5250, lr = 0.00728698
I0813 09:45:28.291357 18283 solver.cpp:337] Iteration 5300, Testing net (#0)
I0813 09:45:32.621475 18283 solver.cpp:404]     Test net output #0: accuracy = 0.908
I0813 09:45:32.621547 18283 solver.cpp:404]     Test net output #1: loss = 0.687999 (* 1 = 0.687999 loss)
I0813 09:45:33.432410 18283 solver.cpp:228] Iteration 5300, loss = 0.200106
I0813 09:45:33.432467 18283 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0813 09:45:33.432481 18283 solver.cpp:244]     Train net output #1: loss = 0.200106 (* 1 = 0.200106 loss)
I0813 09:45:33.432497 18283 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0813 09:46:16.069439 18283 solver.cpp:228] Iteration 5350, loss = 0.180256
I0813 09:46:16.069600 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 09:46:16.069633 18283 solver.cpp:244]     Train net output #1: loss = 0.180256 (* 1 = 0.180256 loss)
I0813 09:46:16.069649 18283 sgd_solver.cpp:106] Iteration 5350, lr = 0.00725135
I0813 09:46:56.892853 18283 solver.cpp:337] Iteration 5400, Testing net (#0)
I0813 09:47:00.953949 18283 solver.cpp:404]     Test net output #0: accuracy = 0.998
I0813 09:47:00.954017 18283 solver.cpp:404]     Test net output #1: loss = 0.688079 (* 1 = 0.688079 loss)
I0813 09:47:01.768142 18283 solver.cpp:228] Iteration 5400, loss = 0.240111
I0813 09:47:01.768203 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 09:47:01.768215 18283 solver.cpp:244]     Train net output #1: loss = 0.240111 (* 1 = 0.240111 loss)
I0813 09:47:01.768229 18283 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0813 09:47:42.891425 18283 solver.cpp:228] Iteration 5450, loss = 0.24017
I0813 09:47:42.891585 18283 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0813 09:47:42.891599 18283 solver.cpp:244]     Train net output #1: loss = 0.24017 (* 1 = 0.24017 loss)
I0813 09:47:42.891611 18283 sgd_solver.cpp:106] Iteration 5450, lr = 0.00721612
I0813 09:48:24.435387 18283 solver.cpp:337] Iteration 5500, Testing net (#0)
I0813 09:48:28.503602 18283 solver.cpp:404]     Test net output #0: accuracy = 0.991
I0813 09:48:28.503669 18283 solver.cpp:404]     Test net output #1: loss = 0.687989 (* 1 = 0.687989 loss)
I0813 09:48:29.315564 18283 solver.cpp:228] Iteration 5500, loss = 0.200015
I0813 09:48:29.315631 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 09:48:29.315642 18283 solver.cpp:244]     Train net output #1: loss = 0.200015 (* 1 = 0.200015 loss)
I0813 09:48:29.315656 18283 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0813 09:49:10.902863 18283 solver.cpp:228] Iteration 5550, loss = 0.180357
I0813 09:49:10.903131 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 09:49:10.903180 18283 solver.cpp:244]     Train net output #1: loss = 0.180357 (* 1 = 0.180357 loss)
I0813 09:49:10.903215 18283 sgd_solver.cpp:106] Iteration 5550, lr = 0.00718129
I0813 09:49:51.279086 18283 solver.cpp:337] Iteration 5600, Testing net (#0)
I0813 09:49:55.511338 18283 solver.cpp:404]     Test net output #0: accuracy = 0.999
I0813 09:49:55.511415 18283 solver.cpp:404]     Test net output #1: loss = 0.688152 (* 1 = 0.688152 loss)
I0813 09:49:56.325603 18283 solver.cpp:228] Iteration 5600, loss = 0.240021
I0813 09:49:56.325670 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 09:49:56.325681 18283 solver.cpp:244]     Train net output #1: loss = 0.240021 (* 1 = 0.240021 loss)
I0813 09:49:56.325695 18283 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0813 09:50:38.080319 18283 solver.cpp:228] Iteration 5650, loss = 0.240578
I0813 09:50:38.080525 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 09:50:38.080579 18283 solver.cpp:244]     Train net output #1: loss = 0.240578 (* 1 = 0.240578 loss)
I0813 09:50:38.080602 18283 sgd_solver.cpp:106] Iteration 5650, lr = 0.00714684
I0813 09:51:18.627377 18283 solver.cpp:337] Iteration 5700, Testing net (#0)
I0813 09:51:22.692942 18283 solver.cpp:404]     Test net output #0: accuracy = 0.854
I0813 09:51:22.693006 18283 solver.cpp:404]     Test net output #1: loss = 0.688054 (* 1 = 0.688054 loss)
I0813 09:51:23.505287 18283 solver.cpp:228] Iteration 5700, loss = 0.200084
I0813 09:51:23.505354 18283 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0813 09:51:23.505368 18283 solver.cpp:244]     Train net output #1: loss = 0.200084 (* 1 = 0.200084 loss)
I0813 09:51:23.505383 18283 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0813 09:52:04.649760 18283 solver.cpp:228] Iteration 5750, loss = 0.180058
I0813 09:52:04.649942 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 09:52:04.649956 18283 solver.cpp:244]     Train net output #1: loss = 0.180058 (* 1 = 0.180058 loss)
I0813 09:52:04.649968 18283 sgd_solver.cpp:106] Iteration 5750, lr = 0.00711278
I0813 09:52:44.968425 18283 solver.cpp:337] Iteration 5800, Testing net (#0)
I0813 09:52:49.021260 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:52:49.021332 18283 solver.cpp:404]     Test net output #1: loss = 0.688615 (* 1 = 0.688615 loss)
I0813 09:52:49.833394 18283 solver.cpp:228] Iteration 5800, loss = 0.240261
I0813 09:52:49.833457 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:52:49.833469 18283 solver.cpp:244]     Train net output #1: loss = 0.240261 (* 1 = 0.240261 loss)
I0813 09:52:49.833482 18283 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0813 09:53:30.962512 18283 solver.cpp:228] Iteration 5850, loss = 0.240084
I0813 09:53:30.962679 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 09:53:30.962693 18283 solver.cpp:244]     Train net output #1: loss = 0.240084 (* 1 = 0.240084 loss)
I0813 09:53:30.962705 18283 sgd_solver.cpp:106] Iteration 5850, lr = 0.0070791
I0813 09:54:11.296746 18283 solver.cpp:337] Iteration 5900, Testing net (#0)
I0813 09:54:15.344104 18283 solver.cpp:404]     Test net output #0: accuracy = 0.673
I0813 09:54:15.344184 18283 solver.cpp:404]     Test net output #1: loss = 0.688373 (* 1 = 0.688373 loss)
I0813 09:54:16.155746 18283 solver.cpp:228] Iteration 5900, loss = 0.200194
I0813 09:54:16.155800 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:54:16.155812 18283 solver.cpp:244]     Train net output #1: loss = 0.200194 (* 1 = 0.200194 loss)
I0813 09:54:16.155830 18283 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0813 09:54:57.323891 18283 solver.cpp:228] Iteration 5950, loss = 0.180163
I0813 09:54:57.324160 18283 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0813 09:54:57.324213 18283 solver.cpp:244]     Train net output #1: loss = 0.180163 (* 1 = 0.180163 loss)
I0813 09:54:57.324234 18283 sgd_solver.cpp:106] Iteration 5950, lr = 0.00704579
I0813 09:55:38.019846 18283 solver.cpp:337] Iteration 6000, Testing net (#0)
I0813 09:55:42.074635 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 09:55:42.074700 18283 solver.cpp:404]     Test net output #1: loss = 0.688349 (* 1 = 0.688349 loss)
I0813 09:55:42.886093 18283 solver.cpp:228] Iteration 6000, loss = 0.240317
I0813 09:55:42.886147 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 09:55:42.886158 18283 solver.cpp:244]     Train net output #1: loss = 0.240317 (* 1 = 0.240317 loss)
I0813 09:55:42.886175 18283 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0813 09:56:23.993618 18283 solver.cpp:228] Iteration 6050, loss = 0.240275
I0813 09:56:23.993858 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:56:23.993906 18283 solver.cpp:244]     Train net output #1: loss = 0.240275 (* 1 = 0.240275 loss)
I0813 09:56:23.993932 18283 sgd_solver.cpp:106] Iteration 6050, lr = 0.00701284
I0813 09:57:04.926980 18283 solver.cpp:337] Iteration 6100, Testing net (#0)
I0813 09:57:09.247454 18283 solver.cpp:404]     Test net output #0: accuracy = 0.693
I0813 09:57:09.247531 18283 solver.cpp:404]     Test net output #1: loss = 0.68833 (* 1 = 0.68833 loss)
I0813 09:57:10.056473 18283 solver.cpp:228] Iteration 6100, loss = 0.200184
I0813 09:57:10.056526 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 09:57:10.056537 18283 solver.cpp:244]     Train net output #1: loss = 0.200184 (* 1 = 0.200184 loss)
I0813 09:57:10.056555 18283 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0813 09:57:52.541070 18283 solver.cpp:228] Iteration 6150, loss = 0.180073
I0813 09:57:52.541254 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 09:57:52.541303 18283 solver.cpp:244]     Train net output #1: loss = 0.180073 (* 1 = 0.180073 loss)
I0813 09:57:52.541328 18283 sgd_solver.cpp:106] Iteration 6150, lr = 0.00698024
I0813 09:58:33.438549 18283 solver.cpp:337] Iteration 6200, Testing net (#0)
I0813 09:58:37.494314 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 09:58:37.494377 18283 solver.cpp:404]     Test net output #1: loss = 0.690639 (* 1 = 0.690639 loss)
I0813 09:58:38.306366 18283 solver.cpp:228] Iteration 6200, loss = 0.240957
I0813 09:58:38.306418 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 09:58:38.306429 18283 solver.cpp:244]     Train net output #1: loss = 0.240957 (* 1 = 0.240957 loss)
I0813 09:58:38.306445 18283 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0813 09:59:19.446033 18283 solver.cpp:228] Iteration 6250, loss = 0.240603
I0813 09:59:19.446193 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 09:59:19.446208 18283 solver.cpp:244]     Train net output #1: loss = 0.240603 (* 1 = 0.240603 loss)
I0813 09:59:19.446219 18283 sgd_solver.cpp:106] Iteration 6250, lr = 0.006948
I0813 09:59:59.813151 18283 solver.cpp:337] Iteration 6300, Testing net (#0)
I0813 10:00:03.869114 18283 solver.cpp:404]     Test net output #0: accuracy = 0.96
I0813 10:00:03.869181 18283 solver.cpp:404]     Test net output #1: loss = 0.68788 (* 1 = 0.68788 loss)
I0813 10:00:04.682399 18283 solver.cpp:228] Iteration 6300, loss = 0.200066
I0813 10:00:04.682449 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:00:04.682461 18283 solver.cpp:244]     Train net output #1: loss = 0.200066 (* 1 = 0.200066 loss)
I0813 10:00:04.682481 18283 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0813 10:00:46.240908 18283 solver.cpp:228] Iteration 6350, loss = 0.180089
I0813 10:00:46.241171 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:00:46.241225 18283 solver.cpp:244]     Train net output #1: loss = 0.180089 (* 1 = 0.180089 loss)
I0813 10:00:46.241245 18283 sgd_solver.cpp:106] Iteration 6350, lr = 0.00691611
I0813 10:01:28.172492 18283 solver.cpp:337] Iteration 6400, Testing net (#0)
I0813 10:01:32.238464 18283 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 10:01:32.238530 18283 solver.cpp:404]     Test net output #1: loss = 0.688097 (* 1 = 0.688097 loss)
I0813 10:01:33.301651 18283 solver.cpp:228] Iteration 6400, loss = 0.24018
I0813 10:01:33.301723 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:01:33.301735 18283 solver.cpp:244]     Train net output #1: loss = 0.24018 (* 1 = 0.24018 loss)
I0813 10:01:33.301750 18283 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0813 10:02:15.153585 18283 solver.cpp:228] Iteration 6450, loss = 0.240094
I0813 10:02:15.153830 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:02:15.153892 18283 solver.cpp:244]     Train net output #1: loss = 0.240094 (* 1 = 0.240094 loss)
I0813 10:02:15.153920 18283 sgd_solver.cpp:106] Iteration 6450, lr = 0.00688455
I0813 10:02:55.691725 18283 solver.cpp:337] Iteration 6500, Testing net (#0)
I0813 10:02:59.750017 18283 solver.cpp:404]     Test net output #0: accuracy = 0.67
I0813 10:02:59.750103 18283 solver.cpp:404]     Test net output #1: loss = 0.68845 (* 1 = 0.68845 loss)
I0813 10:03:00.563912 18283 solver.cpp:228] Iteration 6500, loss = 0.200207
I0813 10:03:00.563980 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 10:03:00.563992 18283 solver.cpp:244]     Train net output #1: loss = 0.200207 (* 1 = 0.200207 loss)
I0813 10:03:00.564005 18283 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0813 10:03:41.740725 18283 solver.cpp:228] Iteration 6550, loss = 0.180053
I0813 10:03:41.740922 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 10:03:41.740974 18283 solver.cpp:244]     Train net output #1: loss = 0.180053 (* 1 = 0.180053 loss)
I0813 10:03:41.741011 18283 sgd_solver.cpp:106] Iteration 6550, lr = 0.00685333
I0813 10:04:22.315091 18283 solver.cpp:337] Iteration 6600, Testing net (#0)
I0813 10:04:26.373179 18283 solver.cpp:404]     Test net output #0: accuracy = 0.999
I0813 10:04:26.373245 18283 solver.cpp:404]     Test net output #1: loss = 0.688035 (* 1 = 0.688035 loss)
I0813 10:04:27.186200 18283 solver.cpp:228] Iteration 6600, loss = 0.240069
I0813 10:04:27.186262 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:04:27.186274 18283 solver.cpp:244]     Train net output #1: loss = 0.240069 (* 1 = 0.240069 loss)
I0813 10:04:27.186290 18283 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0813 10:05:08.379542 18283 solver.cpp:228] Iteration 6650, loss = 0.240197
I0813 10:05:08.379750 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:05:08.379796 18283 solver.cpp:244]     Train net output #1: loss = 0.240197 (* 1 = 0.240197 loss)
I0813 10:05:08.379822 18283 sgd_solver.cpp:106] Iteration 6650, lr = 0.00682243
I0813 10:05:48.857373 18283 solver.cpp:337] Iteration 6700, Testing net (#0)
I0813 10:05:52.917495 18283 solver.cpp:404]     Test net output #0: accuracy = 0.854
I0813 10:05:52.917564 18283 solver.cpp:404]     Test net output #1: loss = 0.688017 (* 1 = 0.688017 loss)
I0813 10:05:53.729158 18283 solver.cpp:228] Iteration 6700, loss = 0.20005
I0813 10:05:53.729210 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 10:05:53.729223 18283 solver.cpp:244]     Train net output #1: loss = 0.20005 (* 1 = 0.20005 loss)
I0813 10:05:53.729239 18283 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0813 10:06:34.892925 18283 solver.cpp:228] Iteration 6750, loss = 0.179973
I0813 10:06:34.893110 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:06:34.893127 18283 solver.cpp:244]     Train net output #1: loss = 0.179973 (* 1 = 0.179973 loss)
I0813 10:06:34.893141 18283 sgd_solver.cpp:106] Iteration 6750, lr = 0.00679186
I0813 10:07:15.217262 18283 solver.cpp:337] Iteration 6800, Testing net (#0)
I0813 10:07:19.274271 18283 solver.cpp:404]     Test net output #0: accuracy = 0.807
I0813 10:07:19.274339 18283 solver.cpp:404]     Test net output #1: loss = 0.688106 (* 1 = 0.688106 loss)
I0813 10:07:20.086160 18283 solver.cpp:228] Iteration 6800, loss = 0.240048
I0813 10:07:20.086215 18283 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0813 10:07:20.086227 18283 solver.cpp:244]     Train net output #1: loss = 0.240048 (* 1 = 0.240048 loss)
I0813 10:07:20.086239 18283 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0813 10:08:01.228456 18283 solver.cpp:228] Iteration 6850, loss = 0.24021
I0813 10:08:01.228664 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 10:08:01.228734 18283 solver.cpp:244]     Train net output #1: loss = 0.24021 (* 1 = 0.24021 loss)
I0813 10:08:01.228772 18283 sgd_solver.cpp:106] Iteration 6850, lr = 0.00676161
I0813 10:08:41.560680 18283 solver.cpp:337] Iteration 6900, Testing net (#0)
I0813 10:08:45.862136 18283 solver.cpp:404]     Test net output #0: accuracy = 0.91
I0813 10:08:45.862205 18283 solver.cpp:404]     Test net output #1: loss = 0.687931 (* 1 = 0.687931 loss)
I0813 10:08:46.674672 18283 solver.cpp:228] Iteration 6900, loss = 0.200059
I0813 10:08:46.674731 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 10:08:46.674742 18283 solver.cpp:244]     Train net output #1: loss = 0.200059 (* 1 = 0.200059 loss)
I0813 10:08:46.674759 18283 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0813 10:09:28.922680 18283 solver.cpp:228] Iteration 6950, loss = 0.180006
I0813 10:09:28.922904 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:09:28.922967 18283 solver.cpp:244]     Train net output #1: loss = 0.180006 (* 1 = 0.180006 loss)
I0813 10:09:28.922999 18283 sgd_solver.cpp:106] Iteration 6950, lr = 0.00673167
I0813 10:10:09.712252 18283 solver.cpp:337] Iteration 7000, Testing net (#0)
I0813 10:10:13.772900 18283 solver.cpp:404]     Test net output #0: accuracy = 0.738
I0813 10:10:13.772967 18283 solver.cpp:404]     Test net output #1: loss = 0.688258 (* 1 = 0.688258 loss)
I0813 10:10:14.584810 18283 solver.cpp:228] Iteration 7000, loss = 0.240099
I0813 10:10:14.584877 18283 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 10:10:14.584889 18283 solver.cpp:244]     Train net output #1: loss = 0.240099 (* 1 = 0.240099 loss)
I0813 10:10:14.584902 18283 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0813 10:10:55.695881 18283 solver.cpp:228] Iteration 7050, loss = 0.240337
I0813 10:10:55.696044 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:10:55.696059 18283 solver.cpp:244]     Train net output #1: loss = 0.240337 (* 1 = 0.240337 loss)
I0813 10:10:55.696070 18283 sgd_solver.cpp:106] Iteration 7050, lr = 0.00670204
I0813 10:11:36.027014 18283 solver.cpp:337] Iteration 7100, Testing net (#0)
I0813 10:11:40.076197 18283 solver.cpp:404]     Test net output #0: accuracy = 0.963
I0813 10:11:40.076277 18283 solver.cpp:404]     Test net output #1: loss = 0.687765 (* 1 = 0.687765 loss)
I0813 10:11:40.888319 18283 solver.cpp:228] Iteration 7100, loss = 0.19998
I0813 10:11:40.888377 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:11:40.888389 18283 solver.cpp:244]     Train net output #1: loss = 0.19998 (* 1 = 0.19998 loss)
I0813 10:11:40.888404 18283 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0813 10:12:22.025948 18283 solver.cpp:228] Iteration 7150, loss = 0.180201
I0813 10:12:22.026151 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:12:22.026206 18283 solver.cpp:244]     Train net output #1: loss = 0.180201 (* 1 = 0.180201 loss)
I0813 10:12:22.026231 18283 sgd_solver.cpp:106] Iteration 7150, lr = 0.0066727
I0813 10:13:02.651571 18283 solver.cpp:337] Iteration 7200, Testing net (#0)
I0813 10:13:06.715942 18283 solver.cpp:404]     Test net output #0: accuracy = 0.989
I0813 10:13:06.716008 18283 solver.cpp:404]     Test net output #1: loss = 0.687776 (* 1 = 0.687776 loss)
I0813 10:13:07.528908 18283 solver.cpp:228] Iteration 7200, loss = 0.239932
I0813 10:13:07.528965 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:13:07.528976 18283 solver.cpp:244]     Train net output #1: loss = 0.239932 (* 1 = 0.239932 loss)
I0813 10:13:07.528995 18283 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0813 10:13:48.693953 18283 solver.cpp:228] Iteration 7250, loss = 0.241136
I0813 10:13:48.694198 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 10:13:48.694249 18283 solver.cpp:244]     Train net output #1: loss = 0.241136 (* 1 = 0.241136 loss)
I0813 10:13:48.694278 18283 sgd_solver.cpp:106] Iteration 7250, lr = 0.00664367
I0813 10:14:30.021818 18283 solver.cpp:337] Iteration 7300, Testing net (#0)
I0813 10:14:34.100555 18283 solver.cpp:404]     Test net output #0: accuracy = 0.91
I0813 10:14:34.100627 18283 solver.cpp:404]     Test net output #1: loss = 0.68786 (* 1 = 0.68786 loss)
I0813 10:14:34.913507 18283 solver.cpp:228] Iteration 7300, loss = 0.200086
I0813 10:14:34.913559 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 10:14:34.913570 18283 solver.cpp:244]     Train net output #1: loss = 0.200086 (* 1 = 0.200086 loss)
I0813 10:14:34.913589 18283 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0813 10:15:16.058435 18283 solver.cpp:228] Iteration 7350, loss = 0.180102
I0813 10:15:16.058609 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:15:16.058624 18283 solver.cpp:244]     Train net output #1: loss = 0.180102 (* 1 = 0.180102 loss)
I0813 10:15:16.058636 18283 sgd_solver.cpp:106] Iteration 7350, lr = 0.00661493
I0813 10:15:56.408857 18283 solver.cpp:337] Iteration 7400, Testing net (#0)
I0813 10:16:00.462939 18283 solver.cpp:404]     Test net output #0: accuracy = 0.894
I0813 10:16:00.463003 18283 solver.cpp:404]     Test net output #1: loss = 0.68788 (* 1 = 0.68788 loss)
I0813 10:16:01.274767 18283 solver.cpp:228] Iteration 7400, loss = 0.239945
I0813 10:16:01.274821 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 10:16:01.274832 18283 solver.cpp:244]     Train net output #1: loss = 0.239945 (* 1 = 0.239945 loss)
I0813 10:16:01.274850 18283 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0813 10:16:42.943511 18283 solver.cpp:228] Iteration 7450, loss = 0.240093
I0813 10:16:42.943732 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:16:42.943784 18283 solver.cpp:244]     Train net output #1: loss = 0.240093 (* 1 = 0.240093 loss)
I0813 10:16:42.943807 18283 sgd_solver.cpp:106] Iteration 7450, lr = 0.00658648
I0813 10:17:24.067299 18283 solver.cpp:337] Iteration 7500, Testing net (#0)
I0813 10:17:28.237998 18283 solver.cpp:404]     Test net output #0: accuracy = 0.873
I0813 10:17:28.238064 18283 solver.cpp:404]     Test net output #1: loss = 0.687927 (* 1 = 0.687927 loss)
I0813 10:17:29.049563 18283 solver.cpp:228] Iteration 7500, loss = 0.200052
I0813 10:17:29.049623 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 10:17:29.049635 18283 solver.cpp:244]     Train net output #1: loss = 0.200052 (* 1 = 0.200052 loss)
I0813 10:17:29.049651 18283 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0813 10:18:10.206676 18283 solver.cpp:228] Iteration 7550, loss = 0.179973
I0813 10:18:10.206914 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:18:10.206964 18283 solver.cpp:244]     Train net output #1: loss = 0.179973 (* 1 = 0.179973 loss)
I0813 10:18:10.206981 18283 sgd_solver.cpp:106] Iteration 7550, lr = 0.00655831
I0813 10:18:50.774148 18283 solver.cpp:337] Iteration 7600, Testing net (#0)
I0813 10:18:55.189445 18283 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 10:18:55.189507 18283 solver.cpp:404]     Test net output #1: loss = 0.689096 (* 1 = 0.689096 loss)
I0813 10:18:56.003851 18283 solver.cpp:228] Iteration 7600, loss = 0.240478
I0813 10:18:56.003896 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 10:18:56.003908 18283 solver.cpp:244]     Train net output #1: loss = 0.240478 (* 1 = 0.240478 loss)
I0813 10:18:56.003924 18283 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0813 10:19:38.278245 18283 solver.cpp:228] Iteration 7650, loss = 0.240167
I0813 10:19:38.278502 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:19:38.278559 18283 solver.cpp:244]     Train net output #1: loss = 0.240167 (* 1 = 0.240167 loss)
I0813 10:19:38.278585 18283 sgd_solver.cpp:106] Iteration 7650, lr = 0.00653043
I0813 10:20:18.690551 18283 solver.cpp:337] Iteration 7700, Testing net (#0)
I0813 10:20:22.745615 18283 solver.cpp:404]     Test net output #0: accuracy = 0.848
I0813 10:20:22.745682 18283 solver.cpp:404]     Test net output #1: loss = 0.688008 (* 1 = 0.688008 loss)
I0813 10:20:23.559026 18283 solver.cpp:228] Iteration 7700, loss = 0.200013
I0813 10:20:23.559082 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 10:20:23.559093 18283 solver.cpp:244]     Train net output #1: loss = 0.200013 (* 1 = 0.200013 loss)
I0813 10:20:23.559105 18283 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0813 10:21:04.695705 18283 solver.cpp:228] Iteration 7750, loss = 0.180156
I0813 10:21:04.695930 18283 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0813 10:21:04.695983 18283 solver.cpp:244]     Train net output #1: loss = 0.180156 (* 1 = 0.180156 loss)
I0813 10:21:04.696014 18283 sgd_solver.cpp:106] Iteration 7750, lr = 0.00650281
I0813 10:21:45.384361 18283 solver.cpp:337] Iteration 7800, Testing net (#0)
I0813 10:21:49.439661 18283 solver.cpp:404]     Test net output #0: accuracy = 0.976
I0813 10:21:49.439733 18283 solver.cpp:404]     Test net output #1: loss = 0.687686 (* 1 = 0.687686 loss)
I0813 10:21:50.250493 18283 solver.cpp:228] Iteration 7800, loss = 0.239935
I0813 10:21:50.250543 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:21:50.250555 18283 solver.cpp:244]     Train net output #1: loss = 0.239935 (* 1 = 0.239935 loss)
I0813 10:21:50.250572 18283 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0813 10:22:31.385325 18283 solver.cpp:228] Iteration 7850, loss = 0.239952
I0813 10:22:31.385499 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:22:31.385512 18283 solver.cpp:244]     Train net output #1: loss = 0.239952 (* 1 = 0.239952 loss)
I0813 10:22:31.385526 18283 sgd_solver.cpp:106] Iteration 7850, lr = 0.00647547
I0813 10:23:11.700567 18283 solver.cpp:337] Iteration 7900, Testing net (#0)
I0813 10:23:15.757648 18283 solver.cpp:404]     Test net output #0: accuracy = 0.902
I0813 10:23:15.757719 18283 solver.cpp:404]     Test net output #1: loss = 0.687855 (* 1 = 0.687855 loss)
I0813 10:23:16.570735 18283 solver.cpp:228] Iteration 7900, loss = 0.200042
I0813 10:23:16.570803 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 10:23:16.570816 18283 solver.cpp:244]     Train net output #1: loss = 0.200042 (* 1 = 0.200042 loss)
I0813 10:23:16.570828 18283 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0813 10:23:57.719290 18283 solver.cpp:228] Iteration 7950, loss = 0.179997
I0813 10:23:57.719502 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:23:57.719558 18283 solver.cpp:244]     Train net output #1: loss = 0.179997 (* 1 = 0.179997 loss)
I0813 10:23:57.719584 18283 sgd_solver.cpp:106] Iteration 7950, lr = 0.0064484
I0813 10:24:38.562145 18283 solver.cpp:337] Iteration 8000, Testing net (#0)
I0813 10:24:42.744946 18283 solver.cpp:404]     Test net output #0: accuracy = 0.686
I0813 10:24:42.745010 18283 solver.cpp:404]     Test net output #1: loss = 0.688699 (* 1 = 0.688699 loss)
I0813 10:24:43.559890 18283 solver.cpp:228] Iteration 8000, loss = 0.240242
I0813 10:24:43.559960 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 10:24:43.559972 18283 solver.cpp:244]     Train net output #1: loss = 0.240242 (* 1 = 0.240242 loss)
I0813 10:24:43.559986 18283 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0813 10:25:25.084413 18283 solver.cpp:228] Iteration 8050, loss = 0.240029
I0813 10:25:25.084709 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:25:25.084772 18283 solver.cpp:244]     Train net output #1: loss = 0.240029 (* 1 = 0.240029 loss)
I0813 10:25:25.084806 18283 sgd_solver.cpp:106] Iteration 8050, lr = 0.00642158
I0813 10:26:05.602982 18283 solver.cpp:337] Iteration 8100, Testing net (#0)
I0813 10:26:09.659865 18283 solver.cpp:404]     Test net output #0: accuracy = 0.945
I0813 10:26:09.659934 18283 solver.cpp:404]     Test net output #1: loss = 0.68771 (* 1 = 0.68771 loss)
I0813 10:26:10.472179 18283 solver.cpp:228] Iteration 8100, loss = 0.200057
I0813 10:26:10.472245 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:26:10.472256 18283 solver.cpp:244]     Train net output #1: loss = 0.200058 (* 1 = 0.200058 loss)
I0813 10:26:10.472271 18283 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0813 10:26:51.550842 18283 solver.cpp:228] Iteration 8150, loss = 0.180021
I0813 10:26:51.551087 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 10:26:51.551147 18283 solver.cpp:244]     Train net output #1: loss = 0.180021 (* 1 = 0.180021 loss)
I0813 10:26:51.551173 18283 sgd_solver.cpp:106] Iteration 8150, lr = 0.00639503
I0813 10:27:32.081681 18283 solver.cpp:337] Iteration 8200, Testing net (#0)
I0813 10:27:36.139737 18283 solver.cpp:404]     Test net output #0: accuracy = 0.974
I0813 10:27:36.139801 18283 solver.cpp:404]     Test net output #1: loss = 0.687626 (* 1 = 0.687626 loss)
I0813 10:27:36.951181 18283 solver.cpp:228] Iteration 8200, loss = 0.239907
I0813 10:27:36.951231 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:27:36.951241 18283 solver.cpp:244]     Train net output #1: loss = 0.239907 (* 1 = 0.239907 loss)
I0813 10:27:36.951253 18283 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0813 10:28:18.077836 18283 solver.cpp:228] Iteration 8250, loss = 0.239979
I0813 10:28:18.078039 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:28:18.078130 18283 solver.cpp:244]     Train net output #1: loss = 0.239979 (* 1 = 0.239979 loss)
I0813 10:28:18.078169 18283 sgd_solver.cpp:106] Iteration 8250, lr = 0.00636873
I0813 10:28:58.489047 18283 solver.cpp:337] Iteration 8300, Testing net (#0)
I0813 10:29:02.544205 18283 solver.cpp:404]     Test net output #0: accuracy = 0.914
I0813 10:29:02.544272 18283 solver.cpp:404]     Test net output #1: loss = 0.687752 (* 1 = 0.687752 loss)
I0813 10:29:03.356268 18283 solver.cpp:228] Iteration 8300, loss = 0.200026
I0813 10:29:03.356323 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 10:29:03.356334 18283 solver.cpp:244]     Train net output #1: loss = 0.200026 (* 1 = 0.200026 loss)
I0813 10:29:03.356351 18283 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0813 10:29:44.472870 18283 solver.cpp:228] Iteration 8350, loss = 0.179966
I0813 10:29:44.473050 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:29:44.473064 18283 solver.cpp:244]     Train net output #1: loss = 0.179966 (* 1 = 0.179966 loss)
I0813 10:29:44.473076 18283 sgd_solver.cpp:106] Iteration 8350, lr = 0.00634268
I0813 10:30:24.793629 18283 solver.cpp:337] Iteration 8400, Testing net (#0)
I0813 10:30:28.852808 18283 solver.cpp:404]     Test net output #0: accuracy = 0.935
I0813 10:30:28.852877 18283 solver.cpp:404]     Test net output #1: loss = 0.687674 (* 1 = 0.687674 loss)
I0813 10:30:29.665189 18283 solver.cpp:228] Iteration 8400, loss = 0.239917
I0813 10:30:29.665241 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:30:29.665253 18283 solver.cpp:244]     Train net output #1: loss = 0.239917 (* 1 = 0.239917 loss)
I0813 10:30:29.665271 18283 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0813 10:31:10.796584 18283 solver.cpp:228] Iteration 8450, loss = 0.239943
I0813 10:31:10.796733 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:31:10.796747 18283 solver.cpp:244]     Train net output #1: loss = 0.239943 (* 1 = 0.239943 loss)
I0813 10:31:10.796759 18283 sgd_solver.cpp:106] Iteration 8450, lr = 0.00631688
I0813 10:31:51.129207 18283 solver.cpp:337] Iteration 8500, Testing net (#0)
I0813 10:31:55.179466 18283 solver.cpp:404]     Test net output #0: accuracy = 0.94
I0813 10:31:55.179529 18283 solver.cpp:404]     Test net output #1: loss = 0.687615 (* 1 = 0.687615 loss)
I0813 10:31:55.991401 18283 solver.cpp:228] Iteration 8500, loss = 0.199888
I0813 10:31:55.991453 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:31:55.991464 18283 solver.cpp:244]     Train net output #1: loss = 0.199888 (* 1 = 0.199888 loss)
I0813 10:31:55.991482 18283 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0813 10:32:37.135872 18283 solver.cpp:228] Iteration 8550, loss = 0.179912
I0813 10:32:37.136044 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:32:37.136059 18283 solver.cpp:244]     Train net output #1: loss = 0.179911 (* 1 = 0.179911 loss)
I0813 10:32:37.136070 18283 sgd_solver.cpp:106] Iteration 8550, lr = 0.00629132
I0813 10:33:17.497408 18283 solver.cpp:337] Iteration 8600, Testing net (#0)
I0813 10:33:21.548796 18283 solver.cpp:404]     Test net output #0: accuracy = 0.883
I0813 10:33:21.548861 18283 solver.cpp:404]     Test net output #1: loss = 0.687878 (* 1 = 0.687878 loss)
I0813 10:33:22.360669 18283 solver.cpp:228] Iteration 8600, loss = 0.240009
I0813 10:33:22.360723 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 10:33:22.360733 18283 solver.cpp:244]     Train net output #1: loss = 0.240009 (* 1 = 0.240009 loss)
I0813 10:33:22.360745 18283 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0813 10:34:03.522245 18283 solver.cpp:228] Iteration 8650, loss = 0.239917
I0813 10:34:03.522408 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:34:03.522423 18283 solver.cpp:244]     Train net output #1: loss = 0.239917 (* 1 = 0.239917 loss)
I0813 10:34:03.522435 18283 sgd_solver.cpp:106] Iteration 8650, lr = 0.00626601
I0813 10:34:44.364171 18283 solver.cpp:337] Iteration 8700, Testing net (#0)
I0813 10:34:48.458084 18283 solver.cpp:404]     Test net output #0: accuracy = 0.813
I0813 10:34:48.458158 18283 solver.cpp:404]     Test net output #1: loss = 0.688073 (* 1 = 0.688073 loss)
I0813 10:34:49.271621 18283 solver.cpp:228] Iteration 8700, loss = 0.200042
I0813 10:34:49.271677 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 10:34:49.271689 18283 solver.cpp:244]     Train net output #1: loss = 0.200042 (* 1 = 0.200042 loss)
I0813 10:34:49.271704 18283 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0813 10:35:30.448019 18283 solver.cpp:228] Iteration 8750, loss = 0.179955
I0813 10:35:30.448248 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:35:30.448302 18283 solver.cpp:244]     Train net output #1: loss = 0.179954 (* 1 = 0.179954 loss)
I0813 10:35:30.448324 18283 sgd_solver.cpp:106] Iteration 8750, lr = 0.00624093
I0813 10:36:11.246456 18283 solver.cpp:337] Iteration 8800, Testing net (#0)
I0813 10:36:15.710119 18283 solver.cpp:404]     Test net output #0: accuracy = 0.989
I0813 10:36:15.710189 18283 solver.cpp:404]     Test net output #1: loss = 0.687558 (* 1 = 0.687558 loss)
I0813 10:36:16.523563 18283 solver.cpp:228] Iteration 8800, loss = 0.240008
I0813 10:36:16.523627 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:36:16.523639 18283 solver.cpp:244]     Train net output #1: loss = 0.240008 (* 1 = 0.240008 loss)
I0813 10:36:16.523656 18283 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0813 10:36:58.418949 18283 solver.cpp:228] Iteration 8850, loss = 0.240219
I0813 10:36:58.419174 18283 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 10:36:58.419227 18283 solver.cpp:244]     Train net output #1: loss = 0.240219 (* 1 = 0.240219 loss)
I0813 10:36:58.419260 18283 sgd_solver.cpp:106] Iteration 8850, lr = 0.00621608
I0813 10:37:38.941646 18283 solver.cpp:337] Iteration 8900, Testing net (#0)
I0813 10:37:42.996654 18283 solver.cpp:404]     Test net output #0: accuracy = 0.877
I0813 10:37:42.996716 18283 solver.cpp:404]     Test net output #1: loss = 0.687884 (* 1 = 0.687884 loss)
I0813 10:37:43.810374 18283 solver.cpp:228] Iteration 8900, loss = 0.200013
I0813 10:37:43.810422 18283 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 10:37:43.810434 18283 solver.cpp:244]     Train net output #1: loss = 0.200013 (* 1 = 0.200013 loss)
I0813 10:37:43.810451 18283 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0813 10:38:24.940755 18283 solver.cpp:228] Iteration 8950, loss = 0.180048
I0813 10:38:24.940954 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 10:38:24.940969 18283 solver.cpp:244]     Train net output #1: loss = 0.180048 (* 1 = 0.180048 loss)
I0813 10:38:24.940982 18283 sgd_solver.cpp:106] Iteration 8950, lr = 0.00619146
I0813 10:39:05.284438 18283 solver.cpp:337] Iteration 9000, Testing net (#0)
I0813 10:39:09.591691 18283 solver.cpp:404]     Test net output #0: accuracy = 0.858
I0813 10:39:09.591763 18283 solver.cpp:404]     Test net output #1: loss = 0.687979 (* 1 = 0.687979 loss)
I0813 10:39:10.404827 18283 solver.cpp:228] Iteration 9000, loss = 0.239988
I0813 10:39:10.404888 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 10:39:10.404901 18283 solver.cpp:244]     Train net output #1: loss = 0.239988 (* 1 = 0.239988 loss)
I0813 10:39:10.404917 18283 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0813 10:39:51.558650 18283 solver.cpp:228] Iteration 9050, loss = 0.239735
I0813 10:39:51.558811 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:39:51.558825 18283 solver.cpp:244]     Train net output #1: loss = 0.239735 (* 1 = 0.239735 loss)
I0813 10:39:51.558837 18283 sgd_solver.cpp:106] Iteration 9050, lr = 0.00616707
I0813 10:40:32.394454 18283 solver.cpp:337] Iteration 9100, Testing net (#0)
I0813 10:40:36.446722 18283 solver.cpp:404]     Test net output #0: accuracy = 0.935
I0813 10:40:36.446790 18283 solver.cpp:404]     Test net output #1: loss = 0.687489 (* 1 = 0.687489 loss)
I0813 10:40:37.258719 18283 solver.cpp:228] Iteration 9100, loss = 0.199927
I0813 10:40:37.258774 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 10:40:37.258785 18283 solver.cpp:244]     Train net output #1: loss = 0.199927 (* 1 = 0.199927 loss)
I0813 10:40:37.258805 18283 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0813 10:41:18.406442 18283 solver.cpp:228] Iteration 9150, loss = 0.17999
I0813 10:41:18.406605 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 10:41:18.406618 18283 solver.cpp:244]     Train net output #1: loss = 0.17999 (* 1 = 0.17999 loss)
I0813 10:41:18.406630 18283 sgd_solver.cpp:106] Iteration 9150, lr = 0.0061429
I0813 10:41:58.776331 18283 solver.cpp:337] Iteration 9200, Testing net (#0)
I0813 10:42:02.902365 18283 solver.cpp:404]     Test net output #0: accuracy = 0.894
I0813 10:42:02.902437 18283 solver.cpp:404]     Test net output #1: loss = 0.687728 (* 1 = 0.687728 loss)
I0813 10:42:03.715780 18283 solver.cpp:228] Iteration 9200, loss = 0.239908
I0813 10:42:03.715838 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:42:03.715849 18283 solver.cpp:244]     Train net output #1: loss = 0.239908 (* 1 = 0.239908 loss)
I0813 10:42:03.715860 18283 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0813 10:42:44.873951 18283 solver.cpp:228] Iteration 9250, loss = 0.239998
I0813 10:42:44.874162 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:42:44.874223 18283 solver.cpp:244]     Train net output #1: loss = 0.239998 (* 1 = 0.239998 loss)
I0813 10:42:44.874245 18283 sgd_solver.cpp:106] Iteration 9250, lr = 0.00611895
I0813 10:43:25.368078 18283 solver.cpp:337] Iteration 9300, Testing net (#0)
I0813 10:43:29.418045 18283 solver.cpp:404]     Test net output #0: accuracy = 0.929
I0813 10:43:29.418128 18283 solver.cpp:404]     Test net output #1: loss = 0.687497 (* 1 = 0.687497 loss)
I0813 10:43:30.229126 18283 solver.cpp:228] Iteration 9300, loss = 0.199918
I0813 10:43:30.229173 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 10:43:30.229184 18283 solver.cpp:244]     Train net output #1: loss = 0.199918 (* 1 = 0.199918 loss)
I0813 10:43:30.229197 18283 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0813 10:44:11.370097 18283 solver.cpp:228] Iteration 9350, loss = 0.18001
I0813 10:44:11.370360 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 10:44:11.370409 18283 solver.cpp:244]     Train net output #1: loss = 0.18001 (* 1 = 0.18001 loss)
I0813 10:44:11.370434 18283 sgd_solver.cpp:106] Iteration 9350, lr = 0.00609522
I0813 10:44:51.875442 18283 solver.cpp:337] Iteration 9400, Testing net (#0)
I0813 10:44:56.243468 18283 solver.cpp:404]     Test net output #0: accuracy = 0.994
I0813 10:44:56.243536 18283 solver.cpp:404]     Test net output #1: loss = 0.687635 (* 1 = 0.687635 loss)
I0813 10:44:57.054991 18283 solver.cpp:228] Iteration 9400, loss = 0.240582
I0813 10:44:57.055042 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:44:57.055053 18283 solver.cpp:244]     Train net output #1: loss = 0.240582 (* 1 = 0.240582 loss)
I0813 10:44:57.055070 18283 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0813 10:45:38.234477 18283 solver.cpp:228] Iteration 9450, loss = 0.239936
I0813 10:45:38.234644 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 10:45:38.234659 18283 solver.cpp:244]     Train net output #1: loss = 0.239936 (* 1 = 0.239936 loss)
I0813 10:45:38.234673 18283 sgd_solver.cpp:106] Iteration 9450, lr = 0.0060717
I0813 10:46:18.568914 18283 solver.cpp:337] Iteration 9500, Testing net (#0)
I0813 10:46:22.624514 18283 solver.cpp:404]     Test net output #0: accuracy = 0.901
I0813 10:46:22.624578 18283 solver.cpp:404]     Test net output #1: loss = 0.687596 (* 1 = 0.687596 loss)
I0813 10:46:23.436516 18283 solver.cpp:228] Iteration 9500, loss = 0.199982
I0813 10:46:23.436565 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:46:23.436578 18283 solver.cpp:244]     Train net output #1: loss = 0.199982 (* 1 = 0.199982 loss)
I0813 10:46:23.436594 18283 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0813 10:47:04.579768 18283 solver.cpp:228] Iteration 9550, loss = 0.180006
I0813 10:47:04.579941 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:47:04.579957 18283 solver.cpp:244]     Train net output #1: loss = 0.180006 (* 1 = 0.180006 loss)
I0813 10:47:04.579969 18283 sgd_solver.cpp:106] Iteration 9550, lr = 0.00604839
I0813 10:47:44.917625 18283 solver.cpp:337] Iteration 9600, Testing net (#0)
I0813 10:47:49.027199 18283 solver.cpp:404]     Test net output #0: accuracy = 0.91
I0813 10:47:49.027271 18283 solver.cpp:404]     Test net output #1: loss = 0.687486 (* 1 = 0.687486 loss)
I0813 10:47:49.839038 18283 solver.cpp:228] Iteration 9600, loss = 0.239686
I0813 10:47:49.839100 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:47:49.839112 18283 solver.cpp:244]     Train net output #1: loss = 0.239686 (* 1 = 0.239686 loss)
I0813 10:47:49.839126 18283 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0813 10:48:30.975164 18283 solver.cpp:228] Iteration 9650, loss = 0.239817
I0813 10:48:30.975329 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:48:30.975342 18283 solver.cpp:244]     Train net output #1: loss = 0.239817 (* 1 = 0.239817 loss)
I0813 10:48:30.975353 18283 sgd_solver.cpp:106] Iteration 9650, lr = 0.00602529
I0813 10:49:11.292331 18283 solver.cpp:337] Iteration 9700, Testing net (#0)
I0813 10:49:15.352800 18283 solver.cpp:404]     Test net output #0: accuracy = 0.88
I0813 10:49:15.352866 18283 solver.cpp:404]     Test net output #1: loss = 0.68769 (* 1 = 0.68769 loss)
I0813 10:49:16.164510 18283 solver.cpp:228] Iteration 9700, loss = 0.199953
I0813 10:49:16.164564 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 10:49:16.164575 18283 solver.cpp:244]     Train net output #1: loss = 0.199953 (* 1 = 0.199953 loss)
I0813 10:49:16.164593 18283 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0813 10:49:57.304754 18283 solver.cpp:228] Iteration 9750, loss = 0.179948
I0813 10:49:57.304900 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:49:57.304915 18283 solver.cpp:244]     Train net output #1: loss = 0.179948 (* 1 = 0.179948 loss)
I0813 10:49:57.304929 18283 sgd_solver.cpp:106] Iteration 9750, lr = 0.0060024
I0813 10:50:37.627629 18283 solver.cpp:337] Iteration 9800, Testing net (#0)
I0813 10:50:41.678591 18283 solver.cpp:404]     Test net output #0: accuracy = 0.916
I0813 10:50:41.678659 18283 solver.cpp:404]     Test net output #1: loss = 0.687397 (* 1 = 0.687397 loss)
I0813 10:50:42.491137 18283 solver.cpp:228] Iteration 9800, loss = 0.239868
I0813 10:50:42.491194 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:50:42.491206 18283 solver.cpp:244]     Train net output #1: loss = 0.239868 (* 1 = 0.239868 loss)
I0813 10:50:42.491219 18283 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0813 10:51:23.638519 18283 solver.cpp:228] Iteration 9850, loss = 0.240622
I0813 10:51:23.638679 18283 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0813 10:51:23.638692 18283 solver.cpp:244]     Train net output #1: loss = 0.240622 (* 1 = 0.240622 loss)
I0813 10:51:23.638705 18283 sgd_solver.cpp:106] Iteration 9850, lr = 0.0059797
I0813 10:52:03.994328 18283 solver.cpp:337] Iteration 9900, Testing net (#0)
I0813 10:52:08.047816 18283 solver.cpp:404]     Test net output #0: accuracy = 0.911
I0813 10:52:08.047883 18283 solver.cpp:404]     Test net output #1: loss = 0.687486 (* 1 = 0.687486 loss)
I0813 10:52:08.859244 18283 solver.cpp:228] Iteration 9900, loss = 0.199802
I0813 10:52:08.859294 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:52:08.859305 18283 solver.cpp:244]     Train net output #1: loss = 0.199802 (* 1 = 0.199802 loss)
I0813 10:52:08.859323 18283 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0813 10:52:50.031494 18283 solver.cpp:228] Iteration 9950, loss = 0.179901
I0813 10:52:50.031643 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:52:50.031656 18283 solver.cpp:244]     Train net output #1: loss = 0.179901 (* 1 = 0.179901 loss)
I0813 10:52:50.031667 18283 sgd_solver.cpp:106] Iteration 9950, lr = 0.00595721
I0813 10:53:30.386937 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_10000.caffemodel
I0813 10:53:30.721909 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_10000.solverstate
I0813 10:53:30.735611 18283 solver.cpp:337] Iteration 10000, Testing net (#0)
I0813 10:53:34.796658 18283 solver.cpp:404]     Test net output #0: accuracy = 0.942
I0813 10:53:34.796725 18283 solver.cpp:404]     Test net output #1: loss = 0.687136 (* 1 = 0.687136 loss)
I0813 10:53:35.610009 18283 solver.cpp:228] Iteration 10000, loss = 0.239706
I0813 10:53:35.610061 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:53:35.610074 18283 solver.cpp:244]     Train net output #1: loss = 0.239706 (* 1 = 0.239706 loss)
I0813 10:53:35.610086 18283 sgd_solver.cpp:106] Iteration 10000, lr = 0.00594604
I0813 10:54:17.199167 18283 solver.cpp:228] Iteration 10050, loss = 0.239901
I0813 10:54:17.199405 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 10:54:17.199453 18283 solver.cpp:244]     Train net output #1: loss = 0.239901 (* 1 = 0.239901 loss)
I0813 10:54:17.199473 18283 sgd_solver.cpp:106] Iteration 10050, lr = 0.00593491
I0813 10:54:57.929915 18283 solver.cpp:337] Iteration 10100, Testing net (#0)
I0813 10:55:01.978333 18283 solver.cpp:404]     Test net output #0: accuracy = 0.904
I0813 10:55:01.978399 18283 solver.cpp:404]     Test net output #1: loss = 0.687438 (* 1 = 0.687438 loss)
I0813 10:55:02.791286 18283 solver.cpp:228] Iteration 10100, loss = 0.199819
I0813 10:55:02.791340 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:55:02.791352 18283 solver.cpp:244]     Train net output #1: loss = 0.199819 (* 1 = 0.199819 loss)
I0813 10:55:02.791369 18283 sgd_solver.cpp:106] Iteration 10100, lr = 0.00592384
I0813 10:55:43.914022 18283 solver.cpp:228] Iteration 10150, loss = 0.179923
I0813 10:55:43.914263 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 10:55:43.914311 18283 solver.cpp:244]     Train net output #1: loss = 0.179923 (* 1 = 0.179923 loss)
I0813 10:55:43.914331 18283 sgd_solver.cpp:106] Iteration 10150, lr = 0.00591281
I0813 10:56:24.921097 18283 solver.cpp:337] Iteration 10200, Testing net (#0)
I0813 10:56:28.968554 18283 solver.cpp:404]     Test net output #0: accuracy = 0.978
I0813 10:56:28.968617 18283 solver.cpp:404]     Test net output #1: loss = 0.687058 (* 1 = 0.687058 loss)
I0813 10:56:29.781445 18283 solver.cpp:228] Iteration 10200, loss = 0.239851
I0813 10:56:29.781502 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:56:29.781513 18283 solver.cpp:244]     Train net output #1: loss = 0.239851 (* 1 = 0.239851 loss)
I0813 10:56:29.781533 18283 sgd_solver.cpp:106] Iteration 10200, lr = 0.00590183
I0813 10:57:10.918437 18283 solver.cpp:228] Iteration 10250, loss = 0.240324
I0813 10:57:10.918668 18283 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 10:57:10.918720 18283 solver.cpp:244]     Train net output #1: loss = 0.240324 (* 1 = 0.240324 loss)
I0813 10:57:10.918740 18283 sgd_solver.cpp:106] Iteration 10250, lr = 0.00589089
I0813 10:57:52.399926 18283 solver.cpp:337] Iteration 10300, Testing net (#0)
I0813 10:57:56.454273 18283 solver.cpp:404]     Test net output #0: accuracy = 0.894
I0813 10:57:56.454342 18283 solver.cpp:404]     Test net output #1: loss = 0.687463 (* 1 = 0.687463 loss)
I0813 10:57:57.266963 18283 solver.cpp:228] Iteration 10300, loss = 0.199734
I0813 10:57:57.267021 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 10:57:57.267032 18283 solver.cpp:244]     Train net output #1: loss = 0.199733 (* 1 = 0.199733 loss)
I0813 10:57:57.267050 18283 sgd_solver.cpp:106] Iteration 10300, lr = 0.00588001
I0813 10:58:39.077801 18283 solver.cpp:228] Iteration 10350, loss = 0.179893
I0813 10:58:39.077965 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 10:58:39.077980 18283 solver.cpp:244]     Train net output #1: loss = 0.179893 (* 1 = 0.179893 loss)
I0813 10:58:39.077991 18283 sgd_solver.cpp:106] Iteration 10350, lr = 0.00586917
I0813 10:59:19.382021 18283 solver.cpp:337] Iteration 10400, Testing net (#0)
I0813 10:59:23.433409 18283 solver.cpp:404]     Test net output #0: accuracy = 0.941
I0813 10:59:23.433475 18283 solver.cpp:404]     Test net output #1: loss = 0.686961 (* 1 = 0.686961 loss)
I0813 10:59:24.245471 18283 solver.cpp:228] Iteration 10400, loss = 0.239613
I0813 10:59:24.245525 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 10:59:24.245537 18283 solver.cpp:244]     Train net output #1: loss = 0.239613 (* 1 = 0.239613 loss)
I0813 10:59:24.245555 18283 sgd_solver.cpp:106] Iteration 10400, lr = 0.00585838
I0813 11:00:05.372256 18283 solver.cpp:228] Iteration 10450, loss = 0.240132
I0813 11:00:05.372411 18283 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0813 11:00:05.372426 18283 solver.cpp:244]     Train net output #1: loss = 0.240132 (* 1 = 0.240132 loss)
I0813 11:00:05.372438 18283 sgd_solver.cpp:106] Iteration 10450, lr = 0.00584763
I0813 11:00:45.722530 18283 solver.cpp:337] Iteration 10500, Testing net (#0)
I0813 11:00:50.110276 18283 solver.cpp:404]     Test net output #0: accuracy = 0.824
I0813 11:00:50.110350 18283 solver.cpp:404]     Test net output #1: loss = 0.688113 (* 1 = 0.688113 loss)
I0813 11:00:50.924073 18283 solver.cpp:228] Iteration 10500, loss = 0.199723
I0813 11:00:50.924136 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 11:00:50.924150 18283 solver.cpp:244]     Train net output #1: loss = 0.199723 (* 1 = 0.199723 loss)
I0813 11:00:50.924165 18283 sgd_solver.cpp:106] Iteration 10500, lr = 0.00583693
I0813 11:01:32.369871 18283 solver.cpp:228] Iteration 10550, loss = 0.179858
I0813 11:01:32.370046 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:01:32.370060 18283 solver.cpp:244]     Train net output #1: loss = 0.179858 (* 1 = 0.179858 loss)
I0813 11:01:32.370072 18283 sgd_solver.cpp:106] Iteration 10550, lr = 0.00582628
I0813 11:02:12.942997 18283 solver.cpp:337] Iteration 10600, Testing net (#0)
I0813 11:02:17.003845 18283 solver.cpp:404]     Test net output #0: accuracy = 0.963
I0813 11:02:17.003914 18283 solver.cpp:404]     Test net output #1: loss = 0.686785 (* 1 = 0.686785 loss)
I0813 11:02:17.816701 18283 solver.cpp:228] Iteration 10600, loss = 0.239778
I0813 11:02:17.816759 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:02:17.816771 18283 solver.cpp:244]     Train net output #1: loss = 0.239778 (* 1 = 0.239778 loss)
I0813 11:02:17.816789 18283 sgd_solver.cpp:106] Iteration 10600, lr = 0.00581567
I0813 11:02:58.981744 18283 solver.cpp:228] Iteration 10650, loss = 0.239697
I0813 11:02:58.981915 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 11:02:58.981928 18283 solver.cpp:244]     Train net output #1: loss = 0.239697 (* 1 = 0.239697 loss)
I0813 11:02:58.981942 18283 sgd_solver.cpp:106] Iteration 10650, lr = 0.0058051
I0813 11:03:39.329825 18283 solver.cpp:337] Iteration 10700, Testing net (#0)
I0813 11:03:43.392971 18283 solver.cpp:404]     Test net output #0: accuracy = 0.934
I0813 11:03:43.393043 18283 solver.cpp:404]     Test net output #1: loss = 0.686824 (* 1 = 0.686824 loss)
I0813 11:03:44.206693 18283 solver.cpp:228] Iteration 10700, loss = 0.199682
I0813 11:03:44.206760 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:03:44.206774 18283 solver.cpp:244]     Train net output #1: loss = 0.199682 (* 1 = 0.199682 loss)
I0813 11:03:44.206786 18283 sgd_solver.cpp:106] Iteration 10700, lr = 0.00579458
I0813 11:04:25.922817 18283 solver.cpp:228] Iteration 10750, loss = 0.179982
I0813 11:04:25.922973 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 11:04:25.922987 18283 solver.cpp:244]     Train net output #1: loss = 0.179982 (* 1 = 0.179982 loss)
I0813 11:04:25.922999 18283 sgd_solver.cpp:106] Iteration 10750, lr = 0.00578411
I0813 11:05:06.756906 18283 solver.cpp:337] Iteration 10800, Testing net (#0)
I0813 11:05:10.820035 18283 solver.cpp:404]     Test net output #0: accuracy = 0.957
I0813 11:05:10.820099 18283 solver.cpp:404]     Test net output #1: loss = 0.686503 (* 1 = 0.686503 loss)
I0813 11:05:11.634263 18283 solver.cpp:228] Iteration 10800, loss = 0.239667
I0813 11:05:11.634330 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:05:11.634341 18283 solver.cpp:244]     Train net output #1: loss = 0.239667 (* 1 = 0.239667 loss)
I0813 11:05:11.634356 18283 sgd_solver.cpp:106] Iteration 10800, lr = 0.00577368
I0813 11:05:52.801012 18283 solver.cpp:228] Iteration 10850, loss = 0.239737
I0813 11:05:52.801167 18283 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0813 11:05:52.801179 18283 solver.cpp:244]     Train net output #1: loss = 0.239737 (* 1 = 0.239737 loss)
I0813 11:05:52.801192 18283 sgd_solver.cpp:106] Iteration 10850, lr = 0.00576329
I0813 11:06:33.905323 18283 solver.cpp:337] Iteration 10900, Testing net (#0)
I0813 11:06:37.956611 18283 solver.cpp:404]     Test net output #0: accuracy = 0.909
I0813 11:06:37.956679 18283 solver.cpp:404]     Test net output #1: loss = 0.686917 (* 1 = 0.686917 loss)
I0813 11:06:38.770601 18283 solver.cpp:228] Iteration 10900, loss = 0.199432
I0813 11:06:38.770664 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:06:38.770676 18283 solver.cpp:244]     Train net output #1: loss = 0.199432 (* 1 = 0.199432 loss)
I0813 11:06:38.770689 18283 sgd_solver.cpp:106] Iteration 10900, lr = 0.00575295
I0813 11:07:19.997891 18283 solver.cpp:228] Iteration 10950, loss = 0.179726
I0813 11:07:19.998064 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:07:19.998078 18283 solver.cpp:244]     Train net output #1: loss = 0.179726 (* 1 = 0.179726 loss)
I0813 11:07:19.998090 18283 sgd_solver.cpp:106] Iteration 10950, lr = 0.00574264
I0813 11:08:00.491554 18283 solver.cpp:337] Iteration 11000, Testing net (#0)
I0813 11:08:04.608690 18283 solver.cpp:404]     Test net output #0: accuracy = 0.926
I0813 11:08:04.608758 18283 solver.cpp:404]     Test net output #1: loss = 0.686814 (* 1 = 0.686814 loss)
I0813 11:08:05.420999 18283 solver.cpp:228] Iteration 11000, loss = 0.239422
I0813 11:08:05.421053 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:08:05.421064 18283 solver.cpp:244]     Train net output #1: loss = 0.239422 (* 1 = 0.239422 loss)
I0813 11:08:05.421082 18283 sgd_solver.cpp:106] Iteration 11000, lr = 0.00573239
I0813 11:08:46.550113 18283 solver.cpp:228] Iteration 11050, loss = 0.239484
I0813 11:08:46.550307 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:08:46.550321 18283 solver.cpp:244]     Train net output #1: loss = 0.239484 (* 1 = 0.239484 loss)
I0813 11:08:46.550333 18283 sgd_solver.cpp:106] Iteration 11050, lr = 0.00572217
I0813 11:09:26.887125 18283 solver.cpp:337] Iteration 11100, Testing net (#0)
I0813 11:09:30.938928 18283 solver.cpp:404]     Test net output #0: accuracy = 0.87
I0813 11:09:30.938993 18283 solver.cpp:404]     Test net output #1: loss = 0.687339 (* 1 = 0.687339 loss)
I0813 11:09:31.751056 18283 solver.cpp:228] Iteration 11100, loss = 0.199596
I0813 11:09:31.751111 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:09:31.751123 18283 solver.cpp:244]     Train net output #1: loss = 0.199596 (* 1 = 0.199596 loss)
I0813 11:09:31.751135 18283 sgd_solver.cpp:106] Iteration 11100, lr = 0.005712
I0813 11:10:12.906656 18283 solver.cpp:228] Iteration 11150, loss = 0.180189
I0813 11:10:12.906813 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:10:12.906827 18283 solver.cpp:244]     Train net output #1: loss = 0.180189 (* 1 = 0.180189 loss)
I0813 11:10:12.906839 18283 sgd_solver.cpp:106] Iteration 11150, lr = 0.00570187
I0813 11:10:53.820406 18283 solver.cpp:337] Iteration 11200, Testing net (#0)
I0813 11:10:57.898530 18283 solver.cpp:404]     Test net output #0: accuracy = 0.912
I0813 11:10:57.898600 18283 solver.cpp:404]     Test net output #1: loss = 0.686685 (* 1 = 0.686685 loss)
I0813 11:10:58.712008 18283 solver.cpp:228] Iteration 11200, loss = 0.239264
I0813 11:10:58.712071 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:10:58.712083 18283 solver.cpp:244]     Train net output #1: loss = 0.239264 (* 1 = 0.239264 loss)
I0813 11:10:58.712101 18283 sgd_solver.cpp:106] Iteration 11200, lr = 0.00569178
I0813 11:11:39.874665 18283 solver.cpp:228] Iteration 11250, loss = 0.239218
I0813 11:11:39.874891 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:11:39.874965 18283 solver.cpp:244]     Train net output #1: loss = 0.239218 (* 1 = 0.239218 loss)
I0813 11:11:39.875001 18283 sgd_solver.cpp:106] Iteration 11250, lr = 0.00568173
I0813 11:12:20.862464 18283 solver.cpp:337] Iteration 11300, Testing net (#0)
I0813 11:12:24.910187 18283 solver.cpp:404]     Test net output #0: accuracy = 0.872
I0813 11:12:24.910257 18283 solver.cpp:404]     Test net output #1: loss = 0.687055 (* 1 = 0.687055 loss)
I0813 11:12:25.721688 18283 solver.cpp:228] Iteration 11300, loss = 0.199321
I0813 11:12:25.721743 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:12:25.721755 18283 solver.cpp:244]     Train net output #1: loss = 0.199321 (* 1 = 0.199321 loss)
I0813 11:12:25.721771 18283 sgd_solver.cpp:106] Iteration 11300, lr = 0.00567173
I0813 11:13:06.848570 18283 solver.cpp:228] Iteration 11350, loss = 0.179915
I0813 11:13:06.848742 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:13:06.848755 18283 solver.cpp:244]     Train net output #1: loss = 0.179915 (* 1 = 0.179915 loss)
I0813 11:13:06.848767 18283 sgd_solver.cpp:106] Iteration 11350, lr = 0.00566176
I0813 11:13:48.180240 18283 solver.cpp:337] Iteration 11400, Testing net (#0)
I0813 11:13:52.222990 18283 solver.cpp:404]     Test net output #0: accuracy = 0.879
I0813 11:13:52.223057 18283 solver.cpp:404]     Test net output #1: loss = 0.687014 (* 1 = 0.687014 loss)
I0813 11:13:53.035327 18283 solver.cpp:228] Iteration 11400, loss = 0.239098
I0813 11:13:53.035382 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:13:53.035393 18283 solver.cpp:244]     Train net output #1: loss = 0.239098 (* 1 = 0.239098 loss)
I0813 11:13:53.035413 18283 sgd_solver.cpp:106] Iteration 11400, lr = 0.00565184
I0813 11:14:34.167987 18283 solver.cpp:228] Iteration 11450, loss = 0.238898
I0813 11:14:34.168190 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:14:34.168203 18283 solver.cpp:244]     Train net output #1: loss = 0.238898 (* 1 = 0.238898 loss)
I0813 11:14:34.168215 18283 sgd_solver.cpp:106] Iteration 11450, lr = 0.00564195
I0813 11:15:15.853910 18283 solver.cpp:337] Iteration 11500, Testing net (#0)
I0813 11:15:19.913471 18283 solver.cpp:404]     Test net output #0: accuracy = 0.867
I0813 11:15:19.913539 18283 solver.cpp:404]     Test net output #1: loss = 0.68722 (* 1 = 0.68722 loss)
I0813 11:15:20.727833 18283 solver.cpp:228] Iteration 11500, loss = 0.199509
I0813 11:15:20.727890 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 11:15:20.727902 18283 solver.cpp:244]     Train net output #1: loss = 0.199509 (* 1 = 0.199509 loss)
I0813 11:15:20.727921 18283 sgd_solver.cpp:106] Iteration 11500, lr = 0.00563211
I0813 11:16:01.909632 18283 solver.cpp:228] Iteration 11550, loss = 0.179615
I0813 11:16:01.909787 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:16:01.909801 18283 solver.cpp:244]     Train net output #1: loss = 0.179614 (* 1 = 0.179614 loss)
I0813 11:16:01.909814 18283 sgd_solver.cpp:106] Iteration 11550, lr = 0.00562231
I0813 11:16:42.588311 18283 solver.cpp:337] Iteration 11600, Testing net (#0)
I0813 11:16:46.841389 18283 solver.cpp:404]     Test net output #0: accuracy = 0.85
I0813 11:16:46.841469 18283 solver.cpp:404]     Test net output #1: loss = 0.687654 (* 1 = 0.687654 loss)
I0813 11:16:47.654628 18283 solver.cpp:228] Iteration 11600, loss = 0.239199
I0813 11:16:47.654681 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 11:16:47.654693 18283 solver.cpp:244]     Train net output #1: loss = 0.239199 (* 1 = 0.239199 loss)
I0813 11:16:47.654711 18283 sgd_solver.cpp:106] Iteration 11600, lr = 0.00561254
I0813 11:17:28.872159 18283 solver.cpp:228] Iteration 11650, loss = 0.23875
I0813 11:17:28.872365 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:17:28.872421 18283 solver.cpp:244]     Train net output #1: loss = 0.23875 (* 1 = 0.23875 loss)
I0813 11:17:28.872454 18283 sgd_solver.cpp:106] Iteration 11650, lr = 0.00560282
I0813 11:18:09.178383 18283 solver.cpp:337] Iteration 11700, Testing net (#0)
I0813 11:18:13.235977 18283 solver.cpp:404]     Test net output #0: accuracy = 0.814
I0813 11:18:13.236057 18283 solver.cpp:404]     Test net output #1: loss = 0.687817 (* 1 = 0.687817 loss)
I0813 11:18:14.047634 18283 solver.cpp:228] Iteration 11700, loss = 0.199316
I0813 11:18:14.047698 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:18:14.047708 18283 solver.cpp:244]     Train net output #1: loss = 0.199316 (* 1 = 0.199316 loss)
I0813 11:18:14.047722 18283 sgd_solver.cpp:106] Iteration 11700, lr = 0.00559313
I0813 11:18:55.174244 18283 solver.cpp:228] Iteration 11750, loss = 0.178942
I0813 11:18:55.174409 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:18:55.174423 18283 solver.cpp:244]     Train net output #1: loss = 0.178942 (* 1 = 0.178942 loss)
I0813 11:18:55.174437 18283 sgd_solver.cpp:106] Iteration 11750, lr = 0.00558349
I0813 11:19:35.515987 18283 solver.cpp:337] Iteration 11800, Testing net (#0)
I0813 11:19:39.569067 18283 solver.cpp:404]     Test net output #0: accuracy = 0.827
I0813 11:19:39.569145 18283 solver.cpp:404]     Test net output #1: loss = 0.687939 (* 1 = 0.687939 loss)
I0813 11:19:40.381850 18283 solver.cpp:228] Iteration 11800, loss = 0.237796
I0813 11:19:40.381906 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:19:40.381917 18283 solver.cpp:244]     Train net output #1: loss = 0.237796 (* 1 = 0.237796 loss)
I0813 11:19:40.381932 18283 sgd_solver.cpp:106] Iteration 11800, lr = 0.00557388
I0813 11:20:21.526959 18283 solver.cpp:228] Iteration 11850, loss = 0.23841
I0813 11:20:21.527139 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:20:21.527154 18283 solver.cpp:244]     Train net output #1: loss = 0.23841 (* 1 = 0.23841 loss)
I0813 11:20:21.527165 18283 sgd_solver.cpp:106] Iteration 11850, lr = 0.00556431
I0813 11:21:01.849429 18283 solver.cpp:337] Iteration 11900, Testing net (#0)
I0813 11:21:05.910099 18283 solver.cpp:404]     Test net output #0: accuracy = 0.786
I0813 11:21:05.910173 18283 solver.cpp:404]     Test net output #1: loss = 0.688904 (* 1 = 0.688904 loss)
I0813 11:21:06.722003 18283 solver.cpp:228] Iteration 11900, loss = 0.198923
I0813 11:21:06.722057 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 11:21:06.722069 18283 solver.cpp:244]     Train net output #1: loss = 0.198923 (* 1 = 0.198923 loss)
I0813 11:21:06.722089 18283 sgd_solver.cpp:106] Iteration 11900, lr = 0.00555478
I0813 11:21:47.840590 18283 solver.cpp:228] Iteration 11950, loss = 0.179079
I0813 11:21:47.840801 18283 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0813 11:21:47.840837 18283 solver.cpp:244]     Train net output #1: loss = 0.179079 (* 1 = 0.179079 loss)
I0813 11:21:47.840859 18283 sgd_solver.cpp:106] Iteration 11950, lr = 0.00554529
I0813 11:22:28.377257 18283 solver.cpp:337] Iteration 12000, Testing net (#0)
I0813 11:22:32.437605 18283 solver.cpp:404]     Test net output #0: accuracy = 0.777
I0813 11:22:32.437675 18283 solver.cpp:404]     Test net output #1: loss = 0.690103 (* 1 = 0.690103 loss)
I0813 11:22:33.248694 18283 solver.cpp:228] Iteration 12000, loss = 0.238211
I0813 11:22:33.248746 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:22:33.248757 18283 solver.cpp:244]     Train net output #1: loss = 0.238211 (* 1 = 0.238211 loss)
I0813 11:22:33.248769 18283 sgd_solver.cpp:106] Iteration 12000, lr = 0.00553583
I0813 11:23:14.397645 18283 solver.cpp:228] Iteration 12050, loss = 0.237753
I0813 11:23:14.397795 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:23:14.397809 18283 solver.cpp:244]     Train net output #1: loss = 0.237753 (* 1 = 0.237753 loss)
I0813 11:23:14.397819 18283 sgd_solver.cpp:106] Iteration 12050, lr = 0.00552642
I0813 11:23:54.730211 18283 solver.cpp:337] Iteration 12100, Testing net (#0)
I0813 11:23:58.780011 18283 solver.cpp:404]     Test net output #0: accuracy = 0.78
I0813 11:23:58.780097 18283 solver.cpp:404]     Test net output #1: loss = 0.689793 (* 1 = 0.689793 loss)
I0813 11:23:59.593003 18283 solver.cpp:228] Iteration 12100, loss = 0.197883
I0813 11:23:59.593066 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:23:59.593077 18283 solver.cpp:244]     Train net output #1: loss = 0.197883 (* 1 = 0.197883 loss)
I0813 11:23:59.593091 18283 sgd_solver.cpp:106] Iteration 12100, lr = 0.00551704
I0813 11:24:40.734897 18283 solver.cpp:228] Iteration 12150, loss = 0.178659
I0813 11:24:40.735059 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 11:24:40.735072 18283 solver.cpp:244]     Train net output #1: loss = 0.178659 (* 1 = 0.178659 loss)
I0813 11:24:40.735083 18283 sgd_solver.cpp:106] Iteration 12150, lr = 0.00550769
I0813 11:25:21.085536 18283 solver.cpp:337] Iteration 12200, Testing net (#0)
I0813 11:25:25.139113 18283 solver.cpp:404]     Test net output #0: accuracy = 0.783
I0813 11:25:25.139181 18283 solver.cpp:404]     Test net output #1: loss = 0.690069 (* 1 = 0.690069 loss)
I0813 11:25:25.951436 18283 solver.cpp:228] Iteration 12200, loss = 0.237403
I0813 11:25:25.951484 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:25:25.951495 18283 solver.cpp:244]     Train net output #1: loss = 0.237403 (* 1 = 0.237403 loss)
I0813 11:25:25.951513 18283 sgd_solver.cpp:106] Iteration 12200, lr = 0.00549839
I0813 11:26:07.107131 18283 solver.cpp:228] Iteration 12250, loss = 0.236311
I0813 11:26:07.107341 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:26:07.107393 18283 solver.cpp:244]     Train net output #1: loss = 0.236311 (* 1 = 0.236311 loss)
I0813 11:26:07.107414 18283 sgd_solver.cpp:106] Iteration 12250, lr = 0.00548912
I0813 11:26:48.212780 18283 solver.cpp:337] Iteration 12300, Testing net (#0)
I0813 11:26:52.397958 18283 solver.cpp:404]     Test net output #0: accuracy = 0.796
I0813 11:26:52.398027 18283 solver.cpp:404]     Test net output #1: loss = 0.689206 (* 1 = 0.689206 loss)
I0813 11:26:53.211145 18283 solver.cpp:228] Iteration 12300, loss = 0.197163
I0813 11:26:53.211205 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:26:53.211215 18283 solver.cpp:244]     Train net output #1: loss = 0.197163 (* 1 = 0.197163 loss)
I0813 11:26:53.211230 18283 sgd_solver.cpp:106] Iteration 12300, lr = 0.00547988
I0813 11:27:34.647136 18283 solver.cpp:228] Iteration 12350, loss = 0.176909
I0813 11:27:34.647310 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:27:34.647323 18283 solver.cpp:244]     Train net output #1: loss = 0.176909 (* 1 = 0.176909 loss)
I0813 11:27:34.647336 18283 sgd_solver.cpp:106] Iteration 12350, lr = 0.00547069
I0813 11:28:14.999846 18283 solver.cpp:337] Iteration 12400, Testing net (#0)
I0813 11:28:19.181653 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 11:28:19.181718 18283 solver.cpp:404]     Test net output #1: loss = 0.695348 (* 1 = 0.695348 loss)
I0813 11:28:19.994868 18283 solver.cpp:228] Iteration 12400, loss = 0.236161
I0813 11:28:19.994936 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:28:19.994948 18283 solver.cpp:244]     Train net output #1: loss = 0.236161 (* 1 = 0.236161 loss)
I0813 11:28:19.994962 18283 sgd_solver.cpp:106] Iteration 12400, lr = 0.00546153
I0813 11:29:01.400454 18283 solver.cpp:228] Iteration 12450, loss = 0.236098
I0813 11:29:01.400668 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:29:01.400727 18283 solver.cpp:244]     Train net output #1: loss = 0.236098 (* 1 = 0.236098 loss)
I0813 11:29:01.400758 18283 sgd_solver.cpp:106] Iteration 12450, lr = 0.0054524
I0813 11:29:41.794968 18283 solver.cpp:337] Iteration 12500, Testing net (#0)
I0813 11:29:46.209468 18283 solver.cpp:404]     Test net output #0: accuracy = 0.774
I0813 11:29:46.209537 18283 solver.cpp:404]     Test net output #1: loss = 0.692426 (* 1 = 0.692426 loss)
I0813 11:29:47.035686 18283 solver.cpp:228] Iteration 12500, loss = 0.195261
I0813 11:29:47.035748 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 11:29:47.035760 18283 solver.cpp:244]     Train net output #1: loss = 0.195261 (* 1 = 0.195261 loss)
I0813 11:29:47.035773 18283 sgd_solver.cpp:106] Iteration 12500, lr = 0.00544331
I0813 11:30:28.274834 18283 solver.cpp:228] Iteration 12550, loss = 0.17688
I0813 11:30:28.275039 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:30:28.275097 18283 solver.cpp:244]     Train net output #1: loss = 0.17688 (* 1 = 0.17688 loss)
I0813 11:30:28.275122 18283 sgd_solver.cpp:106] Iteration 12550, lr = 0.00543426
I0813 11:31:09.209389 18283 solver.cpp:337] Iteration 12600, Testing net (#0)
I0813 11:31:13.259305 18283 solver.cpp:404]     Test net output #0: accuracy = 0.801
I0813 11:31:13.259369 18283 solver.cpp:404]     Test net output #1: loss = 0.689835 (* 1 = 0.689835 loss)
I0813 11:31:14.070241 18283 solver.cpp:228] Iteration 12600, loss = 0.231929
I0813 11:31:14.070302 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:31:14.070312 18283 solver.cpp:244]     Train net output #1: loss = 0.231929 (* 1 = 0.231929 loss)
I0813 11:31:14.070324 18283 sgd_solver.cpp:106] Iteration 12600, lr = 0.00542524
I0813 11:31:56.414891 18283 solver.cpp:228] Iteration 12650, loss = 0.23137
I0813 11:31:56.415099 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:31:56.415150 18283 solver.cpp:244]     Train net output #1: loss = 0.23137 (* 1 = 0.23137 loss)
I0813 11:31:56.415171 18283 sgd_solver.cpp:106] Iteration 12650, lr = 0.00541625
I0813 11:32:37.222666 18283 solver.cpp:337] Iteration 12700, Testing net (#0)
I0813 11:32:41.505889 18283 solver.cpp:404]     Test net output #0: accuracy = 0.776
I0813 11:32:41.505966 18283 solver.cpp:404]     Test net output #1: loss = 0.692929 (* 1 = 0.692929 loss)
I0813 11:32:42.318204 18283 solver.cpp:228] Iteration 12700, loss = 0.195036
I0813 11:32:42.318255 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:32:42.318266 18283 solver.cpp:244]     Train net output #1: loss = 0.195036 (* 1 = 0.195036 loss)
I0813 11:32:42.318281 18283 sgd_solver.cpp:106] Iteration 12700, lr = 0.0054073
I0813 11:33:23.464807 18283 solver.cpp:228] Iteration 12750, loss = 0.175084
I0813 11:33:23.465008 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:33:23.465023 18283 solver.cpp:244]     Train net output #1: loss = 0.175084 (* 1 = 0.175084 loss)
I0813 11:33:23.465037 18283 sgd_solver.cpp:106] Iteration 12750, lr = 0.00539839
I0813 11:34:03.814036 18283 solver.cpp:337] Iteration 12800, Testing net (#0)
I0813 11:34:07.873412 18283 solver.cpp:404]     Test net output #0: accuracy = 0.809
I0813 11:34:07.873479 18283 solver.cpp:404]     Test net output #1: loss = 0.692282 (* 1 = 0.692282 loss)
I0813 11:34:08.685739 18283 solver.cpp:228] Iteration 12800, loss = 0.228127
I0813 11:34:08.685797 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:34:08.685809 18283 solver.cpp:244]     Train net output #1: loss = 0.228127 (* 1 = 0.228127 loss)
I0813 11:34:08.685827 18283 sgd_solver.cpp:106] Iteration 12800, lr = 0.0053895
I0813 11:34:49.822824 18283 solver.cpp:228] Iteration 12850, loss = 0.227449
I0813 11:34:49.823048 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:34:49.823096 18283 solver.cpp:244]     Train net output #1: loss = 0.227449 (* 1 = 0.227449 loss)
I0813 11:34:49.823115 18283 sgd_solver.cpp:106] Iteration 12850, lr = 0.00538066
I0813 11:35:30.976018 18283 solver.cpp:337] Iteration 12900, Testing net (#0)
I0813 11:35:35.234884 18283 solver.cpp:404]     Test net output #0: accuracy = 0.829
I0813 11:35:35.234947 18283 solver.cpp:404]     Test net output #1: loss = 0.685515 (* 1 = 0.685515 loss)
I0813 11:35:36.047289 18283 solver.cpp:228] Iteration 12900, loss = 0.190049
I0813 11:35:36.047349 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:35:36.047360 18283 solver.cpp:244]     Train net output #1: loss = 0.190049 (* 1 = 0.190049 loss)
I0813 11:35:36.047376 18283 sgd_solver.cpp:106] Iteration 12900, lr = 0.00537184
I0813 11:36:17.194603 18283 solver.cpp:228] Iteration 12950, loss = 0.172192
I0813 11:36:17.194763 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 11:36:17.194778 18283 solver.cpp:244]     Train net output #1: loss = 0.172192 (* 1 = 0.172192 loss)
I0813 11:36:17.194792 18283 sgd_solver.cpp:106] Iteration 12950, lr = 0.00536306
I0813 11:36:57.532672 18283 solver.cpp:337] Iteration 13000, Testing net (#0)
I0813 11:37:01.900759 18283 solver.cpp:404]     Test net output #0: accuracy = 0.779
I0813 11:37:01.900823 18283 solver.cpp:404]     Test net output #1: loss = 0.70114 (* 1 = 0.70114 loss)
I0813 11:37:02.716497 18283 solver.cpp:228] Iteration 13000, loss = 0.22289
I0813 11:37:02.716568 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:37:02.716579 18283 solver.cpp:244]     Train net output #1: loss = 0.22289 (* 1 = 0.22289 loss)
I0813 11:37:02.716593 18283 sgd_solver.cpp:106] Iteration 13000, lr = 0.00535432
I0813 11:37:44.194427 18283 solver.cpp:228] Iteration 13050, loss = 0.220372
I0813 11:37:44.194587 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:37:44.194602 18283 solver.cpp:244]     Train net output #1: loss = 0.220372 (* 1 = 0.220372 loss)
I0813 11:37:44.194617 18283 sgd_solver.cpp:106] Iteration 13050, lr = 0.0053456
I0813 11:38:24.826159 18283 solver.cpp:337] Iteration 13100, Testing net (#0)
I0813 11:38:28.887414 18283 solver.cpp:404]     Test net output #0: accuracy = 0.814
I0813 11:38:28.887490 18283 solver.cpp:404]     Test net output #1: loss = 0.68536 (* 1 = 0.68536 loss)
I0813 11:38:29.701548 18283 solver.cpp:228] Iteration 13100, loss = 0.180194
I0813 11:38:29.701614 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:38:29.701625 18283 solver.cpp:244]     Train net output #1: loss = 0.180194 (* 1 = 0.180194 loss)
I0813 11:38:29.701639 18283 sgd_solver.cpp:106] Iteration 13100, lr = 0.00533692
I0813 11:39:10.899868 18283 solver.cpp:228] Iteration 13150, loss = 0.164679
I0813 11:39:10.900167 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:39:10.900219 18283 solver.cpp:244]     Train net output #1: loss = 0.164679 (* 1 = 0.164679 loss)
I0813 11:39:10.900245 18283 sgd_solver.cpp:106] Iteration 13150, lr = 0.00532828
I0813 11:39:52.497046 18283 solver.cpp:337] Iteration 13200, Testing net (#0)
I0813 11:39:56.549290 18283 solver.cpp:404]     Test net output #0: accuracy = 0.78
I0813 11:39:56.549355 18283 solver.cpp:404]     Test net output #1: loss = 0.712402 (* 1 = 0.712402 loss)
I0813 11:39:57.361737 18283 solver.cpp:228] Iteration 13200, loss = 0.218312
I0813 11:39:57.361794 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:39:57.361805 18283 solver.cpp:244]     Train net output #1: loss = 0.218312 (* 1 = 0.218312 loss)
I0813 11:39:57.361825 18283 sgd_solver.cpp:106] Iteration 13200, lr = 0.00531966
I0813 11:40:38.523946 18283 solver.cpp:228] Iteration 13250, loss = 0.210885
I0813 11:40:38.524165 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:40:38.524225 18283 solver.cpp:244]     Train net output #1: loss = 0.210885 (* 1 = 0.210885 loss)
I0813 11:40:38.524293 18283 sgd_solver.cpp:106] Iteration 13250, lr = 0.00531108
I0813 11:41:19.061859 18283 solver.cpp:337] Iteration 13300, Testing net (#0)
I0813 11:41:23.388932 18283 solver.cpp:404]     Test net output #0: accuracy = 0.78
I0813 11:41:23.389014 18283 solver.cpp:404]     Test net output #1: loss = 0.712433 (* 1 = 0.712433 loss)
I0813 11:41:24.202375 18283 solver.cpp:228] Iteration 13300, loss = 0.182633
I0813 11:41:24.202437 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:41:24.202451 18283 solver.cpp:244]     Train net output #1: loss = 0.182633 (* 1 = 0.182633 loss)
I0813 11:41:24.202466 18283 sgd_solver.cpp:106] Iteration 13300, lr = 0.00530253
I0813 11:42:06.096213 18283 solver.cpp:228] Iteration 13350, loss = 0.15785
I0813 11:42:06.096372 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 11:42:06.096387 18283 solver.cpp:244]     Train net output #1: loss = 0.15785 (* 1 = 0.15785 loss)
I0813 11:42:06.096398 18283 sgd_solver.cpp:106] Iteration 13350, lr = 0.00529401
I0813 11:42:46.452185 18283 solver.cpp:337] Iteration 13400, Testing net (#0)
I0813 11:42:50.500054 18283 solver.cpp:404]     Test net output #0: accuracy = 0.768
I0813 11:42:50.500118 18283 solver.cpp:404]     Test net output #1: loss = 0.733674 (* 1 = 0.733674 loss)
I0813 11:42:51.312108 18283 solver.cpp:228] Iteration 13400, loss = 0.19485
I0813 11:42:51.312167 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:42:51.312178 18283 solver.cpp:244]     Train net output #1: loss = 0.19485 (* 1 = 0.19485 loss)
I0813 11:42:51.312198 18283 sgd_solver.cpp:106] Iteration 13400, lr = 0.00528552
I0813 11:43:32.461491 18283 solver.cpp:228] Iteration 13450, loss = 0.18403
I0813 11:43:32.461666 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:43:32.461681 18283 solver.cpp:244]     Train net output #1: loss = 0.18403 (* 1 = 0.18403 loss)
I0813 11:43:32.461694 18283 sgd_solver.cpp:106] Iteration 13450, lr = 0.00527707
I0813 11:44:12.848568 18283 solver.cpp:337] Iteration 13500, Testing net (#0)
I0813 11:44:16.911710 18283 solver.cpp:404]     Test net output #0: accuracy = 0.809
I0813 11:44:16.911789 18283 solver.cpp:404]     Test net output #1: loss = 0.693529 (* 1 = 0.693529 loss)
I0813 11:44:17.724812 18283 solver.cpp:228] Iteration 13500, loss = 0.146573
I0813 11:44:17.724884 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:44:17.724895 18283 solver.cpp:244]     Train net output #1: loss = 0.146573 (* 1 = 0.146573 loss)
I0813 11:44:17.724910 18283 sgd_solver.cpp:106] Iteration 13500, lr = 0.00526865
I0813 11:44:58.906018 18283 solver.cpp:228] Iteration 13550, loss = 0.141268
I0813 11:44:58.906249 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 11:44:58.906301 18283 solver.cpp:244]     Train net output #1: loss = 0.141268 (* 1 = 0.141268 loss)
I0813 11:44:58.906322 18283 sgd_solver.cpp:106] Iteration 13550, lr = 0.00526026
I0813 11:45:39.740414 18283 solver.cpp:337] Iteration 13600, Testing net (#0)
I0813 11:45:44.015925 18283 solver.cpp:404]     Test net output #0: accuracy = 0.86
I0813 11:45:44.015990 18283 solver.cpp:404]     Test net output #1: loss = 0.652123 (* 1 = 0.652123 loss)
I0813 11:45:44.829673 18283 solver.cpp:228] Iteration 13600, loss = 0.167996
I0813 11:45:44.829735 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:45:44.829746 18283 solver.cpp:244]     Train net output #1: loss = 0.167996 (* 1 = 0.167996 loss)
I0813 11:45:44.829761 18283 sgd_solver.cpp:106] Iteration 13600, lr = 0.00525189
I0813 11:46:26.033993 18283 solver.cpp:228] Iteration 13650, loss = 0.15283
I0813 11:46:26.034147 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:46:26.034162 18283 solver.cpp:244]     Train net output #1: loss = 0.15283 (* 1 = 0.15283 loss)
I0813 11:46:26.034176 18283 sgd_solver.cpp:106] Iteration 13650, lr = 0.00524356
I0813 11:47:06.398187 18283 solver.cpp:337] Iteration 13700, Testing net (#0)
I0813 11:47:10.644860 18283 solver.cpp:404]     Test net output #0: accuracy = 0.772
I0813 11:47:10.644932 18283 solver.cpp:404]     Test net output #1: loss = 0.78973 (* 1 = 0.78973 loss)
I0813 11:47:11.458276 18283 solver.cpp:228] Iteration 13700, loss = 0.125864
I0813 11:47:11.458329 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:47:11.458341 18283 solver.cpp:244]     Train net output #1: loss = 0.125864 (* 1 = 0.125864 loss)
I0813 11:47:11.458359 18283 sgd_solver.cpp:106] Iteration 13700, lr = 0.00523527
I0813 11:47:52.619303 18283 solver.cpp:228] Iteration 13750, loss = 0.123094
I0813 11:47:52.619498 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:47:52.619550 18283 solver.cpp:244]     Train net output #1: loss = 0.123094 (* 1 = 0.123094 loss)
I0813 11:47:52.619570 18283 sgd_solver.cpp:106] Iteration 13750, lr = 0.005227
I0813 11:48:33.391407 18283 solver.cpp:337] Iteration 13800, Testing net (#0)
I0813 11:48:37.447912 18283 solver.cpp:404]     Test net output #0: accuracy = 0.844
I0813 11:48:37.447983 18283 solver.cpp:404]     Test net output #1: loss = 0.685095 (* 1 = 0.685095 loss)
I0813 11:48:38.258991 18283 solver.cpp:228] Iteration 13800, loss = 0.154144
I0813 11:48:38.259048 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:48:38.259060 18283 solver.cpp:244]     Train net output #1: loss = 0.154144 (* 1 = 0.154144 loss)
I0813 11:48:38.259078 18283 sgd_solver.cpp:106] Iteration 13800, lr = 0.00521876
I0813 11:49:19.396379 18283 solver.cpp:228] Iteration 13850, loss = 0.120789
I0813 11:49:19.396531 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:49:19.396546 18283 solver.cpp:244]     Train net output #1: loss = 0.120789 (* 1 = 0.120789 loss)
I0813 11:49:19.396558 18283 sgd_solver.cpp:106] Iteration 13850, lr = 0.00521055
I0813 11:49:59.716394 18283 solver.cpp:337] Iteration 13900, Testing net (#0)
I0813 11:50:03.773502 18283 solver.cpp:404]     Test net output #0: accuracy = 0.787
I0813 11:50:03.773571 18283 solver.cpp:404]     Test net output #1: loss = 0.813908 (* 1 = 0.813908 loss)
I0813 11:50:04.586577 18283 solver.cpp:228] Iteration 13900, loss = 0.0858962
I0813 11:50:04.586629 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:50:04.586642 18283 solver.cpp:244]     Train net output #1: loss = 0.0858961 (* 1 = 0.0858961 loss)
I0813 11:50:04.586653 18283 sgd_solver.cpp:106] Iteration 13900, lr = 0.00520237
I0813 11:50:45.723106 18283 solver.cpp:228] Iteration 13950, loss = 0.106006
I0813 11:50:45.723268 18283 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0813 11:50:45.723284 18283 solver.cpp:244]     Train net output #1: loss = 0.106006 (* 1 = 0.106006 loss)
I0813 11:50:45.723295 18283 sgd_solver.cpp:106] Iteration 13950, lr = 0.00519423
I0813 11:51:26.069003 18283 solver.cpp:337] Iteration 14000, Testing net (#0)
I0813 11:51:30.124441 18283 solver.cpp:404]     Test net output #0: accuracy = 0.765
I0813 11:51:30.124511 18283 solver.cpp:404]     Test net output #1: loss = 0.869031 (* 1 = 0.869031 loss)
I0813 11:51:30.936436 18283 solver.cpp:228] Iteration 14000, loss = 0.0947369
I0813 11:51:30.936498 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:51:30.936511 18283 solver.cpp:244]     Train net output #1: loss = 0.0947368 (* 1 = 0.0947368 loss)
I0813 11:51:30.936523 18283 sgd_solver.cpp:106] Iteration 14000, lr = 0.00518611
I0813 11:52:12.065773 18283 solver.cpp:228] Iteration 14050, loss = 0.122348
I0813 11:52:12.065930 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:52:12.065946 18283 solver.cpp:244]     Train net output #1: loss = 0.122348 (* 1 = 0.122348 loss)
I0813 11:52:12.065958 18283 sgd_solver.cpp:106] Iteration 14050, lr = 0.00517802
I0813 11:52:52.394642 18283 solver.cpp:337] Iteration 14100, Testing net (#0)
I0813 11:52:56.800818 18283 solver.cpp:404]     Test net output #0: accuracy = 0.814
I0813 11:52:56.800887 18283 solver.cpp:404]     Test net output #1: loss = 0.6879 (* 1 = 0.6879 loss)
I0813 11:52:57.613631 18283 solver.cpp:228] Iteration 14100, loss = 0.090958
I0813 11:52:57.613710 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:52:57.613723 18283 solver.cpp:244]     Train net output #1: loss = 0.0909579 (* 1 = 0.0909579 loss)
I0813 11:52:57.613739 18283 sgd_solver.cpp:106] Iteration 14100, lr = 0.00516996
I0813 11:53:38.784368 18283 solver.cpp:228] Iteration 14150, loss = 0.0931654
I0813 11:53:38.784589 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:53:38.784641 18283 solver.cpp:244]     Train net output #1: loss = 0.0931654 (* 1 = 0.0931654 loss)
I0813 11:53:38.784660 18283 sgd_solver.cpp:106] Iteration 14150, lr = 0.00516193
I0813 11:54:19.648198 18283 solver.cpp:337] Iteration 14200, Testing net (#0)
I0813 11:54:23.915882 18283 solver.cpp:404]     Test net output #0: accuracy = 0.797
I0813 11:54:23.915953 18283 solver.cpp:404]     Test net output #1: loss = 0.764447 (* 1 = 0.764447 loss)
I0813 11:54:24.728242 18283 solver.cpp:228] Iteration 14200, loss = 0.075426
I0813 11:54:24.728296 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:54:24.728308 18283 solver.cpp:244]     Train net output #1: loss = 0.075426 (* 1 = 0.075426 loss)
I0813 11:54:24.728325 18283 sgd_solver.cpp:106] Iteration 14200, lr = 0.00515393
I0813 11:55:05.886574 18283 solver.cpp:228] Iteration 14250, loss = 0.0817145
I0813 11:55:05.886731 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:55:05.886745 18283 solver.cpp:244]     Train net output #1: loss = 0.0817145 (* 1 = 0.0817145 loss)
I0813 11:55:05.886757 18283 sgd_solver.cpp:106] Iteration 14250, lr = 0.00514596
I0813 11:55:46.238687 18283 solver.cpp:337] Iteration 14300, Testing net (#0)
I0813 11:55:50.512722 18283 solver.cpp:404]     Test net output #0: accuracy = 0.825
I0813 11:55:50.512787 18283 solver.cpp:404]     Test net output #1: loss = 0.648907 (* 1 = 0.648907 loss)
I0813 11:55:51.325490 18283 solver.cpp:228] Iteration 14300, loss = 0.081832
I0813 11:55:51.325541 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:55:51.325556 18283 solver.cpp:244]     Train net output #1: loss = 0.0818319 (* 1 = 0.0818319 loss)
I0813 11:55:51.325570 18283 sgd_solver.cpp:106] Iteration 14300, lr = 0.00513801
I0813 11:56:32.473534 18283 solver.cpp:228] Iteration 14350, loss = 0.0416466
I0813 11:56:32.473762 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:56:32.473820 18283 solver.cpp:244]     Train net output #1: loss = 0.0416466 (* 1 = 0.0416466 loss)
I0813 11:56:32.473845 18283 sgd_solver.cpp:106] Iteration 14350, lr = 0.0051301
I0813 11:57:13.650238 18283 solver.cpp:337] Iteration 14400, Testing net (#0)
I0813 11:57:17.839572 18283 solver.cpp:404]     Test net output #0: accuracy = 0.807
I0813 11:57:17.839637 18283 solver.cpp:404]     Test net output #1: loss = 0.758383 (* 1 = 0.758383 loss)
I0813 11:57:18.674049 18283 solver.cpp:228] Iteration 14400, loss = 0.0666185
I0813 11:57:18.674114 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 11:57:18.674126 18283 solver.cpp:244]     Train net output #1: loss = 0.0666184 (* 1 = 0.0666184 loss)
I0813 11:57:18.674142 18283 sgd_solver.cpp:106] Iteration 14400, lr = 0.00512221
I0813 11:57:59.855139 18283 solver.cpp:228] Iteration 14450, loss = 0.0206396
I0813 11:57:59.855357 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:57:59.855418 18283 solver.cpp:244]     Train net output #1: loss = 0.0206396 (* 1 = 0.0206396 loss)
I0813 11:57:59.855443 18283 sgd_solver.cpp:106] Iteration 14450, lr = 0.00511435
I0813 11:58:40.476518 18283 solver.cpp:337] Iteration 14500, Testing net (#0)
I0813 11:58:44.526825 18283 solver.cpp:404]     Test net output #0: accuracy = 0.783
I0813 11:58:44.526891 18283 solver.cpp:404]     Test net output #1: loss = 0.857209 (* 1 = 0.857209 loss)
I0813 11:58:45.338263 18283 solver.cpp:228] Iteration 14500, loss = 0.0779447
I0813 11:58:45.338320 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 11:58:45.338332 18283 solver.cpp:244]     Train net output #1: loss = 0.0779446 (* 1 = 0.0779446 loss)
I0813 11:58:45.338348 18283 sgd_solver.cpp:106] Iteration 14500, lr = 0.00510653
I0813 11:59:26.493338 18283 solver.cpp:228] Iteration 14550, loss = 0.0239364
I0813 11:59:26.493495 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 11:59:26.493510 18283 solver.cpp:244]     Train net output #1: loss = 0.0239363 (* 1 = 0.0239363 loss)
I0813 11:59:26.493521 18283 sgd_solver.cpp:106] Iteration 14550, lr = 0.00509872
I0813 12:00:06.902784 18283 solver.cpp:337] Iteration 14600, Testing net (#0)
I0813 12:00:10.955232 18283 solver.cpp:404]     Test net output #0: accuracy = 0.779
I0813 12:00:10.955302 18283 solver.cpp:404]     Test net output #1: loss = 0.858597 (* 1 = 0.858597 loss)
I0813 12:00:11.768486 18283 solver.cpp:228] Iteration 14600, loss = 0.0535406
I0813 12:00:11.768545 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:00:11.768558 18283 solver.cpp:244]     Train net output #1: loss = 0.0535405 (* 1 = 0.0535405 loss)
I0813 12:00:11.768571 18283 sgd_solver.cpp:106] Iteration 14600, lr = 0.00509095
I0813 12:00:52.931514 18283 solver.cpp:228] Iteration 14650, loss = 0.0271403
I0813 12:00:52.931663 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:00:52.931676 18283 solver.cpp:244]     Train net output #1: loss = 0.0271402 (* 1 = 0.0271402 loss)
I0813 12:00:52.931689 18283 sgd_solver.cpp:106] Iteration 14650, lr = 0.0050832
I0813 12:01:33.276443 18283 solver.cpp:337] Iteration 14700, Testing net (#0)
I0813 12:01:37.326719 18283 solver.cpp:404]     Test net output #0: accuracy = 0.787
I0813 12:01:37.326786 18283 solver.cpp:404]     Test net output #1: loss = 0.780047 (* 1 = 0.780047 loss)
I0813 12:01:38.139318 18283 solver.cpp:228] Iteration 14700, loss = 0.087346
I0813 12:01:38.139372 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:01:38.139384 18283 solver.cpp:244]     Train net output #1: loss = 0.0873459 (* 1 = 0.0873459 loss)
I0813 12:01:38.139397 18283 sgd_solver.cpp:106] Iteration 14700, lr = 0.00507548
I0813 12:02:19.281400 18283 solver.cpp:228] Iteration 14750, loss = 0.0848742
I0813 12:02:19.281590 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:02:19.281639 18283 solver.cpp:244]     Train net output #1: loss = 0.0848741 (* 1 = 0.0848741 loss)
I0813 12:02:19.281659 18283 sgd_solver.cpp:106] Iteration 14750, lr = 0.00506779
I0813 12:03:00.332950 18283 solver.cpp:337] Iteration 14800, Testing net (#0)
I0813 12:03:04.533354 18283 solver.cpp:404]     Test net output #0: accuracy = 0.785
I0813 12:03:04.533418 18283 solver.cpp:404]     Test net output #1: loss = 0.829345 (* 1 = 0.829345 loss)
I0813 12:03:05.346283 18283 solver.cpp:228] Iteration 14800, loss = 0.061054
I0813 12:03:05.346339 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:03:05.346351 18283 solver.cpp:244]     Train net output #1: loss = 0.0610539 (* 1 = 0.0610539 loss)
I0813 12:03:05.346365 18283 sgd_solver.cpp:106] Iteration 14800, lr = 0.00506012
I0813 12:03:46.547627 18283 solver.cpp:228] Iteration 14850, loss = 0.0611517
I0813 12:03:46.547860 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:03:46.547909 18283 solver.cpp:244]     Train net output #1: loss = 0.0611516 (* 1 = 0.0611516 loss)
I0813 12:03:46.547929 18283 sgd_solver.cpp:106] Iteration 14850, lr = 0.00505249
I0813 12:04:27.554738 18283 solver.cpp:337] Iteration 14900, Testing net (#0)
I0813 12:04:31.615489 18283 solver.cpp:404]     Test net output #0: accuracy = 0.769
I0813 12:04:31.615552 18283 solver.cpp:404]     Test net output #1: loss = 0.915495 (* 1 = 0.915495 loss)
I0813 12:04:32.429332 18283 solver.cpp:228] Iteration 14900, loss = 0.0567191
I0813 12:04:32.429390 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:04:32.429402 18283 solver.cpp:244]     Train net output #1: loss = 0.056719 (* 1 = 0.056719 loss)
I0813 12:04:32.429422 18283 sgd_solver.cpp:106] Iteration 14900, lr = 0.00504488
I0813 12:05:13.611971 18283 solver.cpp:228] Iteration 14950, loss = 0.052758
I0813 12:05:13.612143 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:05:13.612157 18283 solver.cpp:244]     Train net output #1: loss = 0.0527579 (* 1 = 0.0527579 loss)
I0813 12:05:13.612169 18283 sgd_solver.cpp:106] Iteration 14950, lr = 0.00503729
I0813 12:05:54.531113 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_15000.caffemodel
I0813 12:05:54.981166 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_15000.solverstate
I0813 12:05:54.994927 18283 solver.cpp:337] Iteration 15000, Testing net (#0)
I0813 12:05:59.059969 18283 solver.cpp:404]     Test net output #0: accuracy = 0.784
I0813 12:05:59.060056 18283 solver.cpp:404]     Test net output #1: loss = 0.852401 (* 1 = 0.852401 loss)
I0813 12:05:59.873136 18283 solver.cpp:228] Iteration 15000, loss = 0.100656
I0813 12:05:59.873212 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:05:59.873225 18283 solver.cpp:244]     Train net output #1: loss = 0.100656 (* 1 = 0.100656 loss)
I0813 12:05:59.873244 18283 sgd_solver.cpp:106] Iteration 15000, lr = 0.00502973
I0813 12:06:41.071550 18283 solver.cpp:228] Iteration 15050, loss = 0.0396411
I0813 12:06:41.071771 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:06:41.071868 18283 solver.cpp:244]     Train net output #1: loss = 0.039641 (* 1 = 0.039641 loss)
I0813 12:06:41.071918 18283 sgd_solver.cpp:106] Iteration 15050, lr = 0.0050222
I0813 12:07:22.378072 18283 solver.cpp:337] Iteration 15100, Testing net (#0)
I0813 12:07:26.433439 18283 solver.cpp:404]     Test net output #0: accuracy = 0.786
I0813 12:07:26.433513 18283 solver.cpp:404]     Test net output #1: loss = 0.83431 (* 1 = 0.83431 loss)
I0813 12:07:27.246107 18283 solver.cpp:228] Iteration 15100, loss = 0.0578411
I0813 12:07:27.246166 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:07:27.246178 18283 solver.cpp:244]     Train net output #1: loss = 0.0578411 (* 1 = 0.0578411 loss)
I0813 12:07:27.246194 18283 sgd_solver.cpp:106] Iteration 15100, lr = 0.0050147
I0813 12:08:08.856081 18283 solver.cpp:228] Iteration 15150, loss = 0.0776413
I0813 12:08:08.856240 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:08:08.856254 18283 solver.cpp:244]     Train net output #1: loss = 0.0776412 (* 1 = 0.0776412 loss)
I0813 12:08:08.856267 18283 sgd_solver.cpp:106] Iteration 15150, lr = 0.00500722
I0813 12:08:49.691270 18283 solver.cpp:337] Iteration 15200, Testing net (#0)
I0813 12:08:53.747931 18283 solver.cpp:404]     Test net output #0: accuracy = 0.764
I0813 12:08:53.747998 18283 solver.cpp:404]     Test net output #1: loss = 0.955404 (* 1 = 0.955404 loss)
I0813 12:08:54.561324 18283 solver.cpp:228] Iteration 15200, loss = 0.0715577
I0813 12:08:54.561383 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:08:54.561398 18283 solver.cpp:244]     Train net output #1: loss = 0.0715577 (* 1 = 0.0715577 loss)
I0813 12:08:54.561413 18283 sgd_solver.cpp:106] Iteration 15200, lr = 0.00499976
I0813 12:09:36.038069 18283 solver.cpp:228] Iteration 15250, loss = 0.038757
I0813 12:09:36.038324 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:09:36.038373 18283 solver.cpp:244]     Train net output #1: loss = 0.0387569 (* 1 = 0.0387569 loss)
I0813 12:09:36.038413 18283 sgd_solver.cpp:106] Iteration 15250, lr = 0.00499234
I0813 12:10:16.597615 18283 solver.cpp:337] Iteration 15300, Testing net (#0)
I0813 12:10:20.652618 18283 solver.cpp:404]     Test net output #0: accuracy = 0.773
I0813 12:10:20.652693 18283 solver.cpp:404]     Test net output #1: loss = 0.899934 (* 1 = 0.899934 loss)
I0813 12:10:21.464946 18283 solver.cpp:228] Iteration 15300, loss = 0.0957816
I0813 12:10:21.465009 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:10:21.465023 18283 solver.cpp:244]     Train net output #1: loss = 0.0957815 (* 1 = 0.0957815 loss)
I0813 12:10:21.465036 18283 sgd_solver.cpp:106] Iteration 15300, lr = 0.00498494
I0813 12:11:02.609855 18283 solver.cpp:228] Iteration 15350, loss = 0.0386407
I0813 12:11:02.610064 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:11:02.610133 18283 solver.cpp:244]     Train net output #1: loss = 0.0386407 (* 1 = 0.0386407 loss)
I0813 12:11:02.610155 18283 sgd_solver.cpp:106] Iteration 15350, lr = 0.00497756
I0813 12:11:43.978955 18283 solver.cpp:337] Iteration 15400, Testing net (#0)
I0813 12:11:48.300446 18283 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0813 12:11:48.300523 18283 solver.cpp:404]     Test net output #1: loss = 0.89693 (* 1 = 0.89693 loss)
I0813 12:11:49.114495 18283 solver.cpp:228] Iteration 15400, loss = 0.0831
I0813 12:11:49.114559 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:11:49.114572 18283 solver.cpp:244]     Train net output #1: loss = 0.0831 (* 1 = 0.0831 loss)
I0813 12:11:49.114585 18283 sgd_solver.cpp:106] Iteration 15400, lr = 0.00497021
I0813 12:12:30.868721 18283 solver.cpp:228] Iteration 15450, loss = 0.00368209
I0813 12:12:30.868885 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:12:30.868899 18283 solver.cpp:244]     Train net output #1: loss = 0.00368205 (* 1 = 0.00368205 loss)
I0813 12:12:30.868914 18283 sgd_solver.cpp:106] Iteration 15450, lr = 0.00496288
I0813 12:13:11.735112 18283 solver.cpp:337] Iteration 15500, Testing net (#0)
I0813 12:13:15.820118 18283 solver.cpp:404]     Test net output #0: accuracy = 0.802
I0813 12:13:15.820184 18283 solver.cpp:404]     Test net output #1: loss = 0.809327 (* 1 = 0.809327 loss)
I0813 12:13:16.642204 18283 solver.cpp:228] Iteration 15500, loss = 0.0363783
I0813 12:13:16.642261 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:13:16.642277 18283 solver.cpp:244]     Train net output #1: loss = 0.0363783 (* 1 = 0.0363783 loss)
I0813 12:13:16.642292 18283 sgd_solver.cpp:106] Iteration 15500, lr = 0.00495558
I0813 12:13:57.841539 18283 solver.cpp:228] Iteration 15550, loss = 0.0377848
I0813 12:13:57.841754 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:13:57.841820 18283 solver.cpp:244]     Train net output #1: loss = 0.0377847 (* 1 = 0.0377847 loss)
I0813 12:13:57.841852 18283 sgd_solver.cpp:106] Iteration 15550, lr = 0.00494831
I0813 12:14:38.406263 18283 solver.cpp:337] Iteration 15600, Testing net (#0)
I0813 12:14:42.590714 18283 solver.cpp:404]     Test net output #0: accuracy = 0.772
I0813 12:14:42.590776 18283 solver.cpp:404]     Test net output #1: loss = 0.932894 (* 1 = 0.932894 loss)
I0813 12:14:43.404131 18283 solver.cpp:228] Iteration 15600, loss = 0.0428046
I0813 12:14:43.404196 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:14:43.404207 18283 solver.cpp:244]     Train net output #1: loss = 0.0428046 (* 1 = 0.0428046 loss)
I0813 12:14:43.404223 18283 sgd_solver.cpp:106] Iteration 15600, lr = 0.00494106
I0813 12:15:24.881433 18283 solver.cpp:228] Iteration 15650, loss = 0.0539484
I0813 12:15:24.881629 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:15:24.881644 18283 solver.cpp:244]     Train net output #1: loss = 0.0539484 (* 1 = 0.0539484 loss)
I0813 12:15:24.881657 18283 sgd_solver.cpp:106] Iteration 15650, lr = 0.00493383
I0813 12:16:05.265096 18283 solver.cpp:337] Iteration 15700, Testing net (#0)
I0813 12:16:09.327848 18283 solver.cpp:404]     Test net output #0: accuracy = 0.799
I0813 12:16:09.327925 18283 solver.cpp:404]     Test net output #1: loss = 0.814404 (* 1 = 0.814404 loss)
I0813 12:16:10.140903 18283 solver.cpp:228] Iteration 15700, loss = 0.061627
I0813 12:16:10.140976 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:16:10.140987 18283 solver.cpp:244]     Train net output #1: loss = 0.061627 (* 1 = 0.061627 loss)
I0813 12:16:10.141007 18283 sgd_solver.cpp:106] Iteration 15700, lr = 0.00492663
I0813 12:16:51.308676 18283 solver.cpp:228] Iteration 15750, loss = 0.020409
I0813 12:16:51.308832 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:16:51.308846 18283 solver.cpp:244]     Train net output #1: loss = 0.020409 (* 1 = 0.020409 loss)
I0813 12:16:51.308858 18283 sgd_solver.cpp:106] Iteration 15750, lr = 0.00491946
I0813 12:17:32.166319 18283 solver.cpp:337] Iteration 15800, Testing net (#0)
I0813 12:17:36.228642 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 12:17:36.228713 18283 solver.cpp:404]     Test net output #1: loss = 1.00847 (* 1 = 1.00847 loss)
I0813 12:17:37.042719 18283 solver.cpp:228] Iteration 15800, loss = 0.0601794
I0813 12:17:37.042788 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:17:37.042801 18283 solver.cpp:244]     Train net output #1: loss = 0.0601794 (* 1 = 0.0601794 loss)
I0813 12:17:37.042815 18283 sgd_solver.cpp:106] Iteration 15800, lr = 0.0049123
I0813 12:18:19.082903 18283 solver.cpp:228] Iteration 15850, loss = 0.0559423
I0813 12:18:19.083076 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:18:19.083093 18283 solver.cpp:244]     Train net output #1: loss = 0.0559423 (* 1 = 0.0559423 loss)
I0813 12:18:19.083107 18283 sgd_solver.cpp:106] Iteration 15850, lr = 0.00490518
I0813 12:19:00.351078 18283 solver.cpp:337] Iteration 15900, Testing net (#0)
I0813 12:19:04.750278 18283 solver.cpp:404]     Test net output #0: accuracy = 0.787
I0813 12:19:04.750347 18283 solver.cpp:404]     Test net output #1: loss = 0.872967 (* 1 = 0.872967 loss)
I0813 12:19:05.564411 18283 solver.cpp:228] Iteration 15900, loss = 0.0647532
I0813 12:19:05.564474 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:19:05.564487 18283 solver.cpp:244]     Train net output #1: loss = 0.0647531 (* 1 = 0.0647531 loss)
I0813 12:19:05.564503 18283 sgd_solver.cpp:106] Iteration 15900, lr = 0.00489807
I0813 12:19:46.999516 18283 solver.cpp:228] Iteration 15950, loss = 0.0475205
I0813 12:19:46.999738 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:19:46.999792 18283 solver.cpp:244]     Train net output #1: loss = 0.0475205 (* 1 = 0.0475205 loss)
I0813 12:19:46.999820 18283 sgd_solver.cpp:106] Iteration 15950, lr = 0.00489099
I0813 12:20:28.202883 18283 solver.cpp:337] Iteration 16000, Testing net (#0)
I0813 12:20:32.265751 18283 solver.cpp:404]     Test net output #0: accuracy = 0.773
I0813 12:20:32.265812 18283 solver.cpp:404]     Test net output #1: loss = 0.957436 (* 1 = 0.957436 loss)
I0813 12:20:33.079143 18283 solver.cpp:228] Iteration 16000, loss = 0.0510831
I0813 12:20:33.079221 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:20:33.079233 18283 solver.cpp:244]     Train net output #1: loss = 0.0510831 (* 1 = 0.0510831 loss)
I0813 12:20:33.079248 18283 sgd_solver.cpp:106] Iteration 16000, lr = 0.00488394
I0813 12:21:14.708124 18283 solver.cpp:228] Iteration 16050, loss = 0.0188674
I0813 12:21:14.708312 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:21:14.708326 18283 solver.cpp:244]     Train net output #1: loss = 0.0188674 (* 1 = 0.0188674 loss)
I0813 12:21:14.708338 18283 sgd_solver.cpp:106] Iteration 16050, lr = 0.0048769
I0813 12:21:55.426551 18283 solver.cpp:337] Iteration 16100, Testing net (#0)
I0813 12:21:59.773780 18283 solver.cpp:404]     Test net output #0: accuracy = 0.781
I0813 12:21:59.773851 18283 solver.cpp:404]     Test net output #1: loss = 0.916292 (* 1 = 0.916292 loss)
I0813 12:22:00.589063 18283 solver.cpp:228] Iteration 16100, loss = 0.0295117
I0813 12:22:00.589123 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:22:00.589135 18283 solver.cpp:244]     Train net output #1: loss = 0.0295117 (* 1 = 0.0295117 loss)
I0813 12:22:00.589149 18283 sgd_solver.cpp:106] Iteration 16100, lr = 0.0048699
I0813 12:22:41.756920 18283 solver.cpp:228] Iteration 16150, loss = 0.0119221
I0813 12:22:41.757078 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:22:41.757093 18283 solver.cpp:244]     Train net output #1: loss = 0.0119221 (* 1 = 0.0119221 loss)
I0813 12:22:41.757105 18283 sgd_solver.cpp:106] Iteration 16150, lr = 0.00486291
I0813 12:23:22.127506 18283 solver.cpp:337] Iteration 16200, Testing net (#0)
I0813 12:23:26.179348 18283 solver.cpp:404]     Test net output #0: accuracy = 0.776
I0813 12:23:26.179414 18283 solver.cpp:404]     Test net output #1: loss = 0.961891 (* 1 = 0.961891 loss)
I0813 12:23:26.990721 18283 solver.cpp:228] Iteration 16200, loss = 0.0224035
I0813 12:23:26.990774 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:23:26.990785 18283 solver.cpp:244]     Train net output #1: loss = 0.0224035 (* 1 = 0.0224035 loss)
I0813 12:23:26.990798 18283 sgd_solver.cpp:106] Iteration 16200, lr = 0.00485595
I0813 12:24:08.137657 18283 solver.cpp:228] Iteration 16250, loss = 0.0192766
I0813 12:24:08.137810 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:24:08.137825 18283 solver.cpp:244]     Train net output #1: loss = 0.0192766 (* 1 = 0.0192766 loss)
I0813 12:24:08.137838 18283 sgd_solver.cpp:106] Iteration 16250, lr = 0.00484901
I0813 12:24:48.488610 18283 solver.cpp:337] Iteration 16300, Testing net (#0)
I0813 12:24:52.544328 18283 solver.cpp:404]     Test net output #0: accuracy = 0.778
I0813 12:24:52.544407 18283 solver.cpp:404]     Test net output #1: loss = 0.938981 (* 1 = 0.938981 loss)
I0813 12:24:53.358638 18283 solver.cpp:228] Iteration 16300, loss = 0.0491353
I0813 12:24:53.358695 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:24:53.358706 18283 solver.cpp:244]     Train net output #1: loss = 0.0491353 (* 1 = 0.0491353 loss)
I0813 12:24:53.358724 18283 sgd_solver.cpp:106] Iteration 16300, lr = 0.00484209
I0813 12:25:34.849594 18283 solver.cpp:228] Iteration 16350, loss = 0.0130434
I0813 12:25:34.849795 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:25:34.849856 18283 solver.cpp:244]     Train net output #1: loss = 0.0130434 (* 1 = 0.0130434 loss)
I0813 12:25:34.849879 18283 sgd_solver.cpp:106] Iteration 16350, lr = 0.0048352
I0813 12:26:15.600162 18283 solver.cpp:337] Iteration 16400, Testing net (#0)
I0813 12:26:19.688035 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 12:26:19.688102 18283 solver.cpp:404]     Test net output #1: loss = 1.06796 (* 1 = 1.06796 loss)
I0813 12:26:20.500406 18283 solver.cpp:228] Iteration 16400, loss = 0.0351464
I0813 12:26:20.500458 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:26:20.500470 18283 solver.cpp:244]     Train net output #1: loss = 0.0351464 (* 1 = 0.0351464 loss)
I0813 12:26:20.500488 18283 sgd_solver.cpp:106] Iteration 16400, lr = 0.00482833
I0813 12:27:01.691965 18283 solver.cpp:228] Iteration 16450, loss = 0.0209486
I0813 12:27:01.692168 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:27:01.692217 18283 solver.cpp:244]     Train net output #1: loss = 0.0209486 (* 1 = 0.0209486 loss)
I0813 12:27:01.692253 18283 sgd_solver.cpp:106] Iteration 16450, lr = 0.00482148
I0813 12:27:43.306664 18283 solver.cpp:337] Iteration 16500, Testing net (#0)
I0813 12:27:47.661108 18283 solver.cpp:404]     Test net output #0: accuracy = 0.777
I0813 12:27:47.661176 18283 solver.cpp:404]     Test net output #1: loss = 0.941483 (* 1 = 0.941483 loss)
I0813 12:27:48.474179 18283 solver.cpp:228] Iteration 16500, loss = 0.0517395
I0813 12:27:48.474238 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:27:48.474251 18283 solver.cpp:244]     Train net output #1: loss = 0.0517395 (* 1 = 0.0517395 loss)
I0813 12:27:48.474268 18283 sgd_solver.cpp:106] Iteration 16500, lr = 0.00481466
I0813 12:28:29.656587 18283 solver.cpp:228] Iteration 16550, loss = 0.0138717
I0813 12:28:29.656751 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:28:29.656765 18283 solver.cpp:244]     Train net output #1: loss = 0.0138717 (* 1 = 0.0138717 loss)
I0813 12:28:29.656780 18283 sgd_solver.cpp:106] Iteration 16550, lr = 0.00480786
I0813 12:29:10.011018 18283 solver.cpp:337] Iteration 16600, Testing net (#0)
I0813 12:29:14.158491 18283 solver.cpp:404]     Test net output #0: accuracy = 0.77
I0813 12:29:14.158571 18283 solver.cpp:404]     Test net output #1: loss = 0.939614 (* 1 = 0.939614 loss)
I0813 12:29:14.971940 18283 solver.cpp:228] Iteration 16600, loss = 0.0399714
I0813 12:29:14.972005 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:29:14.972018 18283 solver.cpp:244]     Train net output #1: loss = 0.0399714 (* 1 = 0.0399714 loss)
I0813 12:29:14.972053 18283 sgd_solver.cpp:106] Iteration 16600, lr = 0.00480108
I0813 12:29:56.130434 18283 solver.cpp:228] Iteration 16650, loss = 0.0163011
I0813 12:29:56.130609 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:29:56.130622 18283 solver.cpp:244]     Train net output #1: loss = 0.0163011 (* 1 = 0.0163011 loss)
I0813 12:29:56.130635 18283 sgd_solver.cpp:106] Iteration 16650, lr = 0.00479432
I0813 12:30:36.463307 18283 solver.cpp:337] Iteration 16700, Testing net (#0)
I0813 12:30:40.511631 18283 solver.cpp:404]     Test net output #0: accuracy = 0.754
I0813 12:30:40.511696 18283 solver.cpp:404]     Test net output #1: loss = 1.15852 (* 1 = 1.15852 loss)
I0813 12:30:41.324102 18283 solver.cpp:228] Iteration 16700, loss = 0.0280807
I0813 12:30:41.324156 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:30:41.324167 18283 solver.cpp:244]     Train net output #1: loss = 0.0280807 (* 1 = 0.0280807 loss)
I0813 12:30:41.324179 18283 sgd_solver.cpp:106] Iteration 16700, lr = 0.00478759
I0813 12:31:23.085230 18283 solver.cpp:228] Iteration 16750, loss = 0.0552504
I0813 12:31:23.085489 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:31:23.085544 18283 solver.cpp:244]     Train net output #1: loss = 0.0552504 (* 1 = 0.0552504 loss)
I0813 12:31:23.085566 18283 sgd_solver.cpp:106] Iteration 16750, lr = 0.00478087
I0813 12:32:03.742385 18283 solver.cpp:337] Iteration 16800, Testing net (#0)
I0813 12:32:07.792701 18283 solver.cpp:404]     Test net output #0: accuracy = 0.767
I0813 12:32:07.792767 18283 solver.cpp:404]     Test net output #1: loss = 0.975407 (* 1 = 0.975407 loss)
I0813 12:32:08.606156 18283 solver.cpp:228] Iteration 16800, loss = 0.0432876
I0813 12:32:08.606210 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:32:08.606222 18283 solver.cpp:244]     Train net output #1: loss = 0.0432876 (* 1 = 0.0432876 loss)
I0813 12:32:08.606240 18283 sgd_solver.cpp:106] Iteration 16800, lr = 0.00477418
I0813 12:32:49.749971 18283 solver.cpp:228] Iteration 16850, loss = 0.0491726
I0813 12:32:49.750128 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:32:49.750144 18283 solver.cpp:244]     Train net output #1: loss = 0.0491726 (* 1 = 0.0491726 loss)
I0813 12:32:49.750157 18283 sgd_solver.cpp:106] Iteration 16850, lr = 0.00476751
I0813 12:33:30.109302 18283 solver.cpp:337] Iteration 16900, Testing net (#0)
I0813 12:33:34.157711 18283 solver.cpp:404]     Test net output #0: accuracy = 0.783
I0813 12:33:34.157778 18283 solver.cpp:404]     Test net output #1: loss = 0.893711 (* 1 = 0.893711 loss)
I0813 12:33:34.969844 18283 solver.cpp:228] Iteration 16900, loss = 0.0334789
I0813 12:33:34.969902 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:33:34.969913 18283 solver.cpp:244]     Train net output #1: loss = 0.0334789 (* 1 = 0.0334789 loss)
I0813 12:33:34.969929 18283 sgd_solver.cpp:106] Iteration 16900, lr = 0.00476086
I0813 12:34:16.134474 18283 solver.cpp:228] Iteration 16950, loss = 0.0160993
I0813 12:34:16.134666 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:34:16.134681 18283 solver.cpp:244]     Train net output #1: loss = 0.0160993 (* 1 = 0.0160993 loss)
I0813 12:34:16.134692 18283 sgd_solver.cpp:106] Iteration 16950, lr = 0.00475424
I0813 12:34:56.469756 18283 solver.cpp:337] Iteration 17000, Testing net (#0)
I0813 12:35:00.528358 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 12:35:00.528425 18283 solver.cpp:404]     Test net output #1: loss = 1.11542 (* 1 = 1.11542 loss)
I0813 12:35:01.340404 18283 solver.cpp:228] Iteration 17000, loss = 0.0111394
I0813 12:35:01.340456 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:35:01.340467 18283 solver.cpp:244]     Train net output #1: loss = 0.0111394 (* 1 = 0.0111394 loss)
I0813 12:35:01.340482 18283 sgd_solver.cpp:106] Iteration 17000, lr = 0.00474763
I0813 12:35:42.514956 18283 solver.cpp:228] Iteration 17050, loss = 0.0196907
I0813 12:35:42.515202 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:35:42.515252 18283 solver.cpp:244]     Train net output #1: loss = 0.0196907 (* 1 = 0.0196907 loss)
I0813 12:35:42.515280 18283 sgd_solver.cpp:106] Iteration 17050, lr = 0.00474105
I0813 12:36:22.878339 18283 solver.cpp:337] Iteration 17100, Testing net (#0)
I0813 12:36:26.933035 18283 solver.cpp:404]     Test net output #0: accuracy = 0.776
I0813 12:36:26.933105 18283 solver.cpp:404]     Test net output #1: loss = 0.902318 (* 1 = 0.902318 loss)
I0813 12:36:27.745926 18283 solver.cpp:228] Iteration 17100, loss = 0.0238544
I0813 12:36:27.745983 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:36:27.745995 18283 solver.cpp:244]     Train net output #1: loss = 0.0238544 (* 1 = 0.0238544 loss)
I0813 12:36:27.746009 18283 sgd_solver.cpp:106] Iteration 17100, lr = 0.00473449
I0813 12:37:08.895927 18283 solver.cpp:228] Iteration 17150, loss = 0.0546555
I0813 12:37:08.896085 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:37:08.896098 18283 solver.cpp:244]     Train net output #1: loss = 0.0546555 (* 1 = 0.0546555 loss)
I0813 12:37:08.896111 18283 sgd_solver.cpp:106] Iteration 17150, lr = 0.00472795
I0813 12:37:49.263736 18283 solver.cpp:337] Iteration 17200, Testing net (#0)
I0813 12:37:53.590430 18283 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0813 12:37:53.590500 18283 solver.cpp:404]     Test net output #1: loss = 1.0382 (* 1 = 1.0382 loss)
I0813 12:37:54.404947 18283 solver.cpp:228] Iteration 17200, loss = 0.032508
I0813 12:37:54.405009 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:37:54.405022 18283 solver.cpp:244]     Train net output #1: loss = 0.032508 (* 1 = 0.032508 loss)
I0813 12:37:54.405037 18283 sgd_solver.cpp:106] Iteration 17200, lr = 0.00472143
I0813 12:38:35.592679 18283 solver.cpp:228] Iteration 17250, loss = 0.0276512
I0813 12:38:35.592880 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:38:35.592936 18283 solver.cpp:244]     Train net output #1: loss = 0.0276512 (* 1 = 0.0276512 loss)
I0813 12:38:35.592957 18283 sgd_solver.cpp:106] Iteration 17250, lr = 0.00471493
I0813 12:39:16.193763 18283 solver.cpp:337] Iteration 17300, Testing net (#0)
I0813 12:39:20.591558 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 12:39:20.591619 18283 solver.cpp:404]     Test net output #1: loss = 1.04845 (* 1 = 1.04845 loss)
I0813 12:39:21.405616 18283 solver.cpp:228] Iteration 17300, loss = 0.0414654
I0813 12:39:21.405681 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:39:21.405692 18283 solver.cpp:244]     Train net output #1: loss = 0.0414654 (* 1 = 0.0414654 loss)
I0813 12:39:21.405709 18283 sgd_solver.cpp:106] Iteration 17300, lr = 0.00470845
I0813 12:40:02.600283 18283 solver.cpp:228] Iteration 17350, loss = 0.0030513
I0813 12:40:02.600544 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:40:02.600594 18283 solver.cpp:244]     Train net output #1: loss = 0.00305129 (* 1 = 0.00305129 loss)
I0813 12:40:02.600618 18283 sgd_solver.cpp:106] Iteration 17350, lr = 0.00470199
I0813 12:40:43.971416 18283 solver.cpp:337] Iteration 17400, Testing net (#0)
I0813 12:40:48.253895 18283 solver.cpp:404]     Test net output #0: accuracy = 0.81
I0813 12:40:48.253962 18283 solver.cpp:404]     Test net output #1: loss = 0.816357 (* 1 = 0.816357 loss)
I0813 12:40:49.067771 18283 solver.cpp:228] Iteration 17400, loss = 0.0188428
I0813 12:40:49.067829 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:40:49.067842 18283 solver.cpp:244]     Train net output #1: loss = 0.0188428 (* 1 = 0.0188428 loss)
I0813 12:40:49.067857 18283 sgd_solver.cpp:106] Iteration 17400, lr = 0.00469556
I0813 12:41:30.270668 18283 solver.cpp:228] Iteration 17450, loss = 0.00418668
I0813 12:41:30.270879 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:41:30.270937 18283 solver.cpp:244]     Train net output #1: loss = 0.00418668 (* 1 = 0.00418668 loss)
I0813 12:41:30.270961 18283 sgd_solver.cpp:106] Iteration 17450, lr = 0.00468914
I0813 12:42:10.806064 18283 solver.cpp:337] Iteration 17500, Testing net (#0)
I0813 12:42:14.861407 18283 solver.cpp:404]     Test net output #0: accuracy = 0.78
I0813 12:42:14.861477 18283 solver.cpp:404]     Test net output #1: loss = 1.00096 (* 1 = 1.00096 loss)
I0813 12:42:15.674026 18283 solver.cpp:228] Iteration 17500, loss = 0.0559673
I0813 12:42:15.674075 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:42:15.674087 18283 solver.cpp:244]     Train net output #1: loss = 0.0559673 (* 1 = 0.0559673 loss)
I0813 12:42:15.674098 18283 sgd_solver.cpp:106] Iteration 17500, lr = 0.00468274
I0813 12:42:56.838776 18283 solver.cpp:228] Iteration 17550, loss = 0.00637184
I0813 12:42:56.838943 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:42:56.838956 18283 solver.cpp:244]     Train net output #1: loss = 0.00637186 (* 1 = 0.00637186 loss)
I0813 12:42:56.838968 18283 sgd_solver.cpp:106] Iteration 17550, lr = 0.00467637
I0813 12:43:37.176473 18283 solver.cpp:337] Iteration 17600, Testing net (#0)
I0813 12:43:41.229904 18283 solver.cpp:404]     Test net output #0: accuracy = 0.742
I0813 12:43:41.229971 18283 solver.cpp:404]     Test net output #1: loss = 1.1531 (* 1 = 1.1531 loss)
I0813 12:43:42.042083 18283 solver.cpp:228] Iteration 17600, loss = 0.0317115
I0813 12:43:42.042132 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:43:42.042145 18283 solver.cpp:244]     Train net output #1: loss = 0.0317115 (* 1 = 0.0317115 loss)
I0813 12:43:42.042161 18283 sgd_solver.cpp:106] Iteration 17600, lr = 0.00467001
I0813 12:44:23.187497 18283 solver.cpp:228] Iteration 17650, loss = 0.0277805
I0813 12:44:23.187652 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:44:23.187666 18283 solver.cpp:244]     Train net output #1: loss = 0.0277806 (* 1 = 0.0277806 loss)
I0813 12:44:23.187677 18283 sgd_solver.cpp:106] Iteration 17650, lr = 0.00466368
I0813 12:45:03.518945 18283 solver.cpp:337] Iteration 17700, Testing net (#0)
I0813 12:45:07.840423 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 12:45:07.840492 18283 solver.cpp:404]     Test net output #1: loss = 0.987809 (* 1 = 0.987809 loss)
I0813 12:45:08.654244 18283 solver.cpp:228] Iteration 17700, loss = 0.0380124
I0813 12:45:08.654309 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:45:08.654320 18283 solver.cpp:244]     Train net output #1: loss = 0.0380125 (* 1 = 0.0380125 loss)
I0813 12:45:08.654335 18283 sgd_solver.cpp:106] Iteration 17700, lr = 0.00465736
I0813 12:45:49.950165 18283 solver.cpp:228] Iteration 17750, loss = 0.00695307
I0813 12:45:49.950358 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:45:49.950373 18283 solver.cpp:244]     Train net output #1: loss = 0.00695309 (* 1 = 0.00695309 loss)
I0813 12:45:49.950387 18283 sgd_solver.cpp:106] Iteration 17750, lr = 0.00465107
I0813 12:46:30.326618 18283 solver.cpp:337] Iteration 17800, Testing net (#0)
I0813 12:46:34.382844 18283 solver.cpp:404]     Test net output #0: accuracy = 0.769
I0813 12:46:34.382912 18283 solver.cpp:404]     Test net output #1: loss = 1.04278 (* 1 = 1.04278 loss)
I0813 12:46:35.196626 18283 solver.cpp:228] Iteration 17800, loss = 0.0629579
I0813 12:46:35.196688 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:46:35.196702 18283 solver.cpp:244]     Train net output #1: loss = 0.0629579 (* 1 = 0.0629579 loss)
I0813 12:46:35.196718 18283 sgd_solver.cpp:106] Iteration 17800, lr = 0.00464479
I0813 12:47:16.646164 18283 solver.cpp:228] Iteration 17850, loss = 0.0203697
I0813 12:47:16.646325 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:47:16.646339 18283 solver.cpp:244]     Train net output #1: loss = 0.0203698 (* 1 = 0.0203698 loss)
I0813 12:47:16.646351 18283 sgd_solver.cpp:106] Iteration 17850, lr = 0.00463854
I0813 12:47:57.444155 18283 solver.cpp:337] Iteration 17900, Testing net (#0)
I0813 12:48:01.512794 18283 solver.cpp:404]     Test net output #0: accuracy = 0.783
I0813 12:48:01.512861 18283 solver.cpp:404]     Test net output #1: loss = 0.937881 (* 1 = 0.937881 loss)
I0813 12:48:02.324102 18283 solver.cpp:228] Iteration 17900, loss = 0.0135946
I0813 12:48:02.324169 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:48:02.324182 18283 solver.cpp:244]     Train net output #1: loss = 0.0135947 (* 1 = 0.0135947 loss)
I0813 12:48:02.324198 18283 sgd_solver.cpp:106] Iteration 17900, lr = 0.0046323
I0813 12:48:43.494549 18283 solver.cpp:228] Iteration 17950, loss = 0.0330773
I0813 12:48:43.494719 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:48:43.494770 18283 solver.cpp:244]     Train net output #1: loss = 0.0330773 (* 1 = 0.0330773 loss)
I0813 12:48:43.494792 18283 sgd_solver.cpp:106] Iteration 17950, lr = 0.00462609
I0813 12:49:24.104674 18283 solver.cpp:337] Iteration 18000, Testing net (#0)
I0813 12:49:28.152653 18283 solver.cpp:404]     Test net output #0: accuracy = 0.783
I0813 12:49:28.152720 18283 solver.cpp:404]     Test net output #1: loss = 0.895303 (* 1 = 0.895303 loss)
I0813 12:49:28.964609 18283 solver.cpp:228] Iteration 18000, loss = 0.00744285
I0813 12:49:28.964669 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:49:28.964681 18283 solver.cpp:244]     Train net output #1: loss = 0.00744286 (* 1 = 0.00744286 loss)
I0813 12:49:28.964697 18283 sgd_solver.cpp:106] Iteration 18000, lr = 0.00461989
I0813 12:50:10.117136 18283 solver.cpp:228] Iteration 18050, loss = 0.0369899
I0813 12:50:10.117287 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:50:10.117301 18283 solver.cpp:244]     Train net output #1: loss = 0.0369899 (* 1 = 0.0369899 loss)
I0813 12:50:10.117313 18283 sgd_solver.cpp:106] Iteration 18050, lr = 0.00461371
I0813 12:50:50.418087 18283 solver.cpp:337] Iteration 18100, Testing net (#0)
I0813 12:50:54.464624 18283 solver.cpp:404]     Test net output #0: accuracy = 0.727
I0813 12:50:54.464691 18283 solver.cpp:404]     Test net output #1: loss = 1.42667 (* 1 = 1.42667 loss)
I0813 12:50:55.276718 18283 solver.cpp:228] Iteration 18100, loss = 0.0792725
I0813 12:50:55.276770 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 12:50:55.276782 18283 solver.cpp:244]     Train net output #1: loss = 0.0792725 (* 1 = 0.0792725 loss)
I0813 12:50:55.276799 18283 sgd_solver.cpp:106] Iteration 18100, lr = 0.00460755
I0813 12:51:36.741319 18283 solver.cpp:228] Iteration 18150, loss = 0.00693154
I0813 12:51:36.741557 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:51:36.741614 18283 solver.cpp:244]     Train net output #1: loss = 0.00693155 (* 1 = 0.00693155 loss)
I0813 12:51:36.741631 18283 sgd_solver.cpp:106] Iteration 18150, lr = 0.00460141
I0813 12:52:17.469122 18283 solver.cpp:337] Iteration 18200, Testing net (#0)
I0813 12:52:21.514113 18283 solver.cpp:404]     Test net output #0: accuracy = 0.731
I0813 12:52:21.514181 18283 solver.cpp:404]     Test net output #1: loss = 1.33813 (* 1 = 1.33813 loss)
I0813 12:52:22.326287 18283 solver.cpp:228] Iteration 18200, loss = 0.013607
I0813 12:52:22.326340 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:52:22.326351 18283 solver.cpp:244]     Train net output #1: loss = 0.013607 (* 1 = 0.013607 loss)
I0813 12:52:22.326364 18283 sgd_solver.cpp:106] Iteration 18200, lr = 0.00459529
I0813 12:53:03.482975 18283 solver.cpp:228] Iteration 18250, loss = 0.0288486
I0813 12:53:03.483191 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:53:03.483248 18283 solver.cpp:244]     Train net output #1: loss = 0.0288486 (* 1 = 0.0288486 loss)
I0813 12:53:03.483280 18283 sgd_solver.cpp:106] Iteration 18250, lr = 0.00458919
I0813 12:53:43.844990 18283 solver.cpp:337] Iteration 18300, Testing net (#0)
I0813 12:53:47.902724 18283 solver.cpp:404]     Test net output #0: accuracy = 0.791
I0813 12:53:47.902796 18283 solver.cpp:404]     Test net output #1: loss = 0.886504 (* 1 = 0.886504 loss)
I0813 12:53:48.715857 18283 solver.cpp:228] Iteration 18300, loss = 0.00663226
I0813 12:53:48.715924 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:53:48.715936 18283 solver.cpp:244]     Train net output #1: loss = 0.00663227 (* 1 = 0.00663227 loss)
I0813 12:53:48.715950 18283 sgd_solver.cpp:106] Iteration 18300, lr = 0.00458311
I0813 12:54:29.902295 18283 solver.cpp:228] Iteration 18350, loss = 0.0271901
I0813 12:54:29.902461 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:54:29.902475 18283 solver.cpp:244]     Train net output #1: loss = 0.0271901 (* 1 = 0.0271901 loss)
I0813 12:54:29.902487 18283 sgd_solver.cpp:106] Iteration 18350, lr = 0.00457704
I0813 12:55:10.256361 18283 solver.cpp:337] Iteration 18400, Testing net (#0)
I0813 12:55:14.306782 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 12:55:14.306848 18283 solver.cpp:404]     Test net output #1: loss = 1.11841 (* 1 = 1.11841 loss)
I0813 12:55:15.118638 18283 solver.cpp:228] Iteration 18400, loss = 0.0246908
I0813 12:55:15.118692 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:55:15.118705 18283 solver.cpp:244]     Train net output #1: loss = 0.0246908 (* 1 = 0.0246908 loss)
I0813 12:55:15.118721 18283 sgd_solver.cpp:106] Iteration 18400, lr = 0.004571
I0813 12:55:56.249586 18283 solver.cpp:228] Iteration 18450, loss = 0.023679
I0813 12:55:56.249742 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:55:56.249757 18283 solver.cpp:244]     Train net output #1: loss = 0.023679 (* 1 = 0.023679 loss)
I0813 12:55:56.249768 18283 sgd_solver.cpp:106] Iteration 18450, lr = 0.00456497
I0813 12:56:36.566251 18283 solver.cpp:337] Iteration 18500, Testing net (#0)
I0813 12:56:40.907924 18283 solver.cpp:404]     Test net output #0: accuracy = 0.769
I0813 12:56:40.907994 18283 solver.cpp:404]     Test net output #1: loss = 1.03393 (* 1 = 1.03393 loss)
I0813 12:56:41.722162 18283 solver.cpp:228] Iteration 18500, loss = 0.0238261
I0813 12:56:41.722223 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:56:41.722234 18283 solver.cpp:244]     Train net output #1: loss = 0.0238261 (* 1 = 0.0238261 loss)
I0813 12:56:41.722250 18283 sgd_solver.cpp:106] Iteration 18500, lr = 0.00455897
I0813 12:57:22.905784 18283 solver.cpp:228] Iteration 18550, loss = 0.00229991
I0813 12:57:22.905987 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:57:22.906044 18283 solver.cpp:244]     Train net output #1: loss = 0.00229991 (* 1 = 0.00229991 loss)
I0813 12:57:22.906069 18283 sgd_solver.cpp:106] Iteration 18550, lr = 0.00455298
I0813 12:58:03.150326 18283 solver.cpp:337] Iteration 18600, Testing net (#0)
I0813 12:58:07.212980 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 12:58:07.213047 18283 solver.cpp:404]     Test net output #1: loss = 1.04654 (* 1 = 1.04654 loss)
I0813 12:58:08.025781 18283 solver.cpp:228] Iteration 18600, loss = 0.0422033
I0813 12:58:08.025836 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:58:08.025848 18283 solver.cpp:244]     Train net output #1: loss = 0.0422033 (* 1 = 0.0422033 loss)
I0813 12:58:08.025866 18283 sgd_solver.cpp:106] Iteration 18600, lr = 0.00454701
I0813 12:58:50.002271 18283 solver.cpp:228] Iteration 18650, loss = 0.00708114
I0813 12:58:50.002429 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 12:58:50.002444 18283 solver.cpp:244]     Train net output #1: loss = 0.00708114 (* 1 = 0.00708114 loss)
I0813 12:58:50.002459 18283 sgd_solver.cpp:106] Iteration 18650, lr = 0.00454105
I0813 12:59:30.357329 18283 solver.cpp:337] Iteration 18700, Testing net (#0)
I0813 12:59:34.547339 18283 solver.cpp:404]     Test net output #0: accuracy = 0.782
I0813 12:59:34.547405 18283 solver.cpp:404]     Test net output #1: loss = 0.912222 (* 1 = 0.912222 loss)
I0813 12:59:35.360416 18283 solver.cpp:228] Iteration 18700, loss = 0.0467929
I0813 12:59:35.360489 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 12:59:35.360503 18283 solver.cpp:244]     Train net output #1: loss = 0.0467929 (* 1 = 0.0467929 loss)
I0813 12:59:35.360517 18283 sgd_solver.cpp:106] Iteration 18700, lr = 0.00453512
I0813 13:00:17.392380 18283 solver.cpp:228] Iteration 18750, loss = 0
I0813 13:00:17.392611 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:00:17.392655 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 13:00:17.392683 18283 sgd_solver.cpp:106] Iteration 18750, lr = 0.0045292
I0813 13:00:59.148015 18283 solver.cpp:337] Iteration 18800, Testing net (#0)
I0813 13:01:03.396303 18283 solver.cpp:404]     Test net output #0: accuracy = 0.77
I0813 13:01:03.396373 18283 solver.cpp:404]     Test net output #1: loss = 0.972448 (* 1 = 0.972448 loss)
I0813 13:01:04.395098 18283 solver.cpp:228] Iteration 18800, loss = 0.011288
I0813 13:01:04.395160 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:01:04.395174 18283 solver.cpp:244]     Train net output #1: loss = 0.011288 (* 1 = 0.011288 loss)
I0813 13:01:04.395186 18283 sgd_solver.cpp:106] Iteration 18800, lr = 0.0045233
I0813 13:01:46.478781 18283 solver.cpp:228] Iteration 18850, loss = 0.0581013
I0813 13:01:46.478950 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:01:46.478965 18283 solver.cpp:244]     Train net output #1: loss = 0.0581013 (* 1 = 0.0581013 loss)
I0813 13:01:46.478977 18283 sgd_solver.cpp:106] Iteration 18850, lr = 0.00451742
I0813 13:02:27.778744 18283 solver.cpp:337] Iteration 18900, Testing net (#0)
I0813 13:02:32.053390 18283 solver.cpp:404]     Test net output #0: accuracy = 0.779
I0813 13:02:32.053463 18283 solver.cpp:404]     Test net output #1: loss = 0.951405 (* 1 = 0.951405 loss)
I0813 13:02:32.867002 18283 solver.cpp:228] Iteration 18900, loss = 0.0460222
I0813 13:02:32.867068 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:02:32.867079 18283 solver.cpp:244]     Train net output #1: loss = 0.0460222 (* 1 = 0.0460222 loss)
I0813 13:02:32.867094 18283 sgd_solver.cpp:106] Iteration 18900, lr = 0.00451156
I0813 13:03:14.072789 18283 solver.cpp:228] Iteration 18950, loss = 0.0253269
I0813 13:03:14.072953 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:03:14.072968 18283 solver.cpp:244]     Train net output #1: loss = 0.0253269 (* 1 = 0.0253269 loss)
I0813 13:03:14.072978 18283 sgd_solver.cpp:106] Iteration 18950, lr = 0.00450571
I0813 13:03:54.418182 18283 solver.cpp:337] Iteration 19000, Testing net (#0)
I0813 13:03:58.596302 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 13:03:58.596369 18283 solver.cpp:404]     Test net output #1: loss = 1.23504 (* 1 = 1.23504 loss)
I0813 13:03:59.410117 18283 solver.cpp:228] Iteration 19000, loss = 0.00788711
I0813 13:03:59.410188 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:03:59.410202 18283 solver.cpp:244]     Train net output #1: loss = 0.00788712 (* 1 = 0.00788712 loss)
I0813 13:03:59.410217 18283 sgd_solver.cpp:106] Iteration 19000, lr = 0.00449989
I0813 13:04:41.647482 18283 solver.cpp:228] Iteration 19050, loss = 0.0139004
I0813 13:04:41.647712 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:04:41.647768 18283 solver.cpp:244]     Train net output #1: loss = 0.0139004 (* 1 = 0.0139004 loss)
I0813 13:04:41.647789 18283 sgd_solver.cpp:106] Iteration 19050, lr = 0.00449408
I0813 13:05:22.220705 18283 solver.cpp:337] Iteration 19100, Testing net (#0)
I0813 13:05:26.528429 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 13:05:26.528496 18283 solver.cpp:404]     Test net output #1: loss = 1.2251 (* 1 = 1.2251 loss)
I0813 13:05:27.342787 18283 solver.cpp:228] Iteration 19100, loss = 0.0179318
I0813 13:05:27.342849 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:05:27.342861 18283 solver.cpp:244]     Train net output #1: loss = 0.0179318 (* 1 = 0.0179318 loss)
I0813 13:05:27.342875 18283 sgd_solver.cpp:106] Iteration 19100, lr = 0.00448828
I0813 13:06:08.521236 18283 solver.cpp:228] Iteration 19150, loss = 0.0172173
I0813 13:06:08.521455 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:06:08.521515 18283 solver.cpp:244]     Train net output #1: loss = 0.0172173 (* 1 = 0.0172173 loss)
I0813 13:06:08.521543 18283 sgd_solver.cpp:106] Iteration 19150, lr = 0.00448251
I0813 13:06:49.181098 18283 solver.cpp:337] Iteration 19200, Testing net (#0)
I0813 13:06:53.238052 18283 solver.cpp:404]     Test net output #0: accuracy = 0.765
I0813 13:06:53.238116 18283 solver.cpp:404]     Test net output #1: loss = 1.06646 (* 1 = 1.06646 loss)
I0813 13:06:54.050967 18283 solver.cpp:228] Iteration 19200, loss = 0.0250531
I0813 13:06:54.051035 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 13:06:54.051048 18283 solver.cpp:244]     Train net output #1: loss = 0.0250531 (* 1 = 0.0250531 loss)
I0813 13:06:54.051060 18283 sgd_solver.cpp:106] Iteration 19200, lr = 0.00447675
I0813 13:07:35.234036 18283 solver.cpp:228] Iteration 19250, loss = 0.0109114
I0813 13:07:35.234235 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:07:35.234284 18283 solver.cpp:244]     Train net output #1: loss = 0.0109114 (* 1 = 0.0109114 loss)
I0813 13:07:35.234309 18283 sgd_solver.cpp:106] Iteration 19250, lr = 0.00447101
I0813 13:08:15.917855 18283 solver.cpp:337] Iteration 19300, Testing net (#0)
I0813 13:08:19.982251 18283 solver.cpp:404]     Test net output #0: accuracy = 0.765
I0813 13:08:19.982321 18283 solver.cpp:404]     Test net output #1: loss = 1.08628 (* 1 = 1.08628 loss)
I0813 13:08:20.796036 18283 solver.cpp:228] Iteration 19300, loss = 0.0410063
I0813 13:08:20.796094 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 13:08:20.796106 18283 solver.cpp:244]     Train net output #1: loss = 0.0410063 (* 1 = 0.0410063 loss)
I0813 13:08:20.796118 18283 sgd_solver.cpp:106] Iteration 19300, lr = 0.00446529
I0813 13:09:01.981425 18283 solver.cpp:228] Iteration 19350, loss = -5.58794e-09
I0813 13:09:01.981627 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:09:01.981679 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 13:09:01.981705 18283 sgd_solver.cpp:106] Iteration 19350, lr = 0.00445958
I0813 13:09:42.409195 18283 solver.cpp:337] Iteration 19400, Testing net (#0)
I0813 13:09:46.602321 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 13:09:46.602394 18283 solver.cpp:404]     Test net output #1: loss = 1.07265 (* 1 = 1.07265 loss)
I0813 13:09:47.415802 18283 solver.cpp:228] Iteration 19400, loss = 0.0195951
I0813 13:09:47.415869 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:09:47.415884 18283 solver.cpp:244]     Train net output #1: loss = 0.0195951 (* 1 = 0.0195951 loss)
I0813 13:09:47.415896 18283 sgd_solver.cpp:106] Iteration 19400, lr = 0.00445389
I0813 13:10:28.603953 18283 solver.cpp:228] Iteration 19450, loss = 0.00317054
I0813 13:10:28.604156 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:10:28.604174 18283 solver.cpp:244]     Train net output #1: loss = 0.00317055 (* 1 = 0.00317055 loss)
I0813 13:10:28.604188 18283 sgd_solver.cpp:106] Iteration 19450, lr = 0.00444822
I0813 13:11:08.986721 18283 solver.cpp:337] Iteration 19500, Testing net (#0)
I0813 13:11:13.036352 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 13:11:13.036427 18283 solver.cpp:404]     Test net output #1: loss = 1.13749 (* 1 = 1.13749 loss)
I0813 13:11:13.848111 18283 solver.cpp:228] Iteration 19500, loss = 0.0373935
I0813 13:11:13.848165 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 13:11:13.848177 18283 solver.cpp:244]     Train net output #1: loss = 0.0373935 (* 1 = 0.0373935 loss)
I0813 13:11:13.848196 18283 sgd_solver.cpp:106] Iteration 19500, lr = 0.00444256
I0813 13:11:55.017750 18283 solver.cpp:228] Iteration 19550, loss = 0.00202238
I0813 13:11:55.017918 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:11:55.017932 18283 solver.cpp:244]     Train net output #1: loss = 0.00202239 (* 1 = 0.00202239 loss)
I0813 13:11:55.017946 18283 sgd_solver.cpp:106] Iteration 19550, lr = 0.00443692
I0813 13:12:35.399550 18283 solver.cpp:337] Iteration 19600, Testing net (#0)
I0813 13:12:39.677140 18283 solver.cpp:404]     Test net output #0: accuracy = 0.767
I0813 13:12:39.677204 18283 solver.cpp:404]     Test net output #1: loss = 1.11562 (* 1 = 1.11562 loss)
I0813 13:12:40.490556 18283 solver.cpp:228] Iteration 19600, loss = 0.0367395
I0813 13:12:40.490604 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 13:12:40.490617 18283 solver.cpp:244]     Train net output #1: loss = 0.0367395 (* 1 = 0.0367395 loss)
I0813 13:12:40.490628 18283 sgd_solver.cpp:106] Iteration 19600, lr = 0.0044313
I0813 13:13:21.649801 18283 solver.cpp:228] Iteration 19650, loss = 0.0103416
I0813 13:13:21.649967 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:13:21.649981 18283 solver.cpp:244]     Train net output #1: loss = 0.0103417 (* 1 = 0.0103417 loss)
I0813 13:13:21.649996 18283 sgd_solver.cpp:106] Iteration 19650, lr = 0.0044257
I0813 13:14:02.009562 18283 solver.cpp:337] Iteration 19700, Testing net (#0)
I0813 13:14:06.072302 18283 solver.cpp:404]     Test net output #0: accuracy = 0.765
I0813 13:14:06.072371 18283 solver.cpp:404]     Test net output #1: loss = 1.06985 (* 1 = 1.06985 loss)
I0813 13:14:06.884057 18283 solver.cpp:228] Iteration 19700, loss = 0.000162547
I0813 13:14:06.884114 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:14:06.884126 18283 solver.cpp:244]     Train net output #1: loss = 0.000162559 (* 1 = 0.000162559 loss)
I0813 13:14:06.884142 18283 sgd_solver.cpp:106] Iteration 19700, lr = 0.00442011
I0813 13:14:48.056244 18283 solver.cpp:228] Iteration 19750, loss = 0.0197695
I0813 13:14:48.056403 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:14:48.056417 18283 solver.cpp:244]     Train net output #1: loss = 0.0197695 (* 1 = 0.0197695 loss)
I0813 13:14:48.056429 18283 sgd_solver.cpp:106] Iteration 19750, lr = 0.00441453
I0813 13:15:28.417217 18283 solver.cpp:337] Iteration 19800, Testing net (#0)
I0813 13:15:32.469588 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 13:15:32.469655 18283 solver.cpp:404]     Test net output #1: loss = 1.1727 (* 1 = 1.1727 loss)
I0813 13:15:33.282201 18283 solver.cpp:228] Iteration 19800, loss = 0.0227043
I0813 13:15:33.282260 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:15:33.282274 18283 solver.cpp:244]     Train net output #1: loss = 0.0227043 (* 1 = 0.0227043 loss)
I0813 13:15:33.282286 18283 sgd_solver.cpp:106] Iteration 19800, lr = 0.00440898
I0813 13:16:14.443363 18283 solver.cpp:228] Iteration 19850, loss = 0.0196632
I0813 13:16:14.443521 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:16:14.443536 18283 solver.cpp:244]     Train net output #1: loss = 0.0196632 (* 1 = 0.0196632 loss)
I0813 13:16:14.443549 18283 sgd_solver.cpp:106] Iteration 19850, lr = 0.00440344
I0813 13:16:54.794016 18283 solver.cpp:337] Iteration 19900, Testing net (#0)
I0813 13:16:59.260952 18283 solver.cpp:404]     Test net output #0: accuracy = 0.765
I0813 13:16:59.261013 18283 solver.cpp:404]     Test net output #1: loss = 1.09061 (* 1 = 1.09061 loss)
I0813 13:17:00.074398 18283 solver.cpp:228] Iteration 19900, loss = 0.0300743
I0813 13:17:00.074461 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 13:17:00.074475 18283 solver.cpp:244]     Train net output #1: loss = 0.0300743 (* 1 = 0.0300743 loss)
I0813 13:17:00.074491 18283 sgd_solver.cpp:106] Iteration 19900, lr = 0.00439791
I0813 13:17:41.239320 18283 solver.cpp:228] Iteration 19950, loss = 0.0384275
I0813 13:17:41.239526 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 13:17:41.239584 18283 solver.cpp:244]     Train net output #1: loss = 0.0384275 (* 1 = 0.0384275 loss)
I0813 13:17:41.239610 18283 sgd_solver.cpp:106] Iteration 19950, lr = 0.00439241
I0813 13:18:22.134788 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_20000.caffemodel
I0813 13:18:22.550035 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_20000.solverstate
I0813 13:18:22.564304 18283 solver.cpp:337] Iteration 20000, Testing net (#0)
I0813 13:18:26.643203 18283 solver.cpp:404]     Test net output #0: accuracy = 0.738
I0813 13:18:26.643275 18283 solver.cpp:404]     Test net output #1: loss = 1.26267 (* 1 = 1.26267 loss)
I0813 13:18:27.457309 18283 solver.cpp:228] Iteration 20000, loss = 0.0380189
I0813 13:18:27.457381 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:18:27.457393 18283 solver.cpp:244]     Train net output #1: loss = 0.0380189 (* 1 = 0.0380189 loss)
I0813 13:18:27.457411 18283 sgd_solver.cpp:106] Iteration 20000, lr = 0.00438691
I0813 13:19:08.666154 18283 solver.cpp:228] Iteration 20050, loss = 0.0334592
I0813 13:19:08.666324 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:19:08.666339 18283 solver.cpp:244]     Train net output #1: loss = 0.0334592 (* 1 = 0.0334592 loss)
I0813 13:19:08.666352 18283 sgd_solver.cpp:106] Iteration 20050, lr = 0.00438144
I0813 13:19:49.048252 18283 solver.cpp:337] Iteration 20100, Testing net (#0)
I0813 13:19:53.112174 18283 solver.cpp:404]     Test net output #0: accuracy = 0.729
I0813 13:19:53.112254 18283 solver.cpp:404]     Test net output #1: loss = 1.3903 (* 1 = 1.3903 loss)
I0813 13:19:53.926709 18283 solver.cpp:228] Iteration 20100, loss = 0.0421374
I0813 13:19:53.926769 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 13:19:53.926781 18283 solver.cpp:244]     Train net output #1: loss = 0.0421375 (* 1 = 0.0421375 loss)
I0813 13:19:53.926797 18283 sgd_solver.cpp:106] Iteration 20100, lr = 0.00437598
I0813 13:20:35.101729 18283 solver.cpp:228] Iteration 20150, loss = 0.0212392
I0813 13:20:35.101889 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:20:35.101903 18283 solver.cpp:244]     Train net output #1: loss = 0.0212392 (* 1 = 0.0212392 loss)
I0813 13:20:35.101915 18283 sgd_solver.cpp:106] Iteration 20150, lr = 0.00437053
I0813 13:21:15.471138 18283 solver.cpp:337] Iteration 20200, Testing net (#0)
I0813 13:21:19.529789 18283 solver.cpp:404]     Test net output #0: accuracy = 0.769
I0813 13:21:19.529870 18283 solver.cpp:404]     Test net output #1: loss = 0.988578 (* 1 = 0.988578 loss)
I0813 13:21:20.342659 18283 solver.cpp:228] Iteration 20200, loss = 0.0147161
I0813 13:21:20.342718 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:21:20.342730 18283 solver.cpp:244]     Train net output #1: loss = 0.0147161 (* 1 = 0.0147161 loss)
I0813 13:21:20.342747 18283 sgd_solver.cpp:106] Iteration 20200, lr = 0.00436511
I0813 13:22:02.159097 18283 solver.cpp:228] Iteration 20250, loss = 0.000957812
I0813 13:22:02.159344 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:22:02.159409 18283 solver.cpp:244]     Train net output #1: loss = 0.000957844 (* 1 = 0.000957844 loss)
I0813 13:22:02.159442 18283 sgd_solver.cpp:106] Iteration 20250, lr = 0.00435969
I0813 13:22:43.879545 18283 solver.cpp:337] Iteration 20300, Testing net (#0)
I0813 13:22:48.071655 18283 solver.cpp:404]     Test net output #0: accuracy = 0.772
I0813 13:22:48.071723 18283 solver.cpp:404]     Test net output #1: loss = 0.952188 (* 1 = 0.952188 loss)
I0813 13:22:48.886016 18283 solver.cpp:228] Iteration 20300, loss = 0.00803162
I0813 13:22:48.886068 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:22:48.886078 18283 solver.cpp:244]     Train net output #1: loss = 0.00803165 (* 1 = 0.00803165 loss)
I0813 13:22:48.886096 18283 sgd_solver.cpp:106] Iteration 20300, lr = 0.0043543
I0813 13:23:30.598361 18283 solver.cpp:228] Iteration 20350, loss = 0.00278092
I0813 13:23:30.598587 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:23:30.598647 18283 solver.cpp:244]     Train net output #1: loss = 0.00278095 (* 1 = 0.00278095 loss)
I0813 13:23:30.598671 18283 sgd_solver.cpp:106] Iteration 20350, lr = 0.00434892
I0813 13:24:12.189507 18283 solver.cpp:337] Iteration 20400, Testing net (#0)
I0813 13:24:16.244316 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 13:24:16.244385 18283 solver.cpp:404]     Test net output #1: loss = 1.15483 (* 1 = 1.15483 loss)
I0813 13:24:17.057217 18283 solver.cpp:228] Iteration 20400, loss = 0.0203286
I0813 13:24:17.057270 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:24:17.057279 18283 solver.cpp:244]     Train net output #1: loss = 0.0203287 (* 1 = 0.0203287 loss)
I0813 13:24:17.057291 18283 sgd_solver.cpp:106] Iteration 20400, lr = 0.00434355
I0813 13:25:00.198101 18283 solver.cpp:228] Iteration 20450, loss = 0.0177966
I0813 13:25:00.198258 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:25:00.198272 18283 solver.cpp:244]     Train net output #1: loss = 0.0177967 (* 1 = 0.0177967 loss)
I0813 13:25:00.198284 18283 sgd_solver.cpp:106] Iteration 20450, lr = 0.0043382
I0813 13:25:40.571229 18283 solver.cpp:337] Iteration 20500, Testing net (#0)
I0813 13:25:44.835839 18283 solver.cpp:404]     Test net output #0: accuracy = 0.774
I0813 13:25:44.835911 18283 solver.cpp:404]     Test net output #1: loss = 0.932443 (* 1 = 0.932443 loss)
I0813 13:25:45.649381 18283 solver.cpp:228] Iteration 20500, loss = 0.019433
I0813 13:25:45.649449 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:25:45.649461 18283 solver.cpp:244]     Train net output #1: loss = 0.0194331 (* 1 = 0.0194331 loss)
I0813 13:25:45.649476 18283 sgd_solver.cpp:106] Iteration 20500, lr = 0.00433286
I0813 13:26:26.830180 18283 solver.cpp:228] Iteration 20550, loss = 0.0175049
I0813 13:26:26.830335 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:26:26.830349 18283 solver.cpp:244]     Train net output #1: loss = 0.0175049 (* 1 = 0.0175049 loss)
I0813 13:26:26.830361 18283 sgd_solver.cpp:106] Iteration 20550, lr = 0.00432754
I0813 13:27:07.358994 18283 solver.cpp:337] Iteration 20600, Testing net (#0)
I0813 13:27:11.607482 18283 solver.cpp:404]     Test net output #0: accuracy = 0.743
I0813 13:27:11.607545 18283 solver.cpp:404]     Test net output #1: loss = 1.15986 (* 1 = 1.15986 loss)
I0813 13:27:12.420778 18283 solver.cpp:228] Iteration 20600, loss = 0.0056794
I0813 13:27:12.420847 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:27:12.420860 18283 solver.cpp:244]     Train net output #1: loss = 0.00567942 (* 1 = 0.00567942 loss)
I0813 13:27:12.420873 18283 sgd_solver.cpp:106] Iteration 20600, lr = 0.00432224
I0813 13:27:54.404201 18283 solver.cpp:228] Iteration 20650, loss = 0.0168975
I0813 13:27:54.404359 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:27:54.404374 18283 solver.cpp:244]     Train net output #1: loss = 0.0168976 (* 1 = 0.0168976 loss)
I0813 13:27:54.404386 18283 sgd_solver.cpp:106] Iteration 20650, lr = 0.00431695
I0813 13:28:35.818960 18283 solver.cpp:337] Iteration 20700, Testing net (#0)
I0813 13:28:39.871254 18283 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0813 13:28:39.871322 18283 solver.cpp:404]     Test net output #1: loss = 1.02518 (* 1 = 1.02518 loss)
I0813 13:28:40.685614 18283 solver.cpp:228] Iteration 20700, loss = 0.0265758
I0813 13:28:40.685670 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:28:40.685681 18283 solver.cpp:244]     Train net output #1: loss = 0.0265759 (* 1 = 0.0265759 loss)
I0813 13:28:40.685699 18283 sgd_solver.cpp:106] Iteration 20700, lr = 0.00431168
I0813 13:29:21.868382 18283 solver.cpp:228] Iteration 20750, loss = -1.58325e-08
I0813 13:29:21.868618 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:29:21.868676 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 13:29:21.868703 18283 sgd_solver.cpp:106] Iteration 20750, lr = 0.00430642
I0813 13:30:02.409626 18283 solver.cpp:337] Iteration 20800, Testing net (#0)
I0813 13:30:06.469326 18283 solver.cpp:404]     Test net output #0: accuracy = 0.765
I0813 13:30:06.469395 18283 solver.cpp:404]     Test net output #1: loss = 0.967145 (* 1 = 0.967145 loss)
I0813 13:30:07.281255 18283 solver.cpp:228] Iteration 20800, loss = 0.013422
I0813 13:30:07.281304 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:30:07.281316 18283 solver.cpp:244]     Train net output #1: loss = 0.013422 (* 1 = 0.013422 loss)
I0813 13:30:07.281333 18283 sgd_solver.cpp:106] Iteration 20800, lr = 0.00430117
I0813 13:30:48.475975 18283 solver.cpp:228] Iteration 20850, loss = 0.0162169
I0813 13:30:48.476200 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:30:48.476261 18283 solver.cpp:244]     Train net output #1: loss = 0.0162169 (* 1 = 0.0162169 loss)
I0813 13:30:48.476289 18283 sgd_solver.cpp:106] Iteration 20850, lr = 0.00429594
I0813 13:31:29.514219 18283 solver.cpp:337] Iteration 20900, Testing net (#0)
I0813 13:31:33.734989 18283 solver.cpp:404]     Test net output #0: accuracy = 0.805
I0813 13:31:33.735056 18283 solver.cpp:404]     Test net output #1: loss = 0.822501 (* 1 = 0.822501 loss)
I0813 13:31:34.547830 18283 solver.cpp:228] Iteration 20900, loss = 0.0115776
I0813 13:31:34.547888 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:31:34.547899 18283 solver.cpp:244]     Train net output #1: loss = 0.0115776 (* 1 = 0.0115776 loss)
I0813 13:31:34.547914 18283 sgd_solver.cpp:106] Iteration 20900, lr = 0.00429073
I0813 13:32:15.714320 18283 solver.cpp:228] Iteration 20950, loss = 0.0181154
I0813 13:32:15.714481 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:32:15.714496 18283 solver.cpp:244]     Train net output #1: loss = 0.0181154 (* 1 = 0.0181154 loss)
I0813 13:32:15.714509 18283 sgd_solver.cpp:106] Iteration 20950, lr = 0.00428553
I0813 13:32:56.412508 18283 solver.cpp:337] Iteration 21000, Testing net (#0)
I0813 13:33:00.480551 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 13:33:00.480617 18283 solver.cpp:404]     Test net output #1: loss = 1.11271 (* 1 = 1.11271 loss)
I0813 13:33:01.293686 18283 solver.cpp:228] Iteration 21000, loss = 0.000531163
I0813 13:33:01.293742 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:33:01.293754 18283 solver.cpp:244]     Train net output #1: loss = 0.000531187 (* 1 = 0.000531187 loss)
I0813 13:33:01.293771 18283 sgd_solver.cpp:106] Iteration 21000, lr = 0.00428034
I0813 13:33:42.907315 18283 solver.cpp:228] Iteration 21050, loss = 0.00783486
I0813 13:33:42.907479 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:33:42.907493 18283 solver.cpp:244]     Train net output #1: loss = 0.00783488 (* 1 = 0.00783488 loss)
I0813 13:33:42.907507 18283 sgd_solver.cpp:106] Iteration 21050, lr = 0.00427517
I0813 13:34:23.311606 18283 solver.cpp:337] Iteration 21100, Testing net (#0)
I0813 13:34:27.367172 18283 solver.cpp:404]     Test net output #0: accuracy = 0.776
I0813 13:34:27.367254 18283 solver.cpp:404]     Test net output #1: loss = 0.939723 (* 1 = 0.939723 loss)
I0813 13:34:28.181299 18283 solver.cpp:228] Iteration 21100, loss = 0.0142055
I0813 13:34:28.181360 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:34:28.181373 18283 solver.cpp:244]     Train net output #1: loss = 0.0142055 (* 1 = 0.0142055 loss)
I0813 13:34:28.181390 18283 sgd_solver.cpp:106] Iteration 21100, lr = 0.00427002
I0813 13:35:09.901255 18283 solver.cpp:228] Iteration 21150, loss = 0.0218067
I0813 13:35:09.901504 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:35:09.901557 18283 solver.cpp:244]     Train net output #1: loss = 0.0218067 (* 1 = 0.0218067 loss)
I0813 13:35:09.901588 18283 sgd_solver.cpp:106] Iteration 21150, lr = 0.00426488
I0813 13:35:50.470396 18283 solver.cpp:337] Iteration 21200, Testing net (#0)
I0813 13:35:54.903771 18283 solver.cpp:404]     Test net output #0: accuracy = 0.768
I0813 13:35:54.903846 18283 solver.cpp:404]     Test net output #1: loss = 0.992577 (* 1 = 0.992577 loss)
I0813 13:35:55.719079 18283 solver.cpp:228] Iteration 21200, loss = 0.00584671
I0813 13:35:55.719151 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:35:55.719166 18283 solver.cpp:244]     Train net output #1: loss = 0.00584673 (* 1 = 0.00584673 loss)
I0813 13:35:55.719180 18283 sgd_solver.cpp:106] Iteration 21200, lr = 0.00425975
I0813 13:36:37.140806 18283 solver.cpp:228] Iteration 21250, loss = -2.42144e-08
I0813 13:36:37.141010 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:36:37.141059 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 13:36:37.141078 18283 sgd_solver.cpp:106] Iteration 21250, lr = 0.00425464
I0813 13:37:18.610311 18283 solver.cpp:337] Iteration 21300, Testing net (#0)
I0813 13:37:22.882007 18283 solver.cpp:404]     Test net output #0: accuracy = 0.779
I0813 13:37:22.882081 18283 solver.cpp:404]     Test net output #1: loss = 0.925693 (* 1 = 0.925693 loss)
I0813 13:37:23.781577 18283 solver.cpp:228] Iteration 21300, loss = 0.0324355
I0813 13:37:23.781635 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 13:37:23.781647 18283 solver.cpp:244]     Train net output #1: loss = 0.0324355 (* 1 = 0.0324355 loss)
I0813 13:37:23.781666 18283 sgd_solver.cpp:106] Iteration 21300, lr = 0.00424954
I0813 13:38:04.972460 18283 solver.cpp:228] Iteration 21350, loss = 0.0108275
I0813 13:38:04.972618 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:38:04.972632 18283 solver.cpp:244]     Train net output #1: loss = 0.0108275 (* 1 = 0.0108275 loss)
I0813 13:38:04.972643 18283 sgd_solver.cpp:106] Iteration 21350, lr = 0.00424445
I0813 13:38:45.343852 18283 solver.cpp:337] Iteration 21400, Testing net (#0)
I0813 13:38:49.410177 18283 solver.cpp:404]     Test net output #0: accuracy = 0.765
I0813 13:38:49.410256 18283 solver.cpp:404]     Test net output #1: loss = 0.991528 (* 1 = 0.991528 loss)
I0813 13:38:50.223793 18283 solver.cpp:228] Iteration 21400, loss = 0.0158194
I0813 13:38:50.223845 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:38:50.223857 18283 solver.cpp:244]     Train net output #1: loss = 0.0158195 (* 1 = 0.0158195 loss)
I0813 13:38:50.223876 18283 sgd_solver.cpp:106] Iteration 21400, lr = 0.00423938
I0813 13:39:31.432445 18283 solver.cpp:228] Iteration 21450, loss = 0.0149842
I0813 13:39:31.432595 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:39:31.432608 18283 solver.cpp:244]     Train net output #1: loss = 0.0149842 (* 1 = 0.0149842 loss)
I0813 13:39:31.432621 18283 sgd_solver.cpp:106] Iteration 21450, lr = 0.00423433
I0813 13:40:12.671139 18283 solver.cpp:337] Iteration 21500, Testing net (#0)
I0813 13:40:16.736348 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 13:40:16.736413 18283 solver.cpp:404]     Test net output #1: loss = 1.12165 (* 1 = 1.12165 loss)
I0813 13:40:17.549047 18283 solver.cpp:228] Iteration 21500, loss = 0.0485445
I0813 13:40:17.549104 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:40:17.549115 18283 solver.cpp:244]     Train net output #1: loss = 0.0485445 (* 1 = 0.0485445 loss)
I0813 13:40:17.549134 18283 sgd_solver.cpp:106] Iteration 21500, lr = 0.00422929
I0813 13:40:59.632694 18283 solver.cpp:228] Iteration 21550, loss = 0.00687369
I0813 13:40:59.632884 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:40:59.632899 18283 solver.cpp:244]     Train net output #1: loss = 0.00687371 (* 1 = 0.00687371 loss)
I0813 13:40:59.632915 18283 sgd_solver.cpp:106] Iteration 21550, lr = 0.00422426
I0813 13:41:40.558060 18283 solver.cpp:337] Iteration 21600, Testing net (#0)
I0813 13:41:44.618043 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 13:41:44.618114 18283 solver.cpp:404]     Test net output #1: loss = 1.17843 (* 1 = 1.17843 loss)
I0813 13:41:45.430757 18283 solver.cpp:228] Iteration 21600, loss = 0.0229579
I0813 13:41:45.430826 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:41:45.430838 18283 solver.cpp:244]     Train net output #1: loss = 0.0229579 (* 1 = 0.0229579 loss)
I0813 13:41:45.430855 18283 sgd_solver.cpp:106] Iteration 21600, lr = 0.00421924
I0813 13:42:26.583592 18283 solver.cpp:228] Iteration 21650, loss = 0.00615103
I0813 13:42:26.583776 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:42:26.583837 18283 solver.cpp:244]     Train net output #1: loss = 0.00615105 (* 1 = 0.00615105 loss)
I0813 13:42:26.583859 18283 sgd_solver.cpp:106] Iteration 21650, lr = 0.00421424
I0813 13:43:07.120879 18283 solver.cpp:337] Iteration 21700, Testing net (#0)
I0813 13:43:11.584194 18283 solver.cpp:404]     Test net output #0: accuracy = 0.748
I0813 13:43:11.584259 18283 solver.cpp:404]     Test net output #1: loss = 1.11605 (* 1 = 1.11605 loss)
I0813 13:43:12.397975 18283 solver.cpp:228] Iteration 21700, loss = 0.0243136
I0813 13:43:12.398039 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:43:12.398051 18283 solver.cpp:244]     Train net output #1: loss = 0.0243136 (* 1 = 0.0243136 loss)
I0813 13:43:12.398066 18283 sgd_solver.cpp:106] Iteration 21700, lr = 0.00420926
I0813 13:43:53.573894 18283 solver.cpp:228] Iteration 21750, loss = 0.000628572
I0813 13:43:53.574126 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:43:53.574180 18283 solver.cpp:244]     Train net output #1: loss = 0.000628592 (* 1 = 0.000628592 loss)
I0813 13:43:53.574203 18283 sgd_solver.cpp:106] Iteration 21750, lr = 0.00420429
I0813 13:44:34.395473 18283 solver.cpp:337] Iteration 21800, Testing net (#0)
I0813 13:44:38.458351 18283 solver.cpp:404]     Test net output #0: accuracy = 0.738
I0813 13:44:38.458417 18283 solver.cpp:404]     Test net output #1: loss = 1.14997 (* 1 = 1.14997 loss)
I0813 13:44:39.271095 18283 solver.cpp:228] Iteration 21800, loss = 0.0150792
I0813 13:44:39.271152 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:44:39.271162 18283 solver.cpp:244]     Train net output #1: loss = 0.0150792 (* 1 = 0.0150792 loss)
I0813 13:44:39.271181 18283 sgd_solver.cpp:106] Iteration 21800, lr = 0.00419933
I0813 13:45:21.091080 18283 solver.cpp:228] Iteration 21850, loss = 0.00995872
I0813 13:45:21.091233 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:45:21.091248 18283 solver.cpp:244]     Train net output #1: loss = 0.00995874 (* 1 = 0.00995874 loss)
I0813 13:45:21.091260 18283 sgd_solver.cpp:106] Iteration 21850, lr = 0.00419438
I0813 13:46:02.011941 18283 solver.cpp:337] Iteration 21900, Testing net (#0)
I0813 13:46:06.100219 18283 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0813 13:46:06.100286 18283 solver.cpp:404]     Test net output #1: loss = 1.00593 (* 1 = 1.00593 loss)
I0813 13:46:06.913077 18283 solver.cpp:228] Iteration 21900, loss = 0.0162293
I0813 13:46:06.913131 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:46:06.913146 18283 solver.cpp:244]     Train net output #1: loss = 0.0162293 (* 1 = 0.0162293 loss)
I0813 13:46:06.913162 18283 sgd_solver.cpp:106] Iteration 21900, lr = 0.00418945
I0813 13:46:49.515619 18283 solver.cpp:228] Iteration 21950, loss = 0.026126
I0813 13:46:49.515858 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:46:49.515905 18283 solver.cpp:244]     Train net output #1: loss = 0.026126 (* 1 = 0.026126 loss)
I0813 13:46:49.515925 18283 sgd_solver.cpp:106] Iteration 21950, lr = 0.00418453
I0813 13:47:30.356139 18283 solver.cpp:337] Iteration 22000, Testing net (#0)
I0813 13:47:34.409216 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 13:47:34.409288 18283 solver.cpp:404]     Test net output #1: loss = 1.0419 (* 1 = 1.0419 loss)
I0813 13:47:35.222093 18283 solver.cpp:228] Iteration 22000, loss = 0.00751822
I0813 13:47:35.222152 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:47:35.222163 18283 solver.cpp:244]     Train net output #1: loss = 0.00751824 (* 1 = 0.00751824 loss)
I0813 13:47:35.222175 18283 sgd_solver.cpp:106] Iteration 22000, lr = 0.00417963
I0813 13:48:16.383709 18283 solver.cpp:228] Iteration 22050, loss = 0.0376878
I0813 13:48:16.383862 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 13:48:16.383877 18283 solver.cpp:244]     Train net output #1: loss = 0.0376878 (* 1 = 0.0376878 loss)
I0813 13:48:16.383889 18283 sgd_solver.cpp:106] Iteration 22050, lr = 0.00417474
I0813 13:48:56.730703 18283 solver.cpp:337] Iteration 22100, Testing net (#0)
I0813 13:49:00.794430 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 13:49:00.794499 18283 solver.cpp:404]     Test net output #1: loss = 1.10773 (* 1 = 1.10773 loss)
I0813 13:49:01.607535 18283 solver.cpp:228] Iteration 22100, loss = 0.022725
I0813 13:49:01.607599 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:49:01.607609 18283 solver.cpp:244]     Train net output #1: loss = 0.022725 (* 1 = 0.022725 loss)
I0813 13:49:01.607625 18283 sgd_solver.cpp:106] Iteration 22100, lr = 0.00416986
I0813 13:49:43.780472 18283 solver.cpp:228] Iteration 22150, loss = 0.0191271
I0813 13:49:43.780638 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:49:43.780653 18283 solver.cpp:244]     Train net output #1: loss = 0.0191272 (* 1 = 0.0191272 loss)
I0813 13:49:43.780664 18283 sgd_solver.cpp:106] Iteration 22150, lr = 0.00416499
I0813 13:50:24.134675 18283 solver.cpp:337] Iteration 22200, Testing net (#0)
I0813 13:50:28.187088 18283 solver.cpp:404]     Test net output #0: accuracy = 0.774
I0813 13:50:28.187170 18283 solver.cpp:404]     Test net output #1: loss = 0.97154 (* 1 = 0.97154 loss)
I0813 13:50:29.000756 18283 solver.cpp:228] Iteration 22200, loss = 0.00945152
I0813 13:50:29.000811 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:50:29.000823 18283 solver.cpp:244]     Train net output #1: loss = 0.00945153 (* 1 = 0.00945153 loss)
I0813 13:50:29.000834 18283 sgd_solver.cpp:106] Iteration 22200, lr = 0.00416014
I0813 13:51:10.188516 18283 solver.cpp:228] Iteration 22250, loss = 0.00180585
I0813 13:51:10.188676 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:51:10.188691 18283 solver.cpp:244]     Train net output #1: loss = 0.00180585 (* 1 = 0.00180585 loss)
I0813 13:51:10.188704 18283 sgd_solver.cpp:106] Iteration 22250, lr = 0.0041553
I0813 13:51:50.552582 18283 solver.cpp:337] Iteration 22300, Testing net (#0)
I0813 13:51:54.612766 18283 solver.cpp:404]     Test net output #0: accuracy = 0.737
I0813 13:51:54.612840 18283 solver.cpp:404]     Test net output #1: loss = 1.24608 (* 1 = 1.24608 loss)
I0813 13:51:55.425897 18283 solver.cpp:228] Iteration 22300, loss = 0.0141591
I0813 13:51:55.425964 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:51:55.425976 18283 solver.cpp:244]     Train net output #1: loss = 0.0141591 (* 1 = 0.0141591 loss)
I0813 13:51:55.425993 18283 sgd_solver.cpp:106] Iteration 22300, lr = 0.00415048
I0813 13:52:37.116674 18283 solver.cpp:228] Iteration 22350, loss = 0.011637
I0813 13:52:37.116892 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:52:37.116966 18283 solver.cpp:244]     Train net output #1: loss = 0.011637 (* 1 = 0.011637 loss)
I0813 13:52:37.116987 18283 sgd_solver.cpp:106] Iteration 22350, lr = 0.00414567
I0813 13:53:17.835420 18283 solver.cpp:337] Iteration 22400, Testing net (#0)
I0813 13:53:21.898403 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 13:53:21.898469 18283 solver.cpp:404]     Test net output #1: loss = 1.09182 (* 1 = 1.09182 loss)
I0813 13:53:22.710990 18283 solver.cpp:228] Iteration 22400, loss = 0.0120337
I0813 13:53:22.711042 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:53:22.711053 18283 solver.cpp:244]     Train net output #1: loss = 0.0120337 (* 1 = 0.0120337 loss)
I0813 13:53:22.711071 18283 sgd_solver.cpp:106] Iteration 22400, lr = 0.00414087
I0813 13:54:03.883373 18283 solver.cpp:228] Iteration 22450, loss = 0.00146754
I0813 13:54:03.883612 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:54:03.883668 18283 solver.cpp:244]     Train net output #1: loss = 0.00146756 (* 1 = 0.00146756 loss)
I0813 13:54:03.883690 18283 sgd_solver.cpp:106] Iteration 22450, lr = 0.00413608
I0813 13:54:44.281033 18283 solver.cpp:337] Iteration 22500, Testing net (#0)
I0813 13:54:48.343694 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 13:54:48.343763 18283 solver.cpp:404]     Test net output #1: loss = 1.02014 (* 1 = 1.02014 loss)
I0813 13:54:49.156951 18283 solver.cpp:228] Iteration 22500, loss = 0.00507845
I0813 13:54:49.157004 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:54:49.157016 18283 solver.cpp:244]     Train net output #1: loss = 0.00507847 (* 1 = 0.00507847 loss)
I0813 13:54:49.157027 18283 sgd_solver.cpp:106] Iteration 22500, lr = 0.00413131
I0813 13:55:30.318436 18283 solver.cpp:228] Iteration 22550, loss = 0.0136456
I0813 13:55:30.318629 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:55:30.318684 18283 solver.cpp:244]     Train net output #1: loss = 0.0136457 (* 1 = 0.0136457 loss)
I0813 13:55:30.318713 18283 sgd_solver.cpp:106] Iteration 22550, lr = 0.00412655
I0813 13:56:10.943071 18283 solver.cpp:337] Iteration 22600, Testing net (#0)
I0813 13:56:15.277992 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 13:56:15.278056 18283 solver.cpp:404]     Test net output #1: loss = 1.00661 (* 1 = 1.00661 loss)
I0813 13:56:16.091944 18283 solver.cpp:228] Iteration 22600, loss = 0.0192708
I0813 13:56:16.092011 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:56:16.092034 18283 solver.cpp:244]     Train net output #1: loss = 0.0192708 (* 1 = 0.0192708 loss)
I0813 13:56:16.092051 18283 sgd_solver.cpp:106] Iteration 22600, lr = 0.0041218
I0813 13:56:57.980865 18283 solver.cpp:228] Iteration 22650, loss = 0.00259349
I0813 13:56:57.981060 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:56:57.981112 18283 solver.cpp:244]     Train net output #1: loss = 0.0025935 (* 1 = 0.0025935 loss)
I0813 13:56:57.981132 18283 sgd_solver.cpp:106] Iteration 22650, lr = 0.00411706
I0813 13:57:39.381464 18283 solver.cpp:337] Iteration 22700, Testing net (#0)
I0813 13:57:43.437697 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 13:57:43.437769 18283 solver.cpp:404]     Test net output #1: loss = 1.05626 (* 1 = 1.05626 loss)
I0813 13:57:44.250224 18283 solver.cpp:228] Iteration 22700, loss = 0.00250479
I0813 13:57:44.250293 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:57:44.250304 18283 solver.cpp:244]     Train net output #1: loss = 0.0025048 (* 1 = 0.0025048 loss)
I0813 13:57:44.250321 18283 sgd_solver.cpp:106] Iteration 22700, lr = 0.00411234
I0813 13:58:26.435817 18283 solver.cpp:228] Iteration 22750, loss = 0.00386473
I0813 13:58:26.435966 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:58:26.435982 18283 solver.cpp:244]     Train net output #1: loss = 0.00386473 (* 1 = 0.00386473 loss)
I0813 13:58:26.435995 18283 sgd_solver.cpp:106] Iteration 22750, lr = 0.00410763
I0813 13:59:06.832252 18283 solver.cpp:337] Iteration 22800, Testing net (#0)
I0813 13:59:11.188211 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 13:59:11.188279 18283 solver.cpp:404]     Test net output #1: loss = 1.03751 (* 1 = 1.03751 loss)
I0813 13:59:12.000278 18283 solver.cpp:228] Iteration 22800, loss = 0.023392
I0813 13:59:12.000337 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:59:12.000349 18283 solver.cpp:244]     Train net output #1: loss = 0.023392 (* 1 = 0.023392 loss)
I0813 13:59:12.000370 18283 sgd_solver.cpp:106] Iteration 22800, lr = 0.00410293
I0813 13:59:53.179268 18283 solver.cpp:228] Iteration 22850, loss = 0.00323847
I0813 13:59:53.179484 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 13:59:53.179538 18283 solver.cpp:244]     Train net output #1: loss = 0.00323848 (* 1 = 0.00323848 loss)
I0813 13:59:53.179559 18283 sgd_solver.cpp:106] Iteration 22850, lr = 0.00409825
I0813 14:00:34.611192 18283 solver.cpp:337] Iteration 22900, Testing net (#0)
I0813 14:00:38.788317 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 14:00:38.788386 18283 solver.cpp:404]     Test net output #1: loss = 0.977875 (* 1 = 0.977875 loss)
I0813 14:00:39.601622 18283 solver.cpp:228] Iteration 22900, loss = 0.014843
I0813 14:00:39.601681 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:00:39.601692 18283 solver.cpp:244]     Train net output #1: loss = 0.014843 (* 1 = 0.014843 loss)
I0813 14:00:39.601711 18283 sgd_solver.cpp:106] Iteration 22900, lr = 0.00409358
I0813 14:01:21.770062 18283 solver.cpp:228] Iteration 22950, loss = 0.0251093
I0813 14:01:21.770215 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 14:01:21.770229 18283 solver.cpp:244]     Train net output #1: loss = 0.0251094 (* 1 = 0.0251094 loss)
I0813 14:01:21.770243 18283 sgd_solver.cpp:106] Iteration 22950, lr = 0.00408892
I0813 14:02:02.166527 18283 solver.cpp:337] Iteration 23000, Testing net (#0)
I0813 14:02:06.505077 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 14:02:06.505143 18283 solver.cpp:404]     Test net output #1: loss = 1.09413 (* 1 = 1.09413 loss)
I0813 14:02:07.318406 18283 solver.cpp:228] Iteration 23000, loss = 0.00207284
I0813 14:02:07.318475 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:02:07.318486 18283 solver.cpp:244]     Train net output #1: loss = 0.00207285 (* 1 = 0.00207285 loss)
I0813 14:02:07.318500 18283 sgd_solver.cpp:106] Iteration 23000, lr = 0.00408427
I0813 14:02:48.524325 18283 solver.cpp:228] Iteration 23050, loss = 0.0129541
I0813 14:02:48.524535 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:02:48.524590 18283 solver.cpp:244]     Train net output #1: loss = 0.0129541 (* 1 = 0.0129541 loss)
I0813 14:02:48.524616 18283 sgd_solver.cpp:106] Iteration 23050, lr = 0.00407964
I0813 14:03:29.622053 18283 solver.cpp:337] Iteration 23100, Testing net (#0)
I0813 14:03:33.976148 18283 solver.cpp:404]     Test net output #0: accuracy = 0.772
I0813 14:03:33.976218 18283 solver.cpp:404]     Test net output #1: loss = 0.939059 (* 1 = 0.939059 loss)
I0813 14:03:34.790761 18283 solver.cpp:228] Iteration 23100, loss = 0.0315031
I0813 14:03:34.790817 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:03:34.790828 18283 solver.cpp:244]     Train net output #1: loss = 0.0315031 (* 1 = 0.0315031 loss)
I0813 14:03:34.790846 18283 sgd_solver.cpp:106] Iteration 23100, lr = 0.00407501
I0813 14:04:15.941155 18283 solver.cpp:228] Iteration 23150, loss = 0.0156292
I0813 14:04:15.941316 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:04:15.941330 18283 solver.cpp:244]     Train net output #1: loss = 0.0156292 (* 1 = 0.0156292 loss)
I0813 14:04:15.941342 18283 sgd_solver.cpp:106] Iteration 23150, lr = 0.0040704
I0813 14:04:56.288805 18283 solver.cpp:337] Iteration 23200, Testing net (#0)
I0813 14:05:00.550068 18283 solver.cpp:404]     Test net output #0: accuracy = 0.764
I0813 14:05:00.550133 18283 solver.cpp:404]     Test net output #1: loss = 0.99324 (* 1 = 0.99324 loss)
I0813 14:05:01.361104 18283 solver.cpp:228] Iteration 23200, loss = 0.0128386
I0813 14:05:01.361155 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:05:01.361166 18283 solver.cpp:244]     Train net output #1: loss = 0.0128386 (* 1 = 0.0128386 loss)
I0813 14:05:01.361182 18283 sgd_solver.cpp:106] Iteration 23200, lr = 0.0040658
I0813 14:05:42.503454 18283 solver.cpp:228] Iteration 23250, loss = 0.00242573
I0813 14:05:42.503646 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:05:42.503662 18283 solver.cpp:244]     Train net output #1: loss = 0.00242574 (* 1 = 0.00242574 loss)
I0813 14:05:42.503675 18283 sgd_solver.cpp:106] Iteration 23250, lr = 0.00406122
I0813 14:06:22.852942 18283 solver.cpp:337] Iteration 23300, Testing net (#0)
I0813 14:06:27.224470 18283 solver.cpp:404]     Test net output #0: accuracy = 0.773
I0813 14:06:27.224537 18283 solver.cpp:404]     Test net output #1: loss = 0.954132 (* 1 = 0.954132 loss)
I0813 14:06:28.038102 18283 solver.cpp:228] Iteration 23300, loss = 9.8329e-05
I0813 14:06:28.038173 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:06:28.038185 18283 solver.cpp:244]     Train net output #1: loss = 9.83405e-05 (* 1 = 9.83405e-05 loss)
I0813 14:06:28.038200 18283 sgd_solver.cpp:106] Iteration 23300, lr = 0.00405664
I0813 14:07:09.897403 18283 solver.cpp:228] Iteration 23350, loss = 0.0179788
I0813 14:07:09.897568 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:07:09.897583 18283 solver.cpp:244]     Train net output #1: loss = 0.0179788 (* 1 = 0.0179788 loss)
I0813 14:07:09.897596 18283 sgd_solver.cpp:106] Iteration 23350, lr = 0.00405208
I0813 14:07:51.182687 18283 solver.cpp:337] Iteration 23400, Testing net (#0)
I0813 14:07:55.432536 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 14:07:55.432616 18283 solver.cpp:404]     Test net output #1: loss = 1.13728 (* 1 = 1.13728 loss)
I0813 14:07:56.245129 18283 solver.cpp:228] Iteration 23400, loss = 0.00575292
I0813 14:07:56.245193 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:07:56.245206 18283 solver.cpp:244]     Train net output #1: loss = 0.00575293 (* 1 = 0.00575293 loss)
I0813 14:07:56.245219 18283 sgd_solver.cpp:106] Iteration 23400, lr = 0.00404753
I0813 14:08:37.390548 18283 solver.cpp:228] Iteration 23450, loss = 0.00726818
I0813 14:08:37.390708 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:08:37.390722 18283 solver.cpp:244]     Train net output #1: loss = 0.00726818 (* 1 = 0.00726818 loss)
I0813 14:08:37.390733 18283 sgd_solver.cpp:106] Iteration 23450, lr = 0.00404299
I0813 14:09:17.710603 18283 solver.cpp:337] Iteration 23500, Testing net (#0)
I0813 14:09:22.198851 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 14:09:22.198915 18283 solver.cpp:404]     Test net output #1: loss = 1.00225 (* 1 = 1.00225 loss)
I0813 14:09:23.011854 18283 solver.cpp:228] Iteration 23500, loss = 0.0656707
I0813 14:09:23.011919 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 14:09:23.011932 18283 solver.cpp:244]     Train net output #1: loss = 0.0656708 (* 1 = 0.0656708 loss)
I0813 14:09:23.011947 18283 sgd_solver.cpp:106] Iteration 23500, lr = 0.00403847
I0813 14:10:04.190690 18283 solver.cpp:228] Iteration 23550, loss = 0.00739641
I0813 14:10:04.190855 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:10:04.190870 18283 solver.cpp:244]     Train net output #1: loss = 0.00739642 (* 1 = 0.00739642 loss)
I0813 14:10:04.190883 18283 sgd_solver.cpp:106] Iteration 23550, lr = 0.00403395
I0813 14:10:45.152462 18283 solver.cpp:337] Iteration 23600, Testing net (#0)
I0813 14:10:49.391791 18283 solver.cpp:404]     Test net output #0: accuracy = 0.742
I0813 14:10:49.391856 18283 solver.cpp:404]     Test net output #1: loss = 1.11115 (* 1 = 1.11115 loss)
I0813 14:10:50.204514 18283 solver.cpp:228] Iteration 23600, loss = 0.0194365
I0813 14:10:50.204583 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:10:50.204596 18283 solver.cpp:244]     Train net output #1: loss = 0.0194365 (* 1 = 0.0194365 loss)
I0813 14:10:50.204610 18283 sgd_solver.cpp:106] Iteration 23600, lr = 0.00402945
I0813 14:11:31.909875 18283 solver.cpp:228] Iteration 23650, loss = 0.0106116
I0813 14:11:31.910094 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:11:31.910145 18283 solver.cpp:244]     Train net output #1: loss = 0.0106116 (* 1 = 0.0106116 loss)
I0813 14:11:31.910166 18283 sgd_solver.cpp:106] Iteration 23650, lr = 0.00402496
I0813 14:12:13.515400 18283 solver.cpp:337] Iteration 23700, Testing net (#0)
I0813 14:12:17.577226 18283 solver.cpp:404]     Test net output #0: accuracy = 0.799
I0813 14:12:17.577293 18283 solver.cpp:404]     Test net output #1: loss = 0.812743 (* 1 = 0.812743 loss)
I0813 14:12:18.390830 18283 solver.cpp:228] Iteration 23700, loss = 0.0125181
I0813 14:12:18.390894 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:12:18.390908 18283 solver.cpp:244]     Train net output #1: loss = 0.0125182 (* 1 = 0.0125182 loss)
I0813 14:12:18.390923 18283 sgd_solver.cpp:106] Iteration 23700, lr = 0.00402048
I0813 14:13:00.846256 18283 solver.cpp:228] Iteration 23750, loss = 0.00620595
I0813 14:13:00.846495 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:13:00.846549 18283 solver.cpp:244]     Train net output #1: loss = 0.00620596 (* 1 = 0.00620596 loss)
I0813 14:13:00.846581 18283 sgd_solver.cpp:106] Iteration 23750, lr = 0.00401601
I0813 14:13:41.553987 18283 solver.cpp:337] Iteration 23800, Testing net (#0)
I0813 14:13:45.611619 18283 solver.cpp:404]     Test net output #0: accuracy = 0.74
I0813 14:13:45.611690 18283 solver.cpp:404]     Test net output #1: loss = 1.25731 (* 1 = 1.25731 loss)
I0813 14:13:46.425401 18283 solver.cpp:228] Iteration 23800, loss = 0.0121533
I0813 14:13:46.425457 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:13:46.425468 18283 solver.cpp:244]     Train net output #1: loss = 0.0121533 (* 1 = 0.0121533 loss)
I0813 14:13:46.425480 18283 sgd_solver.cpp:106] Iteration 23800, lr = 0.00401155
I0813 14:14:27.577417 18283 solver.cpp:228] Iteration 23850, loss = 0.00891038
I0813 14:14:27.577575 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:14:27.577589 18283 solver.cpp:244]     Train net output #1: loss = 0.0089104 (* 1 = 0.0089104 loss)
I0813 14:14:27.577601 18283 sgd_solver.cpp:106] Iteration 23850, lr = 0.00400711
I0813 14:15:08.714619 18283 solver.cpp:337] Iteration 23900, Testing net (#0)
I0813 14:15:13.039641 18283 solver.cpp:404]     Test net output #0: accuracy = 0.784
I0813 14:15:13.039707 18283 solver.cpp:404]     Test net output #1: loss = 0.926223 (* 1 = 0.926223 loss)
I0813 14:15:13.871884 18283 solver.cpp:228] Iteration 23900, loss = -2.04891e-08
I0813 14:15:13.871947 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:15:13.871958 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 14:15:13.871976 18283 sgd_solver.cpp:106] Iteration 23900, lr = 0.00400267
I0813 14:15:55.055826 18283 solver.cpp:228] Iteration 23950, loss = 0.00593341
I0813 14:15:55.055981 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:15:55.055995 18283 solver.cpp:244]     Train net output #1: loss = 0.00593343 (* 1 = 0.00593343 loss)
I0813 14:15:55.056007 18283 sgd_solver.cpp:106] Iteration 23950, lr = 0.00399825
I0813 14:16:35.410321 18283 solver.cpp:337] Iteration 24000, Testing net (#0)
I0813 14:16:39.458124 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 14:16:39.458189 18283 solver.cpp:404]     Test net output #1: loss = 1.04193 (* 1 = 1.04193 loss)
I0813 14:16:40.270314 18283 solver.cpp:228] Iteration 24000, loss = 0.0327042
I0813 14:16:40.270380 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 14:16:40.270393 18283 solver.cpp:244]     Train net output #1: loss = 0.0327042 (* 1 = 0.0327042 loss)
I0813 14:16:40.270411 18283 sgd_solver.cpp:106] Iteration 24000, lr = 0.00399384
I0813 14:17:21.394079 18283 solver.cpp:228] Iteration 24050, loss = 4.64637e-05
I0813 14:17:21.394242 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:17:21.394255 18283 solver.cpp:244]     Train net output #1: loss = 4.64857e-05 (* 1 = 4.64857e-05 loss)
I0813 14:17:21.394268 18283 sgd_solver.cpp:106] Iteration 24050, lr = 0.00398944
I0813 14:18:01.715905 18283 solver.cpp:337] Iteration 24100, Testing net (#0)
I0813 14:18:05.812613 18283 solver.cpp:404]     Test net output #0: accuracy = 0.776
I0813 14:18:05.812676 18283 solver.cpp:404]     Test net output #1: loss = 0.956882 (* 1 = 0.956882 loss)
I0813 14:18:06.625874 18283 solver.cpp:228] Iteration 24100, loss = 0.0131398
I0813 14:18:06.625929 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:18:06.625941 18283 solver.cpp:244]     Train net output #1: loss = 0.0131398 (* 1 = 0.0131398 loss)
I0813 14:18:06.625957 18283 sgd_solver.cpp:106] Iteration 24100, lr = 0.00398505
I0813 14:18:47.774832 18283 solver.cpp:228] Iteration 24150, loss = 0.00778396
I0813 14:18:47.774991 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:18:47.775004 18283 solver.cpp:244]     Train net output #1: loss = 0.00778398 (* 1 = 0.00778398 loss)
I0813 14:18:47.775017 18283 sgd_solver.cpp:106] Iteration 24150, lr = 0.00398068
I0813 14:19:28.542721 18283 solver.cpp:337] Iteration 24200, Testing net (#0)
I0813 14:19:32.606551 18283 solver.cpp:404]     Test net output #0: accuracy = 0.734
I0813 14:19:32.606631 18283 solver.cpp:404]     Test net output #1: loss = 1.13617 (* 1 = 1.13617 loss)
I0813 14:19:33.419715 18283 solver.cpp:228] Iteration 24200, loss = 0.00546649
I0813 14:19:33.419772 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:19:33.419783 18283 solver.cpp:244]     Train net output #1: loss = 0.00546651 (* 1 = 0.00546651 loss)
I0813 14:19:33.419798 18283 sgd_solver.cpp:106] Iteration 24200, lr = 0.00397631
I0813 14:20:15.089697 18283 solver.cpp:228] Iteration 24250, loss = 0.00339327
I0813 14:20:15.089941 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:20:15.089994 18283 solver.cpp:244]     Train net output #1: loss = 0.00339329 (* 1 = 0.00339329 loss)
I0813 14:20:15.090018 18283 sgd_solver.cpp:106] Iteration 24250, lr = 0.00397196
I0813 14:20:55.625823 18283 solver.cpp:337] Iteration 24300, Testing net (#0)
I0813 14:20:59.683719 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 14:20:59.683784 18283 solver.cpp:404]     Test net output #1: loss = 1.09084 (* 1 = 1.09084 loss)
I0813 14:21:00.497259 18283 solver.cpp:228] Iteration 24300, loss = 0.0122555
I0813 14:21:00.497313 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:21:00.497324 18283 solver.cpp:244]     Train net output #1: loss = 0.0122556 (* 1 = 0.0122556 loss)
I0813 14:21:00.497341 18283 sgd_solver.cpp:106] Iteration 24300, lr = 0.00396761
I0813 14:21:41.656946 18283 solver.cpp:228] Iteration 24350, loss = 0.00416944
I0813 14:21:41.657094 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:21:41.657109 18283 solver.cpp:244]     Train net output #1: loss = 0.00416946 (* 1 = 0.00416946 loss)
I0813 14:21:41.657120 18283 sgd_solver.cpp:106] Iteration 24350, lr = 0.00396328
I0813 14:22:21.992502 18283 solver.cpp:337] Iteration 24400, Testing net (#0)
I0813 14:22:26.043989 18283 solver.cpp:404]     Test net output #0: accuracy = 0.738
I0813 14:22:26.044065 18283 solver.cpp:404]     Test net output #1: loss = 1.17184 (* 1 = 1.17184 loss)
I0813 14:22:26.855878 18283 solver.cpp:228] Iteration 24400, loss = 0.00941831
I0813 14:22:26.855942 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:22:26.855954 18283 solver.cpp:244]     Train net output #1: loss = 0.00941832 (* 1 = 0.00941832 loss)
I0813 14:22:26.855968 18283 sgd_solver.cpp:106] Iteration 24400, lr = 0.00395896
I0813 14:23:07.983113 18283 solver.cpp:228] Iteration 24450, loss = 0.014798
I0813 14:23:07.983264 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:23:07.983279 18283 solver.cpp:244]     Train net output #1: loss = 0.014798 (* 1 = 0.014798 loss)
I0813 14:23:07.983291 18283 sgd_solver.cpp:106] Iteration 24450, lr = 0.00395465
I0813 14:23:48.327744 18283 solver.cpp:337] Iteration 24500, Testing net (#0)
I0813 14:23:52.574771 18283 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0813 14:23:52.574836 18283 solver.cpp:404]     Test net output #1: loss = 0.951151 (* 1 = 0.951151 loss)
I0813 14:23:53.386958 18283 solver.cpp:228] Iteration 24500, loss = 0.0145545
I0813 14:23:53.387014 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:23:53.387027 18283 solver.cpp:244]     Train net output #1: loss = 0.0145545 (* 1 = 0.0145545 loss)
I0813 14:23:53.387044 18283 sgd_solver.cpp:106] Iteration 24500, lr = 0.00395035
I0813 14:24:34.538105 18283 solver.cpp:228] Iteration 24550, loss = 0.00270414
I0813 14:24:34.538260 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:24:34.538275 18283 solver.cpp:244]     Train net output #1: loss = 0.00270415 (* 1 = 0.00270415 loss)
I0813 14:24:34.538286 18283 sgd_solver.cpp:106] Iteration 24550, lr = 0.00394606
I0813 14:25:14.881794 18283 solver.cpp:337] Iteration 24600, Testing net (#0)
I0813 14:25:18.935019 18283 solver.cpp:404]     Test net output #0: accuracy = 0.748
I0813 14:25:18.935091 18283 solver.cpp:404]     Test net output #1: loss = 1.07408 (* 1 = 1.07408 loss)
I0813 14:25:19.748453 18283 solver.cpp:228] Iteration 24600, loss = 0.0278029
I0813 14:25:19.748508 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:25:19.748519 18283 solver.cpp:244]     Train net output #1: loss = 0.0278029 (* 1 = 0.0278029 loss)
I0813 14:25:19.748538 18283 sgd_solver.cpp:106] Iteration 24600, lr = 0.00394178
I0813 14:26:00.912950 18283 solver.cpp:228] Iteration 24650, loss = 0.00204551
I0813 14:26:00.913137 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:26:00.913189 18283 solver.cpp:244]     Train net output #1: loss = 0.00204554 (* 1 = 0.00204554 loss)
I0813 14:26:00.913213 18283 sgd_solver.cpp:106] Iteration 24650, lr = 0.00393752
I0813 14:26:42.275703 18283 solver.cpp:337] Iteration 24700, Testing net (#0)
I0813 14:26:46.434911 18283 solver.cpp:404]     Test net output #0: accuracy = 0.748
I0813 14:26:46.434980 18283 solver.cpp:404]     Test net output #1: loss = 1.10036 (* 1 = 1.10036 loss)
I0813 14:26:47.248649 18283 solver.cpp:228] Iteration 24700, loss = 0.0220729
I0813 14:26:47.248706 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:26:47.248718 18283 solver.cpp:244]     Train net output #1: loss = 0.022073 (* 1 = 0.022073 loss)
I0813 14:26:47.248733 18283 sgd_solver.cpp:106] Iteration 24700, lr = 0.00393326
I0813 14:27:28.773742 18283 solver.cpp:228] Iteration 24750, loss = 0.016599
I0813 14:27:28.773902 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:27:28.773916 18283 solver.cpp:244]     Train net output #1: loss = 0.016599 (* 1 = 0.016599 loss)
I0813 14:27:28.773928 18283 sgd_solver.cpp:106] Iteration 24750, lr = 0.00392902
I0813 14:28:09.137444 18283 solver.cpp:337] Iteration 24800, Testing net (#0)
I0813 14:28:13.376852 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 14:28:13.376917 18283 solver.cpp:404]     Test net output #1: loss = 1.01506 (* 1 = 1.01506 loss)
I0813 14:28:14.188313 18283 solver.cpp:228] Iteration 24800, loss = 0.0120945
I0813 14:28:14.188364 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:28:14.188375 18283 solver.cpp:244]     Train net output #1: loss = 0.0120946 (* 1 = 0.0120946 loss)
I0813 14:28:14.188393 18283 sgd_solver.cpp:106] Iteration 24800, lr = 0.00392478
I0813 14:28:55.331699 18283 solver.cpp:228] Iteration 24850, loss = 0.00581306
I0813 14:28:55.331861 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:28:55.331876 18283 solver.cpp:244]     Train net output #1: loss = 0.00581307 (* 1 = 0.00581307 loss)
I0813 14:28:55.331888 18283 sgd_solver.cpp:106] Iteration 24850, lr = 0.00392056
I0813 14:29:35.672046 18283 solver.cpp:337] Iteration 24900, Testing net (#0)
I0813 14:29:40.054637 18283 solver.cpp:404]     Test net output #0: accuracy = 0.768
I0813 14:29:40.054702 18283 solver.cpp:404]     Test net output #1: loss = 0.923984 (* 1 = 0.923984 loss)
I0813 14:29:40.867180 18283 solver.cpp:228] Iteration 24900, loss = 0.0237622
I0813 14:29:40.867233 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:29:40.867244 18283 solver.cpp:244]     Train net output #1: loss = 0.0237622 (* 1 = 0.0237622 loss)
I0813 14:29:40.867261 18283 sgd_solver.cpp:106] Iteration 24900, lr = 0.00391634
I0813 14:30:22.019904 18283 solver.cpp:228] Iteration 24950, loss = -1.30385e-08
I0813 14:30:22.020192 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:30:22.020252 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 14:30:22.020289 18283 sgd_solver.cpp:106] Iteration 24950, lr = 0.00391214
I0813 14:31:03.511693 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_25000.caffemodel
I0813 14:31:03.962162 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_25000.solverstate
I0813 14:31:03.975672 18283 solver.cpp:337] Iteration 25000, Testing net (#0)
I0813 14:31:08.165503 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 14:31:08.165578 18283 solver.cpp:404]     Test net output #1: loss = 1.07417 (* 1 = 1.07417 loss)
I0813 14:31:08.979727 18283 solver.cpp:228] Iteration 25000, loss = 0.00165555
I0813 14:31:08.979796 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:31:08.979809 18283 solver.cpp:244]     Train net output #1: loss = 0.00165556 (* 1 = 0.00165556 loss)
I0813 14:31:08.979822 18283 sgd_solver.cpp:106] Iteration 25000, lr = 0.00390795
I0813 14:31:50.732458 18283 solver.cpp:228] Iteration 25050, loss = 7.39187e-06
I0813 14:31:50.732667 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:31:50.732715 18283 solver.cpp:244]     Train net output #1: loss = 7.39932e-06 (* 1 = 7.39932e-06 loss)
I0813 14:31:50.732740 18283 sgd_solver.cpp:106] Iteration 25050, lr = 0.00390377
I0813 14:32:31.813417 18283 solver.cpp:337] Iteration 25100, Testing net (#0)
I0813 14:32:35.872709 18283 solver.cpp:404]     Test net output #0: accuracy = 0.768
I0813 14:32:35.872773 18283 solver.cpp:404]     Test net output #1: loss = 0.972715 (* 1 = 0.972715 loss)
I0813 14:32:36.686007 18283 solver.cpp:228] Iteration 25100, loss = 0.018555
I0813 14:32:36.686069 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:32:36.686081 18283 solver.cpp:244]     Train net output #1: loss = 0.018555 (* 1 = 0.018555 loss)
I0813 14:32:36.686097 18283 sgd_solver.cpp:106] Iteration 25100, lr = 0.0038996
I0813 14:33:17.890758 18283 solver.cpp:228] Iteration 25150, loss = -8.3819e-09
I0813 14:33:17.890990 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:33:17.891041 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 14:33:17.891060 18283 sgd_solver.cpp:106] Iteration 25150, lr = 0.00389544
I0813 14:33:58.484904 18283 solver.cpp:337] Iteration 25200, Testing net (#0)
I0813 14:34:02.547390 18283 solver.cpp:404]     Test net output #0: accuracy = 0.732
I0813 14:34:02.547456 18283 solver.cpp:404]     Test net output #1: loss = 1.27821 (* 1 = 1.27821 loss)
I0813 14:34:03.360056 18283 solver.cpp:228] Iteration 25200, loss = 0.00937117
I0813 14:34:03.360111 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:34:03.360124 18283 solver.cpp:244]     Train net output #1: loss = 0.00937118 (* 1 = 0.00937118 loss)
I0813 14:34:03.360141 18283 sgd_solver.cpp:106] Iteration 25200, lr = 0.00389128
I0813 14:34:44.562577 18283 solver.cpp:228] Iteration 25250, loss = 0.0275148
I0813 14:34:44.562762 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:34:44.562826 18283 solver.cpp:244]     Train net output #1: loss = 0.0275148 (* 1 = 0.0275148 loss)
I0813 14:34:44.562861 18283 sgd_solver.cpp:106] Iteration 25250, lr = 0.00388714
I0813 14:35:25.788101 18283 solver.cpp:337] Iteration 25300, Testing net (#0)
I0813 14:35:30.184926 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 14:35:30.184991 18283 solver.cpp:404]     Test net output #1: loss = 0.959989 (* 1 = 0.959989 loss)
I0813 14:35:31.001938 18283 solver.cpp:228] Iteration 25300, loss = 0.0575839
I0813 14:35:31.002002 18283 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0813 14:35:31.002015 18283 solver.cpp:244]     Train net output #1: loss = 0.0575839 (* 1 = 0.0575839 loss)
I0813 14:35:31.002032 18283 sgd_solver.cpp:106] Iteration 25300, lr = 0.00388301
I0813 14:36:12.233503 18283 solver.cpp:228] Iteration 25350, loss = 0.0004855
I0813 14:36:12.233680 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:36:12.233696 18283 solver.cpp:244]     Train net output #1: loss = 0.000485507 (* 1 = 0.000485507 loss)
I0813 14:36:12.233721 18283 sgd_solver.cpp:106] Iteration 25350, lr = 0.00387889
I0813 14:36:53.699543 18283 solver.cpp:337] Iteration 25400, Testing net (#0)
I0813 14:36:57.813511 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 14:36:57.813592 18283 solver.cpp:404]     Test net output #1: loss = 1.0194 (* 1 = 1.0194 loss)
I0813 14:36:58.627898 18283 solver.cpp:228] Iteration 25400, loss = 0.00586698
I0813 14:36:58.627969 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:36:58.627984 18283 solver.cpp:244]     Train net output #1: loss = 0.005867 (* 1 = 0.005867 loss)
I0813 14:36:58.627998 18283 sgd_solver.cpp:106] Iteration 25400, lr = 0.00387478
I0813 14:37:39.976012 18283 solver.cpp:228] Iteration 25450, loss = -1.67638e-08
I0813 14:37:39.976177 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:37:39.976191 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 14:37:39.976202 18283 sgd_solver.cpp:106] Iteration 25450, lr = 0.00387068
I0813 14:38:20.374728 18283 solver.cpp:337] Iteration 25500, Testing net (#0)
I0813 14:38:24.434664 18283 solver.cpp:404]     Test net output #0: accuracy = 0.747
I0813 14:38:24.434741 18283 solver.cpp:404]     Test net output #1: loss = 1.11566 (* 1 = 1.11566 loss)
I0813 14:38:25.248453 18283 solver.cpp:228] Iteration 25500, loss = 0.023662
I0813 14:38:25.248520 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:38:25.248533 18283 solver.cpp:244]     Train net output #1: loss = 0.023662 (* 1 = 0.023662 loss)
I0813 14:38:25.248550 18283 sgd_solver.cpp:106] Iteration 25500, lr = 0.0038666
I0813 14:39:06.458006 18283 solver.cpp:228] Iteration 25550, loss = 1.29091e-05
I0813 14:39:06.458159 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:39:06.458173 18283 solver.cpp:244]     Train net output #1: loss = 1.29163e-05 (* 1 = 1.29163e-05 loss)
I0813 14:39:06.458186 18283 sgd_solver.cpp:106] Iteration 25550, lr = 0.00386252
I0813 14:39:47.309626 18283 solver.cpp:337] Iteration 25600, Testing net (#0)
I0813 14:39:51.375708 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 14:39:51.375788 18283 solver.cpp:404]     Test net output #1: loss = 0.96169 (* 1 = 0.96169 loss)
I0813 14:39:52.187477 18283 solver.cpp:228] Iteration 25600, loss = 0.0113407
I0813 14:39:52.187535 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:39:52.187546 18283 solver.cpp:244]     Train net output #1: loss = 0.0113407 (* 1 = 0.0113407 loss)
I0813 14:39:52.187563 18283 sgd_solver.cpp:106] Iteration 25600, lr = 0.00385845
I0813 14:40:33.396773 18283 solver.cpp:228] Iteration 25650, loss = 0.00925579
I0813 14:40:33.396981 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:40:33.397038 18283 solver.cpp:244]     Train net output #1: loss = 0.0092558 (* 1 = 0.0092558 loss)
I0813 14:40:33.397063 18283 sgd_solver.cpp:106] Iteration 25650, lr = 0.00385439
I0813 14:41:14.278373 18283 solver.cpp:337] Iteration 25700, Testing net (#0)
I0813 14:41:18.499177 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 14:41:18.499240 18283 solver.cpp:404]     Test net output #1: loss = 0.982837 (* 1 = 0.982837 loss)
I0813 14:41:19.312809 18283 solver.cpp:228] Iteration 25700, loss = 0.00444314
I0813 14:41:19.312865 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:41:19.312876 18283 solver.cpp:244]     Train net output #1: loss = 0.00444315 (* 1 = 0.00444315 loss)
I0813 14:41:19.312896 18283 sgd_solver.cpp:106] Iteration 25700, lr = 0.00385034
I0813 14:42:00.487936 18283 solver.cpp:228] Iteration 25750, loss = 0.000128652
I0813 14:42:00.488173 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:42:00.488229 18283 solver.cpp:244]     Train net output #1: loss = 0.000128667 (* 1 = 0.000128667 loss)
I0813 14:42:00.488251 18283 sgd_solver.cpp:106] Iteration 25750, lr = 0.0038463
I0813 14:42:41.520664 18283 solver.cpp:337] Iteration 25800, Testing net (#0)
I0813 14:42:45.922230 18283 solver.cpp:404]     Test net output #0: accuracy = 0.747
I0813 14:42:45.922300 18283 solver.cpp:404]     Test net output #1: loss = 1.04754 (* 1 = 1.04754 loss)
I0813 14:42:46.736889 18283 solver.cpp:228] Iteration 25800, loss = 0.0114268
I0813 14:42:46.736949 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:42:46.736960 18283 solver.cpp:244]     Train net output #1: loss = 0.0114268 (* 1 = 0.0114268 loss)
I0813 14:42:46.736979 18283 sgd_solver.cpp:106] Iteration 25800, lr = 0.00384227
I0813 14:43:29.001754 18283 solver.cpp:228] Iteration 25850, loss = 0.0112529
I0813 14:43:29.001917 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:43:29.001937 18283 solver.cpp:244]     Train net output #1: loss = 0.0112529 (* 1 = 0.0112529 loss)
I0813 14:43:29.001950 18283 sgd_solver.cpp:106] Iteration 25850, lr = 0.00383825
I0813 14:44:09.391010 18283 solver.cpp:337] Iteration 25900, Testing net (#0)
I0813 14:44:13.627377 18283 solver.cpp:404]     Test net output #0: accuracy = 0.78
I0813 14:44:13.627440 18283 solver.cpp:404]     Test net output #1: loss = 0.871565 (* 1 = 0.871565 loss)
I0813 14:44:14.441974 18283 solver.cpp:228] Iteration 25900, loss = 0.0058357
I0813 14:44:14.442039 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:44:14.442051 18283 solver.cpp:244]     Train net output #1: loss = 0.00583571 (* 1 = 0.00583571 loss)
I0813 14:44:14.442065 18283 sgd_solver.cpp:106] Iteration 25900, lr = 0.00383424
I0813 14:44:56.173549 18283 solver.cpp:228] Iteration 25950, loss = 0.0213606
I0813 14:44:56.173774 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 14:44:56.173825 18283 solver.cpp:244]     Train net output #1: loss = 0.0213606 (* 1 = 0.0213606 loss)
I0813 14:44:56.173849 18283 sgd_solver.cpp:106] Iteration 25950, lr = 0.00383024
I0813 14:45:36.805240 18283 solver.cpp:337] Iteration 26000, Testing net (#0)
I0813 14:45:40.877322 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 14:45:40.877387 18283 solver.cpp:404]     Test net output #1: loss = 0.976654 (* 1 = 0.976654 loss)
I0813 14:45:41.691313 18283 solver.cpp:228] Iteration 26000, loss = 0.0193728
I0813 14:45:41.691370 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:45:41.691381 18283 solver.cpp:244]     Train net output #1: loss = 0.0193728 (* 1 = 0.0193728 loss)
I0813 14:45:41.691398 18283 sgd_solver.cpp:106] Iteration 26000, lr = 0.00382625
I0813 14:46:23.554529 18283 solver.cpp:228] Iteration 26050, loss = 0.00746674
I0813 14:46:23.554677 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:46:23.554692 18283 solver.cpp:244]     Train net output #1: loss = 0.00746676 (* 1 = 0.00746676 loss)
I0813 14:46:23.554707 18283 sgd_solver.cpp:106] Iteration 26050, lr = 0.00382227
I0813 14:47:04.234387 18283 solver.cpp:337] Iteration 26100, Testing net (#0)
I0813 14:47:08.303391 18283 solver.cpp:404]     Test net output #0: accuracy = 0.764
I0813 14:47:08.303452 18283 solver.cpp:404]     Test net output #1: loss = 1.01361 (* 1 = 1.01361 loss)
I0813 14:47:09.117903 18283 solver.cpp:228] Iteration 26100, loss = 0.03603
I0813 14:47:09.117974 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:47:09.117986 18283 solver.cpp:244]     Train net output #1: loss = 0.03603 (* 1 = 0.03603 loss)
I0813 14:47:09.118000 18283 sgd_solver.cpp:106] Iteration 26100, lr = 0.0038183
I0813 14:47:50.957689 18283 solver.cpp:228] Iteration 26150, loss = 0.00240371
I0813 14:47:50.957890 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:47:50.957906 18283 solver.cpp:244]     Train net output #1: loss = 0.00240372 (* 1 = 0.00240372 loss)
I0813 14:47:50.957921 18283 sgd_solver.cpp:106] Iteration 26150, lr = 0.00381433
I0813 14:48:31.375329 18283 solver.cpp:337] Iteration 26200, Testing net (#0)
I0813 14:48:35.642014 18283 solver.cpp:404]     Test net output #0: accuracy = 0.736
I0813 14:48:35.642079 18283 solver.cpp:404]     Test net output #1: loss = 1.13203 (* 1 = 1.13203 loss)
I0813 14:48:36.455660 18283 solver.cpp:228] Iteration 26200, loss = 0.0338707
I0813 14:48:36.455713 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 14:48:36.455725 18283 solver.cpp:244]     Train net output #1: loss = 0.0338707 (* 1 = 0.0338707 loss)
I0813 14:48:36.455742 18283 sgd_solver.cpp:106] Iteration 26200, lr = 0.00381038
I0813 14:49:17.647496 18283 solver.cpp:228] Iteration 26250, loss = 0.00607305
I0813 14:49:17.647650 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:49:17.647665 18283 solver.cpp:244]     Train net output #1: loss = 0.00607306 (* 1 = 0.00607306 loss)
I0813 14:49:17.647676 18283 sgd_solver.cpp:106] Iteration 26250, lr = 0.00380644
I0813 14:49:58.027441 18283 solver.cpp:337] Iteration 26300, Testing net (#0)
I0813 14:50:02.082928 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 14:50:02.082996 18283 solver.cpp:404]     Test net output #1: loss = 0.986833 (* 1 = 0.986833 loss)
I0813 14:50:02.896450 18283 solver.cpp:228] Iteration 26300, loss = 0.0107716
I0813 14:50:02.896502 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:50:02.896514 18283 solver.cpp:244]     Train net output #1: loss = 0.0107717 (* 1 = 0.0107717 loss)
I0813 14:50:02.896527 18283 sgd_solver.cpp:106] Iteration 26300, lr = 0.00380251
I0813 14:50:44.093065 18283 solver.cpp:228] Iteration 26350, loss = 0.00839745
I0813 14:50:44.093271 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:50:44.093327 18283 solver.cpp:244]     Train net output #1: loss = 0.00839746 (* 1 = 0.00839746 loss)
I0813 14:50:44.093400 18283 sgd_solver.cpp:106] Iteration 26350, lr = 0.00379858
I0813 14:51:24.634835 18283 solver.cpp:337] Iteration 26400, Testing net (#0)
I0813 14:51:29.028776 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 14:51:29.028846 18283 solver.cpp:404]     Test net output #1: loss = 0.990233 (* 1 = 0.990233 loss)
I0813 14:51:30.019279 18283 solver.cpp:228] Iteration 26400, loss = 0.00131297
I0813 14:51:30.019351 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:51:30.019362 18283 solver.cpp:244]     Train net output #1: loss = 0.00131297 (* 1 = 0.00131297 loss)
I0813 14:51:30.019378 18283 sgd_solver.cpp:106] Iteration 26400, lr = 0.00379467
I0813 14:52:11.327523 18283 solver.cpp:228] Iteration 26450, loss = 0.0363166
I0813 14:52:11.327685 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:52:11.327699 18283 solver.cpp:244]     Train net output #1: loss = 0.0363166 (* 1 = 0.0363166 loss)
I0813 14:52:11.327711 18283 sgd_solver.cpp:106] Iteration 26450, lr = 0.00379076
I0813 14:52:52.698817 18283 solver.cpp:337] Iteration 26500, Testing net (#0)
I0813 14:52:56.767041 18283 solver.cpp:404]     Test net output #0: accuracy = 0.739
I0813 14:52:56.767112 18283 solver.cpp:404]     Test net output #1: loss = 1.16501 (* 1 = 1.16501 loss)
I0813 14:52:57.580315 18283 solver.cpp:228] Iteration 26500, loss = 0.0492151
I0813 14:52:57.580375 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 14:52:57.580387 18283 solver.cpp:244]     Train net output #1: loss = 0.0492151 (* 1 = 0.0492151 loss)
I0813 14:52:57.580405 18283 sgd_solver.cpp:106] Iteration 26500, lr = 0.00378687
I0813 14:53:38.788264 18283 solver.cpp:228] Iteration 26550, loss = 0.00593388
I0813 14:53:38.788416 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:53:38.788430 18283 solver.cpp:244]     Train net output #1: loss = 0.00593388 (* 1 = 0.00593388 loss)
I0813 14:53:38.788442 18283 sgd_solver.cpp:106] Iteration 26550, lr = 0.00378298
I0813 14:54:19.171238 18283 solver.cpp:337] Iteration 26600, Testing net (#0)
I0813 14:54:23.240206 18283 solver.cpp:404]     Test net output #0: accuracy = 0.733
I0813 14:54:23.240268 18283 solver.cpp:404]     Test net output #1: loss = 1.27317 (* 1 = 1.27317 loss)
I0813 14:54:24.053592 18283 solver.cpp:228] Iteration 26600, loss = 0.0175803
I0813 14:54:24.053649 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:54:24.053663 18283 solver.cpp:244]     Train net output #1: loss = 0.0175804 (* 1 = 0.0175804 loss)
I0813 14:54:24.053674 18283 sgd_solver.cpp:106] Iteration 26600, lr = 0.00377911
I0813 14:55:05.273191 18283 solver.cpp:228] Iteration 26650, loss = 0.00228522
I0813 14:55:05.273347 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:55:05.273362 18283 solver.cpp:244]     Train net output #1: loss = 0.00228523 (* 1 = 0.00228523 loss)
I0813 14:55:05.273377 18283 sgd_solver.cpp:106] Iteration 26650, lr = 0.00377524
I0813 14:55:45.645728 18283 solver.cpp:337] Iteration 26700, Testing net (#0)
I0813 14:55:49.708595 18283 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0813 14:55:49.708662 18283 solver.cpp:404]     Test net output #1: loss = 1.27313 (* 1 = 1.27313 loss)
I0813 14:55:50.522614 18283 solver.cpp:228] Iteration 26700, loss = 0.0269908
I0813 14:55:50.522670 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 14:55:50.522681 18283 solver.cpp:244]     Train net output #1: loss = 0.0269908 (* 1 = 0.0269908 loss)
I0813 14:55:50.522699 18283 sgd_solver.cpp:106] Iteration 26700, lr = 0.00377138
I0813 14:56:31.728551 18283 solver.cpp:228] Iteration 26750, loss = 0.0198146
I0813 14:56:31.728709 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:56:31.728723 18283 solver.cpp:244]     Train net output #1: loss = 0.0198146 (* 1 = 0.0198146 loss)
I0813 14:56:31.728734 18283 sgd_solver.cpp:106] Iteration 26750, lr = 0.00376753
I0813 14:57:12.138247 18283 solver.cpp:337] Iteration 26800, Testing net (#0)
I0813 14:57:16.197536 18283 solver.cpp:404]     Test net output #0: accuracy = 0.738
I0813 14:57:16.197599 18283 solver.cpp:404]     Test net output #1: loss = 1.13171 (* 1 = 1.13171 loss)
I0813 14:57:17.010397 18283 solver.cpp:228] Iteration 26800, loss = 0.0141497
I0813 14:57:17.010454 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:57:17.010465 18283 solver.cpp:244]     Train net output #1: loss = 0.0141497 (* 1 = 0.0141497 loss)
I0813 14:57:17.010483 18283 sgd_solver.cpp:106] Iteration 26800, lr = 0.00376369
I0813 14:57:58.188453 18283 solver.cpp:228] Iteration 26850, loss = 0.00826415
I0813 14:57:58.188602 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:57:58.188617 18283 solver.cpp:244]     Train net output #1: loss = 0.00826416 (* 1 = 0.00826416 loss)
I0813 14:57:58.188630 18283 sgd_solver.cpp:106] Iteration 26850, lr = 0.00375986
I0813 14:58:38.566931 18283 solver.cpp:337] Iteration 26900, Testing net (#0)
I0813 14:58:42.627387 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 14:58:42.627456 18283 solver.cpp:404]     Test net output #1: loss = 1.04887 (* 1 = 1.04887 loss)
I0813 14:58:43.441205 18283 solver.cpp:228] Iteration 26900, loss = 0.00252906
I0813 14:58:43.441262 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:58:43.441273 18283 solver.cpp:244]     Train net output #1: loss = 0.00252906 (* 1 = 0.00252906 loss)
I0813 14:58:43.441292 18283 sgd_solver.cpp:106] Iteration 26900, lr = 0.00375604
I0813 14:59:24.649433 18283 solver.cpp:228] Iteration 26950, loss = 0.0150351
I0813 14:59:24.649600 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 14:59:24.649613 18283 solver.cpp:244]     Train net output #1: loss = 0.0150352 (* 1 = 0.0150352 loss)
I0813 14:59:24.649626 18283 sgd_solver.cpp:106] Iteration 26950, lr = 0.00375223
I0813 15:00:05.039248 18283 solver.cpp:337] Iteration 27000, Testing net (#0)
I0813 15:00:09.309360 18283 solver.cpp:404]     Test net output #0: accuracy = 0.728
I0813 15:00:09.309432 18283 solver.cpp:404]     Test net output #1: loss = 1.25384 (* 1 = 1.25384 loss)
I0813 15:00:10.365453 18283 solver.cpp:228] Iteration 27000, loss = 0.012117
I0813 15:00:10.365537 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:00:10.365551 18283 solver.cpp:244]     Train net output #1: loss = 0.012117 (* 1 = 0.012117 loss)
I0813 15:00:10.365568 18283 sgd_solver.cpp:106] Iteration 27000, lr = 0.00374842
I0813 15:00:52.702378 18283 solver.cpp:228] Iteration 27050, loss = -1.21072e-08
I0813 15:00:52.702549 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:00:52.702563 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:00:52.702574 18283 sgd_solver.cpp:106] Iteration 27050, lr = 0.00374463
I0813 15:01:33.208303 18283 solver.cpp:337] Iteration 27100, Testing net (#0)
I0813 15:01:37.399008 18283 solver.cpp:404]     Test net output #0: accuracy = 0.789
I0813 15:01:37.399085 18283 solver.cpp:404]     Test net output #1: loss = 0.805124 (* 1 = 0.805124 loss)
I0813 15:01:38.211930 18283 solver.cpp:228] Iteration 27100, loss = 0.00812926
I0813 15:01:38.212002 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:01:38.212015 18283 solver.cpp:244]     Train net output #1: loss = 0.00812928 (* 1 = 0.00812928 loss)
I0813 15:01:38.212038 18283 sgd_solver.cpp:106] Iteration 27100, lr = 0.00374084
I0813 15:02:20.334728 18283 solver.cpp:228] Iteration 27150, loss = 0.0105987
I0813 15:02:20.334962 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:02:20.335011 18283 solver.cpp:244]     Train net output #1: loss = 0.0105988 (* 1 = 0.0105988 loss)
I0813 15:02:20.335078 18283 sgd_solver.cpp:106] Iteration 27150, lr = 0.00373707
I0813 15:03:00.900995 18283 solver.cpp:337] Iteration 27200, Testing net (#0)
I0813 15:03:05.285347 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 15:03:05.285413 18283 solver.cpp:404]     Test net output #1: loss = 1.01781 (* 1 = 1.01781 loss)
I0813 15:03:06.100471 18283 solver.cpp:228] Iteration 27200, loss = 0.00125158
I0813 15:03:06.100535 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:03:06.100548 18283 solver.cpp:244]     Train net output #1: loss = 0.00125159 (* 1 = 0.00125159 loss)
I0813 15:03:06.100563 18283 sgd_solver.cpp:106] Iteration 27200, lr = 0.0037333
I0813 15:03:47.313480 18283 solver.cpp:228] Iteration 27250, loss = 0.00884963
I0813 15:03:47.313686 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:03:47.313733 18283 solver.cpp:244]     Train net output #1: loss = 0.00884965 (* 1 = 0.00884965 loss)
I0813 15:03:47.313771 18283 sgd_solver.cpp:106] Iteration 27250, lr = 0.00372954
I0813 15:04:28.321404 18283 solver.cpp:337] Iteration 27300, Testing net (#0)
I0813 15:04:32.463399 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 15:04:32.463465 18283 solver.cpp:404]     Test net output #1: loss = 1.06055 (* 1 = 1.06055 loss)
I0813 15:04:33.277266 18283 solver.cpp:228] Iteration 27300, loss = 0.00567346
I0813 15:04:33.277336 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:04:33.277349 18283 solver.cpp:244]     Train net output #1: loss = 0.00567347 (* 1 = 0.00567347 loss)
I0813 15:04:33.277364 18283 sgd_solver.cpp:106] Iteration 27300, lr = 0.00372579
I0813 15:05:14.486006 18283 solver.cpp:228] Iteration 27350, loss = -1.25729e-08
I0813 15:05:14.486229 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:05:14.486274 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:05:14.486292 18283 sgd_solver.cpp:106] Iteration 27350, lr = 0.00372205
I0813 15:05:55.034675 18283 solver.cpp:337] Iteration 27400, Testing net (#0)
I0813 15:05:59.097986 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 15:05:59.098053 18283 solver.cpp:404]     Test net output #1: loss = 1.03193 (* 1 = 1.03193 loss)
I0813 15:05:59.910531 18283 solver.cpp:228] Iteration 27400, loss = 0.0222473
I0813 15:05:59.910578 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:05:59.910589 18283 solver.cpp:244]     Train net output #1: loss = 0.0222473 (* 1 = 0.0222473 loss)
I0813 15:05:59.910605 18283 sgd_solver.cpp:106] Iteration 27400, lr = 0.00371832
I0813 15:06:41.089164 18283 solver.cpp:228] Iteration 27450, loss = -1.58325e-08
I0813 15:06:41.089386 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:06:41.089443 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:06:41.089467 18283 sgd_solver.cpp:106] Iteration 27450, lr = 0.00371459
I0813 15:07:21.659099 18283 solver.cpp:337] Iteration 27500, Testing net (#0)
I0813 15:07:25.723722 18283 solver.cpp:404]     Test net output #0: accuracy = 0.771
I0813 15:07:25.723790 18283 solver.cpp:404]     Test net output #1: loss = 0.984361 (* 1 = 0.984361 loss)
I0813 15:07:26.536913 18283 solver.cpp:228] Iteration 27500, loss = 0.000620883
I0813 15:07:26.536973 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:07:26.536986 18283 solver.cpp:244]     Train net output #1: loss = 0.000620899 (* 1 = 0.000620899 loss)
I0813 15:07:26.537000 18283 sgd_solver.cpp:106] Iteration 27500, lr = 0.00371088
I0813 15:08:07.724702 18283 solver.cpp:228] Iteration 27550, loss = 0.0253218
I0813 15:08:07.724869 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:08:07.724884 18283 solver.cpp:244]     Train net output #1: loss = 0.0253218 (* 1 = 0.0253218 loss)
I0813 15:08:07.724896 18283 sgd_solver.cpp:106] Iteration 27550, lr = 0.00370717
I0813 15:08:48.122289 18283 solver.cpp:337] Iteration 27600, Testing net (#0)
I0813 15:08:52.191561 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 15:08:52.191628 18283 solver.cpp:404]     Test net output #1: loss = 0.967566 (* 1 = 0.967566 loss)
I0813 15:08:53.004369 18283 solver.cpp:228] Iteration 27600, loss = 0.00528721
I0813 15:08:53.004432 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:08:53.004444 18283 solver.cpp:244]     Train net output #1: loss = 0.00528722 (* 1 = 0.00528722 loss)
I0813 15:08:53.004457 18283 sgd_solver.cpp:106] Iteration 27600, lr = 0.00370347
I0813 15:09:34.207134 18283 solver.cpp:228] Iteration 27650, loss = 0.0273594
I0813 15:09:34.207295 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:09:34.207309 18283 solver.cpp:244]     Train net output #1: loss = 0.0273594 (* 1 = 0.0273594 loss)
I0813 15:09:34.207321 18283 sgd_solver.cpp:106] Iteration 27650, lr = 0.00369978
I0813 15:10:15.232758 18283 solver.cpp:337] Iteration 27700, Testing net (#0)
I0813 15:10:19.651135 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 15:10:19.651213 18283 solver.cpp:404]     Test net output #1: loss = 1.02033 (* 1 = 1.02033 loss)
I0813 15:10:20.662305 18283 solver.cpp:228] Iteration 27700, loss = 0.000865374
I0813 15:10:20.662376 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:10:20.662389 18283 solver.cpp:244]     Train net output #1: loss = 0.000865387 (* 1 = 0.000865387 loss)
I0813 15:10:20.662405 18283 sgd_solver.cpp:106] Iteration 27700, lr = 0.0036961
I0813 15:11:02.250576 18283 solver.cpp:228] Iteration 27750, loss = -1.49012e-08
I0813 15:11:02.250730 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:11:02.250743 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:11:02.250754 18283 sgd_solver.cpp:106] Iteration 27750, lr = 0.00369243
I0813 15:11:42.975531 18283 solver.cpp:337] Iteration 27800, Testing net (#0)
I0813 15:11:47.031689 18283 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0813 15:11:47.031757 18283 solver.cpp:404]     Test net output #1: loss = 1.01627 (* 1 = 1.01627 loss)
I0813 15:11:47.851629 18283 solver.cpp:228] Iteration 27800, loss = 0.0239321
I0813 15:11:47.851687 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 15:11:47.851698 18283 solver.cpp:244]     Train net output #1: loss = 0.0239321 (* 1 = 0.0239321 loss)
I0813 15:11:47.851717 18283 sgd_solver.cpp:106] Iteration 27800, lr = 0.00368877
I0813 15:12:29.051899 18283 solver.cpp:228] Iteration 27850, loss = 0.00921111
I0813 15:12:29.052134 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:12:29.052206 18283 solver.cpp:244]     Train net output #1: loss = 0.00921113 (* 1 = 0.00921113 loss)
I0813 15:12:29.052240 18283 sgd_solver.cpp:106] Iteration 27850, lr = 0.00368511
I0813 15:13:09.842188 18283 solver.cpp:337] Iteration 27900, Testing net (#0)
I0813 15:13:13.902954 18283 solver.cpp:404]     Test net output #0: accuracy = 0.781
I0813 15:13:13.903019 18283 solver.cpp:404]     Test net output #1: loss = 0.886612 (* 1 = 0.886612 loss)
I0813 15:13:14.715782 18283 solver.cpp:228] Iteration 27900, loss = 0.0189918
I0813 15:13:14.715834 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:13:14.715844 18283 solver.cpp:244]     Train net output #1: loss = 0.0189918 (* 1 = 0.0189918 loss)
I0813 15:13:14.715857 18283 sgd_solver.cpp:106] Iteration 27900, lr = 0.00368146
I0813 15:13:55.834030 18283 solver.cpp:228] Iteration 27950, loss = 0.00355039
I0813 15:13:55.834195 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:13:55.834210 18283 solver.cpp:244]     Train net output #1: loss = 0.00355041 (* 1 = 0.00355041 loss)
I0813 15:13:55.834221 18283 sgd_solver.cpp:106] Iteration 27950, lr = 0.00367783
I0813 15:14:36.165930 18283 solver.cpp:337] Iteration 28000, Testing net (#0)
I0813 15:14:40.224333 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 15:14:40.224397 18283 solver.cpp:404]     Test net output #1: loss = 1.08544 (* 1 = 1.08544 loss)
I0813 15:14:41.037078 18283 solver.cpp:228] Iteration 28000, loss = 0.0021517
I0813 15:14:41.037130 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:14:41.037142 18283 solver.cpp:244]     Train net output #1: loss = 0.00215171 (* 1 = 0.00215171 loss)
I0813 15:14:41.037161 18283 sgd_solver.cpp:106] Iteration 28000, lr = 0.0036742
I0813 15:15:22.184715 18283 solver.cpp:228] Iteration 28050, loss = 0.00112081
I0813 15:15:22.184872 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:15:22.184886 18283 solver.cpp:244]     Train net output #1: loss = 0.00112082 (* 1 = 0.00112082 loss)
I0813 15:15:22.184897 18283 sgd_solver.cpp:106] Iteration 28050, lr = 0.00367057
I0813 15:16:02.524693 18283 solver.cpp:337] Iteration 28100, Testing net (#0)
I0813 15:16:06.845031 18283 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0813 15:16:06.845093 18283 solver.cpp:404]     Test net output #1: loss = 1.0578 (* 1 = 1.0578 loss)
I0813 15:16:07.658191 18283 solver.cpp:228] Iteration 28100, loss = 0.0161558
I0813 15:16:07.658246 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:16:07.658257 18283 solver.cpp:244]     Train net output #1: loss = 0.0161558 (* 1 = 0.0161558 loss)
I0813 15:16:07.658277 18283 sgd_solver.cpp:106] Iteration 28100, lr = 0.00366696
I0813 15:16:48.848326 18283 solver.cpp:228] Iteration 28150, loss = -1.58325e-08
I0813 15:16:48.848544 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:16:48.848595 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:16:48.848619 18283 sgd_solver.cpp:106] Iteration 28150, lr = 0.00366336
I0813 15:17:30.121048 18283 solver.cpp:337] Iteration 28200, Testing net (#0)
I0813 15:17:34.326597 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 15:17:34.326659 18283 solver.cpp:404]     Test net output #1: loss = 1.1196 (* 1 = 1.1196 loss)
I0813 15:17:35.140189 18283 solver.cpp:228] Iteration 28200, loss = -1.49012e-08
I0813 15:17:35.140250 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:17:35.140262 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:17:35.140277 18283 sgd_solver.cpp:106] Iteration 28200, lr = 0.00365976
I0813 15:18:16.349947 18283 solver.cpp:228] Iteration 28250, loss = 0.0258703
I0813 15:18:16.350114 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:18:16.350127 18283 solver.cpp:244]     Train net output #1: loss = 0.0258703 (* 1 = 0.0258703 loss)
I0813 15:18:16.350139 18283 sgd_solver.cpp:106] Iteration 28250, lr = 0.00365617
I0813 15:18:57.297739 18283 solver.cpp:337] Iteration 28300, Testing net (#0)
I0813 15:19:01.523932 18283 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0813 15:19:01.524003 18283 solver.cpp:404]     Test net output #1: loss = 0.972357 (* 1 = 0.972357 loss)
I0813 15:19:02.336534 18283 solver.cpp:228] Iteration 28300, loss = 0.0179153
I0813 15:19:02.336596 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:19:02.336609 18283 solver.cpp:244]     Train net output #1: loss = 0.0179153 (* 1 = 0.0179153 loss)
I0813 15:19:02.336625 18283 sgd_solver.cpp:106] Iteration 28300, lr = 0.00365259
I0813 15:19:43.574218 18283 solver.cpp:228] Iteration 28350, loss = 0.00672544
I0813 15:19:43.574450 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:19:43.574497 18283 solver.cpp:244]     Train net output #1: loss = 0.00672546 (* 1 = 0.00672546 loss)
I0813 15:19:43.574523 18283 sgd_solver.cpp:106] Iteration 28350, lr = 0.00364902
I0813 15:20:24.679682 18283 solver.cpp:337] Iteration 28400, Testing net (#0)
I0813 15:20:28.913789 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 15:20:28.913861 18283 solver.cpp:404]     Test net output #1: loss = 0.90009 (* 1 = 0.90009 loss)
I0813 15:20:29.728824 18283 solver.cpp:228] Iteration 28400, loss = 0.00184598
I0813 15:20:29.728886 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:20:29.728898 18283 solver.cpp:244]     Train net output #1: loss = 0.001846 (* 1 = 0.001846 loss)
I0813 15:20:29.728912 18283 sgd_solver.cpp:106] Iteration 28400, lr = 0.00364545
I0813 15:21:10.913518 18283 solver.cpp:228] Iteration 28450, loss = 0.00700492
I0813 15:21:10.913750 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:21:10.913805 18283 solver.cpp:244]     Train net output #1: loss = 0.00700494 (* 1 = 0.00700494 loss)
I0813 15:21:10.913830 18283 sgd_solver.cpp:106] Iteration 28450, lr = 0.0036419
I0813 15:21:51.479399 18283 solver.cpp:337] Iteration 28500, Testing net (#0)
I0813 15:21:55.543524 18283 solver.cpp:404]     Test net output #0: accuracy = 0.764
I0813 15:21:55.543602 18283 solver.cpp:404]     Test net output #1: loss = 0.934229 (* 1 = 0.934229 loss)
I0813 15:21:56.355732 18283 solver.cpp:228] Iteration 28500, loss = 0.00700683
I0813 15:21:56.355784 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:21:56.355794 18283 solver.cpp:244]     Train net output #1: loss = 0.00700685 (* 1 = 0.00700685 loss)
I0813 15:21:56.355814 18283 sgd_solver.cpp:106] Iteration 28500, lr = 0.00363835
I0813 15:22:37.515066 18283 solver.cpp:228] Iteration 28550, loss = 0.0174375
I0813 15:22:37.515254 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:22:37.515303 18283 solver.cpp:244]     Train net output #1: loss = 0.0174376 (* 1 = 0.0174376 loss)
I0813 15:22:37.515322 18283 sgd_solver.cpp:106] Iteration 28550, lr = 0.00363481
I0813 15:23:18.345758 18283 solver.cpp:337] Iteration 28600, Testing net (#0)
I0813 15:23:22.416890 18283 solver.cpp:404]     Test net output #0: accuracy = 0.735
I0813 15:23:22.416968 18283 solver.cpp:404]     Test net output #1: loss = 1.10103 (* 1 = 1.10103 loss)
I0813 15:23:23.230183 18283 solver.cpp:228] Iteration 28600, loss = 0.00573761
I0813 15:23:23.230237 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:23:23.230247 18283 solver.cpp:244]     Train net output #1: loss = 0.00573763 (* 1 = 0.00573763 loss)
I0813 15:23:23.230265 18283 sgd_solver.cpp:106] Iteration 28600, lr = 0.00363128
I0813 15:24:04.434798 18283 solver.cpp:228] Iteration 28650, loss = 0.0261239
I0813 15:24:04.434948 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:24:04.434962 18283 solver.cpp:244]     Train net output #1: loss = 0.0261239 (* 1 = 0.0261239 loss)
I0813 15:24:04.434974 18283 sgd_solver.cpp:106] Iteration 28650, lr = 0.00362775
I0813 15:24:45.060667 18283 solver.cpp:337] Iteration 28700, Testing net (#0)
I0813 15:24:49.348933 18283 solver.cpp:404]     Test net output #0: accuracy = 0.775
I0813 15:24:49.349000 18283 solver.cpp:404]     Test net output #1: loss = 0.917724 (* 1 = 0.917724 loss)
I0813 15:24:50.160609 18283 solver.cpp:228] Iteration 28700, loss = 0.024533
I0813 15:24:50.160660 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:24:50.160671 18283 solver.cpp:244]     Train net output #1: loss = 0.0245331 (* 1 = 0.0245331 loss)
I0813 15:24:50.160687 18283 sgd_solver.cpp:106] Iteration 28700, lr = 0.00362424
I0813 15:25:31.355249 18283 solver.cpp:228] Iteration 28750, loss = 0.0221493
I0813 15:25:31.355473 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 15:25:31.355525 18283 solver.cpp:244]     Train net output #1: loss = 0.0221493 (* 1 = 0.0221493 loss)
I0813 15:25:31.355556 18283 sgd_solver.cpp:106] Iteration 28750, lr = 0.00362073
I0813 15:26:12.130926 18283 solver.cpp:337] Iteration 28800, Testing net (#0)
I0813 15:26:16.562961 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 15:26:16.563031 18283 solver.cpp:404]     Test net output #1: loss = 1.0349 (* 1 = 1.0349 loss)
I0813 15:26:17.376837 18283 solver.cpp:228] Iteration 28800, loss = 0.0062146
I0813 15:26:17.376898 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:26:17.376909 18283 solver.cpp:244]     Train net output #1: loss = 0.00621462 (* 1 = 0.00621462 loss)
I0813 15:26:17.376924 18283 sgd_solver.cpp:106] Iteration 28800, lr = 0.00361723
I0813 15:26:59.272543 18283 solver.cpp:228] Iteration 28850, loss = -1.32713e-08
I0813 15:26:59.272766 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:26:59.272819 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:26:59.272836 18283 sgd_solver.cpp:106] Iteration 28850, lr = 0.00361374
I0813 15:27:39.944835 18283 solver.cpp:337] Iteration 28900, Testing net (#0)
I0813 15:27:44.003406 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 15:27:44.003485 18283 solver.cpp:404]     Test net output #1: loss = 1.04307 (* 1 = 1.04307 loss)
I0813 15:27:44.815721 18283 solver.cpp:228] Iteration 28900, loss = 0.00874188
I0813 15:27:44.815768 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:27:44.815779 18283 solver.cpp:244]     Train net output #1: loss = 0.00874189 (* 1 = 0.00874189 loss)
I0813 15:27:44.815798 18283 sgd_solver.cpp:106] Iteration 28900, lr = 0.00361025
I0813 15:28:25.978571 18283 solver.cpp:228] Iteration 28950, loss = -1.30385e-08
I0813 15:28:25.978732 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:28:25.978746 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:28:25.978757 18283 sgd_solver.cpp:106] Iteration 28950, lr = 0.00360678
I0813 15:29:06.329357 18283 solver.cpp:337] Iteration 29000, Testing net (#0)
I0813 15:29:10.390691 18283 solver.cpp:404]     Test net output #0: accuracy = 0.743
I0813 15:29:10.390770 18283 solver.cpp:404]     Test net output #1: loss = 1.05506 (* 1 = 1.05506 loss)
I0813 15:29:11.202211 18283 solver.cpp:228] Iteration 29000, loss = 0.00152011
I0813 15:29:11.202266 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:29:11.202278 18283 solver.cpp:244]     Train net output #1: loss = 0.00152012 (* 1 = 0.00152012 loss)
I0813 15:29:11.202296 18283 sgd_solver.cpp:106] Iteration 29000, lr = 0.00360331
I0813 15:29:52.339810 18283 solver.cpp:228] Iteration 29050, loss = 0.00785159
I0813 15:29:52.339964 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:29:52.339979 18283 solver.cpp:244]     Train net output #1: loss = 0.00785161 (* 1 = 0.00785161 loss)
I0813 15:29:52.339990 18283 sgd_solver.cpp:106] Iteration 29050, lr = 0.00359985
I0813 15:30:32.976945 18283 solver.cpp:337] Iteration 29100, Testing net (#0)
I0813 15:30:37.289521 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 15:30:37.289597 18283 solver.cpp:404]     Test net output #1: loss = 0.992385 (* 1 = 0.992385 loss)
I0813 15:30:38.102589 18283 solver.cpp:228] Iteration 29100, loss = 0.0138145
I0813 15:30:38.102643 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:30:38.102654 18283 solver.cpp:244]     Train net output #1: loss = 0.0138145 (* 1 = 0.0138145 loss)
I0813 15:30:38.102666 18283 sgd_solver.cpp:106] Iteration 29100, lr = 0.0035964
I0813 15:31:19.311233 18283 solver.cpp:228] Iteration 29150, loss = 0.00358141
I0813 15:31:19.311416 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:31:19.311431 18283 solver.cpp:244]     Train net output #1: loss = 0.00358143 (* 1 = 0.00358143 loss)
I0813 15:31:19.311444 18283 sgd_solver.cpp:106] Iteration 29150, lr = 0.00359295
I0813 15:31:59.697439 18283 solver.cpp:337] Iteration 29200, Testing net (#0)
I0813 15:32:03.761313 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 15:32:03.761391 18283 solver.cpp:404]     Test net output #1: loss = 1.02755 (* 1 = 1.02755 loss)
I0813 15:32:04.575414 18283 solver.cpp:228] Iteration 29200, loss = 0.0133289
I0813 15:32:04.575469 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:32:04.575480 18283 solver.cpp:244]     Train net output #1: loss = 0.0133289 (* 1 = 0.0133289 loss)
I0813 15:32:04.575497 18283 sgd_solver.cpp:106] Iteration 29200, lr = 0.00358951
I0813 15:32:45.754037 18283 solver.cpp:228] Iteration 29250, loss = 9.83849e-07
I0813 15:32:45.754196 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:32:45.754211 18283 solver.cpp:244]     Train net output #1: loss = 1.00434e-06 (* 1 = 1.00434e-06 loss)
I0813 15:32:45.754223 18283 sgd_solver.cpp:106] Iteration 29250, lr = 0.00358608
I0813 15:33:26.120431 18283 solver.cpp:337] Iteration 29300, Testing net (#0)
I0813 15:33:30.178022 18283 solver.cpp:404]     Test net output #0: accuracy = 0.769
I0813 15:33:30.178087 18283 solver.cpp:404]     Test net output #1: loss = 0.959492 (* 1 = 0.959492 loss)
I0813 15:33:30.990654 18283 solver.cpp:228] Iteration 29300, loss = 0.0089417
I0813 15:33:30.990707 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:33:30.990720 18283 solver.cpp:244]     Train net output #1: loss = 0.00894172 (* 1 = 0.00894172 loss)
I0813 15:33:30.990737 18283 sgd_solver.cpp:106] Iteration 29300, lr = 0.00358266
I0813 15:34:12.155225 18283 solver.cpp:228] Iteration 29350, loss = -2.79397e-08
I0813 15:34:12.155392 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:34:12.155405 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:34:12.155418 18283 sgd_solver.cpp:106] Iteration 29350, lr = 0.00357925
I0813 15:34:52.477380 18283 solver.cpp:337] Iteration 29400, Testing net (#0)
I0813 15:34:56.526660 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 15:34:56.526727 18283 solver.cpp:404]     Test net output #1: loss = 0.979079 (* 1 = 0.979079 loss)
I0813 15:34:57.338912 18283 solver.cpp:228] Iteration 29400, loss = -2.79397e-08
I0813 15:34:57.338958 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:34:57.338968 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:34:57.338984 18283 sgd_solver.cpp:106] Iteration 29400, lr = 0.00357584
I0813 15:35:38.501466 18283 solver.cpp:228] Iteration 29450, loss = 0.00818291
I0813 15:35:38.501622 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:35:38.501636 18283 solver.cpp:244]     Train net output #1: loss = 0.00818294 (* 1 = 0.00818294 loss)
I0813 15:35:38.501649 18283 sgd_solver.cpp:106] Iteration 29450, lr = 0.00357244
I0813 15:36:18.863131 18283 solver.cpp:337] Iteration 29500, Testing net (#0)
I0813 15:36:22.925148 18283 solver.cpp:404]     Test net output #0: accuracy = 0.782
I0813 15:36:22.925216 18283 solver.cpp:404]     Test net output #1: loss = 0.824791 (* 1 = 0.824791 loss)
I0813 15:36:23.739478 18283 solver.cpp:228] Iteration 29500, loss = 0.00141672
I0813 15:36:23.739537 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:36:23.739550 18283 solver.cpp:244]     Train net output #1: loss = 0.00141674 (* 1 = 0.00141674 loss)
I0813 15:36:23.739563 18283 sgd_solver.cpp:106] Iteration 29500, lr = 0.00356905
I0813 15:37:04.885784 18283 solver.cpp:228] Iteration 29550, loss = -3.07336e-08
I0813 15:37:04.885974 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:37:04.885988 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:37:04.885999 18283 sgd_solver.cpp:106] Iteration 29550, lr = 0.00356566
I0813 15:37:45.240584 18283 solver.cpp:337] Iteration 29600, Testing net (#0)
I0813 15:37:49.304124 18283 solver.cpp:404]     Test net output #0: accuracy = 0.771
I0813 15:37:49.304190 18283 solver.cpp:404]     Test net output #1: loss = 0.922415 (* 1 = 0.922415 loss)
I0813 15:37:50.117771 18283 solver.cpp:228] Iteration 29600, loss = 0.0246908
I0813 15:37:50.117835 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:37:50.117846 18283 solver.cpp:244]     Train net output #1: loss = 0.0246908 (* 1 = 0.0246908 loss)
I0813 15:37:50.117862 18283 sgd_solver.cpp:106] Iteration 29600, lr = 0.00356228
I0813 15:38:31.277925 18283 solver.cpp:228] Iteration 29650, loss = 0.00830888
I0813 15:38:31.278077 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:38:31.278092 18283 solver.cpp:244]     Train net output #1: loss = 0.00830891 (* 1 = 0.00830891 loss)
I0813 15:38:31.278103 18283 sgd_solver.cpp:106] Iteration 29650, lr = 0.00355891
I0813 15:39:11.632627 18283 solver.cpp:337] Iteration 29700, Testing net (#0)
I0813 15:39:15.685233 18283 solver.cpp:404]     Test net output #0: accuracy = 0.795
I0813 15:39:15.685298 18283 solver.cpp:404]     Test net output #1: loss = 0.818252 (* 1 = 0.818252 loss)
I0813 15:39:16.498322 18283 solver.cpp:228] Iteration 29700, loss = 0.0125074
I0813 15:39:16.498373 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:39:16.498385 18283 solver.cpp:244]     Train net output #1: loss = 0.0125075 (* 1 = 0.0125075 loss)
I0813 15:39:16.498401 18283 sgd_solver.cpp:106] Iteration 29700, lr = 0.00355555
I0813 15:39:57.665133 18283 solver.cpp:228] Iteration 29750, loss = 0.0114417
I0813 15:39:57.665285 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:39:57.665299 18283 solver.cpp:244]     Train net output #1: loss = 0.0114417 (* 1 = 0.0114417 loss)
I0813 15:39:57.665312 18283 sgd_solver.cpp:106] Iteration 29750, lr = 0.0035522
I0813 15:40:38.043988 18283 solver.cpp:337] Iteration 29800, Testing net (#0)
I0813 15:40:42.378543 18283 solver.cpp:404]     Test net output #0: accuracy = 0.742
I0813 15:40:42.378610 18283 solver.cpp:404]     Test net output #1: loss = 1.0726 (* 1 = 1.0726 loss)
I0813 15:40:43.191977 18283 solver.cpp:228] Iteration 29800, loss = 0.000311308
I0813 15:40:43.192046 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:40:43.192059 18283 solver.cpp:244]     Train net output #1: loss = 0.000311344 (* 1 = 0.000311344 loss)
I0813 15:40:43.192075 18283 sgd_solver.cpp:106] Iteration 29800, lr = 0.00354885
I0813 15:41:24.401033 18283 solver.cpp:228] Iteration 29850, loss = 0.00336541
I0813 15:41:24.401190 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:41:24.401203 18283 solver.cpp:244]     Train net output #1: loss = 0.00336545 (* 1 = 0.00336545 loss)
I0813 15:41:24.401216 18283 sgd_solver.cpp:106] Iteration 29850, lr = 0.00354551
I0813 15:42:04.758314 18283 solver.cpp:337] Iteration 29900, Testing net (#0)
I0813 15:42:08.820446 18283 solver.cpp:404]     Test net output #0: accuracy = 0.776
I0813 15:42:08.820513 18283 solver.cpp:404]     Test net output #1: loss = 0.942264 (* 1 = 0.942264 loss)
I0813 15:42:09.633929 18283 solver.cpp:228] Iteration 29900, loss = 0.00909565
I0813 15:42:09.634001 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:42:09.634013 18283 solver.cpp:244]     Train net output #1: loss = 0.00909569 (* 1 = 0.00909569 loss)
I0813 15:42:09.634030 18283 sgd_solver.cpp:106] Iteration 29900, lr = 0.00354218
I0813 15:42:51.324149 18283 solver.cpp:228] Iteration 29950, loss = 5.74701e-05
I0813 15:42:51.324303 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:42:51.324318 18283 solver.cpp:244]     Train net output #1: loss = 5.75048e-05 (* 1 = 5.75048e-05 loss)
I0813 15:42:51.324331 18283 sgd_solver.cpp:106] Iteration 29950, lr = 0.00353885
I0813 15:43:31.687947 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_30000.caffemodel
I0813 15:43:32.042955 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_30000.solverstate
I0813 15:43:32.056664 18283 solver.cpp:337] Iteration 30000, Testing net (#0)
I0813 15:43:36.236196 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 15:43:36.236261 18283 solver.cpp:404]     Test net output #1: loss = 0.986721 (* 1 = 0.986721 loss)
I0813 15:43:37.049967 18283 solver.cpp:228] Iteration 30000, loss = 0.0301986
I0813 15:43:37.050031 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:43:37.050042 18283 solver.cpp:244]     Train net output #1: loss = 0.0301986 (* 1 = 0.0301986 loss)
I0813 15:43:37.050057 18283 sgd_solver.cpp:106] Iteration 30000, lr = 0.00353553
I0813 15:44:18.445624 18283 solver.cpp:228] Iteration 30050, loss = -3.72529e-08
I0813 15:44:18.445791 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:44:18.445803 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:44:18.445816 18283 sgd_solver.cpp:106] Iteration 30050, lr = 0.00353222
I0813 15:44:58.805337 18283 solver.cpp:337] Iteration 30100, Testing net (#0)
I0813 15:45:02.861452 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 15:45:02.861531 18283 solver.cpp:404]     Test net output #1: loss = 1.00549 (* 1 = 1.00549 loss)
I0813 15:45:03.675338 18283 solver.cpp:228] Iteration 30100, loss = 0.023362
I0813 15:45:03.675393 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 15:45:03.675405 18283 solver.cpp:244]     Train net output #1: loss = 0.023362 (* 1 = 0.023362 loss)
I0813 15:45:03.675422 18283 sgd_solver.cpp:106] Iteration 30100, lr = 0.00352892
I0813 15:45:45.567970 18283 solver.cpp:228] Iteration 30150, loss = 0.00480162
I0813 15:45:45.568140 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:45:45.568153 18283 solver.cpp:244]     Train net output #1: loss = 0.00480165 (* 1 = 0.00480165 loss)
I0813 15:45:45.568166 18283 sgd_solver.cpp:106] Iteration 30150, lr = 0.00352562
I0813 15:46:25.950217 18283 solver.cpp:337] Iteration 30200, Testing net (#0)
I0813 15:46:30.004089 18283 solver.cpp:404]     Test net output #0: accuracy = 0.774
I0813 15:46:30.004156 18283 solver.cpp:404]     Test net output #1: loss = 0.850501 (* 1 = 0.850501 loss)
I0813 15:46:30.817154 18283 solver.cpp:228] Iteration 30200, loss = 0.00362864
I0813 15:46:30.817210 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:46:30.817220 18283 solver.cpp:244]     Train net output #1: loss = 0.00362868 (* 1 = 0.00362868 loss)
I0813 15:46:30.817239 18283 sgd_solver.cpp:106] Iteration 30200, lr = 0.00352233
I0813 15:47:12.113909 18283 solver.cpp:228] Iteration 30250, loss = 0.0188595
I0813 15:47:12.114151 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:47:12.114215 18283 solver.cpp:244]     Train net output #1: loss = 0.0188595 (* 1 = 0.0188595 loss)
I0813 15:47:12.114243 18283 sgd_solver.cpp:106] Iteration 30250, lr = 0.00351905
I0813 15:47:52.928768 18283 solver.cpp:337] Iteration 30300, Testing net (#0)
I0813 15:47:56.991255 18283 solver.cpp:404]     Test net output #0: accuracy = 0.787
I0813 15:47:56.991323 18283 solver.cpp:404]     Test net output #1: loss = 0.75618 (* 1 = 0.75618 loss)
I0813 15:47:57.803339 18283 solver.cpp:228] Iteration 30300, loss = 0.0100586
I0813 15:47:57.803395 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:47:57.803406 18283 solver.cpp:244]     Train net output #1: loss = 0.0100586 (* 1 = 0.0100586 loss)
I0813 15:47:57.803422 18283 sgd_solver.cpp:106] Iteration 30300, lr = 0.00351578
I0813 15:48:39.040186 18283 solver.cpp:228] Iteration 30350, loss = -3.91155e-08
I0813 15:48:39.040457 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:48:39.040510 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:48:39.040537 18283 sgd_solver.cpp:106] Iteration 30350, lr = 0.00351251
I0813 15:49:20.001086 18283 solver.cpp:337] Iteration 30400, Testing net (#0)
I0813 15:49:24.059641 18283 solver.cpp:404]     Test net output #0: accuracy = 0.781
I0813 15:49:24.059710 18283 solver.cpp:404]     Test net output #1: loss = 0.824589 (* 1 = 0.824589 loss)
I0813 15:49:24.871178 18283 solver.cpp:228] Iteration 30400, loss = 0.00156356
I0813 15:49:24.871233 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:49:24.871244 18283 solver.cpp:244]     Train net output #1: loss = 0.0015636 (* 1 = 0.0015636 loss)
I0813 15:49:24.871263 18283 sgd_solver.cpp:106] Iteration 30400, lr = 0.00350925
I0813 15:50:06.048385 18283 solver.cpp:228] Iteration 30450, loss = 0.000401932
I0813 15:50:06.048540 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:50:06.048555 18283 solver.cpp:244]     Train net output #1: loss = 0.00040197 (* 1 = 0.00040197 loss)
I0813 15:50:06.048568 18283 sgd_solver.cpp:106] Iteration 30450, lr = 0.00350599
I0813 15:50:46.412222 18283 solver.cpp:337] Iteration 30500, Testing net (#0)
I0813 15:50:50.630951 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 15:50:50.631019 18283 solver.cpp:404]     Test net output #1: loss = 0.912558 (* 1 = 0.912558 loss)
I0813 15:50:51.444237 18283 solver.cpp:228] Iteration 30500, loss = 0.0141249
I0813 15:50:51.444294 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:50:51.444306 18283 solver.cpp:244]     Train net output #1: loss = 0.0141249 (* 1 = 0.0141249 loss)
I0813 15:50:51.444321 18283 sgd_solver.cpp:106] Iteration 30500, lr = 0.00350275
I0813 15:51:32.619547 18283 solver.cpp:228] Iteration 30550, loss = 0.0161522
I0813 15:51:32.619701 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:51:32.619715 18283 solver.cpp:244]     Train net output #1: loss = 0.0161522 (* 1 = 0.0161522 loss)
I0813 15:51:32.619727 18283 sgd_solver.cpp:106] Iteration 30550, lr = 0.00349951
I0813 15:52:12.990727 18283 solver.cpp:337] Iteration 30600, Testing net (#0)
I0813 15:52:17.190721 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 15:52:17.190790 18283 solver.cpp:404]     Test net output #1: loss = 1.04106 (* 1 = 1.04106 loss)
I0813 15:52:18.187301 18283 solver.cpp:228] Iteration 30600, loss = 0.022056
I0813 15:52:18.187372 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:52:18.187384 18283 solver.cpp:244]     Train net output #1: loss = 0.0220561 (* 1 = 0.0220561 loss)
I0813 15:52:18.187399 18283 sgd_solver.cpp:106] Iteration 30600, lr = 0.00349627
I0813 15:52:59.426717 18283 solver.cpp:228] Iteration 30650, loss = -4.47035e-08
I0813 15:52:59.426872 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:52:59.426885 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:52:59.426897 18283 sgd_solver.cpp:106] Iteration 30650, lr = 0.00349305
I0813 15:53:39.805606 18283 solver.cpp:337] Iteration 30700, Testing net (#0)
I0813 15:53:44.231849 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 15:53:44.231912 18283 solver.cpp:404]     Test net output #1: loss = 1.04943 (* 1 = 1.04943 loss)
I0813 15:53:45.044760 18283 solver.cpp:228] Iteration 30700, loss = 0.0402834
I0813 15:53:45.044821 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:53:45.044831 18283 solver.cpp:244]     Train net output #1: loss = 0.0402835 (* 1 = 0.0402835 loss)
I0813 15:53:45.044848 18283 sgd_solver.cpp:106] Iteration 30700, lr = 0.00348983
I0813 15:54:27.384436 18283 solver.cpp:228] Iteration 30750, loss = 0.0112258
I0813 15:54:27.384672 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:54:27.384730 18283 solver.cpp:244]     Train net output #1: loss = 0.0112258 (* 1 = 0.0112258 loss)
I0813 15:54:27.384757 18283 sgd_solver.cpp:106] Iteration 30750, lr = 0.00348662
I0813 15:55:08.589457 18283 solver.cpp:337] Iteration 30800, Testing net (#0)
I0813 15:55:12.654073 18283 solver.cpp:404]     Test net output #0: accuracy = 0.739
I0813 15:55:12.654152 18283 solver.cpp:404]     Test net output #1: loss = 1.1615 (* 1 = 1.1615 loss)
I0813 15:55:13.467699 18283 solver.cpp:228] Iteration 30800, loss = 0.00470667
I0813 15:55:13.467768 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:55:13.467780 18283 solver.cpp:244]     Train net output #1: loss = 0.00470671 (* 1 = 0.00470671 loss)
I0813 15:55:13.467798 18283 sgd_solver.cpp:106] Iteration 30800, lr = 0.00348341
I0813 15:55:54.643172 18283 solver.cpp:228] Iteration 30850, loss = 0.0131344
I0813 15:55:54.643340 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:55:54.643353 18283 solver.cpp:244]     Train net output #1: loss = 0.0131345 (* 1 = 0.0131345 loss)
I0813 15:55:54.643365 18283 sgd_solver.cpp:106] Iteration 30850, lr = 0.00348021
I0813 15:56:35.014359 18283 solver.cpp:337] Iteration 30900, Testing net (#0)
I0813 15:56:39.078812 18283 solver.cpp:404]     Test net output #0: accuracy = 0.769
I0813 15:56:39.078882 18283 solver.cpp:404]     Test net output #1: loss = 0.89157 (* 1 = 0.89157 loss)
I0813 15:56:39.890594 18283 solver.cpp:228] Iteration 30900, loss = 0.00162023
I0813 15:56:39.890661 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:56:39.890672 18283 solver.cpp:244]     Train net output #1: loss = 0.00162028 (* 1 = 0.00162028 loss)
I0813 15:56:39.890686 18283 sgd_solver.cpp:106] Iteration 30900, lr = 0.00347702
I0813 15:57:21.078733 18283 solver.cpp:228] Iteration 30950, loss = -4.09782e-08
I0813 15:57:21.078887 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:57:21.078899 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:57:21.078912 18283 sgd_solver.cpp:106] Iteration 30950, lr = 0.00347384
I0813 15:58:01.441362 18283 solver.cpp:337] Iteration 31000, Testing net (#0)
I0813 15:58:05.486867 18283 solver.cpp:404]     Test net output #0: accuracy = 0.772
I0813 15:58:05.486941 18283 solver.cpp:404]     Test net output #1: loss = 0.864081 (* 1 = 0.864081 loss)
I0813 15:58:06.299307 18283 solver.cpp:228] Iteration 31000, loss = -4.09782e-08
I0813 15:58:06.299373 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:58:06.299386 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 15:58:06.299398 18283 sgd_solver.cpp:106] Iteration 31000, lr = 0.00347066
I0813 15:58:48.678815 18283 solver.cpp:228] Iteration 31050, loss = 0.00196763
I0813 15:58:48.678974 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:58:48.678989 18283 solver.cpp:244]     Train net output #1: loss = 0.00196767 (* 1 = 0.00196767 loss)
I0813 15:58:48.679002 18283 sgd_solver.cpp:106] Iteration 31050, lr = 0.00346749
I0813 15:59:29.146910 18283 solver.cpp:337] Iteration 31100, Testing net (#0)
I0813 15:59:33.200009 18283 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0813 15:59:33.200083 18283 solver.cpp:404]     Test net output #1: loss = 1.24678 (* 1 = 1.24678 loss)
I0813 15:59:34.012845 18283 solver.cpp:228] Iteration 31100, loss = 0.0468234
I0813 15:59:34.012902 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 15:59:34.012912 18283 solver.cpp:244]     Train net output #1: loss = 0.0468234 (* 1 = 0.0468234 loss)
I0813 15:59:34.012930 18283 sgd_solver.cpp:106] Iteration 31100, lr = 0.00346433
I0813 16:00:15.200609 18283 solver.cpp:228] Iteration 31150, loss = -4.28408e-08
I0813 16:00:15.200768 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:00:15.200783 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:00:15.200793 18283 sgd_solver.cpp:106] Iteration 31150, lr = 0.00346117
I0813 16:00:56.052049 18283 solver.cpp:337] Iteration 31200, Testing net (#0)
I0813 16:01:00.102908 18283 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0813 16:01:00.102978 18283 solver.cpp:404]     Test net output #1: loss = 1.0618 (* 1 = 1.0618 loss)
I0813 16:01:00.916339 18283 solver.cpp:228] Iteration 31200, loss = 0.000742223
I0813 16:01:00.916398 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:01:00.916409 18283 solver.cpp:244]     Train net output #1: loss = 0.000742264 (* 1 = 0.000742264 loss)
I0813 16:01:00.916427 18283 sgd_solver.cpp:106] Iteration 31200, lr = 0.00345802
I0813 16:01:42.083854 18283 solver.cpp:228] Iteration 31250, loss = 0.00846264
I0813 16:01:42.084166 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:01:42.084218 18283 solver.cpp:244]     Train net output #1: loss = 0.00846269 (* 1 = 0.00846269 loss)
I0813 16:01:42.084241 18283 sgd_solver.cpp:106] Iteration 31250, lr = 0.00345487
I0813 16:02:24.394086 18283 solver.cpp:337] Iteration 31300, Testing net (#0)
I0813 16:02:28.453047 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 16:02:28.453114 18283 solver.cpp:404]     Test net output #1: loss = 1.00754 (* 1 = 1.00754 loss)
I0813 16:02:29.265766 18283 solver.cpp:228] Iteration 31300, loss = 0.00575481
I0813 16:02:29.265833 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:02:29.265846 18283 solver.cpp:244]     Train net output #1: loss = 0.00575485 (* 1 = 0.00575485 loss)
I0813 16:02:29.265867 18283 sgd_solver.cpp:106] Iteration 31300, lr = 0.00345174
I0813 16:03:11.627543 18283 solver.cpp:228] Iteration 31350, loss = -4.09782e-08
I0813 16:03:11.627751 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:03:11.627804 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:03:11.627827 18283 sgd_solver.cpp:106] Iteration 31350, lr = 0.0034486
I0813 16:03:52.185552 18283 solver.cpp:337] Iteration 31400, Testing net (#0)
I0813 16:03:56.591605 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 16:03:56.591670 18283 solver.cpp:404]     Test net output #1: loss = 0.883658 (* 1 = 0.883658 loss)
I0813 16:03:57.406134 18283 solver.cpp:228] Iteration 31400, loss = 0.0105472
I0813 16:03:57.406201 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:03:57.406213 18283 solver.cpp:244]     Train net output #1: loss = 0.0105473 (* 1 = 0.0105473 loss)
I0813 16:03:57.406229 18283 sgd_solver.cpp:106] Iteration 31400, lr = 0.00344548
I0813 16:04:39.629472 18283 solver.cpp:228] Iteration 31450, loss = 8.93005e-05
I0813 16:04:39.629629 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:04:39.629644 18283 solver.cpp:244]     Train net output #1: loss = 8.93414e-05 (* 1 = 8.93414e-05 loss)
I0813 16:04:39.629657 18283 sgd_solver.cpp:106] Iteration 31450, lr = 0.00344236
I0813 16:05:19.970356 18283 solver.cpp:337] Iteration 31500, Testing net (#0)
I0813 16:05:24.032388 18283 solver.cpp:404]     Test net output #0: accuracy = 0.747
I0813 16:05:24.032469 18283 solver.cpp:404]     Test net output #1: loss = 1.10948 (* 1 = 1.10948 loss)
I0813 16:05:24.845777 18283 solver.cpp:228] Iteration 31500, loss = 0.0304516
I0813 16:05:24.845844 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:05:24.845854 18283 solver.cpp:244]     Train net output #1: loss = 0.0304516 (* 1 = 0.0304516 loss)
I0813 16:05:24.845867 18283 sgd_solver.cpp:106] Iteration 31500, lr = 0.00343925
I0813 16:06:05.988230 18283 solver.cpp:228] Iteration 31550, loss = 0.000833366
I0813 16:06:05.988384 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:06:05.988399 18283 solver.cpp:244]     Train net output #1: loss = 0.000833406 (* 1 = 0.000833406 loss)
I0813 16:06:05.988410 18283 sgd_solver.cpp:106] Iteration 31550, lr = 0.00343615
I0813 16:06:47.312077 18283 solver.cpp:337] Iteration 31600, Testing net (#0)
I0813 16:06:51.595551 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 16:06:51.595612 18283 solver.cpp:404]     Test net output #1: loss = 0.98498 (* 1 = 0.98498 loss)
I0813 16:06:52.407340 18283 solver.cpp:228] Iteration 31600, loss = 0.0121311
I0813 16:06:52.407392 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:06:52.407403 18283 solver.cpp:244]     Train net output #1: loss = 0.0121311 (* 1 = 0.0121311 loss)
I0813 16:06:52.407421 18283 sgd_solver.cpp:106] Iteration 31600, lr = 0.00343305
I0813 16:07:33.567425 18283 solver.cpp:228] Iteration 31650, loss = 0.00103043
I0813 16:07:33.567617 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:07:33.567632 18283 solver.cpp:244]     Train net output #1: loss = 0.00103047 (* 1 = 0.00103047 loss)
I0813 16:07:33.567643 18283 sgd_solver.cpp:106] Iteration 31650, lr = 0.00342996
I0813 16:08:13.925037 18283 solver.cpp:337] Iteration 31700, Testing net (#0)
I0813 16:08:17.985291 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 16:08:17.985355 18283 solver.cpp:404]     Test net output #1: loss = 0.978747 (* 1 = 0.978747 loss)
I0813 16:08:18.797611 18283 solver.cpp:228] Iteration 31700, loss = 0.00963594
I0813 16:08:18.797663 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:08:18.797675 18283 solver.cpp:244]     Train net output #1: loss = 0.00963598 (* 1 = 0.00963598 loss)
I0813 16:08:18.797694 18283 sgd_solver.cpp:106] Iteration 31700, lr = 0.00342687
I0813 16:08:59.976148 18283 solver.cpp:228] Iteration 31750, loss = 0.00456406
I0813 16:08:59.976310 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:08:59.976325 18283 solver.cpp:244]     Train net output #1: loss = 0.0045641 (* 1 = 0.0045641 loss)
I0813 16:08:59.976338 18283 sgd_solver.cpp:106] Iteration 31750, lr = 0.00342379
I0813 16:09:40.336633 18283 solver.cpp:337] Iteration 31800, Testing net (#0)
I0813 16:09:44.390969 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 16:09:44.391036 18283 solver.cpp:404]     Test net output #1: loss = 0.957326 (* 1 = 0.957326 loss)
I0813 16:09:45.201309 18283 solver.cpp:228] Iteration 31800, loss = 0.00275431
I0813 16:09:45.201364 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:09:45.201375 18283 solver.cpp:244]     Train net output #1: loss = 0.00275435 (* 1 = 0.00275435 loss)
I0813 16:09:45.201386 18283 sgd_solver.cpp:106] Iteration 31800, lr = 0.00342072
I0813 16:10:26.758852 18283 solver.cpp:228] Iteration 31850, loss = 0.0145118
I0813 16:10:26.759011 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:10:26.759024 18283 solver.cpp:244]     Train net output #1: loss = 0.0145119 (* 1 = 0.0145119 loss)
I0813 16:10:26.759037 18283 sgd_solver.cpp:106] Iteration 31850, lr = 0.00341766
I0813 16:11:07.106636 18283 solver.cpp:337] Iteration 31900, Testing net (#0)
I0813 16:11:11.161108 18283 solver.cpp:404]     Test net output #0: accuracy = 0.772
I0813 16:11:11.161175 18283 solver.cpp:404]     Test net output #1: loss = 0.836979 (* 1 = 0.836979 loss)
I0813 16:11:11.974689 18283 solver.cpp:228] Iteration 31900, loss = 0.00145236
I0813 16:11:11.974750 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:11:11.974762 18283 solver.cpp:244]     Train net output #1: loss = 0.0014524 (* 1 = 0.0014524 loss)
I0813 16:11:11.974774 18283 sgd_solver.cpp:106] Iteration 31900, lr = 0.0034146
I0813 16:11:53.099769 18283 solver.cpp:228] Iteration 31950, loss = 0.00493828
I0813 16:11:53.099934 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:11:53.099949 18283 solver.cpp:244]     Train net output #1: loss = 0.00493832 (* 1 = 0.00493832 loss)
I0813 16:11:53.099961 18283 sgd_solver.cpp:106] Iteration 31950, lr = 0.00341154
I0813 16:12:33.484490 18283 solver.cpp:337] Iteration 32000, Testing net (#0)
I0813 16:12:37.537968 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 16:12:37.538030 18283 solver.cpp:404]     Test net output #1: loss = 1.01251 (* 1 = 1.01251 loss)
I0813 16:12:38.350396 18283 solver.cpp:228] Iteration 32000, loss = 0.00646475
I0813 16:12:38.350453 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:12:38.350466 18283 solver.cpp:244]     Train net output #1: loss = 0.0064648 (* 1 = 0.0064648 loss)
I0813 16:12:38.350481 18283 sgd_solver.cpp:106] Iteration 32000, lr = 0.0034085
I0813 16:13:19.488659 18283 solver.cpp:228] Iteration 32050, loss = 0.0140893
I0813 16:13:19.488919 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:13:19.488967 18283 solver.cpp:244]     Train net output #1: loss = 0.0140894 (* 1 = 0.0140894 loss)
I0813 16:13:19.488987 18283 sgd_solver.cpp:106] Iteration 32050, lr = 0.00340546
I0813 16:13:59.836529 18283 solver.cpp:337] Iteration 32100, Testing net (#0)
I0813 16:14:04.156533 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 16:14:04.156600 18283 solver.cpp:404]     Test net output #1: loss = 0.885111 (* 1 = 0.885111 loss)
I0813 16:14:04.970470 18283 solver.cpp:228] Iteration 32100, loss = -4.19095e-08
I0813 16:14:04.970540 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:14:04.970549 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:14:04.970564 18283 sgd_solver.cpp:106] Iteration 32100, lr = 0.00340242
I0813 16:14:46.438630 18283 solver.cpp:228] Iteration 32150, loss = 0.00672402
I0813 16:14:46.438796 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:14:46.438809 18283 solver.cpp:244]     Train net output #1: loss = 0.00672406 (* 1 = 0.00672406 loss)
I0813 16:14:46.438822 18283 sgd_solver.cpp:106] Iteration 32150, lr = 0.0033994
I0813 16:15:27.229555 18283 solver.cpp:337] Iteration 32200, Testing net (#0)
I0813 16:15:31.496701 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 16:15:31.496764 18283 solver.cpp:404]     Test net output #1: loss = 0.957001 (* 1 = 0.957001 loss)
I0813 16:15:32.308529 18283 solver.cpp:228] Iteration 32200, loss = 0.00133634
I0813 16:15:32.308580 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:15:32.308590 18283 solver.cpp:244]     Train net output #1: loss = 0.00133638 (* 1 = 0.00133638 loss)
I0813 16:15:32.308609 18283 sgd_solver.cpp:106] Iteration 32200, lr = 0.00339637
I0813 16:16:13.460757 18283 solver.cpp:228] Iteration 32250, loss = 0.0185082
I0813 16:16:13.460921 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:16:13.460934 18283 solver.cpp:244]     Train net output #1: loss = 0.0185083 (* 1 = 0.0185083 loss)
I0813 16:16:13.460947 18283 sgd_solver.cpp:106] Iteration 32250, lr = 0.00339336
I0813 16:16:53.819103 18283 solver.cpp:337] Iteration 32300, Testing net (#0)
I0813 16:16:58.114356 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 16:16:58.114439 18283 solver.cpp:404]     Test net output #1: loss = 0.964612 (* 1 = 0.964612 loss)
I0813 16:16:58.928650 18283 solver.cpp:228] Iteration 32300, loss = 0.00143123
I0813 16:16:58.928714 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:16:58.928725 18283 solver.cpp:244]     Train net output #1: loss = 0.00143127 (* 1 = 0.00143127 loss)
I0813 16:16:58.928741 18283 sgd_solver.cpp:106] Iteration 32300, lr = 0.00339035
I0813 16:17:40.121402 18283 solver.cpp:228] Iteration 32350, loss = 0.00574464
I0813 16:17:40.121609 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:17:40.121661 18283 solver.cpp:244]     Train net output #1: loss = 0.00574468 (* 1 = 0.00574468 loss)
I0813 16:17:40.121682 18283 sgd_solver.cpp:106] Iteration 32350, lr = 0.00338735
I0813 16:18:21.023502 18283 solver.cpp:337] Iteration 32400, Testing net (#0)
I0813 16:18:25.082190 18283 solver.cpp:404]     Test net output #0: accuracy = 0.77
I0813 16:18:25.082273 18283 solver.cpp:404]     Test net output #1: loss = 0.93053 (* 1 = 0.93053 loss)
I0813 16:18:25.895692 18283 solver.cpp:228] Iteration 32400, loss = 0.0123874
I0813 16:18:25.895752 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:18:25.895763 18283 solver.cpp:244]     Train net output #1: loss = 0.0123874 (* 1 = 0.0123874 loss)
I0813 16:18:25.895779 18283 sgd_solver.cpp:106] Iteration 32400, lr = 0.00338435
I0813 16:19:07.060345 18283 solver.cpp:228] Iteration 32450, loss = 0.00251819
I0813 16:19:07.060585 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:19:07.060633 18283 solver.cpp:244]     Train net output #1: loss = 0.00251823 (* 1 = 0.00251823 loss)
I0813 16:19:07.060658 18283 sgd_solver.cpp:106] Iteration 32450, lr = 0.00338136
I0813 16:19:48.164885 18283 solver.cpp:337] Iteration 32500, Testing net (#0)
I0813 16:19:52.217207 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 16:19:52.217274 18283 solver.cpp:404]     Test net output #1: loss = 0.982777 (* 1 = 0.982777 loss)
I0813 16:19:53.027948 18283 solver.cpp:228] Iteration 32500, loss = 0.00124714
I0813 16:19:53.028017 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:19:53.028036 18283 solver.cpp:244]     Train net output #1: loss = 0.00124718 (* 1 = 0.00124718 loss)
I0813 16:19:53.028051 18283 sgd_solver.cpp:106] Iteration 32500, lr = 0.00337838
I0813 16:20:35.007848 18283 solver.cpp:228] Iteration 32550, loss = 0.00755832
I0813 16:20:35.008011 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:20:35.008035 18283 solver.cpp:244]     Train net output #1: loss = 0.00755836 (* 1 = 0.00755836 loss)
I0813 16:20:35.008049 18283 sgd_solver.cpp:106] Iteration 32550, lr = 0.0033754
I0813 16:21:15.658442 18283 solver.cpp:337] Iteration 32600, Testing net (#0)
I0813 16:21:19.718380 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 16:21:19.718459 18283 solver.cpp:404]     Test net output #1: loss = 1.04388 (* 1 = 1.04388 loss)
I0813 16:21:20.531664 18283 solver.cpp:228] Iteration 32600, loss = 0.000694358
I0813 16:21:20.531723 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:21:20.531734 18283 solver.cpp:244]     Train net output #1: loss = 0.000694399 (* 1 = 0.000694399 loss)
I0813 16:21:20.531752 18283 sgd_solver.cpp:106] Iteration 32600, lr = 0.00337243
I0813 16:22:01.695649 18283 solver.cpp:228] Iteration 32650, loss = -3.91155e-08
I0813 16:22:01.695823 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:22:01.695837 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:22:01.695850 18283 sgd_solver.cpp:106] Iteration 32650, lr = 0.00336946
I0813 16:22:42.020037 18283 solver.cpp:337] Iteration 32700, Testing net (#0)
I0813 16:22:46.069497 18283 solver.cpp:404]     Test net output #0: accuracy = 0.765
I0813 16:22:46.069573 18283 solver.cpp:404]     Test net output #1: loss = 0.95036 (* 1 = 0.95036 loss)
I0813 16:22:46.882463 18283 solver.cpp:228] Iteration 32700, loss = 0.00399553
I0813 16:22:46.882519 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:22:46.882529 18283 solver.cpp:244]     Train net output #1: loss = 0.00399557 (* 1 = 0.00399557 loss)
I0813 16:22:46.882541 18283 sgd_solver.cpp:106] Iteration 32700, lr = 0.0033665
I0813 16:23:28.039773 18283 solver.cpp:228] Iteration 32750, loss = -3.71656e-08
I0813 16:23:28.039916 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:23:28.039930 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:23:28.039954 18283 sgd_solver.cpp:106] Iteration 32750, lr = 0.00336355
I0813 16:24:08.400703 18283 solver.cpp:337] Iteration 32800, Testing net (#0)
I0813 16:24:12.463670 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 16:24:12.463737 18283 solver.cpp:404]     Test net output #1: loss = 0.955932 (* 1 = 0.955932 loss)
I0813 16:24:13.276276 18283 solver.cpp:228] Iteration 32800, loss = -3.72529e-08
I0813 16:24:13.276337 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:24:13.276348 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:24:13.276361 18283 sgd_solver.cpp:106] Iteration 32800, lr = 0.0033606
I0813 16:24:55.293149 18283 solver.cpp:228] Iteration 32850, loss = -3.72529e-08
I0813 16:24:55.293313 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:24:55.293326 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:24:55.293339 18283 sgd_solver.cpp:106] Iteration 32850, lr = 0.00335766
I0813 16:25:36.654525 18283 solver.cpp:337] Iteration 32900, Testing net (#0)
I0813 16:25:40.716781 18283 solver.cpp:404]     Test net output #0: accuracy = 0.771
I0813 16:25:40.716856 18283 solver.cpp:404]     Test net output #1: loss = 0.859931 (* 1 = 0.859931 loss)
I0813 16:25:41.528903 18283 solver.cpp:228] Iteration 32900, loss = 0.0147109
I0813 16:25:41.528960 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:25:41.528972 18283 solver.cpp:244]     Train net output #1: loss = 0.014711 (* 1 = 0.014711 loss)
I0813 16:25:41.528990 18283 sgd_solver.cpp:106] Iteration 32900, lr = 0.00335473
I0813 16:26:23.230708 18283 solver.cpp:228] Iteration 32950, loss = -3.35276e-08
I0813 16:26:23.230903 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:26:23.230917 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:26:23.230929 18283 sgd_solver.cpp:106] Iteration 32950, lr = 0.0033518
I0813 16:27:04.986413 18283 solver.cpp:337] Iteration 33000, Testing net (#0)
I0813 16:27:09.049911 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 16:27:09.049981 18283 solver.cpp:404]     Test net output #1: loss = 0.932535 (* 1 = 0.932535 loss)
I0813 16:27:09.862033 18283 solver.cpp:228] Iteration 33000, loss = 0.0203115
I0813 16:27:09.862089 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:27:09.862100 18283 solver.cpp:244]     Train net output #1: loss = 0.0203115 (* 1 = 0.0203115 loss)
I0813 16:27:09.862119 18283 sgd_solver.cpp:106] Iteration 33000, lr = 0.00334887
I0813 16:27:51.040666 18283 solver.cpp:228] Iteration 33050, loss = 0.000919484
I0813 16:27:51.040818 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:27:51.040832 18283 solver.cpp:244]     Train net output #1: loss = 0.000919513 (* 1 = 0.000919513 loss)
I0813 16:27:51.040846 18283 sgd_solver.cpp:106] Iteration 33050, lr = 0.00334596
I0813 16:28:31.397704 18283 solver.cpp:337] Iteration 33100, Testing net (#0)
I0813 16:28:35.460947 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 16:28:35.461026 18283 solver.cpp:404]     Test net output #1: loss = 0.950628 (* 1 = 0.950628 loss)
I0813 16:28:36.274919 18283 solver.cpp:228] Iteration 33100, loss = 0.010143
I0813 16:28:36.274981 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:28:36.274991 18283 solver.cpp:244]     Train net output #1: loss = 0.010143 (* 1 = 0.010143 loss)
I0813 16:28:36.275007 18283 sgd_solver.cpp:106] Iteration 33100, lr = 0.00334304
I0813 16:29:18.409911 18283 solver.cpp:228] Iteration 33150, loss = 0.0111114
I0813 16:29:18.410068 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:29:18.410084 18283 solver.cpp:244]     Train net output #1: loss = 0.0111114 (* 1 = 0.0111114 loss)
I0813 16:29:18.410094 18283 sgd_solver.cpp:106] Iteration 33150, lr = 0.00334014
I0813 16:29:58.770938 18283 solver.cpp:337] Iteration 33200, Testing net (#0)
I0813 16:30:02.826388 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 16:30:02.826457 18283 solver.cpp:404]     Test net output #1: loss = 1.0318 (* 1 = 1.0318 loss)
I0813 16:30:03.637961 18283 solver.cpp:228] Iteration 33200, loss = 0.0147271
I0813 16:30:03.638025 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:30:03.638037 18283 solver.cpp:244]     Train net output #1: loss = 0.0147271 (* 1 = 0.0147271 loss)
I0813 16:30:03.638052 18283 sgd_solver.cpp:106] Iteration 33200, lr = 0.00333724
I0813 16:30:44.807085 18283 solver.cpp:228] Iteration 33250, loss = 0.0239429
I0813 16:30:44.807281 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:30:44.807332 18283 solver.cpp:244]     Train net output #1: loss = 0.0239429 (* 1 = 0.0239429 loss)
I0813 16:30:44.807355 18283 sgd_solver.cpp:106] Iteration 33250, lr = 0.00333434
I0813 16:31:26.114583 18283 solver.cpp:337] Iteration 33300, Testing net (#0)
I0813 16:31:30.169124 18283 solver.cpp:404]     Test net output #0: accuracy = 0.77
I0813 16:31:30.169188 18283 solver.cpp:404]     Test net output #1: loss = 0.912623 (* 1 = 0.912623 loss)
I0813 16:31:30.980676 18283 solver.cpp:228] Iteration 33300, loss = 0.000144375
I0813 16:31:30.980732 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:31:30.980743 18283 solver.cpp:244]     Train net output #1: loss = 0.000144405 (* 1 = 0.000144405 loss)
I0813 16:31:30.980762 18283 sgd_solver.cpp:106] Iteration 33300, lr = 0.00333146
I0813 16:32:12.117697 18283 solver.cpp:228] Iteration 33350, loss = -3.1665e-08
I0813 16:32:12.117900 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:32:12.117915 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:32:12.117926 18283 sgd_solver.cpp:106] Iteration 33350, lr = 0.00332857
I0813 16:32:52.454614 18283 solver.cpp:337] Iteration 33400, Testing net (#0)
I0813 16:32:56.511947 18283 solver.cpp:404]     Test net output #0: accuracy = 0.768
I0813 16:32:56.512012 18283 solver.cpp:404]     Test net output #1: loss = 0.893469 (* 1 = 0.893469 loss)
I0813 16:32:57.324887 18283 solver.cpp:228] Iteration 33400, loss = 0.000958443
I0813 16:32:57.324937 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:32:57.324949 18283 solver.cpp:244]     Train net output #1: loss = 0.000958476 (* 1 = 0.000958476 loss)
I0813 16:32:57.324960 18283 sgd_solver.cpp:106] Iteration 33400, lr = 0.0033257
I0813 16:33:38.471966 18283 solver.cpp:228] Iteration 33450, loss = -3.1665e-08
I0813 16:33:38.472131 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:33:38.472143 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:33:38.472156 18283 sgd_solver.cpp:106] Iteration 33450, lr = 0.00332283
I0813 16:34:18.821779 18283 solver.cpp:337] Iteration 33500, Testing net (#0)
I0813 16:34:22.882637 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 16:34:22.882705 18283 solver.cpp:404]     Test net output #1: loss = 0.954777 (* 1 = 0.954777 loss)
I0813 16:34:23.696128 18283 solver.cpp:228] Iteration 33500, loss = 0.0141232
I0813 16:34:23.696180 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:34:23.696192 18283 solver.cpp:244]     Train net output #1: loss = 0.0141232 (* 1 = 0.0141232 loss)
I0813 16:34:23.696208 18283 sgd_solver.cpp:106] Iteration 33500, lr = 0.00331996
I0813 16:35:04.838750 18283 solver.cpp:228] Iteration 33550, loss = -3.1665e-08
I0813 16:35:04.838968 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:35:04.839017 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:35:04.839037 18283 sgd_solver.cpp:106] Iteration 33550, lr = 0.0033171
I0813 16:35:45.753290 18283 solver.cpp:337] Iteration 33600, Testing net (#0)
I0813 16:35:49.807229 18283 solver.cpp:404]     Test net output #0: accuracy = 0.743
I0813 16:35:49.807301 18283 solver.cpp:404]     Test net output #1: loss = 1.13201 (* 1 = 1.13201 loss)
I0813 16:35:50.619824 18283 solver.cpp:228] Iteration 33600, loss = 0.0206424
I0813 16:35:50.619879 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:35:50.619890 18283 solver.cpp:244]     Train net output #1: loss = 0.0206424 (* 1 = 0.0206424 loss)
I0813 16:35:50.619902 18283 sgd_solver.cpp:106] Iteration 33600, lr = 0.00331425
I0813 16:36:31.791172 18283 solver.cpp:228] Iteration 33650, loss = 0.0188677
I0813 16:36:31.791330 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:36:31.791344 18283 solver.cpp:244]     Train net output #1: loss = 0.0188677 (* 1 = 0.0188677 loss)
I0813 16:36:31.791355 18283 sgd_solver.cpp:106] Iteration 33650, lr = 0.0033114
I0813 16:37:12.761426 18283 solver.cpp:337] Iteration 33700, Testing net (#0)
I0813 16:37:17.161465 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 16:37:17.161550 18283 solver.cpp:404]     Test net output #1: loss = 1.01499 (* 1 = 1.01499 loss)
I0813 16:37:17.975363 18283 solver.cpp:228] Iteration 33700, loss = -2.6077e-08
I0813 16:37:17.975431 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:37:17.975443 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:37:17.975456 18283 sgd_solver.cpp:106] Iteration 33700, lr = 0.00330856
I0813 16:37:59.179553 18283 solver.cpp:228] Iteration 33750, loss = 0.0165233
I0813 16:37:59.179744 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:37:59.179759 18283 solver.cpp:244]     Train net output #1: loss = 0.0165233 (* 1 = 0.0165233 loss)
I0813 16:37:59.179770 18283 sgd_solver.cpp:106] Iteration 33750, lr = 0.00330572
I0813 16:38:39.536895 18283 solver.cpp:337] Iteration 33800, Testing net (#0)
I0813 16:38:43.592890 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 16:38:43.592968 18283 solver.cpp:404]     Test net output #1: loss = 0.993229 (* 1 = 0.993229 loss)
I0813 16:38:44.406185 18283 solver.cpp:228] Iteration 33800, loss = 1.75421e-05
I0813 16:38:44.406244 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:38:44.406255 18283 solver.cpp:244]     Train net output #1: loss = 1.75709e-05 (* 1 = 1.75709e-05 loss)
I0813 16:38:44.406271 18283 sgd_solver.cpp:106] Iteration 33800, lr = 0.00330289
I0813 16:39:25.562166 18283 solver.cpp:228] Iteration 33850, loss = 0.00754789
I0813 16:39:25.562316 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:39:25.562330 18283 solver.cpp:244]     Train net output #1: loss = 0.00754792 (* 1 = 0.00754792 loss)
I0813 16:39:25.562342 18283 sgd_solver.cpp:106] Iteration 33850, lr = 0.00330007
I0813 16:40:05.924980 18283 solver.cpp:337] Iteration 33900, Testing net (#0)
I0813 16:40:09.988240 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 16:40:09.988309 18283 solver.cpp:404]     Test net output #1: loss = 0.946315 (* 1 = 0.946315 loss)
I0813 16:40:10.801972 18283 solver.cpp:228] Iteration 33900, loss = 0.0031251
I0813 16:40:10.802029 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:40:10.802040 18283 solver.cpp:244]     Train net output #1: loss = 0.00312513 (* 1 = 0.00312513 loss)
I0813 16:40:10.802060 18283 sgd_solver.cpp:106] Iteration 33900, lr = 0.00329725
I0813 16:40:51.944561 18283 solver.cpp:228] Iteration 33950, loss = 0.00505528
I0813 16:40:51.944725 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:40:51.944738 18283 solver.cpp:244]     Train net output #1: loss = 0.00505531 (* 1 = 0.00505531 loss)
I0813 16:40:51.944751 18283 sgd_solver.cpp:106] Iteration 33950, lr = 0.00329443
I0813 16:41:32.309768 18283 solver.cpp:337] Iteration 34000, Testing net (#0)
I0813 16:41:36.630079 18283 solver.cpp:404]     Test net output #0: accuracy = 0.742
I0813 16:41:36.630146 18283 solver.cpp:404]     Test net output #1: loss = 1.0747 (* 1 = 1.0747 loss)
I0813 16:41:37.443497 18283 solver.cpp:228] Iteration 34000, loss = 0.0213867
I0813 16:41:37.443562 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:41:37.443574 18283 solver.cpp:244]     Train net output #1: loss = 0.0213868 (* 1 = 0.0213868 loss)
I0813 16:41:37.443588 18283 sgd_solver.cpp:106] Iteration 34000, lr = 0.00329163
I0813 16:42:18.598875 18283 solver.cpp:228] Iteration 34050, loss = 0.0073586
I0813 16:42:18.599038 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:42:18.599052 18283 solver.cpp:244]     Train net output #1: loss = 0.00735863 (* 1 = 0.00735863 loss)
I0813 16:42:18.599064 18283 sgd_solver.cpp:106] Iteration 34050, lr = 0.00328882
I0813 16:42:58.940439 18283 solver.cpp:337] Iteration 34100, Testing net (#0)
I0813 16:43:03.001113 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 16:43:03.001178 18283 solver.cpp:404]     Test net output #1: loss = 0.896352 (* 1 = 0.896352 loss)
I0813 16:43:03.815084 18283 solver.cpp:228] Iteration 34100, loss = 0.0025667
I0813 16:43:03.815137 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:43:03.815150 18283 solver.cpp:244]     Train net output #1: loss = 0.00256673 (* 1 = 0.00256673 loss)
I0813 16:43:03.815160 18283 sgd_solver.cpp:106] Iteration 34100, lr = 0.00328603
I0813 16:43:44.970165 18283 solver.cpp:228] Iteration 34150, loss = 0.00440785
I0813 16:43:44.970329 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:43:44.970342 18283 solver.cpp:244]     Train net output #1: loss = 0.00440788 (* 1 = 0.00440788 loss)
I0813 16:43:44.970355 18283 sgd_solver.cpp:106] Iteration 34150, lr = 0.00328324
I0813 16:44:25.323218 18283 solver.cpp:337] Iteration 34200, Testing net (#0)
I0813 16:44:29.688588 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 16:44:29.688653 18283 solver.cpp:404]     Test net output #1: loss = 1.09661 (* 1 = 1.09661 loss)
I0813 16:44:30.502656 18283 solver.cpp:228] Iteration 34200, loss = 0.0116325
I0813 16:44:30.502725 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:44:30.502737 18283 solver.cpp:244]     Train net output #1: loss = 0.0116325 (* 1 = 0.0116325 loss)
I0813 16:44:30.502751 18283 sgd_solver.cpp:106] Iteration 34200, lr = 0.00328045
I0813 16:45:12.463222 18283 solver.cpp:228] Iteration 34250, loss = 0.0082534
I0813 16:45:12.463418 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:45:12.463465 18283 solver.cpp:244]     Train net output #1: loss = 0.00825343 (* 1 = 0.00825343 loss)
I0813 16:45:12.463485 18283 sgd_solver.cpp:106] Iteration 34250, lr = 0.00327767
I0813 16:45:53.441936 18283 solver.cpp:337] Iteration 34300, Testing net (#0)
I0813 16:45:57.498216 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 16:45:57.498283 18283 solver.cpp:404]     Test net output #1: loss = 0.900472 (* 1 = 0.900472 loss)
I0813 16:45:58.311305 18283 solver.cpp:228] Iteration 34300, loss = 0.00646557
I0813 16:45:58.311369 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:45:58.311383 18283 solver.cpp:244]     Train net output #1: loss = 0.0064656 (* 1 = 0.0064656 loss)
I0813 16:45:58.311396 18283 sgd_solver.cpp:106] Iteration 34300, lr = 0.00327489
I0813 16:46:39.455276 18283 solver.cpp:228] Iteration 34350, loss = 0.00187487
I0813 16:46:39.455445 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:46:39.455458 18283 solver.cpp:244]     Train net output #1: loss = 0.0018749 (* 1 = 0.0018749 loss)
I0813 16:46:39.455471 18283 sgd_solver.cpp:106] Iteration 34350, lr = 0.00327212
I0813 16:47:19.801590 18283 solver.cpp:337] Iteration 34400, Testing net (#0)
I0813 16:47:23.858081 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 16:47:23.858150 18283 solver.cpp:404]     Test net output #1: loss = 1.03635 (* 1 = 1.03635 loss)
I0813 16:47:24.671119 18283 solver.cpp:228] Iteration 34400, loss = 0.00539933
I0813 16:47:24.671178 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:47:24.671190 18283 solver.cpp:244]     Train net output #1: loss = 0.00539936 (* 1 = 0.00539936 loss)
I0813 16:47:24.671205 18283 sgd_solver.cpp:106] Iteration 34400, lr = 0.00326936
I0813 16:48:05.842332 18283 solver.cpp:228] Iteration 34450, loss = 0.00415756
I0813 16:48:05.842489 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:48:05.842504 18283 solver.cpp:244]     Train net output #1: loss = 0.00415759 (* 1 = 0.00415759 loss)
I0813 16:48:05.842514 18283 sgd_solver.cpp:106] Iteration 34450, lr = 0.0032666
I0813 16:48:46.823127 18283 solver.cpp:337] Iteration 34500, Testing net (#0)
I0813 16:48:50.880607 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 16:48:50.880681 18283 solver.cpp:404]     Test net output #1: loss = 0.967182 (* 1 = 0.967182 loss)
I0813 16:48:51.694344 18283 solver.cpp:228] Iteration 34500, loss = 0.00170932
I0813 16:48:51.694401 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:48:51.694412 18283 solver.cpp:244]     Train net output #1: loss = 0.00170935 (* 1 = 0.00170935 loss)
I0813 16:48:51.694425 18283 sgd_solver.cpp:106] Iteration 34500, lr = 0.00326385
I0813 16:49:32.895906 18283 solver.cpp:228] Iteration 34550, loss = 0.0206218
I0813 16:49:32.896075 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 16:49:32.896090 18283 solver.cpp:244]     Train net output #1: loss = 0.0206219 (* 1 = 0.0206219 loss)
I0813 16:49:32.896105 18283 sgd_solver.cpp:106] Iteration 34550, lr = 0.0032611
I0813 16:50:13.264132 18283 solver.cpp:337] Iteration 34600, Testing net (#0)
I0813 16:50:17.315199 18283 solver.cpp:404]     Test net output #0: accuracy = 0.754
I0813 16:50:17.315270 18283 solver.cpp:404]     Test net output #1: loss = 0.975175 (* 1 = 0.975175 loss)
I0813 16:50:18.127820 18283 solver.cpp:228] Iteration 34600, loss = 0.0080016
I0813 16:50:18.127888 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:50:18.127900 18283 solver.cpp:244]     Train net output #1: loss = 0.00800163 (* 1 = 0.00800163 loss)
I0813 16:50:18.127913 18283 sgd_solver.cpp:106] Iteration 34600, lr = 0.00325836
I0813 16:50:59.309940 18283 solver.cpp:228] Iteration 34650, loss = 0.0105098
I0813 16:50:59.310180 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:50:59.310242 18283 solver.cpp:244]     Train net output #1: loss = 0.0105098 (* 1 = 0.0105098 loss)
I0813 16:50:59.310271 18283 sgd_solver.cpp:106] Iteration 34650, lr = 0.00325562
I0813 16:51:40.039161 18283 solver.cpp:337] Iteration 34700, Testing net (#0)
I0813 16:51:44.089578 18283 solver.cpp:404]     Test net output #0: accuracy = 0.748
I0813 16:51:44.089661 18283 solver.cpp:404]     Test net output #1: loss = 1.02279 (* 1 = 1.02279 loss)
I0813 16:51:44.902699 18283 solver.cpp:228] Iteration 34700, loss = 0.0127986
I0813 16:51:44.902755 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:51:44.902767 18283 solver.cpp:244]     Train net output #1: loss = 0.0127987 (* 1 = 0.0127987 loss)
I0813 16:51:44.902779 18283 sgd_solver.cpp:106] Iteration 34700, lr = 0.00325289
I0813 16:52:26.051295 18283 solver.cpp:228] Iteration 34750, loss = 0.000379754
I0813 16:52:26.051522 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:52:26.051586 18283 solver.cpp:244]     Train net output #1: loss = 0.000379784 (* 1 = 0.000379784 loss)
I0813 16:52:26.051611 18283 sgd_solver.cpp:106] Iteration 34750, lr = 0.00325016
I0813 16:53:07.274720 18283 solver.cpp:337] Iteration 34800, Testing net (#0)
I0813 16:53:11.563568 18283 solver.cpp:404]     Test net output #0: accuracy = 0.735
I0813 16:53:11.563639 18283 solver.cpp:404]     Test net output #1: loss = 1.06996 (* 1 = 1.06996 loss)
I0813 16:53:12.377090 18283 solver.cpp:228] Iteration 34800, loss = 0.00735901
I0813 16:53:12.377148 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:53:12.377161 18283 solver.cpp:244]     Train net output #1: loss = 0.00735904 (* 1 = 0.00735904 loss)
I0813 16:53:12.377174 18283 sgd_solver.cpp:106] Iteration 34800, lr = 0.00324744
I0813 16:53:54.800904 18283 solver.cpp:228] Iteration 34850, loss = -2.90456e-08
I0813 16:53:54.801069 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:53:54.801084 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:53:54.801096 18283 sgd_solver.cpp:106] Iteration 34850, lr = 0.00324473
I0813 16:54:35.811337 18283 solver.cpp:337] Iteration 34900, Testing net (#0)
I0813 16:54:40.069072 18283 solver.cpp:404]     Test net output #0: accuracy = 0.767
I0813 16:54:40.069136 18283 solver.cpp:404]     Test net output #1: loss = 0.900314 (* 1 = 0.900314 loss)
I0813 16:54:40.882730 18283 solver.cpp:228] Iteration 34900, loss = 0.00095985
I0813 16:54:40.882782 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:54:40.882793 18283 solver.cpp:244]     Train net output #1: loss = 0.000959881 (* 1 = 0.000959881 loss)
I0813 16:54:40.882810 18283 sgd_solver.cpp:106] Iteration 34900, lr = 0.00324202
I0813 16:55:22.039108 18283 solver.cpp:228] Iteration 34950, loss = -2.58442e-08
I0813 16:55:22.039265 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:55:22.039279 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:55:22.039290 18283 sgd_solver.cpp:106] Iteration 34950, lr = 0.00323931
I0813 16:56:02.400987 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_35000.caffemodel
I0813 16:56:02.732602 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_35000.solverstate
I0813 16:56:02.745666 18283 solver.cpp:337] Iteration 35000, Testing net (#0)
I0813 16:56:06.796005 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 16:56:06.796077 18283 solver.cpp:404]     Test net output #1: loss = 0.970704 (* 1 = 0.970704 loss)
I0813 16:56:07.609019 18283 solver.cpp:228] Iteration 35000, loss = 0.0034071
I0813 16:56:07.609067 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:56:07.609078 18283 solver.cpp:244]     Train net output #1: loss = 0.00340713 (* 1 = 0.00340713 loss)
I0813 16:56:07.609097 18283 sgd_solver.cpp:106] Iteration 35000, lr = 0.00323661
I0813 16:56:48.793783 18283 solver.cpp:228] Iteration 35050, loss = 0.00382537
I0813 16:56:48.794034 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:56:48.794090 18283 solver.cpp:244]     Train net output #1: loss = 0.0038254 (* 1 = 0.0038254 loss)
I0813 16:56:48.794114 18283 sgd_solver.cpp:106] Iteration 35050, lr = 0.00323392
I0813 16:57:29.751410 18283 solver.cpp:337] Iteration 35100, Testing net (#0)
I0813 16:57:33.818886 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 16:57:33.818958 18283 solver.cpp:404]     Test net output #1: loss = 0.93831 (* 1 = 0.93831 loss)
I0813 16:57:34.632241 18283 solver.cpp:228] Iteration 35100, loss = -2.23517e-08
I0813 16:57:34.632299 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:57:34.632310 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 16:57:34.632323 18283 sgd_solver.cpp:106] Iteration 35100, lr = 0.00323123
I0813 16:58:15.801753 18283 solver.cpp:228] Iteration 35150, loss = 0.00785199
I0813 16:58:15.801909 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:58:15.801923 18283 solver.cpp:244]     Train net output #1: loss = 0.00785201 (* 1 = 0.00785201 loss)
I0813 16:58:15.801935 18283 sgd_solver.cpp:106] Iteration 35150, lr = 0.00322854
I0813 16:58:56.168712 18283 solver.cpp:337] Iteration 35200, Testing net (#0)
I0813 16:59:00.231395 18283 solver.cpp:404]     Test net output #0: accuracy = 0.776
I0813 16:59:00.231461 18283 solver.cpp:404]     Test net output #1: loss = 0.859824 (* 1 = 0.859824 loss)
I0813 16:59:01.044644 18283 solver.cpp:228] Iteration 35200, loss = 2.21138e-05
I0813 16:59:01.044703 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:59:01.044714 18283 solver.cpp:244]     Train net output #1: loss = 2.21324e-05 (* 1 = 2.21324e-05 loss)
I0813 16:59:01.044726 18283 sgd_solver.cpp:106] Iteration 35200, lr = 0.00322586
I0813 16:59:42.226351 18283 solver.cpp:228] Iteration 35250, loss = 0.00185507
I0813 16:59:42.226555 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 16:59:42.226608 18283 solver.cpp:244]     Train net output #1: loss = 0.00185509 (* 1 = 0.00185509 loss)
I0813 16:59:42.226630 18283 sgd_solver.cpp:106] Iteration 35250, lr = 0.00322319
I0813 17:00:22.785838 18283 solver.cpp:337] Iteration 35300, Testing net (#0)
I0813 17:00:26.836055 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 17:00:26.836120 18283 solver.cpp:404]     Test net output #1: loss = 1.06302 (* 1 = 1.06302 loss)
I0813 17:00:27.649108 18283 solver.cpp:228] Iteration 35300, loss = 0.00774547
I0813 17:00:27.649164 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:00:27.649175 18283 solver.cpp:244]     Train net output #1: loss = 0.0077455 (* 1 = 0.0077455 loss)
I0813 17:00:27.649194 18283 sgd_solver.cpp:106] Iteration 35300, lr = 0.00322052
I0813 17:01:08.816051 18283 solver.cpp:228] Iteration 35350, loss = 0.000788864
I0813 17:01:08.816200 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:01:08.816215 18283 solver.cpp:244]     Train net output #1: loss = 0.000788894 (* 1 = 0.000788894 loss)
I0813 17:01:08.816226 18283 sgd_solver.cpp:106] Iteration 35350, lr = 0.00321786
I0813 17:01:49.190045 18283 solver.cpp:337] Iteration 35400, Testing net (#0)
I0813 17:01:53.290407 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 17:01:53.290472 18283 solver.cpp:404]     Test net output #1: loss = 0.971676 (* 1 = 0.971676 loss)
I0813 17:01:54.104369 18283 solver.cpp:228] Iteration 35400, loss = 0.00248891
I0813 17:01:54.104424 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:01:54.104436 18283 solver.cpp:244]     Train net output #1: loss = 0.00248895 (* 1 = 0.00248895 loss)
I0813 17:01:54.104449 18283 sgd_solver.cpp:106] Iteration 35400, lr = 0.0032152
I0813 17:02:35.309854 18283 solver.cpp:228] Iteration 35450, loss = -3.53903e-08
I0813 17:02:35.310097 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:02:35.310181 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:02:35.310204 18283 sgd_solver.cpp:106] Iteration 35450, lr = 0.00321255
I0813 17:03:15.675881 18283 solver.cpp:337] Iteration 35500, Testing net (#0)
I0813 17:03:19.733366 18283 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0813 17:03:19.733429 18283 solver.cpp:404]     Test net output #1: loss = 0.990854 (* 1 = 0.990854 loss)
I0813 17:03:20.545969 18283 solver.cpp:228] Iteration 35500, loss = 0.0273413
I0813 17:03:20.546026 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:03:20.546038 18283 solver.cpp:244]     Train net output #1: loss = 0.0273413 (* 1 = 0.0273413 loss)
I0813 17:03:20.546053 18283 sgd_solver.cpp:106] Iteration 35500, lr = 0.0032099
I0813 17:04:01.696305 18283 solver.cpp:228] Iteration 35550, loss = 0.0138457
I0813 17:04:01.696476 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:04:01.696491 18283 solver.cpp:244]     Train net output #1: loss = 0.0138457 (* 1 = 0.0138457 loss)
I0813 17:04:01.696502 18283 sgd_solver.cpp:106] Iteration 35550, lr = 0.00320726
I0813 17:04:42.058019 18283 solver.cpp:337] Iteration 35600, Testing net (#0)
I0813 17:04:46.130848 18283 solver.cpp:404]     Test net output #0: accuracy = 0.769
I0813 17:04:46.130918 18283 solver.cpp:404]     Test net output #1: loss = 0.887961 (* 1 = 0.887961 loss)
I0813 17:04:46.942504 18283 solver.cpp:228] Iteration 35600, loss = 0.00206346
I0813 17:04:46.942562 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:04:46.942574 18283 solver.cpp:244]     Train net output #1: loss = 0.0020635 (* 1 = 0.0020635 loss)
I0813 17:04:46.942592 18283 sgd_solver.cpp:106] Iteration 35600, lr = 0.00320462
I0813 17:05:28.113885 18283 solver.cpp:228] Iteration 35650, loss = 0.010899
I0813 17:05:28.114045 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:05:28.114060 18283 solver.cpp:244]     Train net output #1: loss = 0.0108991 (* 1 = 0.0108991 loss)
I0813 17:05:28.114073 18283 sgd_solver.cpp:106] Iteration 35650, lr = 0.00320199
I0813 17:06:08.484009 18283 solver.cpp:337] Iteration 35700, Testing net (#0)
I0813 17:06:12.753988 18283 solver.cpp:404]     Test net output #0: accuracy = 0.781
I0813 17:06:12.754052 18283 solver.cpp:404]     Test net output #1: loss = 0.840532 (* 1 = 0.840532 loss)
I0813 17:06:13.565960 18283 solver.cpp:228] Iteration 35700, loss = 0.0124359
I0813 17:06:13.566014 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:06:13.566025 18283 solver.cpp:244]     Train net output #1: loss = 0.0124359 (* 1 = 0.0124359 loss)
I0813 17:06:13.566037 18283 sgd_solver.cpp:106] Iteration 35700, lr = 0.00319936
I0813 17:06:55.065655 18283 solver.cpp:228] Iteration 35750, loss = 0.000930872
I0813 17:06:55.065886 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:06:55.065942 18283 solver.cpp:244]     Train net output #1: loss = 0.000930903 (* 1 = 0.000930903 loss)
I0813 17:06:55.065965 18283 sgd_solver.cpp:106] Iteration 35750, lr = 0.00319674
I0813 17:07:36.103637 18283 solver.cpp:337] Iteration 35800, Testing net (#0)
I0813 17:07:40.389854 18283 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0813 17:07:40.389932 18283 solver.cpp:404]     Test net output #1: loss = 0.941583 (* 1 = 0.941583 loss)
I0813 17:07:41.203461 18283 solver.cpp:228] Iteration 35800, loss = 0.013672
I0813 17:07:41.203531 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:07:41.203541 18283 solver.cpp:244]     Train net output #1: loss = 0.013672 (* 1 = 0.013672 loss)
I0813 17:07:41.203555 18283 sgd_solver.cpp:106] Iteration 35800, lr = 0.00319412
I0813 17:08:22.847874 18283 solver.cpp:228] Iteration 35850, loss = 0.000411356
I0813 17:08:22.848076 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:08:22.848091 18283 solver.cpp:244]     Train net output #1: loss = 0.000411385 (* 1 = 0.000411385 loss)
I0813 17:08:22.848105 18283 sgd_solver.cpp:106] Iteration 35850, lr = 0.0031915
I0813 17:09:03.392154 18283 solver.cpp:337] Iteration 35900, Testing net (#0)
I0813 17:09:07.455077 18283 solver.cpp:404]     Test net output #0: accuracy = 0.754
I0813 17:09:07.455153 18283 solver.cpp:404]     Test net output #1: loss = 0.959158 (* 1 = 0.959158 loss)
I0813 17:09:08.267078 18283 solver.cpp:228] Iteration 35900, loss = 0.00764294
I0813 17:09:08.267133 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:09:08.267145 18283 solver.cpp:244]     Train net output #1: loss = 0.00764297 (* 1 = 0.00764297 loss)
I0813 17:09:08.267163 18283 sgd_solver.cpp:106] Iteration 35900, lr = 0.0031889
I0813 17:09:49.866426 18283 solver.cpp:228] Iteration 35950, loss = 0.00561317
I0813 17:09:49.866595 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:09:49.866610 18283 solver.cpp:244]     Train net output #1: loss = 0.0056132 (* 1 = 0.0056132 loss)
I0813 17:09:49.866621 18283 sgd_solver.cpp:106] Iteration 35950, lr = 0.00318629
I0813 17:10:30.869165 18283 solver.cpp:337] Iteration 36000, Testing net (#0)
I0813 17:10:35.208001 18283 solver.cpp:404]     Test net output #0: accuracy = 0.773
I0813 17:10:35.208075 18283 solver.cpp:404]     Test net output #1: loss = 0.807568 (* 1 = 0.807568 loss)
I0813 17:10:36.022774 18283 solver.cpp:228] Iteration 36000, loss = -3.35276e-08
I0813 17:10:36.022845 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:10:36.022855 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:10:36.022871 18283 sgd_solver.cpp:106] Iteration 36000, lr = 0.0031837
I0813 17:11:17.212375 18283 solver.cpp:228] Iteration 36050, loss = 0.0131748
I0813 17:11:17.212581 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:11:17.212637 18283 solver.cpp:244]     Train net output #1: loss = 0.0131748 (* 1 = 0.0131748 loss)
I0813 17:11:17.212661 18283 sgd_solver.cpp:106] Iteration 36050, lr = 0.0031811
I0813 17:11:57.779503 18283 solver.cpp:337] Iteration 36100, Testing net (#0)
I0813 17:12:01.833503 18283 solver.cpp:404]     Test net output #0: accuracy = 0.77
I0813 17:12:01.833566 18283 solver.cpp:404]     Test net output #1: loss = 0.865398 (* 1 = 0.865398 loss)
I0813 17:12:02.646339 18283 solver.cpp:228] Iteration 36100, loss = 0.000767205
I0813 17:12:02.646394 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:12:02.646406 18283 solver.cpp:244]     Train net output #1: loss = 0.000767238 (* 1 = 0.000767238 loss)
I0813 17:12:02.646423 18283 sgd_solver.cpp:106] Iteration 36100, lr = 0.00317852
I0813 17:12:43.778789 18283 solver.cpp:228] Iteration 36150, loss = 0.00975835
I0813 17:12:43.778991 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:12:43.779058 18283 solver.cpp:244]     Train net output #1: loss = 0.00975838 (* 1 = 0.00975838 loss)
I0813 17:12:43.779083 18283 sgd_solver.cpp:106] Iteration 36150, lr = 0.00317593
I0813 17:13:24.886729 18283 solver.cpp:337] Iteration 36200, Testing net (#0)
I0813 17:13:29.127588 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 17:13:29.127650 18283 solver.cpp:404]     Test net output #1: loss = 0.989133 (* 1 = 0.989133 loss)
I0813 17:13:29.941339 18283 solver.cpp:228] Iteration 36200, loss = 0.00430171
I0813 17:13:29.941404 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:13:29.941416 18283 solver.cpp:244]     Train net output #1: loss = 0.00430174 (* 1 = 0.00430174 loss)
I0813 17:13:29.941434 18283 sgd_solver.cpp:106] Iteration 36200, lr = 0.00317335
I0813 17:14:11.129271 18283 solver.cpp:228] Iteration 36250, loss = 0.00818995
I0813 17:14:11.129432 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:14:11.129446 18283 solver.cpp:244]     Train net output #1: loss = 0.00818998 (* 1 = 0.00818998 loss)
I0813 17:14:11.129461 18283 sgd_solver.cpp:106] Iteration 36250, lr = 0.00317078
I0813 17:14:51.462366 18283 solver.cpp:337] Iteration 36300, Testing net (#0)
I0813 17:14:55.744050 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 17:14:55.744117 18283 solver.cpp:404]     Test net output #1: loss = 0.996866 (* 1 = 0.996866 loss)
I0813 17:14:56.556609 18283 solver.cpp:228] Iteration 36300, loss = 0.025804
I0813 17:14:56.556666 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 17:14:56.556679 18283 solver.cpp:244]     Train net output #1: loss = 0.025804 (* 1 = 0.025804 loss)
I0813 17:14:56.556695 18283 sgd_solver.cpp:106] Iteration 36300, lr = 0.00316821
I0813 17:15:37.730626 18283 solver.cpp:228] Iteration 36350, loss = 0.000238832
I0813 17:15:37.730829 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:15:37.730883 18283 solver.cpp:244]     Train net output #1: loss = 0.000238866 (* 1 = 0.000238866 loss)
I0813 17:15:37.730921 18283 sgd_solver.cpp:106] Iteration 36350, lr = 0.00316565
I0813 17:16:18.545624 18283 solver.cpp:337] Iteration 36400, Testing net (#0)
I0813 17:16:22.611232 18283 solver.cpp:404]     Test net output #0: accuracy = 0.747
I0813 17:16:22.611300 18283 solver.cpp:404]     Test net output #1: loss = 1.02199 (* 1 = 1.02199 loss)
I0813 17:16:23.424348 18283 solver.cpp:228] Iteration 36400, loss = -3.3062e-08
I0813 17:16:23.424404 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:16:23.424415 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:16:23.424427 18283 sgd_solver.cpp:106] Iteration 36400, lr = 0.00316309
I0813 17:17:04.609143 18283 solver.cpp:228] Iteration 36450, loss = 0.000124532
I0813 17:17:04.609339 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:17:04.609355 18283 solver.cpp:244]     Train net output #1: loss = 0.000124566 (* 1 = 0.000124566 loss)
I0813 17:17:04.609369 18283 sgd_solver.cpp:106] Iteration 36450, lr = 0.00316054
I0813 17:17:45.839591 18283 solver.cpp:337] Iteration 36500, Testing net (#0)
I0813 17:17:50.004469 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 17:17:50.004551 18283 solver.cpp:404]     Test net output #1: loss = 1.02189 (* 1 = 1.02189 loss)
I0813 17:17:50.818619 18283 solver.cpp:228] Iteration 36500, loss = 0.0016388
I0813 17:17:50.818676 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:17:50.818689 18283 solver.cpp:244]     Train net output #1: loss = 0.00163883 (* 1 = 0.00163883 loss)
I0813 17:17:50.818708 18283 sgd_solver.cpp:106] Iteration 36500, lr = 0.00315799
I0813 17:18:32.529258 18283 solver.cpp:228] Iteration 36550, loss = 0.000332895
I0813 17:18:32.529484 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:18:32.529541 18283 solver.cpp:244]     Train net output #1: loss = 0.000332931 (* 1 = 0.000332931 loss)
I0813 17:18:32.529563 18283 sgd_solver.cpp:106] Iteration 36550, lr = 0.00315544
I0813 17:19:13.312285 18283 solver.cpp:337] Iteration 36600, Testing net (#0)
I0813 17:19:17.371084 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 17:19:17.371165 18283 solver.cpp:404]     Test net output #1: loss = 0.990914 (* 1 = 0.990914 loss)
I0813 17:19:18.184484 18283 solver.cpp:228] Iteration 36600, loss = -3.53903e-08
I0813 17:19:18.184538 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:19:18.184548 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:19:18.184566 18283 sgd_solver.cpp:106] Iteration 36600, lr = 0.0031529
I0813 17:19:59.354527 18283 solver.cpp:228] Iteration 36650, loss = 1.92905e-05
I0813 17:19:59.354699 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:19:59.354713 18283 solver.cpp:244]     Train net output #1: loss = 1.93262e-05 (* 1 = 1.93262e-05 loss)
I0813 17:19:59.354727 18283 sgd_solver.cpp:106] Iteration 36650, lr = 0.00315037
I0813 17:20:39.696562 18283 solver.cpp:337] Iteration 36700, Testing net (#0)
I0813 17:20:43.752333 18283 solver.cpp:404]     Test net output #0: accuracy = 0.748
I0813 17:20:43.752401 18283 solver.cpp:404]     Test net output #1: loss = 1.01912 (* 1 = 1.01912 loss)
I0813 17:20:44.564425 18283 solver.cpp:228] Iteration 36700, loss = 0.00320869
I0813 17:20:44.564487 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:20:44.564499 18283 solver.cpp:244]     Train net output #1: loss = 0.00320872 (* 1 = 0.00320872 loss)
I0813 17:20:44.564512 18283 sgd_solver.cpp:106] Iteration 36700, lr = 0.00314784
I0813 17:21:25.717711 18283 solver.cpp:228] Iteration 36750, loss = 0.000189711
I0813 17:21:25.717880 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:21:25.717895 18283 solver.cpp:244]     Train net output #1: loss = 0.000189745 (* 1 = 0.000189745 loss)
I0813 17:21:25.717906 18283 sgd_solver.cpp:106] Iteration 36750, lr = 0.00314531
I0813 17:22:06.072862 18283 solver.cpp:337] Iteration 36800, Testing net (#0)
I0813 17:22:10.119330 18283 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0813 17:22:10.119392 18283 solver.cpp:404]     Test net output #1: loss = 1.10304 (* 1 = 1.10304 loss)
I0813 17:22:10.932166 18283 solver.cpp:228] Iteration 36800, loss = 0.0126356
I0813 17:22:10.932220 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:22:10.932232 18283 solver.cpp:244]     Train net output #1: loss = 0.0126356 (* 1 = 0.0126356 loss)
I0813 17:22:10.932248 18283 sgd_solver.cpp:106] Iteration 36800, lr = 0.00314279
I0813 17:22:52.613467 18283 solver.cpp:228] Iteration 36850, loss = 0.00197547
I0813 17:22:52.613632 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:22:52.613647 18283 solver.cpp:244]     Train net output #1: loss = 0.00197551 (* 1 = 0.00197551 loss)
I0813 17:22:52.613659 18283 sgd_solver.cpp:106] Iteration 36850, lr = 0.00314028
I0813 17:23:33.371783 18283 solver.cpp:337] Iteration 36900, Testing net (#0)
I0813 17:23:37.431468 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 17:23:37.431536 18283 solver.cpp:404]     Test net output #1: loss = 0.980138 (* 1 = 0.980138 loss)
I0813 17:23:38.243959 18283 solver.cpp:228] Iteration 36900, loss = 0.00399748
I0813 17:23:38.244010 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:23:38.244020 18283 solver.cpp:244]     Train net output #1: loss = 0.00399751 (* 1 = 0.00399751 loss)
I0813 17:23:38.244056 18283 sgd_solver.cpp:106] Iteration 36900, lr = 0.00313776
I0813 17:24:19.402701 18283 solver.cpp:228] Iteration 36950, loss = 0.00245345
I0813 17:24:19.402941 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:24:19.403024 18283 solver.cpp:244]     Train net output #1: loss = 0.00245348 (* 1 = 0.00245348 loss)
I0813 17:24:19.403043 18283 sgd_solver.cpp:106] Iteration 36950, lr = 0.00313526
I0813 17:24:59.761149 18283 solver.cpp:337] Iteration 37000, Testing net (#0)
I0813 17:25:03.820847 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 17:25:03.820910 18283 solver.cpp:404]     Test net output #1: loss = 0.967186 (* 1 = 0.967186 loss)
I0813 17:25:04.634769 18283 solver.cpp:228] Iteration 37000, loss = 0.00364219
I0813 17:25:04.634817 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:25:04.634829 18283 solver.cpp:244]     Train net output #1: loss = 0.00364222 (* 1 = 0.00364222 loss)
I0813 17:25:04.634856 18283 sgd_solver.cpp:106] Iteration 37000, lr = 0.00313276
I0813 17:25:45.804347 18283 solver.cpp:228] Iteration 37050, loss = 0.00395441
I0813 17:25:45.804553 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:25:45.804611 18283 solver.cpp:244]     Train net output #1: loss = 0.00395444 (* 1 = 0.00395444 loss)
I0813 17:25:45.804635 18283 sgd_solver.cpp:106] Iteration 37050, lr = 0.00313026
I0813 17:26:26.799762 18283 solver.cpp:337] Iteration 37100, Testing net (#0)
I0813 17:26:30.855388 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 17:26:30.855453 18283 solver.cpp:404]     Test net output #1: loss = 0.967918 (* 1 = 0.967918 loss)
I0813 17:26:31.668298 18283 solver.cpp:228] Iteration 37100, loss = 0.00840497
I0813 17:26:31.668359 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:26:31.668370 18283 solver.cpp:244]     Train net output #1: loss = 0.008405 (* 1 = 0.008405 loss)
I0813 17:26:31.668386 18283 sgd_solver.cpp:106] Iteration 37100, lr = 0.00312777
I0813 17:27:12.888677 18283 solver.cpp:228] Iteration 37150, loss = 0.00625169
I0813 17:27:12.888852 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:27:12.888866 18283 solver.cpp:244]     Train net output #1: loss = 0.00625172 (* 1 = 0.00625172 loss)
I0813 17:27:12.888890 18283 sgd_solver.cpp:106] Iteration 37150, lr = 0.00312528
I0813 17:27:53.307685 18283 solver.cpp:337] Iteration 37200, Testing net (#0)
I0813 17:27:57.592038 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 17:27:57.592103 18283 solver.cpp:404]     Test net output #1: loss = 0.974279 (* 1 = 0.974279 loss)
I0813 17:27:58.403219 18283 solver.cpp:228] Iteration 37200, loss = 0.0208616
I0813 17:27:58.403275 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:27:58.403286 18283 solver.cpp:244]     Train net output #1: loss = 0.0208616 (* 1 = 0.0208616 loss)
I0813 17:27:58.403298 18283 sgd_solver.cpp:106] Iteration 37200, lr = 0.0031228
I0813 17:28:39.574575 18283 solver.cpp:228] Iteration 37250, loss = 0.037741
I0813 17:28:39.574740 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:28:39.574755 18283 solver.cpp:244]     Train net output #1: loss = 0.037741 (* 1 = 0.037741 loss)
I0813 17:28:39.574766 18283 sgd_solver.cpp:106] Iteration 37250, lr = 0.00312032
I0813 17:29:19.926455 18283 solver.cpp:337] Iteration 37300, Testing net (#0)
I0813 17:29:23.982398 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 17:29:23.982463 18283 solver.cpp:404]     Test net output #1: loss = 0.968373 (* 1 = 0.968373 loss)
I0813 17:29:24.795902 18283 solver.cpp:228] Iteration 37300, loss = 4.73857e-05
I0813 17:29:24.795955 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:29:24.795966 18283 solver.cpp:244]     Train net output #1: loss = 4.74149e-05 (* 1 = 4.74149e-05 loss)
I0813 17:29:24.795984 18283 sgd_solver.cpp:106] Iteration 37300, lr = 0.00311784
I0813 17:30:05.957787 18283 solver.cpp:228] Iteration 37350, loss = -2.98023e-08
I0813 17:30:05.957945 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:30:05.957959 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:30:05.957970 18283 sgd_solver.cpp:106] Iteration 37350, lr = 0.00311537
I0813 17:30:46.320082 18283 solver.cpp:337] Iteration 37400, Testing net (#0)
I0813 17:30:50.382422 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 17:30:50.382489 18283 solver.cpp:404]     Test net output #1: loss = 1.03613 (* 1 = 1.03613 loss)
I0813 17:30:51.195154 18283 solver.cpp:228] Iteration 37400, loss = 0.0103102
I0813 17:30:51.195209 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:30:51.195219 18283 solver.cpp:244]     Train net output #1: loss = 0.0103102 (* 1 = 0.0103102 loss)
I0813 17:30:51.195231 18283 sgd_solver.cpp:106] Iteration 37400, lr = 0.00311291
I0813 17:31:32.359280 18283 solver.cpp:228] Iteration 37450, loss = 0.000239594
I0813 17:31:32.359444 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:31:32.359458 18283 solver.cpp:244]     Train net output #1: loss = 0.000239624 (* 1 = 0.000239624 loss)
I0813 17:31:32.359470 18283 sgd_solver.cpp:106] Iteration 37450, lr = 0.00311045
I0813 17:32:12.707582 18283 solver.cpp:337] Iteration 37500, Testing net (#0)
I0813 17:32:16.762529 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 17:32:16.762593 18283 solver.cpp:404]     Test net output #1: loss = 1.06984 (* 1 = 1.06984 loss)
I0813 17:32:17.577064 18283 solver.cpp:228] Iteration 37500, loss = 0.0102523
I0813 17:32:17.577114 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:32:17.577126 18283 solver.cpp:244]     Train net output #1: loss = 0.0102524 (* 1 = 0.0102524 loss)
I0813 17:32:17.577142 18283 sgd_solver.cpp:106] Iteration 37500, lr = 0.00310799
I0813 17:32:58.744858 18283 solver.cpp:228] Iteration 37550, loss = -2.7474e-08
I0813 17:32:58.745061 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:32:58.745076 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:32:58.745088 18283 sgd_solver.cpp:106] Iteration 37550, lr = 0.00310554
I0813 17:33:39.105283 18283 solver.cpp:337] Iteration 37600, Testing net (#0)
I0813 17:33:43.556685 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 17:33:43.556754 18283 solver.cpp:404]     Test net output #1: loss = 1.03374 (* 1 = 1.03374 loss)
I0813 17:33:44.371711 18283 solver.cpp:228] Iteration 37600, loss = 0.0321867
I0813 17:33:44.371764 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:33:44.371775 18283 solver.cpp:244]     Train net output #1: loss = 0.0321867 (* 1 = 0.0321867 loss)
I0813 17:33:44.371793 18283 sgd_solver.cpp:106] Iteration 37600, lr = 0.00310309
I0813 17:34:25.996269 18283 solver.cpp:228] Iteration 37650, loss = 0.00107352
I0813 17:34:25.996511 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:34:25.996564 18283 solver.cpp:244]     Train net output #1: loss = 0.00107354 (* 1 = 0.00107354 loss)
I0813 17:34:25.996595 18283 sgd_solver.cpp:106] Iteration 37650, lr = 0.00310065
I0813 17:35:07.435673 18283 solver.cpp:337] Iteration 37700, Testing net (#0)
I0813 17:35:11.496831 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 17:35:11.496894 18283 solver.cpp:404]     Test net output #1: loss = 1.07689 (* 1 = 1.07689 loss)
I0813 17:35:12.309109 18283 solver.cpp:228] Iteration 37700, loss = 0.0255157
I0813 17:35:12.309168 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:35:12.309180 18283 solver.cpp:244]     Train net output #1: loss = 0.0255157 (* 1 = 0.0255157 loss)
I0813 17:35:12.309196 18283 sgd_solver.cpp:106] Iteration 37700, lr = 0.00309821
I0813 17:35:53.940598 18283 solver.cpp:228] Iteration 37750, loss = 0.00635921
I0813 17:35:53.940747 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:35:53.940762 18283 solver.cpp:244]     Train net output #1: loss = 0.00635924 (* 1 = 0.00635924 loss)
I0813 17:35:53.940773 18283 sgd_solver.cpp:106] Iteration 37750, lr = 0.00309578
I0813 17:36:35.648836 18283 solver.cpp:337] Iteration 37800, Testing net (#0)
I0813 17:36:39.711896 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 17:36:39.712060 18283 solver.cpp:404]     Test net output #1: loss = 1.00459 (* 1 = 1.00459 loss)
I0813 17:36:40.525712 18283 solver.cpp:228] Iteration 37800, loss = 0.000359976
I0813 17:36:40.525779 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:36:40.525792 18283 solver.cpp:244]     Train net output #1: loss = 0.000360008 (* 1 = 0.000360008 loss)
I0813 17:36:40.525805 18283 sgd_solver.cpp:106] Iteration 37800, lr = 0.00309335
I0813 17:37:21.681540 18283 solver.cpp:228] Iteration 37850, loss = 0.00998626
I0813 17:37:21.681701 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:37:21.681715 18283 solver.cpp:244]     Train net output #1: loss = 0.00998629 (* 1 = 0.00998629 loss)
I0813 17:37:21.681727 18283 sgd_solver.cpp:106] Iteration 37850, lr = 0.00309093
I0813 17:38:02.048727 18283 solver.cpp:337] Iteration 37900, Testing net (#0)
I0813 17:38:06.300835 18283 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0813 17:38:06.300894 18283 solver.cpp:404]     Test net output #1: loss = 0.899106 (* 1 = 0.899106 loss)
I0813 17:38:07.113471 18283 solver.cpp:228] Iteration 37900, loss = 0.00522832
I0813 17:38:07.113526 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:38:07.113538 18283 solver.cpp:244]     Train net output #1: loss = 0.00522835 (* 1 = 0.00522835 loss)
I0813 17:38:07.113549 18283 sgd_solver.cpp:106] Iteration 37900, lr = 0.00308851
I0813 17:38:48.260773 18283 solver.cpp:228] Iteration 37950, loss = 0.000161637
I0813 17:38:48.261011 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:38:48.261093 18283 solver.cpp:244]     Train net output #1: loss = 0.000161667 (* 1 = 0.000161667 loss)
I0813 17:38:48.261117 18283 sgd_solver.cpp:106] Iteration 37950, lr = 0.00308609
I0813 17:39:28.616098 18283 solver.cpp:337] Iteration 38000, Testing net (#0)
I0813 17:39:32.675046 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 17:39:32.675108 18283 solver.cpp:404]     Test net output #1: loss = 1.01618 (* 1 = 1.01618 loss)
I0813 17:39:33.488237 18283 solver.cpp:228] Iteration 38000, loss = 0.00225415
I0813 17:39:33.488296 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:39:33.488306 18283 solver.cpp:244]     Train net output #1: loss = 0.00225418 (* 1 = 0.00225418 loss)
I0813 17:39:33.488322 18283 sgd_solver.cpp:106] Iteration 38000, lr = 0.00308368
I0813 17:40:14.675992 18283 solver.cpp:228] Iteration 38050, loss = 0.00722501
I0813 17:40:14.676162 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:40:14.676177 18283 solver.cpp:244]     Train net output #1: loss = 0.00722504 (* 1 = 0.00722504 loss)
I0813 17:40:14.676188 18283 sgd_solver.cpp:106] Iteration 38050, lr = 0.00308127
I0813 17:40:55.006732 18283 solver.cpp:337] Iteration 38100, Testing net (#0)
I0813 17:40:59.047545 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 17:40:59.047610 18283 solver.cpp:404]     Test net output #1: loss = 0.956717 (* 1 = 0.956717 loss)
I0813 17:40:59.859508 18283 solver.cpp:228] Iteration 38100, loss = 0.022868
I0813 17:40:59.859567 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:40:59.859578 18283 solver.cpp:244]     Train net output #1: loss = 0.0228681 (* 1 = 0.0228681 loss)
I0813 17:40:59.859594 18283 sgd_solver.cpp:106] Iteration 38100, lr = 0.00307887
I0813 17:41:41.008383 18283 solver.cpp:228] Iteration 38150, loss = -3.81842e-08
I0813 17:41:41.008548 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:41:41.008561 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:41:41.008571 18283 sgd_solver.cpp:106] Iteration 38150, lr = 0.00307647
I0813 17:42:21.354218 18283 solver.cpp:337] Iteration 38200, Testing net (#0)
I0813 17:42:25.716507 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 17:42:25.716569 18283 solver.cpp:404]     Test net output #1: loss = 0.995074 (* 1 = 0.995074 loss)
I0813 17:42:26.529649 18283 solver.cpp:228] Iteration 38200, loss = 0.0225535
I0813 17:42:26.529716 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:42:26.529728 18283 solver.cpp:244]     Train net output #1: loss = 0.0225536 (* 1 = 0.0225536 loss)
I0813 17:42:26.529743 18283 sgd_solver.cpp:106] Iteration 38200, lr = 0.00307408
I0813 17:43:08.376473 18283 solver.cpp:228] Iteration 38250, loss = 1.85918e-05
I0813 17:43:08.376616 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:43:08.376629 18283 solver.cpp:244]     Train net output #1: loss = 1.86282e-05 (* 1 = 1.86282e-05 loss)
I0813 17:43:08.376652 18283 sgd_solver.cpp:106] Iteration 38250, lr = 0.00307169
I0813 17:43:48.726333 18283 solver.cpp:337] Iteration 38300, Testing net (#0)
I0813 17:43:52.775688 18283 solver.cpp:404]     Test net output #0: accuracy = 0.742
I0813 17:43:52.775755 18283 solver.cpp:404]     Test net output #1: loss = 1.12315 (* 1 = 1.12315 loss)
I0813 17:43:53.587703 18283 solver.cpp:228] Iteration 38300, loss = 0.00889649
I0813 17:43:53.587756 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:43:53.587767 18283 solver.cpp:244]     Train net output #1: loss = 0.00889653 (* 1 = 0.00889653 loss)
I0813 17:43:53.587786 18283 sgd_solver.cpp:106] Iteration 38300, lr = 0.0030693
I0813 17:44:34.771113 18283 solver.cpp:228] Iteration 38350, loss = 0.0064073
I0813 17:44:34.771266 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:44:34.771281 18283 solver.cpp:244]     Train net output #1: loss = 0.00640734 (* 1 = 0.00640734 loss)
I0813 17:44:34.771293 18283 sgd_solver.cpp:106] Iteration 38350, lr = 0.00306692
I0813 17:45:15.311722 18283 solver.cpp:337] Iteration 38400, Testing net (#0)
I0813 17:45:19.560073 18283 solver.cpp:404]     Test net output #0: accuracy = 0.743
I0813 17:45:19.560142 18283 solver.cpp:404]     Test net output #1: loss = 1.12476 (* 1 = 1.12476 loss)
I0813 17:45:20.372367 18283 solver.cpp:228] Iteration 38400, loss = 0.00837243
I0813 17:45:20.372422 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:45:20.372434 18283 solver.cpp:244]     Train net output #1: loss = 0.00837247 (* 1 = 0.00837247 loss)
I0813 17:45:20.372452 18283 sgd_solver.cpp:106] Iteration 38400, lr = 0.00306454
I0813 17:46:01.513183 18283 solver.cpp:228] Iteration 38450, loss = 0.00654337
I0813 17:46:01.513396 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:46:01.513445 18283 solver.cpp:244]     Train net output #1: loss = 0.00654341 (* 1 = 0.00654341 loss)
I0813 17:46:01.513470 18283 sgd_solver.cpp:106] Iteration 38450, lr = 0.00306217
I0813 17:46:42.296905 18283 solver.cpp:337] Iteration 38500, Testing net (#0)
I0813 17:46:46.350601 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 17:46:46.350667 18283 solver.cpp:404]     Test net output #1: loss = 0.964163 (* 1 = 0.964163 loss)
I0813 17:46:47.160647 18283 solver.cpp:228] Iteration 38500, loss = 0.00318504
I0813 17:46:47.160698 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:46:47.160711 18283 solver.cpp:244]     Train net output #1: loss = 0.00318507 (* 1 = 0.00318507 loss)
I0813 17:46:47.160722 18283 sgd_solver.cpp:106] Iteration 38500, lr = 0.0030598
I0813 17:47:28.285444 18283 solver.cpp:228] Iteration 38550, loss = -3.95812e-08
I0813 17:47:28.285653 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:47:28.285713 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:47:28.285739 18283 sgd_solver.cpp:106] Iteration 38550, lr = 0.00305744
I0813 17:48:09.853476 18283 solver.cpp:337] Iteration 38600, Testing net (#0)
I0813 17:48:14.058920 18283 solver.cpp:404]     Test net output #0: accuracy = 0.732
I0813 17:48:14.058989 18283 solver.cpp:404]     Test net output #1: loss = 1.13904 (* 1 = 1.13904 loss)
I0813 17:48:14.871621 18283 solver.cpp:228] Iteration 38600, loss = 0.0180602
I0813 17:48:14.871680 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:48:14.871692 18283 solver.cpp:244]     Train net output #1: loss = 0.0180602 (* 1 = 0.0180602 loss)
I0813 17:48:14.871708 18283 sgd_solver.cpp:106] Iteration 38600, lr = 0.00305508
I0813 17:48:56.615625 18283 solver.cpp:228] Iteration 38650, loss = 0.00180792
I0813 17:48:56.615854 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:48:56.615922 18283 solver.cpp:244]     Train net output #1: loss = 0.00180796 (* 1 = 0.00180796 loss)
I0813 17:48:56.615963 18283 sgd_solver.cpp:106] Iteration 38650, lr = 0.00305273
I0813 17:49:39.302140 18283 solver.cpp:337] Iteration 38700, Testing net (#0)
I0813 17:49:43.364522 18283 solver.cpp:404]     Test net output #0: accuracy = 0.747
I0813 17:49:43.364584 18283 solver.cpp:404]     Test net output #1: loss = 1.05466 (* 1 = 1.05466 loss)
I0813 17:49:44.178136 18283 solver.cpp:228] Iteration 38700, loss = 0.0433067
I0813 17:49:44.178203 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 17:49:44.178215 18283 solver.cpp:244]     Train net output #1: loss = 0.0433067 (* 1 = 0.0433067 loss)
I0813 17:49:44.178232 18283 sgd_solver.cpp:106] Iteration 38700, lr = 0.00305038
I0813 17:50:25.362998 18283 solver.cpp:228] Iteration 38750, loss = -4.47035e-08
I0813 17:50:25.363148 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:50:25.363160 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:50:25.363173 18283 sgd_solver.cpp:106] Iteration 38750, lr = 0.00304803
I0813 17:51:06.710979 18283 solver.cpp:337] Iteration 38800, Testing net (#0)
I0813 17:51:10.775681 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 17:51:10.775758 18283 solver.cpp:404]     Test net output #1: loss = 0.887851 (* 1 = 0.887851 loss)
I0813 17:51:11.590155 18283 solver.cpp:228] Iteration 38800, loss = 0.0110026
I0813 17:51:11.590209 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:51:11.590221 18283 solver.cpp:244]     Train net output #1: loss = 0.0110027 (* 1 = 0.0110027 loss)
I0813 17:51:11.590239 18283 sgd_solver.cpp:106] Iteration 38800, lr = 0.00304569
I0813 17:51:53.476708 18283 solver.cpp:228] Iteration 38850, loss = 9.69071e-05
I0813 17:51:53.476989 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:51:53.477038 18283 solver.cpp:244]     Train net output #1: loss = 9.69535e-05 (* 1 = 9.69535e-05 loss)
I0813 17:51:53.477058 18283 sgd_solver.cpp:106] Iteration 38850, lr = 0.00304335
I0813 17:52:34.212103 18283 solver.cpp:337] Iteration 38900, Testing net (#0)
I0813 17:52:38.269420 18283 solver.cpp:404]     Test net output #0: accuracy = 0.718
I0813 17:52:38.269482 18283 solver.cpp:404]     Test net output #1: loss = 1.19443 (* 1 = 1.19443 loss)
I0813 17:52:39.081837 18283 solver.cpp:228] Iteration 38900, loss = 0.0200991
I0813 17:52:39.081893 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:52:39.081904 18283 solver.cpp:244]     Train net output #1: loss = 0.0200991 (* 1 = 0.0200991 loss)
I0813 17:52:39.081921 18283 sgd_solver.cpp:106] Iteration 38900, lr = 0.00304101
I0813 17:53:20.243327 18283 solver.cpp:228] Iteration 38950, loss = -4.74975e-08
I0813 17:53:20.243525 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:53:20.243587 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:53:20.243613 18283 sgd_solver.cpp:106] Iteration 38950, lr = 0.00303868
I0813 17:54:01.493412 18283 solver.cpp:337] Iteration 39000, Testing net (#0)
I0813 17:54:05.554513 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 17:54:05.554592 18283 solver.cpp:404]     Test net output #1: loss = 0.9207 (* 1 = 0.9207 loss)
I0813 17:54:06.367656 18283 solver.cpp:228] Iteration 39000, loss = -4.84288e-08
I0813 17:54:06.367710 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:54:06.367722 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:54:06.367733 18283 sgd_solver.cpp:106] Iteration 39000, lr = 0.00303636
I0813 17:54:47.563845 18283 solver.cpp:228] Iteration 39050, loss = 0.00418915
I0813 17:54:47.564007 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:54:47.564021 18283 solver.cpp:244]     Train net output #1: loss = 0.0041892 (* 1 = 0.0041892 loss)
I0813 17:54:47.564045 18283 sgd_solver.cpp:106] Iteration 39050, lr = 0.00303404
I0813 17:55:27.946311 18283 solver.cpp:337] Iteration 39100, Testing net (#0)
I0813 17:55:32.188390 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 17:55:32.188473 18283 solver.cpp:404]     Test net output #1: loss = 0.965111 (* 1 = 0.965111 loss)
I0813 17:55:33.003859 18283 solver.cpp:228] Iteration 39100, loss = 0.0079891
I0813 17:55:33.003926 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:55:33.003938 18283 solver.cpp:244]     Train net output #1: loss = 0.00798915 (* 1 = 0.00798915 loss)
I0813 17:55:33.003957 18283 sgd_solver.cpp:106] Iteration 39100, lr = 0.00303172
I0813 17:56:14.200372 18283 solver.cpp:228] Iteration 39150, loss = 0.00105325
I0813 17:56:14.200533 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:56:14.200547 18283 solver.cpp:244]     Train net output #1: loss = 0.0010533 (* 1 = 0.0010533 loss)
I0813 17:56:14.200559 18283 sgd_solver.cpp:106] Iteration 39150, lr = 0.00302941
I0813 17:56:54.529778 18283 solver.cpp:337] Iteration 39200, Testing net (#0)
I0813 17:56:58.575140 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 17:56:58.575203 18283 solver.cpp:404]     Test net output #1: loss = 1.02195 (* 1 = 1.02195 loss)
I0813 17:56:59.387552 18283 solver.cpp:228] Iteration 39200, loss = 0.00546299
I0813 17:56:59.387604 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:56:59.387616 18283 solver.cpp:244]     Train net output #1: loss = 0.00546304 (* 1 = 0.00546304 loss)
I0813 17:56:59.387635 18283 sgd_solver.cpp:106] Iteration 39200, lr = 0.0030271
I0813 17:57:40.517693 18283 solver.cpp:228] Iteration 39250, loss = 0.00198459
I0813 17:57:40.517891 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:57:40.517906 18283 solver.cpp:244]     Train net output #1: loss = 0.00198463 (* 1 = 0.00198463 loss)
I0813 17:57:40.517918 18283 sgd_solver.cpp:106] Iteration 39250, lr = 0.00302479
I0813 17:58:20.842298 18283 solver.cpp:337] Iteration 39300, Testing net (#0)
I0813 17:58:25.235432 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 17:58:25.235497 18283 solver.cpp:404]     Test net output #1: loss = 0.99524 (* 1 = 0.99524 loss)
I0813 17:58:26.048773 18283 solver.cpp:228] Iteration 39300, loss = -5.12227e-08
I0813 17:58:26.048841 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:58:26.048852 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 17:58:26.048873 18283 sgd_solver.cpp:106] Iteration 39300, lr = 0.00302249
I0813 17:59:07.242278 18283 solver.cpp:228] Iteration 39350, loss = 0.00298419
I0813 17:59:07.242434 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:59:07.242447 18283 solver.cpp:244]     Train net output #1: loss = 0.00298424 (* 1 = 0.00298424 loss)
I0813 17:59:07.242460 18283 sgd_solver.cpp:106] Iteration 39350, lr = 0.00302019
I0813 17:59:47.607636 18283 solver.cpp:337] Iteration 39400, Testing net (#0)
I0813 17:59:52.094399 18283 solver.cpp:404]     Test net output #0: accuracy = 0.741
I0813 17:59:52.094467 18283 solver.cpp:404]     Test net output #1: loss = 1.09035 (* 1 = 1.09035 loss)
I0813 17:59:52.907883 18283 solver.cpp:228] Iteration 39400, loss = 0.0170031
I0813 17:59:52.907948 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 17:59:52.907960 18283 solver.cpp:244]     Train net output #1: loss = 0.0170032 (* 1 = 0.0170032 loss)
I0813 17:59:52.907975 18283 sgd_solver.cpp:106] Iteration 39400, lr = 0.0030179
I0813 18:00:34.091426 18283 solver.cpp:228] Iteration 39450, loss = 0.0246888
I0813 18:00:34.091594 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:00:34.091608 18283 solver.cpp:244]     Train net output #1: loss = 0.0246889 (* 1 = 0.0246889 loss)
I0813 18:00:34.091620 18283 sgd_solver.cpp:106] Iteration 39450, lr = 0.00301561
I0813 18:01:14.438426 18283 solver.cpp:337] Iteration 39500, Testing net (#0)
I0813 18:01:18.491890 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 18:01:18.491956 18283 solver.cpp:404]     Test net output #1: loss = 0.942758 (* 1 = 0.942758 loss)
I0813 18:01:19.304920 18283 solver.cpp:228] Iteration 39500, loss = 0.00989944
I0813 18:01:19.304985 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:01:19.304996 18283 solver.cpp:244]     Train net output #1: loss = 0.00989949 (* 1 = 0.00989949 loss)
I0813 18:01:19.305014 18283 sgd_solver.cpp:106] Iteration 39500, lr = 0.00301333
I0813 18:02:00.470486 18283 solver.cpp:228] Iteration 39550, loss = 0.00374706
I0813 18:02:00.470639 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:02:00.470654 18283 solver.cpp:244]     Train net output #1: loss = 0.0037471 (* 1 = 0.0037471 loss)
I0813 18:02:00.470665 18283 sgd_solver.cpp:106] Iteration 39550, lr = 0.00301105
I0813 18:02:40.822618 18283 solver.cpp:337] Iteration 39600, Testing net (#0)
I0813 18:02:45.099264 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 18:02:45.099334 18283 solver.cpp:404]     Test net output #1: loss = 0.989516 (* 1 = 0.989516 loss)
I0813 18:02:45.912258 18283 solver.cpp:228] Iteration 39600, loss = 0.0148266
I0813 18:02:45.912309 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:02:45.912322 18283 solver.cpp:244]     Train net output #1: loss = 0.0148266 (* 1 = 0.0148266 loss)
I0813 18:02:45.912339 18283 sgd_solver.cpp:106] Iteration 39600, lr = 0.00300877
I0813 18:03:27.033113 18283 solver.cpp:228] Iteration 39650, loss = 0.0010347
I0813 18:03:27.033388 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:03:27.033442 18283 solver.cpp:244]     Train net output #1: loss = 0.00103475 (* 1 = 0.00103475 loss)
I0813 18:03:27.033463 18283 sgd_solver.cpp:106] Iteration 39650, lr = 0.0030065
I0813 18:04:08.257628 18283 solver.cpp:337] Iteration 39700, Testing net (#0)
I0813 18:04:12.567908 18283 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0813 18:04:12.567975 18283 solver.cpp:404]     Test net output #1: loss = 0.948448 (* 1 = 0.948448 loss)
I0813 18:04:13.380837 18283 solver.cpp:228] Iteration 39700, loss = 0.0151545
I0813 18:04:13.380903 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:04:13.380914 18283 solver.cpp:244]     Train net output #1: loss = 0.0151545 (* 1 = 0.0151545 loss)
I0813 18:04:13.380931 18283 sgd_solver.cpp:106] Iteration 39700, lr = 0.00300423
I0813 18:04:54.544358 18283 solver.cpp:228] Iteration 39750, loss = 0.000983732
I0813 18:04:54.544526 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:04:54.544541 18283 solver.cpp:244]     Train net output #1: loss = 0.000983777 (* 1 = 0.000983777 loss)
I0813 18:04:54.544555 18283 sgd_solver.cpp:106] Iteration 39750, lr = 0.00300196
I0813 18:05:34.900527 18283 solver.cpp:337] Iteration 39800, Testing net (#0)
I0813 18:05:38.962891 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 18:05:38.962970 18283 solver.cpp:404]     Test net output #1: loss = 1.01344 (* 1 = 1.01344 loss)
I0813 18:05:39.775467 18283 solver.cpp:228] Iteration 39800, loss = 0.00161978
I0813 18:05:39.775526 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:05:39.775537 18283 solver.cpp:244]     Train net output #1: loss = 0.00161982 (* 1 = 0.00161982 loss)
I0813 18:05:39.775554 18283 sgd_solver.cpp:106] Iteration 39800, lr = 0.0029997
I0813 18:06:21.581836 18283 solver.cpp:228] Iteration 39850, loss = 0.0188015
I0813 18:06:21.582047 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:06:21.582098 18283 solver.cpp:244]     Train net output #1: loss = 0.0188015 (* 1 = 0.0188015 loss)
I0813 18:06:21.582118 18283 sgd_solver.cpp:106] Iteration 39850, lr = 0.00299744
I0813 18:07:02.457700 18283 solver.cpp:337] Iteration 39900, Testing net (#0)
I0813 18:07:06.517678 18283 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0813 18:07:06.517737 18283 solver.cpp:404]     Test net output #1: loss = 0.897237 (* 1 = 0.897237 loss)
I0813 18:07:07.330781 18283 solver.cpp:228] Iteration 39900, loss = -4.61005e-08
I0813 18:07:07.330837 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:07:07.330847 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:07:07.330859 18283 sgd_solver.cpp:106] Iteration 39900, lr = 0.00299519
I0813 18:07:48.529551 18283 solver.cpp:228] Iteration 39950, loss = 0.00253697
I0813 18:07:48.529711 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:07:48.529726 18283 solver.cpp:244]     Train net output #1: loss = 0.00253702 (* 1 = 0.00253702 loss)
I0813 18:07:48.529739 18283 sgd_solver.cpp:106] Iteration 39950, lr = 0.00299294
I0813 18:08:28.851106 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_40000.caffemodel
I0813 18:08:29.183595 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_40000.solverstate
I0813 18:08:29.196493 18283 solver.cpp:337] Iteration 40000, Testing net (#0)
I0813 18:08:33.262977 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 18:08:33.263053 18283 solver.cpp:404]     Test net output #1: loss = 0.869061 (* 1 = 0.869061 loss)
I0813 18:08:34.075939 18283 solver.cpp:228] Iteration 40000, loss = 0.00319244
I0813 18:08:34.075999 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:08:34.076010 18283 solver.cpp:244]     Train net output #1: loss = 0.00319249 (* 1 = 0.00319249 loss)
I0813 18:08:34.076035 18283 sgd_solver.cpp:106] Iteration 40000, lr = 0.0029907
I0813 18:09:15.258621 18283 solver.cpp:228] Iteration 40050, loss = 0.00749535
I0813 18:09:15.258887 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:09:15.258936 18283 solver.cpp:244]     Train net output #1: loss = 0.00749539 (* 1 = 0.00749539 loss)
I0813 18:09:15.258963 18283 sgd_solver.cpp:106] Iteration 40050, lr = 0.00298846
I0813 18:09:55.815717 18283 solver.cpp:337] Iteration 40100, Testing net (#0)
I0813 18:09:59.875844 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 18:09:59.875910 18283 solver.cpp:404]     Test net output #1: loss = 0.923921 (* 1 = 0.923921 loss)
I0813 18:10:00.689337 18283 solver.cpp:228] Iteration 40100, loss = 0.00295426
I0813 18:10:00.689396 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:10:00.689409 18283 solver.cpp:244]     Train net output #1: loss = 0.0029543 (* 1 = 0.0029543 loss)
I0813 18:10:00.689424 18283 sgd_solver.cpp:106] Iteration 40100, lr = 0.00298622
I0813 18:10:41.864423 18283 solver.cpp:228] Iteration 40150, loss = 0.00593319
I0813 18:10:41.864590 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:10:41.864645 18283 solver.cpp:244]     Train net output #1: loss = 0.00593323 (* 1 = 0.00593323 loss)
I0813 18:10:41.864696 18283 sgd_solver.cpp:106] Iteration 40150, lr = 0.00298399
I0813 18:11:22.220082 18283 solver.cpp:337] Iteration 40200, Testing net (#0)
I0813 18:11:26.542757 18283 solver.cpp:404]     Test net output #0: accuracy = 0.739
I0813 18:11:26.542826 18283 solver.cpp:404]     Test net output #1: loss = 1.07144 (* 1 = 1.07144 loss)
I0813 18:11:27.355495 18283 solver.cpp:228] Iteration 40200, loss = 0.00133601
I0813 18:11:27.355552 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:11:27.355564 18283 solver.cpp:244]     Train net output #1: loss = 0.00133605 (* 1 = 0.00133605 loss)
I0813 18:11:27.355582 18283 sgd_solver.cpp:106] Iteration 40200, lr = 0.00298176
I0813 18:12:08.516602 18283 solver.cpp:228] Iteration 40250, loss = 0.000248409
I0813 18:12:08.516762 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:12:08.516777 18283 solver.cpp:244]     Train net output #1: loss = 0.00024845 (* 1 = 0.00024845 loss)
I0813 18:12:08.516788 18283 sgd_solver.cpp:106] Iteration 40250, lr = 0.00297953
I0813 18:12:48.887365 18283 solver.cpp:337] Iteration 40300, Testing net (#0)
I0813 18:12:52.945996 18283 solver.cpp:404]     Test net output #0: accuracy = 0.773
I0813 18:12:52.946072 18283 solver.cpp:404]     Test net output #1: loss = 0.799497 (* 1 = 0.799497 loss)
I0813 18:12:53.758934 18283 solver.cpp:228] Iteration 40300, loss = 0.00722733
I0813 18:12:53.758986 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:12:53.758997 18283 solver.cpp:244]     Train net output #1: loss = 0.00722737 (* 1 = 0.00722737 loss)
I0813 18:12:53.759016 18283 sgd_solver.cpp:106] Iteration 40300, lr = 0.00297731
I0813 18:13:35.282301 18283 solver.cpp:228] Iteration 40350, loss = -4.02797e-08
I0813 18:13:35.282462 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:13:35.282475 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:13:35.282487 18283 sgd_solver.cpp:106] Iteration 40350, lr = 0.00297509
I0813 18:14:15.699594 18283 solver.cpp:337] Iteration 40400, Testing net (#0)
I0813 18:14:19.982419 18283 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0813 18:14:19.982482 18283 solver.cpp:404]     Test net output #1: loss = 0.924998 (* 1 = 0.924998 loss)
I0813 18:14:20.797184 18283 solver.cpp:228] Iteration 40400, loss = 0.00938543
I0813 18:14:20.797256 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:14:20.797269 18283 solver.cpp:244]     Train net output #1: loss = 0.00938546 (* 1 = 0.00938546 loss)
I0813 18:14:20.797284 18283 sgd_solver.cpp:106] Iteration 40400, lr = 0.00297288
I0813 18:15:02.448323 18283 solver.cpp:228] Iteration 40450, loss = -3.72529e-08
I0813 18:15:02.448477 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:15:02.448490 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:15:02.448516 18283 sgd_solver.cpp:106] Iteration 40450, lr = 0.00297067
I0813 18:15:42.792846 18283 solver.cpp:337] Iteration 40500, Testing net (#0)
I0813 18:15:46.840476 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 18:15:46.840543 18283 solver.cpp:404]     Test net output #1: loss = 1.09362 (* 1 = 1.09362 loss)
I0813 18:15:47.653056 18283 solver.cpp:228] Iteration 40500, loss = 0.0223343
I0813 18:15:47.653105 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:15:47.653115 18283 solver.cpp:244]     Train net output #1: loss = 0.0223344 (* 1 = 0.0223344 loss)
I0813 18:15:47.653127 18283 sgd_solver.cpp:106] Iteration 40500, lr = 0.00296846
I0813 18:16:28.797216 18283 solver.cpp:228] Iteration 40550, loss = -3.77186e-08
I0813 18:16:28.797385 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:16:28.797399 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:16:28.797411 18283 sgd_solver.cpp:106] Iteration 40550, lr = 0.00296626
I0813 18:17:09.136065 18283 solver.cpp:337] Iteration 40600, Testing net (#0)
I0813 18:17:13.426743 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 18:17:13.426808 18283 solver.cpp:404]     Test net output #1: loss = 0.996236 (* 1 = 0.996236 loss)
I0813 18:17:14.247570 18283 solver.cpp:228] Iteration 40600, loss = 0.00849258
I0813 18:17:14.247627 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:17:14.247640 18283 solver.cpp:244]     Train net output #1: loss = 0.00849262 (* 1 = 0.00849262 loss)
I0813 18:17:14.247656 18283 sgd_solver.cpp:106] Iteration 40600, lr = 0.00296406
I0813 18:17:55.400768 18283 solver.cpp:228] Iteration 40650, loss = 0.00340545
I0813 18:17:55.400928 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:17:55.400943 18283 solver.cpp:244]     Train net output #1: loss = 0.00340549 (* 1 = 0.00340549 loss)
I0813 18:17:55.400954 18283 sgd_solver.cpp:106] Iteration 40650, lr = 0.00296187
I0813 18:18:35.754111 18283 solver.cpp:337] Iteration 40700, Testing net (#0)
I0813 18:18:40.182806 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 18:18:40.182873 18283 solver.cpp:404]     Test net output #1: loss = 0.914617 (* 1 = 0.914617 loss)
I0813 18:18:40.997028 18283 solver.cpp:228] Iteration 40700, loss = 0.00572666
I0813 18:18:40.997092 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:18:40.997103 18283 solver.cpp:244]     Train net output #1: loss = 0.0057267 (* 1 = 0.0057267 loss)
I0813 18:18:40.997119 18283 sgd_solver.cpp:106] Iteration 40700, lr = 0.00295968
I0813 18:19:22.172194 18283 solver.cpp:228] Iteration 40750, loss = -3.57395e-08
I0813 18:19:22.172415 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:19:22.172472 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:19:22.172508 18283 sgd_solver.cpp:106] Iteration 40750, lr = 0.00295749
I0813 18:20:02.775555 18283 solver.cpp:337] Iteration 40800, Testing net (#0)
I0813 18:20:06.824048 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 18:20:06.824116 18283 solver.cpp:404]     Test net output #1: loss = 0.996279 (* 1 = 0.996279 loss)
I0813 18:20:07.635936 18283 solver.cpp:228] Iteration 40800, loss = 0.0069661
I0813 18:20:07.635987 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:20:07.635998 18283 solver.cpp:244]     Train net output #1: loss = 0.00696614 (* 1 = 0.00696614 loss)
I0813 18:20:07.636010 18283 sgd_solver.cpp:106] Iteration 40800, lr = 0.0029553
I0813 18:20:48.772271 18283 solver.cpp:228] Iteration 40850, loss = 0.00026874
I0813 18:20:48.772436 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:20:48.772450 18283 solver.cpp:244]     Train net output #1: loss = 0.000268776 (* 1 = 0.000268776 loss)
I0813 18:20:48.772461 18283 sgd_solver.cpp:106] Iteration 40850, lr = 0.00295312
I0813 18:21:29.112495 18283 solver.cpp:337] Iteration 40900, Testing net (#0)
I0813 18:21:33.368249 18283 solver.cpp:404]     Test net output #0: accuracy = 0.734
I0813 18:21:33.368317 18283 solver.cpp:404]     Test net output #1: loss = 1.1094 (* 1 = 1.1094 loss)
I0813 18:21:34.181648 18283 solver.cpp:228] Iteration 40900, loss = 5.15748e-05
I0813 18:21:34.181716 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:21:34.181728 18283 solver.cpp:244]     Train net output #1: loss = 5.16093e-05 (* 1 = 5.16093e-05 loss)
I0813 18:21:34.181742 18283 sgd_solver.cpp:106] Iteration 40900, lr = 0.00295095
I0813 18:22:15.368757 18283 solver.cpp:228] Iteration 40950, loss = 0.00507171
I0813 18:22:15.368921 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:22:15.368935 18283 solver.cpp:244]     Train net output #1: loss = 0.00507175 (* 1 = 0.00507175 loss)
I0813 18:22:15.368947 18283 sgd_solver.cpp:106] Iteration 40950, lr = 0.00294878
I0813 18:22:55.735641 18283 solver.cpp:337] Iteration 41000, Testing net (#0)
I0813 18:22:59.795596 18283 solver.cpp:404]     Test net output #0: accuracy = 0.764
I0813 18:22:59.795662 18283 solver.cpp:404]     Test net output #1: loss = 0.859216 (* 1 = 0.859216 loss)
I0813 18:23:00.610234 18283 solver.cpp:228] Iteration 41000, loss = 0.0184841
I0813 18:23:00.610297 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:23:00.610309 18283 solver.cpp:244]     Train net output #1: loss = 0.0184841 (* 1 = 0.0184841 loss)
I0813 18:23:00.610327 18283 sgd_solver.cpp:106] Iteration 41000, lr = 0.00294661
I0813 18:23:41.780694 18283 solver.cpp:228] Iteration 41050, loss = 0.0100774
I0813 18:23:41.780864 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:23:41.780877 18283 solver.cpp:244]     Train net output #1: loss = 0.0100775 (* 1 = 0.0100775 loss)
I0813 18:23:41.780889 18283 sgd_solver.cpp:106] Iteration 41050, lr = 0.00294444
I0813 18:24:22.150352 18283 solver.cpp:337] Iteration 41100, Testing net (#0)
I0813 18:24:26.207733 18283 solver.cpp:404]     Test net output #0: accuracy = 0.768
I0813 18:24:26.207814 18283 solver.cpp:404]     Test net output #1: loss = 0.832815 (* 1 = 0.832815 loss)
I0813 18:24:27.021265 18283 solver.cpp:228] Iteration 41100, loss = 0.0179986
I0813 18:24:27.021320 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:24:27.021332 18283 solver.cpp:244]     Train net output #1: loss = 0.0179987 (* 1 = 0.0179987 loss)
I0813 18:24:27.021343 18283 sgd_solver.cpp:106] Iteration 41100, lr = 0.00294228
I0813 18:25:08.184660 18283 solver.cpp:228] Iteration 41150, loss = 0.00072021
I0813 18:25:08.184820 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:25:08.184835 18283 solver.cpp:244]     Train net output #1: loss = 0.000720244 (* 1 = 0.000720244 loss)
I0813 18:25:08.184847 18283 sgd_solver.cpp:106] Iteration 41150, lr = 0.00294012
I0813 18:25:48.530540 18283 solver.cpp:337] Iteration 41200, Testing net (#0)
I0813 18:25:52.587047 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 18:25:52.587113 18283 solver.cpp:404]     Test net output #1: loss = 1.06134 (* 1 = 1.06134 loss)
I0813 18:25:53.398370 18283 solver.cpp:228] Iteration 41200, loss = -3.35276e-08
I0813 18:25:53.398419 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:25:53.398430 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:25:53.398447 18283 sgd_solver.cpp:106] Iteration 41200, lr = 0.00293797
I0813 18:26:34.516998 18283 solver.cpp:228] Iteration 41250, loss = 0.0115179
I0813 18:26:34.517140 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:26:34.517154 18283 solver.cpp:244]     Train net output #1: loss = 0.0115179 (* 1 = 0.0115179 loss)
I0813 18:26:34.517165 18283 sgd_solver.cpp:106] Iteration 41250, lr = 0.00293582
I0813 18:27:14.861480 18283 solver.cpp:337] Iteration 41300, Testing net (#0)
I0813 18:27:18.914103 18283 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0813 18:27:18.914186 18283 solver.cpp:404]     Test net output #1: loss = 1.04532 (* 1 = 1.04532 loss)
I0813 18:27:19.727113 18283 solver.cpp:228] Iteration 41300, loss = 0.0294257
I0813 18:27:19.727165 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:27:19.727177 18283 solver.cpp:244]     Train net output #1: loss = 0.0294257 (* 1 = 0.0294257 loss)
I0813 18:27:19.727188 18283 sgd_solver.cpp:106] Iteration 41300, lr = 0.00293367
I0813 18:28:00.890835 18283 solver.cpp:228] Iteration 41350, loss = -2.8871e-08
I0813 18:28:00.891096 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:28:00.891152 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:28:00.891175 18283 sgd_solver.cpp:106] Iteration 41350, lr = 0.00293153
I0813 18:28:41.708444 18283 solver.cpp:337] Iteration 41400, Testing net (#0)
I0813 18:28:45.767381 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 18:28:45.767449 18283 solver.cpp:404]     Test net output #1: loss = 0.900275 (* 1 = 0.900275 loss)
I0813 18:28:46.581779 18283 solver.cpp:228] Iteration 41400, loss = 0.00274634
I0813 18:28:46.581838 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:28:46.581851 18283 solver.cpp:244]     Train net output #1: loss = 0.00274637 (* 1 = 0.00274637 loss)
I0813 18:28:46.581867 18283 sgd_solver.cpp:106] Iteration 41400, lr = 0.00292939
I0813 18:29:27.739737 18283 solver.cpp:228] Iteration 41450, loss = 0.000253662
I0813 18:29:27.739897 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:29:27.739910 18283 solver.cpp:244]     Train net output #1: loss = 0.000253693 (* 1 = 0.000253693 loss)
I0813 18:29:27.739923 18283 sgd_solver.cpp:106] Iteration 41450, lr = 0.00292726
I0813 18:30:08.101739 18283 solver.cpp:337] Iteration 41500, Testing net (#0)
I0813 18:30:12.356835 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 18:30:12.356906 18283 solver.cpp:404]     Test net output #1: loss = 0.948905 (* 1 = 0.948905 loss)
I0813 18:30:13.169530 18283 solver.cpp:228] Iteration 41500, loss = 1.69367e-05
I0813 18:30:13.169589 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:30:13.169600 18283 solver.cpp:244]     Train net output #1: loss = 1.69665e-05 (* 1 = 1.69665e-05 loss)
I0813 18:30:13.169620 18283 sgd_solver.cpp:106] Iteration 41500, lr = 0.00292513
I0813 18:30:54.347038 18283 solver.cpp:228] Iteration 41550, loss = -3.07336e-08
I0813 18:30:54.347256 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:30:54.347324 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:30:54.347358 18283 sgd_solver.cpp:106] Iteration 41550, lr = 0.002923
I0813 18:31:35.043869 18283 solver.cpp:337] Iteration 41600, Testing net (#0)
I0813 18:31:39.107527 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 18:31:39.107597 18283 solver.cpp:404]     Test net output #1: loss = 0.982066 (* 1 = 0.982066 loss)
I0813 18:31:39.920197 18283 solver.cpp:228] Iteration 41600, loss = -3.25963e-08
I0813 18:31:39.920263 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:31:39.920274 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:31:39.920287 18283 sgd_solver.cpp:106] Iteration 41600, lr = 0.00292087
I0813 18:32:21.106982 18283 solver.cpp:228] Iteration 41650, loss = 0.00528316
I0813 18:32:21.107134 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:32:21.107148 18283 solver.cpp:244]     Train net output #1: loss = 0.0052832 (* 1 = 0.0052832 loss)
I0813 18:32:21.107159 18283 sgd_solver.cpp:106] Iteration 41650, lr = 0.00291875
I0813 18:33:01.467087 18283 solver.cpp:337] Iteration 41700, Testing net (#0)
I0813 18:33:05.691295 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 18:33:05.691357 18283 solver.cpp:404]     Test net output #1: loss = 1.0372 (* 1 = 1.0372 loss)
I0813 18:33:06.504804 18283 solver.cpp:228] Iteration 41700, loss = 0.00453416
I0813 18:33:06.504878 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:33:06.504889 18283 solver.cpp:244]     Train net output #1: loss = 0.00453419 (* 1 = 0.00453419 loss)
I0813 18:33:06.504904 18283 sgd_solver.cpp:106] Iteration 41700, lr = 0.00291664
I0813 18:33:47.915719 18283 solver.cpp:228] Iteration 41750, loss = 0.00203837
I0813 18:33:47.915904 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:33:47.915917 18283 solver.cpp:244]     Train net output #1: loss = 0.0020384 (* 1 = 0.0020384 loss)
I0813 18:33:47.915930 18283 sgd_solver.cpp:106] Iteration 41750, lr = 0.00291452
I0813 18:34:28.292636 18283 solver.cpp:337] Iteration 41800, Testing net (#0)
I0813 18:34:32.549491 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 18:34:32.549558 18283 solver.cpp:404]     Test net output #1: loss = 1.01733 (* 1 = 1.01733 loss)
I0813 18:34:33.361346 18283 solver.cpp:228] Iteration 41800, loss = 0.00613509
I0813 18:34:33.361399 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:34:33.361410 18283 solver.cpp:244]     Train net output #1: loss = 0.00613513 (* 1 = 0.00613513 loss)
I0813 18:34:33.361428 18283 sgd_solver.cpp:106] Iteration 41800, lr = 0.00291241
I0813 18:35:14.533068 18283 solver.cpp:228] Iteration 41850, loss = -3.67872e-08
I0813 18:35:14.533226 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:35:14.533239 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:35:14.533252 18283 sgd_solver.cpp:106] Iteration 41850, lr = 0.0029103
I0813 18:35:54.917856 18283 solver.cpp:337] Iteration 41900, Testing net (#0)
I0813 18:35:58.972694 18283 solver.cpp:404]     Test net output #0: accuracy = 0.764
I0813 18:35:58.972762 18283 solver.cpp:404]     Test net output #1: loss = 0.845167 (* 1 = 0.845167 loss)
I0813 18:35:59.785650 18283 solver.cpp:228] Iteration 41900, loss = -3.77186e-08
I0813 18:35:59.785709 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:35:59.785722 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:35:59.785737 18283 sgd_solver.cpp:106] Iteration 41900, lr = 0.0029082
I0813 18:36:40.959298 18283 solver.cpp:228] Iteration 41950, loss = -3.72529e-08
I0813 18:36:40.959450 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:36:40.959465 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:36:40.959475 18283 sgd_solver.cpp:106] Iteration 41950, lr = 0.0029061
I0813 18:37:21.988270 18283 solver.cpp:337] Iteration 42000, Testing net (#0)
I0813 18:37:26.049945 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 18:37:26.050024 18283 solver.cpp:404]     Test net output #1: loss = 0.98664 (* 1 = 0.98664 loss)
I0813 18:37:26.862540 18283 solver.cpp:228] Iteration 42000, loss = 0.000152154
I0813 18:37:26.862592 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:37:26.862603 18283 solver.cpp:244]     Train net output #1: loss = 0.000152192 (* 1 = 0.000152192 loss)
I0813 18:37:26.862622 18283 sgd_solver.cpp:106] Iteration 42000, lr = 0.00290401
I0813 18:38:08.359285 18283 solver.cpp:228] Iteration 42050, loss = 0.0132364
I0813 18:38:08.359438 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:38:08.359454 18283 solver.cpp:244]     Train net output #1: loss = 0.0132364 (* 1 = 0.0132364 loss)
I0813 18:38:08.359468 18283 sgd_solver.cpp:106] Iteration 42050, lr = 0.00290191
I0813 18:38:48.727690 18283 solver.cpp:337] Iteration 42100, Testing net (#0)
I0813 18:38:52.784041 18283 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0813 18:38:52.784126 18283 solver.cpp:404]     Test net output #1: loss = 0.987087 (* 1 = 0.987087 loss)
I0813 18:38:53.597931 18283 solver.cpp:228] Iteration 42100, loss = 0.00286434
I0813 18:38:53.597985 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:38:53.597996 18283 solver.cpp:244]     Train net output #1: loss = 0.00286438 (* 1 = 0.00286438 loss)
I0813 18:38:53.598007 18283 sgd_solver.cpp:106] Iteration 42100, lr = 0.00289982
I0813 18:39:34.795482 18283 solver.cpp:228] Iteration 42150, loss = -3.47209e-08
I0813 18:39:34.795631 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:39:34.795645 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:39:34.795657 18283 sgd_solver.cpp:106] Iteration 42150, lr = 0.00289774
I0813 18:40:15.182976 18283 solver.cpp:337] Iteration 42200, Testing net (#0)
I0813 18:40:19.436765 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 18:40:19.436847 18283 solver.cpp:404]     Test net output #1: loss = 0.937458 (* 1 = 0.937458 loss)
I0813 18:40:20.249792 18283 solver.cpp:228] Iteration 42200, loss = 0.00978656
I0813 18:40:20.249847 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:40:20.249860 18283 solver.cpp:244]     Train net output #1: loss = 0.00978659 (* 1 = 0.00978659 loss)
I0813 18:40:20.249874 18283 sgd_solver.cpp:106] Iteration 42200, lr = 0.00289566
I0813 18:41:01.422385 18283 solver.cpp:228] Iteration 42250, loss = 0.0119007
I0813 18:41:01.422608 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:41:01.422669 18283 solver.cpp:244]     Train net output #1: loss = 0.0119007 (* 1 = 0.0119007 loss)
I0813 18:41:01.422703 18283 sgd_solver.cpp:106] Iteration 42250, lr = 0.00289358
I0813 18:41:42.282903 18283 solver.cpp:337] Iteration 42300, Testing net (#0)
I0813 18:41:46.493582 18283 solver.cpp:404]     Test net output #0: accuracy = 0.743
I0813 18:41:46.493644 18283 solver.cpp:404]     Test net output #1: loss = 1.03261 (* 1 = 1.03261 loss)
I0813 18:41:47.307011 18283 solver.cpp:228] Iteration 42300, loss = 0.00164351
I0813 18:41:47.307070 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:41:47.307080 18283 solver.cpp:244]     Train net output #1: loss = 0.00164354 (* 1 = 0.00164354 loss)
I0813 18:41:47.307096 18283 sgd_solver.cpp:106] Iteration 42300, lr = 0.0028915
I0813 18:42:28.500800 18283 solver.cpp:228] Iteration 42350, loss = 0.00565009
I0813 18:42:28.500964 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:42:28.500978 18283 solver.cpp:244]     Train net output #1: loss = 0.00565012 (* 1 = 0.00565012 loss)
I0813 18:42:28.500990 18283 sgd_solver.cpp:106] Iteration 42350, lr = 0.00288943
I0813 18:43:08.889336 18283 solver.cpp:337] Iteration 42400, Testing net (#0)
I0813 18:43:13.145324 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 18:43:13.145393 18283 solver.cpp:404]     Test net output #1: loss = 0.999232 (* 1 = 0.999232 loss)
I0813 18:43:13.958943 18283 solver.cpp:228] Iteration 42400, loss = 0.0219045
I0813 18:43:13.959002 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 18:43:13.959013 18283 solver.cpp:244]     Train net output #1: loss = 0.0219046 (* 1 = 0.0219046 loss)
I0813 18:43:13.959029 18283 sgd_solver.cpp:106] Iteration 42400, lr = 0.00288736
I0813 18:43:55.861424 18283 solver.cpp:228] Iteration 42450, loss = 0.0206904
I0813 18:43:55.861588 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:43:55.861603 18283 solver.cpp:244]     Train net output #1: loss = 0.0206904 (* 1 = 0.0206904 loss)
I0813 18:43:55.861614 18283 sgd_solver.cpp:106] Iteration 42450, lr = 0.0028853
I0813 18:44:36.243132 18283 solver.cpp:337] Iteration 42500, Testing net (#0)
I0813 18:44:40.296867 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 18:44:40.296936 18283 solver.cpp:404]     Test net output #1: loss = 0.902509 (* 1 = 0.902509 loss)
I0813 18:44:41.111469 18283 solver.cpp:228] Iteration 42500, loss = 0.00111328
I0813 18:44:41.111538 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:44:41.111551 18283 solver.cpp:244]     Train net output #1: loss = 0.00111331 (* 1 = 0.00111331 loss)
I0813 18:44:41.111562 18283 sgd_solver.cpp:106] Iteration 42500, lr = 0.00288324
I0813 18:45:22.264583 18283 solver.cpp:228] Iteration 42550, loss = 0.0128541
I0813 18:45:22.264740 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:45:22.264755 18283 solver.cpp:244]     Train net output #1: loss = 0.0128542 (* 1 = 0.0128542 loss)
I0813 18:45:22.264766 18283 sgd_solver.cpp:106] Iteration 42550, lr = 0.00288118
I0813 18:46:03.150508 18283 solver.cpp:337] Iteration 42600, Testing net (#0)
I0813 18:46:07.453371 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 18:46:07.453441 18283 solver.cpp:404]     Test net output #1: loss = 0.897222 (* 1 = 0.897222 loss)
I0813 18:46:08.266479 18283 solver.cpp:228] Iteration 42600, loss = 0.00614037
I0813 18:46:08.266537 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:46:08.266549 18283 solver.cpp:244]     Train net output #1: loss = 0.0061404 (* 1 = 0.0061404 loss)
I0813 18:46:08.266564 18283 sgd_solver.cpp:106] Iteration 42600, lr = 0.00287913
I0813 18:46:49.476493 18283 solver.cpp:228] Iteration 42650, loss = 0.00309708
I0813 18:46:49.476658 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:46:49.476672 18283 solver.cpp:244]     Train net output #1: loss = 0.00309711 (* 1 = 0.00309711 loss)
I0813 18:46:49.476685 18283 sgd_solver.cpp:106] Iteration 42650, lr = 0.00287708
I0813 18:47:30.109252 18283 solver.cpp:337] Iteration 42700, Testing net (#0)
I0813 18:47:34.204150 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 18:47:34.204233 18283 solver.cpp:404]     Test net output #1: loss = 1.03613 (* 1 = 1.03613 loss)
I0813 18:47:35.017933 18283 solver.cpp:228] Iteration 42700, loss = 0.0046415
I0813 18:47:35.017990 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:47:35.018002 18283 solver.cpp:244]     Train net output #1: loss = 0.00464154 (* 1 = 0.00464154 loss)
I0813 18:47:35.018021 18283 sgd_solver.cpp:106] Iteration 42700, lr = 0.00287503
I0813 18:48:16.188179 18283 solver.cpp:228] Iteration 42750, loss = 0.00179168
I0813 18:48:16.188341 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:48:16.188356 18283 solver.cpp:244]     Train net output #1: loss = 0.00179172 (* 1 = 0.00179172 loss)
I0813 18:48:16.188369 18283 sgd_solver.cpp:106] Iteration 42750, lr = 0.00287298
I0813 18:48:56.530030 18283 solver.cpp:337] Iteration 42800, Testing net (#0)
I0813 18:49:00.583089 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 18:49:00.583156 18283 solver.cpp:404]     Test net output #1: loss = 0.978013 (* 1 = 0.978013 loss)
I0813 18:49:01.396536 18283 solver.cpp:228] Iteration 42800, loss = 0.0228921
I0813 18:49:01.396594 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:49:01.396605 18283 solver.cpp:244]     Train net output #1: loss = 0.0228921 (* 1 = 0.0228921 loss)
I0813 18:49:01.396620 18283 sgd_solver.cpp:106] Iteration 42800, lr = 0.00287094
I0813 18:49:42.585865 18283 solver.cpp:228] Iteration 42850, loss = 0.00355334
I0813 18:49:42.586103 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:49:42.586158 18283 solver.cpp:244]     Train net output #1: loss = 0.00355337 (* 1 = 0.00355337 loss)
I0813 18:49:42.586179 18283 sgd_solver.cpp:106] Iteration 42850, lr = 0.00286891
I0813 18:50:23.061914 18283 solver.cpp:337] Iteration 42900, Testing net (#0)
I0813 18:50:27.368862 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 18:50:27.368928 18283 solver.cpp:404]     Test net output #1: loss = 1.00268 (* 1 = 1.00268 loss)
I0813 18:50:28.183130 18283 solver.cpp:228] Iteration 42900, loss = 0.00298127
I0813 18:50:28.183197 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:50:28.183209 18283 solver.cpp:244]     Train net output #1: loss = 0.0029813 (* 1 = 0.0029813 loss)
I0813 18:50:28.183224 18283 sgd_solver.cpp:106] Iteration 42900, lr = 0.00286687
I0813 18:51:09.358058 18283 solver.cpp:228] Iteration 42950, loss = 6.10613e-05
I0813 18:51:09.358219 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:51:09.358234 18283 solver.cpp:244]     Train net output #1: loss = 6.10942e-05 (* 1 = 6.10942e-05 loss)
I0813 18:51:09.358248 18283 sgd_solver.cpp:106] Iteration 42950, lr = 0.00286484
I0813 18:51:50.760957 18283 solver.cpp:337] Iteration 43000, Testing net (#0)
I0813 18:51:54.822969 18283 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0813 18:51:54.823050 18283 solver.cpp:404]     Test net output #1: loss = 0.842675 (* 1 = 0.842675 loss)
I0813 18:51:55.635994 18283 solver.cpp:228] Iteration 43000, loss = 0.00785235
I0813 18:51:55.636112 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:51:55.636126 18283 solver.cpp:244]     Train net output #1: loss = 0.00785239 (* 1 = 0.00785239 loss)
I0813 18:51:55.636143 18283 sgd_solver.cpp:106] Iteration 43000, lr = 0.00286281
I0813 18:52:36.819700 18283 solver.cpp:228] Iteration 43050, loss = 0.00898067
I0813 18:52:36.819903 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:52:36.819918 18283 solver.cpp:244]     Train net output #1: loss = 0.00898071 (* 1 = 0.00898071 loss)
I0813 18:52:36.819929 18283 sgd_solver.cpp:106] Iteration 43050, lr = 0.00286079
I0813 18:53:17.181639 18283 solver.cpp:337] Iteration 43100, Testing net (#0)
I0813 18:53:21.422369 18283 solver.cpp:404]     Test net output #0: accuracy = 0.776
I0813 18:53:21.422435 18283 solver.cpp:404]     Test net output #1: loss = 0.8978 (* 1 = 0.8978 loss)
I0813 18:53:22.237135 18283 solver.cpp:228] Iteration 43100, loss = 0.007539
I0813 18:53:22.237203 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:53:22.237215 18283 solver.cpp:244]     Train net output #1: loss = 0.00753904 (* 1 = 0.00753904 loss)
I0813 18:53:22.237231 18283 sgd_solver.cpp:106] Iteration 43100, lr = 0.00285877
I0813 18:54:03.444180 18283 solver.cpp:228] Iteration 43150, loss = 0.000202955
I0813 18:54:03.444394 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:54:03.444447 18283 solver.cpp:244]     Train net output #1: loss = 0.000202991 (* 1 = 0.000202991 loss)
I0813 18:54:03.444489 18283 sgd_solver.cpp:106] Iteration 43150, lr = 0.00285675
I0813 18:54:44.534996 18283 solver.cpp:337] Iteration 43200, Testing net (#0)
I0813 18:54:49.069001 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 18:54:49.069062 18283 solver.cpp:404]     Test net output #1: loss = 0.930663 (* 1 = 0.930663 loss)
I0813 18:54:50.066028 18283 solver.cpp:228] Iteration 43200, loss = 0.00458961
I0813 18:54:50.066100 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:54:50.066113 18283 solver.cpp:244]     Train net output #1: loss = 0.00458965 (* 1 = 0.00458965 loss)
I0813 18:54:50.066126 18283 sgd_solver.cpp:106] Iteration 43200, lr = 0.00285474
I0813 18:55:32.172291 18283 solver.cpp:228] Iteration 43250, loss = 0.013648
I0813 18:55:32.172499 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:55:32.172557 18283 solver.cpp:244]     Train net output #1: loss = 0.0136481 (* 1 = 0.0136481 loss)
I0813 18:55:32.172592 18283 sgd_solver.cpp:106] Iteration 43250, lr = 0.00285273
I0813 18:56:12.735831 18283 solver.cpp:337] Iteration 43300, Testing net (#0)
I0813 18:56:16.790609 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 18:56:16.790671 18283 solver.cpp:404]     Test net output #1: loss = 0.962524 (* 1 = 0.962524 loss)
I0813 18:56:17.603047 18283 solver.cpp:228] Iteration 43300, loss = -3.07336e-08
I0813 18:56:17.603101 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:56:17.603111 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 18:56:17.603129 18283 sgd_solver.cpp:106] Iteration 43300, lr = 0.00285072
I0813 18:56:58.771258 18283 solver.cpp:228] Iteration 43350, loss = 0.00140322
I0813 18:56:58.771419 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:56:58.771432 18283 solver.cpp:244]     Train net output #1: loss = 0.00140325 (* 1 = 0.00140325 loss)
I0813 18:56:58.771443 18283 sgd_solver.cpp:106] Iteration 43350, lr = 0.00284872
I0813 18:57:39.131860 18283 solver.cpp:337] Iteration 43400, Testing net (#0)
I0813 18:57:43.585034 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 18:57:43.585103 18283 solver.cpp:404]     Test net output #1: loss = 0.915489 (* 1 = 0.915489 loss)
I0813 18:57:44.399446 18283 solver.cpp:228] Iteration 43400, loss = 0.000201822
I0813 18:57:44.399504 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:57:44.399515 18283 solver.cpp:244]     Train net output #1: loss = 0.000201854 (* 1 = 0.000201854 loss)
I0813 18:57:44.399535 18283 sgd_solver.cpp:106] Iteration 43400, lr = 0.00284672
I0813 18:58:25.600520 18283 solver.cpp:228] Iteration 43450, loss = 0.00916373
I0813 18:58:25.600761 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:58:25.600821 18283 solver.cpp:244]     Train net output #1: loss = 0.00916376 (* 1 = 0.00916376 loss)
I0813 18:58:25.600846 18283 sgd_solver.cpp:106] Iteration 43450, lr = 0.00284472
I0813 18:59:06.179618 18283 solver.cpp:337] Iteration 43500, Testing net (#0)
I0813 18:59:10.231847 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 18:59:10.231917 18283 solver.cpp:404]     Test net output #1: loss = 0.987116 (* 1 = 0.987116 loss)
I0813 18:59:11.043289 18283 solver.cpp:228] Iteration 43500, loss = 0.0254353
I0813 18:59:11.043344 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:59:11.043356 18283 solver.cpp:244]     Train net output #1: loss = 0.0254354 (* 1 = 0.0254354 loss)
I0813 18:59:11.043373 18283 sgd_solver.cpp:106] Iteration 43500, lr = 0.00284272
I0813 18:59:52.223301 18283 solver.cpp:228] Iteration 43550, loss = 0.00485519
I0813 18:59:52.223467 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 18:59:52.223482 18283 solver.cpp:244]     Train net output #1: loss = 0.00485522 (* 1 = 0.00485522 loss)
I0813 18:59:52.223495 18283 sgd_solver.cpp:106] Iteration 43550, lr = 0.00284073
I0813 19:00:32.583017 18283 solver.cpp:337] Iteration 43600, Testing net (#0)
I0813 19:00:36.637064 18283 solver.cpp:404]     Test net output #0: accuracy = 0.779
I0813 19:00:36.637130 18283 solver.cpp:404]     Test net output #1: loss = 0.800887 (* 1 = 0.800887 loss)
I0813 19:00:37.449861 18283 solver.cpp:228] Iteration 43600, loss = 0.00689864
I0813 19:00:37.449913 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:00:37.449924 18283 solver.cpp:244]     Train net output #1: loss = 0.00689868 (* 1 = 0.00689868 loss)
I0813 19:00:37.449944 18283 sgd_solver.cpp:106] Iteration 43600, lr = 0.00283875
I0813 19:01:18.690971 18283 solver.cpp:228] Iteration 43650, loss = -3.53903e-08
I0813 19:01:18.691138 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:01:18.691150 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:01:18.691164 18283 sgd_solver.cpp:106] Iteration 43650, lr = 0.00283676
I0813 19:01:59.039028 18283 solver.cpp:337] Iteration 43700, Testing net (#0)
I0813 19:02:03.095664 18283 solver.cpp:404]     Test net output #0: accuracy = 0.786
I0813 19:02:03.095734 18283 solver.cpp:404]     Test net output #1: loss = 0.780725 (* 1 = 0.780725 loss)
I0813 19:02:03.908932 18283 solver.cpp:228] Iteration 43700, loss = -3.72529e-08
I0813 19:02:03.908990 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:02:03.909001 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:02:03.909013 18283 sgd_solver.cpp:106] Iteration 43700, lr = 0.00283478
I0813 19:02:45.083026 18283 solver.cpp:228] Iteration 43750, loss = -3.72529e-08
I0813 19:02:45.083243 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:02:45.083289 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:02:45.083315 18283 sgd_solver.cpp:106] Iteration 43750, lr = 0.0028328
I0813 19:03:25.427672 18283 solver.cpp:337] Iteration 43800, Testing net (#0)
I0813 19:03:29.479301 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 19:03:29.479368 18283 solver.cpp:404]     Test net output #1: loss = 0.957623 (* 1 = 0.957623 loss)
I0813 19:03:30.290911 18283 solver.cpp:228] Iteration 43800, loss = 0.00587563
I0813 19:03:30.290963 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:03:30.290976 18283 solver.cpp:244]     Train net output #1: loss = 0.00587566 (* 1 = 0.00587566 loss)
I0813 19:03:30.290993 18283 sgd_solver.cpp:106] Iteration 43800, lr = 0.00283083
I0813 19:04:11.427026 18283 solver.cpp:228] Iteration 43850, loss = 0.0116997
I0813 19:04:11.427177 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:04:11.427191 18283 solver.cpp:244]     Train net output #1: loss = 0.0116997 (* 1 = 0.0116997 loss)
I0813 19:04:11.427202 18283 sgd_solver.cpp:106] Iteration 43850, lr = 0.00282886
I0813 19:04:51.762591 18283 solver.cpp:337] Iteration 43900, Testing net (#0)
I0813 19:04:56.125208 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 19:04:56.125274 18283 solver.cpp:404]     Test net output #1: loss = 0.958162 (* 1 = 0.958162 loss)
I0813 19:04:56.935020 18283 solver.cpp:228] Iteration 43900, loss = 0.0102651
I0813 19:04:56.935073 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:04:56.935086 18283 solver.cpp:244]     Train net output #1: loss = 0.0102651 (* 1 = 0.0102651 loss)
I0813 19:04:56.935104 18283 sgd_solver.cpp:106] Iteration 43900, lr = 0.00282689
I0813 19:05:38.069355 18283 solver.cpp:228] Iteration 43950, loss = 0.00390579
I0813 19:05:38.069510 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:05:38.069525 18283 solver.cpp:244]     Train net output #1: loss = 0.00390583 (* 1 = 0.00390583 loss)
I0813 19:05:38.069535 18283 sgd_solver.cpp:106] Iteration 43950, lr = 0.00282492
I0813 19:06:18.415314 18283 solver.cpp:337] Iteration 44000, Testing net (#0)
I0813 19:06:22.461077 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 19:06:22.461144 18283 solver.cpp:404]     Test net output #1: loss = 0.873508 (* 1 = 0.873508 loss)
I0813 19:06:23.274231 18283 solver.cpp:228] Iteration 44000, loss = 0.00235287
I0813 19:06:23.274284 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:06:23.274296 18283 solver.cpp:244]     Train net output #1: loss = 0.00235291 (* 1 = 0.00235291 loss)
I0813 19:06:23.274313 18283 sgd_solver.cpp:106] Iteration 44000, lr = 0.00282296
I0813 19:07:04.435926 18283 solver.cpp:228] Iteration 44050, loss = 0.0010036
I0813 19:07:04.436094 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:07:04.436108 18283 solver.cpp:244]     Train net output #1: loss = 0.00100364 (* 1 = 0.00100364 loss)
I0813 19:07:04.436120 18283 sgd_solver.cpp:106] Iteration 44050, lr = 0.002821
I0813 19:07:44.766377 18283 solver.cpp:337] Iteration 44100, Testing net (#0)
I0813 19:07:48.822319 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 19:07:48.822384 18283 solver.cpp:404]     Test net output #1: loss = 1.03221 (* 1 = 1.03221 loss)
I0813 19:07:49.634176 18283 solver.cpp:228] Iteration 44100, loss = 0.0205806
I0813 19:07:49.634222 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:07:49.634233 18283 solver.cpp:244]     Train net output #1: loss = 0.0205807 (* 1 = 0.0205807 loss)
I0813 19:07:49.634253 18283 sgd_solver.cpp:106] Iteration 44100, lr = 0.00281905
I0813 19:08:31.141134 18283 solver.cpp:228] Iteration 44150, loss = 0.00816539
I0813 19:08:31.141331 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:08:31.141386 18283 solver.cpp:244]     Train net output #1: loss = 0.00816543 (* 1 = 0.00816543 loss)
I0813 19:08:31.141407 18283 sgd_solver.cpp:106] Iteration 44150, lr = 0.00281709
I0813 19:09:11.741683 18283 solver.cpp:337] Iteration 44200, Testing net (#0)
I0813 19:09:15.797324 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 19:09:15.797396 18283 solver.cpp:404]     Test net output #1: loss = 0.90532 (* 1 = 0.90532 loss)
I0813 19:09:16.610548 18283 solver.cpp:228] Iteration 44200, loss = 0.0137763
I0813 19:09:16.610602 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:09:16.610615 18283 solver.cpp:244]     Train net output #1: loss = 0.0137763 (* 1 = 0.0137763 loss)
I0813 19:09:16.610625 18283 sgd_solver.cpp:106] Iteration 44200, lr = 0.00281514
I0813 19:09:57.761510 18283 solver.cpp:228] Iteration 44250, loss = -3.72529e-08
I0813 19:09:57.761747 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:09:57.761800 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:09:57.761821 18283 sgd_solver.cpp:106] Iteration 44250, lr = 0.0028132
I0813 19:10:38.157126 18283 solver.cpp:337] Iteration 44300, Testing net (#0)
I0813 19:10:42.203693 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 19:10:42.203764 18283 solver.cpp:404]     Test net output #1: loss = 0.956128 (* 1 = 0.956128 loss)
I0813 19:10:43.014389 18283 solver.cpp:228] Iteration 44300, loss = 0.0243778
I0813 19:10:43.014443 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:10:43.014456 18283 solver.cpp:244]     Train net output #1: loss = 0.0243778 (* 1 = 0.0243778 loss)
I0813 19:10:43.014472 18283 sgd_solver.cpp:106] Iteration 44300, lr = 0.00281125
I0813 19:11:24.191997 18283 solver.cpp:228] Iteration 44350, loss = 2.38873e-05
I0813 19:11:24.192169 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:11:24.192183 18283 solver.cpp:244]     Train net output #1: loss = 2.39235e-05 (* 1 = 2.39235e-05 loss)
I0813 19:11:24.192195 18283 sgd_solver.cpp:106] Iteration 44350, lr = 0.00280931
I0813 19:12:04.546937 18283 solver.cpp:337] Iteration 44400, Testing net (#0)
I0813 19:12:08.605141 18283 solver.cpp:404]     Test net output #0: accuracy = 0.754
I0813 19:12:08.605206 18283 solver.cpp:404]     Test net output #1: loss = 0.930946 (* 1 = 0.930946 loss)
I0813 19:12:09.417222 18283 solver.cpp:228] Iteration 44400, loss = -3.56231e-08
I0813 19:12:09.417273 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:12:09.417284 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:12:09.417301 18283 sgd_solver.cpp:106] Iteration 44400, lr = 0.00280738
I0813 19:12:50.581950 18283 solver.cpp:228] Iteration 44450, loss = -3.38769e-08
I0813 19:12:50.582146 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:12:50.582197 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:12:50.582218 18283 sgd_solver.cpp:106] Iteration 44450, lr = 0.00280544
I0813 19:13:31.242696 18283 solver.cpp:337] Iteration 44500, Testing net (#0)
I0813 19:13:35.295338 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 19:13:35.295406 18283 solver.cpp:404]     Test net output #1: loss = 0.951967 (* 1 = 0.951967 loss)
I0813 19:13:36.120893 18283 solver.cpp:228] Iteration 44500, loss = 0.00817506
I0813 19:13:36.120954 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:13:36.120965 18283 solver.cpp:244]     Train net output #1: loss = 0.0081751 (* 1 = 0.0081751 loss)
I0813 19:13:36.120977 18283 sgd_solver.cpp:106] Iteration 44500, lr = 0.00280351
I0813 19:14:17.658645 18283 solver.cpp:228] Iteration 44550, loss = 0.0193997
I0813 19:14:17.658797 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:14:17.658810 18283 solver.cpp:244]     Train net output #1: loss = 0.0193997 (* 1 = 0.0193997 loss)
I0813 19:14:17.658823 18283 sgd_solver.cpp:106] Iteration 44550, lr = 0.00280159
I0813 19:14:58.410733 18283 solver.cpp:337] Iteration 44600, Testing net (#0)
I0813 19:15:02.563051 18283 solver.cpp:404]     Test net output #0: accuracy = 0.743
I0813 19:15:02.563117 18283 solver.cpp:404]     Test net output #1: loss = 1.01883 (* 1 = 1.01883 loss)
I0813 19:15:03.376929 18283 solver.cpp:228] Iteration 44600, loss = 0.0203613
I0813 19:15:03.376981 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:15:03.376993 18283 solver.cpp:244]     Train net output #1: loss = 0.0203613 (* 1 = 0.0203613 loss)
I0813 19:15:03.377012 18283 sgd_solver.cpp:106] Iteration 44600, lr = 0.00279966
I0813 19:15:44.551400 18283 solver.cpp:228] Iteration 44650, loss = -3.44589e-08
I0813 19:15:44.551594 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:15:44.551640 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:15:44.551657 18283 sgd_solver.cpp:106] Iteration 44650, lr = 0.00279774
I0813 19:16:25.133651 18283 solver.cpp:337] Iteration 44700, Testing net (#0)
I0813 19:16:29.193462 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 19:16:29.193528 18283 solver.cpp:404]     Test net output #1: loss = 0.938693 (* 1 = 0.938693 loss)
I0813 19:16:30.007277 18283 solver.cpp:228] Iteration 44700, loss = 0.00103099
I0813 19:16:30.007328 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:16:30.007339 18283 solver.cpp:244]     Train net output #1: loss = 0.00103103 (* 1 = 0.00103103 loss)
I0813 19:16:30.007351 18283 sgd_solver.cpp:106] Iteration 44700, lr = 0.00279582
I0813 19:17:11.187114 18283 solver.cpp:228] Iteration 44750, loss = 0.00099989
I0813 19:17:11.187382 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:17:11.187433 18283 solver.cpp:244]     Train net output #1: loss = 0.000999923 (* 1 = 0.000999923 loss)
I0813 19:17:11.187459 18283 sgd_solver.cpp:106] Iteration 44750, lr = 0.00279391
I0813 19:17:51.890146 18283 solver.cpp:337] Iteration 44800, Testing net (#0)
I0813 19:17:55.942662 18283 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0813 19:17:55.942724 18283 solver.cpp:404]     Test net output #1: loss = 0.993924 (* 1 = 0.993924 loss)
I0813 19:17:56.755290 18283 solver.cpp:228] Iteration 44800, loss = 0.0101431
I0813 19:17:56.755345 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:17:56.755357 18283 solver.cpp:244]     Train net output #1: loss = 0.0101431 (* 1 = 0.0101431 loss)
I0813 19:17:56.755368 18283 sgd_solver.cpp:106] Iteration 44800, lr = 0.00279199
I0813 19:18:37.954816 18283 solver.cpp:228] Iteration 44850, loss = 0.0149244
I0813 19:18:37.955026 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:18:37.955122 18283 solver.cpp:244]     Train net output #1: loss = 0.0149245 (* 1 = 0.0149245 loss)
I0813 19:18:37.955163 18283 sgd_solver.cpp:106] Iteration 44850, lr = 0.00279009
I0813 19:19:18.476125 18283 solver.cpp:337] Iteration 44900, Testing net (#0)
I0813 19:19:22.528375 18283 solver.cpp:404]     Test net output #0: accuracy = 0.743
I0813 19:19:22.528445 18283 solver.cpp:404]     Test net output #1: loss = 1.02608 (* 1 = 1.02608 loss)
I0813 19:19:23.340654 18283 solver.cpp:228] Iteration 44900, loss = 0.00740269
I0813 19:19:23.340706 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:19:23.340718 18283 solver.cpp:244]     Train net output #1: loss = 0.00740272 (* 1 = 0.00740272 loss)
I0813 19:19:23.340735 18283 sgd_solver.cpp:106] Iteration 44900, lr = 0.00278818
I0813 19:20:04.506340 18283 solver.cpp:228] Iteration 44950, loss = 0.000714113
I0813 19:20:04.506503 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:20:04.506516 18283 solver.cpp:244]     Train net output #1: loss = 0.000714136 (* 1 = 0.000714136 loss)
I0813 19:20:04.506531 18283 sgd_solver.cpp:106] Iteration 44950, lr = 0.00278628
I0813 19:20:44.837673 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_45000.caffemodel
I0813 19:20:45.283329 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_45000.solverstate
I0813 19:20:45.298580 18283 solver.cpp:337] Iteration 45000, Testing net (#0)
I0813 19:20:49.422713 18283 solver.cpp:404]     Test net output #0: accuracy = 0.73
I0813 19:20:49.422785 18283 solver.cpp:404]     Test net output #1: loss = 1.15136 (* 1 = 1.15136 loss)
I0813 19:20:50.238255 18283 solver.cpp:228] Iteration 45000, loss = 0.0162006
I0813 19:20:50.238319 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:20:50.238332 18283 solver.cpp:244]     Train net output #1: loss = 0.0162006 (* 1 = 0.0162006 loss)
I0813 19:20:50.238345 18283 sgd_solver.cpp:106] Iteration 45000, lr = 0.00278438
I0813 19:21:31.403776 18283 solver.cpp:228] Iteration 45050, loss = 0.00379343
I0813 19:21:31.404057 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:21:31.404129 18283 solver.cpp:244]     Train net output #1: loss = 0.00379345 (* 1 = 0.00379345 loss)
I0813 19:21:31.404161 18283 sgd_solver.cpp:106] Iteration 45050, lr = 0.00278248
I0813 19:22:12.631289 18283 solver.cpp:337] Iteration 45100, Testing net (#0)
I0813 19:22:16.819151 18283 solver.cpp:404]     Test net output #0: accuracy = 0.74
I0813 19:22:16.819258 18283 solver.cpp:404]     Test net output #1: loss = 1.07503 (* 1 = 1.07503 loss)
I0813 19:22:18.013983 18283 solver.cpp:228] Iteration 45100, loss = 0.0170511
I0813 19:22:18.014061 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:22:18.014075 18283 solver.cpp:244]     Train net output #1: loss = 0.0170511 (* 1 = 0.0170511 loss)
I0813 19:22:18.014091 18283 sgd_solver.cpp:106] Iteration 45100, lr = 0.00278059
I0813 19:22:59.342890 18283 solver.cpp:228] Iteration 45150, loss = 0.0087265
I0813 19:22:59.343130 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:22:59.343180 18283 solver.cpp:244]     Train net output #1: loss = 0.00872651 (* 1 = 0.00872651 loss)
I0813 19:22:59.343214 18283 sgd_solver.cpp:106] Iteration 45150, lr = 0.00277869
I0813 19:23:40.230334 18283 solver.cpp:337] Iteration 45200, Testing net (#0)
I0813 19:23:44.285662 18283 solver.cpp:404]     Test net output #0: accuracy = 0.747
I0813 19:23:44.285729 18283 solver.cpp:404]     Test net output #1: loss = 1.02136 (* 1 = 1.02136 loss)
I0813 19:23:45.099968 18283 solver.cpp:228] Iteration 45200, loss = 0.00490042
I0813 19:23:45.100030 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:23:45.100041 18283 solver.cpp:244]     Train net output #1: loss = 0.00490043 (* 1 = 0.00490043 loss)
I0813 19:23:45.100060 18283 sgd_solver.cpp:106] Iteration 45200, lr = 0.00277681
I0813 19:24:26.292256 18283 solver.cpp:228] Iteration 45250, loss = 0.00626453
I0813 19:24:26.292412 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:24:26.292425 18283 solver.cpp:244]     Train net output #1: loss = 0.00626455 (* 1 = 0.00626455 loss)
I0813 19:24:26.292438 18283 sgd_solver.cpp:106] Iteration 45250, lr = 0.00277492
I0813 19:25:07.180842 18283 solver.cpp:337] Iteration 45300, Testing net (#0)
I0813 19:25:11.403975 18283 solver.cpp:404]     Test net output #0: accuracy = 0.768
I0813 19:25:11.404045 18283 solver.cpp:404]     Test net output #1: loss = 0.836807 (* 1 = 0.836807 loss)
I0813 19:25:12.216212 18283 solver.cpp:228] Iteration 45300, loss = 0.00659099
I0813 19:25:12.216290 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:25:12.216303 18283 solver.cpp:244]     Train net output #1: loss = 0.006591 (* 1 = 0.006591 loss)
I0813 19:25:12.216320 18283 sgd_solver.cpp:106] Iteration 45300, lr = 0.00277304
I0813 19:25:53.418092 18283 solver.cpp:228] Iteration 45350, loss = 0.00371575
I0813 19:25:53.418254 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:25:53.418267 18283 solver.cpp:244]     Train net output #1: loss = 0.00371577 (* 1 = 0.00371577 loss)
I0813 19:25:53.418280 18283 sgd_solver.cpp:106] Iteration 45350, lr = 0.00277116
I0813 19:26:33.784035 18283 solver.cpp:337] Iteration 45400, Testing net (#0)
I0813 19:26:38.043829 18283 solver.cpp:404]     Test net output #0: accuracy = 0.773
I0813 19:26:38.043900 18283 solver.cpp:404]     Test net output #1: loss = 0.848311 (* 1 = 0.848311 loss)
I0813 19:26:38.855162 18283 solver.cpp:228] Iteration 45400, loss = -1.67638e-08
I0813 19:26:38.855221 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:26:38.855232 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:26:38.855249 18283 sgd_solver.cpp:106] Iteration 45400, lr = 0.00276929
I0813 19:27:20.014783 18283 solver.cpp:228] Iteration 45450, loss = 5.94268e-06
I0813 19:27:20.014943 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:27:20.014957 18283 solver.cpp:244]     Train net output #1: loss = 5.95927e-06 (* 1 = 5.95927e-06 loss)
I0813 19:27:20.014968 18283 sgd_solver.cpp:106] Iteration 45450, lr = 0.00276741
I0813 19:28:00.355851 18283 solver.cpp:337] Iteration 45500, Testing net (#0)
I0813 19:28:04.803824 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 19:28:04.803894 18283 solver.cpp:404]     Test net output #1: loss = 0.934527 (* 1 = 0.934527 loss)
I0813 19:28:05.617048 18283 solver.cpp:228] Iteration 45500, loss = -1.88593e-08
I0813 19:28:05.617112 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:28:05.617123 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:28:05.617137 18283 sgd_solver.cpp:106] Iteration 45500, lr = 0.00276554
I0813 19:28:46.818404 18283 solver.cpp:228] Iteration 45550, loss = 0.0092317
I0813 19:28:46.818676 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:28:46.818724 18283 solver.cpp:244]     Train net output #1: loss = 0.00923172 (* 1 = 0.00923172 loss)
I0813 19:28:46.818752 18283 sgd_solver.cpp:106] Iteration 45550, lr = 0.00276367
I0813 19:29:28.602900 18283 solver.cpp:337] Iteration 45600, Testing net (#0)
I0813 19:29:32.669775 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 19:29:32.669852 18283 solver.cpp:404]     Test net output #1: loss = 0.882233 (* 1 = 0.882233 loss)
I0813 19:29:33.483278 18283 solver.cpp:228] Iteration 45600, loss = 0.00688971
I0813 19:29:33.483336 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:29:33.483350 18283 solver.cpp:244]     Train net output #1: loss = 0.00688973 (* 1 = 0.00688973 loss)
I0813 19:29:33.483366 18283 sgd_solver.cpp:106] Iteration 45600, lr = 0.00276181
I0813 19:30:14.675153 18283 solver.cpp:228] Iteration 45650, loss = 5.73043e-05
I0813 19:30:14.675325 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:30:14.675339 18283 solver.cpp:244]     Train net output #1: loss = 5.7323e-05 (* 1 = 5.7323e-05 loss)
I0813 19:30:14.675351 18283 sgd_solver.cpp:106] Iteration 45650, lr = 0.00275995
I0813 19:30:56.008647 18283 solver.cpp:337] Iteration 45700, Testing net (#0)
I0813 19:31:00.267681 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 19:31:00.267745 18283 solver.cpp:404]     Test net output #1: loss = 1.02179 (* 1 = 1.02179 loss)
I0813 19:31:01.080922 18283 solver.cpp:228] Iteration 45700, loss = 0.00890848
I0813 19:31:01.080981 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:31:01.080994 18283 solver.cpp:244]     Train net output #1: loss = 0.0089085 (* 1 = 0.0089085 loss)
I0813 19:31:01.081007 18283 sgd_solver.cpp:106] Iteration 45700, lr = 0.00275809
I0813 19:31:42.270290 18283 solver.cpp:228] Iteration 45750, loss = 0.0186198
I0813 19:31:42.270439 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:31:42.270452 18283 solver.cpp:244]     Train net output #1: loss = 0.0186198 (* 1 = 0.0186198 loss)
I0813 19:31:42.270465 18283 sgd_solver.cpp:106] Iteration 45750, lr = 0.00275624
I0813 19:32:22.646278 18283 solver.cpp:337] Iteration 45800, Testing net (#0)
I0813 19:32:26.703239 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 19:32:26.703305 18283 solver.cpp:404]     Test net output #1: loss = 0.952146 (* 1 = 0.952146 loss)
I0813 19:32:27.517753 18283 solver.cpp:228] Iteration 45800, loss = -1.62981e-08
I0813 19:32:27.517807 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:32:27.517819 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:32:27.517830 18283 sgd_solver.cpp:106] Iteration 45800, lr = 0.00275438
I0813 19:33:08.704038 18283 solver.cpp:228] Iteration 45850, loss = 0.00171109
I0813 19:33:08.704197 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:33:08.704211 18283 solver.cpp:244]     Train net output #1: loss = 0.00171111 (* 1 = 0.00171111 loss)
I0813 19:33:08.704223 18283 sgd_solver.cpp:106] Iteration 45850, lr = 0.00275253
I0813 19:33:49.088511 18283 solver.cpp:337] Iteration 45900, Testing net (#0)
I0813 19:33:53.141496 18283 solver.cpp:404]     Test net output #0: accuracy = 0.735
I0813 19:33:53.141559 18283 solver.cpp:404]     Test net output #1: loss = 1.07919 (* 1 = 1.07919 loss)
I0813 19:33:53.952270 18283 solver.cpp:228] Iteration 45900, loss = 0.0226018
I0813 19:33:53.952322 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:33:53.952332 18283 solver.cpp:244]     Train net output #1: loss = 0.0226018 (* 1 = 0.0226018 loss)
I0813 19:33:53.952352 18283 sgd_solver.cpp:106] Iteration 45900, lr = 0.00275069
I0813 19:34:35.147006 18283 solver.cpp:228] Iteration 45950, loss = 0.00250913
I0813 19:34:35.147203 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:34:35.147218 18283 solver.cpp:244]     Train net output #1: loss = 0.00250915 (* 1 = 0.00250915 loss)
I0813 19:34:35.147230 18283 sgd_solver.cpp:106] Iteration 45950, lr = 0.00274884
I0813 19:35:15.509071 18283 solver.cpp:337] Iteration 46000, Testing net (#0)
I0813 19:35:19.563078 18283 solver.cpp:404]     Test net output #0: accuracy = 0.747
I0813 19:35:19.563143 18283 solver.cpp:404]     Test net output #1: loss = 0.996021 (* 1 = 0.996021 loss)
I0813 19:35:20.375679 18283 solver.cpp:228] Iteration 46000, loss = -2.14204e-08
I0813 19:35:20.375731 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:35:20.375742 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:35:20.375761 18283 sgd_solver.cpp:106] Iteration 46000, lr = 0.002747
I0813 19:36:02.119529 18283 solver.cpp:228] Iteration 46050, loss = 0.0043781
I0813 19:36:02.119747 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:36:02.119801 18283 solver.cpp:244]     Train net output #1: loss = 0.00437813 (* 1 = 0.00437813 loss)
I0813 19:36:02.119839 18283 sgd_solver.cpp:106] Iteration 46050, lr = 0.00274516
I0813 19:36:42.647866 18283 solver.cpp:337] Iteration 46100, Testing net (#0)
I0813 19:36:46.699394 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 19:36:46.699463 18283 solver.cpp:404]     Test net output #1: loss = 0.97905 (* 1 = 0.97905 loss)
I0813 19:36:47.513144 18283 solver.cpp:228] Iteration 46100, loss = -2.04709e-08
I0813 19:36:47.513197 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:36:47.513207 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:36:47.513224 18283 sgd_solver.cpp:106] Iteration 46100, lr = 0.00274333
I0813 19:37:28.628947 18283 solver.cpp:228] Iteration 46150, loss = 0.00917395
I0813 19:37:28.629104 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:37:28.629118 18283 solver.cpp:244]     Train net output #1: loss = 0.00917397 (* 1 = 0.00917397 loss)
I0813 19:37:28.629130 18283 sgd_solver.cpp:106] Iteration 46150, lr = 0.0027415
I0813 19:38:08.924479 18283 solver.cpp:337] Iteration 46200, Testing net (#0)
I0813 19:38:12.976963 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 19:38:12.977027 18283 solver.cpp:404]     Test net output #1: loss = 0.962989 (* 1 = 0.962989 loss)
I0813 19:38:13.790010 18283 solver.cpp:228] Iteration 46200, loss = 0.00825893
I0813 19:38:13.790073 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:38:13.790086 18283 solver.cpp:244]     Train net output #1: loss = 0.00825895 (* 1 = 0.00825895 loss)
I0813 19:38:13.790098 18283 sgd_solver.cpp:106] Iteration 46200, lr = 0.00273967
I0813 19:38:54.945147 18283 solver.cpp:228] Iteration 46250, loss = 0.0168591
I0813 19:38:54.945297 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:38:54.945312 18283 solver.cpp:244]     Train net output #1: loss = 0.0168591 (* 1 = 0.0168591 loss)
I0813 19:38:54.945323 18283 sgd_solver.cpp:106] Iteration 46250, lr = 0.00273784
I0813 19:39:35.307235 18283 solver.cpp:337] Iteration 46300, Testing net (#0)
I0813 19:39:39.367307 18283 solver.cpp:404]     Test net output #0: accuracy = 0.738
I0813 19:39:39.367386 18283 solver.cpp:404]     Test net output #1: loss = 0.958046 (* 1 = 0.958046 loss)
I0813 19:39:40.179574 18283 solver.cpp:228] Iteration 46300, loss = 0.0106799
I0813 19:39:40.179630 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:39:40.179643 18283 solver.cpp:244]     Train net output #1: loss = 0.0106799 (* 1 = 0.0106799 loss)
I0813 19:39:40.179658 18283 sgd_solver.cpp:106] Iteration 46300, lr = 0.00273602
I0813 19:40:21.311053 18283 solver.cpp:228] Iteration 46350, loss = 0.0203172
I0813 19:40:21.311202 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 19:40:21.311214 18283 solver.cpp:244]     Train net output #1: loss = 0.0203172 (* 1 = 0.0203172 loss)
I0813 19:40:21.311225 18283 sgd_solver.cpp:106] Iteration 46350, lr = 0.0027342
I0813 19:41:01.660889 18283 solver.cpp:337] Iteration 46400, Testing net (#0)
I0813 19:41:05.713853 18283 solver.cpp:404]     Test net output #0: accuracy = 0.72
I0813 19:41:05.713922 18283 solver.cpp:404]     Test net output #1: loss = 1.13803 (* 1 = 1.13803 loss)
I0813 19:41:06.525506 18283 solver.cpp:228] Iteration 46400, loss = 0.0231766
I0813 19:41:06.525565 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:41:06.525578 18283 solver.cpp:244]     Train net output #1: loss = 0.0231766 (* 1 = 0.0231766 loss)
I0813 19:41:06.525593 18283 sgd_solver.cpp:106] Iteration 46400, lr = 0.00273238
I0813 19:41:47.675560 18283 solver.cpp:228] Iteration 46450, loss = 0.0128199
I0813 19:41:47.675724 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:41:47.675737 18283 solver.cpp:244]     Train net output #1: loss = 0.0128199 (* 1 = 0.0128199 loss)
I0813 19:41:47.675748 18283 sgd_solver.cpp:106] Iteration 46450, lr = 0.00273056
I0813 19:42:27.988186 18283 solver.cpp:337] Iteration 46500, Testing net (#0)
I0813 19:42:32.039005 18283 solver.cpp:404]     Test net output #0: accuracy = 0.74
I0813 19:42:32.039067 18283 solver.cpp:404]     Test net output #1: loss = 1.0142 (* 1 = 1.0142 loss)
I0813 19:42:32.851752 18283 solver.cpp:228] Iteration 46500, loss = 0.00172629
I0813 19:42:32.851804 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:42:32.851815 18283 solver.cpp:244]     Train net output #1: loss = 0.00172632 (* 1 = 0.00172632 loss)
I0813 19:42:32.851845 18283 sgd_solver.cpp:106] Iteration 46500, lr = 0.00272875
I0813 19:43:13.989397 18283 solver.cpp:228] Iteration 46550, loss = 5.87857e-05
I0813 19:43:13.989548 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:43:13.989562 18283 solver.cpp:244]     Train net output #1: loss = 5.88113e-05 (* 1 = 5.88113e-05 loss)
I0813 19:43:13.989573 18283 sgd_solver.cpp:106] Iteration 46550, lr = 0.00272694
I0813 19:43:54.949344 18283 solver.cpp:337] Iteration 46600, Testing net (#0)
I0813 19:43:59.004268 18283 solver.cpp:404]     Test net output #0: accuracy = 0.742
I0813 19:43:59.004354 18283 solver.cpp:404]     Test net output #1: loss = 0.980273 (* 1 = 0.980273 loss)
I0813 19:43:59.816319 18283 solver.cpp:228] Iteration 46600, loss = -2.6077e-08
I0813 19:43:59.816380 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:43:59.816391 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:43:59.816407 18283 sgd_solver.cpp:106] Iteration 46600, lr = 0.00272513
I0813 19:44:40.962889 18283 solver.cpp:228] Iteration 46650, loss = 0.00353019
I0813 19:44:40.963048 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:44:40.963063 18283 solver.cpp:244]     Train net output #1: loss = 0.00353021 (* 1 = 0.00353021 loss)
I0813 19:44:40.963074 18283 sgd_solver.cpp:106] Iteration 46650, lr = 0.00272333
I0813 19:45:21.298576 18283 solver.cpp:337] Iteration 46700, Testing net (#0)
I0813 19:45:25.360508 18283 solver.cpp:404]     Test net output #0: accuracy = 0.735
I0813 19:45:25.360584 18283 solver.cpp:404]     Test net output #1: loss = 1.00802 (* 1 = 1.00802 loss)
I0813 19:45:26.172951 18283 solver.cpp:228] Iteration 46700, loss = 0.0146555
I0813 19:45:26.173012 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:45:26.173024 18283 solver.cpp:244]     Train net output #1: loss = 0.0146555 (* 1 = 0.0146555 loss)
I0813 19:45:26.173040 18283 sgd_solver.cpp:106] Iteration 46700, lr = 0.00272153
I0813 19:46:07.584730 18283 solver.cpp:228] Iteration 46750, loss = 0.00178935
I0813 19:46:07.584900 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:46:07.584915 18283 solver.cpp:244]     Train net output #1: loss = 0.00178937 (* 1 = 0.00178937 loss)
I0813 19:46:07.584928 18283 sgd_solver.cpp:106] Iteration 46750, lr = 0.00271973
I0813 19:46:47.942476 18283 solver.cpp:337] Iteration 46800, Testing net (#0)
I0813 19:46:52.015719 18283 solver.cpp:404]     Test net output #0: accuracy = 0.747
I0813 19:46:52.015784 18283 solver.cpp:404]     Test net output #1: loss = 0.95266 (* 1 = 0.95266 loss)
I0813 19:46:52.828538 18283 solver.cpp:228] Iteration 46800, loss = 0.00826679
I0813 19:46:52.828595 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:46:52.828608 18283 solver.cpp:244]     Train net output #1: loss = 0.00826681 (* 1 = 0.00826681 loss)
I0813 19:46:52.828627 18283 sgd_solver.cpp:106] Iteration 46800, lr = 0.00271793
I0813 19:47:34.026444 18283 solver.cpp:228] Iteration 46850, loss = -2.6077e-08
I0813 19:47:34.026638 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:47:34.026651 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:47:34.026662 18283 sgd_solver.cpp:106] Iteration 46850, lr = 0.00271614
I0813 19:48:14.350512 18283 solver.cpp:337] Iteration 46900, Testing net (#0)
I0813 19:48:18.595314 18283 solver.cpp:404]     Test net output #0: accuracy = 0.772
I0813 19:48:18.595379 18283 solver.cpp:404]     Test net output #1: loss = 0.857005 (* 1 = 0.857005 loss)
I0813 19:48:19.408131 18283 solver.cpp:228] Iteration 46900, loss = 0.00597989
I0813 19:48:19.408186 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:48:19.408198 18283 solver.cpp:244]     Train net output #1: loss = 0.00597992 (* 1 = 0.00597992 loss)
I0813 19:48:19.408216 18283 sgd_solver.cpp:106] Iteration 46900, lr = 0.00271435
I0813 19:49:00.548334 18283 solver.cpp:228] Iteration 46950, loss = 0.00353822
I0813 19:49:00.548470 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:49:00.548483 18283 solver.cpp:244]     Train net output #1: loss = 0.00353825 (* 1 = 0.00353825 loss)
I0813 19:49:00.548496 18283 sgd_solver.cpp:106] Iteration 46950, lr = 0.00271256
I0813 19:49:40.904048 18283 solver.cpp:337] Iteration 47000, Testing net (#0)
I0813 19:49:45.289772 18283 solver.cpp:404]     Test net output #0: accuracy = 0.732
I0813 19:49:45.289834 18283 solver.cpp:404]     Test net output #1: loss = 1.0036 (* 1 = 1.0036 loss)
I0813 19:49:46.102722 18283 solver.cpp:228] Iteration 47000, loss = 1.20429e-05
I0813 19:49:46.102782 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:49:46.102793 18283 solver.cpp:244]     Train net output #1: loss = 1.20747e-05 (* 1 = 1.20747e-05 loss)
I0813 19:49:46.102813 18283 sgd_solver.cpp:106] Iteration 47000, lr = 0.00271078
I0813 19:50:27.290479 18283 solver.cpp:228] Iteration 47050, loss = -3.1665e-08
I0813 19:50:27.290645 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:50:27.290658 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 19:50:27.290670 18283 sgd_solver.cpp:106] Iteration 47050, lr = 0.002709
I0813 19:51:07.621043 18283 solver.cpp:337] Iteration 47100, Testing net (#0)
I0813 19:51:11.893061 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 19:51:11.893129 18283 solver.cpp:404]     Test net output #1: loss = 0.977135 (* 1 = 0.977135 loss)
I0813 19:51:12.704918 18283 solver.cpp:228] Iteration 47100, loss = 0.00202051
I0813 19:51:12.704968 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:51:12.704979 18283 solver.cpp:244]     Train net output #1: loss = 0.00202054 (* 1 = 0.00202054 loss)
I0813 19:51:12.704991 18283 sgd_solver.cpp:106] Iteration 47100, lr = 0.00270722
I0813 19:51:53.849203 18283 solver.cpp:228] Iteration 47150, loss = 0.000244195
I0813 19:51:53.849362 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:51:53.849377 18283 solver.cpp:244]     Train net output #1: loss = 0.000244225 (* 1 = 0.000244225 loss)
I0813 19:51:53.849388 18283 sgd_solver.cpp:106] Iteration 47150, lr = 0.00270544
I0813 19:52:34.196470 18283 solver.cpp:337] Iteration 47200, Testing net (#0)
I0813 19:52:38.253032 18283 solver.cpp:404]     Test net output #0: accuracy = 0.747
I0813 19:52:38.253098 18283 solver.cpp:404]     Test net output #1: loss = 0.927921 (* 1 = 0.927921 loss)
I0813 19:52:39.064749 18283 solver.cpp:228] Iteration 47200, loss = 4.59589e-05
I0813 19:52:39.064805 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:52:39.064816 18283 solver.cpp:244]     Train net output #1: loss = 4.59892e-05 (* 1 = 4.59892e-05 loss)
I0813 19:52:39.064832 18283 sgd_solver.cpp:106] Iteration 47200, lr = 0.00270367
I0813 19:53:20.233495 18283 solver.cpp:228] Iteration 47250, loss = 0.0121052
I0813 19:53:20.233688 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:53:20.233703 18283 solver.cpp:244]     Train net output #1: loss = 0.0121052 (* 1 = 0.0121052 loss)
I0813 19:53:20.233714 18283 sgd_solver.cpp:106] Iteration 47250, lr = 0.00270189
I0813 19:54:00.606482 18283 solver.cpp:337] Iteration 47300, Testing net (#0)
I0813 19:54:04.651322 18283 solver.cpp:404]     Test net output #0: accuracy = 0.724
I0813 19:54:04.651383 18283 solver.cpp:404]     Test net output #1: loss = 1.07965 (* 1 = 1.07965 loss)
I0813 19:54:05.463461 18283 solver.cpp:228] Iteration 47300, loss = 0.04033
I0813 19:54:05.463510 18283 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 19:54:05.463521 18283 solver.cpp:244]     Train net output #1: loss = 0.04033 (* 1 = 0.04033 loss)
I0813 19:54:05.463532 18283 sgd_solver.cpp:106] Iteration 47300, lr = 0.00270013
I0813 19:54:46.626896 18283 solver.cpp:228] Iteration 47350, loss = 4.7646e-05
I0813 19:54:46.627053 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:54:46.627068 18283 solver.cpp:244]     Train net output #1: loss = 4.76742e-05 (* 1 = 4.76742e-05 loss)
I0813 19:54:46.627079 18283 sgd_solver.cpp:106] Iteration 47350, lr = 0.00269836
I0813 19:55:26.994731 18283 solver.cpp:337] Iteration 47400, Testing net (#0)
I0813 19:55:31.459651 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 19:55:31.459717 18283 solver.cpp:404]     Test net output #1: loss = 0.933906 (* 1 = 0.933906 loss)
I0813 19:55:32.272966 18283 solver.cpp:228] Iteration 47400, loss = 0.00212347
I0813 19:55:32.273031 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:55:32.273043 18283 solver.cpp:244]     Train net output #1: loss = 0.00212349 (* 1 = 0.00212349 loss)
I0813 19:55:32.273058 18283 sgd_solver.cpp:106] Iteration 47400, lr = 0.0026966
I0813 19:56:13.447499 18283 solver.cpp:228] Iteration 47450, loss = 0.00515603
I0813 19:56:13.447651 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:56:13.447665 18283 solver.cpp:244]     Train net output #1: loss = 0.00515606 (* 1 = 0.00515606 loss)
I0813 19:56:13.447679 18283 sgd_solver.cpp:106] Iteration 47450, lr = 0.00269484
I0813 19:56:53.818665 18283 solver.cpp:337] Iteration 47500, Testing net (#0)
I0813 19:56:58.225772 18283 solver.cpp:404]     Test net output #0: accuracy = 0.749
I0813 19:56:58.225839 18283 solver.cpp:404]     Test net output #1: loss = 0.987109 (* 1 = 0.987109 loss)
I0813 19:56:59.091161 18283 solver.cpp:228] Iteration 47500, loss = 0.00890339
I0813 19:56:59.091226 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:56:59.091238 18283 solver.cpp:244]     Train net output #1: loss = 0.00890341 (* 1 = 0.00890341 loss)
I0813 19:56:59.091253 18283 sgd_solver.cpp:106] Iteration 47500, lr = 0.00269308
I0813 19:57:40.390190 18283 solver.cpp:228] Iteration 47550, loss = 0.000700592
I0813 19:57:40.390352 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:57:40.390365 18283 solver.cpp:244]     Train net output #1: loss = 0.000700619 (* 1 = 0.000700619 loss)
I0813 19:57:40.390377 18283 sgd_solver.cpp:106] Iteration 47550, lr = 0.00269132
I0813 19:58:20.718967 18283 solver.cpp:337] Iteration 47600, Testing net (#0)
I0813 19:58:24.762090 18283 solver.cpp:404]     Test net output #0: accuracy = 0.731
I0813 19:58:24.762158 18283 solver.cpp:404]     Test net output #1: loss = 1.08365 (* 1 = 1.08365 loss)
I0813 19:58:25.574967 18283 solver.cpp:228] Iteration 47600, loss = 0.000442171
I0813 19:58:25.575037 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:58:25.575047 18283 solver.cpp:244]     Train net output #1: loss = 0.000442203 (* 1 = 0.000442203 loss)
I0813 19:58:25.575067 18283 sgd_solver.cpp:106] Iteration 47600, lr = 0.00268957
I0813 19:59:07.658771 18283 solver.cpp:228] Iteration 47650, loss = 0.000296985
I0813 19:59:07.658959 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:59:07.658973 18283 solver.cpp:244]     Train net output #1: loss = 0.000297016 (* 1 = 0.000297016 loss)
I0813 19:59:07.658987 18283 sgd_solver.cpp:106] Iteration 47650, lr = 0.00268782
I0813 19:59:48.006147 18283 solver.cpp:337] Iteration 47700, Testing net (#0)
I0813 19:59:52.294333 18283 solver.cpp:404]     Test net output #0: accuracy = 0.736
I0813 19:59:52.294401 18283 solver.cpp:404]     Test net output #1: loss = 1.03296 (* 1 = 1.03296 loss)
I0813 19:59:53.108345 18283 solver.cpp:228] Iteration 47700, loss = 0.0160326
I0813 19:59:53.108399 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 19:59:53.108410 18283 solver.cpp:244]     Train net output #1: loss = 0.0160326 (* 1 = 0.0160326 loss)
I0813 19:59:53.108428 18283 sgd_solver.cpp:106] Iteration 47700, lr = 0.00268607
I0813 20:00:34.287135 18283 solver.cpp:228] Iteration 47750, loss = 0.00878037
I0813 20:00:34.287299 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:00:34.287313 18283 solver.cpp:244]     Train net output #1: loss = 0.0087804 (* 1 = 0.0087804 loss)
I0813 20:00:34.287325 18283 sgd_solver.cpp:106] Iteration 47750, lr = 0.00268433
I0813 20:01:14.627750 18283 solver.cpp:337] Iteration 47800, Testing net (#0)
I0813 20:01:18.805470 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 20:01:18.805534 18283 solver.cpp:404]     Test net output #1: loss = 0.882657 (* 1 = 0.882657 loss)
I0813 20:01:19.619381 18283 solver.cpp:228] Iteration 47800, loss = 0.0177616
I0813 20:01:19.619443 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:01:19.619457 18283 solver.cpp:244]     Train net output #1: loss = 0.0177617 (* 1 = 0.0177617 loss)
I0813 20:01:19.619469 18283 sgd_solver.cpp:106] Iteration 47800, lr = 0.00268259
I0813 20:02:00.785585 18283 solver.cpp:228] Iteration 47850, loss = -2.98605e-08
I0813 20:02:00.785816 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:02:00.785862 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:02:00.785887 18283 sgd_solver.cpp:106] Iteration 47850, lr = 0.00268085
I0813 20:02:41.685284 18283 solver.cpp:337] Iteration 47900, Testing net (#0)
I0813 20:02:45.740892 18283 solver.cpp:404]     Test net output #0: accuracy = 0.773
I0813 20:02:45.740973 18283 solver.cpp:404]     Test net output #1: loss = 0.778289 (* 1 = 0.778289 loss)
I0813 20:02:46.552561 18283 solver.cpp:228] Iteration 47900, loss = 0.00534675
I0813 20:02:46.552615 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:02:46.552628 18283 solver.cpp:244]     Train net output #1: loss = 0.00534678 (* 1 = 0.00534678 loss)
I0813 20:02:46.552645 18283 sgd_solver.cpp:106] Iteration 47900, lr = 0.00267911
I0813 20:03:27.679322 18283 solver.cpp:228] Iteration 47950, loss = -3.35276e-08
I0813 20:03:27.679474 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:03:27.679487 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:03:27.679502 18283 sgd_solver.cpp:106] Iteration 47950, lr = 0.00267738
I0813 20:04:07.986971 18283 solver.cpp:337] Iteration 48000, Testing net (#0)
I0813 20:04:12.035071 18283 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0813 20:04:12.035137 18283 solver.cpp:404]     Test net output #1: loss = 0.813209 (* 1 = 0.813209 loss)
I0813 20:04:12.847700 18283 solver.cpp:228] Iteration 48000, loss = 0.00821041
I0813 20:04:12.847766 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:04:12.847779 18283 solver.cpp:244]     Train net output #1: loss = 0.00821045 (* 1 = 0.00821045 loss)
I0813 20:04:12.847792 18283 sgd_solver.cpp:106] Iteration 48000, lr = 0.00267565
I0813 20:04:53.978585 18283 solver.cpp:228] Iteration 48050, loss = 0.00369614
I0813 20:04:53.978754 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:04:53.978767 18283 solver.cpp:244]     Train net output #1: loss = 0.00369617 (* 1 = 0.00369617 loss)
I0813 20:04:53.978780 18283 sgd_solver.cpp:106] Iteration 48050, lr = 0.00267392
I0813 20:05:34.312005 18283 solver.cpp:337] Iteration 48100, Testing net (#0)
I0813 20:05:38.359431 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 20:05:38.359498 18283 solver.cpp:404]     Test net output #1: loss = 0.883605 (* 1 = 0.883605 loss)
I0813 20:05:39.171512 18283 solver.cpp:228] Iteration 48100, loss = 0.00758914
I0813 20:05:39.171566 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:05:39.171578 18283 solver.cpp:244]     Train net output #1: loss = 0.00758917 (* 1 = 0.00758917 loss)
I0813 20:05:39.171592 18283 sgd_solver.cpp:106] Iteration 48100, lr = 0.00267219
I0813 20:06:20.316099 18283 solver.cpp:228] Iteration 48150, loss = 0.00127635
I0813 20:06:20.316347 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:06:20.316426 18283 solver.cpp:244]     Train net output #1: loss = 0.00127639 (* 1 = 0.00127639 loss)
I0813 20:06:20.316460 18283 sgd_solver.cpp:106] Iteration 48150, lr = 0.00267047
I0813 20:07:01.388495 18283 solver.cpp:337] Iteration 48200, Testing net (#0)
I0813 20:07:05.437412 18283 solver.cpp:404]     Test net output #0: accuracy = 0.754
I0813 20:07:05.437489 18283 solver.cpp:404]     Test net output #1: loss = 0.901977 (* 1 = 0.901977 loss)
I0813 20:07:06.249447 18283 solver.cpp:228] Iteration 48200, loss = 0.00169519
I0813 20:07:06.249500 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:07:06.249511 18283 solver.cpp:244]     Train net output #1: loss = 0.00169522 (* 1 = 0.00169522 loss)
I0813 20:07:06.249523 18283 sgd_solver.cpp:106] Iteration 48200, lr = 0.00266875
I0813 20:07:47.886174 18283 solver.cpp:228] Iteration 48250, loss = 2.13217e-05
I0813 20:07:47.886401 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:07:47.886416 18283 solver.cpp:244]     Train net output #1: loss = 2.13516e-05 (* 1 = 2.13516e-05 loss)
I0813 20:07:47.886428 18283 sgd_solver.cpp:106] Iteration 48250, lr = 0.00266703
I0813 20:08:29.020516 18283 solver.cpp:337] Iteration 48300, Testing net (#0)
I0813 20:08:33.073627 18283 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0813 20:08:33.073693 18283 solver.cpp:404]     Test net output #1: loss = 0.876869 (* 1 = 0.876869 loss)
I0813 20:08:33.886577 18283 solver.cpp:228] Iteration 48300, loss = -2.70084e-08
I0813 20:08:33.886632 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:08:33.886643 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:08:33.886660 18283 sgd_solver.cpp:106] Iteration 48300, lr = 0.00266532
I0813 20:09:15.045230 18283 solver.cpp:228] Iteration 48350, loss = -2.79397e-08
I0813 20:09:15.045393 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:09:15.045406 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:09:15.045419 18283 sgd_solver.cpp:106] Iteration 48350, lr = 0.0026636
I0813 20:09:56.198868 18283 solver.cpp:337] Iteration 48400, Testing net (#0)
I0813 20:10:00.597288 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 20:10:00.597354 18283 solver.cpp:404]     Test net output #1: loss = 1.07451 (* 1 = 1.07451 loss)
I0813 20:10:01.599746 18283 solver.cpp:228] Iteration 48400, loss = 0.0138501
I0813 20:10:01.599814 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:10:01.599828 18283 solver.cpp:244]     Train net output #1: loss = 0.0138501 (* 1 = 0.0138501 loss)
I0813 20:10:01.599843 18283 sgd_solver.cpp:106] Iteration 48400, lr = 0.00266189
I0813 20:10:43.663015 18283 solver.cpp:228] Iteration 48450, loss = 0.00567756
I0813 20:10:43.663173 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:10:43.663187 18283 solver.cpp:244]     Train net output #1: loss = 0.00567759 (* 1 = 0.00567759 loss)
I0813 20:10:43.663202 18283 sgd_solver.cpp:106] Iteration 48450, lr = 0.00266018
I0813 20:11:24.003571 18283 solver.cpp:337] Iteration 48500, Testing net (#0)
I0813 20:11:28.065990 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 20:11:28.066061 18283 solver.cpp:404]     Test net output #1: loss = 0.911671 (* 1 = 0.911671 loss)
I0813 20:11:28.878413 18283 solver.cpp:228] Iteration 48500, loss = 0.00397062
I0813 20:11:28.878468 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:11:28.878479 18283 solver.cpp:244]     Train net output #1: loss = 0.00397065 (* 1 = 0.00397065 loss)
I0813 20:11:28.878495 18283 sgd_solver.cpp:106] Iteration 48500, lr = 0.00265848
I0813 20:12:10.764449 18283 solver.cpp:228] Iteration 48550, loss = 0.00371712
I0813 20:12:10.764616 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:12:10.764631 18283 solver.cpp:244]     Train net output #1: loss = 0.00371715 (* 1 = 0.00371715 loss)
I0813 20:12:10.764643 18283 sgd_solver.cpp:106] Iteration 48550, lr = 0.00265678
I0813 20:12:51.530658 18283 solver.cpp:337] Iteration 48600, Testing net (#0)
I0813 20:12:55.800932 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 20:12:55.801002 18283 solver.cpp:404]     Test net output #1: loss = 0.90438 (* 1 = 0.90438 loss)
I0813 20:12:56.612463 18283 solver.cpp:228] Iteration 48600, loss = 0.0150317
I0813 20:12:56.612517 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:12:56.612529 18283 solver.cpp:244]     Train net output #1: loss = 0.0150317 (* 1 = 0.0150317 loss)
I0813 20:12:56.612548 18283 sgd_solver.cpp:106] Iteration 48600, lr = 0.00265507
I0813 20:13:37.758868 18283 solver.cpp:228] Iteration 48650, loss = 0.00416648
I0813 20:13:37.759032 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:13:37.759047 18283 solver.cpp:244]     Train net output #1: loss = 0.00416652 (* 1 = 0.00416652 loss)
I0813 20:13:37.759062 18283 sgd_solver.cpp:106] Iteration 48650, lr = 0.00265338
I0813 20:14:18.136857 18283 solver.cpp:337] Iteration 48700, Testing net (#0)
I0813 20:14:22.189752 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 20:14:22.189817 18283 solver.cpp:404]     Test net output #1: loss = 0.917338 (* 1 = 0.917338 loss)
I0813 20:14:23.002586 18283 solver.cpp:228] Iteration 48700, loss = 0.0170127
I0813 20:14:23.002641 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:14:23.002653 18283 solver.cpp:244]     Train net output #1: loss = 0.0170128 (* 1 = 0.0170128 loss)
I0813 20:14:23.002671 18283 sgd_solver.cpp:106] Iteration 48700, lr = 0.00265168
I0813 20:15:04.191462 18283 solver.cpp:228] Iteration 48750, loss = -3.53903e-08
I0813 20:15:04.191611 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:15:04.191624 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:15:04.191635 18283 sgd_solver.cpp:106] Iteration 48750, lr = 0.00264999
I0813 20:15:44.564926 18283 solver.cpp:337] Iteration 48800, Testing net (#0)
I0813 20:15:48.619284 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 20:15:48.619352 18283 solver.cpp:404]     Test net output #1: loss = 0.955176 (* 1 = 0.955176 loss)
I0813 20:15:49.432399 18283 solver.cpp:228] Iteration 48800, loss = 0.00462887
I0813 20:15:49.432451 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:15:49.432461 18283 solver.cpp:244]     Train net output #1: loss = 0.00462891 (* 1 = 0.00462891 loss)
I0813 20:15:49.432473 18283 sgd_solver.cpp:106] Iteration 48800, lr = 0.0026483
I0813 20:16:30.643780 18283 solver.cpp:228] Iteration 48850, loss = 0.000331969
I0813 20:16:30.643929 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:16:30.643944 18283 solver.cpp:244]     Train net output #1: loss = 0.000332007 (* 1 = 0.000332007 loss)
I0813 20:16:30.643954 18283 sgd_solver.cpp:106] Iteration 48850, lr = 0.00264661
I0813 20:17:11.019547 18283 solver.cpp:337] Iteration 48900, Testing net (#0)
I0813 20:17:15.479521 18283 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0813 20:17:15.479590 18283 solver.cpp:404]     Test net output #1: loss = 0.995566 (* 1 = 0.995566 loss)
I0813 20:17:16.293105 18283 solver.cpp:228] Iteration 48900, loss = 0.000879181
I0813 20:17:16.293172 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:17:16.293185 18283 solver.cpp:244]     Train net output #1: loss = 0.000879222 (* 1 = 0.000879222 loss)
I0813 20:17:16.293200 18283 sgd_solver.cpp:106] Iteration 48900, lr = 0.00264493
I0813 20:17:57.886158 18283 solver.cpp:228] Iteration 48950, loss = 0.00030257
I0813 20:17:57.886351 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:17:57.886368 18283 solver.cpp:244]     Train net output #1: loss = 0.000302613 (* 1 = 0.000302613 loss)
I0813 20:17:57.886382 18283 sgd_solver.cpp:106] Iteration 48950, lr = 0.00264324
I0813 20:18:38.743749 18283 solver.cpp:337] Iteration 49000, Testing net (#0)
I0813 20:18:42.805825 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 20:18:42.805889 18283 solver.cpp:404]     Test net output #1: loss = 1.01656 (* 1 = 1.01656 loss)
I0813 20:18:43.619379 18283 solver.cpp:228] Iteration 49000, loss = 0.0308734
I0813 20:18:43.619436 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:18:43.619446 18283 solver.cpp:244]     Train net output #1: loss = 0.0308735 (* 1 = 0.0308735 loss)
I0813 20:18:43.619465 18283 sgd_solver.cpp:106] Iteration 49000, lr = 0.00264156
I0813 20:19:24.778724 18283 solver.cpp:228] Iteration 49050, loss = 0.00285952
I0813 20:19:24.778893 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:19:24.778908 18283 solver.cpp:244]     Train net output #1: loss = 0.00285956 (* 1 = 0.00285956 loss)
I0813 20:19:24.778920 18283 sgd_solver.cpp:106] Iteration 49050, lr = 0.00263989
I0813 20:20:05.127468 18283 solver.cpp:337] Iteration 49100, Testing net (#0)
I0813 20:20:09.199527 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 20:20:09.199595 18283 solver.cpp:404]     Test net output #1: loss = 1.01933 (* 1 = 1.01933 loss)
I0813 20:20:10.012641 18283 solver.cpp:228] Iteration 49100, loss = 0.0077351
I0813 20:20:10.012694 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:20:10.012706 18283 solver.cpp:244]     Train net output #1: loss = 0.00773514 (* 1 = 0.00773514 loss)
I0813 20:20:10.012718 18283 sgd_solver.cpp:106] Iteration 49100, lr = 0.00263821
I0813 20:20:51.149507 18283 solver.cpp:228] Iteration 49150, loss = 0.00295303
I0813 20:20:51.149739 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:20:51.149797 18283 solver.cpp:244]     Train net output #1: loss = 0.00295307 (* 1 = 0.00295307 loss)
I0813 20:20:51.149823 18283 sgd_solver.cpp:106] Iteration 49150, lr = 0.00263654
I0813 20:21:31.849814 18283 solver.cpp:337] Iteration 49200, Testing net (#0)
I0813 20:21:35.904325 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 20:21:35.904394 18283 solver.cpp:404]     Test net output #1: loss = 0.903806 (* 1 = 0.903806 loss)
I0813 20:21:36.716419 18283 solver.cpp:228] Iteration 49200, loss = 0.00397377
I0813 20:21:36.716472 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:21:36.716485 18283 solver.cpp:244]     Train net output #1: loss = 0.0039738 (* 1 = 0.0039738 loss)
I0813 20:21:36.716500 18283 sgd_solver.cpp:106] Iteration 49200, lr = 0.00263487
I0813 20:22:17.859534 18283 solver.cpp:228] Iteration 49250, loss = 0.0086069
I0813 20:22:17.859697 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:22:17.859711 18283 solver.cpp:244]     Train net output #1: loss = 0.00860693 (* 1 = 0.00860693 loss)
I0813 20:22:17.859722 18283 sgd_solver.cpp:106] Iteration 49250, lr = 0.0026332
I0813 20:22:58.166815 18283 solver.cpp:337] Iteration 49300, Testing net (#0)
I0813 20:23:02.222780 18283 solver.cpp:404]     Test net output #0: accuracy = 0.764
I0813 20:23:02.222846 18283 solver.cpp:404]     Test net output #1: loss = 0.879657 (* 1 = 0.879657 loss)
I0813 20:23:03.036047 18283 solver.cpp:228] Iteration 49300, loss = -3.14321e-08
I0813 20:23:03.036103 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:23:03.036113 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:23:03.036131 18283 sgd_solver.cpp:106] Iteration 49300, lr = 0.00263153
I0813 20:23:44.189805 18283 solver.cpp:228] Iteration 49350, loss = 0.00523047
I0813 20:23:44.190001 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:23:44.190016 18283 solver.cpp:244]     Train net output #1: loss = 0.0052305 (* 1 = 0.0052305 loss)
I0813 20:23:44.190026 18283 sgd_solver.cpp:106] Iteration 49350, lr = 0.00262987
I0813 20:24:24.531584 18283 solver.cpp:337] Iteration 49400, Testing net (#0)
I0813 20:24:28.924592 18283 solver.cpp:404]     Test net output #0: accuracy = 0.766
I0813 20:24:28.924657 18283 solver.cpp:404]     Test net output #1: loss = 0.857404 (* 1 = 0.857404 loss)
I0813 20:24:29.739274 18283 solver.cpp:228] Iteration 49400, loss = 0.00154754
I0813 20:24:29.739341 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:24:29.739352 18283 solver.cpp:244]     Train net output #1: loss = 0.00154757 (* 1 = 0.00154757 loss)
I0813 20:24:29.739367 18283 sgd_solver.cpp:106] Iteration 49400, lr = 0.00262821
I0813 20:25:10.910394 18283 solver.cpp:228] Iteration 49450, loss = 0.00201166
I0813 20:25:10.910555 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:25:10.910570 18283 solver.cpp:244]     Train net output #1: loss = 0.00201169 (* 1 = 0.00201169 loss)
I0813 20:25:10.910584 18283 sgd_solver.cpp:106] Iteration 49450, lr = 0.00262655
I0813 20:25:51.232395 18283 solver.cpp:337] Iteration 49500, Testing net (#0)
I0813 20:25:55.292502 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 20:25:55.292567 18283 solver.cpp:404]     Test net output #1: loss = 0.933438 (* 1 = 0.933438 loss)
I0813 20:25:56.105847 18283 solver.cpp:228] Iteration 49500, loss = 0.0107201
I0813 20:25:56.105902 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:25:56.105918 18283 solver.cpp:244]     Train net output #1: loss = 0.0107201 (* 1 = 0.0107201 loss)
I0813 20:25:56.105934 18283 sgd_solver.cpp:106] Iteration 49500, lr = 0.0026249
I0813 20:26:37.252725 18283 solver.cpp:228] Iteration 49550, loss = -2.79397e-08
I0813 20:26:37.252884 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:26:37.252897 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:26:37.252908 18283 sgd_solver.cpp:106] Iteration 49550, lr = 0.00262324
I0813 20:27:18.270521 18283 solver.cpp:337] Iteration 49600, Testing net (#0)
I0813 20:27:22.324578 18283 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0813 20:27:22.324645 18283 solver.cpp:404]     Test net output #1: loss = 0.967299 (* 1 = 0.967299 loss)
I0813 20:27:23.137845 18283 solver.cpp:228] Iteration 49600, loss = 0.0065047
I0813 20:27:23.137899 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:27:23.137912 18283 solver.cpp:244]     Train net output #1: loss = 0.00650472 (* 1 = 0.00650472 loss)
I0813 20:27:23.137923 18283 sgd_solver.cpp:106] Iteration 49600, lr = 0.00262159
I0813 20:28:04.315943 18283 solver.cpp:228] Iteration 49650, loss = 0.00271462
I0813 20:28:04.316180 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:28:04.316227 18283 solver.cpp:244]     Train net output #1: loss = 0.00271465 (* 1 = 0.00271465 loss)
I0813 20:28:04.316247 18283 sgd_solver.cpp:106] Iteration 49650, lr = 0.00261994
I0813 20:28:45.166441 18283 solver.cpp:337] Iteration 49700, Testing net (#0)
I0813 20:28:49.219446 18283 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0813 20:28:49.219514 18283 solver.cpp:404]     Test net output #1: loss = 1.02562 (* 1 = 1.02562 loss)
I0813 20:28:50.031018 18283 solver.cpp:228] Iteration 49700, loss = 0.0148812
I0813 20:28:50.031074 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:28:50.031085 18283 solver.cpp:244]     Train net output #1: loss = 0.0148812 (* 1 = 0.0148812 loss)
I0813 20:28:50.031100 18283 sgd_solver.cpp:106] Iteration 49700, lr = 0.0026183
I0813 20:29:31.163852 18283 solver.cpp:228] Iteration 49750, loss = 0.00412138
I0813 20:29:31.164057 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:29:31.164072 18283 solver.cpp:244]     Train net output #1: loss = 0.00412141 (* 1 = 0.00412141 loss)
I0813 20:29:31.164083 18283 sgd_solver.cpp:106] Iteration 49750, lr = 0.00261666
I0813 20:30:11.511463 18283 solver.cpp:337] Iteration 49800, Testing net (#0)
I0813 20:30:15.561136 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 20:30:15.561202 18283 solver.cpp:404]     Test net output #1: loss = 1.0609 (* 1 = 1.0609 loss)
I0813 20:30:16.373682 18283 solver.cpp:228] Iteration 49800, loss = 0.00650489
I0813 20:30:16.373735 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:30:16.373749 18283 solver.cpp:244]     Train net output #1: loss = 0.00650492 (* 1 = 0.00650492 loss)
I0813 20:30:16.373767 18283 sgd_solver.cpp:106] Iteration 49800, lr = 0.00261501
I0813 20:30:57.498178 18283 solver.cpp:228] Iteration 49850, loss = 0.000319361
I0813 20:30:57.498332 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:30:57.498345 18283 solver.cpp:244]     Train net output #1: loss = 0.000319389 (* 1 = 0.000319389 loss)
I0813 20:30:57.498359 18283 sgd_solver.cpp:106] Iteration 49850, lr = 0.00261338
I0813 20:31:37.845973 18283 solver.cpp:337] Iteration 49900, Testing net (#0)
I0813 20:31:41.902209 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 20:31:41.902277 18283 solver.cpp:404]     Test net output #1: loss = 0.909295 (* 1 = 0.909295 loss)
I0813 20:31:42.715170 18283 solver.cpp:228] Iteration 49900, loss = -2.98023e-08
I0813 20:31:42.715235 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:31:42.715246 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:31:42.715260 18283 sgd_solver.cpp:106] Iteration 49900, lr = 0.00261174
I0813 20:32:23.832232 18283 solver.cpp:228] Iteration 49950, loss = 0.00402504
I0813 20:32:23.832391 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:32:23.832406 18283 solver.cpp:244]     Train net output #1: loss = 0.00402507 (* 1 = 0.00402507 loss)
I0813 20:32:23.832417 18283 sgd_solver.cpp:106] Iteration 49950, lr = 0.00261011
I0813 20:33:04.156931 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_50000.caffemodel
I0813 20:33:04.487993 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_50000.solverstate
I0813 20:33:04.500823 18283 solver.cpp:337] Iteration 50000, Testing net (#0)
I0813 20:33:08.564713 18283 solver.cpp:404]     Test net output #0: accuracy = 0.729
I0813 20:33:08.564774 18283 solver.cpp:404]     Test net output #1: loss = 1.12502 (* 1 = 1.12502 loss)
I0813 20:33:09.377861 18283 solver.cpp:228] Iteration 50000, loss = 0.00489479
I0813 20:33:09.377912 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:33:09.377923 18283 solver.cpp:244]     Train net output #1: loss = 0.00489482 (* 1 = 0.00489482 loss)
I0813 20:33:09.377935 18283 sgd_solver.cpp:106] Iteration 50000, lr = 0.00260847
I0813 20:33:50.526824 18283 solver.cpp:228] Iteration 50050, loss = 0.0175171
I0813 20:33:50.526994 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:33:50.527007 18283 solver.cpp:244]     Train net output #1: loss = 0.0175172 (* 1 = 0.0175172 loss)
I0813 20:33:50.527019 18283 sgd_solver.cpp:106] Iteration 50050, lr = 0.00260685
I0813 20:34:30.889529 18283 solver.cpp:337] Iteration 50100, Testing net (#0)
I0813 20:34:34.951159 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 20:34:34.951227 18283 solver.cpp:404]     Test net output #1: loss = 0.879997 (* 1 = 0.879997 loss)
I0813 20:34:35.765926 18283 solver.cpp:228] Iteration 50100, loss = 0.00108693
I0813 20:34:35.765974 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:34:35.765985 18283 solver.cpp:244]     Train net output #1: loss = 0.00108697 (* 1 = 0.00108697 loss)
I0813 20:34:35.766002 18283 sgd_solver.cpp:106] Iteration 50100, lr = 0.00260522
I0813 20:35:16.924057 18283 solver.cpp:228] Iteration 50150, loss = -3.35276e-08
I0813 20:35:16.924242 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:35:16.924257 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:35:16.924268 18283 sgd_solver.cpp:106] Iteration 50150, lr = 0.00260359
I0813 20:35:57.262337 18283 solver.cpp:337] Iteration 50200, Testing net (#0)
I0813 20:36:01.326259 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 20:36:01.326330 18283 solver.cpp:404]     Test net output #1: loss = 0.930277 (* 1 = 0.930277 loss)
I0813 20:36:02.140542 18283 solver.cpp:228] Iteration 50200, loss = 9.5058e-05
I0813 20:36:02.140594 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:36:02.140605 18283 solver.cpp:244]     Train net output #1: loss = 9.50921e-05 (* 1 = 9.50921e-05 loss)
I0813 20:36:02.140617 18283 sgd_solver.cpp:106] Iteration 50200, lr = 0.00260197
I0813 20:36:43.307687 18283 solver.cpp:228] Iteration 50250, loss = 0.00193912
I0813 20:36:43.307838 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:36:43.307852 18283 solver.cpp:244]     Train net output #1: loss = 0.00193916 (* 1 = 0.00193916 loss)
I0813 20:36:43.307864 18283 sgd_solver.cpp:106] Iteration 50250, lr = 0.00260035
I0813 20:37:23.639402 18283 solver.cpp:337] Iteration 50300, Testing net (#0)
I0813 20:37:27.699184 18283 solver.cpp:404]     Test net output #0: accuracy = 0.761
I0813 20:37:27.699252 18283 solver.cpp:404]     Test net output #1: loss = 0.891379 (* 1 = 0.891379 loss)
I0813 20:37:28.512970 18283 solver.cpp:228] Iteration 50300, loss = 0.00902335
I0813 20:37:28.513025 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:37:28.513036 18283 solver.cpp:244]     Train net output #1: loss = 0.00902338 (* 1 = 0.00902338 loss)
I0813 20:37:28.513046 18283 sgd_solver.cpp:106] Iteration 50300, lr = 0.00259874
I0813 20:38:09.701851 18283 solver.cpp:228] Iteration 50350, loss = 0.000274889
I0813 20:38:09.702003 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:38:09.702016 18283 solver.cpp:244]     Train net output #1: loss = 0.000274923 (* 1 = 0.000274923 loss)
I0813 20:38:09.702028 18283 sgd_solver.cpp:106] Iteration 50350, lr = 0.00259712
I0813 20:38:50.067454 18283 solver.cpp:337] Iteration 50400, Testing net (#0)
I0813 20:38:54.124582 18283 solver.cpp:404]     Test net output #0: accuracy = 0.736
I0813 20:38:54.124649 18283 solver.cpp:404]     Test net output #1: loss = 1.01226 (* 1 = 1.01226 loss)
I0813 20:38:54.938271 18283 solver.cpp:228] Iteration 50400, loss = 0.00697706
I0813 20:38:54.938326 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:38:54.938338 18283 solver.cpp:244]     Train net output #1: loss = 0.0069771 (* 1 = 0.0069771 loss)
I0813 20:38:54.938359 18283 sgd_solver.cpp:106] Iteration 50400, lr = 0.00259551
I0813 20:39:36.092922 18283 solver.cpp:228] Iteration 50450, loss = 0.00324019
I0813 20:39:36.093080 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:39:36.093093 18283 solver.cpp:244]     Train net output #1: loss = 0.00324022 (* 1 = 0.00324022 loss)
I0813 20:39:36.093106 18283 sgd_solver.cpp:106] Iteration 50450, lr = 0.0025939
I0813 20:40:16.407526 18283 solver.cpp:337] Iteration 50500, Testing net (#0)
I0813 20:40:20.460976 18283 solver.cpp:404]     Test net output #0: accuracy = 0.765
I0813 20:40:20.461043 18283 solver.cpp:404]     Test net output #1: loss = 0.832022 (* 1 = 0.832022 loss)
I0813 20:40:21.273046 18283 solver.cpp:228] Iteration 50500, loss = -2.98023e-08
I0813 20:40:21.273097 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:40:21.273108 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:40:21.273124 18283 sgd_solver.cpp:106] Iteration 50500, lr = 0.00259229
I0813 20:41:02.435747 18283 solver.cpp:228] Iteration 50550, loss = -2.98023e-08
I0813 20:41:02.435904 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:41:02.435917 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:41:02.435930 18283 sgd_solver.cpp:106] Iteration 50550, lr = 0.00259068
I0813 20:41:42.795934 18283 solver.cpp:337] Iteration 50600, Testing net (#0)
I0813 20:41:47.163166 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 20:41:47.163234 18283 solver.cpp:404]     Test net output #1: loss = 0.950572 (* 1 = 0.950572 loss)
I0813 20:41:47.977787 18283 solver.cpp:228] Iteration 50600, loss = -2.6077e-08
I0813 20:41:47.977855 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:41:47.977869 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:41:47.977883 18283 sgd_solver.cpp:106] Iteration 50600, lr = 0.00258908
I0813 20:42:29.419950 18283 solver.cpp:228] Iteration 50650, loss = 0.0129082
I0813 20:42:29.420132 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:42:29.420150 18283 solver.cpp:244]     Train net output #1: loss = 0.0129083 (* 1 = 0.0129083 loss)
I0813 20:42:29.420164 18283 sgd_solver.cpp:106] Iteration 50650, lr = 0.00258748
I0813 20:43:09.804654 18283 solver.cpp:337] Iteration 50700, Testing net (#0)
I0813 20:43:13.862833 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 20:43:13.862915 18283 solver.cpp:404]     Test net output #1: loss = 0.944864 (* 1 = 0.944864 loss)
I0813 20:43:14.676677 18283 solver.cpp:228] Iteration 50700, loss = 0.0146039
I0813 20:43:14.676740 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:43:14.676751 18283 solver.cpp:244]     Train net output #1: loss = 0.0146039 (* 1 = 0.0146039 loss)
I0813 20:43:14.676764 18283 sgd_solver.cpp:106] Iteration 50700, lr = 0.00258588
I0813 20:43:55.853432 18283 solver.cpp:228] Iteration 50750, loss = 0.0013051
I0813 20:43:55.853668 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:43:55.853729 18283 solver.cpp:244]     Train net output #1: loss = 0.00130512 (* 1 = 0.00130512 loss)
I0813 20:43:55.853756 18283 sgd_solver.cpp:106] Iteration 50750, lr = 0.00258428
I0813 20:44:36.408310 18283 solver.cpp:337] Iteration 50800, Testing net (#0)
I0813 20:44:40.461395 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 20:44:40.461458 18283 solver.cpp:404]     Test net output #1: loss = 0.885177 (* 1 = 0.885177 loss)
I0813 20:44:41.273891 18283 solver.cpp:228] Iteration 50800, loss = -2.6077e-08
I0813 20:44:41.273944 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:44:41.273954 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:44:41.273972 18283 sgd_solver.cpp:106] Iteration 50800, lr = 0.00258269
I0813 20:45:22.419015 18283 solver.cpp:228] Iteration 50850, loss = 0.00687538
I0813 20:45:22.419173 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:45:22.419188 18283 solver.cpp:244]     Train net output #1: loss = 0.00687541 (* 1 = 0.00687541 loss)
I0813 20:45:22.419203 18283 sgd_solver.cpp:106] Iteration 50850, lr = 0.0025811
I0813 20:46:02.768545 18283 solver.cpp:337] Iteration 50900, Testing net (#0)
I0813 20:46:06.827723 18283 solver.cpp:404]     Test net output #0: accuracy = 0.732
I0813 20:46:06.827792 18283 solver.cpp:404]     Test net output #1: loss = 1.09565 (* 1 = 1.09565 loss)
I0813 20:46:07.641101 18283 solver.cpp:228] Iteration 50900, loss = 0.016787
I0813 20:46:07.641156 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:46:07.641168 18283 solver.cpp:244]     Train net output #1: loss = 0.0167871 (* 1 = 0.0167871 loss)
I0813 20:46:07.641183 18283 sgd_solver.cpp:106] Iteration 50900, lr = 0.00257951
I0813 20:46:48.812721 18283 solver.cpp:228] Iteration 50950, loss = 0.00320113
I0813 20:46:48.812881 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:46:48.812896 18283 solver.cpp:244]     Train net output #1: loss = 0.00320115 (* 1 = 0.00320115 loss)
I0813 20:46:48.812906 18283 sgd_solver.cpp:106] Iteration 50950, lr = 0.00257792
I0813 20:47:29.191231 18283 solver.cpp:337] Iteration 51000, Testing net (#0)
I0813 20:47:33.246374 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 20:47:33.246441 18283 solver.cpp:404]     Test net output #1: loss = 0.95735 (* 1 = 0.95735 loss)
I0813 20:47:34.059794 18283 solver.cpp:228] Iteration 51000, loss = 0.00242969
I0813 20:47:34.059852 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:47:34.059864 18283 solver.cpp:244]     Train net output #1: loss = 0.00242971 (* 1 = 0.00242971 loss)
I0813 20:47:34.059880 18283 sgd_solver.cpp:106] Iteration 51000, lr = 0.00257634
I0813 20:48:15.230692 18283 solver.cpp:228] Iteration 51050, loss = 5.32689e-05
I0813 20:48:15.230890 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:48:15.230903 18283 solver.cpp:244]     Train net output #1: loss = 5.32931e-05 (* 1 = 5.32931e-05 loss)
I0813 20:48:15.230914 18283 sgd_solver.cpp:106] Iteration 51050, lr = 0.00257475
I0813 20:48:55.582721 18283 solver.cpp:337] Iteration 51100, Testing net (#0)
I0813 20:48:59.643442 18283 solver.cpp:404]     Test net output #0: accuracy = 0.775
I0813 20:48:59.643512 18283 solver.cpp:404]     Test net output #1: loss = 0.762774 (* 1 = 0.762774 loss)
I0813 20:49:00.455874 18283 solver.cpp:228] Iteration 51100, loss = 0.0135709
I0813 20:49:00.455938 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:49:00.455950 18283 solver.cpp:244]     Train net output #1: loss = 0.013571 (* 1 = 0.013571 loss)
I0813 20:49:00.455963 18283 sgd_solver.cpp:106] Iteration 51100, lr = 0.00257317
I0813 20:49:41.616657 18283 solver.cpp:228] Iteration 51150, loss = -2.14204e-08
I0813 20:49:41.616816 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:49:41.616828 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:49:41.616839 18283 sgd_solver.cpp:106] Iteration 51150, lr = 0.0025716
I0813 20:50:21.978255 18283 solver.cpp:337] Iteration 51200, Testing net (#0)
I0813 20:50:26.030071 18283 solver.cpp:404]     Test net output #0: accuracy = 0.765
I0813 20:50:26.030134 18283 solver.cpp:404]     Test net output #1: loss = 0.833763 (* 1 = 0.833763 loss)
I0813 20:50:26.842444 18283 solver.cpp:228] Iteration 51200, loss = 0.00176474
I0813 20:50:26.842506 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:50:26.842519 18283 solver.cpp:244]     Train net output #1: loss = 0.00176476 (* 1 = 0.00176476 loss)
I0813 20:50:26.842533 18283 sgd_solver.cpp:106] Iteration 51200, lr = 0.00257002
I0813 20:51:07.990427 18283 solver.cpp:228] Iteration 51250, loss = -2.23081e-08
I0813 20:51:07.990666 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:51:07.990715 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 20:51:07.990770 18283 sgd_solver.cpp:106] Iteration 51250, lr = 0.00256845
I0813 20:51:48.964624 18283 solver.cpp:337] Iteration 51300, Testing net (#0)
I0813 20:51:53.012691 18283 solver.cpp:404]     Test net output #0: accuracy = 0.768
I0813 20:51:53.012770 18283 solver.cpp:404]     Test net output #1: loss = 0.825744 (* 1 = 0.825744 loss)
I0813 20:51:53.826202 18283 solver.cpp:228] Iteration 51300, loss = 0.000548797
I0813 20:51:53.826254 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:51:53.826267 18283 solver.cpp:244]     Train net output #1: loss = 0.000548819 (* 1 = 0.000548819 loss)
I0813 20:51:53.826283 18283 sgd_solver.cpp:106] Iteration 51300, lr = 0.00256687
I0813 20:52:35.001413 18283 solver.cpp:228] Iteration 51350, loss = 0.00951554
I0813 20:52:35.001575 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:52:35.001590 18283 solver.cpp:244]     Train net output #1: loss = 0.00951556 (* 1 = 0.00951556 loss)
I0813 20:52:35.001601 18283 sgd_solver.cpp:106] Iteration 51350, lr = 0.00256531
I0813 20:53:15.838565 18283 solver.cpp:337] Iteration 51400, Testing net (#0)
I0813 20:53:19.889495 18283 solver.cpp:404]     Test net output #0: accuracy = 0.741
I0813 20:53:19.889569 18283 solver.cpp:404]     Test net output #1: loss = 0.912907 (* 1 = 0.912907 loss)
I0813 20:53:20.702919 18283 solver.cpp:228] Iteration 51400, loss = 0.0200033
I0813 20:53:20.702975 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:53:20.702987 18283 solver.cpp:244]     Train net output #1: loss = 0.0200034 (* 1 = 0.0200034 loss)
I0813 20:53:20.703004 18283 sgd_solver.cpp:106] Iteration 51400, lr = 0.00256374
I0813 20:54:01.863234 18283 solver.cpp:228] Iteration 51450, loss = 0.000604615
I0813 20:54:01.863435 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:54:01.863450 18283 solver.cpp:244]     Train net output #1: loss = 0.000604637 (* 1 = 0.000604637 loss)
I0813 20:54:01.863462 18283 sgd_solver.cpp:106] Iteration 51450, lr = 0.00256217
I0813 20:54:42.223104 18283 solver.cpp:337] Iteration 51500, Testing net (#0)
I0813 20:54:46.285550 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 20:54:46.285619 18283 solver.cpp:404]     Test net output #1: loss = 0.982928 (* 1 = 0.982928 loss)
I0813 20:54:47.098562 18283 solver.cpp:228] Iteration 51500, loss = 0.0100252
I0813 20:54:47.098629 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:54:47.098641 18283 solver.cpp:244]     Train net output #1: loss = 0.0100252 (* 1 = 0.0100252 loss)
I0813 20:54:47.098660 18283 sgd_solver.cpp:106] Iteration 51500, lr = 0.00256061
I0813 20:55:28.282554 18283 solver.cpp:228] Iteration 51550, loss = 0.00291161
I0813 20:55:28.282702 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:55:28.282716 18283 solver.cpp:244]     Train net output #1: loss = 0.00291163 (* 1 = 0.00291163 loss)
I0813 20:55:28.282727 18283 sgd_solver.cpp:106] Iteration 51550, lr = 0.00255905
I0813 20:56:08.609614 18283 solver.cpp:337] Iteration 51600, Testing net (#0)
I0813 20:56:12.672700 18283 solver.cpp:404]     Test net output #0: accuracy = 0.73
I0813 20:56:12.672770 18283 solver.cpp:404]     Test net output #1: loss = 1.00787 (* 1 = 1.00787 loss)
I0813 20:56:13.485841 18283 solver.cpp:228] Iteration 51600, loss = 0.00231426
I0813 20:56:13.485894 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:56:13.485906 18283 solver.cpp:244]     Train net output #1: loss = 0.00231428 (* 1 = 0.00231428 loss)
I0813 20:56:13.485921 18283 sgd_solver.cpp:106] Iteration 51600, lr = 0.00255749
I0813 20:56:54.723479 18283 solver.cpp:228] Iteration 51650, loss = 0.00655826
I0813 20:56:54.723667 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:56:54.723724 18283 solver.cpp:244]     Train net output #1: loss = 0.00655828 (* 1 = 0.00655828 loss)
I0813 20:56:54.723748 18283 sgd_solver.cpp:106] Iteration 51650, lr = 0.00255594
I0813 20:57:35.272069 18283 solver.cpp:337] Iteration 51700, Testing net (#0)
I0813 20:57:39.324179 18283 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0813 20:57:39.324245 18283 solver.cpp:404]     Test net output #1: loss = 0.846989 (* 1 = 0.846989 loss)
I0813 20:57:40.136596 18283 solver.cpp:228] Iteration 51700, loss = 0.0002137
I0813 20:57:40.136648 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:57:40.136660 18283 solver.cpp:244]     Train net output #1: loss = 0.000213718 (* 1 = 0.000213718 loss)
I0813 20:57:40.136677 18283 sgd_solver.cpp:106] Iteration 51700, lr = 0.00255438
I0813 20:58:21.265082 18283 solver.cpp:228] Iteration 51750, loss = 0.00383108
I0813 20:58:21.265295 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:58:21.265349 18283 solver.cpp:244]     Train net output #1: loss = 0.0038311 (* 1 = 0.0038311 loss)
I0813 20:58:21.265372 18283 sgd_solver.cpp:106] Iteration 51750, lr = 0.00255283
I0813 20:59:01.947684 18283 solver.cpp:337] Iteration 51800, Testing net (#0)
I0813 20:59:06.116964 18283 solver.cpp:404]     Test net output #0: accuracy = 0.759
I0813 20:59:06.117032 18283 solver.cpp:404]     Test net output #1: loss = 0.886895 (* 1 = 0.886895 loss)
I0813 20:59:06.930516 18283 solver.cpp:228] Iteration 51800, loss = 0.0108138
I0813 20:59:06.930577 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:59:06.930588 18283 solver.cpp:244]     Train net output #1: loss = 0.0108138 (* 1 = 0.0108138 loss)
I0813 20:59:06.930603 18283 sgd_solver.cpp:106] Iteration 51800, lr = 0.00255128
I0813 20:59:48.196003 18283 solver.cpp:228] Iteration 51850, loss = 0.0100048
I0813 20:59:48.196218 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 20:59:48.196233 18283 solver.cpp:244]     Train net output #1: loss = 0.0100049 (* 1 = 0.0100049 loss)
I0813 20:59:48.196244 18283 sgd_solver.cpp:106] Iteration 51850, lr = 0.00254974
I0813 21:00:28.658223 18283 solver.cpp:337] Iteration 51900, Testing net (#0)
I0813 21:00:32.736107 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 21:00:32.736171 18283 solver.cpp:404]     Test net output #1: loss = 0.960805 (* 1 = 0.960805 loss)
I0813 21:00:33.552896 18283 solver.cpp:228] Iteration 51900, loss = 0.00752445
I0813 21:00:33.552954 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:00:33.552966 18283 solver.cpp:244]     Train net output #1: loss = 0.00752447 (* 1 = 0.00752447 loss)
I0813 21:00:33.552984 18283 sgd_solver.cpp:106] Iteration 51900, lr = 0.00254819
I0813 21:01:14.790138 18283 solver.cpp:228] Iteration 51950, loss = 0.00789774
I0813 21:01:14.790289 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:01:14.790304 18283 solver.cpp:244]     Train net output #1: loss = 0.00789776 (* 1 = 0.00789776 loss)
I0813 21:01:14.790318 18283 sgd_solver.cpp:106] Iteration 51950, lr = 0.00254665
I0813 21:01:55.478704 18283 solver.cpp:337] Iteration 52000, Testing net (#0)
I0813 21:01:59.529167 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 21:01:59.529233 18283 solver.cpp:404]     Test net output #1: loss = 0.870772 (* 1 = 0.870772 loss)
I0813 21:02:00.342530 18283 solver.cpp:228] Iteration 52000, loss = 0.00820096
I0813 21:02:00.342589 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:02:00.342602 18283 solver.cpp:244]     Train net output #1: loss = 0.00820098 (* 1 = 0.00820098 loss)
I0813 21:02:00.342615 18283 sgd_solver.cpp:106] Iteration 52000, lr = 0.00254511
I0813 21:02:41.481376 18283 solver.cpp:228] Iteration 52050, loss = -1.93249e-08
I0813 21:02:41.481539 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:02:41.481554 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:02:41.481565 18283 sgd_solver.cpp:106] Iteration 52050, lr = 0.00254357
I0813 21:03:21.838457 18283 solver.cpp:337] Iteration 52100, Testing net (#0)
I0813 21:03:25.902196 18283 solver.cpp:404]     Test net output #0: accuracy = 0.738
I0813 21:03:25.902266 18283 solver.cpp:404]     Test net output #1: loss = 0.976939 (* 1 = 0.976939 loss)
I0813 21:03:26.715735 18283 solver.cpp:228] Iteration 52100, loss = 0.00117369
I0813 21:03:26.715787 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:03:26.715800 18283 solver.cpp:244]     Train net output #1: loss = 0.00117371 (* 1 = 0.00117371 loss)
I0813 21:03:26.715811 18283 sgd_solver.cpp:106] Iteration 52100, lr = 0.00254203
I0813 21:04:07.848072 18283 solver.cpp:228] Iteration 52150, loss = 0.00789833
I0813 21:04:07.848223 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:04:07.848237 18283 solver.cpp:244]     Train net output #1: loss = 0.00789835 (* 1 = 0.00789835 loss)
I0813 21:04:07.848249 18283 sgd_solver.cpp:106] Iteration 52150, lr = 0.0025405
I0813 21:04:48.198292 18283 solver.cpp:337] Iteration 52200, Testing net (#0)
I0813 21:04:52.565441 18283 solver.cpp:404]     Test net output #0: accuracy = 0.748
I0813 21:04:52.565524 18283 solver.cpp:404]     Test net output #1: loss = 0.994652 (* 1 = 0.994652 loss)
I0813 21:04:53.379132 18283 solver.cpp:228] Iteration 52200, loss = 0.000669567
I0813 21:04:53.379202 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:04:53.379215 18283 solver.cpp:244]     Train net output #1: loss = 0.000669584 (* 1 = 0.000669584 loss)
I0813 21:04:53.379231 18283 sgd_solver.cpp:106] Iteration 52200, lr = 0.00253897
I0813 21:05:34.563918 18283 solver.cpp:228] Iteration 52250, loss = -1.67638e-08
I0813 21:05:34.564080 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:05:34.564095 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:05:34.564106 18283 sgd_solver.cpp:106] Iteration 52250, lr = 0.00253744
I0813 21:06:15.539014 18283 solver.cpp:337] Iteration 52300, Testing net (#0)
I0813 21:06:19.604756 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 21:06:19.604838 18283 solver.cpp:404]     Test net output #1: loss = 0.883133 (* 1 = 0.883133 loss)
I0813 21:06:20.418923 18283 solver.cpp:228] Iteration 52300, loss = 0.000924832
I0813 21:06:20.418992 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:06:20.419003 18283 solver.cpp:244]     Train net output #1: loss = 0.00092485 (* 1 = 0.00092485 loss)
I0813 21:06:20.419021 18283 sgd_solver.cpp:106] Iteration 52300, lr = 0.00253591
I0813 21:07:01.661994 18283 solver.cpp:228] Iteration 52350, loss = -1.66474e-08
I0813 21:07:01.662161 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:07:01.662175 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:07:01.662187 18283 sgd_solver.cpp:106] Iteration 52350, lr = 0.00253439
I0813 21:07:42.052837 18283 solver.cpp:337] Iteration 52400, Testing net (#0)
I0813 21:07:46.111577 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 21:07:46.111646 18283 solver.cpp:404]     Test net output #1: loss = 0.881823 (* 1 = 0.881823 loss)
I0813 21:07:46.925016 18283 solver.cpp:228] Iteration 52400, loss = 0.0203926
I0813 21:07:46.925084 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:07:46.925096 18283 solver.cpp:244]     Train net output #1: loss = 0.0203926 (* 1 = 0.0203926 loss)
I0813 21:07:46.925108 18283 sgd_solver.cpp:106] Iteration 52400, lr = 0.00253286
I0813 21:08:28.111438 18283 solver.cpp:228] Iteration 52450, loss = 0.0112755
I0813 21:08:28.111668 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:08:28.111721 18283 solver.cpp:244]     Train net output #1: loss = 0.0112755 (* 1 = 0.0112755 loss)
I0813 21:08:28.111740 18283 sgd_solver.cpp:106] Iteration 52450, lr = 0.00253134
I0813 21:09:09.311915 18283 solver.cpp:337] Iteration 52500, Testing net (#0)
I0813 21:09:13.382505 18283 solver.cpp:404]     Test net output #0: accuracy = 0.767
I0813 21:09:13.382575 18283 solver.cpp:404]     Test net output #1: loss = 0.899944 (* 1 = 0.899944 loss)
I0813 21:09:14.199223 18283 solver.cpp:228] Iteration 52500, loss = 0.0011631
I0813 21:09:14.199282 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:09:14.199293 18283 solver.cpp:244]     Train net output #1: loss = 0.00116311 (* 1 = 0.00116311 loss)
I0813 21:09:14.199311 18283 sgd_solver.cpp:106] Iteration 52500, lr = 0.00252982
I0813 21:09:55.487992 18283 solver.cpp:228] Iteration 52550, loss = 0.00466543
I0813 21:09:55.488147 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:09:55.488162 18283 solver.cpp:244]     Train net output #1: loss = 0.00466545 (* 1 = 0.00466545 loss)
I0813 21:09:55.488176 18283 sgd_solver.cpp:106] Iteration 52550, lr = 0.00252831
I0813 21:10:35.917325 18283 solver.cpp:337] Iteration 52600, Testing net (#0)
I0813 21:10:40.123579 18283 solver.cpp:404]     Test net output #0: accuracy = 0.725
I0813 21:10:40.123646 18283 solver.cpp:404]     Test net output #1: loss = 1.02408 (* 1 = 1.02408 loss)
I0813 21:10:40.936570 18283 solver.cpp:228] Iteration 52600, loss = 0.00719303
I0813 21:10:40.936633 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:10:40.936645 18283 solver.cpp:244]     Train net output #1: loss = 0.00719305 (* 1 = 0.00719305 loss)
I0813 21:10:40.936660 18283 sgd_solver.cpp:106] Iteration 52600, lr = 0.00252679
I0813 21:11:22.670603 18283 solver.cpp:228] Iteration 52650, loss = 0.00218748
I0813 21:11:22.670821 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:11:22.670897 18283 solver.cpp:244]     Train net output #1: loss = 0.00218749 (* 1 = 0.00218749 loss)
I0813 21:11:22.670943 18283 sgd_solver.cpp:106] Iteration 52650, lr = 0.00252528
I0813 21:12:03.119307 18283 solver.cpp:337] Iteration 52700, Testing net (#0)
I0813 21:12:07.174655 18283 solver.cpp:404]     Test net output #0: accuracy = 0.723
I0813 21:12:07.174721 18283 solver.cpp:404]     Test net output #1: loss = 1.02234 (* 1 = 1.02234 loss)
I0813 21:12:07.987632 18283 solver.cpp:228] Iteration 52700, loss = 0.0235303
I0813 21:12:07.987685 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:12:07.987696 18283 solver.cpp:244]     Train net output #1: loss = 0.0235304 (* 1 = 0.0235304 loss)
I0813 21:12:07.987709 18283 sgd_solver.cpp:106] Iteration 52700, lr = 0.00252377
I0813 21:12:49.207070 18283 solver.cpp:228] Iteration 52750, loss = 0.000357725
I0813 21:12:49.207237 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:12:49.207252 18283 solver.cpp:244]     Train net output #1: loss = 0.000357738 (* 1 = 0.000357738 loss)
I0813 21:12:49.207264 18283 sgd_solver.cpp:106] Iteration 52750, lr = 0.00252226
I0813 21:13:29.598249 18283 solver.cpp:337] Iteration 52800, Testing net (#0)
I0813 21:13:33.817513 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 21:13:33.817579 18283 solver.cpp:404]     Test net output #1: loss = 0.91263 (* 1 = 0.91263 loss)
I0813 21:13:34.631470 18283 solver.cpp:228] Iteration 52800, loss = 0.00684682
I0813 21:13:34.631539 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:13:34.631551 18283 solver.cpp:244]     Train net output #1: loss = 0.00684683 (* 1 = 0.00684683 loss)
I0813 21:13:34.631566 18283 sgd_solver.cpp:106] Iteration 52800, lr = 0.00252075
I0813 21:14:15.832844 18283 solver.cpp:228] Iteration 52850, loss = 0.00315655
I0813 21:14:15.833003 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:14:15.833017 18283 solver.cpp:244]     Train net output #1: loss = 0.00315656 (* 1 = 0.00315656 loss)
I0813 21:14:15.833029 18283 sgd_solver.cpp:106] Iteration 52850, lr = 0.00251925
I0813 21:14:56.551718 18283 solver.cpp:337] Iteration 52900, Testing net (#0)
I0813 21:15:00.614020 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 21:15:00.614100 18283 solver.cpp:404]     Test net output #1: loss = 0.888414 (* 1 = 0.888414 loss)
I0813 21:15:01.427597 18283 solver.cpp:228] Iteration 52900, loss = 0.00844656
I0813 21:15:01.427659 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:15:01.427670 18283 solver.cpp:244]     Train net output #1: loss = 0.00844657 (* 1 = 0.00844657 loss)
I0813 21:15:01.427685 18283 sgd_solver.cpp:106] Iteration 52900, lr = 0.00251775
I0813 21:15:43.639375 18283 solver.cpp:228] Iteration 52950, loss = -1.0943e-08
I0813 21:15:43.639529 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:15:43.639542 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:15:43.639554 18283 sgd_solver.cpp:106] Iteration 52950, lr = 0.00251625
I0813 21:16:24.002722 18283 solver.cpp:337] Iteration 53000, Testing net (#0)
I0813 21:16:28.292296 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 21:16:28.292362 18283 solver.cpp:404]     Test net output #1: loss = 0.933788 (* 1 = 0.933788 loss)
I0813 21:16:29.106875 18283 solver.cpp:228] Iteration 53000, loss = 0.0039257
I0813 21:16:29.106943 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:16:29.106967 18283 solver.cpp:244]     Train net output #1: loss = 0.00392571 (* 1 = 0.00392571 loss)
I0813 21:16:29.106982 18283 sgd_solver.cpp:106] Iteration 53000, lr = 0.00251475
I0813 21:17:10.748769 18283 solver.cpp:228] Iteration 53050, loss = 0.00421016
I0813 21:17:10.748929 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:17:10.748942 18283 solver.cpp:244]     Train net output #1: loss = 0.00421017 (* 1 = 0.00421017 loss)
I0813 21:17:10.748956 18283 sgd_solver.cpp:106] Iteration 53050, lr = 0.00251325
I0813 21:17:51.492961 18283 solver.cpp:337] Iteration 53100, Testing net (#0)
I0813 21:17:55.749565 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 21:17:55.749647 18283 solver.cpp:404]     Test net output #1: loss = 0.877817 (* 1 = 0.877817 loss)
I0813 21:17:56.563237 18283 solver.cpp:228] Iteration 53100, loss = -7.45058e-09
I0813 21:17:56.563302 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:17:56.563313 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:17:56.563326 18283 sgd_solver.cpp:106] Iteration 53100, lr = 0.00251176
I0813 21:18:37.719147 18283 solver.cpp:228] Iteration 53150, loss = 0.0140769
I0813 21:18:37.719346 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:18:37.719360 18283 solver.cpp:244]     Train net output #1: loss = 0.0140769 (* 1 = 0.0140769 loss)
I0813 21:18:37.719372 18283 sgd_solver.cpp:106] Iteration 53150, lr = 0.00251027
I0813 21:19:18.078708 18283 solver.cpp:337] Iteration 53200, Testing net (#0)
I0813 21:19:22.137784 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 21:19:22.137850 18283 solver.cpp:404]     Test net output #1: loss = 1.0106 (* 1 = 1.0106 loss)
I0813 21:19:22.951074 18283 solver.cpp:228] Iteration 53200, loss = 0.0263812
I0813 21:19:22.951135 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:19:22.951148 18283 solver.cpp:244]     Train net output #1: loss = 0.0263812 (* 1 = 0.0263812 loss)
I0813 21:19:22.951162 18283 sgd_solver.cpp:106] Iteration 53200, lr = 0.00250878
I0813 21:20:04.117799 18283 solver.cpp:228] Iteration 53250, loss = 0.000206317
I0813 21:20:04.117962 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:20:04.117976 18283 solver.cpp:244]     Train net output #1: loss = 0.000206326 (* 1 = 0.000206326 loss)
I0813 21:20:04.117988 18283 sgd_solver.cpp:106] Iteration 53250, lr = 0.00250729
I0813 21:20:44.471601 18283 solver.cpp:337] Iteration 53300, Testing net (#0)
I0813 21:20:48.814424 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 21:20:48.814488 18283 solver.cpp:404]     Test net output #1: loss = 0.867536 (* 1 = 0.867536 loss)
I0813 21:20:49.628516 18283 solver.cpp:228] Iteration 53300, loss = -1.02445e-08
I0813 21:20:49.628585 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:20:49.628597 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:20:49.628610 18283 sgd_solver.cpp:106] Iteration 53300, lr = 0.0025058
I0813 21:21:30.822197 18283 solver.cpp:228] Iteration 53350, loss = -1.0943e-08
I0813 21:21:30.822370 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:21:30.822383 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:21:30.822396 18283 sgd_solver.cpp:106] Iteration 53350, lr = 0.00250432
I0813 21:22:11.205924 18283 solver.cpp:337] Iteration 53400, Testing net (#0)
I0813 21:22:15.269706 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 21:22:15.269784 18283 solver.cpp:404]     Test net output #1: loss = 0.865739 (* 1 = 0.865739 loss)
I0813 21:22:16.082590 18283 solver.cpp:228] Iteration 53400, loss = 0.0037077
I0813 21:22:16.082648 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:22:16.082659 18283 solver.cpp:244]     Train net output #1: loss = 0.00370771 (* 1 = 0.00370771 loss)
I0813 21:22:16.082677 18283 sgd_solver.cpp:106] Iteration 53400, lr = 0.00250284
I0813 21:22:57.270697 18283 solver.cpp:228] Iteration 53450, loss = 0.0163708
I0813 21:22:57.270853 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:22:57.270865 18283 solver.cpp:244]     Train net output #1: loss = 0.0163708 (* 1 = 0.0163708 loss)
I0813 21:22:57.270887 18283 sgd_solver.cpp:106] Iteration 53450, lr = 0.00250136
I0813 21:23:37.979321 18283 solver.cpp:337] Iteration 53500, Testing net (#0)
I0813 21:23:42.041069 18283 solver.cpp:404]     Test net output #0: accuracy = 0.738
I0813 21:23:42.041137 18283 solver.cpp:404]     Test net output #1: loss = 0.962341 (* 1 = 0.962341 loss)
I0813 21:23:42.855106 18283 solver.cpp:228] Iteration 53500, loss = 0.000334572
I0813 21:23:42.855162 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:23:42.855173 18283 solver.cpp:244]     Train net output #1: loss = 0.000334584 (* 1 = 0.000334584 loss)
I0813 21:23:42.855192 18283 sgd_solver.cpp:106] Iteration 53500, lr = 0.00249988
I0813 21:24:24.460558 18283 solver.cpp:228] Iteration 53550, loss = 0.00773901
I0813 21:24:24.460746 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:24:24.460759 18283 solver.cpp:244]     Train net output #1: loss = 0.00773902 (* 1 = 0.00773902 loss)
I0813 21:24:24.460785 18283 sgd_solver.cpp:106] Iteration 53550, lr = 0.00249841
I0813 21:25:04.834712 18283 solver.cpp:337] Iteration 53600, Testing net (#0)
I0813 21:25:08.896597 18283 solver.cpp:404]     Test net output #0: accuracy = 0.748
I0813 21:25:08.896677 18283 solver.cpp:404]     Test net output #1: loss = 0.899074 (* 1 = 0.899074 loss)
I0813 21:25:09.710783 18283 solver.cpp:228] Iteration 53600, loss = 0.00795034
I0813 21:25:09.710837 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:25:09.710853 18283 solver.cpp:244]     Train net output #1: loss = 0.00795035 (* 1 = 0.00795035 loss)
I0813 21:25:09.710868 18283 sgd_solver.cpp:106] Iteration 53600, lr = 0.00249693
I0813 21:25:52.647058 18283 solver.cpp:228] Iteration 53650, loss = 0.00141765
I0813 21:25:52.647218 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:25:52.647233 18283 solver.cpp:244]     Train net output #1: loss = 0.00141765 (* 1 = 0.00141765 loss)
I0813 21:25:52.647245 18283 sgd_solver.cpp:106] Iteration 53650, lr = 0.00249546
I0813 21:26:33.472822 18283 solver.cpp:337] Iteration 53700, Testing net (#0)
I0813 21:26:37.777715 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 21:26:37.777782 18283 solver.cpp:404]     Test net output #1: loss = 0.935434 (* 1 = 0.935434 loss)
I0813 21:26:38.770290 18283 solver.cpp:228] Iteration 53700, loss = 0.0151762
I0813 21:26:38.770362 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:26:38.770375 18283 solver.cpp:244]     Train net output #1: loss = 0.0151762 (* 1 = 0.0151762 loss)
I0813 21:26:38.770390 18283 sgd_solver.cpp:106] Iteration 53700, lr = 0.00249399
I0813 21:27:19.967072 18283 solver.cpp:228] Iteration 53750, loss = 0.00578609
I0813 21:27:19.967296 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:27:19.967351 18283 solver.cpp:244]     Train net output #1: loss = 0.00578609 (* 1 = 0.00578609 loss)
I0813 21:27:19.967391 18283 sgd_solver.cpp:106] Iteration 53750, lr = 0.00249253
I0813 21:28:01.591338 18283 solver.cpp:337] Iteration 53800, Testing net (#0)
I0813 21:28:05.941790 18283 solver.cpp:404]     Test net output #0: accuracy = 0.771
I0813 21:28:05.941856 18283 solver.cpp:404]     Test net output #1: loss = 0.821768 (* 1 = 0.821768 loss)
I0813 21:28:06.756574 18283 solver.cpp:228] Iteration 53800, loss = -9.75706e-09
I0813 21:28:06.756642 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:28:06.756654 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:28:06.756666 18283 sgd_solver.cpp:106] Iteration 53800, lr = 0.00249106
I0813 21:28:47.943392 18283 solver.cpp:228] Iteration 53850, loss = -8.3819e-09
I0813 21:28:47.943542 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:28:47.943555 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:28:47.943567 18283 sgd_solver.cpp:106] Iteration 53850, lr = 0.0024896
I0813 21:29:29.043058 18283 solver.cpp:337] Iteration 53900, Testing net (#0)
I0813 21:29:33.261667 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 21:29:33.261746 18283 solver.cpp:404]     Test net output #1: loss = 0.962789 (* 1 = 0.962789 loss)
I0813 21:29:34.075275 18283 solver.cpp:228] Iteration 53900, loss = 0.00863966
I0813 21:29:34.075345 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:29:34.075356 18283 solver.cpp:244]     Train net output #1: loss = 0.00863967 (* 1 = 0.00863967 loss)
I0813 21:29:34.075371 18283 sgd_solver.cpp:106] Iteration 53900, lr = 0.00248814
I0813 21:30:15.282856 18283 solver.cpp:228] Iteration 53950, loss = 0.00916077
I0813 21:30:15.283090 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:30:15.283148 18283 solver.cpp:244]     Train net output #1: loss = 0.00916078 (* 1 = 0.00916078 loss)
I0813 21:30:15.283180 18283 sgd_solver.cpp:106] Iteration 53950, lr = 0.00248668
I0813 21:30:55.936120 18283 solver.cpp:337] Iteration 54000, Testing net (#0)
I0813 21:30:59.989568 18283 solver.cpp:404]     Test net output #0: accuracy = 0.742
I0813 21:30:59.989632 18283 solver.cpp:404]     Test net output #1: loss = 0.976495 (* 1 = 0.976495 loss)
I0813 21:31:00.803596 18283 solver.cpp:228] Iteration 54000, loss = -8.14907e-09
I0813 21:31:00.803653 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:31:00.803664 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:31:00.803679 18283 sgd_solver.cpp:106] Iteration 54000, lr = 0.00248522
I0813 21:31:41.965303 18283 solver.cpp:228] Iteration 54050, loss = 0.000243184
I0813 21:31:41.965461 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:31:41.965474 18283 solver.cpp:244]     Train net output #1: loss = 0.000243194 (* 1 = 0.000243194 loss)
I0813 21:31:41.965487 18283 sgd_solver.cpp:106] Iteration 54050, lr = 0.00248377
I0813 21:32:22.310928 18283 solver.cpp:337] Iteration 54100, Testing net (#0)
I0813 21:32:26.564697 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 21:32:26.564764 18283 solver.cpp:404]     Test net output #1: loss = 0.889294 (* 1 = 0.889294 loss)
I0813 21:32:27.377841 18283 solver.cpp:228] Iteration 54100, loss = 0.0132595
I0813 21:32:27.377905 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:32:27.377918 18283 solver.cpp:244]     Train net output #1: loss = 0.0132595 (* 1 = 0.0132595 loss)
I0813 21:32:27.377938 18283 sgd_solver.cpp:106] Iteration 54100, lr = 0.00248231
I0813 21:33:08.557065 18283 solver.cpp:228] Iteration 54150, loss = -7.45058e-09
I0813 21:33:08.557230 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:33:08.557245 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:33:08.557257 18283 sgd_solver.cpp:106] Iteration 54150, lr = 0.00248086
I0813 21:33:48.901288 18283 solver.cpp:337] Iteration 54200, Testing net (#0)
I0813 21:33:52.957322 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 21:33:52.957391 18283 solver.cpp:404]     Test net output #1: loss = 0.844268 (* 1 = 0.844268 loss)
I0813 21:33:53.771185 18283 solver.cpp:228] Iteration 54200, loss = 0.0221611
I0813 21:33:53.771240 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:33:53.771252 18283 solver.cpp:244]     Train net output #1: loss = 0.0221612 (* 1 = 0.0221612 loss)
I0813 21:33:53.771267 18283 sgd_solver.cpp:106] Iteration 54200, lr = 0.00247941
I0813 21:34:34.934881 18283 solver.cpp:228] Iteration 54250, loss = 0.00901784
I0813 21:34:34.935051 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:34:34.935066 18283 solver.cpp:244]     Train net output #1: loss = 0.00901785 (* 1 = 0.00901785 loss)
I0813 21:34:34.935080 18283 sgd_solver.cpp:106] Iteration 54250, lr = 0.00247796
I0813 21:35:15.275523 18283 solver.cpp:337] Iteration 54300, Testing net (#0)
I0813 21:35:19.729058 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 21:35:19.729126 18283 solver.cpp:404]     Test net output #1: loss = 0.907791 (* 1 = 0.907791 loss)
I0813 21:35:20.543269 18283 solver.cpp:228] Iteration 54300, loss = 0.00571606
I0813 21:35:20.543331 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:35:20.543344 18283 solver.cpp:244]     Train net output #1: loss = 0.00571607 (* 1 = 0.00571607 loss)
I0813 21:35:20.543359 18283 sgd_solver.cpp:106] Iteration 54300, lr = 0.00247652
I0813 21:36:01.722926 18283 solver.cpp:228] Iteration 54350, loss = 0.000208252
I0813 21:36:01.723088 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:36:01.723103 18283 solver.cpp:244]     Train net output #1: loss = 0.00020826 (* 1 = 0.00020826 loss)
I0813 21:36:01.723115 18283 sgd_solver.cpp:106] Iteration 54350, lr = 0.00247508
I0813 21:36:42.083637 18283 solver.cpp:337] Iteration 54400, Testing net (#0)
I0813 21:36:46.338856 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 21:36:46.338922 18283 solver.cpp:404]     Test net output #1: loss = 0.99492 (* 1 = 0.99492 loss)
I0813 21:36:47.151374 18283 solver.cpp:228] Iteration 54400, loss = -7.45058e-09
I0813 21:36:47.151432 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:36:47.151443 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:36:47.151463 18283 sgd_solver.cpp:106] Iteration 54400, lr = 0.00247363
I0813 21:37:28.307312 18283 solver.cpp:228] Iteration 54450, loss = 0.00131864
I0813 21:37:28.307467 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:37:28.307482 18283 solver.cpp:244]     Train net output #1: loss = 0.00131865 (* 1 = 0.00131865 loss)
I0813 21:37:28.307493 18283 sgd_solver.cpp:106] Iteration 54450, lr = 0.0024722
I0813 21:38:08.644341 18283 solver.cpp:337] Iteration 54500, Testing net (#0)
I0813 21:38:13.047096 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 21:38:13.047168 18283 solver.cpp:404]     Test net output #1: loss = 0.908351 (* 1 = 0.908351 loss)
I0813 21:38:13.859096 18283 solver.cpp:228] Iteration 54500, loss = 0.000297513
I0813 21:38:13.859150 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:38:13.859163 18283 solver.cpp:244]     Train net output #1: loss = 0.000297518 (* 1 = 0.000297518 loss)
I0813 21:38:13.859179 18283 sgd_solver.cpp:106] Iteration 54500, lr = 0.00247076
I0813 21:38:55.066941 18283 solver.cpp:228] Iteration 54550, loss = -7.39237e-09
I0813 21:38:55.067164 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:38:55.067214 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:38:55.067234 18283 sgd_solver.cpp:106] Iteration 54550, lr = 0.00246932
I0813 21:39:35.565019 18283 solver.cpp:337] Iteration 54600, Testing net (#0)
I0813 21:39:39.872149 18283 solver.cpp:404]     Test net output #0: accuracy = 0.735
I0813 21:39:39.872215 18283 solver.cpp:404]     Test net output #1: loss = 1.04668 (* 1 = 1.04668 loss)
I0813 21:39:40.684077 18283 solver.cpp:228] Iteration 54600, loss = 0.00225562
I0813 21:39:40.684144 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:39:40.684155 18283 solver.cpp:244]     Train net output #1: loss = 0.00225563 (* 1 = 0.00225563 loss)
I0813 21:39:40.684170 18283 sgd_solver.cpp:106] Iteration 54600, lr = 0.00246789
I0813 21:40:21.880544 18283 solver.cpp:228] Iteration 54650, loss = 0.000124577
I0813 21:40:21.880691 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:40:21.880703 18283 solver.cpp:244]     Train net output #1: loss = 0.000124584 (* 1 = 0.000124584 loss)
I0813 21:40:21.880715 18283 sgd_solver.cpp:106] Iteration 54650, lr = 0.00246646
I0813 21:41:02.258661 18283 solver.cpp:337] Iteration 54700, Testing net (#0)
I0813 21:41:06.513196 18283 solver.cpp:404]     Test net output #0: accuracy = 0.748
I0813 21:41:06.513264 18283 solver.cpp:404]     Test net output #1: loss = 0.985996 (* 1 = 0.985996 loss)
I0813 21:41:07.540304 18283 solver.cpp:228] Iteration 54700, loss = 0.00843617
I0813 21:41:07.540374 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:41:07.540387 18283 solver.cpp:244]     Train net output #1: loss = 0.00843617 (* 1 = 0.00843617 loss)
I0813 21:41:07.540401 18283 sgd_solver.cpp:106] Iteration 54700, lr = 0.00246503
I0813 21:41:48.703922 18283 solver.cpp:228] Iteration 54750, loss = -3.72529e-09
I0813 21:41:48.704092 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:41:48.704107 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:41:48.704118 18283 sgd_solver.cpp:106] Iteration 54750, lr = 0.0024636
I0813 21:42:29.054678 18283 solver.cpp:337] Iteration 54800, Testing net (#0)
I0813 21:42:33.103804 18283 solver.cpp:404]     Test net output #0: accuracy = 0.751
I0813 21:42:33.103871 18283 solver.cpp:404]     Test net output #1: loss = 0.972896 (* 1 = 0.972896 loss)
I0813 21:42:33.916232 18283 solver.cpp:228] Iteration 54800, loss = -3.72529e-09
I0813 21:42:33.916296 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:42:33.916307 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:42:33.916324 18283 sgd_solver.cpp:106] Iteration 54800, lr = 0.00246217
I0813 21:43:15.067337 18283 solver.cpp:228] Iteration 54850, loss = 0.00515496
I0813 21:43:15.067522 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:43:15.067536 18283 solver.cpp:244]     Train net output #1: loss = 0.00515496 (* 1 = 0.00515496 loss)
I0813 21:43:15.067548 18283 sgd_solver.cpp:106] Iteration 54850, lr = 0.00246075
I0813 21:43:55.420469 18283 solver.cpp:337] Iteration 54900, Testing net (#0)
I0813 21:43:59.472272 18283 solver.cpp:404]     Test net output #0: accuracy = 0.747
I0813 21:43:59.472337 18283 solver.cpp:404]     Test net output #1: loss = 0.975938 (* 1 = 0.975938 loss)
I0813 21:44:00.285133 18283 solver.cpp:228] Iteration 54900, loss = 0.000194591
I0813 21:44:00.285182 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:44:00.285193 18283 solver.cpp:244]     Train net output #1: loss = 0.000194594 (* 1 = 0.000194594 loss)
I0813 21:44:00.285210 18283 sgd_solver.cpp:106] Iteration 54900, lr = 0.00245933
I0813 21:44:41.450794 18283 solver.cpp:228] Iteration 54950, loss = -3.72529e-09
I0813 21:44:41.450999 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:44:41.451053 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:44:41.451081 18283 sgd_solver.cpp:106] Iteration 54950, lr = 0.00245791
I0813 21:45:22.595468 18283 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_55000.caffemodel
I0813 21:45:22.988765 18283 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_55000.solverstate
I0813 21:45:23.001716 18283 solver.cpp:337] Iteration 55000, Testing net (#0)
I0813 21:45:27.084206 18283 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0813 21:45:27.084276 18283 solver.cpp:404]     Test net output #1: loss = 0.877072 (* 1 = 0.877072 loss)
I0813 21:45:27.912468 18283 solver.cpp:228] Iteration 55000, loss = 0.00197222
I0813 21:45:27.912525 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:45:27.912536 18283 solver.cpp:244]     Train net output #1: loss = 0.00197222 (* 1 = 0.00197222 loss)
I0813 21:45:27.912552 18283 sgd_solver.cpp:106] Iteration 55000, lr = 0.00245649
I0813 21:46:09.189203 18283 solver.cpp:228] Iteration 55050, loss = 0.00428041
I0813 21:46:09.189410 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:46:09.189457 18283 solver.cpp:244]     Train net output #1: loss = 0.00428041 (* 1 = 0.00428041 loss)
I0813 21:46:09.189476 18283 sgd_solver.cpp:106] Iteration 55050, lr = 0.00245507
I0813 21:46:50.121950 18283 solver.cpp:337] Iteration 55100, Testing net (#0)
I0813 21:46:54.492565 18283 solver.cpp:404]     Test net output #0: accuracy = 0.773
I0813 21:46:54.492625 18283 solver.cpp:404]     Test net output #1: loss = 0.805763 (* 1 = 0.805763 loss)
I0813 21:46:55.319291 18283 solver.cpp:228] Iteration 55100, loss = 0.0039411
I0813 21:46:55.319360 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:46:55.319372 18283 solver.cpp:244]     Train net output #1: loss = 0.0039411 (* 1 = 0.0039411 loss)
I0813 21:46:55.319386 18283 sgd_solver.cpp:106] Iteration 55100, lr = 0.00245366
I0813 21:47:36.545428 18283 solver.cpp:228] Iteration 55150, loss = 0.00941546
I0813 21:47:36.545583 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:47:36.545596 18283 solver.cpp:244]     Train net output #1: loss = 0.00941547 (* 1 = 0.00941547 loss)
I0813 21:47:36.545608 18283 sgd_solver.cpp:106] Iteration 55150, lr = 0.00245225
I0813 21:48:16.973140 18283 solver.cpp:337] Iteration 55200, Testing net (#0)
I0813 21:48:21.025907 18283 solver.cpp:404]     Test net output #0: accuracy = 0.76
I0813 21:48:21.025974 18283 solver.cpp:404]     Test net output #1: loss = 0.851519 (* 1 = 0.851519 loss)
I0813 21:48:21.838728 18283 solver.cpp:228] Iteration 55200, loss = 0.000136568
I0813 21:48:21.838795 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:48:21.838809 18283 solver.cpp:244]     Train net output #1: loss = 0.000136579 (* 1 = 0.000136579 loss)
I0813 21:48:21.838822 18283 sgd_solver.cpp:106] Iteration 55200, lr = 0.00245084
I0813 21:49:03.046933 18283 solver.cpp:228] Iteration 55250, loss = -1.28057e-08
I0813 21:49:03.047124 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:49:03.047138 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:49:03.047149 18283 sgd_solver.cpp:106] Iteration 55250, lr = 0.00244943
I0813 21:49:43.865953 18283 solver.cpp:337] Iteration 55300, Testing net (#0)
I0813 21:49:48.135982 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 21:49:48.136059 18283 solver.cpp:404]     Test net output #1: loss = 0.963404 (* 1 = 0.963404 loss)
I0813 21:49:48.949167 18283 solver.cpp:228] Iteration 55300, loss = 0.0163261
I0813 21:49:48.949226 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:49:48.949239 18283 solver.cpp:244]     Train net output #1: loss = 0.0163261 (* 1 = 0.0163261 loss)
I0813 21:49:48.949254 18283 sgd_solver.cpp:106] Iteration 55300, lr = 0.00244802
I0813 21:50:30.520828 18283 solver.cpp:228] Iteration 55350, loss = 0.016383
I0813 21:50:30.521042 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:50:30.521100 18283 solver.cpp:244]     Train net output #1: loss = 0.016383 (* 1 = 0.016383 loss)
I0813 21:50:30.521167 18283 sgd_solver.cpp:106] Iteration 55350, lr = 0.00244662
I0813 21:51:11.078985 18283 solver.cpp:337] Iteration 55400, Testing net (#0)
I0813 21:51:15.128394 18283 solver.cpp:404]     Test net output #0: accuracy = 0.752
I0813 21:51:15.128471 18283 solver.cpp:404]     Test net output #1: loss = 0.960716 (* 1 = 0.960716 loss)
I0813 21:51:15.939857 18283 solver.cpp:228] Iteration 55400, loss = -1.86265e-08
I0813 21:51:15.939909 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:51:15.939920 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:51:15.939939 18283 sgd_solver.cpp:106] Iteration 55400, lr = 0.00244521
I0813 21:51:57.083696 18283 solver.cpp:228] Iteration 55450, loss = 0.00849076
I0813 21:51:57.083895 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:51:57.083943 18283 solver.cpp:244]     Train net output #1: loss = 0.00849077 (* 1 = 0.00849077 loss)
I0813 21:51:57.083969 18283 sgd_solver.cpp:106] Iteration 55450, lr = 0.00244381
I0813 21:52:37.431083 18283 solver.cpp:337] Iteration 55500, Testing net (#0)
I0813 21:52:41.798358 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 21:52:41.798426 18283 solver.cpp:404]     Test net output #1: loss = 0.903017 (* 1 = 0.903017 loss)
I0813 21:52:42.612649 18283 solver.cpp:228] Iteration 55500, loss = 0.0108536
I0813 21:52:42.612714 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:52:42.612725 18283 solver.cpp:244]     Train net output #1: loss = 0.0108536 (* 1 = 0.0108536 loss)
I0813 21:52:42.612740 18283 sgd_solver.cpp:106] Iteration 55500, lr = 0.00244241
I0813 21:53:23.796350 18283 solver.cpp:228] Iteration 55550, loss = 0.00339196
I0813 21:53:23.796514 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:53:23.796527 18283 solver.cpp:244]     Train net output #1: loss = 0.00339198 (* 1 = 0.00339198 loss)
I0813 21:53:23.796540 18283 sgd_solver.cpp:106] Iteration 55550, lr = 0.00244102
I0813 21:54:04.174018 18283 solver.cpp:337] Iteration 55600, Testing net (#0)
I0813 21:54:08.238968 18283 solver.cpp:404]     Test net output #0: accuracy = 0.755
I0813 21:54:08.239042 18283 solver.cpp:404]     Test net output #1: loss = 0.917192 (* 1 = 0.917192 loss)
I0813 21:54:09.052603 18283 solver.cpp:228] Iteration 55600, loss = 0.00622726
I0813 21:54:09.052673 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:54:09.052685 18283 solver.cpp:244]     Train net output #1: loss = 0.00622727 (* 1 = 0.00622727 loss)
I0813 21:54:09.052706 18283 sgd_solver.cpp:106] Iteration 55600, lr = 0.00243962
I0813 21:54:50.242736 18283 solver.cpp:228] Iteration 55650, loss = 0.000532654
I0813 21:54:50.242975 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:54:50.243031 18283 solver.cpp:244]     Train net output #1: loss = 0.000532668 (* 1 = 0.000532668 loss)
I0813 21:54:50.243053 18283 sgd_solver.cpp:106] Iteration 55650, lr = 0.00243823
I0813 21:55:30.780884 18283 solver.cpp:337] Iteration 55700, Testing net (#0)
I0813 21:55:34.837535 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 21:55:34.837604 18283 solver.cpp:404]     Test net output #1: loss = 0.992589 (* 1 = 0.992589 loss)
I0813 21:55:35.649395 18283 solver.cpp:228] Iteration 55700, loss = -1.30385e-08
I0813 21:55:35.649451 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:55:35.649461 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:55:35.649476 18283 sgd_solver.cpp:106] Iteration 55700, lr = 0.00243683
I0813 21:56:16.798264 18283 solver.cpp:228] Iteration 55750, loss = -1.30385e-08
I0813 21:56:16.798413 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:56:16.798426 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:56:16.798439 18283 sgd_solver.cpp:106] Iteration 55750, lr = 0.00243544
I0813 21:56:57.158349 18283 solver.cpp:337] Iteration 55800, Testing net (#0)
I0813 21:57:01.457712 18283 solver.cpp:404]     Test net output #0: accuracy = 0.762
I0813 21:57:01.457778 18283 solver.cpp:404]     Test net output #1: loss = 0.860852 (* 1 = 0.860852 loss)
I0813 21:57:02.269142 18283 solver.cpp:228] Iteration 55800, loss = 0.0116663
I0813 21:57:02.269196 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:57:02.269207 18283 solver.cpp:244]     Train net output #1: loss = 0.0116663 (* 1 = 0.0116663 loss)
I0813 21:57:02.269223 18283 sgd_solver.cpp:106] Iteration 55800, lr = 0.00243406
I0813 21:57:43.953481 18283 solver.cpp:228] Iteration 55850, loss = 0.00837525
I0813 21:57:43.953644 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:57:43.953658 18283 solver.cpp:244]     Train net output #1: loss = 0.00837527 (* 1 = 0.00837527 loss)
I0813 21:57:43.953671 18283 sgd_solver.cpp:106] Iteration 55850, lr = 0.00243267
I0813 21:58:24.610569 18283 solver.cpp:337] Iteration 55900, Testing net (#0)
I0813 21:58:28.662907 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 21:58:28.662972 18283 solver.cpp:404]     Test net output #1: loss = 0.919594 (* 1 = 0.919594 loss)
I0813 21:58:29.475006 18283 solver.cpp:228] Iteration 55900, loss = 0.00148831
I0813 21:58:29.475062 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:58:29.475075 18283 solver.cpp:244]     Train net output #1: loss = 0.00148833 (* 1 = 0.00148833 loss)
I0813 21:58:29.475086 18283 sgd_solver.cpp:106] Iteration 55900, lr = 0.00243129
I0813 21:59:10.652076 18283 solver.cpp:228] Iteration 55950, loss = -1.49012e-08
I0813 21:59:10.652232 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:59:10.652246 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 21:59:10.652259 18283 sgd_solver.cpp:106] Iteration 55950, lr = 0.0024299
I0813 21:59:51.002470 18283 solver.cpp:337] Iteration 56000, Testing net (#0)
I0813 21:59:55.056092 18283 solver.cpp:404]     Test net output #0: accuracy = 0.733
I0813 21:59:55.056157 18283 solver.cpp:404]     Test net output #1: loss = 1.04942 (* 1 = 1.04942 loss)
I0813 21:59:55.869443 18283 solver.cpp:228] Iteration 56000, loss = 0.0110876
I0813 21:59:55.869504 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 21:59:55.869516 18283 solver.cpp:244]     Train net output #1: loss = 0.0110876 (* 1 = 0.0110876 loss)
I0813 21:59:55.869530 18283 sgd_solver.cpp:106] Iteration 56000, lr = 0.00242852
I0813 22:00:37.752496 18283 solver.cpp:228] Iteration 56050, loss = 0.00744696
I0813 22:00:37.752660 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:00:37.752674 18283 solver.cpp:244]     Train net output #1: loss = 0.00744697 (* 1 = 0.00744697 loss)
I0813 22:00:37.752688 18283 sgd_solver.cpp:106] Iteration 56050, lr = 0.00242714
I0813 22:01:18.101527 18283 solver.cpp:337] Iteration 56100, Testing net (#0)
I0813 22:01:22.166013 18283 solver.cpp:404]     Test net output #0: accuracy = 0.753
I0813 22:01:22.166092 18283 solver.cpp:404]     Test net output #1: loss = 0.919915 (* 1 = 0.919915 loss)
I0813 22:01:22.980020 18283 solver.cpp:228] Iteration 56100, loss = 0.0195543
I0813 22:01:22.980078 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:01:22.980090 18283 solver.cpp:244]     Train net output #1: loss = 0.0195543 (* 1 = 0.0195543 loss)
I0813 22:01:22.980103 18283 sgd_solver.cpp:106] Iteration 56100, lr = 0.00242577
I0813 22:02:04.646059 18283 solver.cpp:228] Iteration 56150, loss = 0.00810709
I0813 22:02:04.646227 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:02:04.646242 18283 solver.cpp:244]     Train net output #1: loss = 0.0081071 (* 1 = 0.0081071 loss)
I0813 22:02:04.646253 18283 sgd_solver.cpp:106] Iteration 56150, lr = 0.00242439
I0813 22:02:45.038527 18283 solver.cpp:337] Iteration 56200, Testing net (#0)
I0813 22:02:49.092937 18283 solver.cpp:404]     Test net output #0: accuracy = 0.772
I0813 22:02:49.093003 18283 solver.cpp:404]     Test net output #1: loss = 0.788771 (* 1 = 0.788771 loss)
I0813 22:02:49.907611 18283 solver.cpp:228] Iteration 56200, loss = 0.00465148
I0813 22:02:49.907680 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:02:49.907691 18283 solver.cpp:244]     Train net output #1: loss = 0.0046515 (* 1 = 0.0046515 loss)
I0813 22:02:49.907711 18283 sgd_solver.cpp:106] Iteration 56200, lr = 0.00242302
I0813 22:03:31.101908 18283 solver.cpp:228] Iteration 56250, loss = 0.00361869
I0813 22:03:31.102072 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:03:31.102087 18283 solver.cpp:244]     Train net output #1: loss = 0.0036187 (* 1 = 0.0036187 loss)
I0813 22:03:31.102097 18283 sgd_solver.cpp:106] Iteration 56250, lr = 0.00242165
I0813 22:04:11.471974 18283 solver.cpp:337] Iteration 56300, Testing net (#0)
I0813 22:04:15.681155 18283 solver.cpp:404]     Test net output #0: accuracy = 0.757
I0813 22:04:15.681238 18283 solver.cpp:404]     Test net output #1: loss = 0.922059 (* 1 = 0.922059 loss)
I0813 22:04:16.494451 18283 solver.cpp:228] Iteration 56300, loss = -8.3819e-09
I0813 22:04:16.494508 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:04:16.494520 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 22:04:16.494535 18283 sgd_solver.cpp:106] Iteration 56300, lr = 0.00242028
I0813 22:04:57.680008 18283 solver.cpp:228] Iteration 56350, loss = 9.51821e-05
I0813 22:04:57.680250 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:04:57.680299 18283 solver.cpp:244]     Train net output #1: loss = 9.5191e-05 (* 1 = 9.5191e-05 loss)
I0813 22:04:57.680317 18283 sgd_solver.cpp:106] Iteration 56350, lr = 0.00241891
I0813 22:05:38.225795 18283 solver.cpp:337] Iteration 56400, Testing net (#0)
I0813 22:05:42.277988 18283 solver.cpp:404]     Test net output #0: accuracy = 0.764
I0813 22:05:42.278055 18283 solver.cpp:404]     Test net output #1: loss = 0.825174 (* 1 = 0.825174 loss)
I0813 22:05:43.090350 18283 solver.cpp:228] Iteration 56400, loss = 0.00819449
I0813 22:05:43.090404 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:05:43.090415 18283 solver.cpp:244]     Train net output #1: loss = 0.0081945 (* 1 = 0.0081945 loss)
I0813 22:05:43.090433 18283 sgd_solver.cpp:106] Iteration 56400, lr = 0.00241754
I0813 22:06:24.251096 18283 solver.cpp:228] Iteration 56450, loss = 1.35275e-05
I0813 22:06:24.251307 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:06:24.251358 18283 solver.cpp:244]     Train net output #1: loss = 1.35362e-05 (* 1 = 1.35362e-05 loss)
I0813 22:06:24.251380 18283 sgd_solver.cpp:106] Iteration 56450, lr = 0.00241618
I0813 22:07:04.910377 18283 solver.cpp:337] Iteration 56500, Testing net (#0)
I0813 22:07:08.963775 18283 solver.cpp:404]     Test net output #0: accuracy = 0.748
I0813 22:07:08.963843 18283 solver.cpp:404]     Test net output #1: loss = 0.927382 (* 1 = 0.927382 loss)
I0813 22:07:09.774580 18283 solver.cpp:228] Iteration 56500, loss = 0.0156673
I0813 22:07:09.774627 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:07:09.774638 18283 solver.cpp:244]     Train net output #1: loss = 0.0156673 (* 1 = 0.0156673 loss)
I0813 22:07:09.774657 18283 sgd_solver.cpp:106] Iteration 56500, lr = 0.00241481
I0813 22:07:50.906213 18283 solver.cpp:228] Iteration 56550, loss = -6.98492e-09
I0813 22:07:50.906383 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:07:50.906396 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 22:07:50.906407 18283 sgd_solver.cpp:106] Iteration 56550, lr = 0.00241345
I0813 22:08:31.232550 18283 solver.cpp:337] Iteration 56600, Testing net (#0)
I0813 22:08:35.285364 18283 solver.cpp:404]     Test net output #0: accuracy = 0.744
I0813 22:08:35.285431 18283 solver.cpp:404]     Test net output #1: loss = 0.954709 (* 1 = 0.954709 loss)
I0813 22:08:36.098753 18283 solver.cpp:228] Iteration 56600, loss = 0.0213387
I0813 22:08:36.098803 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:08:36.098814 18283 solver.cpp:244]     Train net output #1: loss = 0.0213387 (* 1 = 0.0213387 loss)
I0813 22:08:36.098832 18283 sgd_solver.cpp:106] Iteration 56600, lr = 0.00241209
I0813 22:09:17.278269 18283 solver.cpp:228] Iteration 56650, loss = 0.00753119
I0813 22:09:17.278427 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:09:17.278442 18283 solver.cpp:244]     Train net output #1: loss = 0.0075312 (* 1 = 0.0075312 loss)
I0813 22:09:17.278456 18283 sgd_solver.cpp:106] Iteration 56650, lr = 0.00241074
I0813 22:09:57.635579 18283 solver.cpp:337] Iteration 56700, Testing net (#0)
I0813 22:10:01.700660 18283 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0813 22:10:01.700739 18283 solver.cpp:404]     Test net output #1: loss = 0.915552 (* 1 = 0.915552 loss)
I0813 22:10:02.513833 18283 solver.cpp:228] Iteration 56700, loss = 0.00808338
I0813 22:10:02.513881 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:10:02.513893 18283 solver.cpp:244]     Train net output #1: loss = 0.00808338 (* 1 = 0.00808338 loss)
I0813 22:10:02.513912 18283 sgd_solver.cpp:106] Iteration 56700, lr = 0.00240938
I0813 22:10:43.697624 18283 solver.cpp:228] Iteration 56750, loss = 0.0021056
I0813 22:10:43.697778 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:10:43.697791 18283 solver.cpp:244]     Train net output #1: loss = 0.0021056 (* 1 = 0.0021056 loss)
I0813 22:10:43.697803 18283 sgd_solver.cpp:106] Iteration 56750, lr = 0.00240803
I0813 22:11:24.055830 18283 solver.cpp:337] Iteration 56800, Testing net (#0)
I0813 22:11:28.115876 18283 solver.cpp:404]     Test net output #0: accuracy = 0.738
I0813 22:11:28.115953 18283 solver.cpp:404]     Test net output #1: loss = 0.976752 (* 1 = 0.976752 loss)
I0813 22:11:28.928733 18283 solver.cpp:228] Iteration 56800, loss = 0.00340633
I0813 22:11:28.928789 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:11:28.928800 18283 solver.cpp:244]     Train net output #1: loss = 0.00340633 (* 1 = 0.00340633 loss)
I0813 22:11:28.928818 18283 sgd_solver.cpp:106] Iteration 56800, lr = 0.00240668
I0813 22:12:10.049500 18283 solver.cpp:228] Iteration 56850, loss = 3.00519e-05
I0813 22:12:10.049659 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:12:10.049674 18283 solver.cpp:244]     Train net output #1: loss = 3.0055e-05 (* 1 = 3.0055e-05 loss)
I0813 22:12:10.049685 18283 sgd_solver.cpp:106] Iteration 56850, lr = 0.00240533
I0813 22:12:50.396504 18283 solver.cpp:337] Iteration 56900, Testing net (#0)
I0813 22:12:54.458142 18283 solver.cpp:404]     Test net output #0: accuracy = 0.767
I0813 22:12:54.458225 18283 solver.cpp:404]     Test net output #1: loss = 0.813054 (* 1 = 0.813054 loss)
I0813 22:12:55.271077 18283 solver.cpp:228] Iteration 56900, loss = 0.0221269
I0813 22:12:55.271139 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:12:55.271152 18283 solver.cpp:244]     Train net output #1: loss = 0.022127 (* 1 = 0.022127 loss)
I0813 22:12:55.271164 18283 sgd_solver.cpp:106] Iteration 56900, lr = 0.00240398
I0813 22:13:36.452147 18283 solver.cpp:228] Iteration 56950, loss = 0.00890999
I0813 22:13:36.452344 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:13:36.452359 18283 solver.cpp:244]     Train net output #1: loss = 0.00891 (* 1 = 0.00891 loss)
I0813 22:13:36.452371 18283 sgd_solver.cpp:106] Iteration 56950, lr = 0.00240263
I0813 22:14:16.785575 18283 solver.cpp:337] Iteration 57000, Testing net (#0)
I0813 22:14:20.848932 18283 solver.cpp:404]     Test net output #0: accuracy = 0.746
I0813 22:14:20.849011 18283 solver.cpp:404]     Test net output #1: loss = 0.99342 (* 1 = 0.99342 loss)
I0813 22:14:21.662030 18283 solver.cpp:228] Iteration 57000, loss = -5.60249e-09
I0813 22:14:21.662082 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:14:21.662093 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 22:14:21.662111 18283 sgd_solver.cpp:106] Iteration 57000, lr = 0.00240129
I0813 22:15:02.878439 18283 solver.cpp:228] Iteration 57050, loss = 0.00999457
I0813 22:15:02.878679 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:15:02.878743 18283 solver.cpp:244]     Train net output #1: loss = 0.00999458 (* 1 = 0.00999458 loss)
I0813 22:15:02.878778 18283 sgd_solver.cpp:106] Iteration 57050, lr = 0.00239994
I0813 22:15:45.530362 18283 solver.cpp:337] Iteration 57100, Testing net (#0)
I0813 22:15:49.932147 18283 solver.cpp:404]     Test net output #0: accuracy = 0.758
I0813 22:15:49.932214 18283 solver.cpp:404]     Test net output #1: loss = 0.825637 (* 1 = 0.825637 loss)
I0813 22:15:50.762574 18283 solver.cpp:228] Iteration 57100, loss = 0.00130625
I0813 22:15:50.762632 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:15:50.762644 18283 solver.cpp:244]     Train net output #1: loss = 0.00130625 (* 1 = 0.00130625 loss)
I0813 22:15:50.762657 18283 sgd_solver.cpp:106] Iteration 57100, lr = 0.0023986
I0813 22:16:32.708073 18283 solver.cpp:228] Iteration 57150, loss = -4.65661e-09
I0813 22:16:32.708359 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:16:32.708405 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 22:16:32.708436 18283 sgd_solver.cpp:106] Iteration 57150, lr = 0.00239726
I0813 22:17:14.812777 18283 solver.cpp:337] Iteration 57200, Testing net (#0)
I0813 22:17:18.996395 18283 solver.cpp:404]     Test net output #0: accuracy = 0.742
I0813 22:17:18.996456 18283 solver.cpp:404]     Test net output #1: loss = 0.995539 (* 1 = 0.995539 loss)
I0813 22:17:20.053365 18283 solver.cpp:228] Iteration 57200, loss = -5.58794e-09
I0813 22:17:20.053433 18283 solver.cpp:244]     Train net output #0: accuracy = 1
I0813 22:17:20.053445 18283 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0813 22:17:20.053460 18283 sgd_solver.cpp:106] Iteration 57200, lr = 0.00239592
