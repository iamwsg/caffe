./build/tools/caffe: /home/shaogangwang/anaconda2/lib/libtiff.so.5: no version information available (required by /usr/local/lib/libopencv_highgui.so.2.4)
I0810 12:46:18.504405 13394 caffe.cpp:178] Use CPU.
I0810 12:46:19.046506 13394 solver.cpp:48] Initializing solver from parameters: 
train_net: "examples/scene/metNetTrain.prototxt"
test_net: "examples/scene/metNetTest.prototxt"
test_iter: 10
test_interval: 100
base_lr: 0.01
display: 10
max_iter: 300000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0002
snapshot: 5000
snapshot_prefix: "examples/scene/scene"
solver_mode: CPU
I0810 12:46:19.047082 13394 solver.cpp:81] Creating training net from train_net file: examples/scene/metNetTrain.prototxt
I0810 12:46:19.056403 13394 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 1
    mirror: false
  }
  data_param {
    source: "/home/shaogangwang/Datasets/FeatsDB/featsTrain10k"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "th"
  type: "Threshold"
  bottom: "label"
  top: "th"
  threshold_param {
    threshold: 0
  }
}
layer {
  name: "i1"
  type: "Slice"
  bottom: "data"
  top: "i1"
  top: "i2"
  top: "i3"
  top: "i4"
  top: "i5"
  top: "i6"
  top: "i7"
  top: "i8"
  top: "i9"
  top: "i10"
  top: "i11"
  top: "i12"
  top: "i13"
  top: "i14"
  top: "i15"
  top: "i16"
  top: "i17"
  top: "i18"
  top: "i19"
  top: "i20"
  slice_param {
    slice_dim: 2
    slice_point: 1
    slice_point: 2
    slice_point: 3
    slice_point: 4
    slice_point: 5
    slice_point: 6
    slice_point: 7
    slice_point: 8
    slice_point: 9
    slice_point: 10
    slice_point: 11
    slice_point: 12
    slice_point: 13
    slice_point: 14
    slice_point: 15
    slice_point: 16
    slice_point: 17
    slice_point: 18
    slice_point: 19
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "i1"
  bottom: "i11"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Concat1"
  top: "InnerProduct1"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct1"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "Dropout1"
  top: "InnerProduct2"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "InnerProduct2"
  top: "InnerProduct2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct2"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m1"
  type: "InnerProduct"
  bottom: "Dropout2"
  top: "m1"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "i1"
  bottom: "i12"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "Concat2"
  top: "InnerProduct3"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct3"
  top: "InnerProduct3"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct3"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "Dropout3"
  top: "InnerProduct4"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "InnerProduct4"
  top: "InnerProduct4"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct4"
  top: "Dropout4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m2"
  type: "InnerProduct"
  bottom: "Dropout4"
  top: "m2"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "i1"
  bottom: "i13"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct5"
  type: "InnerProduct"
  bottom: "Concat3"
  top: "InnerProduct5"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "InnerProduct5"
  top: "InnerProduct5"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct5"
  top: "Dropout5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct6"
  type: "InnerProduct"
  bottom: "Dropout5"
  top: "InnerProduct6"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "InnerProduct6"
  top: "InnerProduct6"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct6"
  top: "Dropout6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m3"
  type: "InnerProduct"
  bottom: "Dropout6"
  top: "m3"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "i1"
  bottom: "i14"
  top: "Concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct7"
  type: "InnerProduct"
  bottom: "Concat4"
  top: "InnerProduct7"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "InnerProduct7"
  top: "InnerProduct7"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct7"
  top: "Dropout7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct8"
  type: "InnerProduct"
  bottom: "Dropout7"
  top: "InnerProduct8"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "InnerProduct8"
  top: "InnerProduct8"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct8"
  top: "Dropout8"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m4"
  type: "InnerProduct"
  bottom: "Dropout8"
  top: "m4"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "i1"
  bottom: "i15"
  top: "Concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct9"
  type: "InnerProduct"
  bottom: "Concat5"
  top: "InnerProduct9"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "InnerProduct9"
  top: "InnerProduct9"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct9"
  top: "Dropout9"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct10"
  type: "InnerProduct"
  bottom: "Dropout9"
  top: "InnerProduct10"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "InnerProduct10"
  top: "InnerProduct10"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct10"
  top: "Dropout10"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m5"
  type: "InnerProduct"
  bottom: "Dropout10"
  top: "m5"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "i1"
  bottom: "i16"
  top: "Concat6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct11"
  type: "InnerProduct"
  bottom: "Concat6"
  top: "InnerProduct11"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "InnerProduct11"
  top: "InnerProduct11"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct11"
  top: "Dropout11"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct12"
  type: "InnerProduct"
  bottom: "Dropout11"
  top: "InnerProduct12"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "InnerProduct12"
  top: "InnerProduct12"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct12"
  top: "Dropout12"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m6"
  type: "InnerProduct"
  bottom: "Dropout12"
  top: "m6"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "i1"
  bottom: "i17"
  top: "Concat7"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct13"
  type: "InnerProduct"
  bottom: "Concat7"
  top: "InnerProduct13"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "InnerProduct13"
  top: "InnerProduct13"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct13"
  top: "Dropout13"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct14"
  type: "InnerProduct"
  bottom: "Dropout13"
  top: "InnerProduct14"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "InnerProduct14"
  top: "InnerProduct14"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct14"
  top: "Dropout14"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m7"
  type: "InnerProduct"
  bottom: "Dropout14"
  top: "m7"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "i1"
  bottom: "i18"
  top: "Concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct15"
  type: "InnerProduct"
  bottom: "Concat8"
  top: "InnerProduct15"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "InnerProduct15"
  top: "InnerProduct15"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct15"
  top: "Dropout15"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct16"
  type: "InnerProduct"
  bottom: "Dropout15"
  top: "InnerProduct16"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "InnerProduct16"
  top: "InnerProduct16"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct16"
  top: "Dropout16"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m8"
  type: "InnerProduct"
  bottom: "Dropout16"
  top: "m8"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "i1"
  bottom: "i19"
  top: "Concat9"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct17"
  type: "InnerProduct"
  bottom: "Concat9"
  top: "InnerProduct17"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "InnerProduct17"
  top: "InnerProduct17"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct17"
  top: "Dropout17"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct18"
  type: "InnerProduct"
  bottom: "Dropout17"
  top: "InnerProduct18"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "InnerProduct18"
  top: "InnerProduct18"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct18"
  top: "Dropout18"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m9"
  type: "InnerProduct"
  bottom: "Dropout18"
  top: "m9"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat10"
  type: "Concat"
  bottom: "i1"
  bottom: "i20"
  top: "Concat10"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct19"
  type: "InnerProduct"
  bottom: "Concat10"
  top: "InnerProduct19"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "InnerProduct19"
  top: "InnerProduct19"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct19"
  top: "Dropout19"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct20"
  type: "InnerProduct"
  bottom: "Dropout19"
  top: "InnerProduct20"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "InnerProduct20"
  top: "InnerProduct20"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct20"
  top: "Dropout20"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m10"
  type: "InnerProduct"
  bottom: "Dropout20"
  top: "m10"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat11"
  type: "Concat"
  bottom: "i2"
  bottom: "i11"
  top: "Concat11"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct21"
  type: "InnerProduct"
  bottom: "Concat11"
  top: "InnerProduct21"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "InnerProduct21"
  top: "InnerProduct21"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct21"
  top: "Dropout21"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct22"
  type: "InnerProduct"
  bottom: "Dropout21"
  top: "InnerProduct22"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "InnerProduct22"
  top: "InnerProduct22"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct22"
  top: "Dropout22"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m11"
  type: "InnerProduct"
  bottom: "Dropout22"
  top: "m11"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat12"
  type: "Concat"
  bottom: "i3"
  bottom: "i11"
  top: "Concat12"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct23"
  type: "InnerProduct"
  bottom: "Concat12"
  top: "InnerProduct23"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "InnerProduct23"
  top: "InnerProduct23"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct23"
  top: "Dropout23"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct24"
  type: "InnerProduct"
  bottom: "Dropout23"
  top: "InnerProduct24"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "InnerProduct24"
  top: "InnerProduct24"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct24"
  top: "Dropout24"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m12"
  type: "InnerProduct"
  bottom: "Dropout24"
  top: "m12"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat13"
  type: "Concat"
  bottom: "i4"
  bottom: "i11"
  top: "Concat13"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct25"
  type: "InnerProduct"
  bottom: "Concat13"
  top: "InnerProduct25"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "InnerProduct25"
  top: "InnerProduct25"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct25"
  top: "Dropout25"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct26"
  type: "InnerProduct"
  bottom: "Dropout25"
  top: "InnerProduct26"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "InnerProduct26"
  top: "InnerProduct26"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct26"
  top: "Dropout26"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m13"
  type: "InnerProduct"
  bottom: "Dropout26"
  top: "m13"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat14"
  type: "Concat"
  bottom: "i5"
  bottom: "i11"
  top: "Concat14"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct27"
  type: "InnerProduct"
  bottom: "Concat14"
  top: "InnerProduct27"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "InnerProduct27"
  top: "InnerProduct27"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct27"
  top: "Dropout27"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct28"
  type: "InnerProduct"
  bottom: "Dropout27"
  top: "InnerProduct28"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "InnerProduct28"
  top: "InnerProduct28"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct28"
  top: "Dropout28"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m14"
  type: "InnerProduct"
  bottom: "Dropout28"
  top: "m14"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat15"
  type: "Concat"
  bottom: "i6"
  bottom: "i11"
  top: "Concat15"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct29"
  type: "InnerProduct"
  bottom: "Concat15"
  top: "InnerProduct29"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "InnerProduct29"
  top: "InnerProduct29"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct29"
  top: "Dropout29"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct30"
  type: "InnerProduct"
  bottom: "Dropout29"
  top: "InnerProduct30"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "InnerProduct30"
  top: "InnerProduct30"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct30"
  top: "Dropout30"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m15"
  type: "InnerProduct"
  bottom: "Dropout30"
  top: "m15"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat16"
  type: "Concat"
  bottom: "i7"
  bottom: "i11"
  top: "Concat16"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct31"
  type: "InnerProduct"
  bottom: "Concat16"
  top: "InnerProduct31"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "InnerProduct31"
  top: "InnerProduct31"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct31"
  top: "Dropout31"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct32"
  type: "InnerProduct"
  bottom: "Dropout31"
  top: "InnerProduct32"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "InnerProduct32"
  top: "InnerProduct32"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct32"
  top: "Dropout32"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m16"
  type: "InnerProduct"
  bottom: "Dropout32"
  top: "m16"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat17"
  type: "Concat"
  bottom: "i8"
  bottom: "i11"
  top: "Concat17"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct33"
  type: "InnerProduct"
  bottom: "Concat17"
  top: "InnerProduct33"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "InnerProduct33"
  top: "InnerProduct33"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct33"
  top: "Dropout33"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct34"
  type: "InnerProduct"
  bottom: "Dropout33"
  top: "InnerProduct34"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "InnerProduct34"
  top: "InnerProduct34"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct34"
  top: "Dropout34"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m17"
  type: "InnerProduct"
  bottom: "Dropout34"
  top: "m17"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat18"
  type: "Concat"
  bottom: "i9"
  bottom: "i11"
  top: "Concat18"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct35"
  type: "InnerProduct"
  bottom: "Concat18"
  top: "InnerProduct35"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "InnerProduct35"
  top: "InnerProduct35"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct35"
  top: "Dropout35"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct36"
  type: "InnerProduct"
  bottom: "Dropout35"
  top: "InnerProduct36"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "InnerProduct36"
  top: "InnerProduct36"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct36"
  top: "Dropout36"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m18"
  type: "InnerProduct"
  bottom: "Dropout36"
  top: "m18"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat19"
  type: "Concat"
  bottom: "i10"
  bottom: "i11"
  top: "Concat19"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct37"
  type: "InnerProduct"
  bottom: "Concat19"
  top: "InnerProduct37"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU37"
  type: "ReLU"
  bottom: "Inner
I0810 12:46:19.057708 13394 layer_factory.hpp:77] Creating layer data
I0810 12:46:19.058820 13394 net.cpp:91] Creating Layer data
I0810 12:46:19.058841 13394 net.cpp:399] data -> data
I0810 12:46:19.058879 13394 net.cpp:399] data -> label
I0810 12:46:19.091855 13400 db_lmdb.cpp:35] Opened lmdb /home/shaogangwang/Datasets/FeatsDB/featsTrain10k
I0810 12:46:19.159485 13394 data_layer.cpp:41] output data size: 64,1,20,4096
I0810 12:46:19.722736 13394 net.cpp:141] Setting up data
I0810 12:46:19.723131 13394 net.cpp:148] Top shape: 64 1 20 4096 (5242880)
I0810 12:46:19.723264 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:19.723529 13394 net.cpp:156] Memory required for data: 20971776
I0810 12:46:19.723788 13394 layer_factory.hpp:77] Creating layer label_data_1_split
I0810 12:46:19.723928 13394 net.cpp:91] Creating Layer label_data_1_split
I0810 12:46:19.724043 13394 net.cpp:425] label_data_1_split <- label
I0810 12:46:19.724165 13394 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0810 12:46:19.724369 13394 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0810 12:46:19.724493 13394 net.cpp:141] Setting up label_data_1_split
I0810 12:46:19.724611 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:19.725426 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:19.725554 13394 net.cpp:156] Memory required for data: 20972288
I0810 12:46:19.725664 13394 layer_factory.hpp:77] Creating layer th
I0810 12:46:19.725786 13394 net.cpp:91] Creating Layer th
I0810 12:46:19.725894 13394 net.cpp:425] th <- label_data_1_split_0
I0810 12:46:19.726007 13394 net.cpp:399] th -> th
I0810 12:46:19.726127 13394 net.cpp:141] Setting up th
I0810 12:46:19.726239 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:19.726436 13394 net.cpp:156] Memory required for data: 20972544
I0810 12:46:19.726547 13394 layer_factory.hpp:77] Creating layer th_th_0_split
I0810 12:46:19.726662 13394 net.cpp:91] Creating Layer th_th_0_split
I0810 12:46:19.726771 13394 net.cpp:425] th_th_0_split <- th
I0810 12:46:19.726882 13394 net.cpp:399] th_th_0_split -> th_th_0_split_0
I0810 12:46:19.727006 13394 net.cpp:399] th_th_0_split -> th_th_0_split_1
I0810 12:46:19.727185 13394 net.cpp:141] Setting up th_th_0_split
I0810 12:46:19.727309 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:19.727437 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:19.727545 13394 net.cpp:156] Memory required for data: 20973056
I0810 12:46:19.728142 13394 layer_factory.hpp:77] Creating layer i1
I0810 12:46:19.728278 13394 net.cpp:91] Creating Layer i1
I0810 12:46:19.728385 13394 net.cpp:425] i1 <- data
I0810 12:46:19.728502 13394 net.cpp:399] i1 -> i1
I0810 12:46:19.728627 13394 net.cpp:399] i1 -> i2
I0810 12:46:19.728746 13394 net.cpp:399] i1 -> i3
I0810 12:46:19.728863 13394 net.cpp:399] i1 -> i4
I0810 12:46:19.728977 13394 net.cpp:399] i1 -> i5
I0810 12:46:19.729142 13394 net.cpp:399] i1 -> i6
I0810 12:46:19.727027 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:46:19.729579 13394 net.cpp:399] i1 -> i7
I0810 12:46:19.729704 13394 net.cpp:399] i1 -> i8
I0810 12:46:19.729840 13394 net.cpp:399] i1 -> i9
I0810 12:46:19.729965 13394 net.cpp:399] i1 -> i10
I0810 12:46:19.730084 13394 net.cpp:399] i1 -> i11
I0810 12:46:19.730201 13394 net.cpp:399] i1 -> i12
I0810 12:46:19.730316 13394 net.cpp:399] i1 -> i13
I0810 12:46:19.730432 13394 net.cpp:399] i1 -> i14
I0810 12:46:19.730546 13394 net.cpp:399] i1 -> i15
I0810 12:46:19.730664 13394 net.cpp:399] i1 -> i16
I0810 12:46:19.730779 13394 net.cpp:399] i1 -> i17
I0810 12:46:19.730895 13394 net.cpp:399] i1 -> i18
I0810 12:46:19.731011 13394 net.cpp:399] i1 -> i19
I0810 12:46:19.731166 13394 net.cpp:399] i1 -> i20
I0810 12:46:19.731324 13394 net.cpp:141] Setting up i1
I0810 12:46:19.731441 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.731551 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.731662 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.731771 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.731879 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.731988 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732111 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732249 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732385 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732523 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732661 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732750 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732782 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732813 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732846 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732874 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732902 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732928 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732952 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.732981 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.733006 13394 net.cpp:156] Memory required for data: 41944576
I0810 12:46:19.733029 13394 layer_factory.hpp:77] Creating layer i1_i1_0_split
I0810 12:46:19.733062 13394 net.cpp:91] Creating Layer i1_i1_0_split
I0810 12:46:19.733088 13394 net.cpp:425] i1_i1_0_split <- i1
I0810 12:46:19.733116 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_0
I0810 12:46:19.733152 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_1
I0810 12:46:19.733191 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_2
I0810 12:46:19.733227 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_3
I0810 12:46:19.733263 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_4
I0810 12:46:19.733304 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_5
I0810 12:46:19.733352 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_6
I0810 12:46:19.733391 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_7
I0810 12:46:19.733433 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_8
I0810 12:46:19.733479 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_9
I0810 12:46:19.733525 13394 net.cpp:141] Setting up i1_i1_0_split
I0810 12:46:19.733552 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.733593 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.733625 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.733654 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.733686 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.733716 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.733754 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.735177 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.735208 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.735234 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.735255 13394 net.cpp:156] Memory required for data: 52430336
I0810 12:46:19.735291 13394 layer_factory.hpp:77] Creating layer i11_i1_10_split
I0810 12:46:19.735326 13394 net.cpp:91] Creating Layer i11_i1_10_split
I0810 12:46:19.735348 13394 net.cpp:425] i11_i1_10_split <- i11
I0810 12:46:19.735374 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_0
I0810 12:46:19.735404 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_1
I0810 12:46:19.735433 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_2
I0810 12:46:19.735460 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_3
I0810 12:46:19.735488 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_4
I0810 12:46:19.735517 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_5
I0810 12:46:19.735543 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_6
I0810 12:46:19.735571 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_7
I0810 12:46:19.735599 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_8
I0810 12:46:19.735632 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_9
I0810 12:46:19.735671 13394 net.cpp:141] Setting up i11_i1_10_split
I0810 12:46:19.735700 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.735728 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.735754 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.735780 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.735807 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.737210 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.737323 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.737431 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.737536 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.737642 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:19.737743 13394 net.cpp:156] Memory required for data: 62916096
I0810 12:46:19.737848 13394 layer_factory.hpp:77] Creating layer Concat1
I0810 12:46:19.737972 13394 net.cpp:91] Creating Layer Concat1
I0810 12:46:19.738104 13394 net.cpp:425] Concat1 <- i1_i1_0_split_0
I0810 12:46:19.738278 13394 net.cpp:425] Concat1 <- i11_i1_10_split_0
I0810 12:46:19.738407 13394 net.cpp:399] Concat1 -> Concat1
I0810 12:46:19.738545 13394 net.cpp:141] Setting up Concat1
I0810 12:46:19.738698 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.738816 13394 net.cpp:156] Memory required for data: 65013248
I0810 12:46:19.738929 13394 layer_factory.hpp:77] Creating layer InnerProduct1
I0810 12:46:19.739051 13394 net.cpp:91] Creating Layer InnerProduct1
I0810 12:46:19.739162 13394 net.cpp:425] InnerProduct1 <- Concat1
I0810 12:46:19.739301 13394 net.cpp:399] InnerProduct1 -> InnerProduct1
I0810 12:46:19.744856 13394 net.cpp:141] Setting up InnerProduct1
I0810 12:46:19.745046 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.745160 13394 net.cpp:156] Memory required for data: 65029632
I0810 12:46:19.745286 13394 layer_factory.hpp:77] Creating layer ReLU1
I0810 12:46:19.745406 13394 net.cpp:91] Creating Layer ReLU1
I0810 12:46:19.745517 13394 net.cpp:425] ReLU1 <- InnerProduct1
I0810 12:46:19.745628 13394 net.cpp:386] ReLU1 -> InnerProduct1 (in-place)
I0810 12:46:19.745754 13394 net.cpp:141] Setting up ReLU1
I0810 12:46:19.745865 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.745973 13394 net.cpp:156] Memory required for data: 65046016
I0810 12:46:19.746161 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.746340 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.746448 13394 net.cpp:425] drop1 <- InnerProduct1
I0810 12:46:19.746562 13394 net.cpp:399] drop1 -> Dropout1
I0810 12:46:19.746681 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.746793 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.746860 13394 net.cpp:156] Memory required for data: 65062400
I0810 12:46:19.746883 13394 layer_factory.hpp:77] Creating layer InnerProduct2
I0810 12:46:19.746915 13394 net.cpp:91] Creating Layer InnerProduct2
I0810 12:46:19.746938 13394 net.cpp:425] InnerProduct2 <- Dropout1
I0810 12:46:19.746966 13394 net.cpp:399] InnerProduct2 -> InnerProduct2
I0810 12:46:19.747051 13394 net.cpp:141] Setting up InnerProduct2
I0810 12:46:19.747076 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.747097 13394 net.cpp:156] Memory required for data: 65078784
I0810 12:46:19.747125 13394 layer_factory.hpp:77] Creating layer ReLU2
I0810 12:46:19.747150 13394 net.cpp:91] Creating Layer ReLU2
I0810 12:46:19.747174 13394 net.cpp:425] ReLU2 <- InnerProduct2
I0810 12:46:19.747200 13394 net.cpp:386] ReLU2 -> InnerProduct2 (in-place)
I0810 12:46:19.747228 13394 net.cpp:141] Setting up ReLU2
I0810 12:46:19.747252 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.747287 13394 net.cpp:156] Memory required for data: 65095168
I0810 12:46:19.747313 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.747337 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.747361 13394 net.cpp:425] drop2 <- InnerProduct2
I0810 12:46:19.747387 13394 net.cpp:399] drop2 -> Dropout2
I0810 12:46:19.747416 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.747442 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.747463 13394 net.cpp:156] Memory required for data: 65111552
I0810 12:46:19.747485 13394 layer_factory.hpp:77] Creating layer m1
I0810 12:46:19.747515 13394 net.cpp:91] Creating Layer m1
I0810 12:46:19.747539 13394 net.cpp:425] m1 <- Dropout2
I0810 12:46:19.747565 13394 net.cpp:399] m1 -> m1
I0810 12:46:19.747604 13394 net.cpp:141] Setting up m1
I0810 12:46:19.747629 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.747653 13394 net.cpp:156] Memory required for data: 65111808
I0810 12:46:19.747680 13394 layer_factory.hpp:77] Creating layer Concat2
I0810 12:46:19.747706 13394 net.cpp:91] Creating Layer Concat2
I0810 12:46:19.747730 13394 net.cpp:425] Concat2 <- i1_i1_0_split_1
I0810 12:46:19.747755 13394 net.cpp:425] Concat2 <- i12
I0810 12:46:19.747781 13394 net.cpp:399] Concat2 -> Concat2
I0810 12:46:19.747810 13394 net.cpp:141] Setting up Concat2
I0810 12:46:19.747835 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.747859 13394 net.cpp:156] Memory required for data: 67208960
I0810 12:46:19.747880 13394 layer_factory.hpp:77] Creating layer InnerProduct3
I0810 12:46:19.747916 13394 net.cpp:91] Creating Layer InnerProduct3
I0810 12:46:19.747939 13394 net.cpp:425] InnerProduct3 <- Concat2
I0810 12:46:19.747967 13394 net.cpp:399] InnerProduct3 -> InnerProduct3
I0810 12:46:19.754503 13394 net.cpp:141] Setting up InnerProduct3
I0810 12:46:19.754528 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.754534 13394 net.cpp:156] Memory required for data: 67225344
I0810 12:46:19.754542 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.754551 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.754559 13394 layer_factory.hpp:77] Creating layer ReLU3
I0810 12:46:19.754570 13394 net.cpp:91] Creating Layer ReLU3
I0810 12:46:19.754580 13394 net.cpp:425] ReLU3 <- InnerProduct3
I0810 12:46:19.754593 13394 net.cpp:386] ReLU3 -> InnerProduct3 (in-place)
I0810 12:46:19.754606 13394 net.cpp:141] Setting up ReLU3
I0810 12:46:19.754616 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.754622 13394 net.cpp:156] Memory required for data: 67241728
I0810 12:46:19.754629 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.754659 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.754667 13394 net.cpp:425] drop1 <- InnerProduct3
I0810 12:46:19.754678 13394 net.cpp:399] drop1 -> Dropout3
I0810 12:46:19.754693 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.754701 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.754709 13394 net.cpp:156] Memory required for data: 67258112
I0810 12:46:19.754715 13394 layer_factory.hpp:77] Creating layer InnerProduct4
I0810 12:46:19.754727 13394 net.cpp:91] Creating Layer InnerProduct4
I0810 12:46:19.754734 13394 net.cpp:425] InnerProduct4 <- Dropout3
I0810 12:46:19.754750 13394 net.cpp:399] InnerProduct4 -> InnerProduct4
I0810 12:46:19.754823 13394 net.cpp:141] Setting up InnerProduct4
I0810 12:46:19.754833 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.754840 13394 net.cpp:156] Memory required for data: 67274496
I0810 12:46:19.754850 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.754858 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.754864 13394 layer_factory.hpp:77] Creating layer ReLU4
I0810 12:46:19.754873 13394 net.cpp:91] Creating Layer ReLU4
I0810 12:46:19.754879 13394 net.cpp:425] ReLU4 <- InnerProduct4
I0810 12:46:19.754889 13394 net.cpp:386] ReLU4 -> InnerProduct4 (in-place)
I0810 12:46:19.754897 13394 net.cpp:141] Setting up ReLU4
I0810 12:46:19.754906 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.754912 13394 net.cpp:156] Memory required for data: 67290880
I0810 12:46:19.754919 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.754930 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.754937 13394 net.cpp:425] drop2 <- InnerProduct4
I0810 12:46:19.754947 13394 net.cpp:399] drop2 -> Dropout4
I0810 12:46:19.754959 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.754967 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.754973 13394 net.cpp:156] Memory required for data: 67307264
I0810 12:46:19.754979 13394 layer_factory.hpp:77] Creating layer m2
I0810 12:46:19.754989 13394 net.cpp:91] Creating Layer m2
I0810 12:46:19.754997 13394 net.cpp:425] m2 <- Dropout4
I0810 12:46:19.755009 13394 net.cpp:399] m2 -> m2
I0810 12:46:19.755029 13394 net.cpp:141] Setting up m2
I0810 12:46:19.755038 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.755044 13394 net.cpp:156] Memory required for data: 67307520
I0810 12:46:19.755051 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.755059 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.755065 13394 layer_factory.hpp:77] Creating layer Concat3
I0810 12:46:19.755074 13394 net.cpp:91] Creating Layer Concat3
I0810 12:46:19.755081 13394 net.cpp:425] Concat3 <- i1_i1_0_split_2
I0810 12:46:19.755090 13394 net.cpp:425] Concat3 <- i13
I0810 12:46:19.755100 13394 net.cpp:399] Concat3 -> Concat3
I0810 12:46:19.755111 13394 net.cpp:141] Setting up Concat3
I0810 12:46:19.755120 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.755126 13394 net.cpp:156] Memory required for data: 69404672
I0810 12:46:19.755133 13394 layer_factory.hpp:77] Creating layer InnerProduct5
I0810 12:46:19.755146 13394 net.cpp:91] Creating Layer InnerProduct5
I0810 12:46:19.755152 13394 net.cpp:425] InnerProduct5 <- Concat3
I0810 12:46:19.755162 13394 net.cpp:399] InnerProduct5 -> InnerProduct5
I0810 12:46:19.763165 13394 net.cpp:141] Setting up InnerProduct5
I0810 12:46:19.763190 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.763198 13394 net.cpp:156] Memory required for data: 69421056
I0810 12:46:19.763207 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.763216 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.763222 13394 layer_factory.hpp:77] Creating layer ReLU5
I0810 12:46:19.763237 13394 net.cpp:91] Creating Layer ReLU5
I0810 12:46:19.763245 13394 net.cpp:425] ReLU5 <- InnerProduct5
I0810 12:46:19.763286 13394 net.cpp:386] ReLU5 -> InnerProduct5 (in-place)
I0810 12:46:19.763299 13394 net.cpp:141] Setting up ReLU5
I0810 12:46:19.763309 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.763314 13394 net.cpp:156] Memory required for data: 69437440
I0810 12:46:19.763321 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.763335 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.763342 13394 net.cpp:425] drop1 <- InnerProduct5
I0810 12:46:19.763352 13394 net.cpp:399] drop1 -> Dropout5
I0810 12:46:19.763365 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.763375 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.763381 13394 net.cpp:156] Memory required for data: 69453824
I0810 12:46:19.763386 13394 layer_factory.hpp:77] Creating layer InnerProduct6
I0810 12:46:19.763401 13394 net.cpp:91] Creating Layer InnerProduct6
I0810 12:46:19.763407 13394 net.cpp:425] InnerProduct6 <- Dropout5
I0810 12:46:19.763418 13394 net.cpp:399] InnerProduct6 -> InnerProduct6
I0810 12:46:19.763496 13394 net.cpp:141] Setting up InnerProduct6
I0810 12:46:19.763504 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.763510 13394 net.cpp:156] Memory required for data: 69470208
I0810 12:46:19.763517 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.763525 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.763531 13394 layer_factory.hpp:77] Creating layer ReLU6
I0810 12:46:19.763540 13394 net.cpp:91] Creating Layer ReLU6
I0810 12:46:19.763546 13394 net.cpp:425] ReLU6 <- InnerProduct6
I0810 12:46:19.763558 13394 net.cpp:386] ReLU6 -> InnerProduct6 (in-place)
I0810 12:46:19.763568 13394 net.cpp:141] Setting up ReLU6
I0810 12:46:19.763576 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.763582 13394 net.cpp:156] Memory required for data: 69486592
I0810 12:46:19.763588 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.763597 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.763603 13394 net.cpp:425] drop2 <- InnerProduct6
I0810 12:46:19.763613 13394 net.cpp:399] drop2 -> Dropout6
I0810 12:46:19.763625 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.763633 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.763639 13394 net.cpp:156] Memory required for data: 69502976
I0810 12:46:19.763645 13394 layer_factory.hpp:77] Creating layer m3
I0810 12:46:19.763655 13394 net.cpp:91] Creating Layer m3
I0810 12:46:19.763661 13394 net.cpp:425] m3 <- Dropout6
I0810 12:46:19.763674 13394 net.cpp:399] m3 -> m3
I0810 12:46:19.763706 13394 net.cpp:141] Setting up m3
I0810 12:46:19.763718 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.763725 13394 net.cpp:156] Memory required for data: 69503232
I0810 12:46:19.763736 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.763746 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.763751 13394 layer_factory.hpp:77] Creating layer Concat4
I0810 12:46:19.763761 13394 net.cpp:91] Creating Layer Concat4
I0810 12:46:19.763768 13394 net.cpp:425] Concat4 <- i1_i1_0_split_3
I0810 12:46:19.763777 13394 net.cpp:425] Concat4 <- i14
I0810 12:46:19.763787 13394 net.cpp:399] Concat4 -> Concat4
I0810 12:46:19.763798 13394 net.cpp:141] Setting up Concat4
I0810 12:46:19.763808 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.763813 13394 net.cpp:156] Memory required for data: 71600384
I0810 12:46:19.763823 13394 layer_factory.hpp:77] Creating layer InnerProduct7
I0810 12:46:19.763842 13394 net.cpp:91] Creating Layer InnerProduct7
I0810 12:46:19.763849 13394 net.cpp:425] InnerProduct7 <- Concat4
I0810 12:46:19.763862 13394 net.cpp:399] InnerProduct7 -> InnerProduct7
I0810 12:46:19.769325 13394 net.cpp:141] Setting up InnerProduct7
I0810 12:46:19.769346 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.769354 13394 net.cpp:156] Memory required for data: 71616768
I0810 12:46:19.769364 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.769415 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.769426 13394 layer_factory.hpp:77] Creating layer ReLU7
I0810 12:46:19.769438 13394 net.cpp:91] Creating Layer ReLU7
I0810 12:46:19.769451 13394 net.cpp:425] ReLU7 <- InnerProduct7
I0810 12:46:19.769469 13394 net.cpp:386] ReLU7 -> InnerProduct7 (in-place)
I0810 12:46:19.769485 13394 net.cpp:141] Setting up ReLU7
I0810 12:46:19.769500 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.769511 13394 net.cpp:156] Memory required for data: 71633152
I0810 12:46:19.769518 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.769532 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.769542 13394 net.cpp:425] drop1 <- InnerProduct7
I0810 12:46:19.769561 13394 net.cpp:399] drop1 -> Dropout7
I0810 12:46:19.769578 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.769590 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.769600 13394 net.cpp:156] Memory required for data: 71649536
I0810 12:46:19.769608 13394 layer_factory.hpp:77] Creating layer InnerProduct8
I0810 12:46:19.769623 13394 net.cpp:91] Creating Layer InnerProduct8
I0810 12:46:19.769632 13394 net.cpp:425] InnerProduct8 <- Dropout7
I0810 12:46:19.769647 13394 net.cpp:399] InnerProduct8 -> InnerProduct8
I0810 12:46:19.769722 13394 net.cpp:141] Setting up InnerProduct8
I0810 12:46:19.769734 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.769743 13394 net.cpp:156] Memory required for data: 71665920
I0810 12:46:19.769754 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.769767 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.769775 13394 layer_factory.hpp:77] Creating layer ReLU8
I0810 12:46:19.769788 13394 net.cpp:91] Creating Layer ReLU8
I0810 12:46:19.769798 13394 net.cpp:425] ReLU8 <- InnerProduct8
I0810 12:46:19.769812 13394 net.cpp:386] ReLU8 -> InnerProduct8 (in-place)
I0810 12:46:19.769825 13394 net.cpp:141] Setting up ReLU8
I0810 12:46:19.769837 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.769847 13394 net.cpp:156] Memory required for data: 71682304
I0810 12:46:19.769855 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.769868 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.769878 13394 net.cpp:425] drop2 <- InnerProduct8
I0810 12:46:19.769889 13394 net.cpp:399] drop2 -> Dropout8
I0810 12:46:19.769906 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.769917 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.769927 13394 net.cpp:156] Memory required for data: 71698688
I0810 12:46:19.769935 13394 layer_factory.hpp:77] Creating layer m4
I0810 12:46:19.769949 13394 net.cpp:91] Creating Layer m4
I0810 12:46:19.769959 13394 net.cpp:425] m4 <- Dropout8
I0810 12:46:19.769974 13394 net.cpp:399] m4 -> m4
I0810 12:46:19.769999 13394 net.cpp:141] Setting up m4
I0810 12:46:19.770010 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.770020 13394 net.cpp:156] Memory required for data: 71698944
I0810 12:46:19.770030 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.770041 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.770051 13394 layer_factory.hpp:77] Creating layer Concat5
I0810 12:46:19.770064 13394 net.cpp:91] Creating Layer Concat5
I0810 12:46:19.770073 13394 net.cpp:425] Concat5 <- i1_i1_0_split_4
I0810 12:46:19.770083 13394 net.cpp:425] Concat5 <- i15
I0810 12:46:19.770097 13394 net.cpp:399] Concat5 -> Concat5
I0810 12:46:19.770113 13394 net.cpp:141] Setting up Concat5
I0810 12:46:19.770126 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.770135 13394 net.cpp:156] Memory required for data: 73796096
I0810 12:46:19.770146 13394 layer_factory.hpp:77] Creating layer InnerProduct9
I0810 12:46:19.770162 13394 net.cpp:91] Creating Layer InnerProduct9
I0810 12:46:19.770172 13394 net.cpp:425] InnerProduct9 <- Concat5
I0810 12:46:19.770198 13394 net.cpp:399] InnerProduct9 -> InnerProduct9
I0810 12:46:19.775758 13394 net.cpp:141] Setting up InnerProduct9
I0810 12:46:19.775781 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.775789 13394 net.cpp:156] Memory required for data: 73812480
I0810 12:46:19.775799 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.775812 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.775823 13394 layer_factory.hpp:77] Creating layer ReLU9
I0810 12:46:19.775840 13394 net.cpp:91] Creating Layer ReLU9
I0810 12:46:19.775851 13394 net.cpp:425] ReLU9 <- InnerProduct9
I0810 12:46:19.775866 13394 net.cpp:386] ReLU9 -> InnerProduct9 (in-place)
I0810 12:46:19.775882 13394 net.cpp:141] Setting up ReLU9
I0810 12:46:19.775893 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.775903 13394 net.cpp:156] Memory required for data: 73828864
I0810 12:46:19.775910 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.775926 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.775936 13394 net.cpp:425] drop1 <- InnerProduct9
I0810 12:46:19.775949 13394 net.cpp:399] drop1 -> Dropout9
I0810 12:46:19.775966 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.775977 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.775988 13394 net.cpp:156] Memory required for data: 73845248
I0810 12:46:19.775995 13394 layer_factory.hpp:77] Creating layer InnerProduct10
I0810 12:46:19.776015 13394 net.cpp:91] Creating Layer InnerProduct10
I0810 12:46:19.776024 13394 net.cpp:425] InnerProduct10 <- Dropout9
I0810 12:46:19.776039 13394 net.cpp:399] InnerProduct10 -> InnerProduct10
I0810 12:46:19.776113 13394 net.cpp:141] Setting up InnerProduct10
I0810 12:46:19.776124 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.776134 13394 net.cpp:156] Memory required for data: 73861632
I0810 12:46:19.776141 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.776152 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.776161 13394 layer_factory.hpp:77] Creating layer ReLU10
I0810 12:46:19.776171 13394 net.cpp:91] Creating Layer ReLU10
I0810 12:46:19.776181 13394 net.cpp:425] ReLU10 <- InnerProduct10
I0810 12:46:19.776195 13394 net.cpp:386] ReLU10 -> InnerProduct10 (in-place)
I0810 12:46:19.776208 13394 net.cpp:141] Setting up ReLU10
I0810 12:46:19.776221 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.776231 13394 net.cpp:156] Memory required for data: 73878016
I0810 12:46:19.776237 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.776250 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.776260 13394 net.cpp:425] drop2 <- InnerProduct10
I0810 12:46:19.776274 13394 net.cpp:399] drop2 -> Dropout10
I0810 12:46:19.776290 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.776302 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.776312 13394 net.cpp:156] Memory required for data: 73894400
I0810 12:46:19.776320 13394 layer_factory.hpp:77] Creating layer m5
I0810 12:46:19.776335 13394 net.cpp:91] Creating Layer m5
I0810 12:46:19.776345 13394 net.cpp:425] m5 <- Dropout10
I0810 12:46:19.776360 13394 net.cpp:399] m5 -> m5
I0810 12:46:19.776384 13394 net.cpp:141] Setting up m5
I0810 12:46:19.776396 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.776404 13394 net.cpp:156] Memory required for data: 73894656
I0810 12:46:19.776412 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.776423 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.776433 13394 layer_factory.hpp:77] Creating layer Concat6
I0810 12:46:19.776446 13394 net.cpp:91] Creating Layer Concat6
I0810 12:46:19.776456 13394 net.cpp:425] Concat6 <- i1_i1_0_split_5
I0810 12:46:19.776466 13394 net.cpp:425] Concat6 <- i16
I0810 12:46:19.776482 13394 net.cpp:399] Concat6 -> Concat6
I0810 12:46:19.776499 13394 net.cpp:141] Setting up Concat6
I0810 12:46:19.776527 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.776538 13394 net.cpp:156] Memory required for data: 75991808
I0810 12:46:19.776546 13394 layer_factory.hpp:77] Creating layer InnerProduct11
I0810 12:46:19.776561 13394 net.cpp:91] Creating Layer InnerProduct11
I0810 12:46:19.776569 13394 net.cpp:425] InnerProduct11 <- Concat6
I0810 12:46:19.776582 13394 net.cpp:399] InnerProduct11 -> InnerProduct11
I0810 12:46:19.781965 13394 net.cpp:141] Setting up InnerProduct11
I0810 12:46:19.781986 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.781994 13394 net.cpp:156] Memory required for data: 76008192
I0810 12:46:19.782032 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.782043 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.782054 13394 layer_factory.hpp:77] Creating layer ReLU11
I0810 12:46:19.782069 13394 net.cpp:91] Creating Layer ReLU11
I0810 12:46:19.782080 13394 net.cpp:425] ReLU11 <- InnerProduct11
I0810 12:46:19.782095 13394 net.cpp:386] ReLU11 -> InnerProduct11 (in-place)
I0810 12:46:19.782110 13394 net.cpp:141] Setting up ReLU11
I0810 12:46:19.782122 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.782131 13394 net.cpp:156] Memory required for data: 76024576
I0810 12:46:19.782140 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.782152 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.782162 13394 net.cpp:425] drop1 <- InnerProduct11
I0810 12:46:19.782174 13394 net.cpp:399] drop1 -> Dropout11
I0810 12:46:19.782192 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.782203 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.782213 13394 net.cpp:156] Memory required for data: 76040960
I0810 12:46:19.782220 13394 layer_factory.hpp:77] Creating layer InnerProduct12
I0810 12:46:19.782240 13394 net.cpp:91] Creating Layer InnerProduct12
I0810 12:46:19.782250 13394 net.cpp:425] InnerProduct12 <- Dropout11
I0810 12:46:19.782265 13394 net.cpp:399] InnerProduct12 -> InnerProduct12
I0810 12:46:19.782337 13394 net.cpp:141] Setting up InnerProduct12
I0810 12:46:19.782349 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.782358 13394 net.cpp:156] Memory required for data: 76057344
I0810 12:46:19.782379 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.782390 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.782400 13394 layer_factory.hpp:77] Creating layer ReLU12
I0810 12:46:19.782413 13394 net.cpp:91] Creating Layer ReLU12
I0810 12:46:19.782423 13394 net.cpp:425] ReLU12 <- InnerProduct12
I0810 12:46:19.782433 13394 net.cpp:386] ReLU12 -> InnerProduct12 (in-place)
I0810 12:46:19.782446 13394 net.cpp:141] Setting up ReLU12
I0810 12:46:19.782459 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.782469 13394 net.cpp:156] Memory required for data: 76073728
I0810 12:46:19.782476 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.782490 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.782500 13394 net.cpp:425] drop2 <- InnerProduct12
I0810 12:46:19.782516 13394 net.cpp:399] drop2 -> Dropout12
I0810 12:46:19.782532 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.782546 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.782554 13394 net.cpp:156] Memory required for data: 76090112
I0810 12:46:19.782562 13394 layer_factory.hpp:77] Creating layer m6
I0810 12:46:19.782577 13394 net.cpp:91] Creating Layer m6
I0810 12:46:19.782587 13394 net.cpp:425] m6 <- Dropout12
I0810 12:46:19.782598 13394 net.cpp:399] m6 -> m6
I0810 12:46:19.782624 13394 net.cpp:141] Setting up m6
I0810 12:46:19.782636 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.782645 13394 net.cpp:156] Memory required for data: 76090368
I0810 12:46:19.782654 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.782663 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.782686 13394 layer_factory.hpp:77] Creating layer Concat7
I0810 12:46:19.782697 13394 net.cpp:91] Creating Layer Concat7
I0810 12:46:19.782707 13394 net.cpp:425] Concat7 <- i1_i1_0_split_6
I0810 12:46:19.782716 13394 net.cpp:425] Concat7 <- i17
I0810 12:46:19.782729 13394 net.cpp:399] Concat7 -> Concat7
I0810 12:46:19.782747 13394 net.cpp:141] Setting up Concat7
I0810 12:46:19.782758 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.782768 13394 net.cpp:156] Memory required for data: 78187520
I0810 12:46:19.782775 13394 layer_factory.hpp:77] Creating layer InnerProduct13
I0810 12:46:19.782789 13394 net.cpp:91] Creating Layer InnerProduct13
I0810 12:46:19.782799 13394 net.cpp:425] InnerProduct13 <- Concat7
I0810 12:46:19.782815 13394 net.cpp:399] InnerProduct13 -> InnerProduct13
I0810 12:46:19.788178 13394 net.cpp:141] Setting up InnerProduct13
I0810 12:46:19.788203 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.788210 13394 net.cpp:156] Memory required for data: 78203904
I0810 12:46:19.788219 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.788231 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.788242 13394 layer_factory.hpp:77] Creating layer ReLU13
I0810 12:46:19.788254 13394 net.cpp:91] Creating Layer ReLU13
I0810 12:46:19.788265 13394 net.cpp:425] ReLU13 <- InnerProduct13
I0810 12:46:19.788280 13394 net.cpp:386] ReLU13 -> InnerProduct13 (in-place)
I0810 12:46:19.788295 13394 net.cpp:141] Setting up ReLU13
I0810 12:46:19.788307 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.788316 13394 net.cpp:156] Memory required for data: 78220288
I0810 12:46:19.788326 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.788342 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.788353 13394 net.cpp:425] drop1 <- InnerProduct13
I0810 12:46:19.788365 13394 net.cpp:399] drop1 -> Dropout13
I0810 12:46:19.788383 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.788399 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.788408 13394 net.cpp:156] Memory required for data: 78236672
I0810 12:46:19.788416 13394 layer_factory.hpp:77] Creating layer InnerProduct14
I0810 12:46:19.788431 13394 net.cpp:91] Creating Layer InnerProduct14
I0810 12:46:19.788442 13394 net.cpp:425] InnerProduct14 <- Dropout13
I0810 12:46:19.788457 13394 net.cpp:399] InnerProduct14 -> InnerProduct14
I0810 12:46:19.788548 13394 net.cpp:141] Setting up InnerProduct14
I0810 12:46:19.788564 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.788574 13394 net.cpp:156] Memory required for data: 78253056
I0810 12:46:19.788583 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.788594 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.788604 13394 layer_factory.hpp:77] Creating layer ReLU14
I0810 12:46:19.788615 13394 net.cpp:91] Creating Layer ReLU14
I0810 12:46:19.788625 13394 net.cpp:425] ReLU14 <- InnerProduct14
I0810 12:46:19.788635 13394 net.cpp:386] ReLU14 -> InnerProduct14 (in-place)
I0810 12:46:19.788648 13394 net.cpp:141] Setting up ReLU14
I0810 12:46:19.788661 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.788671 13394 net.cpp:156] Memory required for data: 78269440
I0810 12:46:19.788678 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.788691 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.788727 13394 net.cpp:425] drop2 <- InnerProduct14
I0810 12:46:19.788748 13394 net.cpp:399] drop2 -> Dropout14
I0810 12:46:19.788765 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.788776 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.788785 13394 net.cpp:156] Memory required for data: 78285824
I0810 12:46:19.788794 13394 layer_factory.hpp:77] Creating layer m7
I0810 12:46:19.788805 13394 net.cpp:91] Creating Layer m7
I0810 12:46:19.788815 13394 net.cpp:425] m7 <- Dropout14
I0810 12:46:19.788828 13394 net.cpp:399] m7 -> m7
I0810 12:46:19.788873 13394 net.cpp:141] Setting up m7
I0810 12:46:19.788887 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.788895 13394 net.cpp:156] Memory required for data: 78286080
I0810 12:46:19.788907 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.788918 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.788928 13394 layer_factory.hpp:77] Creating layer Concat8
I0810 12:46:19.788939 13394 net.cpp:91] Creating Layer Concat8
I0810 12:46:19.788949 13394 net.cpp:425] Concat8 <- i1_i1_0_split_7
I0810 12:46:19.788959 13394 net.cpp:425] Concat8 <- i18
I0810 12:46:19.788974 13394 net.cpp:399] Concat8 -> Concat8
I0810 12:46:19.788990 13394 net.cpp:141] Setting up Concat8
I0810 12:46:19.789003 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.791316 13394 net.cpp:156] Memory required for data: 80383232
I0810 12:46:19.791326 13394 layer_factory.hpp:77] Creating layer InnerProduct15
I0810 12:46:19.791365 13394 net.cpp:91] Creating Layer InnerProduct15
I0810 12:46:19.791374 13394 net.cpp:425] InnerProduct15 <- Concat8
I0810 12:46:19.791388 13394 net.cpp:399] InnerProduct15 -> InnerProduct15
I0810 12:46:19.797130 13394 net.cpp:141] Setting up InnerProduct15
I0810 12:46:19.797153 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.797160 13394 net.cpp:156] Memory required for data: 80399616
I0810 12:46:19.797169 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.797178 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.797186 13394 layer_factory.hpp:77] Creating layer ReLU15
I0810 12:46:19.797197 13394 net.cpp:91] Creating Layer ReLU15
I0810 12:46:19.797205 13394 net.cpp:425] ReLU15 <- InnerProduct15
I0810 12:46:19.797219 13394 net.cpp:386] ReLU15 -> InnerProduct15 (in-place)
I0810 12:46:19.797230 13394 net.cpp:141] Setting up ReLU15
I0810 12:46:19.797240 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.797245 13394 net.cpp:156] Memory required for data: 80416000
I0810 12:46:19.797253 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.797264 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.797272 13394 net.cpp:425] drop1 <- InnerProduct15
I0810 12:46:19.797284 13394 net.cpp:399] drop1 -> Dropout15
I0810 12:46:19.797302 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.797310 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.797320 13394 net.cpp:156] Memory required for data: 80432384
I0810 12:46:19.797327 13394 layer_factory.hpp:77] Creating layer InnerProduct16
I0810 12:46:19.797343 13394 net.cpp:91] Creating Layer InnerProduct16
I0810 12:46:19.797353 13394 net.cpp:425] InnerProduct16 <- Dropout15
I0810 12:46:19.797366 13394 net.cpp:399] InnerProduct16 -> InnerProduct16
I0810 12:46:19.797431 13394 net.cpp:141] Setting up InnerProduct16
I0810 12:46:19.797442 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.797448 13394 net.cpp:156] Memory required for data: 80448768
I0810 12:46:19.797456 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.797463 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.797471 13394 layer_factory.hpp:77] Creating layer ReLU16
I0810 12:46:19.797482 13394 net.cpp:91] Creating Layer ReLU16
I0810 12:46:19.797488 13394 net.cpp:425] ReLU16 <- InnerProduct16
I0810 12:46:19.797499 13394 net.cpp:386] ReLU16 -> InnerProduct16 (in-place)
I0810 12:46:19.797513 13394 net.cpp:141] Setting up ReLU16
I0810 12:46:19.797528 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.797534 13394 net.cpp:156] Memory required for data: 80465152
I0810 12:46:19.797544 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.797554 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.797560 13394 net.cpp:425] drop2 <- InnerProduct16
I0810 12:46:19.797570 13394 net.cpp:399] drop2 -> Dropout16
I0810 12:46:19.797585 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.797621 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.797627 13394 net.cpp:156] Memory required for data: 80481536
I0810 12:46:19.797637 13394 layer_factory.hpp:77] Creating layer m8
I0810 12:46:19.797652 13394 net.cpp:91] Creating Layer m8
I0810 12:46:19.797662 13394 net.cpp:425] m8 <- Dropout16
I0810 12:46:19.797672 13394 net.cpp:399] m8 -> m8
I0810 12:46:19.797698 13394 net.cpp:141] Setting up m8
I0810 12:46:19.797709 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.797716 13394 net.cpp:156] Memory required for data: 80481792
I0810 12:46:19.797727 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.797735 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.797744 13394 layer_factory.hpp:77] Creating layer Concat9
I0810 12:46:19.797755 13394 net.cpp:91] Creating Layer Concat9
I0810 12:46:19.797765 13394 net.cpp:425] Concat9 <- i1_i1_0_split_8
I0810 12:46:19.797775 13394 net.cpp:425] Concat9 <- i19
I0810 12:46:19.797793 13394 net.cpp:399] Concat9 -> Concat9
I0810 12:46:19.797809 13394 net.cpp:141] Setting up Concat9
I0810 12:46:19.797821 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.797830 13394 net.cpp:156] Memory required for data: 82578944
I0810 12:46:19.797838 13394 layer_factory.hpp:77] Creating layer InnerProduct17
I0810 12:46:19.797852 13394 net.cpp:91] Creating Layer InnerProduct17
I0810 12:46:19.797860 13394 net.cpp:425] InnerProduct17 <- Concat9
I0810 12:46:19.797871 13394 net.cpp:399] InnerProduct17 -> InnerProduct17
I0810 12:46:19.803134 13394 net.cpp:141] Setting up InnerProduct17
I0810 12:46:19.803156 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.803163 13394 net.cpp:156] Memory required for data: 82595328
I0810 12:46:19.803170 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.803182 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.803189 13394 layer_factory.hpp:77] Creating layer ReLU17
I0810 12:46:19.803202 13394 net.cpp:91] Creating Layer ReLU17
I0810 12:46:19.803213 13394 net.cpp:425] ReLU17 <- InnerProduct17
I0810 12:46:19.803226 13394 net.cpp:386] ReLU17 -> InnerProduct17 (in-place)
I0810 12:46:19.803243 13394 net.cpp:141] Setting up ReLU17
I0810 12:46:19.803256 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.803266 13394 net.cpp:156] Memory required for data: 82611712
I0810 12:46:19.803278 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.803288 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.803299 13394 net.cpp:425] drop1 <- InnerProduct17
I0810 12:46:19.803311 13394 net.cpp:399] drop1 -> Dropout17
I0810 12:46:19.803330 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.803341 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.803347 13394 net.cpp:156] Memory required for data: 82628096
I0810 12:46:19.803356 13394 layer_factory.hpp:77] Creating layer InnerProduct18
I0810 12:46:19.803370 13394 net.cpp:91] Creating Layer InnerProduct18
I0810 12:46:19.803380 13394 net.cpp:425] InnerProduct18 <- Dropout17
I0810 12:46:19.803397 13394 net.cpp:399] InnerProduct18 -> InnerProduct18
I0810 12:46:19.803468 13394 net.cpp:141] Setting up InnerProduct18
I0810 12:46:19.803481 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.803491 13394 net.cpp:156] Memory required for data: 82644480
I0810 12:46:19.803500 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.803510 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.803517 13394 layer_factory.hpp:77] Creating layer ReLU18
I0810 12:46:19.803534 13394 net.cpp:91] Creating Layer ReLU18
I0810 12:46:19.803542 13394 net.cpp:425] ReLU18 <- InnerProduct18
I0810 12:46:19.803551 13394 net.cpp:386] ReLU18 -> InnerProduct18 (in-place)
I0810 12:46:19.803565 13394 net.cpp:141] Setting up ReLU18
I0810 12:46:19.803573 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.803601 13394 net.cpp:156] Memory required for data: 82660864
I0810 12:46:19.803607 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.803622 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.803632 13394 net.cpp:425] drop2 <- InnerProduct18
I0810 12:46:19.803643 13394 net.cpp:399] drop2 -> Dropout18
I0810 12:46:19.803659 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.803671 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.803681 13394 net.cpp:156] Memory required for data: 82677248
I0810 12:46:19.803692 13394 layer_factory.hpp:77] Creating layer m9
I0810 12:46:19.803707 13394 net.cpp:91] Creating Layer m9
I0810 12:46:19.803716 13394 net.cpp:425] m9 <- Dropout18
I0810 12:46:19.803726 13394 net.cpp:399] m9 -> m9
I0810 12:46:19.803747 13394 net.cpp:141] Setting up m9
I0810 12:46:19.803756 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.803762 13394 net.cpp:156] Memory required for data: 82677504
I0810 12:46:19.803769 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.803777 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.803784 13394 layer_factory.hpp:77] Creating layer Concat10
I0810 12:46:19.803798 13394 net.cpp:91] Creating Layer Concat10
I0810 12:46:19.803805 13394 net.cpp:425] Concat10 <- i1_i1_0_split_9
I0810 12:46:19.803814 13394 net.cpp:425] Concat10 <- i20
I0810 12:46:19.803825 13394 net.cpp:399] Concat10 -> Concat10
I0810 12:46:19.803840 13394 net.cpp:141] Setting up Concat10
I0810 12:46:19.803849 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.803856 13394 net.cpp:156] Memory required for data: 84774656
I0810 12:46:19.803864 13394 layer_factory.hpp:77] Creating layer InnerProduct19
I0810 12:46:19.803875 13394 net.cpp:91] Creating Layer InnerProduct19
I0810 12:46:19.803884 13394 net.cpp:425] InnerProduct19 <- Concat10
I0810 12:46:19.803895 13394 net.cpp:399] InnerProduct19 -> InnerProduct19
I0810 12:46:19.811077 13394 net.cpp:141] Setting up InnerProduct19
I0810 12:46:19.811095 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.811103 13394 net.cpp:156] Memory required for data: 84791040
I0810 12:46:19.811112 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.811120 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.811128 13394 layer_factory.hpp:77] Creating layer ReLU19
I0810 12:46:19.811142 13394 net.cpp:91] Creating Layer ReLU19
I0810 12:46:19.811151 13394 net.cpp:425] ReLU19 <- InnerProduct19
I0810 12:46:19.811162 13394 net.cpp:386] ReLU19 -> InnerProduct19 (in-place)
I0810 12:46:19.811175 13394 net.cpp:141] Setting up ReLU19
I0810 12:46:19.811184 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.811192 13394 net.cpp:156] Memory required for data: 84807424
I0810 12:46:19.811200 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.811210 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.811218 13394 net.cpp:425] drop1 <- InnerProduct19
I0810 12:46:19.811231 13394 net.cpp:399] drop1 -> Dropout19
I0810 12:46:19.811245 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.811254 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.811259 13394 net.cpp:156] Memory required for data: 84823808
I0810 12:46:19.811266 13394 layer_factory.hpp:77] Creating layer InnerProduct20
I0810 12:46:19.811286 13394 net.cpp:91] Creating Layer InnerProduct20
I0810 12:46:19.811293 13394 net.cpp:425] InnerProduct20 <- Dropout19
I0810 12:46:19.811306 13394 net.cpp:399] InnerProduct20 -> InnerProduct20
I0810 12:46:19.811375 13394 net.cpp:141] Setting up InnerProduct20
I0810 12:46:19.811385 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.811393 13394 net.cpp:156] Memory required for data: 84840192
I0810 12:46:19.811403 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.811410 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.811434 13394 layer_factory.hpp:77] Creating layer ReLU20
I0810 12:46:19.811444 13394 net.cpp:91] Creating Layer ReLU20
I0810 12:46:19.811450 13394 net.cpp:425] ReLU20 <- InnerProduct20
I0810 12:46:19.811462 13394 net.cpp:386] ReLU20 -> InnerProduct20 (in-place)
I0810 12:46:19.811472 13394 net.cpp:141] Setting up ReLU20
I0810 12:46:19.811481 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.811487 13394 net.cpp:156] Memory required for data: 84856576
I0810 12:46:19.811496 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.811506 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.811514 13394 net.cpp:425] drop2 <- InnerProduct20
I0810 12:46:19.811524 13394 net.cpp:399] drop2 -> Dropout20
I0810 12:46:19.811538 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.811549 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.811555 13394 net.cpp:156] Memory required for data: 84872960
I0810 12:46:19.811563 13394 layer_factory.hpp:77] Creating layer m10
I0810 12:46:19.811578 13394 net.cpp:91] Creating Layer m10
I0810 12:46:19.811584 13394 net.cpp:425] m10 <- Dropout20
I0810 12:46:19.811595 13394 net.cpp:399] m10 -> m10
I0810 12:46:19.811617 13394 net.cpp:141] Setting up m10
I0810 12:46:19.811628 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.811635 13394 net.cpp:156] Memory required for data: 84873216
I0810 12:46:19.811642 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.811650 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.811656 13394 layer_factory.hpp:77] Creating layer Concat11
I0810 12:46:19.811666 13394 net.cpp:91] Creating Layer Concat11
I0810 12:46:19.811672 13394 net.cpp:425] Concat11 <- i2
I0810 12:46:19.811681 13394 net.cpp:425] Concat11 <- i11_i1_10_split_1
I0810 12:46:19.811691 13394 net.cpp:399] Concat11 -> Concat11
I0810 12:46:19.811702 13394 net.cpp:141] Setting up Concat11
I0810 12:46:19.811710 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.811717 13394 net.cpp:156] Memory required for data: 86970368
I0810 12:46:19.811723 13394 layer_factory.hpp:77] Creating layer InnerProduct21
I0810 12:46:19.811733 13394 net.cpp:91] Creating Layer InnerProduct21
I0810 12:46:19.811739 13394 net.cpp:425] InnerProduct21 <- Concat11
I0810 12:46:19.811753 13394 net.cpp:399] InnerProduct21 -> InnerProduct21
I0810 12:46:19.816946 13394 net.cpp:141] Setting up InnerProduct21
I0810 12:46:19.816963 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.816970 13394 net.cpp:156] Memory required for data: 86986752
I0810 12:46:19.816978 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.816987 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.816993 13394 layer_factory.hpp:77] Creating layer ReLU21
I0810 12:46:19.817004 13394 net.cpp:91] Creating Layer ReLU21
I0810 12:46:19.817013 13394 net.cpp:425] ReLU21 <- InnerProduct21
I0810 12:46:19.817023 13394 net.cpp:386] ReLU21 -> InnerProduct21 (in-place)
I0810 12:46:19.817034 13394 net.cpp:141] Setting up ReLU21
I0810 12:46:19.817044 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.817050 13394 net.cpp:156] Memory required for data: 87003136
I0810 12:46:19.817057 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.817072 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.817080 13394 net.cpp:425] drop1 <- InnerProduct21
I0810 12:46:19.817090 13394 net.cpp:399] drop1 -> Dropout21
I0810 12:46:19.817103 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.817111 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.817117 13394 net.cpp:156] Memory required for data: 87019520
I0810 12:46:19.817123 13394 layer_factory.hpp:77] Creating layer InnerProduct22
I0810 12:46:19.817137 13394 net.cpp:91] Creating Layer InnerProduct22
I0810 12:46:19.817145 13394 net.cpp:425] InnerProduct22 <- Dropout21
I0810 12:46:19.817157 13394 net.cpp:399] InnerProduct22 -> InnerProduct22
I0810 12:46:19.817226 13394 net.cpp:141] Setting up InnerProduct22
I0810 12:46:19.817252 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.817260 13394 net.cpp:156] Memory required for data: 87035904
I0810 12:46:19.817267 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.817276 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.817284 13394 layer_factory.hpp:77] Creating layer ReLU22
I0810 12:46:19.817296 13394 net.cpp:91] Creating Layer ReLU22
I0810 12:46:19.817303 13394 net.cpp:425] ReLU22 <- InnerProduct22
I0810 12:46:19.817312 13394 net.cpp:386] ReLU22 -> InnerProduct22 (in-place)
I0810 12:46:19.817322 13394 net.cpp:141] Setting up ReLU22
I0810 12:46:19.817330 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.817337 13394 net.cpp:156] Memory required for data: 87052288
I0810 12:46:19.817343 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.817353 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.817360 13394 net.cpp:425] drop2 <- InnerProduct22
I0810 12:46:19.817373 13394 net.cpp:399] drop2 -> Dropout22
I0810 12:46:19.817385 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.817394 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.817402 13394 net.cpp:156] Memory required for data: 87068672
I0810 12:46:19.817410 13394 layer_factory.hpp:77] Creating layer m11
I0810 12:46:19.817421 13394 net.cpp:91] Creating Layer m11
I0810 12:46:19.817430 13394 net.cpp:425] m11 <- Dropout22
I0810 12:46:19.817440 13394 net.cpp:399] m11 -> m11
I0810 12:46:19.817462 13394 net.cpp:141] Setting up m11
I0810 12:46:19.817471 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.817476 13394 net.cpp:156] Memory required for data: 87068928
I0810 12:46:19.817504 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.817513 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.817520 13394 layer_factory.hpp:77] Creating layer Concat12
I0810 12:46:19.817534 13394 net.cpp:91] Creating Layer Concat12
I0810 12:46:19.817543 13394 net.cpp:425] Concat12 <- i3
I0810 12:46:19.817553 13394 net.cpp:425] Concat12 <- i11_i1_10_split_2
I0810 12:46:19.817564 13394 net.cpp:399] Concat12 -> Concat12
I0810 12:46:19.817576 13394 net.cpp:141] Setting up Concat12
I0810 12:46:19.817586 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.817594 13394 net.cpp:156] Memory required for data: 89166080
I0810 12:46:19.817600 13394 layer_factory.hpp:77] Creating layer InnerProduct23
I0810 12:46:19.817613 13394 net.cpp:91] Creating Layer InnerProduct23
I0810 12:46:19.817620 13394 net.cpp:425] InnerProduct23 <- Concat12
I0810 12:46:19.817632 13394 net.cpp:399] InnerProduct23 -> InnerProduct23
I0810 12:46:19.826068 13394 net.cpp:141] Setting up InnerProduct23
I0810 12:46:19.826094 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.826102 13394 net.cpp:156] Memory required for data: 89182464
I0810 12:46:19.826112 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.826123 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.826134 13394 layer_factory.hpp:77] Creating layer ReLU23
I0810 12:46:19.826150 13394 net.cpp:91] Creating Layer ReLU23
I0810 12:46:19.826162 13394 net.cpp:425] ReLU23 <- InnerProduct23
I0810 12:46:19.826182 13394 net.cpp:386] ReLU23 -> InnerProduct23 (in-place)
I0810 12:46:19.826200 13394 net.cpp:141] Setting up ReLU23
I0810 12:46:19.826212 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.826222 13394 net.cpp:156] Memory required for data: 89198848
I0810 12:46:19.826232 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.826242 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.826253 13394 net.cpp:425] drop1 <- InnerProduct23
I0810 12:46:19.826264 13394 net.cpp:399] drop1 -> Dropout23
I0810 12:46:19.826278 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.826292 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.826320 13394 net.cpp:156] Memory required for data: 89215232
I0810 12:46:19.826328 13394 layer_factory.hpp:77] Creating layer InnerProduct24
I0810 12:46:19.826339 13394 net.cpp:91] Creating Layer InnerProduct24
I0810 12:46:19.826349 13394 net.cpp:425] InnerProduct24 <- Dropout23
I0810 12:46:19.826361 13394 net.cpp:399] InnerProduct24 -> InnerProduct24
I0810 12:46:19.826434 13394 net.cpp:141] Setting up InnerProduct24
I0810 12:46:19.826447 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.826455 13394 net.cpp:156] Memory required for data: 89231616
I0810 12:46:19.826463 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.826474 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.826485 13394 layer_factory.hpp:77] Creating layer ReLU24
I0810 12:46:19.826493 13394 net.cpp:91] Creating Layer ReLU24
I0810 12:46:19.826503 13394 net.cpp:425] ReLU24 <- InnerProduct24
I0810 12:46:19.826516 13394 net.cpp:386] ReLU24 -> InnerProduct24 (in-place)
I0810 12:46:19.826531 13394 net.cpp:141] Setting up ReLU24
I0810 12:46:19.826542 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.826552 13394 net.cpp:156] Memory required for data: 89248000
I0810 12:46:19.826560 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.826571 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.826581 13394 net.cpp:425] drop2 <- InnerProduct24
I0810 12:46:19.826596 13394 net.cpp:399] drop2 -> Dropout24
I0810 12:46:19.826611 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.826623 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.826630 13394 net.cpp:156] Memory required for data: 89264384
I0810 12:46:19.826640 13394 layer_factory.hpp:77] Creating layer m12
I0810 12:46:19.826654 13394 net.cpp:91] Creating Layer m12
I0810 12:46:19.826663 13394 net.cpp:425] m12 <- Dropout24
I0810 12:46:19.826674 13394 net.cpp:399] m12 -> m12
I0810 12:46:19.826699 13394 net.cpp:141] Setting up m12
I0810 12:46:19.826711 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.826720 13394 net.cpp:156] Memory required for data: 89264640
I0810 12:46:19.826728 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.826740 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.826750 13394 layer_factory.hpp:77] Creating layer Concat13
I0810 12:46:19.826762 13394 net.cpp:91] Creating Layer Concat13
I0810 12:46:19.826773 13394 net.cpp:425] Concat13 <- i4
I0810 12:46:19.826782 13394 net.cpp:425] Concat13 <- i11_i1_10_split_3
I0810 12:46:19.826795 13394 net.cpp:399] Concat13 -> Concat13
I0810 12:46:19.826812 13394 net.cpp:141] Setting up Concat13
I0810 12:46:19.826823 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.826834 13394 net.cpp:156] Memory required for data: 91361792
I0810 12:46:19.826844 13394 layer_factory.hpp:77] Creating layer InnerProduct25
I0810 12:46:19.826856 13394 net.cpp:91] Creating Layer InnerProduct25
I0810 12:46:19.826865 13394 net.cpp:425] InnerProduct25 <- Concat13
I0810 12:46:19.826876 13394 net.cpp:399] InnerProduct25 -> InnerProduct25
I0810 12:46:19.834173 13394 net.cpp:141] Setting up InnerProduct25
I0810 12:46:19.834271 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.834345 13394 net.cpp:156] Memory required for data: 91378176
I0810 12:46:19.834374 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.834401 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.834427 13394 layer_factory.hpp:77] Creating layer ReLU25
I0810 12:46:19.834460 13394 net.cpp:91] Creating Layer ReLU25
I0810 12:46:19.834486 13394 net.cpp:425] ReLU25 <- InnerProduct25
I0810 12:46:19.834513 13394 net.cpp:386] ReLU25 -> InnerProduct25 (in-place)
I0810 12:46:19.834552 13394 net.cpp:141] Setting up ReLU25
I0810 12:46:19.834578 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.834604 13394 net.cpp:156] Memory required for data: 91394560
I0810 12:46:19.834645 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.834771 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.834797 13394 net.cpp:425] drop1 <- InnerProduct25
I0810 12:46:19.834827 13394 net.cpp:399] drop1 -> Dropout25
I0810 12:46:19.834859 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.834878 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.834884 13394 net.cpp:156] Memory required for data: 91410944
I0810 12:46:19.834892 13394 layer_factory.hpp:77] Creating layer InnerProduct26
I0810 12:46:19.834905 13394 net.cpp:91] Creating Layer InnerProduct26
I0810 12:46:19.834913 13394 net.cpp:425] InnerProduct26 <- Dropout25
I0810 12:46:19.834923 13394 net.cpp:399] InnerProduct26 -> InnerProduct26
I0810 12:46:19.834990 13394 net.cpp:141] Setting up InnerProduct26
I0810 12:46:19.834997 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.835003 13394 net.cpp:156] Memory required for data: 91427328
I0810 12:46:19.835011 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.835018 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.835024 13394 layer_factory.hpp:77] Creating layer ReLU26
I0810 12:46:19.835033 13394 net.cpp:91] Creating Layer ReLU26
I0810 12:46:19.835039 13394 net.cpp:425] ReLU26 <- InnerProduct26
I0810 12:46:19.835052 13394 net.cpp:386] ReLU26 -> InnerProduct26 (in-place)
I0810 12:46:19.835062 13394 net.cpp:141] Setting up ReLU26
I0810 12:46:19.835070 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.835077 13394 net.cpp:156] Memory required for data: 91443712
I0810 12:46:19.835083 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.835091 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.835098 13394 net.cpp:425] drop2 <- InnerProduct26
I0810 12:46:19.835108 13394 net.cpp:399] drop2 -> Dropout26
I0810 12:46:19.835119 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.835127 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.835134 13394 net.cpp:156] Memory required for data: 91460096
I0810 12:46:19.835139 13394 layer_factory.hpp:77] Creating layer m13
I0810 12:46:19.835151 13394 net.cpp:91] Creating Layer m13
I0810 12:46:19.835158 13394 net.cpp:425] m13 <- Dropout26
I0810 12:46:19.835168 13394 net.cpp:399] m13 -> m13
I0810 12:46:19.835191 13394 net.cpp:141] Setting up m13
I0810 12:46:19.835199 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.835206 13394 net.cpp:156] Memory required for data: 91460352
I0810 12:46:19.835211 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.835219 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.835225 13394 layer_factory.hpp:77] Creating layer Concat14
I0810 12:46:19.835235 13394 net.cpp:91] Creating Layer Concat14
I0810 12:46:19.835242 13394 net.cpp:425] Concat14 <- i5
I0810 12:46:19.835250 13394 net.cpp:425] Concat14 <- i11_i1_10_split_4
I0810 12:46:19.835260 13394 net.cpp:399] Concat14 -> Concat14
I0810 12:46:19.835279 13394 net.cpp:141] Setting up Concat14
I0810 12:46:19.835289 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.835294 13394 net.cpp:156] Memory required for data: 93557504
I0810 12:46:19.835301 13394 layer_factory.hpp:77] Creating layer InnerProduct27
I0810 12:46:19.835311 13394 net.cpp:91] Creating Layer InnerProduct27
I0810 12:46:19.835319 13394 net.cpp:425] InnerProduct27 <- Concat14
I0810 12:46:19.835331 13394 net.cpp:399] InnerProduct27 -> InnerProduct27
I0810 12:46:19.841308 13394 net.cpp:141] Setting up InnerProduct27
I0810 12:46:19.841328 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.841336 13394 net.cpp:156] Memory required for data: 93573888
I0810 12:46:19.841344 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.841352 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.841359 13394 layer_factory.hpp:77] Creating layer ReLU27
I0810 12:46:19.841387 13394 net.cpp:91] Creating Layer ReLU27
I0810 12:46:19.841395 13394 net.cpp:425] ReLU27 <- InnerProduct27
I0810 12:46:19.841405 13394 net.cpp:386] ReLU27 -> InnerProduct27 (in-place)
I0810 12:46:19.841418 13394 net.cpp:141] Setting up ReLU27
I0810 12:46:19.841425 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.841433 13394 net.cpp:156] Memory required for data: 93590272
I0810 12:46:19.841439 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.841451 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.841459 13394 net.cpp:425] drop1 <- InnerProduct27
I0810 12:46:19.841469 13394 net.cpp:399] drop1 -> Dropout27
I0810 12:46:19.841482 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.841502 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.841518 13394 net.cpp:156] Memory required for data: 93606656
I0810 12:46:19.841531 13394 layer_factory.hpp:77] Creating layer InnerProduct28
I0810 12:46:19.841555 13394 net.cpp:91] Creating Layer InnerProduct28
I0810 12:46:19.841567 13394 net.cpp:425] InnerProduct28 <- Dropout27
I0810 12:46:19.841594 13394 net.cpp:399] InnerProduct28 -> InnerProduct28
I0810 12:46:19.841722 13394 net.cpp:141] Setting up InnerProduct28
I0810 12:46:19.841743 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.841758 13394 net.cpp:156] Memory required for data: 93623040
I0810 12:46:19.841774 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.841783 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.841789 13394 layer_factory.hpp:77] Creating layer ReLU28
I0810 12:46:19.841799 13394 net.cpp:91] Creating Layer ReLU28
I0810 12:46:19.841805 13394 net.cpp:425] ReLU28 <- InnerProduct28
I0810 12:46:19.841814 13394 net.cpp:386] ReLU28 -> InnerProduct28 (in-place)
I0810 12:46:19.841825 13394 net.cpp:141] Setting up ReLU28
I0810 12:46:19.841833 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.841840 13394 net.cpp:156] Memory required for data: 93639424
I0810 12:46:19.841845 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.841855 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.841861 13394 net.cpp:425] drop2 <- InnerProduct28
I0810 12:46:19.841869 13394 net.cpp:399] drop2 -> Dropout28
I0810 12:46:19.841881 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.841889 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.841895 13394 net.cpp:156] Memory required for data: 93655808
I0810 12:46:19.841902 13394 layer_factory.hpp:77] Creating layer m14
I0810 12:46:19.841915 13394 net.cpp:91] Creating Layer m14
I0810 12:46:19.841922 13394 net.cpp:425] m14 <- Dropout28
I0810 12:46:19.841931 13394 net.cpp:399] m14 -> m14
I0810 12:46:19.841954 13394 net.cpp:141] Setting up m14
I0810 12:46:19.841962 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.841969 13394 net.cpp:156] Memory required for data: 93656064
I0810 12:46:19.841975 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.841984 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.841989 13394 layer_factory.hpp:77] Creating layer Concat15
I0810 12:46:19.841998 13394 net.cpp:91] Creating Layer Concat15
I0810 12:46:19.842005 13394 net.cpp:425] Concat15 <- i6
I0810 12:46:19.842013 13394 net.cpp:425] Concat15 <- i11_i1_10_split_5
I0810 12:46:19.842025 13394 net.cpp:399] Concat15 -> Concat15
I0810 12:46:19.842037 13394 net.cpp:141] Setting up Concat15
I0810 12:46:19.842046 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.842052 13394 net.cpp:156] Memory required for data: 95753216
I0810 12:46:19.842058 13394 layer_factory.hpp:77] Creating layer InnerProduct29
I0810 12:46:19.842068 13394 net.cpp:91] Creating Layer InnerProduct29
I0810 12:46:19.842074 13394 net.cpp:425] InnerProduct29 <- Concat15
I0810 12:46:19.842087 13394 net.cpp:399] InnerProduct29 -> InnerProduct29
I0810 12:46:19.847399 13394 net.cpp:141] Setting up InnerProduct29
I0810 12:46:19.847439 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.847445 13394 net.cpp:156] Memory required for data: 95769600
I0810 12:46:19.847453 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.847461 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.847470 13394 layer_factory.hpp:77] Creating layer ReLU29
I0810 12:46:19.847479 13394 net.cpp:91] Creating Layer ReLU29
I0810 12:46:19.847486 13394 net.cpp:425] ReLU29 <- InnerProduct29
I0810 12:46:19.847496 13394 net.cpp:386] ReLU29 -> InnerProduct29 (in-place)
I0810 12:46:19.847508 13394 net.cpp:141] Setting up ReLU29
I0810 12:46:19.847517 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.847522 13394 net.cpp:156] Memory required for data: 95785984
I0810 12:46:19.847529 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.847542 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.847548 13394 net.cpp:425] drop1 <- InnerProduct29
I0810 12:46:19.847558 13394 net.cpp:399] drop1 -> Dropout29
I0810 12:46:19.847571 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.847579 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.847585 13394 net.cpp:156] Memory required for data: 95802368
I0810 12:46:19.847591 13394 layer_factory.hpp:77] Creating layer InnerProduct30
I0810 12:46:19.847604 13394 net.cpp:91] Creating Layer InnerProduct30
I0810 12:46:19.847611 13394 net.cpp:425] InnerProduct30 <- Dropout29
I0810 12:46:19.847621 13394 net.cpp:399] InnerProduct30 -> InnerProduct30
I0810 12:46:19.847684 13394 net.cpp:141] Setting up InnerProduct30
I0810 12:46:19.847692 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.847698 13394 net.cpp:156] Memory required for data: 95818752
I0810 12:46:19.847705 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.847712 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.847719 13394 layer_factory.hpp:77] Creating layer ReLU30
I0810 12:46:19.847729 13394 net.cpp:91] Creating Layer ReLU30
I0810 12:46:19.847736 13394 net.cpp:425] ReLU30 <- InnerProduct30
I0810 12:46:19.847744 13394 net.cpp:386] ReLU30 -> InnerProduct30 (in-place)
I0810 12:46:19.847754 13394 net.cpp:141] Setting up ReLU30
I0810 12:46:19.847762 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.847769 13394 net.cpp:156] Memory required for data: 95835136
I0810 12:46:19.847774 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.847784 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.847790 13394 net.cpp:425] drop2 <- InnerProduct30
I0810 12:46:19.847802 13394 net.cpp:399] drop2 -> Dropout30
I0810 12:46:19.847815 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.847822 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.847828 13394 net.cpp:156] Memory required for data: 95851520
I0810 12:46:19.847834 13394 layer_factory.hpp:77] Creating layer m15
I0810 12:46:19.847844 13394 net.cpp:91] Creating Layer m15
I0810 12:46:19.847851 13394 net.cpp:425] m15 <- Dropout30
I0810 12:46:19.847862 13394 net.cpp:399] m15 -> m15
I0810 12:46:19.847885 13394 net.cpp:141] Setting up m15
I0810 12:46:19.847893 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.847899 13394 net.cpp:156] Memory required for data: 95851776
I0810 12:46:19.847905 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.847913 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.847919 13394 layer_factory.hpp:77] Creating layer Concat16
I0810 12:46:19.847929 13394 net.cpp:91] Creating Layer Concat16
I0810 12:46:19.847935 13394 net.cpp:425] Concat16 <- i7
I0810 12:46:19.847944 13394 net.cpp:425] Concat16 <- i11_i1_10_split_6
I0810 12:46:19.847954 13394 net.cpp:399] Concat16 -> Concat16
I0810 12:46:19.847966 13394 net.cpp:141] Setting up Concat16
I0810 12:46:19.847975 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.847980 13394 net.cpp:156] Memory required for data: 97948928
I0810 12:46:19.847995 13394 layer_factory.hpp:77] Creating layer InnerProduct31
I0810 12:46:19.848048 13394 net.cpp:91] Creating Layer InnerProduct31
I0810 12:46:19.848055 13394 net.cpp:425] InnerProduct31 <- Concat16
I0810 12:46:19.848069 13394 net.cpp:399] InnerProduct31 -> InnerProduct31
I0810 12:46:19.857823 13394 net.cpp:141] Setting up InnerProduct31
I0810 12:46:19.857861 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.857868 13394 net.cpp:156] Memory required for data: 97965312
I0810 12:46:19.857878 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.857887 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.857897 13394 layer_factory.hpp:77] Creating layer ReLU31
I0810 12:46:19.857908 13394 net.cpp:91] Creating Layer ReLU31
I0810 12:46:19.857918 13394 net.cpp:425] ReLU31 <- InnerProduct31
I0810 12:46:19.857928 13394 net.cpp:386] ReLU31 -> InnerProduct31 (in-place)
I0810 12:46:19.857942 13394 net.cpp:141] Setting up ReLU31
I0810 12:46:19.857951 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.857957 13394 net.cpp:156] Memory required for data: 97981696
I0810 12:46:19.857964 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.857975 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.857981 13394 net.cpp:425] drop1 <- InnerProduct31
I0810 12:46:19.857995 13394 net.cpp:399] drop1 -> Dropout31
I0810 12:46:19.858009 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.858017 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.858026 13394 net.cpp:156] Memory required for data: 97998080
I0810 12:46:19.858032 13394 layer_factory.hpp:77] Creating layer InnerProduct32
I0810 12:46:19.858048 13394 net.cpp:91] Creating Layer InnerProduct32
I0810 12:46:19.858057 13394 net.cpp:425] InnerProduct32 <- Dropout31
I0810 12:46:19.858067 13394 net.cpp:399] InnerProduct32 -> InnerProduct32
I0810 12:46:19.858134 13394 net.cpp:141] Setting up InnerProduct32
I0810 12:46:19.858144 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.858150 13394 net.cpp:156] Memory required for data: 98014464
I0810 12:46:19.858158 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.858166 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.858175 13394 layer_factory.hpp:77] Creating layer ReLU32
I0810 12:46:19.858184 13394 net.cpp:91] Creating Layer ReLU32
I0810 12:46:19.858191 13394 net.cpp:425] ReLU32 <- InnerProduct32
I0810 12:46:19.858204 13394 net.cpp:386] ReLU32 -> InnerProduct32 (in-place)
I0810 12:46:19.858214 13394 net.cpp:141] Setting up ReLU32
I0810 12:46:19.858223 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.858229 13394 net.cpp:156] Memory required for data: 98030848
I0810 12:46:19.858237 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.858244 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.858252 13394 net.cpp:425] drop2 <- InnerProduct32
I0810 12:46:19.858263 13394 net.cpp:399] drop2 -> Dropout32
I0810 12:46:19.858275 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.858289 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.858296 13394 net.cpp:156] Memory required for data: 98047232
I0810 12:46:19.858304 13394 layer_factory.hpp:77] Creating layer m16
I0810 12:46:19.858314 13394 net.cpp:91] Creating Layer m16
I0810 12:46:19.858321 13394 net.cpp:425] m16 <- Dropout32
I0810 12:46:19.858333 13394 net.cpp:399] m16 -> m16
I0810 12:46:19.858358 13394 net.cpp:141] Setting up m16
I0810 12:46:19.858366 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.858373 13394 net.cpp:156] Memory required for data: 98047488
I0810 12:46:19.858379 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.858388 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.858395 13394 layer_factory.hpp:77] Creating layer Concat17
I0810 12:46:19.858405 13394 net.cpp:91] Creating Layer Concat17
I0810 12:46:19.858428 13394 net.cpp:425] Concat17 <- i8
I0810 12:46:19.858438 13394 net.cpp:425] Concat17 <- i11_i1_10_split_7
I0810 12:46:19.858448 13394 net.cpp:399] Concat17 -> Concat17
I0810 12:46:19.858461 13394 net.cpp:141] Setting up Concat17
I0810 12:46:19.858471 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.858479 13394 net.cpp:156] Memory required for data: 100144640
I0810 12:46:19.858485 13394 layer_factory.hpp:77] Creating layer InnerProduct33
I0810 12:46:19.858496 13394 net.cpp:91] Creating Layer InnerProduct33
I0810 12:46:19.858505 13394 net.cpp:425] InnerProduct33 <- Concat17
I0810 12:46:19.858520 13394 net.cpp:399] InnerProduct33 -> InnerProduct33
I0810 12:46:19.863837 13394 net.cpp:141] Setting up InnerProduct33
I0810 12:46:19.863857 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.863863 13394 net.cpp:156] Memory required for data: 100161024
I0810 12:46:19.863873 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.863883 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.863891 13394 layer_factory.hpp:77] Creating layer ReLU33
I0810 12:46:19.863903 13394 net.cpp:91] Creating Layer ReLU33
I0810 12:46:19.863911 13394 net.cpp:425] ReLU33 <- InnerProduct33
I0810 12:46:19.863921 13394 net.cpp:386] ReLU33 -> InnerProduct33 (in-place)
I0810 12:46:19.863936 13394 net.cpp:141] Setting up ReLU33
I0810 12:46:19.863945 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.863951 13394 net.cpp:156] Memory required for data: 100177408
I0810 12:46:19.863957 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.863972 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.863979 13394 net.cpp:425] drop1 <- InnerProduct33
I0810 12:46:19.863991 13394 net.cpp:399] drop1 -> Dropout33
I0810 12:46:19.864006 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.864013 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.864020 13394 net.cpp:156] Memory required for data: 100193792
I0810 12:46:19.864028 13394 layer_factory.hpp:77] Creating layer InnerProduct34
I0810 12:46:19.864043 13394 net.cpp:91] Creating Layer InnerProduct34
I0810 12:46:19.864050 13394 net.cpp:425] InnerProduct34 <- Dropout33
I0810 12:46:19.864064 13394 net.cpp:399] InnerProduct34 -> InnerProduct34
I0810 12:46:19.864132 13394 net.cpp:141] Setting up InnerProduct34
I0810 12:46:19.864146 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.864152 13394 net.cpp:156] Memory required for data: 100210176
I0810 12:46:19.864161 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.864169 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.864176 13394 layer_factory.hpp:77] Creating layer ReLU34
I0810 12:46:19.864186 13394 net.cpp:91] Creating Layer ReLU34
I0810 12:46:19.864192 13394 net.cpp:425] ReLU34 <- InnerProduct34
I0810 12:46:19.864202 13394 net.cpp:386] ReLU34 -> InnerProduct34 (in-place)
I0810 12:46:19.864212 13394 net.cpp:141] Setting up ReLU34
I0810 12:46:19.864222 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.864228 13394 net.cpp:156] Memory required for data: 100226560
I0810 12:46:19.864234 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.864244 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.864253 13394 net.cpp:425] drop2 <- InnerProduct34
I0810 12:46:19.864265 13394 net.cpp:399] drop2 -> Dropout34
I0810 12:46:19.864279 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.864289 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.864295 13394 net.cpp:156] Memory required for data: 100242944
I0810 12:46:19.864300 13394 layer_factory.hpp:77] Creating layer m17
I0810 12:46:19.864310 13394 net.cpp:91] Creating Layer m17
I0810 12:46:19.864316 13394 net.cpp:425] m17 <- Dropout34
I0810 12:46:19.864327 13394 net.cpp:399] m17 -> m17
I0810 12:46:19.864351 13394 net.cpp:141] Setting up m17
I0810 12:46:19.864358 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.864384 13394 net.cpp:156] Memory required for data: 100243200
I0810 12:46:19.864392 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.864400 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.864406 13394 layer_factory.hpp:77] Creating layer Concat18
I0810 12:46:19.864416 13394 net.cpp:91] Creating Layer Concat18
I0810 12:46:19.864423 13394 net.cpp:425] Concat18 <- i9
I0810 12:46:19.864433 13394 net.cpp:425] Concat18 <- i11_i1_10_split_8
I0810 12:46:19.864442 13394 net.cpp:399] Concat18 -> Concat18
I0810 12:46:19.864456 13394 net.cpp:141] Setting up Concat18
I0810 12:46:19.864466 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.864473 13394 net.cpp:156] Memory required for data: 102340352
I0810 12:46:19.864480 13394 layer_factory.hpp:77] Creating layer InnerProduct35
I0810 12:46:19.864490 13394 net.cpp:91] Creating Layer InnerProduct35
I0810 12:46:19.864498 13394 net.cpp:425] InnerProduct35 <- Concat18
I0810 12:46:19.864514 13394 net.cpp:399] InnerProduct35 -> InnerProduct35
I0810 12:46:19.873811 13394 net.cpp:141] Setting up InnerProduct35
I0810 12:46:19.873836 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.873844 13394 net.cpp:156] Memory required for data: 102356736
I0810 12:46:19.873857 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.873867 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.873877 13394 layer_factory.hpp:77] Creating layer ReLU35
I0810 12:46:19.873888 13394 net.cpp:91] Creating Layer ReLU35
I0810 12:46:19.873900 13394 net.cpp:425] ReLU35 <- InnerProduct35
I0810 12:46:19.873921 13394 net.cpp:386] ReLU35 -> InnerProduct35 (in-place)
I0810 12:46:19.873936 13394 net.cpp:141] Setting up ReLU35
I0810 12:46:19.873946 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.873953 13394 net.cpp:156] Memory required for data: 102373120
I0810 12:46:19.873961 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.873972 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.873981 13394 net.cpp:425] drop1 <- InnerProduct35
I0810 12:46:19.873997 13394 net.cpp:399] drop1 -> Dropout35
I0810 12:46:19.874012 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.874022 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.874030 13394 net.cpp:156] Memory required for data: 102389504
I0810 12:46:19.874037 13394 layer_factory.hpp:77] Creating layer InnerProduct36
I0810 12:46:19.874053 13394 net.cpp:91] Creating Layer InnerProduct36
I0810 12:46:19.874060 13394 net.cpp:425] InnerProduct36 <- Dropout35
I0810 12:46:19.874078 13394 net.cpp:399] InnerProduct36 -> InnerProduct36
I0810 12:46:19.874152 13394 net.cpp:141] Setting up InnerProduct36
I0810 12:46:19.874164 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.874171 13394 net.cpp:156] Memory required for data: 102405888
I0810 12:46:19.874179 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.874188 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.874196 13394 layer_factory.hpp:77] Creating layer ReLU36
I0810 12:46:19.874207 13394 net.cpp:91] Creating Layer ReLU36
I0810 12:46:19.874213 13394 net.cpp:425] ReLU36 <- InnerProduct36
I0810 12:46:19.874225 13394 net.cpp:386] ReLU36 -> InnerProduct36 (in-place)
I0810 12:46:19.874238 13394 net.cpp:141] Setting up ReLU36
I0810 12:46:19.874249 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.874256 13394 net.cpp:156] Memory required for data: 102422272
I0810 12:46:19.874264 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.874276 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.874284 13394 net.cpp:425] drop2 <- InnerProduct36
I0810 12:46:19.874296 13394 net.cpp:399] drop2 -> Dropout36
I0810 12:46:19.874313 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.874325 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.874354 13394 net.cpp:156] Memory required for data: 102438656
I0810 12:46:19.874363 13394 layer_factory.hpp:77] Creating layer m18
I0810 12:46:19.874377 13394 net.cpp:91] Creating Layer m18
I0810 12:46:19.874384 13394 net.cpp:425] m18 <- Dropout36
I0810 12:46:19.874397 13394 net.cpp:399] m18 -> m18
I0810 12:46:19.874428 13394 net.cpp:141] Setting up m18
I0810 12:46:19.874439 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.874445 13394 net.cpp:156] Memory required for data: 102438912
I0810 12:46:19.874454 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.874465 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.874472 13394 layer_factory.hpp:77] Creating layer Concat19
I0810 12:46:19.874482 13394 net.cpp:91] Creating Layer Concat19
I0810 12:46:19.874488 13394 net.cpp:425] Concat19 <- i10
I0810 12:46:19.874500 13394 net.cpp:425] Concat19 <- i11_i1_10_split_9
I0810 12:46:19.874512 13394 net.cpp:399] Concat19 -> Concat19
I0810 12:46:19.874529 13394 net.cpp:141] Setting up Concat19
I0810 12:46:19.874541 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:19.874547 13394 net.cpp:156] Memory required for data: 104536064
I0810 12:46:19.874555 13394 layer_factory.hpp:77] Creating layer InnerProduct37
I0810 12:46:19.874570 13394 net.cpp:91] Creating Layer InnerProduct37
I0810 12:46:19.874577 13394 net.cpp:425] InnerProduct37 <- Concat19
I0810 12:46:19.874589 13394 net.cpp:399] InnerProduct37 -> InnerProduct37
I0810 12:46:19.880071 13394 net.cpp:141] Setting up InnerProduct37
I0810 12:46:19.880095 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.880103 13394 net.cpp:156] Memory required for data: 104552448
I0810 12:46:19.880115 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:19.880125 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:19.880132 13394 layer_factory.hpp:77] Creating layer ReLU37
I0810 12:46:19.880143 13394 net.cpp:91] Creating Layer ReLU37
I0810 12:46:19.880152 13394 net.cpp:425] ReLU37 <- InnerProduct37
I0810 12:46:19.880169 13394 net.cpp:386] ReLU37 -> InnerProduct37 (in-place)
I0810 12:46:19.880184 13394 net.cpp:141] Setting up ReLU37
I0810 12:46:19.880195 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.880203 13394 net.cpp:156] Memory required for data: 104568832
I0810 12:46:19.880210 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:19.880221 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:19.880228 13394 net.cpp:425] drop1 <- InnerProduct37
I0810 12:46:19.880244 13394 net.cpp:399] drop1 -> Dropout37
I0810 12:46:19.880259 13394 net.cpp:141] Setting up drop1
I0810 12:46:19.880270 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.880278 13394 net.cpp:156] Memory required for data: 104585216
I0810 12:46:19.880286 13394 layer_factory.hpp:77] Creating layer InnerProduct38
I0810 12:46:19.880298 13394 net.cpp:91] Creating Layer InnerProduct38
I0810 12:46:19.880306 13394 net.cpp:425] InnerProduct38 <- Dropout37
I0810 12:46:19.880321 13394 net.cpp:399] InnerProduct38 -> InnerProduct38
I0810 12:46:19.880399 13394 net.cpp:141] Setting up InnerProduct38
I0810 12:46:19.880411 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.880419 13394 net.cpp:156] Memory required for data: 104601600
I0810 12:46:19.880426 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:19.880436 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:19.880445 13394 layer_factory.hpp:77] Creating layer ReLU38
I0810 12:46:19.880455 13394 net.cpp:91] Creating Layer ReLU38
I0810 12:46:19.880463 13394 net.cpp:425] ReLU38 <- InnerProduct38
I0810 12:46:19.880476 13394 net.cpp:386] ReLU38 -> InnerProduct38 (in-place)
I0810 12:46:19.880489 13394 net.cpp:141] Setting up ReLU38
I0810 12:46:19.880499 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.880506 13394 net.cpp:156] Memory required for data: 104617984
I0810 12:46:19.880534 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:19.880544 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:19.880551 13394 net.cpp:425] drop2 <- InnerProduct38
I0810 12:46:19.880563 13394 net.cpp:399] drop2 -> Dropout38
I0810 12:46:19.880579 13394 net.cpp:141] Setting up drop2
I0810 12:46:19.880590 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:19.880599 13394 net.cpp:156] Memory required for data: 104634368
I0810 12:46:19.880606 13394 layer_factory.hpp:77] Creating layer m19
I0810 12:46:19.880619 13394 net.cpp:91] Creating Layer m19
I0810 12:46:19.880625 13394 net.cpp:425] m19 <- Dropout38
I0810 12:46:19.880640 13394 net.cpp:399] m19 -> m19
I0810 12:46:19.880666 13394 net.cpp:141] Setting up m19
I0810 12:46:19.880677 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:19.880686 13394 net.cpp:156] Memory required for data: 104634624
I0810 12:46:19.880694 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:19.880703 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:19.880710 13394 layer_factory.hpp:77] Creating layer con
I0810 12:46:19.880723 13394 net.cpp:91] Creating Layer con
I0810 12:46:19.880730 13394 net.cpp:425] con <- m1
I0810 12:46:19.880741 13394 net.cpp:425] con <- m2
I0810 12:46:19.880753 13394 net.cpp:425] con <- m3
I0810 12:46:19.880762 13394 net.cpp:425] con <- m4
I0810 12:46:19.880771 13394 net.cpp:425] con <- m5
I0810 12:46:19.880781 13394 net.cpp:425] con <- m6
I0810 12:46:19.880789 13394 net.cpp:425] con <- m7
I0810 12:46:19.880797 13394 net.cpp:425] con <- m8
I0810 12:46:19.880805 13394 net.cpp:425] con <- m9
I0810 12:46:19.880815 13394 net.cpp:425] con <- m10
I0810 12:46:19.880823 13394 net.cpp:425] con <- m11
I0810 12:46:19.880833 13394 net.cpp:425] con <- m12
I0810 12:46:19.880843 13394 net.cpp:425] con <- m13
I0810 12:46:19.880851 13394 net.cpp:425] con <- m14
I0810 12:46:19.880859 13394 net.cpp:425] con <- m15
I0810 12:46:19.880867 13394 net.cpp:425] con <- m16
I0810 12:46:19.880875 13394 net.cpp:425] con <- m17
I0810 12:46:19.880884 13394 net.cpp:425] con <- m18
I0810 12:46:19.880892 13394 net.cpp:425] con <- m19
I0810 12:46:19.880913 13394 net.cpp:399] con -> con
I0810 12:46:19.880934 13394 net.cpp:141] Setting up con
I0810 12:46:19.880944 13394 net.cpp:148] Top shape: 64 19 (1216)
I0810 12:46:19.880951 13394 net.cpp:156] Memory required for data: 104639488
I0810 12:46:19.880959 13394 layer_factory.hpp:77] Creating layer r1
I0810 12:46:19.880972 13394 net.cpp:91] Creating Layer r1
I0810 12:46:19.880980 13394 net.cpp:425] r1 <- con
I0810 12:46:19.880991 13394 net.cpp:399] r1 -> r1
I0810 12:46:19.881016 13394 net.cpp:141] Setting up r1
I0810 12:46:19.881027 13394 net.cpp:148] Top shape: 64 1 1 19 (1216)
I0810 12:46:19.881036 13394 net.cpp:156] Memory required for data: 104644352
I0810 12:46:19.881043 13394 layer_factory.hpp:77] Creating layer p
I0810 12:46:19.881055 13394 net.cpp:91] Creating Layer p
I0810 12:46:19.881063 13394 net.cpp:425] p <- r1
I0810 12:46:19.881073 13394 net.cpp:399] p -> p
I0810 12:46:19.881099 13394 net.cpp:141] Setting up p
I0810 12:46:19.881109 13394 net.cpp:148] Top shape: 64 1 1 1 (64)
I0810 12:46:19.881119 13394 net.cpp:156] Memory required for data: 104644608
I0810 12:46:19.881125 13394 layer_factory.hpp:77] Creating layer r2
I0810 12:46:19.881141 13394 net.cpp:91] Creating Layer r2
I0810 12:46:19.881150 13394 net.cpp:425] r2 <- p
I0810 12:46:19.881162 13394 net.cpp:399] r2 -> r2
I0810 12:46:19.881177 13394 net.cpp:141] Setting up r2
I0810 12:46:19.881188 13394 net.cpp:148] Top shape: 64 1 1 1 (64)
I0810 12:46:19.881196 13394 net.cpp:156] Memory required for data: 104644864
I0810 12:46:19.881203 13394 layer_factory.hpp:77] Creating layer padL
I0810 12:46:19.881214 13394 net.cpp:91] Creating Layer padL
I0810 12:46:19.881224 13394 net.cpp:425] padL <- label_data_1_split_1
I0810 12:46:19.881237 13394 net.cpp:399] padL -> padL
I0810 12:46:19.881250 13394 net.cpp:141] Setting up padL
I0810 12:46:19.881259 13394 net.cpp:148] Top shape: 64 1 1 1 (64)
I0810 12:46:19.881280 13394 net.cpp:156] Memory required for data: 104645120
I0810 12:46:19.881289 13394 layer_factory.hpp:77] Creating layer pad
I0810 12:46:19.881305 13394 net.cpp:91] Creating Layer pad
I0810 12:46:19.881314 13394 net.cpp:425] pad <- r2
I0810 12:46:19.881325 13394 net.cpp:425] pad <- padL
I0810 12:46:19.881335 13394 net.cpp:399] pad -> pad
I0810 12:46:19.881348 13394 net.cpp:141] Setting up pad
I0810 12:46:19.881363 13394 net.cpp:148] Top shape: 64 2 1 1 (128)
I0810 12:46:19.881369 13394 net.cpp:156] Memory required for data: 104645632
I0810 12:46:19.881378 13394 layer_factory.hpp:77] Creating layer pad_pad_0_split
I0810 12:46:19.881388 13394 net.cpp:91] Creating Layer pad_pad_0_split
I0810 12:46:19.881397 13394 net.cpp:425] pad_pad_0_split <- pad
I0810 12:46:19.881407 13394 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_0
I0810 12:46:19.881420 13394 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_1
I0810 12:46:19.881434 13394 net.cpp:141] Setting up pad_pad_0_split
I0810 12:46:19.881445 13394 net.cpp:148] Top shape: 64 2 1 1 (128)
I0810 12:46:19.881454 13394 net.cpp:148] Top shape: 64 2 1 1 (128)
I0810 12:46:19.881460 13394 net.cpp:156] Memory required for data: 104646656
I0810 12:46:19.881466 13394 layer_factory.hpp:77] Creating layer loss
I0810 12:46:19.881481 13394 net.cpp:91] Creating Layer loss
I0810 12:46:19.881489 13394 net.cpp:425] loss <- pad_pad_0_split_0
I0810 12:46:19.881500 13394 net.cpp:425] loss <- th_th_0_split_0
I0810 12:46:19.881510 13394 net.cpp:399] loss -> loss
I0810 12:46:19.881527 13394 net.cpp:141] Setting up loss
I0810 12:46:19.881536 13394 net.cpp:148] Top shape: (1)
I0810 12:46:19.881543 13394 net.cpp:151]     with loss weight 1
I0810 12:46:19.881566 13394 net.cpp:156] Memory required for data: 104646660
I0810 12:46:19.881572 13394 layer_factory.hpp:77] Creating layer accuracy
I0810 12:46:19.881597 13394 net.cpp:91] Creating Layer accuracy
I0810 12:46:19.881605 13394 net.cpp:425] accuracy <- pad_pad_0_split_1
I0810 12:46:19.881614 13394 net.cpp:425] accuracy <- th_th_0_split_1
I0810 12:46:19.881626 13394 net.cpp:399] accuracy -> accuracy
I0810 12:46:19.881642 13394 net.cpp:141] Setting up accuracy
I0810 12:46:19.881651 13394 net.cpp:148] Top shape: (1)
I0810 12:46:19.881657 13394 net.cpp:156] Memory required for data: 104646664
I0810 12:46:19.881665 13394 net.cpp:219] accuracy does not need backward computation.
I0810 12:46:19.881674 13394 net.cpp:217] loss needs backward computation.
I0810 12:46:19.881682 13394 net.cpp:217] pad_pad_0_split needs backward computation.
I0810 12:46:19.881690 13394 net.cpp:217] pad needs backward computation.
I0810 12:46:19.881700 13394 net.cpp:219] padL does not need backward computation.
I0810 12:46:19.881708 13394 net.cpp:217] r2 needs backward computation.
I0810 12:46:19.881716 13394 net.cpp:217] p needs backward computation.
I0810 12:46:19.881726 13394 net.cpp:217] r1 needs backward computation.
I0810 12:46:19.881732 13394 net.cpp:217] con needs backward computation.
I0810 12:46:19.881749 13394 net.cpp:217] m19 needs backward computation.
I0810 12:46:19.881758 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.881767 13394 net.cpp:217] ReLU38 needs backward computation.
I0810 12:46:19.881775 13394 net.cpp:217] InnerProduct38 needs backward computation.
I0810 12:46:19.881783 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.881793 13394 net.cpp:217] ReLU37 needs backward computation.
I0810 12:46:19.881799 13394 net.cpp:217] InnerProduct37 needs backward computation.
I0810 12:46:19.881808 13394 net.cpp:219] Concat19 does not need backward computation.
I0810 12:46:19.881817 13394 net.cpp:217] m18 needs backward computation.
I0810 12:46:19.881824 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.881834 13394 net.cpp:217] ReLU36 needs backward computation.
I0810 12:46:19.881840 13394 net.cpp:217] InnerProduct36 needs backward computation.
I0810 12:46:19.881850 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.881856 13394 net.cpp:217] ReLU35 needs backward computation.
I0810 12:46:19.881877 13394 net.cpp:217] InnerProduct35 needs backward computation.
I0810 12:46:19.881887 13394 net.cpp:219] Concat18 does not need backward computation.
I0810 12:46:19.881897 13394 net.cpp:217] m17 needs backward computation.
I0810 12:46:19.881906 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.881916 13394 net.cpp:217] ReLU34 needs backward computation.
I0810 12:46:19.881922 13394 net.cpp:217] InnerProduct34 needs backward computation.
I0810 12:46:19.881932 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.881939 13394 net.cpp:217] ReLU33 needs backward computation.
I0810 12:46:19.881947 13394 net.cpp:217] InnerProduct33 needs backward computation.
I0810 12:46:19.881953 13394 net.cpp:219] Concat17 does not need backward computation.
I0810 12:46:19.881964 13394 net.cpp:217] m16 needs backward computation.
I0810 12:46:19.881973 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.881983 13394 net.cpp:217] ReLU32 needs backward computation.
I0810 12:46:19.881990 13394 net.cpp:217] InnerProduct32 needs backward computation.
I0810 12:46:19.881999 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882009 13394 net.cpp:217] ReLU31 needs backward computation.
I0810 12:46:19.882016 13394 net.cpp:217] InnerProduct31 needs backward computation.
I0810 12:46:19.882025 13394 net.cpp:219] Concat16 does not need backward computation.
I0810 12:46:19.882033 13394 net.cpp:217] m15 needs backward computation.
I0810 12:46:19.882041 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882050 13394 net.cpp:217] ReLU30 needs backward computation.
I0810 12:46:19.882060 13394 net.cpp:217] InnerProduct30 needs backward computation.
I0810 12:46:19.882068 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882077 13394 net.cpp:217] ReLU29 needs backward computation.
I0810 12:46:19.882086 13394 net.cpp:217] InnerProduct29 needs backward computation.
I0810 12:46:19.882094 13394 net.cpp:219] Concat15 does not need backward computation.
I0810 12:46:19.882103 13394 net.cpp:217] m14 needs backward computation.
I0810 12:46:19.882112 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882119 13394 net.cpp:217] ReLU28 needs backward computation.
I0810 12:46:19.882128 13394 net.cpp:217] InnerProduct28 needs backward computation.
I0810 12:46:19.882138 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882146 13394 net.cpp:217] ReLU27 needs backward computation.
I0810 12:46:19.882154 13394 net.cpp:217] InnerProduct27 needs backward computation.
I0810 12:46:19.882164 13394 net.cpp:219] Concat14 does not need backward computation.
I0810 12:46:19.882174 13394 net.cpp:217] m13 needs backward computation.
I0810 12:46:19.882181 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882189 13394 net.cpp:217] ReLU26 needs backward computation.
I0810 12:46:19.882196 13394 net.cpp:217] InnerProduct26 needs backward computation.
I0810 12:46:19.882205 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882215 13394 net.cpp:217] ReLU25 needs backward computation.
I0810 12:46:19.882222 13394 net.cpp:217] InnerProduct25 needs backward computation.
I0810 12:46:19.882232 13394 net.cpp:219] Concat13 does not need backward computation.
I0810 12:46:19.882242 13394 net.cpp:217] m12 needs backward computation.
I0810 12:46:19.882251 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882259 13394 net.cpp:217] ReLU24 needs backward computation.
I0810 12:46:19.882268 13394 net.cpp:217] InnerProduct24 needs backward computation.
I0810 12:46:19.882277 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882285 13394 net.cpp:217] ReLU23 needs backward computation.
I0810 12:46:19.882293 13394 net.cpp:217] InnerProduct23 needs backward computation.
I0810 12:46:19.882302 13394 net.cpp:219] Concat12 does not need backward computation.
I0810 12:46:19.882313 13394 net.cpp:217] m11 needs backward computation.
I0810 12:46:19.882324 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882345 13394 net.cpp:217] ReLU22 needs backward computation.
I0810 12:46:19.882354 13394 net.cpp:217] InnerProduct22 needs backward computation.
I0810 12:46:19.882364 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882371 13394 net.cpp:217] ReLU21 needs backward computation.
I0810 12:46:19.882378 13394 net.cpp:217] InnerProduct21 needs backward computation.
I0810 12:46:19.882387 13394 net.cpp:219] Concat11 does not need backward computation.
I0810 12:46:19.882398 13394 net.cpp:217] m10 needs backward computation.
I0810 12:46:19.882407 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882416 13394 net.cpp:217] ReLU20 needs backward computation.
I0810 12:46:19.882462 13394 net.cpp:217] InnerProduct20 needs backward computation.
I0810 12:46:19.882473 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882483 13394 net.cpp:217] ReLU19 needs backward computation.
I0810 12:46:19.882491 13394 net.cpp:217] InnerProduct19 needs backward computation.
I0810 12:46:19.882500 13394 net.cpp:219] Concat10 does not need backward computation.
I0810 12:46:19.882511 13394 net.cpp:217] m9 needs backward computation.
I0810 12:46:19.882520 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882529 13394 net.cpp:217] ReLU18 needs backward computation.
I0810 12:46:19.882535 13394 net.cpp:217] InnerProduct18 needs backward computation.
I0810 12:46:19.882544 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882553 13394 net.cpp:217] ReLU17 needs backward computation.
I0810 12:46:19.882560 13394 net.cpp:217] InnerProduct17 needs backward computation.
I0810 12:46:19.882571 13394 net.cpp:219] Concat9 does not need backward computation.
I0810 12:46:19.882581 13394 net.cpp:217] m8 needs backward computation.
I0810 12:46:19.882591 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882599 13394 net.cpp:217] ReLU16 needs backward computation.
I0810 12:46:19.882607 13394 net.cpp:217] InnerProduct16 needs backward computation.
I0810 12:46:19.882616 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882623 13394 net.cpp:217] ReLU15 needs backward computation.
I0810 12:46:19.882632 13394 net.cpp:217] InnerProduct15 needs backward computation.
I0810 12:46:19.882642 13394 net.cpp:219] Concat8 does not need backward computation.
I0810 12:46:19.882653 13394 net.cpp:217] m7 needs backward computation.
I0810 12:46:19.882663 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882670 13394 net.cpp:217] ReLU14 needs backward computation.
I0810 12:46:19.882678 13394 net.cpp:217] InnerProduct14 needs backward computation.
I0810 12:46:19.882688 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882696 13394 net.cpp:217] ReLU13 needs backward computation.
I0810 12:46:19.882704 13394 net.cpp:217] InnerProduct13 needs backward computation.
I0810 12:46:19.882714 13394 net.cpp:219] Concat7 does not need backward computation.
I0810 12:46:19.882724 13394 net.cpp:217] m6 needs backward computation.
I0810 12:46:19.882732 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882742 13394 net.cpp:217] ReLU12 needs backward computation.
I0810 12:46:19.882750 13394 net.cpp:217] InnerProduct12 needs backward computation.
I0810 12:46:19.882760 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882767 13394 net.cpp:217] ReLU11 needs backward computation.
I0810 12:46:19.882776 13394 net.cpp:217] InnerProduct11 needs backward computation.
I0810 12:46:19.882784 13394 net.cpp:219] Concat6 does not need backward computation.
I0810 12:46:19.882794 13394 net.cpp:217] m5 needs backward computation.
I0810 12:46:19.882802 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882810 13394 net.cpp:217] ReLU10 needs backward computation.
I0810 12:46:19.882818 13394 net.cpp:217] InnerProduct10 needs backward computation.
I0810 12:46:19.882828 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882836 13394 net.cpp:217] ReLU9 needs backward computation.
I0810 12:46:19.882858 13394 net.cpp:217] InnerProduct9 needs backward computation.
I0810 12:46:19.882868 13394 net.cpp:219] Concat5 does not need backward computation.
I0810 12:46:19.882879 13394 net.cpp:217] m4 needs backward computation.
I0810 12:46:19.882887 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882895 13394 net.cpp:217] ReLU8 needs backward computation.
I0810 12:46:19.882903 13394 net.cpp:217] InnerProduct8 needs backward computation.
I0810 12:46:19.882911 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882920 13394 net.cpp:217] ReLU7 needs backward computation.
I0810 12:46:19.882927 13394 net.cpp:217] InnerProduct7 needs backward computation.
I0810 12:46:19.882936 13394 net.cpp:219] Concat4 does not need backward computation.
I0810 12:46:19.882946 13394 net.cpp:217] m3 needs backward computation.
I0810 12:46:19.882954 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.882962 13394 net.cpp:217] ReLU6 needs backward computation.
I0810 12:46:19.882972 13394 net.cpp:217] InnerProduct6 needs backward computation.
I0810 12:46:19.882979 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.882988 13394 net.cpp:217] ReLU5 needs backward computation.
I0810 12:46:19.882997 13394 net.cpp:217] InnerProduct5 needs backward computation.
I0810 12:46:19.883008 13394 net.cpp:219] Concat3 does not need backward computation.
I0810 12:46:19.883023 13394 net.cpp:217] m2 needs backward computation.
I0810 12:46:19.883031 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.883039 13394 net.cpp:217] ReLU4 needs backward computation.
I0810 12:46:19.883047 13394 net.cpp:217] InnerProduct4 needs backward computation.
I0810 12:46:19.883056 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.883064 13394 net.cpp:217] ReLU3 needs backward computation.
I0810 12:46:19.883072 13394 net.cpp:217] InnerProduct3 needs backward computation.
I0810 12:46:19.883082 13394 net.cpp:219] Concat2 does not need backward computation.
I0810 12:46:19.883092 13394 net.cpp:217] m1 needs backward computation.
I0810 12:46:19.883101 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:19.883110 13394 net.cpp:217] ReLU2 needs backward computation.
I0810 12:46:19.883117 13394 net.cpp:217] InnerProduct2 needs backward computation.
I0810 12:46:19.883126 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:19.883134 13394 net.cpp:217] ReLU1 needs backward computation.
I0810 12:46:19.883142 13394 net.cpp:217] InnerProduct1 needs backward computation.
I0810 12:46:19.883152 13394 net.cpp:219] Concat1 does not need backward computation.
I0810 12:46:19.883163 13394 net.cpp:219] i11_i1_10_split does not need backward computation.
I0810 12:46:19.883175 13394 net.cpp:219] i1_i1_0_split does not need backward computation.
I0810 12:46:19.883188 13394 net.cpp:219] i1 does not need backward computation.
I0810 12:46:19.883198 13394 net.cpp:219] th_th_0_split does not need backward computation.
I0810 12:46:19.883206 13394 net.cpp:219] th does not need backward computation.
I0810 12:46:19.883215 13394 net.cpp:219] label_data_1_split does not need backward computation.
I0810 12:46:19.883225 13394 net.cpp:219] data does not need backward computation.
I0810 12:46:19.883232 13394 net.cpp:261] This network produces output accuracy
I0810 12:46:19.883240 13394 net.cpp:261] This network produces output loss
I0810 12:46:19.883646 13394 net.cpp:274] Network initialization done.
I0810 12:46:19.891876 13394 solver.cpp:181] Creating test net (#0) specified by test_net file: examples/scene/metNetTest.prototxt
I0810 12:46:19.893723 13394 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 1
    mirror: false
  }
  data_param {
    source: "/home/shaogangwang/Datasets/FeatsDB/featsTest1k"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "th"
  type: "Threshold"
  bottom: "label"
  top: "th"
  threshold_param {
    threshold: 0
  }
}
layer {
  name: "i1"
  type: "Slice"
  bottom: "data"
  top: "i1"
  top: "i2"
  top: "i3"
  top: "i4"
  top: "i5"
  top: "i6"
  top: "i7"
  top: "i8"
  top: "i9"
  top: "i10"
  top: "i11"
  top: "i12"
  top: "i13"
  top: "i14"
  top: "i15"
  top: "i16"
  top: "i17"
  top: "i18"
  top: "i19"
  top: "i20"
  slice_param {
    slice_dim: 2
    slice_point: 1
    slice_point: 2
    slice_point: 3
    slice_point: 4
    slice_point: 5
    slice_point: 6
    slice_point: 7
    slice_point: 8
    slice_point: 9
    slice_point: 10
    slice_point: 11
    slice_point: 12
    slice_point: 13
    slice_point: 14
    slice_point: 15
    slice_point: 16
    slice_point: 17
    slice_point: 18
    slice_point: 19
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "i1"
  bottom: "i11"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Concat1"
  top: "InnerProduct1"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct1"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "Dropout1"
  top: "InnerProduct2"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "InnerProduct2"
  top: "InnerProduct2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct2"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m1"
  type: "InnerProduct"
  bottom: "Dropout2"
  top: "m1"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "i1"
  bottom: "i12"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "Concat2"
  top: "InnerProduct3"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct3"
  top: "InnerProduct3"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct3"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "Dropout3"
  top: "InnerProduct4"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "InnerProduct4"
  top: "InnerProduct4"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct4"
  top: "Dropout4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m2"
  type: "InnerProduct"
  bottom: "Dropout4"
  top: "m2"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "i1"
  bottom: "i13"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct5"
  type: "InnerProduct"
  bottom: "Concat3"
  top: "InnerProduct5"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "InnerProduct5"
  top: "InnerProduct5"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct5"
  top: "Dropout5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct6"
  type: "InnerProduct"
  bottom: "Dropout5"
  top: "InnerProduct6"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "InnerProduct6"
  top: "InnerProduct6"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct6"
  top: "Dropout6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m3"
  type: "InnerProduct"
  bottom: "Dropout6"
  top: "m3"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "i1"
  bottom: "i14"
  top: "Concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct7"
  type: "InnerProduct"
  bottom: "Concat4"
  top: "InnerProduct7"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "InnerProduct7"
  top: "InnerProduct7"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct7"
  top: "Dropout7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct8"
  type: "InnerProduct"
  bottom: "Dropout7"
  top: "InnerProduct8"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "InnerProduct8"
  top: "InnerProduct8"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct8"
  top: "Dropout8"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m4"
  type: "InnerProduct"
  bottom: "Dropout8"
  top: "m4"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "i1"
  bottom: "i15"
  top: "Concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct9"
  type: "InnerProduct"
  bottom: "Concat5"
  top: "InnerProduct9"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "InnerProduct9"
  top: "InnerProduct9"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct9"
  top: "Dropout9"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct10"
  type: "InnerProduct"
  bottom: "Dropout9"
  top: "InnerProduct10"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "InnerProduct10"
  top: "InnerProduct10"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct10"
  top: "Dropout10"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m5"
  type: "InnerProduct"
  bottom: "Dropout10"
  top: "m5"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "i1"
  bottom: "i16"
  top: "Concat6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct11"
  type: "InnerProduct"
  bottom: "Concat6"
  top: "InnerProduct11"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "InnerProduct11"
  top: "InnerProduct11"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct11"
  top: "Dropout11"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct12"
  type: "InnerProduct"
  bottom: "Dropout11"
  top: "InnerProduct12"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "InnerProduct12"
  top: "InnerProduct12"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct12"
  top: "Dropout12"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m6"
  type: "InnerProduct"
  bottom: "Dropout12"
  top: "m6"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "i1"
  bottom: "i17"
  top: "Concat7"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct13"
  type: "InnerProduct"
  bottom: "Concat7"
  top: "InnerProduct13"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "InnerProduct13"
  top: "InnerProduct13"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct13"
  top: "Dropout13"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct14"
  type: "InnerProduct"
  bottom: "Dropout13"
  top: "InnerProduct14"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "InnerProduct14"
  top: "InnerProduct14"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct14"
  top: "Dropout14"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m7"
  type: "InnerProduct"
  bottom: "Dropout14"
  top: "m7"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "i1"
  bottom: "i18"
  top: "Concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct15"
  type: "InnerProduct"
  bottom: "Concat8"
  top: "InnerProduct15"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "InnerProduct15"
  top: "InnerProduct15"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct15"
  top: "Dropout15"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct16"
  type: "InnerProduct"
  bottom: "Dropout15"
  top: "InnerProduct16"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "InnerProduct16"
  top: "InnerProduct16"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct16"
  top: "Dropout16"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m8"
  type: "InnerProduct"
  bottom: "Dropout16"
  top: "m8"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "i1"
  bottom: "i19"
  top: "Concat9"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct17"
  type: "InnerProduct"
  bottom: "Concat9"
  top: "InnerProduct17"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "InnerProduct17"
  top: "InnerProduct17"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct17"
  top: "Dropout17"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct18"
  type: "InnerProduct"
  bottom: "Dropout17"
  top: "InnerProduct18"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "InnerProduct18"
  top: "InnerProduct18"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct18"
  top: "Dropout18"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m9"
  type: "InnerProduct"
  bottom: "Dropout18"
  top: "m9"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat10"
  type: "Concat"
  bottom: "i1"
  bottom: "i20"
  top: "Concat10"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct19"
  type: "InnerProduct"
  bottom: "Concat10"
  top: "InnerProduct19"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "InnerProduct19"
  top: "InnerProduct19"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct19"
  top: "Dropout19"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct20"
  type: "InnerProduct"
  bottom: "Dropout19"
  top: "InnerProduct20"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "InnerProduct20"
  top: "InnerProduct20"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct20"
  top: "Dropout20"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m10"
  type: "InnerProduct"
  bottom: "Dropout20"
  top: "m10"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat11"
  type: "Concat"
  bottom: "i2"
  bottom: "i11"
  top: "Concat11"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct21"
  type: "InnerProduct"
  bottom: "Concat11"
  top: "InnerProduct21"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "InnerProduct21"
  top: "InnerProduct21"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct21"
  top: "Dropout21"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct22"
  type: "InnerProduct"
  bottom: "Dropout21"
  top: "InnerProduct22"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "InnerProduct22"
  top: "InnerProduct22"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct22"
  top: "Dropout22"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m11"
  type: "InnerProduct"
  bottom: "Dropout22"
  top: "m11"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat12"
  type: "Concat"
  bottom: "i3"
  bottom: "i11"
  top: "Concat12"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct23"
  type: "InnerProduct"
  bottom: "Concat12"
  top: "InnerProduct23"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "InnerProduct23"
  top: "InnerProduct23"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct23"
  top: "Dropout23"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct24"
  type: "InnerProduct"
  bottom: "Dropout23"
  top: "InnerProduct24"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "InnerProduct24"
  top: "InnerProduct24"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct24"
  top: "Dropout24"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m12"
  type: "InnerProduct"
  bottom: "Dropout24"
  top: "m12"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat13"
  type: "Concat"
  bottom: "i4"
  bottom: "i11"
  top: "Concat13"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct25"
  type: "InnerProduct"
  bottom: "Concat13"
  top: "InnerProduct25"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "InnerProduct25"
  top: "InnerProduct25"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct25"
  top: "Dropout25"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct26"
  type: "InnerProduct"
  bottom: "Dropout25"
  top: "InnerProduct26"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "InnerProduct26"
  top: "InnerProduct26"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct26"
  top: "Dropout26"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m13"
  type: "InnerProduct"
  bottom: "Dropout26"
  top: "m13"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat14"
  type: "Concat"
  bottom: "i5"
  bottom: "i11"
  top: "Concat14"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct27"
  type: "InnerProduct"
  bottom: "Concat14"
  top: "InnerProduct27"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "InnerProduct27"
  top: "InnerProduct27"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct27"
  top: "Dropout27"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct28"
  type: "InnerProduct"
  bottom: "Dropout27"
  top: "InnerProduct28"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "InnerProduct28"
  top: "InnerProduct28"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct28"
  top: "Dropout28"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m14"
  type: "InnerProduct"
  bottom: "Dropout28"
  top: "m14"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat15"
  type: "Concat"
  bottom: "i6"
  bottom: "i11"
  top: "Concat15"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct29"
  type: "InnerProduct"
  bottom: "Concat15"
  top: "InnerProduct29"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "InnerProduct29"
  top: "InnerProduct29"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct29"
  top: "Dropout29"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct30"
  type: "InnerProduct"
  bottom: "Dropout29"
  top: "InnerProduct30"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "InnerProduct30"
  top: "InnerProduct30"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct30"
  top: "Dropout30"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m15"
  type: "InnerProduct"
  bottom: "Dropout30"
  top: "m15"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat16"
  type: "Concat"
  bottom: "i7"
  bottom: "i11"
  top: "Concat16"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct31"
  type: "InnerProduct"
  bottom: "Concat16"
  top: "InnerProduct31"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "InnerProduct31"
  top: "InnerProduct31"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct31"
  top: "Dropout31"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct32"
  type: "InnerProduct"
  bottom: "Dropout31"
  top: "InnerProduct32"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "InnerProduct32"
  top: "InnerProduct32"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct32"
  top: "Dropout32"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m16"
  type: "InnerProduct"
  bottom: "Dropout32"
  top: "m16"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat17"
  type: "Concat"
  bottom: "i8"
  bottom: "i11"
  top: "Concat17"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct33"
  type: "InnerProduct"
  bottom: "Concat17"
  top: "InnerProduct33"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "InnerProduct33"
  top: "InnerProduct33"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct33"
  top: "Dropout33"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct34"
  type: "InnerProduct"
  bottom: "Dropout33"
  top: "InnerProduct34"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "InnerProduct34"
  top: "InnerProduct34"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct34"
  top: "Dropout34"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m17"
  type: "InnerProduct"
  bottom: "Dropout34"
  top: "m17"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat18"
  type: "Concat"
  bottom: "i9"
  bottom: "i11"
  top: "Concat18"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct35"
  type: "InnerProduct"
  bottom: "Concat18"
  top: "InnerProduct35"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "InnerProduct35"
  top: "InnerProduct35"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct35"
  top: "Dropout35"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct36"
  type: "InnerProduct"
  bottom: "Dropout35"
  top: "InnerProduct36"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "InnerProduct36"
  top: "InnerProduct36"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct36"
  top: "Dropout36"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m18"
  type: "InnerProduct"
  bottom: "Dropout36"
  top: "m18"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat19"
  type: "Concat"
  bottom: "i10"
  bottom: "i11"
  top: "Concat19"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct37"
  type: "InnerProduct"
  bottom: "Concat19"
  top: "InnerProduct37"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU37"
  type: "ReLU"
  bottom: "InnerProd
I0810 12:46:19.894785 13394 layer_factory.hpp:77] Creating layer data
I0810 12:46:19.894915 13394 net.cpp:91] Creating Layer data
I0810 12:46:19.894927 13394 net.cpp:399] data -> data
I0810 12:46:19.894948 13394 net.cpp:399] data -> label
I0810 12:46:19.895790 13402 db_lmdb.cpp:35] Opened lmdb /home/shaogangwang/Datasets/FeatsDB/featsTest1k
I0810 12:46:19.942962 13394 data_layer.cpp:41] output data size: 64,1,20,4096
I0810 12:46:20.030019 13394 net.cpp:141] Setting up data
I0810 12:46:20.030063 13394 net.cpp:148] Top shape: 64 1 20 4096 (5242880)
I0810 12:46:20.030078 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:20.030086 13394 net.cpp:156] Memory required for data: 20971776
I0810 12:46:20.030099 13394 layer_factory.hpp:77] Creating layer label_data_1_split
I0810 12:46:20.030125 13394 net.cpp:91] Creating Layer label_data_1_split
I0810 12:46:20.030136 13394 net.cpp:425] label_data_1_split <- label
I0810 12:46:20.030151 13394 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0810 12:46:20.030174 13394 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0810 12:46:20.030195 13394 net.cpp:141] Setting up label_data_1_split
I0810 12:46:20.030207 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:20.030218 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:20.030225 13394 net.cpp:156] Memory required for data: 20972288
I0810 12:46:20.030233 13394 layer_factory.hpp:77] Creating layer th
I0810 12:46:20.030248 13394 net.cpp:91] Creating Layer th
I0810 12:46:20.030256 13394 net.cpp:425] th <- label_data_1_split_0
I0810 12:46:20.030267 13394 net.cpp:399] th -> th
I0810 12:46:20.030297 13394 net.cpp:141] Setting up th
I0810 12:46:20.030314 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:20.030333 13394 net.cpp:156] Memory required for data: 20972544
I0810 12:46:20.030347 13394 layer_factory.hpp:77] Creating layer th_th_0_split
I0810 12:46:20.030376 13394 net.cpp:91] Creating Layer th_th_0_split
I0810 12:46:20.030392 13394 net.cpp:425] th_th_0_split <- th
I0810 12:46:20.030416 13394 net.cpp:399] th_th_0_split -> th_th_0_split_0
I0810 12:46:20.030452 13394 net.cpp:399] th_th_0_split -> th_th_0_split_1
I0810 12:46:20.030481 13394 net.cpp:141] Setting up th_th_0_split
I0810 12:46:20.030493 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:20.030522 13394 net.cpp:148] Top shape: 64 (64)
I0810 12:46:20.030539 13394 net.cpp:156] Memory required for data: 20973056
I0810 12:46:20.030556 13394 layer_factory.hpp:77] Creating layer i1
I0810 12:46:20.030593 13394 net.cpp:91] Creating Layer i1
I0810 12:46:20.030608 13394 net.cpp:425] i1 <- data
I0810 12:46:20.030635 13394 net.cpp:399] i1 -> i1
I0810 12:46:20.030665 13394 net.cpp:399] i1 -> i2
I0810 12:46:20.030688 13394 net.cpp:399] i1 -> i3
I0810 12:46:20.030705 13394 net.cpp:399] i1 -> i4
I0810 12:46:20.030720 13394 net.cpp:399] i1 -> i5
I0810 12:46:20.030736 13394 net.cpp:399] i1 -> i6
I0810 12:46:20.030750 13394 net.cpp:399] i1 -> i7
I0810 12:46:20.030766 13394 net.cpp:399] i1 -> i8
I0810 12:46:20.030781 13394 net.cpp:399] i1 -> i9
I0810 12:46:20.030796 13394 net.cpp:399] i1 -> i10
I0810 12:46:20.030812 13394 net.cpp:399] i1 -> i11
I0810 12:46:20.030828 13394 net.cpp:399] i1 -> i12
I0810 12:46:20.030843 13394 net.cpp:399] i1 -> i13
I0810 12:46:20.030890 13394 net.cpp:399] i1 -> i14
I0810 12:46:20.030905 13394 net.cpp:399] i1 -> i15
I0810 12:46:20.030920 13394 net.cpp:399] i1 -> i16
I0810 12:46:20.030935 13394 net.cpp:399] i1 -> i17
I0810 12:46:20.030951 13394 net.cpp:399] i1 -> i18
I0810 12:46:20.030971 13394 net.cpp:399] i1 -> i19
I0810 12:46:20.030988 13394 net.cpp:399] i1 -> i20
I0810 12:46:20.031028 13394 net.cpp:141] Setting up i1
I0810 12:46:20.031038 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031047 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031056 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031066 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031075 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031085 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031095 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031105 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031113 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031123 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031132 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031141 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031150 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031159 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031168 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031177 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031185 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031194 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031203 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031213 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031219 13394 net.cpp:156] Memory required for data: 41944576
I0810 12:46:20.031226 13394 layer_factory.hpp:77] Creating layer i1_i1_0_split
I0810 12:46:20.031239 13394 net.cpp:91] Creating Layer i1_i1_0_split
I0810 12:46:20.031247 13394 net.cpp:425] i1_i1_0_split <- i1
I0810 12:46:20.031258 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_0
I0810 12:46:20.031283 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_1
I0810 12:46:20.031301 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_2
I0810 12:46:20.031316 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_3
I0810 12:46:20.031329 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_4
I0810 12:46:20.031344 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_5
I0810 12:46:20.031365 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_6
I0810 12:46:20.031379 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_7
I0810 12:46:20.031393 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_8
I0810 12:46:20.031407 13394 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_9
I0810 12:46:20.031430 13394 net.cpp:141] Setting up i1_i1_0_split
I0810 12:46:20.031438 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031447 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031456 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031466 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031474 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031484 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031493 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031502 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031512 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031522 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031528 13394 net.cpp:156] Memory required for data: 52430336
I0810 12:46:20.031536 13394 layer_factory.hpp:77] Creating layer i11_i1_10_split
I0810 12:46:20.031548 13394 net.cpp:91] Creating Layer i11_i1_10_split
I0810 12:46:20.031554 13394 net.cpp:425] i11_i1_10_split <- i11
I0810 12:46:20.031566 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_0
I0810 12:46:20.031579 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_1
I0810 12:46:20.031610 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_2
I0810 12:46:20.031625 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_3
I0810 12:46:20.031638 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_4
I0810 12:46:20.031652 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_5
I0810 12:46:20.031666 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_6
I0810 12:46:20.031679 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_7
I0810 12:46:20.031693 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_8
I0810 12:46:20.031708 13394 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_9
I0810 12:46:20.031728 13394 net.cpp:141] Setting up i11_i1_10_split
I0810 12:46:20.031738 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031746 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031755 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031764 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031774 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031782 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031790 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031800 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031808 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031817 13394 net.cpp:148] Top shape: 64 1 1 4096 (262144)
I0810 12:46:20.031824 13394 net.cpp:156] Memory required for data: 62916096
I0810 12:46:20.031831 13394 layer_factory.hpp:77] Creating layer Concat1
I0810 12:46:20.031844 13394 net.cpp:91] Creating Layer Concat1
I0810 12:46:20.031852 13394 net.cpp:425] Concat1 <- i1_i1_0_split_0
I0810 12:46:20.031860 13394 net.cpp:425] Concat1 <- i11_i1_10_split_0
I0810 12:46:20.031872 13394 net.cpp:399] Concat1 -> Concat1
I0810 12:46:20.031885 13394 net.cpp:141] Setting up Concat1
I0810 12:46:20.031894 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.031901 13394 net.cpp:156] Memory required for data: 65013248
I0810 12:46:20.031908 13394 layer_factory.hpp:77] Creating layer InnerProduct1
I0810 12:46:20.031926 13394 net.cpp:91] Creating Layer InnerProduct1
I0810 12:46:20.031934 13394 net.cpp:425] InnerProduct1 <- Concat1
I0810 12:46:20.031945 13394 net.cpp:399] InnerProduct1 -> InnerProduct1
I0810 12:46:20.036231 13394 net.cpp:141] Setting up InnerProduct1
I0810 12:46:20.036249 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.036257 13394 net.cpp:156] Memory required for data: 65029632
I0810 12:46:20.036273 13394 layer_factory.hpp:77] Creating layer ReLU1
I0810 12:46:20.036284 13394 net.cpp:91] Creating Layer ReLU1
I0810 12:46:20.036293 13394 net.cpp:425] ReLU1 <- InnerProduct1
I0810 12:46:20.036301 13394 net.cpp:386] ReLU1 -> InnerProduct1 (in-place)
I0810 12:46:20.036314 13394 net.cpp:141] Setting up ReLU1
I0810 12:46:20.036320 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.036326 13394 net.cpp:156] Memory required for data: 65046016
I0810 12:46:20.036332 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.036341 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.036347 13394 net.cpp:425] drop1 <- InnerProduct1
I0810 12:46:20.036356 13394 net.cpp:399] drop1 -> Dropout1
I0810 12:46:20.036368 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.036376 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.036382 13394 net.cpp:156] Memory required for data: 65062400
I0810 12:46:20.036388 13394 layer_factory.hpp:77] Creating layer InnerProduct2
I0810 12:46:20.036401 13394 net.cpp:91] Creating Layer InnerProduct2
I0810 12:46:20.036406 13394 net.cpp:425] InnerProduct2 <- Dropout1
I0810 12:46:20.036417 13394 net.cpp:399] InnerProduct2 -> InnerProduct2
I0810 12:46:20.036470 13394 net.cpp:141] Setting up InnerProduct2
I0810 12:46:20.036478 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.036484 13394 net.cpp:156] Memory required for data: 65078784
I0810 12:46:20.036494 13394 layer_factory.hpp:77] Creating layer ReLU2
I0810 12:46:20.036502 13394 net.cpp:91] Creating Layer ReLU2
I0810 12:46:20.036526 13394 net.cpp:425] ReLU2 <- InnerProduct2
I0810 12:46:20.036535 13394 net.cpp:386] ReLU2 -> InnerProduct2 (in-place)
I0810 12:46:20.036545 13394 net.cpp:141] Setting up ReLU2
I0810 12:46:20.036551 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.036557 13394 net.cpp:156] Memory required for data: 65095168
I0810 12:46:20.036563 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.036571 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.036577 13394 net.cpp:425] drop2 <- InnerProduct2
I0810 12:46:20.036586 13394 net.cpp:399] drop2 -> Dropout2
I0810 12:46:20.036597 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.036603 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.036609 13394 net.cpp:156] Memory required for data: 65111552
I0810 12:46:20.036615 13394 layer_factory.hpp:77] Creating layer m1
I0810 12:46:20.036624 13394 net.cpp:91] Creating Layer m1
I0810 12:46:20.036630 13394 net.cpp:425] m1 <- Dropout2
I0810 12:46:20.036639 13394 net.cpp:399] m1 -> m1
I0810 12:46:20.036658 13394 net.cpp:141] Setting up m1
I0810 12:46:20.036665 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.036671 13394 net.cpp:156] Memory required for data: 65111808
I0810 12:46:20.036681 13394 layer_factory.hpp:77] Creating layer Concat2
I0810 12:46:20.036691 13394 net.cpp:91] Creating Layer Concat2
I0810 12:46:20.036697 13394 net.cpp:425] Concat2 <- i1_i1_0_split_1
I0810 12:46:20.036705 13394 net.cpp:425] Concat2 <- i12
I0810 12:46:20.036715 13394 net.cpp:399] Concat2 -> Concat2
I0810 12:46:20.036726 13394 net.cpp:141] Setting up Concat2
I0810 12:46:20.036734 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.036741 13394 net.cpp:156] Memory required for data: 67208960
I0810 12:46:20.036746 13394 layer_factory.hpp:77] Creating layer InnerProduct3
I0810 12:46:20.036759 13394 net.cpp:91] Creating Layer InnerProduct3
I0810 12:46:20.036766 13394 net.cpp:425] InnerProduct3 <- Concat2
I0810 12:46:20.036774 13394 net.cpp:399] InnerProduct3 -> InnerProduct3
I0810 12:46:20.042364 13394 net.cpp:141] Setting up InnerProduct3
I0810 12:46:20.042384 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.042392 13394 net.cpp:156] Memory required for data: 67225344
I0810 12:46:20.042399 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.042407 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.042414 13394 layer_factory.hpp:77] Creating layer ReLU3
I0810 12:46:20.042425 13394 net.cpp:91] Creating Layer ReLU3
I0810 12:46:20.042433 13394 net.cpp:425] ReLU3 <- InnerProduct3
I0810 12:46:20.042443 13394 net.cpp:386] ReLU3 -> InnerProduct3 (in-place)
I0810 12:46:20.042454 13394 net.cpp:141] Setting up ReLU3
I0810 12:46:20.042461 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.042467 13394 net.cpp:156] Memory required for data: 67241728
I0810 12:46:20.042474 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.042482 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.042490 13394 net.cpp:425] drop1 <- InnerProduct3
I0810 12:46:20.042497 13394 net.cpp:399] drop1 -> Dropout3
I0810 12:46:20.042510 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.042517 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.042523 13394 net.cpp:156] Memory required for data: 67258112
I0810 12:46:20.042529 13394 layer_factory.hpp:77] Creating layer InnerProduct4
I0810 12:46:20.042541 13394 net.cpp:91] Creating Layer InnerProduct4
I0810 12:46:20.042547 13394 net.cpp:425] InnerProduct4 <- Dropout3
I0810 12:46:20.042557 13394 net.cpp:399] InnerProduct4 -> InnerProduct4
I0810 12:46:20.042610 13394 net.cpp:141] Setting up InnerProduct4
I0810 12:46:20.042618 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.042623 13394 net.cpp:156] Memory required for data: 67274496
I0810 12:46:20.042634 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.042640 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.042664 13394 layer_factory.hpp:77] Creating layer ReLU4
I0810 12:46:20.042672 13394 net.cpp:91] Creating Layer ReLU4
I0810 12:46:20.042678 13394 net.cpp:425] ReLU4 <- InnerProduct4
I0810 12:46:20.042686 13394 net.cpp:386] ReLU4 -> InnerProduct4 (in-place)
I0810 12:46:20.042696 13394 net.cpp:141] Setting up ReLU4
I0810 12:46:20.042703 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.042709 13394 net.cpp:156] Memory required for data: 67290880
I0810 12:46:20.042716 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.042723 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.042729 13394 net.cpp:425] drop2 <- InnerProduct4
I0810 12:46:20.042738 13394 net.cpp:399] drop2 -> Dropout4
I0810 12:46:20.042749 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.042767 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.042788 13394 net.cpp:156] Memory required for data: 67307264
I0810 12:46:20.042795 13394 layer_factory.hpp:77] Creating layer m2
I0810 12:46:20.042807 13394 net.cpp:91] Creating Layer m2
I0810 12:46:20.042815 13394 net.cpp:425] m2 <- Dropout4
I0810 12:46:20.042829 13394 net.cpp:399] m2 -> m2
I0810 12:46:20.042853 13394 net.cpp:141] Setting up m2
I0810 12:46:20.042862 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.042870 13394 net.cpp:156] Memory required for data: 67307520
I0810 12:46:20.042878 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.042888 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.042896 13394 layer_factory.hpp:77] Creating layer Concat3
I0810 12:46:20.042906 13394 net.cpp:91] Creating Layer Concat3
I0810 12:46:20.042914 13394 net.cpp:425] Concat3 <- i1_i1_0_split_2
I0810 12:46:20.042925 13394 net.cpp:425] Concat3 <- i13
I0810 12:46:20.042937 13394 net.cpp:399] Concat3 -> Concat3
I0810 12:46:20.042949 13394 net.cpp:141] Setting up Concat3
I0810 12:46:20.042958 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.042963 13394 net.cpp:156] Memory required for data: 69404672
I0810 12:46:20.042969 13394 layer_factory.hpp:77] Creating layer InnerProduct5
I0810 12:46:20.042979 13394 net.cpp:91] Creating Layer InnerProduct5
I0810 12:46:20.042985 13394 net.cpp:425] InnerProduct5 <- Concat3
I0810 12:46:20.042995 13394 net.cpp:399] InnerProduct5 -> InnerProduct5
I0810 12:46:20.047294 13394 net.cpp:141] Setting up InnerProduct5
I0810 12:46:20.047314 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.047320 13394 net.cpp:156] Memory required for data: 69421056
I0810 12:46:20.047329 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.047338 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.047343 13394 layer_factory.hpp:77] Creating layer ReLU5
I0810 12:46:20.047354 13394 net.cpp:91] Creating Layer ReLU5
I0810 12:46:20.047361 13394 net.cpp:425] ReLU5 <- InnerProduct5
I0810 12:46:20.047371 13394 net.cpp:386] ReLU5 -> InnerProduct5 (in-place)
I0810 12:46:20.047384 13394 net.cpp:141] Setting up ReLU5
I0810 12:46:20.047391 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.047397 13394 net.cpp:156] Memory required for data: 69437440
I0810 12:46:20.047404 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.047412 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.047420 13394 net.cpp:425] drop1 <- InnerProduct5
I0810 12:46:20.047430 13394 net.cpp:399] drop1 -> Dropout5
I0810 12:46:20.047441 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.047449 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.047456 13394 net.cpp:156] Memory required for data: 69453824
I0810 12:46:20.047461 13394 layer_factory.hpp:77] Creating layer InnerProduct6
I0810 12:46:20.047472 13394 net.cpp:91] Creating Layer InnerProduct6
I0810 12:46:20.047478 13394 net.cpp:425] InnerProduct6 <- Dropout5
I0810 12:46:20.047488 13394 net.cpp:399] InnerProduct6 -> InnerProduct6
I0810 12:46:20.047541 13394 net.cpp:141] Setting up InnerProduct6
I0810 12:46:20.047567 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.047574 13394 net.cpp:156] Memory required for data: 69470208
I0810 12:46:20.047580 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.047587 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.047593 13394 layer_factory.hpp:77] Creating layer ReLU6
I0810 12:46:20.047601 13394 net.cpp:91] Creating Layer ReLU6
I0810 12:46:20.047607 13394 net.cpp:425] ReLU6 <- InnerProduct6
I0810 12:46:20.047616 13394 net.cpp:386] ReLU6 -> InnerProduct6 (in-place)
I0810 12:46:20.047626 13394 net.cpp:141] Setting up ReLU6
I0810 12:46:20.047633 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.047638 13394 net.cpp:156] Memory required for data: 69486592
I0810 12:46:20.047644 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.047652 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.047658 13394 net.cpp:425] drop2 <- InnerProduct6
I0810 12:46:20.047667 13394 net.cpp:399] drop2 -> Dropout6
I0810 12:46:20.047683 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.047693 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.047699 13394 net.cpp:156] Memory required for data: 69502976
I0810 12:46:20.047705 13394 layer_factory.hpp:77] Creating layer m3
I0810 12:46:20.047719 13394 net.cpp:91] Creating Layer m3
I0810 12:46:20.047725 13394 net.cpp:425] m3 <- Dropout6
I0810 12:46:20.047739 13394 net.cpp:399] m3 -> m3
I0810 12:46:20.047775 13394 net.cpp:141] Setting up m3
I0810 12:46:20.047788 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.047796 13394 net.cpp:156] Memory required for data: 69503232
I0810 12:46:20.047812 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.047821 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.047827 13394 layer_factory.hpp:77] Creating layer Concat4
I0810 12:46:20.047837 13394 net.cpp:91] Creating Layer Concat4
I0810 12:46:20.047842 13394 net.cpp:425] Concat4 <- i1_i1_0_split_3
I0810 12:46:20.047850 13394 net.cpp:425] Concat4 <- i14
I0810 12:46:20.047860 13394 net.cpp:399] Concat4 -> Concat4
I0810 12:46:20.047871 13394 net.cpp:141] Setting up Concat4
I0810 12:46:20.047879 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.047885 13394 net.cpp:156] Memory required for data: 71600384
I0810 12:46:20.047891 13394 layer_factory.hpp:77] Creating layer InnerProduct7
I0810 12:46:20.047909 13394 net.cpp:91] Creating Layer InnerProduct7
I0810 12:46:20.047914 13394 net.cpp:425] InnerProduct7 <- Concat4
I0810 12:46:20.047924 13394 net.cpp:399] InnerProduct7 -> InnerProduct7
I0810 12:46:20.052870 13394 net.cpp:141] Setting up InnerProduct7
I0810 12:46:20.052893 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.052902 13394 net.cpp:156] Memory required for data: 71616768
I0810 12:46:20.052912 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.052922 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.052929 13394 layer_factory.hpp:77] Creating layer ReLU7
I0810 12:46:20.052942 13394 net.cpp:91] Creating Layer ReLU7
I0810 12:46:20.052953 13394 net.cpp:425] ReLU7 <- InnerProduct7
I0810 12:46:20.052965 13394 net.cpp:386] ReLU7 -> InnerProduct7 (in-place)
I0810 12:46:20.052979 13394 net.cpp:141] Setting up ReLU7
I0810 12:46:20.052988 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.052994 13394 net.cpp:156] Memory required for data: 71633152
I0810 12:46:20.053000 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.053011 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.053020 13394 net.cpp:425] drop1 <- InnerProduct7
I0810 12:46:20.053031 13394 net.cpp:399] drop1 -> Dropout7
I0810 12:46:20.053047 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.053057 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.053063 13394 net.cpp:156] Memory required for data: 71649536
I0810 12:46:20.053092 13394 layer_factory.hpp:77] Creating layer InnerProduct8
I0810 12:46:20.053107 13394 net.cpp:91] Creating Layer InnerProduct8
I0810 12:46:20.053114 13394 net.cpp:425] InnerProduct8 <- Dropout7
I0810 12:46:20.053125 13394 net.cpp:399] InnerProduct8 -> InnerProduct8
I0810 12:46:20.053184 13394 net.cpp:141] Setting up InnerProduct8
I0810 12:46:20.053192 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.053200 13394 net.cpp:156] Memory required for data: 71665920
I0810 12:46:20.053206 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.053215 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.053222 13394 layer_factory.hpp:77] Creating layer ReLU8
I0810 12:46:20.053232 13394 net.cpp:91] Creating Layer ReLU8
I0810 12:46:20.053239 13394 net.cpp:425] ReLU8 <- InnerProduct8
I0810 12:46:20.053248 13394 net.cpp:386] ReLU8 -> InnerProduct8 (in-place)
I0810 12:46:20.053258 13394 net.cpp:141] Setting up ReLU8
I0810 12:46:20.053268 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.053277 13394 net.cpp:156] Memory required for data: 71682304
I0810 12:46:20.053283 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.053292 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.053298 13394 net.cpp:425] drop2 <- InnerProduct8
I0810 12:46:20.053309 13394 net.cpp:399] drop2 -> Dropout8
I0810 12:46:20.053323 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.053331 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.053338 13394 net.cpp:156] Memory required for data: 71698688
I0810 12:46:20.053344 13394 layer_factory.hpp:77] Creating layer m4
I0810 12:46:20.053356 13394 net.cpp:91] Creating Layer m4
I0810 12:46:20.053364 13394 net.cpp:425] m4 <- Dropout8
I0810 12:46:20.053375 13394 net.cpp:399] m4 -> m4
I0810 12:46:20.053398 13394 net.cpp:141] Setting up m4
I0810 12:46:20.053408 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.053414 13394 net.cpp:156] Memory required for data: 71698944
I0810 12:46:20.053422 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.053429 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.053436 13394 layer_factory.hpp:77] Creating layer Concat5
I0810 12:46:20.053448 13394 net.cpp:91] Creating Layer Concat5
I0810 12:46:20.053455 13394 net.cpp:425] Concat5 <- i1_i1_0_split_4
I0810 12:46:20.053465 13394 net.cpp:425] Concat5 <- i15
I0810 12:46:20.053475 13394 net.cpp:399] Concat5 -> Concat5
I0810 12:46:20.053489 13394 net.cpp:141] Setting up Concat5
I0810 12:46:20.053499 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.053508 13394 net.cpp:156] Memory required for data: 73796096
I0810 12:46:20.053514 13394 layer_factory.hpp:77] Creating layer InnerProduct9
I0810 12:46:20.053527 13394 net.cpp:91] Creating Layer InnerProduct9
I0810 12:46:20.053536 13394 net.cpp:425] InnerProduct9 <- Concat5
I0810 12:46:20.053549 13394 net.cpp:399] InnerProduct9 -> InnerProduct9
I0810 12:46:20.057936 13394 net.cpp:141] Setting up InnerProduct9
I0810 12:46:20.057952 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.057960 13394 net.cpp:156] Memory required for data: 73812480
I0810 12:46:20.057970 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.057981 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.057989 13394 layer_factory.hpp:77] Creating layer ReLU9
I0810 12:46:20.058001 13394 net.cpp:91] Creating Layer ReLU9
I0810 12:46:20.058009 13394 net.cpp:425] ReLU9 <- InnerProduct9
I0810 12:46:20.058022 13394 net.cpp:386] ReLU9 -> InnerProduct9 (in-place)
I0810 12:46:20.058034 13394 net.cpp:141] Setting up ReLU9
I0810 12:46:20.058044 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.058051 13394 net.cpp:156] Memory required for data: 73828864
I0810 12:46:20.058058 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.058084 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.058091 13394 net.cpp:425] drop1 <- InnerProduct9
I0810 12:46:20.058102 13394 net.cpp:399] drop1 -> Dropout9
I0810 12:46:20.058117 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.058127 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.058135 13394 net.cpp:156] Memory required for data: 73845248
I0810 12:46:20.058142 13394 layer_factory.hpp:77] Creating layer InnerProduct10
I0810 12:46:20.058154 13394 net.cpp:91] Creating Layer InnerProduct10
I0810 12:46:20.058161 13394 net.cpp:425] InnerProduct10 <- Dropout9
I0810 12:46:20.058174 13394 net.cpp:399] InnerProduct10 -> InnerProduct10
I0810 12:46:20.058231 13394 net.cpp:141] Setting up InnerProduct10
I0810 12:46:20.058243 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.058249 13394 net.cpp:156] Memory required for data: 73861632
I0810 12:46:20.058257 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.058266 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.058275 13394 layer_factory.hpp:77] Creating layer ReLU10
I0810 12:46:20.058284 13394 net.cpp:91] Creating Layer ReLU10
I0810 12:46:20.058291 13394 net.cpp:425] ReLU10 <- InnerProduct10
I0810 12:46:20.058301 13394 net.cpp:386] ReLU10 -> InnerProduct10 (in-place)
I0810 12:46:20.058315 13394 net.cpp:141] Setting up ReLU10
I0810 12:46:20.058323 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.058329 13394 net.cpp:156] Memory required for data: 73878016
I0810 12:46:20.058336 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.058346 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.058354 13394 net.cpp:425] drop2 <- InnerProduct10
I0810 12:46:20.058367 13394 net.cpp:399] drop2 -> Dropout10
I0810 12:46:20.058382 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.058392 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.058398 13394 net.cpp:156] Memory required for data: 73894400
I0810 12:46:20.058404 13394 layer_factory.hpp:77] Creating layer m5
I0810 12:46:20.058415 13394 net.cpp:91] Creating Layer m5
I0810 12:46:20.058423 13394 net.cpp:425] m5 <- Dropout10
I0810 12:46:20.058437 13394 net.cpp:399] m5 -> m5
I0810 12:46:20.058460 13394 net.cpp:141] Setting up m5
I0810 12:46:20.058470 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.058478 13394 net.cpp:156] Memory required for data: 73894656
I0810 12:46:20.058487 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.058496 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.058504 13394 layer_factory.hpp:77] Creating layer Concat6
I0810 12:46:20.058516 13394 net.cpp:91] Creating Layer Concat6
I0810 12:46:20.058523 13394 net.cpp:425] Concat6 <- i1_i1_0_split_5
I0810 12:46:20.058533 13394 net.cpp:425] Concat6 <- i16
I0810 12:46:20.058544 13394 net.cpp:399] Concat6 -> Concat6
I0810 12:46:20.058559 13394 net.cpp:141] Setting up Concat6
I0810 12:46:20.058570 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.058578 13394 net.cpp:156] Memory required for data: 75991808
I0810 12:46:20.058584 13394 layer_factory.hpp:77] Creating layer InnerProduct11
I0810 12:46:20.058598 13394 net.cpp:91] Creating Layer InnerProduct11
I0810 12:46:20.058605 13394 net.cpp:425] InnerProduct11 <- Concat6
I0810 12:46:20.058619 13394 net.cpp:399] InnerProduct11 -> InnerProduct11
I0810 12:46:20.062978 13394 net.cpp:141] Setting up InnerProduct11
I0810 12:46:20.062995 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.063004 13394 net.cpp:156] Memory required for data: 76008192
I0810 12:46:20.063012 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.063022 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.063030 13394 layer_factory.hpp:77] Creating layer ReLU11
I0810 12:46:20.063040 13394 net.cpp:91] Creating Layer ReLU11
I0810 12:46:20.063066 13394 net.cpp:425] ReLU11 <- InnerProduct11
I0810 12:46:20.063077 13394 net.cpp:386] ReLU11 -> InnerProduct11 (in-place)
I0810 12:46:20.063091 13394 net.cpp:141] Setting up ReLU11
I0810 12:46:20.063099 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.063105 13394 net.cpp:156] Memory required for data: 76024576
I0810 12:46:20.063112 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.063123 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.063130 13394 net.cpp:425] drop1 <- InnerProduct11
I0810 12:46:20.063140 13394 net.cpp:399] drop1 -> Dropout11
I0810 12:46:20.063154 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.063164 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.063171 13394 net.cpp:156] Memory required for data: 76040960
I0810 12:46:20.063179 13394 layer_factory.hpp:77] Creating layer InnerProduct12
I0810 12:46:20.063189 13394 net.cpp:91] Creating Layer InnerProduct12
I0810 12:46:20.063196 13394 net.cpp:425] InnerProduct12 <- Dropout11
I0810 12:46:20.063207 13394 net.cpp:399] InnerProduct12 -> InnerProduct12
I0810 12:46:20.063264 13394 net.cpp:141] Setting up InnerProduct12
I0810 12:46:20.063289 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.063305 13394 net.cpp:156] Memory required for data: 76057344
I0810 12:46:20.063325 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.063335 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.063344 13394 layer_factory.hpp:77] Creating layer ReLU12
I0810 12:46:20.063354 13394 net.cpp:91] Creating Layer ReLU12
I0810 12:46:20.063361 13394 net.cpp:425] ReLU12 <- InnerProduct12
I0810 12:46:20.063370 13394 net.cpp:386] ReLU12 -> InnerProduct12 (in-place)
I0810 12:46:20.063381 13394 net.cpp:141] Setting up ReLU12
I0810 12:46:20.063390 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.063396 13394 net.cpp:156] Memory required for data: 76073728
I0810 12:46:20.063402 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.063412 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.063421 13394 net.cpp:425] drop2 <- InnerProduct12
I0810 12:46:20.063431 13394 net.cpp:399] drop2 -> Dropout12
I0810 12:46:20.063446 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.063455 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.063462 13394 net.cpp:156] Memory required for data: 76090112
I0810 12:46:20.063468 13394 layer_factory.hpp:77] Creating layer m6
I0810 12:46:20.063479 13394 net.cpp:91] Creating Layer m6
I0810 12:46:20.063486 13394 net.cpp:425] m6 <- Dropout12
I0810 12:46:20.063498 13394 net.cpp:399] m6 -> m6
I0810 12:46:20.063519 13394 net.cpp:141] Setting up m6
I0810 12:46:20.063530 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.063536 13394 net.cpp:156] Memory required for data: 76090368
I0810 12:46:20.063544 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.063554 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.063561 13394 layer_factory.hpp:77] Creating layer Concat7
I0810 12:46:20.063570 13394 net.cpp:91] Creating Layer Concat7
I0810 12:46:20.063578 13394 net.cpp:425] Concat7 <- i1_i1_0_split_6
I0810 12:46:20.063588 13394 net.cpp:425] Concat7 <- i17
I0810 12:46:20.063599 13394 net.cpp:399] Concat7 -> Concat7
I0810 12:46:20.063612 13394 net.cpp:141] Setting up Concat7
I0810 12:46:20.063622 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.063629 13394 net.cpp:156] Memory required for data: 78187520
I0810 12:46:20.063637 13394 layer_factory.hpp:77] Creating layer InnerProduct13
I0810 12:46:20.063652 13394 net.cpp:91] Creating Layer InnerProduct13
I0810 12:46:20.063662 13394 net.cpp:425] InnerProduct13 <- Concat7
I0810 12:46:20.063673 13394 net.cpp:399] InnerProduct13 -> InnerProduct13
I0810 12:46:20.068079 13394 net.cpp:141] Setting up InnerProduct13
I0810 12:46:20.068100 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.068107 13394 net.cpp:156] Memory required for data: 78203904
I0810 12:46:20.068159 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.068169 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.068177 13394 layer_factory.hpp:77] Creating layer ReLU13
I0810 12:46:20.068191 13394 net.cpp:91] Creating Layer ReLU13
I0810 12:46:20.068199 13394 net.cpp:425] ReLU13 <- InnerProduct13
I0810 12:46:20.068210 13394 net.cpp:386] ReLU13 -> InnerProduct13 (in-place)
I0810 12:46:20.068223 13394 net.cpp:141] Setting up ReLU13
I0810 12:46:20.068233 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.068240 13394 net.cpp:156] Memory required for data: 78220288
I0810 12:46:20.068246 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.068256 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.068264 13394 net.cpp:425] drop1 <- InnerProduct13
I0810 12:46:20.068274 13394 net.cpp:399] drop1 -> Dropout13
I0810 12:46:20.068287 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.068295 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.068302 13394 net.cpp:156] Memory required for data: 78236672
I0810 12:46:20.068308 13394 layer_factory.hpp:77] Creating layer InnerProduct14
I0810 12:46:20.068320 13394 net.cpp:91] Creating Layer InnerProduct14
I0810 12:46:20.068328 13394 net.cpp:425] InnerProduct14 <- Dropout13
I0810 12:46:20.068339 13394 net.cpp:399] InnerProduct14 -> InnerProduct14
I0810 12:46:20.068394 13394 net.cpp:141] Setting up InnerProduct14
I0810 12:46:20.068403 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.068409 13394 net.cpp:156] Memory required for data: 78253056
I0810 12:46:20.068416 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.068426 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.068434 13394 layer_factory.hpp:77] Creating layer ReLU14
I0810 12:46:20.068441 13394 net.cpp:91] Creating Layer ReLU14
I0810 12:46:20.068449 13394 net.cpp:425] ReLU14 <- InnerProduct14
I0810 12:46:20.068459 13394 net.cpp:386] ReLU14 -> InnerProduct14 (in-place)
I0810 12:46:20.068470 13394 net.cpp:141] Setting up ReLU14
I0810 12:46:20.068478 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.068485 13394 net.cpp:156] Memory required for data: 78269440
I0810 12:46:20.068490 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.068500 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.068507 13394 net.cpp:425] drop2 <- InnerProduct14
I0810 12:46:20.068518 13394 net.cpp:399] drop2 -> Dropout14
I0810 12:46:20.068533 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.068542 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.068549 13394 net.cpp:156] Memory required for data: 78285824
I0810 12:46:20.068555 13394 layer_factory.hpp:77] Creating layer m7
I0810 12:46:20.068567 13394 net.cpp:91] Creating Layer m7
I0810 12:46:20.068574 13394 net.cpp:425] m7 <- Dropout14
I0810 12:46:20.068588 13394 net.cpp:399] m7 -> m7
I0810 12:46:20.068609 13394 net.cpp:141] Setting up m7
I0810 12:46:20.068619 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.068625 13394 net.cpp:156] Memory required for data: 78286080
I0810 12:46:20.068634 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.068641 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.068648 13394 layer_factory.hpp:77] Creating layer Concat8
I0810 12:46:20.068660 13394 net.cpp:91] Creating Layer Concat8
I0810 12:46:20.068681 13394 net.cpp:425] Concat8 <- i1_i1_0_split_7
I0810 12:46:20.068691 13394 net.cpp:425] Concat8 <- i18
I0810 12:46:20.068703 13394 net.cpp:399] Concat8 -> Concat8
I0810 12:46:20.068717 13394 net.cpp:141] Setting up Concat8
I0810 12:46:20.068725 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.068733 13394 net.cpp:156] Memory required for data: 80383232
I0810 12:46:20.068742 13394 layer_factory.hpp:77] Creating layer InnerProduct15
I0810 12:46:20.068773 13394 net.cpp:91] Creating Layer InnerProduct15
I0810 12:46:20.068791 13394 net.cpp:425] InnerProduct15 <- Concat8
I0810 12:46:20.068804 13394 net.cpp:399] InnerProduct15 -> InnerProduct15
I0810 12:46:20.073870 13394 net.cpp:141] Setting up InnerProduct15
I0810 12:46:20.073889 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.073896 13394 net.cpp:156] Memory required for data: 80399616
I0810 12:46:20.073905 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.073914 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.073922 13394 layer_factory.hpp:77] Creating layer ReLU15
I0810 12:46:20.073933 13394 net.cpp:91] Creating Layer ReLU15
I0810 12:46:20.073941 13394 net.cpp:425] ReLU15 <- InnerProduct15
I0810 12:46:20.073951 13394 net.cpp:386] ReLU15 -> InnerProduct15 (in-place)
I0810 12:46:20.073963 13394 net.cpp:141] Setting up ReLU15
I0810 12:46:20.073971 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.073978 13394 net.cpp:156] Memory required for data: 80416000
I0810 12:46:20.073985 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.073994 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.074002 13394 net.cpp:425] drop1 <- InnerProduct15
I0810 12:46:20.074012 13394 net.cpp:399] drop1 -> Dropout15
I0810 12:46:20.074025 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.074033 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.074040 13394 net.cpp:156] Memory required for data: 80432384
I0810 12:46:20.074046 13394 layer_factory.hpp:77] Creating layer InnerProduct16
I0810 12:46:20.074059 13394 net.cpp:91] Creating Layer InnerProduct16
I0810 12:46:20.074065 13394 net.cpp:425] InnerProduct16 <- Dropout15
I0810 12:46:20.074076 13394 net.cpp:399] InnerProduct16 -> InnerProduct16
I0810 12:46:20.074132 13394 net.cpp:141] Setting up InnerProduct16
I0810 12:46:20.074141 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.074147 13394 net.cpp:156] Memory required for data: 80448768
I0810 12:46:20.074154 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.074162 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.074169 13394 layer_factory.hpp:77] Creating layer ReLU16
I0810 12:46:20.074177 13394 net.cpp:91] Creating Layer ReLU16
I0810 12:46:20.074184 13394 net.cpp:425] ReLU16 <- InnerProduct16
I0810 12:46:20.074193 13394 net.cpp:386] ReLU16 -> InnerProduct16 (in-place)
I0810 12:46:20.074203 13394 net.cpp:141] Setting up ReLU16
I0810 12:46:20.074786 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.074795 13394 net.cpp:156] Memory required for data: 80465152
I0810 12:46:20.074802 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.074812 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.074820 13394 net.cpp:425] drop2 <- InnerProduct16
I0810 12:46:20.074832 13394 net.cpp:399] drop2 -> Dropout16
I0810 12:46:20.074848 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.074858 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.074865 13394 net.cpp:156] Memory required for data: 80481536
I0810 12:46:20.074872 13394 layer_factory.hpp:77] Creating layer m8
I0810 12:46:20.074884 13394 net.cpp:91] Creating Layer m8
I0810 12:46:20.074892 13394 net.cpp:425] m8 <- Dropout16
I0810 12:46:20.074904 13394 net.cpp:399] m8 -> m8
I0810 12:46:20.074928 13394 net.cpp:141] Setting up m8
I0810 12:46:20.074937 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.074945 13394 net.cpp:156] Memory required for data: 80481792
I0810 12:46:20.074954 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.074961 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.074968 13394 layer_factory.hpp:77] Creating layer Concat9
I0810 12:46:20.074978 13394 net.cpp:91] Creating Layer Concat9
I0810 12:46:20.074985 13394 net.cpp:425] Concat9 <- i1_i1_0_split_8
I0810 12:46:20.074995 13394 net.cpp:425] Concat9 <- i19
I0810 12:46:20.075023 13394 net.cpp:399] Concat9 -> Concat9
I0810 12:46:20.075039 13394 net.cpp:141] Setting up Concat9
I0810 12:46:20.075049 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.075058 13394 net.cpp:156] Memory required for data: 82578944
I0810 12:46:20.075067 13394 layer_factory.hpp:77] Creating layer InnerProduct17
I0810 12:46:20.075078 13394 net.cpp:91] Creating Layer InnerProduct17
I0810 12:46:20.075085 13394 net.cpp:425] InnerProduct17 <- Concat9
I0810 12:46:20.075096 13394 net.cpp:399] InnerProduct17 -> InnerProduct17
I0810 12:46:20.079483 13394 net.cpp:141] Setting up InnerProduct17
I0810 12:46:20.079500 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.079509 13394 net.cpp:156] Memory required for data: 82595328
I0810 12:46:20.079516 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.079526 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.079535 13394 layer_factory.hpp:77] Creating layer ReLU17
I0810 12:46:20.079547 13394 net.cpp:91] Creating Layer ReLU17
I0810 12:46:20.079556 13394 net.cpp:425] ReLU17 <- InnerProduct17
I0810 12:46:20.079567 13394 net.cpp:386] ReLU17 -> InnerProduct17 (in-place)
I0810 12:46:20.079581 13394 net.cpp:141] Setting up ReLU17
I0810 12:46:20.079591 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.079597 13394 net.cpp:156] Memory required for data: 82611712
I0810 12:46:20.079605 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.079617 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.079623 13394 net.cpp:425] drop1 <- InnerProduct17
I0810 12:46:20.079634 13394 net.cpp:399] drop1 -> Dropout17
I0810 12:46:20.079648 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.079658 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.079664 13394 net.cpp:156] Memory required for data: 82628096
I0810 12:46:20.079670 13394 layer_factory.hpp:77] Creating layer InnerProduct18
I0810 12:46:20.079682 13394 net.cpp:91] Creating Layer InnerProduct18
I0810 12:46:20.079689 13394 net.cpp:425] InnerProduct18 <- Dropout17
I0810 12:46:20.079700 13394 net.cpp:399] InnerProduct18 -> InnerProduct18
I0810 12:46:20.079759 13394 net.cpp:141] Setting up InnerProduct18
I0810 12:46:20.079771 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.079778 13394 net.cpp:156] Memory required for data: 82644480
I0810 12:46:20.079787 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.079795 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.079802 13394 layer_factory.hpp:77] Creating layer ReLU18
I0810 12:46:20.079813 13394 net.cpp:91] Creating Layer ReLU18
I0810 12:46:20.079821 13394 net.cpp:425] ReLU18 <- InnerProduct18
I0810 12:46:20.079831 13394 net.cpp:386] ReLU18 -> InnerProduct18 (in-place)
I0810 12:46:20.079843 13394 net.cpp:141] Setting up ReLU18
I0810 12:46:20.079850 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.079857 13394 net.cpp:156] Memory required for data: 82660864
I0810 12:46:20.079864 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.079874 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.079880 13394 net.cpp:425] drop2 <- InnerProduct18
I0810 12:46:20.079891 13394 net.cpp:399] drop2 -> Dropout18
I0810 12:46:20.079903 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.079912 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.079921 13394 net.cpp:156] Memory required for data: 82677248
I0810 12:46:20.079926 13394 layer_factory.hpp:77] Creating layer m9
I0810 12:46:20.079937 13394 net.cpp:91] Creating Layer m9
I0810 12:46:20.079946 13394 net.cpp:425] m9 <- Dropout18
I0810 12:46:20.079959 13394 net.cpp:399] m9 -> m9
I0810 12:46:20.079983 13394 net.cpp:141] Setting up m9
I0810 12:46:20.079993 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.079999 13394 net.cpp:156] Memory required for data: 82677504
I0810 12:46:20.080006 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.080034 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.080041 13394 layer_factory.hpp:77] Creating layer Concat10
I0810 12:46:20.080050 13394 net.cpp:91] Creating Layer Concat10
I0810 12:46:20.080059 13394 net.cpp:425] Concat10 <- i1_i1_0_split_9
I0810 12:46:20.080067 13394 net.cpp:425] Concat10 <- i20
I0810 12:46:20.080077 13394 net.cpp:399] Concat10 -> Concat10
I0810 12:46:20.080091 13394 net.cpp:141] Setting up Concat10
I0810 12:46:20.080101 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.080108 13394 net.cpp:156] Memory required for data: 84774656
I0810 12:46:20.080116 13394 layer_factory.hpp:77] Creating layer InnerProduct19
I0810 12:46:20.080128 13394 net.cpp:91] Creating Layer InnerProduct19
I0810 12:46:20.080137 13394 net.cpp:425] InnerProduct19 <- Concat10
I0810 12:46:20.080150 13394 net.cpp:399] InnerProduct19 -> InnerProduct19
I0810 12:46:20.084596 13394 net.cpp:141] Setting up InnerProduct19
I0810 12:46:20.084615 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.084622 13394 net.cpp:156] Memory required for data: 84791040
I0810 12:46:20.084631 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.084640 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.084646 13394 layer_factory.hpp:77] Creating layer ReLU19
I0810 12:46:20.084657 13394 net.cpp:91] Creating Layer ReLU19
I0810 12:46:20.084666 13394 net.cpp:425] ReLU19 <- InnerProduct19
I0810 12:46:20.084676 13394 net.cpp:386] ReLU19 -> InnerProduct19 (in-place)
I0810 12:46:20.084689 13394 net.cpp:141] Setting up ReLU19
I0810 12:46:20.084697 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.084703 13394 net.cpp:156] Memory required for data: 84807424
I0810 12:46:20.084710 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.084720 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.084727 13394 net.cpp:425] drop1 <- InnerProduct19
I0810 12:46:20.084736 13394 net.cpp:399] drop1 -> Dropout19
I0810 12:46:20.084749 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.084758 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.084764 13394 net.cpp:156] Memory required for data: 84823808
I0810 12:46:20.084771 13394 layer_factory.hpp:77] Creating layer InnerProduct20
I0810 12:46:20.084784 13394 net.cpp:91] Creating Layer InnerProduct20
I0810 12:46:20.084792 13394 net.cpp:425] InnerProduct20 <- Dropout19
I0810 12:46:20.084802 13394 net.cpp:399] InnerProduct20 -> InnerProduct20
I0810 12:46:20.084861 13394 net.cpp:141] Setting up InnerProduct20
I0810 12:46:20.084869 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.084877 13394 net.cpp:156] Memory required for data: 84840192
I0810 12:46:20.084884 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.084892 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.084899 13394 layer_factory.hpp:77] Creating layer ReLU20
I0810 12:46:20.084908 13394 net.cpp:91] Creating Layer ReLU20
I0810 12:46:20.084916 13394 net.cpp:425] ReLU20 <- InnerProduct20
I0810 12:46:20.084926 13394 net.cpp:386] ReLU20 -> InnerProduct20 (in-place)
I0810 12:46:20.084936 13394 net.cpp:141] Setting up ReLU20
I0810 12:46:20.084945 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.084952 13394 net.cpp:156] Memory required for data: 84856576
I0810 12:46:20.084959 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.084969 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.084975 13394 net.cpp:425] drop2 <- InnerProduct20
I0810 12:46:20.084985 13394 net.cpp:399] drop2 -> Dropout20
I0810 12:46:20.084996 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.085005 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.085011 13394 net.cpp:156] Memory required for data: 84872960
I0810 12:46:20.085018 13394 layer_factory.hpp:77] Creating layer m10
I0810 12:46:20.085029 13394 net.cpp:91] Creating Layer m10
I0810 12:46:20.085054 13394 net.cpp:425] m10 <- Dropout20
I0810 12:46:20.085067 13394 net.cpp:399] m10 -> m10
I0810 12:46:20.085088 13394 net.cpp:141] Setting up m10
I0810 12:46:20.085095 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.085103 13394 net.cpp:156] Memory required for data: 84873216
I0810 12:46:20.085108 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.085116 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.085124 13394 layer_factory.hpp:77] Creating layer Concat11
I0810 12:46:20.085134 13394 net.cpp:91] Creating Layer Concat11
I0810 12:46:20.085141 13394 net.cpp:425] Concat11 <- i2
I0810 12:46:20.085151 13394 net.cpp:425] Concat11 <- i11_i1_10_split_1
I0810 12:46:20.085161 13394 net.cpp:399] Concat11 -> Concat11
I0810 12:46:20.085175 13394 net.cpp:141] Setting up Concat11
I0810 12:46:20.085186 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.085192 13394 net.cpp:156] Memory required for data: 86970368
I0810 12:46:20.085199 13394 layer_factory.hpp:77] Creating layer InnerProduct21
I0810 12:46:20.085209 13394 net.cpp:91] Creating Layer InnerProduct21
I0810 12:46:20.085216 13394 net.cpp:425] InnerProduct21 <- Concat11
I0810 12:46:20.085227 13394 net.cpp:399] InnerProduct21 -> InnerProduct21
I0810 12:46:20.089648 13394 net.cpp:141] Setting up InnerProduct21
I0810 12:46:20.089665 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.089673 13394 net.cpp:156] Memory required for data: 86986752
I0810 12:46:20.089681 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.089690 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.089699 13394 layer_factory.hpp:77] Creating layer ReLU21
I0810 12:46:20.089711 13394 net.cpp:91] Creating Layer ReLU21
I0810 12:46:20.089720 13394 net.cpp:425] ReLU21 <- InnerProduct21
I0810 12:46:20.089731 13394 net.cpp:386] ReLU21 -> InnerProduct21 (in-place)
I0810 12:46:20.089743 13394 net.cpp:141] Setting up ReLU21
I0810 12:46:20.089752 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.089759 13394 net.cpp:156] Memory required for data: 87003136
I0810 12:46:20.089766 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.089777 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.089784 13394 net.cpp:425] drop1 <- InnerProduct21
I0810 12:46:20.089797 13394 net.cpp:399] drop1 -> Dropout21
I0810 12:46:20.089810 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.089820 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.089828 13394 net.cpp:156] Memory required for data: 87019520
I0810 12:46:20.089834 13394 layer_factory.hpp:77] Creating layer InnerProduct22
I0810 12:46:20.089846 13394 net.cpp:91] Creating Layer InnerProduct22
I0810 12:46:20.089854 13394 net.cpp:425] InnerProduct22 <- Dropout21
I0810 12:46:20.089865 13394 net.cpp:399] InnerProduct22 -> InnerProduct22
I0810 12:46:20.089926 13394 net.cpp:141] Setting up InnerProduct22
I0810 12:46:20.089936 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.089944 13394 net.cpp:156] Memory required for data: 87035904
I0810 12:46:20.089952 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.089962 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.089969 13394 layer_factory.hpp:77] Creating layer ReLU22
I0810 12:46:20.089978 13394 net.cpp:91] Creating Layer ReLU22
I0810 12:46:20.089985 13394 net.cpp:425] ReLU22 <- InnerProduct22
I0810 12:46:20.089995 13394 net.cpp:386] ReLU22 -> InnerProduct22 (in-place)
I0810 12:46:20.090005 13394 net.cpp:141] Setting up ReLU22
I0810 12:46:20.090014 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.090020 13394 net.cpp:156] Memory required for data: 87052288
I0810 12:46:20.090028 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.090039 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.090064 13394 net.cpp:425] drop2 <- InnerProduct22
I0810 12:46:20.090075 13394 net.cpp:399] drop2 -> Dropout22
I0810 12:46:20.090090 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.090097 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.090104 13394 net.cpp:156] Memory required for data: 87068672
I0810 12:46:20.090111 13394 layer_factory.hpp:77] Creating layer m11
I0810 12:46:20.090121 13394 net.cpp:91] Creating Layer m11
I0810 12:46:20.090128 13394 net.cpp:425] m11 <- Dropout22
I0810 12:46:20.090139 13394 net.cpp:399] m11 -> m11
I0810 12:46:20.090162 13394 net.cpp:141] Setting up m11
I0810 12:46:20.090172 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.090178 13394 net.cpp:156] Memory required for data: 87068928
I0810 12:46:20.090207 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.090216 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.090224 13394 layer_factory.hpp:77] Creating layer Concat12
I0810 12:46:20.090234 13394 net.cpp:91] Creating Layer Concat12
I0810 12:46:20.090240 13394 net.cpp:425] Concat12 <- i3
I0810 12:46:20.090250 13394 net.cpp:425] Concat12 <- i11_i1_10_split_2
I0810 12:46:20.090261 13394 net.cpp:399] Concat12 -> Concat12
I0810 12:46:20.090276 13394 net.cpp:141] Setting up Concat12
I0810 12:46:20.090284 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.090291 13394 net.cpp:156] Memory required for data: 89166080
I0810 12:46:20.090298 13394 layer_factory.hpp:77] Creating layer InnerProduct23
I0810 12:46:20.090311 13394 net.cpp:91] Creating Layer InnerProduct23
I0810 12:46:20.090318 13394 net.cpp:425] InnerProduct23 <- Concat12
I0810 12:46:20.090329 13394 net.cpp:399] InnerProduct23 -> InnerProduct23
I0810 12:46:20.094714 13394 net.cpp:141] Setting up InnerProduct23
I0810 12:46:20.094732 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.094738 13394 net.cpp:156] Memory required for data: 89182464
I0810 12:46:20.094746 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.094756 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.094765 13394 layer_factory.hpp:77] Creating layer ReLU23
I0810 12:46:20.094775 13394 net.cpp:91] Creating Layer ReLU23
I0810 12:46:20.094784 13394 net.cpp:425] ReLU23 <- InnerProduct23
I0810 12:46:20.094795 13394 net.cpp:386] ReLU23 -> InnerProduct23 (in-place)
I0810 12:46:20.094807 13394 net.cpp:141] Setting up ReLU23
I0810 12:46:20.094815 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.094822 13394 net.cpp:156] Memory required for data: 89198848
I0810 12:46:20.094828 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.094838 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.094846 13394 net.cpp:425] drop1 <- InnerProduct23
I0810 12:46:20.094856 13394 net.cpp:399] drop1 -> Dropout23
I0810 12:46:20.094871 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.094882 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.094889 13394 net.cpp:156] Memory required for data: 89215232
I0810 12:46:20.094898 13394 layer_factory.hpp:77] Creating layer InnerProduct24
I0810 12:46:20.094909 13394 net.cpp:91] Creating Layer InnerProduct24
I0810 12:46:20.094916 13394 net.cpp:425] InnerProduct24 <- Dropout23
I0810 12:46:20.094928 13394 net.cpp:399] InnerProduct24 -> InnerProduct24
I0810 12:46:20.094985 13394 net.cpp:141] Setting up InnerProduct24
I0810 12:46:20.094995 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.095002 13394 net.cpp:156] Memory required for data: 89231616
I0810 12:46:20.095010 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.095019 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.095026 13394 layer_factory.hpp:77] Creating layer ReLU24
I0810 12:46:20.095036 13394 net.cpp:91] Creating Layer ReLU24
I0810 12:46:20.095042 13394 net.cpp:425] ReLU24 <- InnerProduct24
I0810 12:46:20.095052 13394 net.cpp:386] ReLU24 -> InnerProduct24 (in-place)
I0810 12:46:20.095080 13394 net.cpp:141] Setting up ReLU24
I0810 12:46:20.095090 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.095098 13394 net.cpp:156] Memory required for data: 89248000
I0810 12:46:20.095105 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.095114 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.095123 13394 net.cpp:425] drop2 <- InnerProduct24
I0810 12:46:20.095134 13394 net.cpp:399] drop2 -> Dropout24
I0810 12:46:20.095145 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.095155 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.095160 13394 net.cpp:156] Memory required for data: 89264384
I0810 12:46:20.095167 13394 layer_factory.hpp:77] Creating layer m12
I0810 12:46:20.095177 13394 net.cpp:91] Creating Layer m12
I0810 12:46:20.095185 13394 net.cpp:425] m12 <- Dropout24
I0810 12:46:20.095196 13394 net.cpp:399] m12 -> m12
I0810 12:46:20.095221 13394 net.cpp:141] Setting up m12
I0810 12:46:20.095230 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.095238 13394 net.cpp:156] Memory required for data: 89264640
I0810 12:46:20.095247 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.095254 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.095262 13394 layer_factory.hpp:77] Creating layer Concat13
I0810 12:46:20.095286 13394 net.cpp:91] Creating Layer Concat13
I0810 12:46:20.095295 13394 net.cpp:425] Concat13 <- i4
I0810 12:46:20.095304 13394 net.cpp:425] Concat13 <- i11_i1_10_split_3
I0810 12:46:20.095316 13394 net.cpp:399] Concat13 -> Concat13
I0810 12:46:20.095331 13394 net.cpp:141] Setting up Concat13
I0810 12:46:20.095342 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.095350 13394 net.cpp:156] Memory required for data: 91361792
I0810 12:46:20.095357 13394 layer_factory.hpp:77] Creating layer InnerProduct25
I0810 12:46:20.095369 13394 net.cpp:91] Creating Layer InnerProduct25
I0810 12:46:20.095377 13394 net.cpp:425] InnerProduct25 <- Concat13
I0810 12:46:20.095388 13394 net.cpp:399] InnerProduct25 -> InnerProduct25
I0810 12:46:20.100389 13394 net.cpp:141] Setting up InnerProduct25
I0810 12:46:20.100406 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.100414 13394 net.cpp:156] Memory required for data: 91378176
I0810 12:46:20.100424 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.100432 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.100440 13394 layer_factory.hpp:77] Creating layer ReLU25
I0810 12:46:20.100451 13394 net.cpp:91] Creating Layer ReLU25
I0810 12:46:20.100461 13394 net.cpp:425] ReLU25 <- InnerProduct25
I0810 12:46:20.100471 13394 net.cpp:386] ReLU25 -> InnerProduct25 (in-place)
I0810 12:46:20.100483 13394 net.cpp:141] Setting up ReLU25
I0810 12:46:20.100492 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.100499 13394 net.cpp:156] Memory required for data: 91394560
I0810 12:46:20.100507 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.100517 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.100525 13394 net.cpp:425] drop1 <- InnerProduct25
I0810 12:46:20.100536 13394 net.cpp:399] drop1 -> Dropout25
I0810 12:46:20.100551 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.100561 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.100569 13394 net.cpp:156] Memory required for data: 91410944
I0810 12:46:20.100575 13394 layer_factory.hpp:77] Creating layer InnerProduct26
I0810 12:46:20.100586 13394 net.cpp:91] Creating Layer InnerProduct26
I0810 12:46:20.100594 13394 net.cpp:425] InnerProduct26 <- Dropout25
I0810 12:46:20.100605 13394 net.cpp:399] InnerProduct26 -> InnerProduct26
I0810 12:46:20.100664 13394 net.cpp:141] Setting up InnerProduct26
I0810 12:46:20.100674 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.100680 13394 net.cpp:156] Memory required for data: 91427328
I0810 12:46:20.100687 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.100711 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.100718 13394 layer_factory.hpp:77] Creating layer ReLU26
I0810 12:46:20.100728 13394 net.cpp:91] Creating Layer ReLU26
I0810 12:46:20.100735 13394 net.cpp:425] ReLU26 <- InnerProduct26
I0810 12:46:20.100745 13394 net.cpp:386] ReLU26 -> InnerProduct26 (in-place)
I0810 12:46:20.100755 13394 net.cpp:141] Setting up ReLU26
I0810 12:46:20.100764 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.100771 13394 net.cpp:156] Memory required for data: 91443712
I0810 12:46:20.100778 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.100787 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.100795 13394 net.cpp:425] drop2 <- InnerProduct26
I0810 12:46:20.100806 13394 net.cpp:399] drop2 -> Dropout26
I0810 12:46:20.100819 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.100828 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.100836 13394 net.cpp:156] Memory required for data: 91460096
I0810 12:46:20.100842 13394 layer_factory.hpp:77] Creating layer m13
I0810 12:46:20.100853 13394 net.cpp:91] Creating Layer m13
I0810 12:46:20.100860 13394 net.cpp:425] m13 <- Dropout26
I0810 12:46:20.100873 13394 net.cpp:399] m13 -> m13
I0810 12:46:20.100894 13394 net.cpp:141] Setting up m13
I0810 12:46:20.100904 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.100910 13394 net.cpp:156] Memory required for data: 91460352
I0810 12:46:20.100917 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.100925 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.100934 13394 layer_factory.hpp:77] Creating layer Concat14
I0810 12:46:20.100944 13394 net.cpp:91] Creating Layer Concat14
I0810 12:46:20.100950 13394 net.cpp:425] Concat14 <- i5
I0810 12:46:20.100960 13394 net.cpp:425] Concat14 <- i11_i1_10_split_4
I0810 12:46:20.100972 13394 net.cpp:399] Concat14 -> Concat14
I0810 12:46:20.100986 13394 net.cpp:141] Setting up Concat14
I0810 12:46:20.100996 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.101002 13394 net.cpp:156] Memory required for data: 93557504
I0810 12:46:20.101008 13394 layer_factory.hpp:77] Creating layer InnerProduct27
I0810 12:46:20.101019 13394 net.cpp:91] Creating Layer InnerProduct27
I0810 12:46:20.101027 13394 net.cpp:425] InnerProduct27 <- Concat14
I0810 12:46:20.101038 13394 net.cpp:399] InnerProduct27 -> InnerProduct27
I0810 12:46:20.105455 13394 net.cpp:141] Setting up InnerProduct27
I0810 12:46:20.105474 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.105481 13394 net.cpp:156] Memory required for data: 93573888
I0810 12:46:20.105489 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.105497 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.105509 13394 layer_factory.hpp:77] Creating layer ReLU27
I0810 12:46:20.105521 13394 net.cpp:91] Creating Layer ReLU27
I0810 12:46:20.105530 13394 net.cpp:425] ReLU27 <- InnerProduct27
I0810 12:46:20.105540 13394 net.cpp:386] ReLU27 -> InnerProduct27 (in-place)
I0810 12:46:20.105553 13394 net.cpp:141] Setting up ReLU27
I0810 12:46:20.105563 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.105571 13394 net.cpp:156] Memory required for data: 93590272
I0810 12:46:20.105578 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.105587 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.105594 13394 net.cpp:425] drop1 <- InnerProduct27
I0810 12:46:20.105607 13394 net.cpp:399] drop1 -> Dropout27
I0810 12:46:20.105620 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.105629 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.105638 13394 net.cpp:156] Memory required for data: 93606656
I0810 12:46:20.105644 13394 layer_factory.hpp:77] Creating layer InnerProduct28
I0810 12:46:20.105655 13394 net.cpp:91] Creating Layer InnerProduct28
I0810 12:46:20.105684 13394 net.cpp:425] InnerProduct28 <- Dropout27
I0810 12:46:20.105695 13394 net.cpp:399] InnerProduct28 -> InnerProduct28
I0810 12:46:20.105784 13394 net.cpp:141] Setting up InnerProduct28
I0810 12:46:20.105795 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.105803 13394 net.cpp:156] Memory required for data: 93623040
I0810 12:46:20.105811 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.105819 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.105826 13394 layer_factory.hpp:77] Creating layer ReLU28
I0810 12:46:20.105835 13394 net.cpp:91] Creating Layer ReLU28
I0810 12:46:20.105842 13394 net.cpp:425] ReLU28 <- InnerProduct28
I0810 12:46:20.105852 13394 net.cpp:386] ReLU28 -> InnerProduct28 (in-place)
I0810 12:46:20.105864 13394 net.cpp:141] Setting up ReLU28
I0810 12:46:20.105871 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.105877 13394 net.cpp:156] Memory required for data: 93639424
I0810 12:46:20.105885 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.105893 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.105901 13394 net.cpp:425] drop2 <- InnerProduct28
I0810 12:46:20.105909 13394 net.cpp:399] drop2 -> Dropout28
I0810 12:46:20.105923 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.105931 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.105938 13394 net.cpp:156] Memory required for data: 93655808
I0810 12:46:20.105944 13394 layer_factory.hpp:77] Creating layer m14
I0810 12:46:20.105954 13394 net.cpp:91] Creating Layer m14
I0810 12:46:20.105962 13394 net.cpp:425] m14 <- Dropout28
I0810 12:46:20.105972 13394 net.cpp:399] m14 -> m14
I0810 12:46:20.105993 13394 net.cpp:141] Setting up m14
I0810 12:46:20.106003 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.106009 13394 net.cpp:156] Memory required for data: 93656064
I0810 12:46:20.106016 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.106026 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.106034 13394 layer_factory.hpp:77] Creating layer Concat15
I0810 12:46:20.106043 13394 net.cpp:91] Creating Layer Concat15
I0810 12:46:20.106050 13394 net.cpp:425] Concat15 <- i6
I0810 12:46:20.106060 13394 net.cpp:425] Concat15 <- i11_i1_10_split_5
I0810 12:46:20.106071 13394 net.cpp:399] Concat15 -> Concat15
I0810 12:46:20.106086 13394 net.cpp:141] Setting up Concat15
I0810 12:46:20.106094 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.106101 13394 net.cpp:156] Memory required for data: 95753216
I0810 12:46:20.106108 13394 layer_factory.hpp:77] Creating layer InnerProduct29
I0810 12:46:20.106119 13394 net.cpp:91] Creating Layer InnerProduct29
I0810 12:46:20.106127 13394 net.cpp:425] InnerProduct29 <- Concat15
I0810 12:46:20.106139 13394 net.cpp:399] InnerProduct29 -> InnerProduct29
I0810 12:46:20.110589 13394 net.cpp:141] Setting up InnerProduct29
I0810 12:46:20.110607 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.110615 13394 net.cpp:156] Memory required for data: 95769600
I0810 12:46:20.110622 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.110631 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.110640 13394 layer_factory.hpp:77] Creating layer ReLU29
I0810 12:46:20.110651 13394 net.cpp:91] Creating Layer ReLU29
I0810 12:46:20.110658 13394 net.cpp:425] ReLU29 <- InnerProduct29
I0810 12:46:20.110668 13394 net.cpp:386] ReLU29 -> InnerProduct29 (in-place)
I0810 12:46:20.110680 13394 net.cpp:141] Setting up ReLU29
I0810 12:46:20.110688 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.110695 13394 net.cpp:156] Memory required for data: 95785984
I0810 12:46:20.110702 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.110710 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.110718 13394 net.cpp:425] drop1 <- InnerProduct29
I0810 12:46:20.110748 13394 net.cpp:399] drop1 -> Dropout29
I0810 12:46:20.110762 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.110770 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.110777 13394 net.cpp:156] Memory required for data: 95802368
I0810 12:46:20.110785 13394 layer_factory.hpp:77] Creating layer InnerProduct30
I0810 12:46:20.110797 13394 net.cpp:91] Creating Layer InnerProduct30
I0810 12:46:20.110805 13394 net.cpp:425] InnerProduct30 <- Dropout29
I0810 12:46:20.110816 13394 net.cpp:399] InnerProduct30 -> InnerProduct30
I0810 12:46:20.110875 13394 net.cpp:141] Setting up InnerProduct30
I0810 12:46:20.110884 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.110890 13394 net.cpp:156] Memory required for data: 95818752
I0810 12:46:20.110898 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.110906 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.110914 13394 layer_factory.hpp:77] Creating layer ReLU30
I0810 12:46:20.110924 13394 net.cpp:91] Creating Layer ReLU30
I0810 12:46:20.110930 13394 net.cpp:425] ReLU30 <- InnerProduct30
I0810 12:46:20.110940 13394 net.cpp:386] ReLU30 -> InnerProduct30 (in-place)
I0810 12:46:20.110952 13394 net.cpp:141] Setting up ReLU30
I0810 12:46:20.110962 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.110970 13394 net.cpp:156] Memory required for data: 95835136
I0810 12:46:20.110975 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.110985 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.110993 13394 net.cpp:425] drop2 <- InnerProduct30
I0810 12:46:20.111003 13394 net.cpp:399] drop2 -> Dropout30
I0810 12:46:20.111016 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.111026 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.111032 13394 net.cpp:156] Memory required for data: 95851520
I0810 12:46:20.111038 13394 layer_factory.hpp:77] Creating layer m15
I0810 12:46:20.111049 13394 net.cpp:91] Creating Layer m15
I0810 12:46:20.111057 13394 net.cpp:425] m15 <- Dropout30
I0810 12:46:20.111068 13394 net.cpp:399] m15 -> m15
I0810 12:46:20.111088 13394 net.cpp:141] Setting up m15
I0810 12:46:20.111096 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.111102 13394 net.cpp:156] Memory required for data: 95851776
I0810 12:46:20.111109 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.111119 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.111126 13394 layer_factory.hpp:77] Creating layer Concat16
I0810 12:46:20.111136 13394 net.cpp:91] Creating Layer Concat16
I0810 12:46:20.111143 13394 net.cpp:425] Concat16 <- i7
I0810 12:46:20.111152 13394 net.cpp:425] Concat16 <- i11_i1_10_split_6
I0810 12:46:20.111162 13394 net.cpp:399] Concat16 -> Concat16
I0810 12:46:20.111178 13394 net.cpp:141] Setting up Concat16
I0810 12:46:20.111187 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.111194 13394 net.cpp:156] Memory required for data: 97948928
I0810 12:46:20.111201 13394 layer_factory.hpp:77] Creating layer InnerProduct31
I0810 12:46:20.111248 13394 net.cpp:91] Creating Layer InnerProduct31
I0810 12:46:20.111255 13394 net.cpp:425] InnerProduct31 <- Concat16
I0810 12:46:20.111266 13394 net.cpp:399] InnerProduct31 -> InnerProduct31
I0810 12:46:20.116279 13394 net.cpp:141] Setting up InnerProduct31
I0810 12:46:20.116302 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.116310 13394 net.cpp:156] Memory required for data: 97965312
I0810 12:46:20.116322 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.116331 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.116345 13394 layer_factory.hpp:77] Creating layer ReLU31
I0810 12:46:20.116358 13394 net.cpp:91] Creating Layer ReLU31
I0810 12:46:20.116367 13394 net.cpp:425] ReLU31 <- InnerProduct31
I0810 12:46:20.116379 13394 net.cpp:386] ReLU31 -> InnerProduct31 (in-place)
I0810 12:46:20.116410 13394 net.cpp:141] Setting up ReLU31
I0810 12:46:20.116421 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.116430 13394 net.cpp:156] Memory required for data: 97981696
I0810 12:46:20.116436 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.116446 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.116453 13394 net.cpp:425] drop1 <- InnerProduct31
I0810 12:46:20.116466 13394 net.cpp:399] drop1 -> Dropout31
I0810 12:46:20.116479 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.116489 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.116497 13394 net.cpp:156] Memory required for data: 97998080
I0810 12:46:20.116505 13394 layer_factory.hpp:77] Creating layer InnerProduct32
I0810 12:46:20.116519 13394 net.cpp:91] Creating Layer InnerProduct32
I0810 12:46:20.116528 13394 net.cpp:425] InnerProduct32 <- Dropout31
I0810 12:46:20.116539 13394 net.cpp:399] InnerProduct32 -> InnerProduct32
I0810 12:46:20.116596 13394 net.cpp:141] Setting up InnerProduct32
I0810 12:46:20.116607 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.116614 13394 net.cpp:156] Memory required for data: 98014464
I0810 12:46:20.116623 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.116631 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.116641 13394 layer_factory.hpp:77] Creating layer ReLU32
I0810 12:46:20.116650 13394 net.cpp:91] Creating Layer ReLU32
I0810 12:46:20.116658 13394 net.cpp:425] ReLU32 <- InnerProduct32
I0810 12:46:20.116668 13394 net.cpp:386] ReLU32 -> InnerProduct32 (in-place)
I0810 12:46:20.116680 13394 net.cpp:141] Setting up ReLU32
I0810 12:46:20.116690 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.116696 13394 net.cpp:156] Memory required for data: 98030848
I0810 12:46:20.116703 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.116711 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.116719 13394 net.cpp:425] drop2 <- InnerProduct32
I0810 12:46:20.116729 13394 net.cpp:399] drop2 -> Dropout32
I0810 12:46:20.116740 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.116750 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.116755 13394 net.cpp:156] Memory required for data: 98047232
I0810 12:46:20.116762 13394 layer_factory.hpp:77] Creating layer m16
I0810 12:46:20.116773 13394 net.cpp:91] Creating Layer m16
I0810 12:46:20.116781 13394 net.cpp:425] m16 <- Dropout32
I0810 12:46:20.116793 13394 net.cpp:399] m16 -> m16
I0810 12:46:20.116816 13394 net.cpp:141] Setting up m16
I0810 12:46:20.116827 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.116834 13394 net.cpp:156] Memory required for data: 98047488
I0810 12:46:20.116842 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.116852 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.116860 13394 layer_factory.hpp:77] Creating layer Concat17
I0810 12:46:20.116874 13394 net.cpp:91] Creating Layer Concat17
I0810 12:46:20.116881 13394 net.cpp:425] Concat17 <- i8
I0810 12:46:20.116890 13394 net.cpp:425] Concat17 <- i11_i1_10_split_7
I0810 12:46:20.116900 13394 net.cpp:399] Concat17 -> Concat17
I0810 12:46:20.116915 13394 net.cpp:141] Setting up Concat17
I0810 12:46:20.116925 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.116931 13394 net.cpp:156] Memory required for data: 100144640
I0810 12:46:20.116938 13394 layer_factory.hpp:77] Creating layer InnerProduct33
I0810 12:46:20.116948 13394 net.cpp:91] Creating Layer InnerProduct33
I0810 12:46:20.116955 13394 net.cpp:425] InnerProduct33 <- Concat17
I0810 12:46:20.116966 13394 net.cpp:399] InnerProduct33 -> InnerProduct33
I0810 12:46:20.121433 13394 net.cpp:141] Setting up InnerProduct33
I0810 12:46:20.121449 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.121457 13394 net.cpp:156] Memory required for data: 100161024
I0810 12:46:20.121467 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.121495 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.121505 13394 layer_factory.hpp:77] Creating layer ReLU33
I0810 12:46:20.121518 13394 net.cpp:91] Creating Layer ReLU33
I0810 12:46:20.121527 13394 net.cpp:425] ReLU33 <- InnerProduct33
I0810 12:46:20.121538 13394 net.cpp:386] ReLU33 -> InnerProduct33 (in-place)
I0810 12:46:20.121551 13394 net.cpp:141] Setting up ReLU33
I0810 12:46:20.121561 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.121567 13394 net.cpp:156] Memory required for data: 100177408
I0810 12:46:20.121573 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.121583 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.121589 13394 net.cpp:425] drop1 <- InnerProduct33
I0810 12:46:20.121601 13394 net.cpp:399] drop1 -> Dropout33
I0810 12:46:20.121616 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.121628 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.121634 13394 net.cpp:156] Memory required for data: 100193792
I0810 12:46:20.121641 13394 layer_factory.hpp:77] Creating layer InnerProduct34
I0810 12:46:20.121654 13394 net.cpp:91] Creating Layer InnerProduct34
I0810 12:46:20.121661 13394 net.cpp:425] InnerProduct34 <- Dropout33
I0810 12:46:20.121673 13394 net.cpp:399] InnerProduct34 -> InnerProduct34
I0810 12:46:20.121733 13394 net.cpp:141] Setting up InnerProduct34
I0810 12:46:20.121743 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.121749 13394 net.cpp:156] Memory required for data: 100210176
I0810 12:46:20.121757 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.121765 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.121773 13394 layer_factory.hpp:77] Creating layer ReLU34
I0810 12:46:20.121784 13394 net.cpp:91] Creating Layer ReLU34
I0810 12:46:20.121791 13394 net.cpp:425] ReLU34 <- InnerProduct34
I0810 12:46:20.121801 13394 net.cpp:386] ReLU34 -> InnerProduct34 (in-place)
I0810 12:46:20.121814 13394 net.cpp:141] Setting up ReLU34
I0810 12:46:20.121824 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.121830 13394 net.cpp:156] Memory required for data: 100226560
I0810 12:46:20.121837 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.121847 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.121855 13394 net.cpp:425] drop2 <- InnerProduct34
I0810 12:46:20.121865 13394 net.cpp:399] drop2 -> Dropout34
I0810 12:46:20.121877 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.121887 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.121896 13394 net.cpp:156] Memory required for data: 100242944
I0810 12:46:20.121902 13394 layer_factory.hpp:77] Creating layer m17
I0810 12:46:20.121913 13394 net.cpp:91] Creating Layer m17
I0810 12:46:20.121920 13394 net.cpp:425] m17 <- Dropout34
I0810 12:46:20.121933 13394 net.cpp:399] m17 -> m17
I0810 12:46:20.121955 13394 net.cpp:141] Setting up m17
I0810 12:46:20.121964 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.121970 13394 net.cpp:156] Memory required for data: 100243200
I0810 12:46:20.121978 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.121985 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.121992 13394 layer_factory.hpp:77] Creating layer Concat18
I0810 12:46:20.122002 13394 net.cpp:91] Creating Layer Concat18
I0810 12:46:20.122009 13394 net.cpp:425] Concat18 <- i9
I0810 12:46:20.122017 13394 net.cpp:425] Concat18 <- i11_i1_10_split_8
I0810 12:46:20.122028 13394 net.cpp:399] Concat18 -> Concat18
I0810 12:46:20.122041 13394 net.cpp:141] Setting up Concat18
I0810 12:46:20.122051 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.122056 13394 net.cpp:156] Memory required for data: 102340352
I0810 12:46:20.122063 13394 layer_factory.hpp:77] Creating layer InnerProduct35
I0810 12:46:20.122076 13394 net.cpp:91] Creating Layer InnerProduct35
I0810 12:46:20.122081 13394 net.cpp:425] InnerProduct35 <- Concat18
I0810 12:46:20.122103 13394 net.cpp:399] InnerProduct35 -> InnerProduct35
I0810 12:46:20.127249 13394 net.cpp:141] Setting up InnerProduct35
I0810 12:46:20.127266 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.127279 13394 net.cpp:156] Memory required for data: 102356736
I0810 12:46:20.127288 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.127296 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.127303 13394 layer_factory.hpp:77] Creating layer ReLU35
I0810 12:46:20.127313 13394 net.cpp:91] Creating Layer ReLU35
I0810 12:46:20.127322 13394 net.cpp:425] ReLU35 <- InnerProduct35
I0810 12:46:20.127334 13394 net.cpp:386] ReLU35 -> InnerProduct35 (in-place)
I0810 12:46:20.127346 13394 net.cpp:141] Setting up ReLU35
I0810 12:46:20.127357 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.127363 13394 net.cpp:156] Memory required for data: 102373120
I0810 12:46:20.127369 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.127379 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.127387 13394 net.cpp:425] drop1 <- InnerProduct35
I0810 12:46:20.127398 13394 net.cpp:399] drop1 -> Dropout35
I0810 12:46:20.127413 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.127423 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.127429 13394 net.cpp:156] Memory required for data: 102389504
I0810 12:46:20.127436 13394 layer_factory.hpp:77] Creating layer InnerProduct36
I0810 12:46:20.127447 13394 net.cpp:91] Creating Layer InnerProduct36
I0810 12:46:20.127455 13394 net.cpp:425] InnerProduct36 <- Dropout35
I0810 12:46:20.127467 13394 net.cpp:399] InnerProduct36 -> InnerProduct36
I0810 12:46:20.127523 13394 net.cpp:141] Setting up InnerProduct36
I0810 12:46:20.127533 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.127539 13394 net.cpp:156] Memory required for data: 102405888
I0810 12:46:20.127547 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.127555 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.127563 13394 layer_factory.hpp:77] Creating layer ReLU36
I0810 12:46:20.127573 13394 net.cpp:91] Creating Layer ReLU36
I0810 12:46:20.127578 13394 net.cpp:425] ReLU36 <- InnerProduct36
I0810 12:46:20.127588 13394 net.cpp:386] ReLU36 -> InnerProduct36 (in-place)
I0810 12:46:20.127600 13394 net.cpp:141] Setting up ReLU36
I0810 12:46:20.127609 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.127615 13394 net.cpp:156] Memory required for data: 102422272
I0810 12:46:20.127621 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.127631 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.127638 13394 net.cpp:425] drop2 <- InnerProduct36
I0810 12:46:20.127648 13394 net.cpp:399] drop2 -> Dropout36
I0810 12:46:20.127660 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.127671 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.127677 13394 net.cpp:156] Memory required for data: 102438656
I0810 12:46:20.127684 13394 layer_factory.hpp:77] Creating layer m18
I0810 12:46:20.127696 13394 net.cpp:91] Creating Layer m18
I0810 12:46:20.127703 13394 net.cpp:425] m18 <- Dropout36
I0810 12:46:20.127714 13394 net.cpp:399] m18 -> m18
I0810 12:46:20.127734 13394 net.cpp:141] Setting up m18
I0810 12:46:20.127743 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.127748 13394 net.cpp:156] Memory required for data: 102438912
I0810 12:46:20.127755 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.127764 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.127771 13394 layer_factory.hpp:77] Creating layer Concat19
I0810 12:46:20.127781 13394 net.cpp:91] Creating Layer Concat19
I0810 12:46:20.127787 13394 net.cpp:425] Concat19 <- i10
I0810 12:46:20.127797 13394 net.cpp:425] Concat19 <- i11_i1_10_split_9
I0810 12:46:20.127807 13394 net.cpp:399] Concat19 -> Concat19
I0810 12:46:20.127840 13394 net.cpp:141] Setting up Concat19
I0810 12:46:20.127849 13394 net.cpp:148] Top shape: 64 2 1 4096 (524288)
I0810 12:46:20.127856 13394 net.cpp:156] Memory required for data: 104536064
I0810 12:46:20.127862 13394 layer_factory.hpp:77] Creating layer InnerProduct37
I0810 12:46:20.127872 13394 net.cpp:91] Creating Layer InnerProduct37
I0810 12:46:20.127878 13394 net.cpp:425] InnerProduct37 <- Concat19
I0810 12:46:20.127889 13394 net.cpp:399] InnerProduct37 -> InnerProduct37
I0810 12:46:20.133734 13394 net.cpp:141] Setting up InnerProduct37
I0810 12:46:20.133754 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.133760 13394 net.cpp:156] Memory required for data: 104552448
I0810 12:46:20.133769 13394 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0810 12:46:20.133780 13394 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0810 12:46:20.133787 13394 layer_factory.hpp:77] Creating layer ReLU37
I0810 12:46:20.133798 13394 net.cpp:91] Creating Layer ReLU37
I0810 12:46:20.133806 13394 net.cpp:425] ReLU37 <- InnerProduct37
I0810 12:46:20.133817 13394 net.cpp:386] ReLU37 -> InnerProduct37 (in-place)
I0810 12:46:20.133829 13394 net.cpp:141] Setting up ReLU37
I0810 12:46:20.133838 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.133844 13394 net.cpp:156] Memory required for data: 104568832
I0810 12:46:20.133852 13394 layer_factory.hpp:77] Creating layer drop1
I0810 12:46:20.133862 13394 net.cpp:91] Creating Layer drop1
I0810 12:46:20.133870 13394 net.cpp:425] drop1 <- InnerProduct37
I0810 12:46:20.133883 13394 net.cpp:399] drop1 -> Dropout37
I0810 12:46:20.133898 13394 net.cpp:141] Setting up drop1
I0810 12:46:20.133908 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.133914 13394 net.cpp:156] Memory required for data: 104585216
I0810 12:46:20.133920 13394 layer_factory.hpp:77] Creating layer InnerProduct38
I0810 12:46:20.133932 13394 net.cpp:91] Creating Layer InnerProduct38
I0810 12:46:20.133939 13394 net.cpp:425] InnerProduct38 <- Dropout37
I0810 12:46:20.133950 13394 net.cpp:399] InnerProduct38 -> InnerProduct38
I0810 12:46:20.134009 13394 net.cpp:141] Setting up InnerProduct38
I0810 12:46:20.134018 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.134027 13394 net.cpp:156] Memory required for data: 104601600
I0810 12:46:20.134033 13394 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0810 12:46:20.134042 13394 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0810 12:46:20.134048 13394 layer_factory.hpp:77] Creating layer ReLU38
I0810 12:46:20.134057 13394 net.cpp:91] Creating Layer ReLU38
I0810 12:46:20.134064 13394 net.cpp:425] ReLU38 <- InnerProduct38
I0810 12:46:20.134073 13394 net.cpp:386] ReLU38 -> InnerProduct38 (in-place)
I0810 12:46:20.134085 13394 net.cpp:141] Setting up ReLU38
I0810 12:46:20.134094 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.134102 13394 net.cpp:156] Memory required for data: 104617984
I0810 12:46:20.134110 13394 layer_factory.hpp:77] Creating layer drop2
I0810 12:46:20.134120 13394 net.cpp:91] Creating Layer drop2
I0810 12:46:20.134129 13394 net.cpp:425] drop2 <- InnerProduct38
I0810 12:46:20.134140 13394 net.cpp:399] drop2 -> Dropout38
I0810 12:46:20.134155 13394 net.cpp:141] Setting up drop2
I0810 12:46:20.134165 13394 net.cpp:148] Top shape: 64 64 (4096)
I0810 12:46:20.134171 13394 net.cpp:156] Memory required for data: 104634368
I0810 12:46:20.134179 13394 layer_factory.hpp:77] Creating layer m19
I0810 12:46:20.134191 13394 net.cpp:91] Creating Layer m19
I0810 12:46:20.134199 13394 net.cpp:425] m19 <- Dropout38
I0810 12:46:20.134212 13394 net.cpp:399] m19 -> m19
I0810 12:46:20.134235 13394 net.cpp:141] Setting up m19
I0810 12:46:20.134246 13394 net.cpp:148] Top shape: 64 1 (64)
I0810 12:46:20.134253 13394 net.cpp:156] Memory required for data: 104634624
I0810 12:46:20.134260 13394 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0810 12:46:20.134286 13394 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0810 12:46:20.134294 13394 layer_factory.hpp:77] Creating layer con
I0810 12:46:20.134307 13394 net.cpp:91] Creating Layer con
I0810 12:46:20.134316 13394 net.cpp:425] con <- m1
I0810 12:46:20.134326 13394 net.cpp:425] con <- m2
I0810 12:46:20.134336 13394 net.cpp:425] con <- m3
I0810 12:46:20.134346 13394 net.cpp:425] con <- m4
I0810 12:46:20.134353 13394 net.cpp:425] con <- m5
I0810 12:46:20.134361 13394 net.cpp:425] con <- m6
I0810 12:46:20.134369 13394 net.cpp:425] con <- m7
I0810 12:46:20.134378 13394 net.cpp:425] con <- m8
I0810 12:46:20.134388 13394 net.cpp:425] con <- m9
I0810 12:46:20.134398 13394 net.cpp:425] con <- m10
I0810 12:46:20.134407 13394 net.cpp:425] con <- m11
I0810 12:46:20.134416 13394 net.cpp:425] con <- m12
I0810 12:46:20.134424 13394 net.cpp:425] con <- m13
I0810 12:46:20.134433 13394 net.cpp:425] con <- m14
I0810 12:46:20.134441 13394 net.cpp:425] con <- m15
I0810 12:46:20.134450 13394 net.cpp:425] con <- m16
I0810 12:46:20.134457 13394 net.cpp:425] con <- m17
I0810 12:46:20.134465 13394 net.cpp:425] con <- m18
I0810 12:46:20.134474 13394 net.cpp:425] con <- m19
I0810 12:46:20.134486 13394 net.cpp:399] con -> con
I0810 12:46:20.134505 13394 net.cpp:141] Setting up con
I0810 12:46:20.134516 13394 net.cpp:148] Top shape: 64 19 (1216)
I0810 12:46:20.134522 13394 net.cpp:156] Memory required for data: 104639488
I0810 12:46:20.134531 13394 layer_factory.hpp:77] Creating layer r1
I0810 12:46:20.134544 13394 net.cpp:91] Creating Layer r1
I0810 12:46:20.134552 13394 net.cpp:425] r1 <- con
I0810 12:46:20.134563 13394 net.cpp:399] r1 -> r1
I0810 12:46:20.134580 13394 net.cpp:141] Setting up r1
I0810 12:46:20.134591 13394 net.cpp:148] Top shape: 64 1 1 19 (1216)
I0810 12:46:20.134598 13394 net.cpp:156] Memory required for data: 104644352
I0810 12:46:20.134604 13394 layer_factory.hpp:77] Creating layer p
I0810 12:46:20.134615 13394 net.cpp:91] Creating Layer p
I0810 12:46:20.134624 13394 net.cpp:425] p <- r1
I0810 12:46:20.134634 13394 net.cpp:399] p -> p
I0810 12:46:20.134652 13394 net.cpp:141] Setting up p
I0810 12:46:20.134661 13394 net.cpp:148] Top shape: 64 1 1 1 (64)
I0810 12:46:20.134667 13394 net.cpp:156] Memory required for data: 104644608
I0810 12:46:20.134675 13394 layer_factory.hpp:77] Creating layer r2
I0810 12:46:20.134686 13394 net.cpp:91] Creating Layer r2
I0810 12:46:20.134693 13394 net.cpp:425] r2 <- p
I0810 12:46:20.134704 13394 net.cpp:399] r2 -> r2
I0810 12:46:20.134719 13394 net.cpp:141] Setting up r2
I0810 12:46:20.134729 13394 net.cpp:148] Top shape: 64 1 1 1 (64)
I0810 12:46:20.134737 13394 net.cpp:156] Memory required for data: 104644864
I0810 12:46:20.134744 13394 layer_factory.hpp:77] Creating layer padL
I0810 12:46:20.134754 13394 net.cpp:91] Creating Layer padL
I0810 12:46:20.134763 13394 net.cpp:425] padL <- label_data_1_split_1
I0810 12:46:20.134774 13394 net.cpp:399] padL -> padL
I0810 12:46:20.134790 13394 net.cpp:141] Setting up padL
I0810 12:46:20.134800 13394 net.cpp:148] Top shape: 64 1 1 1 (64)
I0810 12:46:20.134807 13394 net.cpp:156] Memory required for data: 104645120
I0810 12:46:20.134815 13394 layer_factory.hpp:77] Creating layer pad
I0810 12:46:20.134826 13394 net.cpp:91] Creating Layer pad
I0810 12:46:20.134835 13394 net.cpp:425] pad <- r2
I0810 12:46:20.134842 13394 net.cpp:425] pad <- padL
I0810 12:46:20.134855 13394 net.cpp:399] pad -> pad
I0810 12:46:20.134868 13394 net.cpp:141] Setting up pad
I0810 12:46:20.134879 13394 net.cpp:148] Top shape: 64 2 1 1 (128)
I0810 12:46:20.134886 13394 net.cpp:156] Memory required for data: 104645632
I0810 12:46:20.134893 13394 layer_factory.hpp:77] Creating layer pad_pad_0_split
I0810 12:46:20.134904 13394 net.cpp:91] Creating Layer pad_pad_0_split
I0810 12:46:20.134912 13394 net.cpp:425] pad_pad_0_split <- pad
I0810 12:46:20.134922 13394 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_0
I0810 12:46:20.134934 13394 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_1
I0810 12:46:20.134950 13394 net.cpp:141] Setting up pad_pad_0_split
I0810 12:46:20.134989 13394 net.cpp:148] Top shape: 64 2 1 1 (128)
I0810 12:46:20.134999 13394 net.cpp:148] Top shape: 64 2 1 1 (128)
I0810 12:46:20.135005 13394 net.cpp:156] Memory required for data: 104646656
I0810 12:46:20.135013 13394 layer_factory.hpp:77] Creating layer loss
I0810 12:46:20.135023 13394 net.cpp:91] Creating Layer loss
I0810 12:46:20.135030 13394 net.cpp:425] loss <- pad_pad_0_split_0
I0810 12:46:20.135040 13394 net.cpp:425] loss <- th_th_0_split_0
I0810 12:46:20.135052 13394 net.cpp:399] loss -> loss
I0810 12:46:20.135067 13394 net.cpp:141] Setting up loss
I0810 12:46:20.135076 13394 net.cpp:148] Top shape: (1)
I0810 12:46:20.135082 13394 net.cpp:151]     with loss weight 1
I0810 12:46:20.135099 13394 net.cpp:156] Memory required for data: 104646660
I0810 12:46:20.135107 13394 layer_factory.hpp:77] Creating layer accuracy
I0810 12:46:20.135120 13394 net.cpp:91] Creating Layer accuracy
I0810 12:46:20.135129 13394 net.cpp:425] accuracy <- pad_pad_0_split_1
I0810 12:46:20.135138 13394 net.cpp:425] accuracy <- th_th_0_split_1
I0810 12:46:20.135151 13394 net.cpp:399] accuracy -> accuracy
I0810 12:46:20.135165 13394 net.cpp:141] Setting up accuracy
I0810 12:46:20.135174 13394 net.cpp:148] Top shape: (1)
I0810 12:46:20.135180 13394 net.cpp:156] Memory required for data: 104646664
I0810 12:46:20.135188 13394 net.cpp:219] accuracy does not need backward computation.
I0810 12:46:20.135197 13394 net.cpp:217] loss needs backward computation.
I0810 12:46:20.135206 13394 net.cpp:217] pad_pad_0_split needs backward computation.
I0810 12:46:20.135215 13394 net.cpp:217] pad needs backward computation.
I0810 12:46:20.135223 13394 net.cpp:219] padL does not need backward computation.
I0810 12:46:20.135232 13394 net.cpp:217] r2 needs backward computation.
I0810 12:46:20.135241 13394 net.cpp:217] p needs backward computation.
I0810 12:46:20.135249 13394 net.cpp:217] r1 needs backward computation.
I0810 12:46:20.135258 13394 net.cpp:217] con needs backward computation.
I0810 12:46:20.135283 13394 net.cpp:217] m19 needs backward computation.
I0810 12:46:20.135293 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135301 13394 net.cpp:217] ReLU38 needs backward computation.
I0810 12:46:20.135309 13394 net.cpp:217] InnerProduct38 needs backward computation.
I0810 12:46:20.135318 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.135326 13394 net.cpp:217] ReLU37 needs backward computation.
I0810 12:46:20.135334 13394 net.cpp:217] InnerProduct37 needs backward computation.
I0810 12:46:20.135344 13394 net.cpp:219] Concat19 does not need backward computation.
I0810 12:46:20.135355 13394 net.cpp:217] m18 needs backward computation.
I0810 12:46:20.135365 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135372 13394 net.cpp:217] ReLU36 needs backward computation.
I0810 12:46:20.135380 13394 net.cpp:217] InnerProduct36 needs backward computation.
I0810 12:46:20.135387 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.135396 13394 net.cpp:217] ReLU35 needs backward computation.
I0810 12:46:20.135406 13394 net.cpp:217] InnerProduct35 needs backward computation.
I0810 12:46:20.135413 13394 net.cpp:219] Concat18 does not need backward computation.
I0810 12:46:20.135422 13394 net.cpp:217] m17 needs backward computation.
I0810 12:46:20.135431 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135439 13394 net.cpp:217] ReLU34 needs backward computation.
I0810 12:46:20.135447 13394 net.cpp:217] InnerProduct34 needs backward computation.
I0810 12:46:20.135455 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.135463 13394 net.cpp:217] ReLU33 needs backward computation.
I0810 12:46:20.135471 13394 net.cpp:217] InnerProduct33 needs backward computation.
I0810 12:46:20.135479 13394 net.cpp:219] Concat17 does not need backward computation.
I0810 12:46:20.135488 13394 net.cpp:217] m16 needs backward computation.
I0810 12:46:20.135498 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135505 13394 net.cpp:217] ReLU32 needs backward computation.
I0810 12:46:20.135525 13394 net.cpp:217] InnerProduct32 needs backward computation.
I0810 12:46:20.135535 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.135543 13394 net.cpp:217] ReLU31 needs backward computation.
I0810 12:46:20.135550 13394 net.cpp:217] InnerProduct31 needs backward computation.
I0810 12:46:20.135558 13394 net.cpp:219] Concat16 does not need backward computation.
I0810 12:46:20.135567 13394 net.cpp:217] m15 needs backward computation.
I0810 12:46:20.135576 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135586 13394 net.cpp:217] ReLU30 needs backward computation.
I0810 12:46:20.135592 13394 net.cpp:217] InnerProduct30 needs backward computation.
I0810 12:46:20.135601 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.135608 13394 net.cpp:217] ReLU29 needs backward computation.
I0810 12:46:20.135617 13394 net.cpp:217] InnerProduct29 needs backward computation.
I0810 12:46:20.135624 13394 net.cpp:219] Concat15 does not need backward computation.
I0810 12:46:20.135633 13394 net.cpp:217] m14 needs backward computation.
I0810 12:46:20.135643 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135651 13394 net.cpp:217] ReLU28 needs backward computation.
I0810 12:46:20.135659 13394 net.cpp:217] InnerProduct28 needs backward computation.
I0810 12:46:20.135666 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.135674 13394 net.cpp:217] ReLU27 needs backward computation.
I0810 12:46:20.135684 13394 net.cpp:217] InnerProduct27 needs backward computation.
I0810 12:46:20.135694 13394 net.cpp:219] Concat14 does not need backward computation.
I0810 12:46:20.135704 13394 net.cpp:217] m13 needs backward computation.
I0810 12:46:20.135711 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135720 13394 net.cpp:217] ReLU26 needs backward computation.
I0810 12:46:20.135727 13394 net.cpp:217] InnerProduct26 needs backward computation.
I0810 12:46:20.135735 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.135743 13394 net.cpp:217] ReLU25 needs backward computation.
I0810 12:46:20.135751 13394 net.cpp:217] InnerProduct25 needs backward computation.
I0810 12:46:20.135759 13394 net.cpp:219] Concat13 does not need backward computation.
I0810 12:46:20.135769 13394 net.cpp:217] m12 needs backward computation.
I0810 12:46:20.135777 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135785 13394 net.cpp:217] ReLU24 needs backward computation.
I0810 12:46:20.135793 13394 net.cpp:217] InnerProduct24 needs backward computation.
I0810 12:46:20.135803 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.135812 13394 net.cpp:217] ReLU23 needs backward computation.
I0810 12:46:20.135819 13394 net.cpp:217] InnerProduct23 needs backward computation.
I0810 12:46:20.135828 13394 net.cpp:219] Concat12 does not need backward computation.
I0810 12:46:20.135838 13394 net.cpp:217] m11 needs backward computation.
I0810 12:46:20.135846 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135854 13394 net.cpp:217] ReLU22 needs backward computation.
I0810 12:46:20.135862 13394 net.cpp:217] InnerProduct22 needs backward computation.
I0810 12:46:20.135871 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.135879 13394 net.cpp:217] ReLU21 needs backward computation.
I0810 12:46:20.135886 13394 net.cpp:217] InnerProduct21 needs backward computation.
I0810 12:46:20.135895 13394 net.cpp:219] Concat11 does not need backward computation.
I0810 12:46:20.135905 13394 net.cpp:217] m10 needs backward computation.
I0810 12:46:20.135915 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135922 13394 net.cpp:217] ReLU20 needs backward computation.
I0810 12:46:20.135929 13394 net.cpp:217] InnerProduct20 needs backward computation.
I0810 12:46:20.135937 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.135946 13394 net.cpp:217] ReLU19 needs backward computation.
I0810 12:46:20.135954 13394 net.cpp:217] InnerProduct19 needs backward computation.
I0810 12:46:20.135972 13394 net.cpp:219] Concat10 does not need backward computation.
I0810 12:46:20.135982 13394 net.cpp:217] m9 needs backward computation.
I0810 12:46:20.135990 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.135999 13394 net.cpp:217] ReLU18 needs backward computation.
I0810 12:46:20.136008 13394 net.cpp:217] InnerProduct18 needs backward computation.
I0810 12:46:20.136016 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.136025 13394 net.cpp:217] ReLU17 needs backward computation.
I0810 12:46:20.136032 13394 net.cpp:217] InnerProduct17 needs backward computation.
I0810 12:46:20.136041 13394 net.cpp:219] Concat9 does not need backward computation.
I0810 12:46:20.136051 13394 net.cpp:217] m8 needs backward computation.
I0810 12:46:20.136060 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.136068 13394 net.cpp:217] ReLU16 needs backward computation.
I0810 12:46:20.136076 13394 net.cpp:217] InnerProduct16 needs backward computation.
I0810 12:46:20.136083 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.136092 13394 net.cpp:217] ReLU15 needs backward computation.
I0810 12:46:20.136099 13394 net.cpp:217] InnerProduct15 needs backward computation.
I0810 12:46:20.136108 13394 net.cpp:219] Concat8 does not need backward computation.
I0810 12:46:20.136117 13394 net.cpp:217] m7 needs backward computation.
I0810 12:46:20.136126 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.136135 13394 net.cpp:217] ReLU14 needs backward computation.
I0810 12:46:20.136143 13394 net.cpp:217] InnerProduct14 needs backward computation.
I0810 12:46:20.136152 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.136159 13394 net.cpp:217] ReLU13 needs backward computation.
I0810 12:46:20.136167 13394 net.cpp:217] InnerProduct13 needs backward computation.
I0810 12:46:20.136174 13394 net.cpp:219] Concat7 does not need backward computation.
I0810 12:46:20.136184 13394 net.cpp:217] m6 needs backward computation.
I0810 12:46:20.136193 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.136200 13394 net.cpp:217] ReLU12 needs backward computation.
I0810 12:46:20.136209 13394 net.cpp:217] InnerProduct12 needs backward computation.
I0810 12:46:20.136217 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.136225 13394 net.cpp:217] ReLU11 needs backward computation.
I0810 12:46:20.136232 13394 net.cpp:217] InnerProduct11 needs backward computation.
I0810 12:46:20.136240 13394 net.cpp:219] Concat6 does not need backward computation.
I0810 12:46:20.136250 13394 net.cpp:217] m5 needs backward computation.
I0810 12:46:20.136260 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.136267 13394 net.cpp:217] ReLU10 needs backward computation.
I0810 12:46:20.136274 13394 net.cpp:217] InnerProduct10 needs backward computation.
I0810 12:46:20.136281 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.136291 13394 net.cpp:217] ReLU9 needs backward computation.
I0810 12:46:20.136299 13394 net.cpp:217] InnerProduct9 needs backward computation.
I0810 12:46:20.136308 13394 net.cpp:219] Concat5 does not need backward computation.
I0810 12:46:20.136318 13394 net.cpp:217] m4 needs backward computation.
I0810 12:46:20.136327 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.136334 13394 net.cpp:217] ReLU8 needs backward computation.
I0810 12:46:20.136343 13394 net.cpp:217] InnerProduct8 needs backward computation.
I0810 12:46:20.136350 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.136358 13394 net.cpp:217] ReLU7 needs backward computation.
I0810 12:46:20.136365 13394 net.cpp:217] InnerProduct7 needs backward computation.
I0810 12:46:20.136373 13394 net.cpp:219] Concat4 does not need backward computation.
I0810 12:46:20.136384 13394 net.cpp:217] m3 needs backward computation.
I0810 12:46:20.136391 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.136399 13394 net.cpp:217] ReLU6 needs backward computation.
I0810 12:46:20.136417 13394 net.cpp:217] InnerProduct6 needs backward computation.
I0810 12:46:20.136427 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.136435 13394 net.cpp:217] ReLU5 needs backward computation.
I0810 12:46:20.136443 13394 net.cpp:217] InnerProduct5 needs backward computation.
I0810 12:46:20.136451 13394 net.cpp:219] Concat3 does not need backward computation.
I0810 12:46:20.136461 13394 net.cpp:217] m2 needs backward computation.
I0810 12:46:20.136469 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.136477 13394 net.cpp:217] ReLU4 needs backward computation.
I0810 12:46:20.136487 13394 net.cpp:217] InnerProduct4 needs backward computation.
I0810 12:46:20.136495 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.136503 13394 net.cpp:217] ReLU3 needs backward computation.
I0810 12:46:20.136510 13394 net.cpp:217] InnerProduct3 needs backward computation.
I0810 12:46:20.136518 13394 net.cpp:219] Concat2 does not need backward computation.
I0810 12:46:20.136526 13394 net.cpp:217] m1 needs backward computation.
I0810 12:46:20.136534 13394 net.cpp:217] drop2 needs backward computation.
I0810 12:46:20.136543 13394 net.cpp:217] ReLU2 needs backward computation.
I0810 12:46:20.136550 13394 net.cpp:217] InnerProduct2 needs backward computation.
I0810 12:46:20.136559 13394 net.cpp:217] drop1 needs backward computation.
I0810 12:46:20.136566 13394 net.cpp:217] ReLU1 needs backward computation.
I0810 12:46:20.136574 13394 net.cpp:217] InnerProduct1 needs backward computation.
I0810 12:46:20.136582 13394 net.cpp:219] Concat1 does not need backward computation.
I0810 12:46:20.136595 13394 net.cpp:219] i11_i1_10_split does not need backward computation.
I0810 12:46:20.136605 13394 net.cpp:219] i1_i1_0_split does not need backward computation.
I0810 12:46:20.136617 13394 net.cpp:219] i1 does not need backward computation.
I0810 12:46:20.136626 13394 net.cpp:219] th_th_0_split does not need backward computation.
I0810 12:46:20.136634 13394 net.cpp:219] th does not need backward computation.
I0810 12:46:20.136643 13394 net.cpp:219] label_data_1_split does not need backward computation.
I0810 12:46:20.136652 13394 net.cpp:219] data does not need backward computation.
I0810 12:46:20.136659 13394 net.cpp:261] This network produces output accuracy
I0810 12:46:20.136667 13394 net.cpp:261] This network produces output loss
I0810 12:46:20.136991 13394 net.cpp:274] Network initialization done.
I0810 12:46:20.138038 13394 solver.cpp:60] Solver scaffolding done.
I0810 12:46:20.138084 13394 caffe.cpp:219] Starting Optimization
I0810 12:46:20.138092 13394 solver.cpp:279] Solving 
I0810 12:46:20.138098 13394 solver.cpp:280] Learning Rate Policy: inv
I0810 12:46:20.138778 13394 solver.cpp:337] Iteration 0, Testing net (#0)
I0810 12:46:20.138906 13394 blocking_queue.cpp:50] Data layer prefetch queue empty
I0810 12:46:34.291559 13394 solver.cpp:404]     Test net output #0: accuracy = 1
I0810 12:46:34.291613 13394 solver.cpp:404]     Test net output #1: loss = 0.884823 (* 1 = 0.884823 loss)
I0810 12:46:34.739156 13394 solver.cpp:228] Iteration 0, loss = 1.10655
I0810 12:46:34.739199 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 12:46:34.739214 13394 solver.cpp:244]     Train net output #1: loss = 1.10655 (* 1 = 1.10655 loss)
I0810 12:46:34.739231 13394 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0810 12:46:37.272512 13403 blocking_queue.cpp:50] Waiting for data
I0810 12:46:40.832713 13394 solver.cpp:228] Iteration 10, loss = 0.692881
I0810 12:46:40.832764 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 12:46:40.832782 13394 solver.cpp:244]     Train net output #1: loss = 0.692881 (* 1 = 0.692881 loss)
I0810 12:46:40.832799 13394 sgd_solver.cpp:106] Iteration 10, lr = 0.00999251
I0810 12:46:52.736362 13394 solver.cpp:228] Iteration 20, loss = 0.232038
I0810 12:46:52.736589 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 12:46:52.736625 13394 solver.cpp:244]     Train net output #1: loss = 0.232038 (* 1 = 0.232038 loss)
I0810 12:46:52.736655 13394 sgd_solver.cpp:106] Iteration 20, lr = 0.00998503
I0810 12:46:55.065526 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:47:02.323175 13394 solver.cpp:228] Iteration 30, loss = 0.293398
I0810 12:47:02.323230 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:47:02.323247 13394 solver.cpp:244]     Train net output #1: loss = 0.293398 (* 1 = 0.293398 loss)
I0810 12:47:02.323261 13394 sgd_solver.cpp:106] Iteration 30, lr = 0.00997756
I0810 12:47:11.546283 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:47:13.148339 13394 solver.cpp:228] Iteration 40, loss = 0.37792
I0810 12:47:13.148387 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 12:47:13.148406 13394 solver.cpp:244]     Train net output #1: loss = 0.37792 (* 1 = 0.37792 loss)
I0810 12:47:13.148422 13394 sgd_solver.cpp:106] Iteration 40, lr = 0.0099701
I0810 12:47:22.071837 13394 solver.cpp:228] Iteration 50, loss = 0.221614
I0810 12:47:22.071882 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:47:22.072013 13394 solver.cpp:244]     Train net output #1: loss = 0.221614 (* 1 = 0.221614 loss)
I0810 12:47:22.072034 13394 sgd_solver.cpp:106] Iteration 50, lr = 0.00996266
I0810 12:47:24.866060 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:47:30.918459 13394 solver.cpp:228] Iteration 60, loss = 0.0781568
I0810 12:47:30.918606 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 12:47:30.918642 13394 solver.cpp:244]     Train net output #1: loss = 0.0781568 (* 1 = 0.0781568 loss)
I0810 12:47:30.918673 13394 sgd_solver.cpp:106] Iteration 60, lr = 0.00995523
I0810 12:47:38.405110 13394 solver.cpp:228] Iteration 70, loss = 0.110527
I0810 12:47:38.405155 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 12:47:38.405172 13394 solver.cpp:244]     Train net output #1: loss = 0.110527 (* 1 = 0.110527 loss)
I0810 12:47:38.405189 13394 sgd_solver.cpp:106] Iteration 70, lr = 0.00994782
I0810 12:47:39.402834 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:47:49.163110 13394 solver.cpp:228] Iteration 80, loss = 0.140058
I0810 12:47:49.163159 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 12:47:49.163177 13394 solver.cpp:244]     Train net output #1: loss = 0.140058 (* 1 = 0.140058 loss)
I0810 12:47:49.163192 13394 sgd_solver.cpp:106] Iteration 80, lr = 0.00994042
I0810 12:47:55.619968 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:47:58.256831 13394 solver.cpp:228] Iteration 90, loss = 0.252517
I0810 12:47:58.256872 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:47:58.256888 13394 solver.cpp:244]     Train net output #1: loss = 0.252517 (* 1 = 0.252517 loss)
I0810 12:47:58.256902 13394 sgd_solver.cpp:106] Iteration 90, lr = 0.00993303
I0810 12:48:09.624486 13394 solver.cpp:337] Iteration 100, Testing net (#0)
I0810 12:48:12.394162 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:48:13.715281 13394 solver.cpp:404]     Test net output #0: accuracy = 0.682813
I0810 12:48:13.715534 13394 solver.cpp:404]     Test net output #1: loss = 1.39417 (* 1 = 1.39417 loss)
I0810 12:48:14.017318 13394 solver.cpp:228] Iteration 100, loss = 0.229054
I0810 12:48:14.017362 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:48:14.017382 13394 solver.cpp:244]     Train net output #1: loss = 0.229054 (* 1 = 0.229054 loss)
I0810 12:48:14.017398 13394 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0810 12:48:24.000695 13394 solver.cpp:228] Iteration 110, loss = 0.0988402
I0810 12:48:24.000741 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 12:48:24.000759 13394 solver.cpp:244]     Train net output #1: loss = 0.0988402 (* 1 = 0.0988402 loss)
I0810 12:48:24.000776 13394 sgd_solver.cpp:106] Iteration 110, lr = 0.00991829
I0810 12:48:27.905707 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:48:34.628993 13394 solver.cpp:228] Iteration 120, loss = 0.15985
I0810 12:48:34.629045 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:48:34.629063 13394 solver.cpp:244]     Train net output #1: loss = 0.15985 (* 1 = 0.15985 loss)
I0810 12:48:34.629081 13394 sgd_solver.cpp:106] Iteration 120, lr = 0.00991093
I0810 12:48:42.136611 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:48:42.462764 13394 solver.cpp:228] Iteration 130, loss = 0.0951918
I0810 12:48:42.462813 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 12:48:42.462833 13394 solver.cpp:244]     Train net output #1: loss = 0.0951918 (* 1 = 0.0951918 loss)
I0810 12:48:42.462848 13394 sgd_solver.cpp:106] Iteration 130, lr = 0.0099036
I0810 12:48:50.895344 13394 solver.cpp:228] Iteration 140, loss = 0.34726
I0810 12:48:50.895390 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 12:48:50.895408 13394 solver.cpp:244]     Train net output #1: loss = 0.34726 (* 1 = 0.34726 loss)
I0810 12:48:50.895427 13394 sgd_solver.cpp:106] Iteration 140, lr = 0.00989627
I0810 12:48:55.110105 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:48:58.215462 13394 solver.cpp:228] Iteration 150, loss = 0.157253
I0810 12:48:58.215924 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:48:58.215947 13394 solver.cpp:244]     Train net output #1: loss = 0.157253 (* 1 = 0.157253 loss)
I0810 12:48:58.215965 13394 sgd_solver.cpp:106] Iteration 150, lr = 0.00988896
I0810 12:49:09.272930 13394 solver.cpp:228] Iteration 160, loss = 0.125357
I0810 12:49:09.272972 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 12:49:09.272989 13394 solver.cpp:244]     Train net output #1: loss = 0.125357 (* 1 = 0.125357 loss)
I0810 12:49:09.273001 13394 sgd_solver.cpp:106] Iteration 160, lr = 0.00988166
I0810 12:49:11.139700 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:49:18.836189 13394 solver.cpp:228] Iteration 170, loss = 0.125599
I0810 12:49:18.836232 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 12:49:18.836251 13394 solver.cpp:244]     Train net output #1: loss = 0.125599 (* 1 = 0.125599 loss)
I0810 12:49:18.836266 13394 sgd_solver.cpp:106] Iteration 170, lr = 0.00987437
I0810 12:49:25.074672 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:49:27.948083 13394 solver.cpp:228] Iteration 180, loss = 0.125491
I0810 12:49:27.948335 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 12:49:27.948492 13394 solver.cpp:244]     Train net output #1: loss = 0.125491 (* 1 = 0.125491 loss)
I0810 12:49:27.948621 13394 sgd_solver.cpp:106] Iteration 180, lr = 0.00986709
I0810 12:49:36.911154 13394 solver.cpp:228] Iteration 190, loss = 0.0938993
I0810 12:49:36.911279 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 12:49:36.911300 13394 solver.cpp:244]     Train net output #1: loss = 0.0938992 (* 1 = 0.0938992 loss)
I0810 12:49:36.911317 13394 sgd_solver.cpp:106] Iteration 190, lr = 0.00985983
I0810 12:49:40.478014 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:49:45.656178 13394 solver.cpp:337] Iteration 200, Testing net (#0)
I0810 12:49:47.143448 13394 solver.cpp:404]     Test net output #0: accuracy = 0.698438
I0810 12:49:47.143494 13394 solver.cpp:404]     Test net output #1: loss = 1.26756 (* 1 = 1.26756 loss)
I0810 12:49:47.416107 13394 solver.cpp:228] Iteration 200, loss = 0.15704
I0810 12:49:47.416209 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 12:49:47.416270 13394 solver.cpp:244]     Train net output #1: loss = 0.15704 (* 1 = 0.15704 loss)
I0810 12:49:47.416307 13394 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0810 12:49:56.234050 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:49:57.474959 13394 solver.cpp:228] Iteration 210, loss = 0.344025
I0810 12:49:57.475010 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:49:57.475028 13394 solver.cpp:244]     Train net output #1: loss = 0.344025 (* 1 = 0.344025 loss)
I0810 12:49:57.475044 13394 sgd_solver.cpp:106] Iteration 210, lr = 0.00984534
I0810 12:50:06.692490 13394 solver.cpp:228] Iteration 220, loss = 0.188594
I0810 12:50:06.692533 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:50:06.692551 13394 solver.cpp:244]     Train net output #1: loss = 0.188594 (* 1 = 0.188594 loss)
I0810 12:50:06.692566 13394 sgd_solver.cpp:106] Iteration 220, lr = 0.00983811
I0810 12:50:11.165848 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:50:17.218209 13394 solver.cpp:228] Iteration 230, loss = 0.219234
I0810 12:50:17.218313 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:50:17.218356 13394 solver.cpp:244]     Train net output #1: loss = 0.219234 (* 1 = 0.219234 loss)
I0810 12:50:17.218394 13394 sgd_solver.cpp:106] Iteration 230, lr = 0.0098309
I0810 12:50:25.943606 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:50:26.071403 13394 solver.cpp:228] Iteration 240, loss = 0.156973
I0810 12:50:26.071457 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:50:26.071475 13394 solver.cpp:244]     Train net output #1: loss = 0.156973 (* 1 = 0.156973 loss)
I0810 12:50:26.071491 13394 sgd_solver.cpp:106] Iteration 240, lr = 0.0098237
I0810 12:50:35.399400 13394 solver.cpp:228] Iteration 250, loss = 0.125738
I0810 12:50:35.399503 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 12:50:35.399546 13394 solver.cpp:244]     Train net output #1: loss = 0.125738 (* 1 = 0.125738 loss)
I0810 12:50:35.399587 13394 sgd_solver.cpp:106] Iteration 250, lr = 0.00981651
I0810 12:50:41.082063 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:50:44.308099 13394 solver.cpp:228] Iteration 260, loss = 0.219476
I0810 12:50:44.308198 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:50:44.308218 13394 solver.cpp:244]     Train net output #1: loss = 0.219476 (* 1 = 0.219476 loss)
I0810 12:50:44.308233 13394 sgd_solver.cpp:106] Iteration 260, lr = 0.00980933
I0810 12:50:55.831135 13394 solver.cpp:228] Iteration 270, loss = 0.221046
I0810 12:50:55.831182 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:50:55.831197 13394 solver.cpp:244]     Train net output #1: loss = 0.221046 (* 1 = 0.221046 loss)
I0810 12:50:55.831212 13394 sgd_solver.cpp:106] Iteration 270, lr = 0.00980217
I0810 12:50:58.379786 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:51:06.336155 13394 solver.cpp:228] Iteration 280, loss = 0.191077
I0810 12:51:06.336308 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:51:06.336354 13394 solver.cpp:244]     Train net output #1: loss = 0.191077 (* 1 = 0.191077 loss)
I0810 12:51:06.336390 13394 sgd_solver.cpp:106] Iteration 280, lr = 0.00979502
I0810 12:51:12.791908 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:51:14.987651 13394 solver.cpp:228] Iteration 290, loss = 0.28263
I0810 12:51:14.991631 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 12:51:14.991673 13394 solver.cpp:244]     Train net output #1: loss = 0.28263 (* 1 = 0.28263 loss)
I0810 12:51:14.991703 13394 sgd_solver.cpp:106] Iteration 290, lr = 0.00978788
I0810 12:51:24.337424 13394 solver.cpp:337] Iteration 300, Testing net (#0)
I0810 12:51:25.844960 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 12:51:25.845152 13394 solver.cpp:404]     Test net output #1: loss = 1.31094 (* 1 = 1.31094 loss)
I0810 12:51:26.124341 13394 solver.cpp:228] Iteration 300, loss = 0.0630295
I0810 12:51:26.124390 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 12:51:26.124409 13394 solver.cpp:244]     Train net output #1: loss = 0.0630295 (* 1 = 0.0630295 loss)
I0810 12:51:26.124426 13394 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0810 12:51:29.605700 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:51:35.094946 13394 solver.cpp:228] Iteration 310, loss = 0.251695
I0810 12:51:35.094992 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 12:51:35.095007 13394 solver.cpp:244]     Train net output #1: loss = 0.251695 (* 1 = 0.251695 loss)
I0810 12:51:35.095021 13394 sgd_solver.cpp:106] Iteration 310, lr = 0.00977363
I0810 12:51:42.988171 13394 solver.cpp:228] Iteration 320, loss = 0.15814
I0810 12:51:42.988212 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:51:42.988227 13394 solver.cpp:244]     Train net output #1: loss = 0.15814 (* 1 = 0.15814 loss)
I0810 12:51:42.988240 13394 sgd_solver.cpp:106] Iteration 320, lr = 0.00976653
I0810 12:51:43.748047 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:51:51.348060 13394 solver.cpp:228] Iteration 330, loss = 0.0940414
I0810 12:51:51.348206 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 12:51:51.348222 13394 solver.cpp:244]     Train net output #1: loss = 0.0940413 (* 1 = 0.0940413 loss)
I0810 12:51:51.348237 13394 sgd_solver.cpp:106] Iteration 330, lr = 0.00975944
I0810 12:51:58.704238 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:52:00.422530 13394 solver.cpp:228] Iteration 340, loss = 0.284345
I0810 12:52:00.422580 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 12:52:00.422600 13394 solver.cpp:244]     Train net output #1: loss = 0.284345 (* 1 = 0.284345 loss)
I0810 12:52:00.422616 13394 sgd_solver.cpp:106] Iteration 340, lr = 0.00975236
I0810 12:52:09.924893 13394 solver.cpp:228] Iteration 350, loss = 0.286824
I0810 12:52:09.924935 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 12:52:09.924952 13394 solver.cpp:244]     Train net output #1: loss = 0.286824 (* 1 = 0.286824 loss)
I0810 12:52:09.924968 13394 sgd_solver.cpp:106] Iteration 350, lr = 0.00974529
I0810 12:52:15.512382 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:52:18.478792 13394 solver.cpp:228] Iteration 360, loss = 0.0011422
I0810 12:52:18.478884 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 12:52:18.478919 13394 solver.cpp:244]     Train net output #1: loss = 0.00114218 (* 1 = 0.00114218 loss)
I0810 12:52:18.478955 13394 sgd_solver.cpp:106] Iteration 360, lr = 0.00973823
I0810 12:52:27.978144 13394 solver.cpp:228] Iteration 370, loss = 0.189138
I0810 12:52:27.978255 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:52:27.978274 13394 solver.cpp:244]     Train net output #1: loss = 0.189138 (* 1 = 0.189138 loss)
I0810 12:52:27.978289 13394 sgd_solver.cpp:106] Iteration 370, lr = 0.00973119
I0810 12:52:29.996484 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:52:36.895655 13394 solver.cpp:228] Iteration 380, loss = 0.253937
I0810 12:52:36.895700 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 12:52:36.895719 13394 solver.cpp:244]     Train net output #1: loss = 0.253937 (* 1 = 0.253937 loss)
I0810 12:52:36.895735 13394 sgd_solver.cpp:106] Iteration 380, lr = 0.00972416
I0810 12:52:45.097728 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:52:47.416095 13394 solver.cpp:228] Iteration 390, loss = 0.220882
I0810 12:52:47.416141 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:52:47.416159 13394 solver.cpp:244]     Train net output #1: loss = 0.220882 (* 1 = 0.220882 loss)
I0810 12:52:47.416175 13394 sgd_solver.cpp:106] Iteration 390, lr = 0.00971714
I0810 12:52:56.044957 13394 solver.cpp:337] Iteration 400, Testing net (#0)
I0810 12:52:57.740500 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 12:52:57.740607 13394 solver.cpp:404]     Test net output #1: loss = 1.28686 (* 1 = 1.28686 loss)
I0810 12:52:58.022532 13394 solver.cpp:228] Iteration 400, loss = 0.190005
I0810 12:52:58.022627 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:52:58.022644 13394 solver.cpp:244]     Train net output #1: loss = 0.190005 (* 1 = 0.190005 loss)
I0810 12:52:58.022656 13394 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0810 12:53:01.277825 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:53:06.304211 13394 solver.cpp:228] Iteration 410, loss = 0.157646
I0810 12:53:06.304253 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:53:06.304270 13394 solver.cpp:244]     Train net output #1: loss = 0.157646 (* 1 = 0.157646 loss)
I0810 12:53:06.304286 13394 sgd_solver.cpp:106] Iteration 410, lr = 0.00970313
I0810 12:53:26.452142 13394 solver.cpp:228] Iteration 420, loss = 0.157727
I0810 12:53:26.452189 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:53:26.452208 13394 solver.cpp:244]     Train net output #1: loss = 0.157727 (* 1 = 0.157727 loss)
I0810 12:53:26.452224 13394 sgd_solver.cpp:106] Iteration 420, lr = 0.00969615
I0810 12:53:28.815891 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:53:48.036155 13394 solver.cpp:228] Iteration 430, loss = 0.157321
I0810 12:53:48.036204 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:53:48.036223 13394 solver.cpp:244]     Train net output #1: loss = 0.157321 (* 1 = 0.157321 loss)
I0810 12:53:48.036238 13394 sgd_solver.cpp:106] Iteration 430, lr = 0.00968917
I0810 12:53:52.300231 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:53:55.830032 13394 solver.cpp:228] Iteration 440, loss = 0.0940304
I0810 12:53:55.830080 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 12:53:55.830097 13394 solver.cpp:244]     Train net output #1: loss = 0.0940303 (* 1 = 0.0940303 loss)
I0810 12:53:55.830113 13394 sgd_solver.cpp:106] Iteration 440, lr = 0.00968221
I0810 12:54:07.207046 13394 solver.cpp:228] Iteration 450, loss = 0.0627144
I0810 12:54:07.207139 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 12:54:07.207159 13394 solver.cpp:244]     Train net output #1: loss = 0.0627144 (* 1 = 0.0627144 loss)
I0810 12:54:07.207173 13394 sgd_solver.cpp:106] Iteration 450, lr = 0.00967526
I0810 12:54:09.545054 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:54:13.252809 13394 solver.cpp:228] Iteration 460, loss = 0.156687
I0810 12:54:13.252864 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:54:13.252883 13394 solver.cpp:244]     Train net output #1: loss = 0.156687 (* 1 = 0.156687 loss)
I0810 12:54:13.252899 13394 sgd_solver.cpp:106] Iteration 460, lr = 0.00966833
I0810 12:54:18.824753 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:54:19.099526 13394 solver.cpp:228] Iteration 470, loss = 0.157958
I0810 12:54:19.099570 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:54:19.099586 13394 solver.cpp:244]     Train net output #1: loss = 0.157958 (* 1 = 0.157958 loss)
I0810 12:54:19.099599 13394 sgd_solver.cpp:106] Iteration 470, lr = 0.0096614
I0810 12:54:24.270639 13394 solver.cpp:228] Iteration 480, loss = 0.156711
I0810 12:54:24.270683 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:54:24.270697 13394 solver.cpp:244]     Train net output #1: loss = 0.156711 (* 1 = 0.156711 loss)
I0810 12:54:24.270711 13394 sgd_solver.cpp:106] Iteration 480, lr = 0.00965448
I0810 12:54:29.221976 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:54:29.374058 13394 solver.cpp:228] Iteration 490, loss = 0.0314032
I0810 12:54:29.374104 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 12:54:29.374122 13394 solver.cpp:244]     Train net output #1: loss = 0.0314031 (* 1 = 0.0314031 loss)
I0810 12:54:29.374202 13394 sgd_solver.cpp:106] Iteration 490, lr = 0.00964758
I0810 12:54:35.440703 13394 solver.cpp:337] Iteration 500, Testing net (#0)
I0810 12:54:36.941635 13394 solver.cpp:404]     Test net output #0: accuracy = 0.69375
I0810 12:54:36.941687 13394 solver.cpp:404]     Test net output #1: loss = 1.22956 (* 1 = 1.22956 loss)
I0810 12:54:37.219288 13394 solver.cpp:228] Iteration 500, loss = 0.157068
I0810 12:54:37.219396 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:54:37.219516 13394 solver.cpp:244]     Train net output #1: loss = 0.157068 (* 1 = 0.157068 loss)
I0810 12:54:37.219585 13394 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0810 12:54:42.605872 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:54:44.871794 13394 solver.cpp:228] Iteration 510, loss = 0.221548
I0810 12:54:44.871842 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:54:44.871860 13394 solver.cpp:244]     Train net output #1: loss = 0.221548 (* 1 = 0.221548 loss)
I0810 12:54:44.871876 13394 sgd_solver.cpp:106] Iteration 510, lr = 0.00963381
I0810 12:54:51.169502 13394 solver.cpp:228] Iteration 520, loss = 0.2007
I0810 12:54:51.169549 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:54:51.169569 13394 solver.cpp:244]     Train net output #1: loss = 0.2007 (* 1 = 0.2007 loss)
I0810 12:54:51.169584 13394 sgd_solver.cpp:106] Iteration 520, lr = 0.00962694
I0810 12:54:54.604940 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:54:57.320070 13394 solver.cpp:228] Iteration 530, loss = 0.188515
I0810 12:54:57.320116 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:54:57.320134 13394 solver.cpp:244]     Train net output #1: loss = 0.188515 (* 1 = 0.188515 loss)
I0810 12:54:57.320149 13394 sgd_solver.cpp:106] Iteration 530, lr = 0.00962008
I0810 12:55:04.133065 13394 solver.cpp:228] Iteration 540, loss = 0.156421
I0810 12:55:04.133117 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:55:04.133136 13394 solver.cpp:244]     Train net output #1: loss = 0.156421 (* 1 = 0.156421 loss)
I0810 12:55:04.133153 13394 sgd_solver.cpp:106] Iteration 540, lr = 0.00961323
I0810 12:55:06.514762 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:55:10.643934 13394 solver.cpp:228] Iteration 550, loss = 0.0627639
I0810 12:55:10.644069 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 12:55:10.644086 13394 solver.cpp:244]     Train net output #1: loss = 0.0627638 (* 1 = 0.0627638 loss)
I0810 12:55:10.644100 13394 sgd_solver.cpp:106] Iteration 550, lr = 0.0096064
I0810 12:55:16.560495 13394 solver.cpp:228] Iteration 560, loss = 0.0938557
I0810 12:55:16.560923 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 12:55:16.561067 13394 solver.cpp:244]     Train net output #1: loss = 0.0938556 (* 1 = 0.0938556 loss)
I0810 12:55:16.561326 13394 sgd_solver.cpp:106] Iteration 560, lr = 0.00959958
I0810 12:55:17.290410 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:55:22.913424 13394 solver.cpp:228] Iteration 570, loss = 0.251987
I0810 12:55:22.913543 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 12:55:22.913588 13394 solver.cpp:244]     Train net output #1: loss = 0.251987 (* 1 = 0.251987 loss)
I0810 12:55:22.913633 13394 sgd_solver.cpp:106] Iteration 570, lr = 0.00959276
I0810 12:55:28.035838 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:55:29.583333 13394 solver.cpp:228] Iteration 580, loss = 0.094925
I0810 12:55:29.583381 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 12:55:29.583401 13394 solver.cpp:244]     Train net output #1: loss = 0.0949249 (* 1 = 0.0949249 loss)
I0810 12:55:29.583417 13394 sgd_solver.cpp:106] Iteration 580, lr = 0.00958596
I0810 12:55:36.808195 13394 solver.cpp:228] Iteration 590, loss = 0.0634775
I0810 12:55:36.808240 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 12:55:36.808259 13394 solver.cpp:244]     Train net output #1: loss = 0.0634774 (* 1 = 0.0634774 loss)
I0810 12:55:36.808274 13394 sgd_solver.cpp:106] Iteration 590, lr = 0.00957917
I0810 12:55:38.933742 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:55:43.123127 13394 solver.cpp:337] Iteration 600, Testing net (#0)
I0810 12:55:47.338050 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 12:55:47.338100 13394 solver.cpp:404]     Test net output #1: loss = 1.21692 (* 1 = 1.21692 loss)
I0810 12:55:47.617575 13394 solver.cpp:228] Iteration 600, loss = 0.094681
I0810 12:55:47.617619 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 12:55:47.617635 13394 solver.cpp:244]     Train net output #1: loss = 0.0946809 (* 1 = 0.0946809 loss)
I0810 12:55:47.617648 13394 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0810 12:55:51.003191 13403 blocking_queue.cpp:50] Waiting for data
I0810 12:55:55.839107 13394 solver.cpp:228] Iteration 610, loss = 0.0633593
I0810 12:55:55.839159 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 12:55:55.839179 13394 solver.cpp:244]     Train net output #1: loss = 0.0633592 (* 1 = 0.0633592 loss)
I0810 12:55:55.839196 13394 sgd_solver.cpp:106] Iteration 610, lr = 0.00956563
I0810 12:56:03.238122 13394 solver.cpp:228] Iteration 620, loss = 0.282294
I0810 12:56:03.238173 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 12:56:03.238191 13394 solver.cpp:244]     Train net output #1: loss = 0.282294 (* 1 = 0.282294 loss)
I0810 12:56:03.238209 13394 sgd_solver.cpp:106] Iteration 620, lr = 0.00955887
I0810 12:56:04.928987 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:56:09.394878 13394 solver.cpp:228] Iteration 630, loss = 0.126722
I0810 12:56:09.394930 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 12:56:09.394948 13394 solver.cpp:244]     Train net output #1: loss = 0.126722 (* 1 = 0.126722 loss)
I0810 12:56:09.394968 13394 sgd_solver.cpp:106] Iteration 630, lr = 0.00955213
I0810 12:56:16.036939 13394 solver.cpp:228] Iteration 640, loss = 0.312733
I0810 12:56:16.037133 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 12:56:16.037178 13394 solver.cpp:244]     Train net output #1: loss = 0.312733 (* 1 = 0.312733 loss)
I0810 12:56:16.037214 13394 sgd_solver.cpp:106] Iteration 640, lr = 0.00954539
I0810 12:56:16.039089 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:56:22.621923 13394 solver.cpp:228] Iteration 650, loss = 0.221699
I0810 12:56:22.621969 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:56:22.621989 13394 solver.cpp:244]     Train net output #1: loss = 0.221699 (* 1 = 0.221699 loss)
I0810 12:56:22.622004 13394 sgd_solver.cpp:106] Iteration 650, lr = 0.00953867
I0810 12:56:27.843250 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:56:30.414542 13394 solver.cpp:228] Iteration 660, loss = 0.127878
I0810 12:56:30.414589 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 12:56:30.414608 13394 solver.cpp:244]     Train net output #1: loss = 0.127878 (* 1 = 0.127878 loss)
I0810 12:56:30.414623 13394 sgd_solver.cpp:106] Iteration 660, lr = 0.00953196
I0810 12:56:37.113418 13394 solver.cpp:228] Iteration 670, loss = 0.224098
I0810 12:56:37.113466 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:56:37.113484 13394 solver.cpp:244]     Train net output #1: loss = 0.224098 (* 1 = 0.224098 loss)
I0810 12:56:37.113502 13394 sgd_solver.cpp:106] Iteration 670, lr = 0.00952526
I0810 12:56:39.855412 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:56:44.022511 13394 solver.cpp:228] Iteration 680, loss = 0.25046
I0810 12:56:44.022559 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 12:56:44.022578 13394 solver.cpp:244]     Train net output #1: loss = 0.25046 (* 1 = 0.25046 loss)
I0810 12:56:44.022593 13394 sgd_solver.cpp:106] Iteration 680, lr = 0.00951857
I0810 12:56:50.233551 13394 solver.cpp:228] Iteration 690, loss = 0.220582
I0810 12:56:50.233649 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:56:50.233664 13394 solver.cpp:244]     Train net output #1: loss = 0.220582 (* 1 = 0.220582 loss)
I0810 12:56:50.233678 13394 sgd_solver.cpp:106] Iteration 690, lr = 0.00951189
I0810 12:56:51.114240 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:56:55.524032 13394 solver.cpp:337] Iteration 700, Testing net (#0)
I0810 12:56:58.858392 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 12:56:58.858501 13394 solver.cpp:404]     Test net output #1: loss = 1.22266 (* 1 = 1.22266 loss)
I0810 12:56:59.136127 13394 solver.cpp:228] Iteration 700, loss = 0.126266
I0810 12:56:59.136173 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 12:56:59.136193 13394 solver.cpp:244]     Train net output #1: loss = 0.126266 (* 1 = 0.126266 loss)
I0810 12:56:59.136253 13394 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0810 12:57:02.237442 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:57:09.811123 13394 solver.cpp:228] Iteration 710, loss = 0.252137
I0810 12:57:09.811170 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 12:57:09.811204 13394 solver.cpp:244]     Train net output #1: loss = 0.252136 (* 1 = 0.252136 loss)
I0810 12:57:09.811259 13394 sgd_solver.cpp:106] Iteration 710, lr = 0.00949856
I0810 12:57:16.132072 13394 solver.cpp:228] Iteration 720, loss = 0.157814
I0810 12:57:16.132148 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:57:16.132166 13394 solver.cpp:244]     Train net output #1: loss = 0.157814 (* 1 = 0.157814 loss)
I0810 12:57:16.132184 13394 sgd_solver.cpp:106] Iteration 720, lr = 0.00949192
I0810 12:57:17.540074 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:57:22.531164 13394 solver.cpp:228] Iteration 730, loss = 0.157582
I0810 12:57:22.531543 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:57:22.531687 13394 solver.cpp:244]     Train net output #1: loss = 0.157582 (* 1 = 0.157582 loss)
I0810 12:57:22.531848 13394 sgd_solver.cpp:106] Iteration 730, lr = 0.00948528
I0810 12:57:27.421914 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:57:28.102722 13394 solver.cpp:228] Iteration 740, loss = 0.158022
I0810 12:57:28.102771 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:57:28.102792 13394 solver.cpp:244]     Train net output #1: loss = 0.158022 (* 1 = 0.158022 loss)
I0810 12:57:28.102807 13394 sgd_solver.cpp:106] Iteration 740, lr = 0.00947866
I0810 12:57:34.388229 13394 solver.cpp:228] Iteration 750, loss = 0.219762
I0810 12:57:34.388276 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:57:34.388296 13394 solver.cpp:244]     Train net output #1: loss = 0.219762 (* 1 = 0.219762 loss)
I0810 12:57:34.388314 13394 sgd_solver.cpp:106] Iteration 750, lr = 0.00947204
I0810 12:57:38.535336 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:57:41.094210 13394 solver.cpp:228] Iteration 760, loss = 0.286414
I0810 12:57:41.094264 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 12:57:41.094281 13394 solver.cpp:244]     Train net output #1: loss = 0.286414 (* 1 = 0.286414 loss)
I0810 12:57:41.094295 13394 sgd_solver.cpp:106] Iteration 760, lr = 0.00946544
I0810 12:57:48.255261 13394 solver.cpp:228] Iteration 770, loss = 0.219243
I0810 12:57:48.255314 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:57:48.255332 13394 solver.cpp:244]     Train net output #1: loss = 0.219243 (* 1 = 0.219243 loss)
I0810 12:57:48.255347 13394 sgd_solver.cpp:106] Iteration 770, lr = 0.00945885
I0810 12:58:02.026607 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:58:06.904337 13394 solver.cpp:228] Iteration 780, loss = 0.188844
I0810 12:58:06.904379 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:58:06.904394 13394 solver.cpp:244]     Train net output #1: loss = 0.188843 (* 1 = 0.188843 loss)
I0810 12:58:06.904409 13394 sgd_solver.cpp:106] Iteration 780, lr = 0.00945227
I0810 12:58:13.675038 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:58:13.759291 13394 solver.cpp:228] Iteration 790, loss = 0.189609
I0810 12:58:13.759389 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:58:13.759431 13394 solver.cpp:244]     Train net output #1: loss = 0.189609 (* 1 = 0.189609 loss)
I0810 12:58:13.759470 13394 sgd_solver.cpp:106] Iteration 790, lr = 0.0094457
I0810 12:58:19.215744 13394 solver.cpp:337] Iteration 800, Testing net (#0)
I0810 12:58:21.523095 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 12:58:21.523228 13394 solver.cpp:404]     Test net output #1: loss = 1.19055 (* 1 = 1.19055 loss)
I0810 12:58:21.829257 13394 solver.cpp:228] Iteration 800, loss = 0.312647
I0810 12:58:21.829300 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 12:58:21.829319 13394 solver.cpp:244]     Train net output #1: loss = 0.312647 (* 1 = 0.312647 loss)
I0810 12:58:21.829334 13394 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0810 12:58:23.997891 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:58:31.525693 13394 solver.cpp:228] Iteration 810, loss = 0.220905
I0810 12:58:31.525763 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:58:31.525790 13394 solver.cpp:244]     Train net output #1: loss = 0.220904 (* 1 = 0.220904 loss)
I0810 12:58:31.525804 13394 sgd_solver.cpp:106] Iteration 810, lr = 0.00943258
I0810 12:58:37.219883 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:58:37.545284 13394 solver.cpp:228] Iteration 820, loss = 0.156779
I0810 12:58:37.545331 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 12:58:37.545348 13394 solver.cpp:244]     Train net output #1: loss = 0.156779 (* 1 = 0.156779 loss)
I0810 12:58:37.545364 13394 sgd_solver.cpp:106] Iteration 820, lr = 0.00942605
I0810 12:58:44.017053 13394 solver.cpp:228] Iteration 830, loss = 0.219253
I0810 12:58:44.017102 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 12:58:44.017123 13394 solver.cpp:244]     Train net output #1: loss = 0.219253 (* 1 = 0.219253 loss)
I0810 12:58:44.017140 13394 sgd_solver.cpp:106] Iteration 830, lr = 0.00941952
I0810 12:58:48.014180 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:58:49.556486 13394 solver.cpp:228] Iteration 840, loss = 0.251317
I0810 12:58:49.556527 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 12:58:49.556542 13394 solver.cpp:244]     Train net output #1: loss = 0.251317 (* 1 = 0.251317 loss)
I0810 12:58:49.556555 13394 sgd_solver.cpp:106] Iteration 840, lr = 0.009413
I0810 12:58:57.338014 13394 solver.cpp:228] Iteration 850, loss = 0.252196
I0810 12:58:57.338066 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 12:58:57.338084 13394 solver.cpp:244]     Train net output #1: loss = 0.252196 (* 1 = 0.252196 loss)
I0810 12:58:57.338102 13394 sgd_solver.cpp:106] Iteration 850, lr = 0.00940649
I0810 12:59:00.138312 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:59:03.948376 13394 solver.cpp:228] Iteration 860, loss = 0.223929
I0810 12:59:03.948484 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 12:59:03.948526 13394 solver.cpp:244]     Train net output #1: loss = 0.223929 (* 1 = 0.223929 loss)
I0810 12:59:03.948566 13394 sgd_solver.cpp:106] Iteration 860, lr = 0.0094
I0810 12:59:10.789170 13394 solver.cpp:228] Iteration 870, loss = 0.190583
I0810 12:59:10.789280 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 12:59:10.789299 13394 solver.cpp:244]     Train net output #1: loss = 0.190583 (* 1 = 0.190583 loss)
I0810 12:59:10.789316 13394 sgd_solver.cpp:106] Iteration 870, lr = 0.00939351
I0810 12:59:11.070209 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:59:16.426008 13394 solver.cpp:228] Iteration 880, loss = 0.220498
I0810 12:59:16.426117 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:59:16.426163 13394 solver.cpp:244]     Train net output #1: loss = 0.220498 (* 1 = 0.220498 loss)
I0810 12:59:16.426205 13394 sgd_solver.cpp:106] Iteration 880, lr = 0.00938703
I0810 12:59:21.658118 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:59:22.953339 13394 solver.cpp:228] Iteration 890, loss = 0.221051
I0810 12:59:22.953395 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:59:22.953414 13394 solver.cpp:244]     Train net output #1: loss = 0.221051 (* 1 = 0.221051 loss)
I0810 12:59:22.953433 13394 sgd_solver.cpp:106] Iteration 890, lr = 0.00938057
I0810 12:59:29.543789 13394 solver.cpp:337] Iteration 900, Testing net (#0)
I0810 12:59:32.586671 13394 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0810 12:59:32.586720 13394 solver.cpp:404]     Test net output #1: loss = 1.21434 (* 1 = 1.21434 loss)
I0810 12:59:32.861120 13394 solver.cpp:228] Iteration 900, loss = 0.12616
I0810 12:59:32.861227 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 12:59:32.861284 13394 solver.cpp:244]     Train net output #1: loss = 0.12616 (* 1 = 0.12616 loss)
I0810 12:59:32.861320 13394 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0810 12:59:33.603160 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:59:42.522745 13394 solver.cpp:228] Iteration 910, loss = 0.251422
I0810 12:59:42.522912 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 12:59:42.522935 13394 solver.cpp:244]     Train net output #1: loss = 0.251422 (* 1 = 0.251422 loss)
I0810 12:59:42.522951 13394 sgd_solver.cpp:106] Iteration 910, lr = 0.00936767
I0810 12:59:46.616052 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:59:48.836495 13394 solver.cpp:228] Iteration 920, loss = 0.126022
I0810 12:59:48.836539 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 12:59:48.836556 13394 solver.cpp:244]     Train net output #1: loss = 0.126022 (* 1 = 0.126022 loss)
I0810 12:59:48.836573 13394 sgd_solver.cpp:106] Iteration 920, lr = 0.00936123
I0810 12:59:53.818225 13394 solver.cpp:228] Iteration 930, loss = 0.251492
I0810 12:59:53.818274 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 12:59:53.818295 13394 solver.cpp:244]     Train net output #1: loss = 0.251492 (* 1 = 0.251492 loss)
I0810 12:59:53.818311 13394 sgd_solver.cpp:106] Iteration 930, lr = 0.00935481
I0810 12:59:56.094146 13401 blocking_queue.cpp:50] Waiting for data
I0810 12:59:58.033231 13394 solver.cpp:228] Iteration 940, loss = 0.221526
I0810 12:59:58.033273 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 12:59:58.033293 13394 solver.cpp:244]     Train net output #1: loss = 0.221526 (* 1 = 0.221526 loss)
I0810 12:59:58.033308 13394 sgd_solver.cpp:106] Iteration 940, lr = 0.00934839
I0810 13:00:05.044167 13394 solver.cpp:228] Iteration 950, loss = 0.157282
I0810 13:00:05.044318 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:00:05.044369 13394 solver.cpp:244]     Train net output #1: loss = 0.157282 (* 1 = 0.157282 loss)
I0810 13:00:05.044405 13394 sgd_solver.cpp:106] Iteration 950, lr = 0.00934199
I0810 13:00:07.169870 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:00:10.368923 13394 solver.cpp:228] Iteration 960, loss = 0.0627462
I0810 13:00:10.368973 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:00:10.368990 13394 solver.cpp:244]     Train net output #1: loss = 0.0627461 (* 1 = 0.0627461 loss)
I0810 13:00:10.369009 13394 sgd_solver.cpp:106] Iteration 960, lr = 0.0093356
I0810 13:00:16.742777 13394 solver.cpp:228] Iteration 970, loss = 0.189068
I0810 13:00:16.742935 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:00:16.742980 13394 solver.cpp:244]     Train net output #1: loss = 0.189068 (* 1 = 0.189068 loss)
I0810 13:00:16.743019 13394 sgd_solver.cpp:106] Iteration 970, lr = 0.00932921
I0810 13:00:17.135848 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:00:23.191655 13394 solver.cpp:228] Iteration 980, loss = 0.25055
I0810 13:00:23.191701 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:00:23.191720 13394 solver.cpp:244]     Train net output #1: loss = 0.25055 (* 1 = 0.25055 loss)
I0810 13:00:23.191735 13394 sgd_solver.cpp:106] Iteration 980, lr = 0.00932284
I0810 13:00:28.325572 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:00:29.879719 13394 solver.cpp:228] Iteration 990, loss = 0.220667
I0810 13:00:29.879765 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:00:29.879783 13394 solver.cpp:244]     Train net output #1: loss = 0.220667 (* 1 = 0.220667 loss)
I0810 13:00:29.879801 13394 sgd_solver.cpp:106] Iteration 990, lr = 0.00931648
I0810 13:00:35.530977 13394 solver.cpp:337] Iteration 1000, Testing net (#0)
I0810 13:00:37.751922 13394 solver.cpp:404]     Test net output #0: accuracy = 0.7
I0810 13:00:37.752228 13394 solver.cpp:404]     Test net output #1: loss = 1.13213 (* 1 = 1.13213 loss)
I0810 13:00:37.955096 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:00:38.061825 13394 solver.cpp:228] Iteration 1000, loss = 0.258482
I0810 13:00:38.061878 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:00:38.061894 13394 solver.cpp:244]     Train net output #1: loss = 0.258482 (* 1 = 0.258482 loss)
I0810 13:00:38.061909 13394 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0810 13:00:48.051919 13394 blocking_queue.cpp:50] Data layer prefetch queue empty
I0810 13:00:51.260499 13394 solver.cpp:228] Iteration 1010, loss = 0.219293
I0810 13:00:51.260543 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:00:51.260558 13394 solver.cpp:244]     Train net output #1: loss = 0.219293 (* 1 = 0.219293 loss)
I0810 13:00:51.260572 13394 sgd_solver.cpp:106] Iteration 1010, lr = 0.00930378
I0810 13:00:56.310124 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:00:57.641003 13394 solver.cpp:228] Iteration 1020, loss = 0.225839
I0810 13:00:57.641302 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:00:57.641441 13394 solver.cpp:244]     Train net output #1: loss = 0.225839 (* 1 = 0.225839 loss)
I0810 13:00:57.641573 13394 sgd_solver.cpp:106] Iteration 1020, lr = 0.00929745
I0810 13:01:03.874481 13394 solver.cpp:228] Iteration 1030, loss = 0.0952105
I0810 13:01:03.874557 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:01:03.874598 13394 solver.cpp:244]     Train net output #1: loss = 0.0952105 (* 1 = 0.0952105 loss)
I0810 13:01:03.874689 13394 sgd_solver.cpp:106] Iteration 1030, lr = 0.00929113
I0810 13:01:06.594194 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:01:09.199875 13394 solver.cpp:228] Iteration 1040, loss = 0.0938462
I0810 13:01:09.199931 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:01:09.199949 13394 solver.cpp:244]     Train net output #1: loss = 0.0938462 (* 1 = 0.0938462 loss)
I0810 13:01:09.199965 13394 sgd_solver.cpp:106] Iteration 1040, lr = 0.00928481
I0810 13:01:15.046896 13394 solver.cpp:228] Iteration 1050, loss = 0.0945001
I0810 13:01:15.046944 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:01:15.047080 13394 solver.cpp:244]     Train net output #1: loss = 0.0945 (* 1 = 0.0945 loss)
I0810 13:01:15.047147 13394 sgd_solver.cpp:106] Iteration 1050, lr = 0.00927851
I0810 13:01:16.188984 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:01:20.354118 13394 solver.cpp:228] Iteration 1060, loss = 0.0940263
I0810 13:01:20.354261 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:01:20.354282 13394 solver.cpp:244]     Train net output #1: loss = 0.0940262 (* 1 = 0.0940262 loss)
I0810 13:01:20.354298 13394 sgd_solver.cpp:106] Iteration 1060, lr = 0.00927222
I0810 13:01:28.671028 13394 solver.cpp:228] Iteration 1070, loss = 0.0315668
I0810 13:01:28.671089 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:01:28.671110 13394 solver.cpp:244]     Train net output #1: loss = 0.0315667 (* 1 = 0.0315667 loss)
I0810 13:01:28.671126 13394 sgd_solver.cpp:106] Iteration 1070, lr = 0.00926594
I0810 13:01:29.195868 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:01:34.677913 13394 solver.cpp:228] Iteration 1080, loss = 0.222375
I0810 13:01:34.677954 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:01:34.677973 13394 solver.cpp:244]     Train net output #1: loss = 0.222374 (* 1 = 0.222374 loss)
I0810 13:01:34.677989 13394 sgd_solver.cpp:106] Iteration 1080, lr = 0.00925966
I0810 13:01:40.320976 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:01:41.045207 13394 solver.cpp:228] Iteration 1090, loss = 0.220298
I0810 13:01:41.045251 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:01:41.045269 13394 solver.cpp:244]     Train net output #1: loss = 0.220298 (* 1 = 0.220298 loss)
I0810 13:01:41.045286 13394 sgd_solver.cpp:106] Iteration 1090, lr = 0.0092534
I0810 13:01:53.026525 13394 solver.cpp:337] Iteration 1100, Testing net (#0)
I0810 13:01:55.808275 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:01:55.808459 13394 solver.cpp:404]     Test net output #1: loss = 1.16236 (* 1 = 1.16236 loss)
I0810 13:01:56.109622 13394 solver.cpp:228] Iteration 1100, loss = 0.188729
I0810 13:01:56.109670 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:01:56.109690 13394 solver.cpp:244]     Train net output #1: loss = 0.188729 (* 1 = 0.188729 loss)
I0810 13:01:56.109707 13394 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0810 13:01:56.860327 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:02:04.928223 13394 solver.cpp:228] Iteration 1110, loss = 0.345697
I0810 13:02:04.928269 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:02:04.928289 13394 solver.cpp:244]     Train net output #1: loss = 0.345697 (* 1 = 0.345697 loss)
I0810 13:02:04.928306 13394 sgd_solver.cpp:106] Iteration 1110, lr = 0.0092409
I0810 13:02:09.847017 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:02:12.004112 13394 solver.cpp:228] Iteration 1120, loss = 0.221896
I0810 13:02:12.004155 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:02:12.004170 13394 solver.cpp:244]     Train net output #1: loss = 0.221896 (* 1 = 0.221896 loss)
I0810 13:02:12.004184 13394 sgd_solver.cpp:106] Iteration 1120, lr = 0.00923467
I0810 13:02:27.989344 13394 solver.cpp:228] Iteration 1130, loss = 0.126027
I0810 13:02:27.989465 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:02:27.989485 13394 solver.cpp:244]     Train net output #1: loss = 0.126027 (* 1 = 0.126027 loss)
I0810 13:02:27.989501 13394 sgd_solver.cpp:106] Iteration 1130, lr = 0.00922845
I0810 13:02:37.342257 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:02:43.884472 13394 solver.cpp:228] Iteration 1140, loss = 0.219721
I0810 13:02:43.884523 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:02:43.884542 13394 solver.cpp:244]     Train net output #1: loss = 0.219721 (* 1 = 0.219721 loss)
I0810 13:02:43.884558 13394 sgd_solver.cpp:106] Iteration 1140, lr = 0.00922223
I0810 13:02:55.203362 13394 solver.cpp:228] Iteration 1150, loss = 0.12629
I0810 13:02:55.203410 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:02:55.203428 13394 solver.cpp:244]     Train net output #1: loss = 0.12629 (* 1 = 0.12629 loss)
I0810 13:02:55.203444 13394 sgd_solver.cpp:106] Iteration 1150, lr = 0.00921603
I0810 13:02:57.258507 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:03:01.590245 13394 solver.cpp:228] Iteration 1160, loss = 0.282254
I0810 13:03:01.590351 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:03:01.590368 13394 solver.cpp:244]     Train net output #1: loss = 0.282254 (* 1 = 0.282254 loss)
I0810 13:03:01.590386 13394 sgd_solver.cpp:106] Iteration 1160, lr = 0.00920983
I0810 13:03:07.322504 13394 solver.cpp:228] Iteration 1170, loss = 0.188482
I0810 13:03:07.322616 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:03:07.322640 13394 solver.cpp:244]     Train net output #1: loss = 0.188482 (* 1 = 0.188482 loss)
I0810 13:03:07.322657 13394 sgd_solver.cpp:106] Iteration 1170, lr = 0.00920365
I0810 13:03:08.278139 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:03:13.884595 13394 solver.cpp:228] Iteration 1180, loss = 0.156447
I0810 13:03:13.884637 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:03:13.884652 13394 solver.cpp:244]     Train net output #1: loss = 0.156447 (* 1 = 0.156447 loss)
I0810 13:03:13.884665 13394 sgd_solver.cpp:106] Iteration 1180, lr = 0.00919748
I0810 13:03:18.152381 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:03:19.869488 13394 solver.cpp:228] Iteration 1190, loss = 0.251414
I0810 13:03:19.869534 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:03:19.869551 13394 solver.cpp:244]     Train net output #1: loss = 0.251414 (* 1 = 0.251414 loss)
I0810 13:03:19.869568 13394 sgd_solver.cpp:106] Iteration 1190, lr = 0.00919131
I0810 13:03:26.221402 13394 solver.cpp:337] Iteration 1200, Testing net (#0)
I0810 13:03:28.662155 13394 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0810 13:03:28.662214 13394 solver.cpp:404]     Test net output #1: loss = 1.16319 (* 1 = 1.16319 loss)
I0810 13:03:28.945286 13394 solver.cpp:228] Iteration 1200, loss = 0.18792
I0810 13:03:28.945328 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:03:28.945344 13394 solver.cpp:244]     Train net output #1: loss = 0.18792 (* 1 = 0.18792 loss)
I0810 13:03:28.945359 13394 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0810 13:03:29.022938 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:03:38.647225 13394 solver.cpp:228] Iteration 1210, loss = 0.34741
I0810 13:03:38.649756 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:03:38.649924 13394 solver.cpp:244]     Train net output #1: loss = 0.34741 (* 1 = 0.34741 loss)
I0810 13:03:38.649991 13394 sgd_solver.cpp:106] Iteration 1210, lr = 0.00917901
I0810 13:03:42.652799 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:03:44.753453 13394 solver.cpp:228] Iteration 1220, loss = 0.313983
I0810 13:03:44.753662 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:03:44.753712 13394 solver.cpp:244]     Train net output #1: loss = 0.313983 (* 1 = 0.313983 loss)
I0810 13:03:44.753731 13394 sgd_solver.cpp:106] Iteration 1220, lr = 0.00917287
I0810 13:03:48.524740 13394 solver.cpp:228] Iteration 1230, loss = 0.156841
I0810 13:03:48.524792 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:03:48.524811 13394 solver.cpp:244]     Train net output #1: loss = 0.156841 (* 1 = 0.156841 loss)
I0810 13:03:48.524828 13394 sgd_solver.cpp:106] Iteration 1230, lr = 0.00916675
I0810 13:03:52.128631 13394 solver.cpp:228] Iteration 1240, loss = 0.125907
I0810 13:03:52.128676 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:03:52.128695 13394 solver.cpp:244]     Train net output #1: loss = 0.125907 (* 1 = 0.125907 loss)
I0810 13:03:52.128711 13394 sgd_solver.cpp:106] Iteration 1240, lr = 0.00916063
I0810 13:03:52.573879 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:03:57.089989 13394 solver.cpp:228] Iteration 1250, loss = 0.251463
I0810 13:03:57.090034 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:03:57.090052 13394 solver.cpp:244]     Train net output #1: loss = 0.251463 (* 1 = 0.251463 loss)
I0810 13:03:57.090067 13394 sgd_solver.cpp:106] Iteration 1250, lr = 0.00915452
I0810 13:04:02.737943 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:04:03.479748 13394 solver.cpp:228] Iteration 1260, loss = 0.28426
I0810 13:04:03.479789 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:04:03.479804 13394 solver.cpp:244]     Train net output #1: loss = 0.28426 (* 1 = 0.28426 loss)
I0810 13:04:03.479816 13394 sgd_solver.cpp:106] Iteration 1260, lr = 0.00914842
I0810 13:04:09.299440 13394 solver.cpp:228] Iteration 1270, loss = 0.125192
I0810 13:04:09.299540 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:04:09.299556 13394 solver.cpp:244]     Train net output #1: loss = 0.125192 (* 1 = 0.125192 loss)
I0810 13:04:09.299572 13394 sgd_solver.cpp:106] Iteration 1270, lr = 0.00914233
I0810 13:04:12.591987 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:04:15.821866 13394 solver.cpp:228] Iteration 1280, loss = 0.220639
I0810 13:04:15.821913 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:04:15.821930 13394 solver.cpp:244]     Train net output #1: loss = 0.220639 (* 1 = 0.220639 loss)
I0810 13:04:15.821945 13394 sgd_solver.cpp:106] Iteration 1280, lr = 0.00913625
I0810 13:04:22.420280 13394 solver.cpp:228] Iteration 1290, loss = 0.313931
I0810 13:04:22.420327 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:04:22.420347 13394 solver.cpp:244]     Train net output #1: loss = 0.313931 (* 1 = 0.313931 loss)
I0810 13:04:22.420362 13394 sgd_solver.cpp:106] Iteration 1290, lr = 0.00913018
I0810 13:04:23.096412 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:04:27.889698 13394 solver.cpp:337] Iteration 1300, Testing net (#0)
I0810 13:04:29.766017 13394 solver.cpp:404]     Test net output #0: accuracy = 0.692187
I0810 13:04:29.766075 13394 solver.cpp:404]     Test net output #1: loss = 1.11092 (* 1 = 1.11092 loss)
I0810 13:04:30.062124 13394 solver.cpp:228] Iteration 1300, loss = 0.189781
I0810 13:04:30.062182 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:04:30.062201 13394 solver.cpp:244]     Train net output #1: loss = 0.189781 (* 1 = 0.189781 loss)
I0810 13:04:30.062218 13394 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0810 13:04:34.653164 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:04:38.154325 13394 solver.cpp:228] Iteration 1310, loss = 0.0687211
I0810 13:04:38.154427 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:04:38.154470 13394 solver.cpp:244]     Train net output #1: loss = 0.068721 (* 1 = 0.068721 loss)
I0810 13:04:38.154508 13394 sgd_solver.cpp:106] Iteration 1310, lr = 0.00911807
I0810 13:04:44.531013 13394 solver.cpp:228] Iteration 1320, loss = 0.0941088
I0810 13:04:44.531148 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:04:44.531169 13394 solver.cpp:244]     Train net output #1: loss = 0.0941087 (* 1 = 0.0941087 loss)
I0810 13:04:44.531184 13394 sgd_solver.cpp:106] Iteration 1320, lr = 0.00911203
I0810 13:04:46.020529 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:04:51.075459 13394 solver.cpp:228] Iteration 1330, loss = 0.12617
I0810 13:04:51.075505 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:04:51.075523 13394 solver.cpp:244]     Train net output #1: loss = 0.12617 (* 1 = 0.12617 loss)
I0810 13:04:51.075538 13394 sgd_solver.cpp:106] Iteration 1330, lr = 0.009106
I0810 13:04:56.067327 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:04:56.884467 13394 solver.cpp:228] Iteration 1340, loss = 0.220039
I0810 13:04:56.884620 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:04:56.884660 13394 solver.cpp:244]     Train net output #1: loss = 0.220039 (* 1 = 0.220039 loss)
I0810 13:04:56.884699 13394 sgd_solver.cpp:106] Iteration 1340, lr = 0.00909997
I0810 13:05:02.878826 13394 solver.cpp:228] Iteration 1350, loss = 0.22011
I0810 13:05:02.878876 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:05:02.878892 13394 solver.cpp:244]     Train net output #1: loss = 0.22011 (* 1 = 0.22011 loss)
I0810 13:05:02.878906 13394 sgd_solver.cpp:106] Iteration 1350, lr = 0.00909396
I0810 13:05:05.856998 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:05:08.840073 13394 solver.cpp:228] Iteration 1360, loss = 0.0942922
I0810 13:05:08.840121 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:05:08.840139 13394 solver.cpp:244]     Train net output #1: loss = 0.0942922 (* 1 = 0.0942922 loss)
I0810 13:05:08.840155 13394 sgd_solver.cpp:106] Iteration 1360, lr = 0.00908796
I0810 13:05:16.231619 13394 solver.cpp:228] Iteration 1370, loss = 0.156997
I0810 13:05:16.231815 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:05:16.231858 13394 solver.cpp:244]     Train net output #1: loss = 0.156997 (* 1 = 0.156997 loss)
I0810 13:05:16.231895 13394 sgd_solver.cpp:106] Iteration 1370, lr = 0.00908196
I0810 13:05:17.827318 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:05:23.676224 13394 solver.cpp:228] Iteration 1380, loss = 0.0940215
I0810 13:05:23.676326 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:05:23.676352 13394 solver.cpp:244]     Train net output #1: loss = 0.0940214 (* 1 = 0.0940214 loss)
I0810 13:05:23.676368 13394 sgd_solver.cpp:106] Iteration 1380, lr = 0.00907598
I0810 13:05:29.443184 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:05:30.260865 13394 solver.cpp:228] Iteration 1390, loss = 0.347305
I0810 13:05:30.260911 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:05:30.260929 13394 solver.cpp:244]     Train net output #1: loss = 0.347305 (* 1 = 0.347305 loss)
I0810 13:05:30.260946 13394 sgd_solver.cpp:106] Iteration 1390, lr = 0.00907
I0810 13:05:35.700947 13394 solver.cpp:337] Iteration 1400, Testing net (#0)
I0810 13:05:37.865115 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:05:37.865242 13394 solver.cpp:404]     Test net output #1: loss = 1.12406 (* 1 = 1.12406 loss)
I0810 13:05:38.135960 13394 solver.cpp:228] Iteration 1400, loss = 0.157168
I0810 13:05:38.136008 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:05:38.136025 13394 solver.cpp:244]     Train net output #1: loss = 0.157168 (* 1 = 0.157168 loss)
I0810 13:05:38.136042 13394 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0810 13:05:38.950781 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:05:48.782438 13394 solver.cpp:228] Iteration 1410, loss = 0.13022
I0810 13:05:48.782570 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:05:48.782588 13394 solver.cpp:244]     Train net output #1: loss = 0.13022 (* 1 = 0.13022 loss)
I0810 13:05:48.782603 13394 sgd_solver.cpp:106] Iteration 1410, lr = 0.00905807
I0810 13:05:56.818467 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:05:57.562537 13394 solver.cpp:228] Iteration 1420, loss = 0.125868
I0810 13:05:57.562587 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:05:57.562605 13394 solver.cpp:244]     Train net output #1: loss = 0.125868 (* 1 = 0.125868 loss)
I0810 13:05:57.562621 13394 sgd_solver.cpp:106] Iteration 1420, lr = 0.00905212
I0810 13:06:03.450939 13394 solver.cpp:228] Iteration 1430, loss = 0.127216
I0810 13:06:03.450987 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:06:03.451004 13394 solver.cpp:244]     Train net output #1: loss = 0.127216 (* 1 = 0.127216 loss)
I0810 13:06:03.451016 13394 sgd_solver.cpp:106] Iteration 1430, lr = 0.00904618
I0810 13:06:06.357245 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:06:09.661546 13394 solver.cpp:228] Iteration 1440, loss = 0.0941886
I0810 13:06:09.661594 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:06:09.661612 13394 solver.cpp:244]     Train net output #1: loss = 0.0941886 (* 1 = 0.0941886 loss)
I0810 13:06:09.661630 13394 sgd_solver.cpp:106] Iteration 1440, lr = 0.00904025
I0810 13:06:15.681037 13394 solver.cpp:228] Iteration 1450, loss = 0.156421
I0810 13:06:15.681082 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:06:15.681095 13394 solver.cpp:244]     Train net output #1: loss = 0.156421 (* 1 = 0.156421 loss)
I0810 13:06:15.681108 13394 sgd_solver.cpp:106] Iteration 1450, lr = 0.00903433
I0810 13:06:16.920301 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:06:22.262871 13394 solver.cpp:228] Iteration 1460, loss = 0.346764
I0810 13:06:22.270160 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:06:22.270220 13394 solver.cpp:244]     Train net output #1: loss = 0.346764 (* 1 = 0.346764 loss)
I0810 13:06:22.270264 13394 sgd_solver.cpp:106] Iteration 1460, lr = 0.00902842
I0810 13:06:27.549100 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:06:28.830571 13394 solver.cpp:228] Iteration 1470, loss = 0.187673
I0810 13:06:28.830633 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:06:28.830651 13394 solver.cpp:244]     Train net output #1: loss = 0.187673 (* 1 = 0.187673 loss)
I0810 13:06:28.830667 13394 sgd_solver.cpp:106] Iteration 1470, lr = 0.00902251
I0810 13:06:39.138233 13394 solver.cpp:228] Iteration 1480, loss = 0.22231
I0810 13:06:39.138397 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:06:39.138440 13394 solver.cpp:244]     Train net output #1: loss = 0.22231 (* 1 = 0.22231 loss)
I0810 13:06:39.138478 13394 sgd_solver.cpp:106] Iteration 1480, lr = 0.00901662
I0810 13:06:41.675066 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:06:44.189201 13394 solver.cpp:228] Iteration 1490, loss = 0.15979
I0810 13:06:44.189246 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:06:44.189262 13394 solver.cpp:244]     Train net output #1: loss = 0.15979 (* 1 = 0.15979 loss)
I0810 13:06:44.189276 13394 sgd_solver.cpp:106] Iteration 1490, lr = 0.00901073
I0810 13:06:49.095640 13394 solver.cpp:337] Iteration 1500, Testing net (#0)
I0810 13:06:51.935439 13403 blocking_queue.cpp:50] Waiting for data
I0810 13:06:52.960494 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 13:06:52.960628 13394 solver.cpp:404]     Test net output #1: loss = 1.14331 (* 1 = 1.14331 loss)
I0810 13:06:53.242933 13394 solver.cpp:228] Iteration 1500, loss = 0.125416
I0810 13:06:53.242980 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:06:53.242995 13394 solver.cpp:244]     Train net output #1: loss = 0.125416 (* 1 = 0.125416 loss)
I0810 13:06:53.243008 13394 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0810 13:07:02.402354 13394 solver.cpp:228] Iteration 1510, loss = 0.219325
I0810 13:07:02.402400 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:07:02.402415 13394 solver.cpp:244]     Train net output #1: loss = 0.219325 (* 1 = 0.219325 loss)
I0810 13:07:02.402434 13394 sgd_solver.cpp:106] Iteration 1510, lr = 0.00899898
I0810 13:07:05.498317 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:07:07.619496 13394 solver.cpp:228] Iteration 1520, loss = 0.219344
I0810 13:07:07.619540 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:07:07.619560 13394 solver.cpp:244]     Train net output #1: loss = 0.219344 (* 1 = 0.219344 loss)
I0810 13:07:07.619575 13394 sgd_solver.cpp:106] Iteration 1520, lr = 0.00899313
I0810 13:07:13.560004 13394 solver.cpp:228] Iteration 1530, loss = 0.188686
I0810 13:07:13.560058 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:07:13.560076 13394 solver.cpp:244]     Train net output #1: loss = 0.188686 (* 1 = 0.188686 loss)
I0810 13:07:13.560092 13394 sgd_solver.cpp:106] Iteration 1530, lr = 0.00898727
I0810 13:07:15.761790 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:07:19.007746 13394 solver.cpp:228] Iteration 1540, loss = 0.285657
I0810 13:07:19.007791 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:07:19.007808 13394 solver.cpp:244]     Train net output #1: loss = 0.285657 (* 1 = 0.285657 loss)
I0810 13:07:19.007823 13394 sgd_solver.cpp:106] Iteration 1540, lr = 0.00898143
I0810 13:07:23.534544 13394 solver.cpp:228] Iteration 1550, loss = 0.0629597
I0810 13:07:23.534639 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:07:23.534657 13394 solver.cpp:244]     Train net output #1: loss = 0.0629597 (* 1 = 0.0629597 loss)
I0810 13:07:23.534741 13394 sgd_solver.cpp:106] Iteration 1550, lr = 0.0089756
I0810 13:07:26.292292 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:07:26.325635 13394 solver.cpp:228] Iteration 1560, loss = 0.250533
I0810 13:07:26.325680 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:07:26.325696 13394 solver.cpp:244]     Train net output #1: loss = 0.250533 (* 1 = 0.250533 loss)
I0810 13:07:26.325712 13394 sgd_solver.cpp:106] Iteration 1560, lr = 0.00896978
I0810 13:07:33.580958 13394 solver.cpp:228] Iteration 1570, loss = 0.156757
I0810 13:07:33.581007 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:07:33.581025 13394 solver.cpp:244]     Train net output #1: loss = 0.156757 (* 1 = 0.156757 loss)
I0810 13:07:33.581172 13394 sgd_solver.cpp:106] Iteration 1570, lr = 0.00896396
I0810 13:07:37.498848 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:07:39.354161 13394 solver.cpp:228] Iteration 1580, loss = 0.0938604
I0810 13:07:39.354212 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:07:39.354231 13394 solver.cpp:244]     Train net output #1: loss = 0.0938604 (* 1 = 0.0938604 loss)
I0810 13:07:39.354249 13394 sgd_solver.cpp:106] Iteration 1580, lr = 0.00895816
I0810 13:07:46.394712 13394 solver.cpp:228] Iteration 1590, loss = 0.282615
I0810 13:07:46.394819 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:07:46.394876 13394 solver.cpp:244]     Train net output #1: loss = 0.282615 (* 1 = 0.282615 loss)
I0810 13:07:46.394914 13394 sgd_solver.cpp:106] Iteration 1590, lr = 0.00895236
I0810 13:07:48.350555 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:07:51.005239 13394 solver.cpp:337] Iteration 1600, Testing net (#0)
I0810 13:07:52.777637 13394 solver.cpp:404]     Test net output #0: accuracy = 0.696875
I0810 13:07:52.777691 13394 solver.cpp:404]     Test net output #1: loss = 1.10802 (* 1 = 1.10802 loss)
I0810 13:07:53.050983 13394 solver.cpp:228] Iteration 1600, loss = 0.285662
I0810 13:07:53.051033 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:07:53.051053 13394 solver.cpp:244]     Train net output #1: loss = 0.285662 (* 1 = 0.285662 loss)
I0810 13:07:53.051069 13394 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0810 13:07:58.226590 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:07:58.693861 13394 solver.cpp:228] Iteration 1610, loss = 2.98023e-08
I0810 13:07:58.693912 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:07:58.693929 13394 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0810 13:07:58.693945 13394 sgd_solver.cpp:106] Iteration 1610, lr = 0.00894079
I0810 13:08:03.471595 13394 solver.cpp:228] Iteration 1620, loss = 0.188545
I0810 13:08:03.471638 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:08:03.471654 13394 solver.cpp:244]     Train net output #1: loss = 0.188545 (* 1 = 0.188545 loss)
I0810 13:08:03.471670 13394 sgd_solver.cpp:106] Iteration 1620, lr = 0.00893502
I0810 13:08:08.036794 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:08:09.554344 13394 solver.cpp:228] Iteration 1630, loss = 0.250693
I0810 13:08:09.554388 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:08:09.554406 13394 solver.cpp:244]     Train net output #1: loss = 0.250693 (* 1 = 0.250693 loss)
I0810 13:08:09.554422 13394 sgd_solver.cpp:106] Iteration 1630, lr = 0.00892925
I0810 13:08:16.193990 13394 solver.cpp:228] Iteration 1640, loss = 0.221312
I0810 13:08:16.194036 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:08:16.194054 13394 solver.cpp:244]     Train net output #1: loss = 0.221312 (* 1 = 0.221312 loss)
I0810 13:08:16.194069 13394 sgd_solver.cpp:106] Iteration 1640, lr = 0.0089235
I0810 13:08:19.300016 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:08:22.807183 13394 solver.cpp:228] Iteration 1650, loss = 0.188949
I0810 13:08:22.807226 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:08:22.807245 13394 solver.cpp:244]     Train net output #1: loss = 0.188949 (* 1 = 0.188949 loss)
I0810 13:08:22.807262 13394 sgd_solver.cpp:106] Iteration 1650, lr = 0.00891776
I0810 13:08:28.710624 13394 solver.cpp:228] Iteration 1660, loss = 0.157525
I0810 13:08:28.710824 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:08:28.710865 13394 solver.cpp:244]     Train net output #1: loss = 0.157525 (* 1 = 0.157525 loss)
I0810 13:08:28.710901 13394 sgd_solver.cpp:106] Iteration 1660, lr = 0.00891202
I0810 13:08:30.107592 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:08:35.078557 13394 solver.cpp:228] Iteration 1670, loss = 0.15719
I0810 13:08:35.078603 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:08:35.078622 13394 solver.cpp:244]     Train net output #1: loss = 0.15719 (* 1 = 0.15719 loss)
I0810 13:08:35.078639 13394 sgd_solver.cpp:106] Iteration 1670, lr = 0.00890629
I0810 13:08:41.062113 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:08:41.824689 13394 solver.cpp:228] Iteration 1680, loss = 0.156925
I0810 13:08:41.824913 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:08:41.824995 13394 solver.cpp:244]     Train net output #1: loss = 0.156925 (* 1 = 0.156925 loss)
I0810 13:08:41.825036 13394 sgd_solver.cpp:106] Iteration 1680, lr = 0.00890057
I0810 13:08:48.663542 13394 solver.cpp:228] Iteration 1690, loss = 0.0947179
I0810 13:08:48.663586 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:08:48.663604 13394 solver.cpp:244]     Train net output #1: loss = 0.0947178 (* 1 = 0.0947178 loss)
I0810 13:08:48.663620 13394 sgd_solver.cpp:106] Iteration 1690, lr = 0.00889486
I0810 13:08:53.534533 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:08:54.522572 13394 solver.cpp:337] Iteration 1700, Testing net (#0)
I0810 13:08:56.009189 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:08:56.009475 13394 solver.cpp:404]     Test net output #1: loss = 1.11648 (* 1 = 1.11648 loss)
I0810 13:08:56.293040 13394 solver.cpp:228] Iteration 1700, loss = 0.0632041
I0810 13:08:56.293182 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:08:56.293227 13394 solver.cpp:244]     Train net output #1: loss = 0.0632041 (* 1 = 0.0632041 loss)
I0810 13:08:56.293265 13394 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0810 13:09:03.774500 13394 solver.cpp:228] Iteration 1710, loss = 0.157064
I0810 13:09:03.774688 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:09:03.774729 13394 solver.cpp:244]     Train net output #1: loss = 0.157064 (* 1 = 0.157064 loss)
I0810 13:09:03.774766 13394 sgd_solver.cpp:106] Iteration 1710, lr = 0.00888346
I0810 13:09:05.107998 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:09:09.154346 13394 solver.cpp:228] Iteration 1720, loss = 0.157271
I0810 13:09:09.154392 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:09:09.154407 13394 solver.cpp:244]     Train net output #1: loss = 0.157271 (* 1 = 0.157271 loss)
I0810 13:09:09.154420 13394 sgd_solver.cpp:106] Iteration 1720, lr = 0.00887778
I0810 13:09:12.864524 13394 solver.cpp:228] Iteration 1730, loss = 0.157653
I0810 13:09:12.864639 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:09:12.864681 13394 solver.cpp:244]     Train net output #1: loss = 0.157653 (* 1 = 0.157653 loss)
I0810 13:09:12.864717 13394 sgd_solver.cpp:106] Iteration 1730, lr = 0.0088721
I0810 13:09:13.388490 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:09:17.086510 13394 solver.cpp:228] Iteration 1740, loss = 0.0340627
I0810 13:09:17.086558 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:09:17.086575 13394 solver.cpp:244]     Train net output #1: loss = 0.0340627 (* 1 = 0.0340627 loss)
I0810 13:09:17.086588 13394 sgd_solver.cpp:106] Iteration 1740, lr = 0.00886643
I0810 13:09:22.866540 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:09:23.067845 13394 solver.cpp:228] Iteration 1750, loss = 0.158181
I0810 13:09:23.067893 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:09:23.067914 13394 solver.cpp:244]     Train net output #1: loss = 0.158181 (* 1 = 0.158181 loss)
I0810 13:09:23.067971 13394 sgd_solver.cpp:106] Iteration 1750, lr = 0.00886077
I0810 13:09:29.625584 13394 solver.cpp:228] Iteration 1760, loss = 0.219451
I0810 13:09:29.625633 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:09:29.625651 13394 solver.cpp:244]     Train net output #1: loss = 0.219451 (* 1 = 0.219451 loss)
I0810 13:09:29.625669 13394 sgd_solver.cpp:106] Iteration 1760, lr = 0.00885512
I0810 13:09:34.970932 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:09:42.482015 13394 solver.cpp:228] Iteration 1770, loss = 0.188598
I0810 13:09:42.482060 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:09:42.482079 13394 solver.cpp:244]     Train net output #1: loss = 0.188598 (* 1 = 0.188598 loss)
I0810 13:09:42.482094 13394 sgd_solver.cpp:106] Iteration 1770, lr = 0.00884948
I0810 13:09:50.286908 13394 solver.cpp:228] Iteration 1780, loss = 0.192341
I0810 13:09:50.286954 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:09:50.286972 13394 solver.cpp:244]     Train net output #1: loss = 0.192341 (* 1 = 0.192341 loss)
I0810 13:09:50.286988 13394 sgd_solver.cpp:106] Iteration 1780, lr = 0.00884384
I0810 13:09:52.069346 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:09:57.128793 13394 solver.cpp:228] Iteration 1790, loss = 0.156427
I0810 13:09:57.128836 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:09:57.128851 13394 solver.cpp:244]     Train net output #1: loss = 0.156427 (* 1 = 0.156427 loss)
I0810 13:09:57.128865 13394 sgd_solver.cpp:106] Iteration 1790, lr = 0.00883822
I0810 13:10:02.648406 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:10:02.717825 13394 solver.cpp:337] Iteration 1800, Testing net (#0)
I0810 13:10:07.644556 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:10:07.644682 13394 solver.cpp:404]     Test net output #1: loss = 1.12264 (* 1 = 1.12264 loss)
I0810 13:10:07.926637 13394 solver.cpp:228] Iteration 1800, loss = 0.0628741
I0810 13:10:07.926684 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:10:07.926703 13394 solver.cpp:244]     Train net output #1: loss = 0.062874 (* 1 = 0.062874 loss)
I0810 13:10:07.926720 13394 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0810 13:10:17.140229 13394 solver.cpp:228] Iteration 1810, loss = 0.0938369
I0810 13:10:17.140277 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:10:17.140295 13394 solver.cpp:244]     Train net output #1: loss = 0.0938369 (* 1 = 0.0938369 loss)
I0810 13:10:17.140311 13394 sgd_solver.cpp:106] Iteration 1810, lr = 0.00882699
I0810 13:10:17.416451 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:10:23.433619 13394 solver.cpp:228] Iteration 1820, loss = 0.251588
I0810 13:10:23.433676 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:10:23.433696 13394 solver.cpp:244]     Train net output #1: loss = 0.251588 (* 1 = 0.251588 loss)
I0810 13:10:23.433713 13394 sgd_solver.cpp:106] Iteration 1820, lr = 0.00882139
I0810 13:10:26.506043 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:10:26.654633 13394 solver.cpp:228] Iteration 1830, loss = 0.0939138
I0810 13:10:26.654729 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:10:26.654768 13394 solver.cpp:244]     Train net output #1: loss = 0.0939137 (* 1 = 0.0939137 loss)
I0810 13:10:26.654801 13394 sgd_solver.cpp:106] Iteration 1830, lr = 0.00881579
I0810 13:10:30.722868 13394 solver.cpp:228] Iteration 1840, loss = 0.062672
I0810 13:10:30.722918 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:10:30.722936 13394 solver.cpp:244]     Train net output #1: loss = 0.062672 (* 1 = 0.062672 loss)
I0810 13:10:30.722954 13394 sgd_solver.cpp:106] Iteration 1840, lr = 0.00881021
I0810 13:10:35.482269 13394 solver.cpp:228] Iteration 1850, loss = 0.0940386
I0810 13:10:35.482317 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:10:35.482337 13394 solver.cpp:244]     Train net output #1: loss = 0.0940385 (* 1 = 0.0940385 loss)
I0810 13:10:35.482352 13394 sgd_solver.cpp:106] Iteration 1850, lr = 0.00880463
I0810 13:10:37.327780 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:10:40.452144 13394 solver.cpp:228] Iteration 1860, loss = 0.0672306
I0810 13:10:40.452304 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:10:40.452344 13394 solver.cpp:244]     Train net output #1: loss = 0.0672306 (* 1 = 0.0672306 loss)
I0810 13:10:40.452386 13394 sgd_solver.cpp:106] Iteration 1860, lr = 0.00879906
I0810 13:10:45.652108 13394 solver.cpp:228] Iteration 1870, loss = 0.283089
I0810 13:10:45.652161 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:10:45.652179 13394 solver.cpp:244]     Train net output #1: loss = 0.283089 (* 1 = 0.283089 loss)
I0810 13:10:45.652195 13394 sgd_solver.cpp:106] Iteration 1870, lr = 0.0087935
I0810 13:10:46.763538 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:10:51.920429 13394 solver.cpp:228] Iteration 1880, loss = 0.126392
I0810 13:10:51.920485 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:10:51.920502 13394 solver.cpp:244]     Train net output #1: loss = 0.126392 (* 1 = 0.126392 loss)
I0810 13:10:51.920517 13394 sgd_solver.cpp:106] Iteration 1880, lr = 0.00878795
I0810 13:10:57.903846 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:10:58.492797 13394 solver.cpp:228] Iteration 1890, loss = 0.314406
I0810 13:10:58.492844 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:10:58.492862 13394 solver.cpp:244]     Train net output #1: loss = 0.314406 (* 1 = 0.314406 loss)
I0810 13:10:58.492877 13394 sgd_solver.cpp:106] Iteration 1890, lr = 0.00878241
I0810 13:11:04.997468 13394 solver.cpp:337] Iteration 1900, Testing net (#0)
I0810 13:11:08.357734 13394 solver.cpp:404]     Test net output #0: accuracy = 0.695312
I0810 13:11:08.357787 13394 solver.cpp:404]     Test net output #1: loss = 1.09292 (* 1 = 1.09292 loss)
I0810 13:11:08.637552 13394 solver.cpp:228] Iteration 1900, loss = 0.218821
I0810 13:11:08.637604 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:11:08.637624 13394 solver.cpp:244]     Train net output #1: loss = 0.218821 (* 1 = 0.218821 loss)
I0810 13:11:08.637640 13394 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0810 13:11:09.070053 13403 blocking_queue.cpp:50] Waiting for data
I0810 13:11:14.268736 13394 solver.cpp:228] Iteration 1910, loss = 0.12658
I0810 13:11:14.268890 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:11:14.268909 13394 solver.cpp:244]     Train net output #1: loss = 0.12658 (* 1 = 0.12658 loss)
I0810 13:11:14.268926 13394 sgd_solver.cpp:106] Iteration 1910, lr = 0.00877135
I0810 13:11:18.125915 13394 solver.cpp:228] Iteration 1920, loss = 0.22479
I0810 13:11:18.125962 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:11:18.125977 13394 solver.cpp:244]     Train net output #1: loss = 0.22479 (* 1 = 0.22479 loss)
I0810 13:11:18.125990 13394 sgd_solver.cpp:106] Iteration 1920, lr = 0.00876583
I0810 13:11:18.254020 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:11:22.291561 13394 solver.cpp:228] Iteration 1930, loss = 0.258785
I0810 13:11:22.291610 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:11:22.291628 13394 solver.cpp:244]     Train net output #1: loss = 0.258785 (* 1 = 0.258785 loss)
I0810 13:11:22.291646 13394 sgd_solver.cpp:106] Iteration 1930, lr = 0.00876031
I0810 13:11:27.695897 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:11:27.900779 13394 solver.cpp:228] Iteration 1940, loss = 0.222565
I0810 13:11:27.900835 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:11:27.900852 13394 solver.cpp:244]     Train net output #1: loss = 0.222565 (* 1 = 0.222565 loss)
I0810 13:11:27.900868 13394 sgd_solver.cpp:106] Iteration 1940, lr = 0.00875481
I0810 13:11:32.361013 13394 solver.cpp:228] Iteration 1950, loss = 0.126686
I0810 13:11:32.361058 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:11:32.361075 13394 solver.cpp:244]     Train net output #1: loss = 0.126686 (* 1 = 0.126686 loss)
I0810 13:11:32.361091 13394 sgd_solver.cpp:106] Iteration 1950, lr = 0.00874932
I0810 13:11:36.602207 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:11:36.860445 13394 solver.cpp:228] Iteration 1960, loss = 0.250697
I0810 13:11:36.860496 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:11:36.860512 13394 solver.cpp:244]     Train net output #1: loss = 0.250697 (* 1 = 0.250697 loss)
I0810 13:11:36.860525 13394 sgd_solver.cpp:106] Iteration 1960, lr = 0.00874383
I0810 13:11:41.286520 13394 solver.cpp:228] Iteration 1970, loss = 0.157488
I0810 13:11:41.286705 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:11:41.286746 13394 solver.cpp:244]     Train net output #1: loss = 0.157488 (* 1 = 0.157488 loss)
I0810 13:11:41.286783 13394 sgd_solver.cpp:106] Iteration 1970, lr = 0.00873835
I0810 13:11:44.800451 13394 solver.cpp:228] Iteration 1980, loss = 0.158277
I0810 13:11:44.800551 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:11:44.800570 13394 solver.cpp:244]     Train net output #1: loss = 0.158277 (* 1 = 0.158277 loss)
I0810 13:11:44.800587 13394 sgd_solver.cpp:106] Iteration 1980, lr = 0.00873288
I0810 13:11:45.249627 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:11:50.926934 13394 solver.cpp:228] Iteration 1990, loss = 0.157134
I0810 13:11:50.926980 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:11:50.926997 13394 solver.cpp:244]     Train net output #1: loss = 0.157134 (* 1 = 0.157134 loss)
I0810 13:11:50.927013 13394 sgd_solver.cpp:106] Iteration 1990, lr = 0.00872741
I0810 13:11:56.497141 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:11:57.027935 13394 solver.cpp:337] Iteration 2000, Testing net (#0)
I0810 13:11:58.569989 13394 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0810 13:11:58.570036 13394 solver.cpp:404]     Test net output #1: loss = 1.14443 (* 1 = 1.14443 loss)
I0810 13:11:58.850744 13394 solver.cpp:228] Iteration 2000, loss = 0.221566
I0810 13:11:58.851033 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:11:58.851171 13394 solver.cpp:244]     Train net output #1: loss = 0.221566 (* 1 = 0.221566 loss)
I0810 13:11:58.851310 13394 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0810 13:12:05.867665 13394 solver.cpp:228] Iteration 2010, loss = 0.284816
I0810 13:12:05.867717 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:12:05.867735 13394 solver.cpp:244]     Train net output #1: loss = 0.284816 (* 1 = 0.284816 loss)
I0810 13:12:05.867751 13394 sgd_solver.cpp:106] Iteration 2010, lr = 0.00871651
I0810 13:12:06.808182 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:12:11.882524 13394 solver.cpp:228] Iteration 2020, loss = 0.222618
I0810 13:12:11.882575 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:12:11.882593 13394 solver.cpp:244]     Train net output #1: loss = 0.222618 (* 1 = 0.222618 loss)
I0810 13:12:11.882611 13394 sgd_solver.cpp:106] Iteration 2020, lr = 0.00871107
I0810 13:12:16.080965 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:12:16.399559 13394 solver.cpp:228] Iteration 2030, loss = 0.188937
I0810 13:12:16.399608 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:12:16.399627 13394 solver.cpp:244]     Train net output #1: loss = 0.188937 (* 1 = 0.188937 loss)
I0810 13:12:16.399644 13394 sgd_solver.cpp:106] Iteration 2030, lr = 0.00870564
I0810 13:12:19.348053 13394 solver.cpp:228] Iteration 2040, loss = 0.188647
I0810 13:12:19.348098 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:12:19.348112 13394 solver.cpp:244]     Train net output #1: loss = 0.188647 (* 1 = 0.188647 loss)
I0810 13:12:19.348126 13394 sgd_solver.cpp:106] Iteration 2040, lr = 0.00870022
I0810 13:12:22.224675 13394 solver.cpp:228] Iteration 2050, loss = 0.31429
I0810 13:12:22.224720 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:12:22.224737 13394 solver.cpp:244]     Train net output #1: loss = 0.31429 (* 1 = 0.31429 loss)
I0810 13:12:22.224752 13394 sgd_solver.cpp:106] Iteration 2050, lr = 0.0086948
I0810 13:12:25.022742 13394 solver.cpp:228] Iteration 2060, loss = 0.22045
I0810 13:12:25.022791 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:12:25.022810 13394 solver.cpp:244]     Train net output #1: loss = 0.22045 (* 1 = 0.22045 loss)
I0810 13:12:25.022828 13394 sgd_solver.cpp:106] Iteration 2060, lr = 0.00868939
I0810 13:12:28.854167 13394 solver.cpp:228] Iteration 2070, loss = 0.157506
I0810 13:12:28.854212 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:12:28.854230 13394 solver.cpp:244]     Train net output #1: loss = 0.157506 (* 1 = 0.157506 loss)
I0810 13:12:28.854246 13394 sgd_solver.cpp:106] Iteration 2070, lr = 0.00868399
I0810 13:12:29.145519 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:12:35.413280 13394 solver.cpp:228] Iteration 2080, loss = 0.219862
I0810 13:12:35.413326 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:12:35.413342 13394 solver.cpp:244]     Train net output #1: loss = 0.219862 (* 1 = 0.219862 loss)
I0810 13:12:35.413357 13394 sgd_solver.cpp:106] Iteration 2080, lr = 0.0086786
I0810 13:12:39.362267 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:12:41.352905 13394 solver.cpp:228] Iteration 2090, loss = 0.251828
I0810 13:12:41.352954 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:12:41.352972 13394 solver.cpp:244]     Train net output #1: loss = 0.251828 (* 1 = 0.251828 loss)
I0810 13:12:41.352989 13394 sgd_solver.cpp:106] Iteration 2090, lr = 0.00867322
I0810 13:12:46.508282 13394 solver.cpp:337] Iteration 2100, Testing net (#0)
I0810 13:12:49.169083 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 13:12:49.169180 13394 solver.cpp:404]     Test net output #1: loss = 1.11452 (* 1 = 1.11452 loss)
I0810 13:12:49.441181 13394 solver.cpp:228] Iteration 2100, loss = 0.2508
I0810 13:12:49.441223 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:12:49.441241 13394 solver.cpp:244]     Train net output #1: loss = 0.2508 (* 1 = 0.2508 loss)
I0810 13:12:49.441257 13394 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0810 13:12:49.779542 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:12:53.539468 13394 blocking_queue.cpp:50] Data layer prefetch queue empty
I0810 13:12:59.709971 13394 solver.cpp:228] Iteration 2110, loss = 0.220955
I0810 13:12:59.710019 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:12:59.710039 13394 solver.cpp:244]     Train net output #1: loss = 0.220955 (* 1 = 0.220955 loss)
I0810 13:12:59.710055 13394 sgd_solver.cpp:106] Iteration 2110, lr = 0.00866247
I0810 13:13:03.000965 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:13:06.219552 13394 solver.cpp:228] Iteration 2120, loss = 0.188777
I0810 13:13:06.219599 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:13:06.219617 13394 solver.cpp:244]     Train net output #1: loss = 0.188777 (* 1 = 0.188777 loss)
I0810 13:13:06.219633 13394 sgd_solver.cpp:106] Iteration 2120, lr = 0.00865711
I0810 13:13:12.161921 13394 solver.cpp:228] Iteration 2130, loss = 0.221083
I0810 13:13:12.161962 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:13:12.161978 13394 solver.cpp:244]     Train net output #1: loss = 0.221083 (* 1 = 0.221083 loss)
I0810 13:13:12.161990 13394 sgd_solver.cpp:106] Iteration 2130, lr = 0.00865176
I0810 13:13:13.102563 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:13:18.036046 13394 solver.cpp:228] Iteration 2140, loss = 0.220505
I0810 13:13:18.048907 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:13:18.048931 13394 solver.cpp:244]     Train net output #1: loss = 0.220505 (* 1 = 0.220505 loss)
I0810 13:13:18.048946 13394 sgd_solver.cpp:106] Iteration 2140, lr = 0.00864641
I0810 13:13:20.993973 13394 solver.cpp:228] Iteration 2150, loss = 0.125562
I0810 13:13:20.994016 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:13:20.994035 13394 solver.cpp:244]     Train net output #1: loss = 0.125562 (* 1 = 0.125562 loss)
I0810 13:13:20.994050 13394 sgd_solver.cpp:106] Iteration 2150, lr = 0.00864108
I0810 13:13:21.286429 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:13:23.835736 13394 solver.cpp:228] Iteration 2160, loss = 0.252754
I0810 13:13:23.835783 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:13:23.835798 13394 solver.cpp:244]     Train net output #1: loss = 0.252753 (* 1 = 0.252753 loss)
I0810 13:13:23.835813 13394 sgd_solver.cpp:106] Iteration 2160, lr = 0.00863575
I0810 13:13:27.448288 13394 solver.cpp:228] Iteration 2170, loss = 0.126012
I0810 13:13:27.448330 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:13:27.448345 13394 solver.cpp:244]     Train net output #1: loss = 0.126012 (* 1 = 0.126012 loss)
I0810 13:13:27.448359 13394 sgd_solver.cpp:106] Iteration 2170, lr = 0.00863042
I0810 13:13:31.959038 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:13:36.660840 13394 solver.cpp:228] Iteration 2180, loss = 0.250681
I0810 13:13:36.660939 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:13:36.660991 13394 solver.cpp:244]     Train net output #1: loss = 0.250681 (* 1 = 0.250681 loss)
I0810 13:13:36.661031 13394 sgd_solver.cpp:106] Iteration 2180, lr = 0.00862511
I0810 13:13:42.144804 13394 solver.cpp:228] Iteration 2190, loss = 0.22073
I0810 13:13:42.144855 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:13:42.144872 13394 solver.cpp:244]     Train net output #1: loss = 0.22073 (* 1 = 0.22073 loss)
I0810 13:13:42.144888 13394 sgd_solver.cpp:106] Iteration 2190, lr = 0.0086198
I0810 13:13:46.360862 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:13:48.217381 13394 solver.cpp:337] Iteration 2200, Testing net (#0)
I0810 13:13:51.436100 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:13:51.436157 13394 solver.cpp:404]     Test net output #1: loss = 1.11797 (* 1 = 1.11797 loss)
I0810 13:13:51.728916 13394 solver.cpp:228] Iteration 2200, loss = 0.157073
I0810 13:13:51.728962 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:13:51.728981 13394 solver.cpp:244]     Train net output #1: loss = 0.157073 (* 1 = 0.157073 loss)
I0810 13:13:51.728996 13394 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0810 13:13:58.861757 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:14:00.256180 13394 solver.cpp:228] Iteration 2210, loss = 0.0626626
I0810 13:14:00.256225 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:14:00.256244 13394 solver.cpp:244]     Train net output #1: loss = 0.0626626 (* 1 = 0.0626626 loss)
I0810 13:14:00.256259 13394 sgd_solver.cpp:106] Iteration 2210, lr = 0.00860921
I0810 13:14:04.847245 13394 solver.cpp:228] Iteration 2220, loss = 0.189074
I0810 13:14:04.847301 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:14:04.847319 13394 solver.cpp:244]     Train net output #1: loss = 0.189074 (* 1 = 0.189074 loss)
I0810 13:14:04.847337 13394 sgd_solver.cpp:106] Iteration 2220, lr = 0.00860392
I0810 13:14:06.988317 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:14:08.460811 13394 solver.cpp:228] Iteration 2230, loss = 0.250213
I0810 13:14:08.460860 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:14:08.460880 13394 solver.cpp:244]     Train net output #1: loss = 0.250213 (* 1 = 0.250213 loss)
I0810 13:14:08.460894 13394 sgd_solver.cpp:106] Iteration 2230, lr = 0.00859865
I0810 13:14:11.262838 13394 solver.cpp:228] Iteration 2240, loss = 0.219074
I0810 13:14:11.262886 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:14:11.262904 13394 solver.cpp:244]     Train net output #1: loss = 0.219074 (* 1 = 0.219074 loss)
I0810 13:14:11.262919 13394 sgd_solver.cpp:106] Iteration 2240, lr = 0.00859338
I0810 13:14:14.617900 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:14:15.328835 13394 solver.cpp:228] Iteration 2250, loss = 0.250247
I0810 13:14:15.328884 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:14:15.328903 13394 solver.cpp:244]     Train net output #1: loss = 0.250247 (* 1 = 0.250247 loss)
I0810 13:14:15.328922 13394 sgd_solver.cpp:106] Iteration 2250, lr = 0.00858812
I0810 13:14:20.353221 13394 solver.cpp:228] Iteration 2260, loss = 0.221213
I0810 13:14:20.353348 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:14:20.353368 13394 solver.cpp:244]     Train net output #1: loss = 0.221213 (* 1 = 0.221213 loss)
I0810 13:14:20.353384 13394 sgd_solver.cpp:106] Iteration 2260, lr = 0.00858286
I0810 13:14:23.945363 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:14:25.174960 13394 solver.cpp:228] Iteration 2270, loss = 0.221084
I0810 13:14:25.175009 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:14:25.175029 13394 solver.cpp:244]     Train net output #1: loss = 0.221084 (* 1 = 0.221084 loss)
I0810 13:14:25.175045 13394 sgd_solver.cpp:106] Iteration 2270, lr = 0.00857762
I0810 13:14:29.670049 13394 solver.cpp:228] Iteration 2280, loss = 0.0938958
I0810 13:14:29.670095 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:14:29.670114 13394 solver.cpp:244]     Train net output #1: loss = 0.0938957 (* 1 = 0.0938957 loss)
I0810 13:14:29.670131 13394 sgd_solver.cpp:106] Iteration 2280, lr = 0.00857238
I0810 13:14:32.673909 13394 solver.cpp:228] Iteration 2290, loss = 0.0945583
I0810 13:14:32.673956 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:14:32.673974 13394 solver.cpp:244]     Train net output #1: loss = 0.0945582 (* 1 = 0.0945582 loss)
I0810 13:14:32.673988 13394 sgd_solver.cpp:106] Iteration 2290, lr = 0.00856714
I0810 13:14:34.562664 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:14:35.952769 13394 solver.cpp:337] Iteration 2300, Testing net (#0)
I0810 13:14:38.733067 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 13:14:38.733120 13394 solver.cpp:404]     Test net output #1: loss = 1.13787 (* 1 = 1.13787 loss)
I0810 13:14:39.017318 13394 solver.cpp:228] Iteration 2300, loss = 0.0944846
I0810 13:14:39.017422 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:14:39.017465 13394 solver.cpp:244]     Train net output #1: loss = 0.0944845 (* 1 = 0.0944845 loss)
I0810 13:14:39.017501 13394 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0810 13:14:47.755460 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:14:48.094528 13394 solver.cpp:228] Iteration 2310, loss = 0.0941288
I0810 13:14:48.094624 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:14:48.094661 13394 solver.cpp:244]     Train net output #1: loss = 0.0941288 (* 1 = 0.0941288 loss)
I0810 13:14:48.094694 13394 sgd_solver.cpp:106] Iteration 2310, lr = 0.0085567
I0810 13:14:54.541659 13394 solver.cpp:228] Iteration 2320, loss = 0.0314169
I0810 13:14:54.541815 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:14:54.541836 13394 solver.cpp:244]     Train net output #1: loss = 0.0314168 (* 1 = 0.0314168 loss)
I0810 13:14:54.541852 13394 sgd_solver.cpp:106] Iteration 2320, lr = 0.00855149
I0810 13:14:58.445412 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:15:00.965289 13394 solver.cpp:228] Iteration 2330, loss = 0.220375
I0810 13:15:00.965338 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:15:00.965358 13394 solver.cpp:244]     Train net output #1: loss = 0.220375 (* 1 = 0.220375 loss)
I0810 13:15:00.965373 13394 sgd_solver.cpp:106] Iteration 2330, lr = 0.00854629
I0810 13:15:06.858806 13394 solver.cpp:228] Iteration 2340, loss = 0.219699
I0810 13:15:06.858850 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:15:06.858867 13394 solver.cpp:244]     Train net output #1: loss = 0.219699 (* 1 = 0.219699 loss)
I0810 13:15:06.858882 13394 sgd_solver.cpp:106] Iteration 2340, lr = 0.0085411
I0810 13:15:07.656500 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:15:09.906296 13394 solver.cpp:228] Iteration 2350, loss = 0.188384
I0810 13:15:09.906342 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:15:09.906360 13394 solver.cpp:244]     Train net output #1: loss = 0.188384 (* 1 = 0.188384 loss)
I0810 13:15:09.906376 13394 sgd_solver.cpp:106] Iteration 2350, lr = 0.00853591
I0810 13:15:12.812644 13394 solver.cpp:228] Iteration 2360, loss = 0.344025
I0810 13:15:12.812703 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:15:12.812721 13394 solver.cpp:244]     Train net output #1: loss = 0.344025 (* 1 = 0.344025 loss)
I0810 13:15:12.812736 13394 sgd_solver.cpp:106] Iteration 2360, lr = 0.00853073
I0810 13:15:15.559363 13394 solver.cpp:228] Iteration 2370, loss = 0.220171
I0810 13:15:15.559407 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:15:15.559422 13394 solver.cpp:244]     Train net output #1: loss = 0.220171 (* 1 = 0.220171 loss)
I0810 13:15:15.559434 13394 sgd_solver.cpp:106] Iteration 2370, lr = 0.00852556
I0810 13:15:16.561296 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:15:20.969796 13394 solver.cpp:228] Iteration 2380, loss = 0.125353
I0810 13:15:20.969847 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:15:20.969866 13394 solver.cpp:244]     Train net output #1: loss = 0.125353 (* 1 = 0.125353 loss)
I0810 13:15:20.969882 13394 sgd_solver.cpp:106] Iteration 2380, lr = 0.00852039
I0810 13:15:28.238917 13394 solver.cpp:228] Iteration 2390, loss = 0.219005
I0810 13:15:28.239051 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:15:28.239068 13394 solver.cpp:244]     Train net output #1: loss = 0.219005 (* 1 = 0.219005 loss)
I0810 13:15:28.239083 13394 sgd_solver.cpp:106] Iteration 2390, lr = 0.00851523
I0810 13:15:28.680250 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:15:33.131042 13394 solver.cpp:337] Iteration 2400, Testing net (#0)
I0810 13:15:35.628005 13394 solver.cpp:404]     Test net output #0: accuracy = 0.692187
I0810 13:15:35.628052 13394 solver.cpp:404]     Test net output #1: loss = 1.10227 (* 1 = 1.10227 loss)
I0810 13:15:35.911165 13394 solver.cpp:228] Iteration 2400, loss = 0.125615
I0810 13:15:35.911270 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:15:35.911339 13394 solver.cpp:244]     Train net output #1: loss = 0.125615 (* 1 = 0.125615 loss)
I0810 13:15:35.911378 13394 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0810 13:15:38.481017 13403 blocking_queue.cpp:50] Waiting for data
I0810 13:15:43.872458 13394 solver.cpp:228] Iteration 2410, loss = 0.282129
I0810 13:15:43.872500 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:15:43.872515 13394 solver.cpp:244]     Train net output #1: loss = 0.282129 (* 1 = 0.282129 loss)
I0810 13:15:43.872530 13394 sgd_solver.cpp:106] Iteration 2410, lr = 0.00850494
I0810 13:15:49.616895 13394 solver.cpp:228] Iteration 2420, loss = 0.190029
I0810 13:15:49.616945 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:15:49.616962 13394 solver.cpp:244]     Train net output #1: loss = 0.190029 (* 1 = 0.190029 loss)
I0810 13:15:49.616977 13394 sgd_solver.cpp:106] Iteration 2420, lr = 0.0084998
I0810 13:15:50.473430 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:15:53.163333 13394 solver.cpp:228] Iteration 2430, loss = 0.156882
I0810 13:15:53.163381 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:15:53.163399 13394 solver.cpp:244]     Train net output #1: loss = 0.156882 (* 1 = 0.156882 loss)
I0810 13:15:53.163416 13394 sgd_solver.cpp:106] Iteration 2430, lr = 0.00849467
I0810 13:15:58.225067 13394 solver.cpp:228] Iteration 2440, loss = 0.251817
I0810 13:15:58.225107 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:15:58.225122 13394 solver.cpp:244]     Train net output #1: loss = 0.251817 (* 1 = 0.251817 loss)
I0810 13:15:58.225136 13394 sgd_solver.cpp:106] Iteration 2440, lr = 0.00848955
I0810 13:15:59.013917 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:16:04.401252 13394 solver.cpp:228] Iteration 2450, loss = 0.187883
I0810 13:16:04.401293 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:16:04.401307 13394 solver.cpp:244]     Train net output #1: loss = 0.187883 (* 1 = 0.187883 loss)
I0810 13:16:04.401326 13394 sgd_solver.cpp:106] Iteration 2450, lr = 0.00848444
I0810 13:16:07.930187 13394 solver.cpp:228] Iteration 2460, loss = 0.345431
I0810 13:16:07.930241 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:16:07.930261 13394 solver.cpp:244]     Train net output #1: loss = 0.345431 (* 1 = 0.345431 loss)
I0810 13:16:07.930279 13394 sgd_solver.cpp:106] Iteration 2460, lr = 0.00847933
I0810 13:16:10.785454 13394 solver.cpp:228] Iteration 2470, loss = 0.315876
I0810 13:16:10.785504 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:16:10.785521 13394 solver.cpp:244]     Train net output #1: loss = 0.315876 (* 1 = 0.315876 loss)
I0810 13:16:10.785537 13394 sgd_solver.cpp:106] Iteration 2470, lr = 0.00847423
I0810 13:16:13.666991 13394 solver.cpp:228] Iteration 2480, loss = 0.156506
I0810 13:16:13.667049 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:16:13.667068 13394 solver.cpp:244]     Train net output #1: loss = 0.156506 (* 1 = 0.156506 loss)
I0810 13:16:13.667083 13394 sgd_solver.cpp:106] Iteration 2480, lr = 0.00846913
I0810 13:16:16.480372 13394 solver.cpp:228] Iteration 2490, loss = 0.127717
I0810 13:16:16.480417 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:16:16.480434 13394 solver.cpp:244]     Train net output #1: loss = 0.127717 (* 1 = 0.127717 loss)
I0810 13:16:16.480450 13394 sgd_solver.cpp:106] Iteration 2490, lr = 0.00846405
I0810 13:16:17.789373 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:16:19.329587 13394 solver.cpp:337] Iteration 2500, Testing net (#0)
I0810 13:16:22.381971 13394 solver.cpp:404]     Test net output #0: accuracy = 0.692187
I0810 13:16:22.382030 13394 solver.cpp:404]     Test net output #1: loss = 1.09342 (* 1 = 1.09342 loss)
I0810 13:16:22.665931 13394 solver.cpp:228] Iteration 2500, loss = 0.250512
I0810 13:16:22.665980 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:16:22.665998 13394 solver.cpp:244]     Train net output #1: loss = 0.250512 (* 1 = 0.250512 loss)
I0810 13:16:22.666014 13394 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0810 13:16:30.986249 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:16:32.718307 13394 solver.cpp:228] Iteration 2510, loss = 0.284483
I0810 13:16:32.718360 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:16:32.718379 13394 solver.cpp:244]     Train net output #1: loss = 0.284483 (* 1 = 0.284483 loss)
I0810 13:16:32.718395 13394 sgd_solver.cpp:106] Iteration 2510, lr = 0.0084539
I0810 13:16:38.549074 13394 solver.cpp:228] Iteration 2520, loss = 0.127429
I0810 13:16:38.549125 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:16:38.549144 13394 solver.cpp:244]     Train net output #1: loss = 0.127429 (* 1 = 0.127429 loss)
I0810 13:16:38.549162 13394 sgd_solver.cpp:106] Iteration 2520, lr = 0.00844883
I0810 13:16:40.633376 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:16:42.396749 13394 solver.cpp:228] Iteration 2530, loss = 0.223659
I0810 13:16:42.396800 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:16:42.396817 13394 solver.cpp:244]     Train net output #1: loss = 0.223659 (* 1 = 0.223659 loss)
I0810 13:16:42.396833 13394 sgd_solver.cpp:106] Iteration 2530, lr = 0.00844378
I0810 13:16:46.346460 13394 solver.cpp:228] Iteration 2540, loss = 0.314145
I0810 13:16:46.346511 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:16:46.346530 13394 solver.cpp:244]     Train net output #1: loss = 0.314144 (* 1 = 0.314144 loss)
I0810 13:16:46.346546 13394 sgd_solver.cpp:106] Iteration 2540, lr = 0.00843873
I0810 13:16:49.179868 13394 solver.cpp:228] Iteration 2550, loss = 0.189647
I0810 13:16:49.179924 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:16:49.179941 13394 solver.cpp:244]     Train net output #1: loss = 0.189646 (* 1 = 0.189646 loss)
I0810 13:16:49.179960 13394 sgd_solver.cpp:106] Iteration 2550, lr = 0.00843368
I0810 13:16:51.962836 13394 solver.cpp:228] Iteration 2560, loss = 0.0630494
I0810 13:16:51.962889 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:16:51.962908 13394 solver.cpp:244]     Train net output #1: loss = 0.0630494 (* 1 = 0.0630494 loss)
I0810 13:16:51.962926 13394 sgd_solver.cpp:106] Iteration 2560, lr = 0.00842864
I0810 13:16:53.494941 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:16:55.687990 13394 solver.cpp:228] Iteration 2570, loss = 0.0950936
I0810 13:16:55.688040 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:16:55.688055 13394 solver.cpp:244]     Train net output #1: loss = 0.0950935 (* 1 = 0.0950935 loss)
I0810 13:16:55.688076 13394 sgd_solver.cpp:106] Iteration 2570, lr = 0.00842362
I0810 13:16:58.880273 13394 solver.cpp:228] Iteration 2580, loss = 0.125639
I0810 13:16:58.880318 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:16:58.880434 13394 solver.cpp:244]     Train net output #1: loss = 0.125639 (* 1 = 0.125639 loss)
I0810 13:16:58.880506 13394 sgd_solver.cpp:106] Iteration 2580, lr = 0.00841859
I0810 13:17:00.831745 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:17:04.993407 13394 solver.cpp:228] Iteration 2590, loss = 0.221549
I0810 13:17:05.016361 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:17:05.016468 13394 solver.cpp:244]     Train net output #1: loss = 0.221548 (* 1 = 0.221548 loss)
I0810 13:17:05.016541 13394 sgd_solver.cpp:106] Iteration 2590, lr = 0.00841358
I0810 13:17:08.631033 13394 solver.cpp:337] Iteration 2600, Testing net (#0)
I0810 13:17:11.390041 13394 solver.cpp:404]     Test net output #0: accuracy = 0.682813
I0810 13:17:11.390164 13394 solver.cpp:404]     Test net output #1: loss = 1.12391 (* 1 = 1.12391 loss)
I0810 13:17:11.679803 13394 solver.cpp:228] Iteration 2600, loss = 0.219843
I0810 13:17:11.679855 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:17:11.679872 13394 solver.cpp:244]     Train net output #1: loss = 0.219843 (* 1 = 0.219843 loss)
I0810 13:17:11.679886 13394 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0810 13:17:11.729012 13403 blocking_queue.cpp:50] Waiting for data
I0810 13:17:14.656605 13394 solver.cpp:228] Iteration 2610, loss = 0.0940501
I0810 13:17:14.656702 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:17:14.656744 13394 solver.cpp:244]     Train net output #1: loss = 0.09405 (* 1 = 0.09405 loss)
I0810 13:17:14.656780 13394 sgd_solver.cpp:106] Iteration 2610, lr = 0.00840357
I0810 13:17:22.153045 13394 solver.cpp:228] Iteration 2620, loss = 0.156886
I0810 13:17:22.153090 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:17:22.153107 13394 solver.cpp:244]     Train net output #1: loss = 0.156886 (* 1 = 0.156886 loss)
I0810 13:17:22.153122 13394 sgd_solver.cpp:106] Iteration 2620, lr = 0.00839857
I0810 13:17:30.776183 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:17:35.365399 13394 solver.cpp:228] Iteration 2630, loss = 0.0942357
I0810 13:17:35.365494 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:17:35.365514 13394 solver.cpp:244]     Train net output #1: loss = 0.0942357 (* 1 = 0.0942357 loss)
I0810 13:17:35.365528 13394 sgd_solver.cpp:106] Iteration 2630, lr = 0.00839358
I0810 13:17:39.821378 13394 solver.cpp:228] Iteration 2640, loss = 0.345596
I0810 13:17:39.821434 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:17:39.821452 13394 solver.cpp:244]     Train net output #1: loss = 0.345596 (* 1 = 0.345596 loss)
I0810 13:17:39.821470 13394 sgd_solver.cpp:106] Iteration 2640, lr = 0.0083886
I0810 13:17:40.657658 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:17:42.654163 13394 solver.cpp:228] Iteration 2650, loss = 0.156493
I0810 13:17:42.654218 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:17:42.654238 13394 solver.cpp:244]     Train net output #1: loss = 0.156492 (* 1 = 0.156492 loss)
I0810 13:17:42.654348 13394 sgd_solver.cpp:106] Iteration 2650, lr = 0.00838363
I0810 13:17:45.474476 13394 solver.cpp:228] Iteration 2660, loss = 0.125092
I0810 13:17:45.474530 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:17:45.474560 13394 solver.cpp:244]     Train net output #1: loss = 0.125092 (* 1 = 0.125092 loss)
I0810 13:17:45.474575 13394 sgd_solver.cpp:106] Iteration 2660, lr = 0.00837866
I0810 13:17:48.248692 13394 solver.cpp:228] Iteration 2670, loss = 0.125262
I0810 13:17:48.248736 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:17:48.248751 13394 solver.cpp:244]     Train net output #1: loss = 0.125261 (* 1 = 0.125261 loss)
I0810 13:17:48.248765 13394 sgd_solver.cpp:106] Iteration 2670, lr = 0.0083737
I0810 13:17:51.055440 13394 solver.cpp:228] Iteration 2680, loss = 0.125824
I0810 13:17:51.055487 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:17:51.055503 13394 solver.cpp:244]     Train net output #1: loss = 0.125824 (* 1 = 0.125824 loss)
I0810 13:17:51.055518 13394 sgd_solver.cpp:106] Iteration 2680, lr = 0.00836875
I0810 13:17:55.627010 13394 solver.cpp:228] Iteration 2690, loss = 0.0938505
I0810 13:17:55.627055 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:17:55.627070 13394 solver.cpp:244]     Train net output #1: loss = 0.0938504 (* 1 = 0.0938504 loss)
I0810 13:17:55.627085 13394 sgd_solver.cpp:106] Iteration 2690, lr = 0.0083638
I0810 13:17:58.461668 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:18:00.661592 13394 solver.cpp:337] Iteration 2700, Testing net (#0)
I0810 13:18:02.441964 13394 solver.cpp:404]     Test net output #0: accuracy = 0.698438
I0810 13:18:02.442033 13394 solver.cpp:404]     Test net output #1: loss = 1.07565 (* 1 = 1.07565 loss)
I0810 13:18:02.726876 13394 solver.cpp:228] Iteration 2700, loss = 0.156831
I0810 13:18:02.726922 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:18:02.726938 13394 solver.cpp:244]     Train net output #1: loss = 0.156831 (* 1 = 0.156831 loss)
I0810 13:18:02.726951 13394 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0810 13:18:12.097510 13394 solver.cpp:228] Iteration 2710, loss = 0.346141
I0810 13:18:12.097656 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:18:12.097673 13394 solver.cpp:244]     Train net output #1: loss = 0.34614 (* 1 = 0.34614 loss)
I0810 13:18:12.097687 13394 sgd_solver.cpp:106] Iteration 2710, lr = 0.00835393
I0810 13:18:13.399392 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:18:18.471338 13394 solver.cpp:228] Iteration 2720, loss = 0.188615
I0810 13:18:18.471449 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:18:18.471494 13394 solver.cpp:244]     Train net output #1: loss = 0.188615 (* 1 = 0.188615 loss)
I0810 13:18:18.471531 13394 sgd_solver.cpp:106] Iteration 2720, lr = 0.008349
I0810 13:18:23.202054 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:18:23.645190 13394 solver.cpp:228] Iteration 2730, loss = 0.220506
I0810 13:18:23.645238 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:18:23.645257 13394 solver.cpp:244]     Train net output #1: loss = 0.220506 (* 1 = 0.220506 loss)
I0810 13:18:23.645273 13394 sgd_solver.cpp:106] Iteration 2730, lr = 0.00834408
I0810 13:18:29.369565 13394 solver.cpp:228] Iteration 2740, loss = 0.157707
I0810 13:18:29.369607 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:18:29.369622 13394 solver.cpp:244]     Train net output #1: loss = 0.157707 (* 1 = 0.157707 loss)
I0810 13:18:29.369635 13394 sgd_solver.cpp:106] Iteration 2740, lr = 0.00833917
I0810 13:18:32.883749 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:18:34.982185 13394 solver.cpp:228] Iteration 2750, loss = 0.125839
I0810 13:18:34.982231 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:18:34.982246 13394 solver.cpp:244]     Train net output #1: loss = 0.125839 (* 1 = 0.125839 loss)
I0810 13:18:34.982265 13394 sgd_solver.cpp:106] Iteration 2750, lr = 0.00833427
I0810 13:18:42.581194 13394 solver.cpp:228] Iteration 2760, loss = 0.220079
I0810 13:18:42.581306 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:18:42.581341 13394 solver.cpp:244]     Train net output #1: loss = 0.220079 (* 1 = 0.220079 loss)
I0810 13:18:42.581598 13394 sgd_solver.cpp:106] Iteration 2760, lr = 0.00832937
I0810 13:18:44.715801 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:18:48.355731 13394 solver.cpp:228] Iteration 2770, loss = 0.221098
I0810 13:18:48.355784 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:18:48.355803 13394 solver.cpp:244]     Train net output #1: loss = 0.221098 (* 1 = 0.221098 loss)
I0810 13:18:48.355819 13394 sgd_solver.cpp:106] Iteration 2770, lr = 0.00832447
I0810 13:18:51.212663 13394 solver.cpp:228] Iteration 2780, loss = 0.18784
I0810 13:18:51.212707 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:18:51.212723 13394 solver.cpp:244]     Train net output #1: loss = 0.18784 (* 1 = 0.18784 loss)
I0810 13:18:51.212739 13394 sgd_solver.cpp:106] Iteration 2780, lr = 0.00831959
I0810 13:18:54.006361 13394 solver.cpp:228] Iteration 2790, loss = 0.283455
I0810 13:18:54.006405 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:18:54.006423 13394 solver.cpp:244]     Train net output #1: loss = 0.283455 (* 1 = 0.283455 loss)
I0810 13:18:54.006443 13394 sgd_solver.cpp:106] Iteration 2790, lr = 0.00831471
I0810 13:18:57.063336 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:18:57.067831 13394 solver.cpp:337] Iteration 2800, Testing net (#0)
I0810 13:19:00.548108 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 13:19:00.548161 13394 solver.cpp:404]     Test net output #1: loss = 1.12203 (* 1 = 1.12203 loss)
I0810 13:19:00.849203 13394 solver.cpp:228] Iteration 2800, loss = 0.0625566
I0810 13:19:00.849248 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:19:00.849267 13394 solver.cpp:244]     Train net output #1: loss = 0.0625565 (* 1 = 0.0625565 loss)
I0810 13:19:00.849282 13394 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0810 13:19:04.834167 13394 solver.cpp:228] Iteration 2810, loss = 0.25054
I0810 13:19:04.834259 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:19:04.834301 13394 solver.cpp:244]     Train net output #1: loss = 0.25054 (* 1 = 0.25054 loss)
I0810 13:19:04.834338 13394 sgd_solver.cpp:106] Iteration 2810, lr = 0.00830497
I0810 13:19:07.099120 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:19:09.218013 13394 solver.cpp:228] Iteration 2820, loss = 0.156798
I0810 13:19:09.218055 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:19:09.218073 13394 solver.cpp:244]     Train net output #1: loss = 0.156798 (* 1 = 0.156798 loss)
I0810 13:19:09.218089 13394 sgd_solver.cpp:106] Iteration 2820, lr = 0.00830011
I0810 13:19:15.926005 13394 solver.cpp:228] Iteration 2830, loss = 0.0944678
I0810 13:19:15.926141 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:19:15.926158 13394 solver.cpp:244]     Train net output #1: loss = 0.0944677 (* 1 = 0.0944677 loss)
I0810 13:19:15.926173 13394 sgd_solver.cpp:106] Iteration 2830, lr = 0.00829526
I0810 13:19:17.382742 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:19:20.580662 13394 solver.cpp:228] Iteration 2840, loss = 0.284666
I0810 13:19:20.580706 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:19:20.580724 13394 solver.cpp:244]     Train net output #1: loss = 0.284666 (* 1 = 0.284666 loss)
I0810 13:19:20.580739 13394 sgd_solver.cpp:106] Iteration 2840, lr = 0.00829041
I0810 13:19:26.109174 13394 solver.cpp:228] Iteration 2850, loss = 0.282666
I0810 13:19:26.109228 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:19:26.109247 13394 solver.cpp:244]     Train net output #1: loss = 0.282666 (* 1 = 0.282666 loss)
I0810 13:19:26.109264 13394 sgd_solver.cpp:106] Iteration 2850, lr = 0.00828557
I0810 13:19:26.148912 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:19:30.090235 13394 solver.cpp:228] Iteration 2860, loss = 8.9407e-08
I0810 13:19:30.090279 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:19:30.090296 13394 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0810 13:19:30.090309 13394 sgd_solver.cpp:106] Iteration 2860, lr = 0.00828074
I0810 13:19:33.537811 13394 solver.cpp:228] Iteration 2870, loss = 0.187808
I0810 13:19:33.537860 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:19:33.537876 13394 solver.cpp:244]     Train net output #1: loss = 0.187808 (* 1 = 0.187808 loss)
I0810 13:19:33.537891 13394 sgd_solver.cpp:106] Iteration 2870, lr = 0.00827592
I0810 13:19:33.552001 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:19:37.166148 13394 solver.cpp:228] Iteration 2880, loss = 0.251832
I0810 13:19:37.166198 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:19:37.166215 13394 solver.cpp:244]     Train net output #1: loss = 0.251832 (* 1 = 0.251832 loss)
I0810 13:19:37.166301 13394 sgd_solver.cpp:106] Iteration 2880, lr = 0.0082711
I0810 13:19:40.448101 13394 solver.cpp:228] Iteration 2890, loss = 0.22047
I0810 13:19:40.448148 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:19:40.448166 13394 solver.cpp:244]     Train net output #1: loss = 0.22047 (* 1 = 0.22047 loss)
I0810 13:19:40.448181 13394 sgd_solver.cpp:106] Iteration 2890, lr = 0.00826628
I0810 13:19:43.006664 13394 solver.cpp:337] Iteration 2900, Testing net (#0)
I0810 13:19:44.476835 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:19:44.476949 13394 solver.cpp:404]     Test net output #1: loss = 1.10913 (* 1 = 1.10913 loss)
I0810 13:19:44.770123 13394 solver.cpp:228] Iteration 2900, loss = 0.188932
I0810 13:19:44.770172 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:19:44.770191 13394 solver.cpp:244]     Train net output #1: loss = 0.188932 (* 1 = 0.188932 loss)
I0810 13:19:44.770207 13394 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0810 13:19:47.591814 13394 solver.cpp:228] Iteration 2910, loss = 0.157624
I0810 13:19:47.591964 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:19:47.591982 13394 solver.cpp:244]     Train net output #1: loss = 0.157624 (* 1 = 0.157624 loss)
I0810 13:19:47.591997 13394 sgd_solver.cpp:106] Iteration 2910, lr = 0.00825668
I0810 13:19:50.403128 13394 solver.cpp:228] Iteration 2920, loss = 0.157087
I0810 13:19:50.403172 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:19:50.403187 13394 solver.cpp:244]     Train net output #1: loss = 0.157087 (* 1 = 0.157087 loss)
I0810 13:19:50.403199 13394 sgd_solver.cpp:106] Iteration 2920, lr = 0.00825188
I0810 13:19:53.195658 13394 solver.cpp:228] Iteration 2930, loss = 0.157465
I0810 13:19:53.195710 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:19:53.195729 13394 solver.cpp:244]     Train net output #1: loss = 0.157464 (* 1 = 0.157464 loss)
I0810 13:19:53.195745 13394 sgd_solver.cpp:106] Iteration 2930, lr = 0.0082471
I0810 13:19:54.220109 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:19:57.742202 13394 solver.cpp:228] Iteration 2940, loss = 0.0943282
I0810 13:19:57.742324 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:19:57.742367 13394 solver.cpp:244]     Train net output #1: loss = 0.094328 (* 1 = 0.094328 loss)
I0810 13:19:57.742403 13394 sgd_solver.cpp:106] Iteration 2940, lr = 0.00824232
I0810 13:20:02.497259 13394 solver.cpp:228] Iteration 2950, loss = 0.0629446
I0810 13:20:02.497308 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:20:02.497325 13394 solver.cpp:244]     Train net output #1: loss = 0.0629445 (* 1 = 0.0629445 loss)
I0810 13:20:02.497344 13394 sgd_solver.cpp:106] Iteration 2950, lr = 0.00823754
I0810 13:20:04.515519 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:20:09.176632 13394 solver.cpp:228] Iteration 2960, loss = 0.157562
I0810 13:20:09.176679 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:20:09.176698 13394 solver.cpp:244]     Train net output #1: loss = 0.157562 (* 1 = 0.157562 loss)
I0810 13:20:09.176717 13394 sgd_solver.cpp:106] Iteration 2960, lr = 0.00823278
I0810 13:20:13.142141 13394 solver.cpp:228] Iteration 2970, loss = 0.157158
I0810 13:20:13.142184 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:20:13.142202 13394 solver.cpp:244]     Train net output #1: loss = 0.157158 (* 1 = 0.157158 loss)
I0810 13:20:13.142217 13394 sgd_solver.cpp:106] Iteration 2970, lr = 0.00822801
I0810 13:20:13.333434 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:20:15.960559 13394 solver.cpp:228] Iteration 2980, loss = 0.15728
I0810 13:20:15.960603 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:20:15.960618 13394 solver.cpp:244]     Train net output #1: loss = 0.15728 (* 1 = 0.15728 loss)
I0810 13:20:15.960636 13394 sgd_solver.cpp:106] Iteration 2980, lr = 0.00822326
I0810 13:20:18.755195 13394 solver.cpp:228] Iteration 2990, loss = 0.031417
I0810 13:20:18.755350 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:20:18.755368 13394 solver.cpp:244]     Train net output #1: loss = 0.0314169 (* 1 = 0.0314169 loss)
I0810 13:20:18.755385 13394 sgd_solver.cpp:106] Iteration 2990, lr = 0.00821851
I0810 13:20:21.257436 13394 solver.cpp:337] Iteration 3000, Testing net (#0)
I0810 13:20:22.789216 13394 solver.cpp:404]     Test net output #0: accuracy = 0.69375
I0810 13:20:22.789273 13394 solver.cpp:404]     Test net output #1: loss = 1.08192 (* 1 = 1.08192 loss)
I0810 13:20:23.059525 13394 solver.cpp:228] Iteration 3000, loss = 0.15643
I0810 13:20:23.059571 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:20:23.059589 13394 solver.cpp:244]     Train net output #1: loss = 0.15643 (* 1 = 0.15643 loss)
I0810 13:20:23.059607 13394 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0810 13:20:29.596580 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:20:30.604137 13394 solver.cpp:228] Iteration 3010, loss = 0.219579
I0810 13:20:30.604182 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:20:30.604200 13394 solver.cpp:244]     Train net output #1: loss = 0.219579 (* 1 = 0.219579 loss)
I0810 13:20:30.604215 13394 sgd_solver.cpp:106] Iteration 3010, lr = 0.00820903
I0810 13:20:34.498350 13394 solver.cpp:228] Iteration 3020, loss = 0.189034
I0810 13:20:34.498404 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:20:34.498422 13394 solver.cpp:244]     Train net output #1: loss = 0.189034 (* 1 = 0.189034 loss)
I0810 13:20:34.498440 13394 sgd_solver.cpp:106] Iteration 3020, lr = 0.0082043
I0810 13:20:37.261147 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:20:37.903146 13394 solver.cpp:228] Iteration 3030, loss = 0.191148
I0810 13:20:37.903188 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:20:37.903206 13394 solver.cpp:244]     Train net output #1: loss = 0.191148 (* 1 = 0.191148 loss)
I0810 13:20:37.903221 13394 sgd_solver.cpp:106] Iteration 3030, lr = 0.00819958
I0810 13:20:40.727058 13394 solver.cpp:228] Iteration 3040, loss = 0.156956
I0810 13:20:40.727104 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:20:40.727119 13394 solver.cpp:244]     Train net output #1: loss = 0.156956 (* 1 = 0.156956 loss)
I0810 13:20:40.727133 13394 sgd_solver.cpp:106] Iteration 3040, lr = 0.00819486
I0810 13:20:43.571842 13394 solver.cpp:228] Iteration 3050, loss = 0.0638458
I0810 13:20:43.571888 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:20:43.571903 13394 solver.cpp:244]     Train net output #1: loss = 0.0638457 (* 1 = 0.0638457 loss)
I0810 13:20:43.571918 13394 sgd_solver.cpp:106] Iteration 3050, lr = 0.00819015
I0810 13:20:46.417826 13394 solver.cpp:228] Iteration 3060, loss = 0.0939871
I0810 13:20:46.417870 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:20:46.417884 13394 solver.cpp:244]     Train net output #1: loss = 0.093987 (* 1 = 0.093987 loss)
I0810 13:20:46.417897 13394 sgd_solver.cpp:106] Iteration 3060, lr = 0.00818545
I0810 13:20:49.233791 13394 solver.cpp:228] Iteration 3070, loss = 0.25082
I0810 13:20:49.233894 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:20:49.233909 13394 solver.cpp:244]     Train net output #1: loss = 0.25082 (* 1 = 0.25082 loss)
I0810 13:20:49.233923 13394 sgd_solver.cpp:106] Iteration 3070, lr = 0.00818075
I0810 13:20:52.884920 13394 solver.cpp:228] Iteration 3080, loss = 0.0941976
I0810 13:20:52.884984 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:20:52.885002 13394 solver.cpp:244]     Train net output #1: loss = 0.0941975 (* 1 = 0.0941975 loss)
I0810 13:20:52.885018 13394 sgd_solver.cpp:106] Iteration 3080, lr = 0.00817606
I0810 13:20:55.997202 13394 solver.cpp:228] Iteration 3090, loss = 0.062652
I0810 13:20:55.997246 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:20:55.997262 13394 solver.cpp:244]     Train net output #1: loss = 0.0626518 (* 1 = 0.0626518 loss)
I0810 13:20:55.997275 13394 sgd_solver.cpp:106] Iteration 3090, lr = 0.00817138
I0810 13:20:56.189787 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:20:58.615080 13394 solver.cpp:337] Iteration 3100, Testing net (#0)
I0810 13:21:00.910513 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 13:21:00.910574 13394 solver.cpp:404]     Test net output #1: loss = 1.09066 (* 1 = 1.09066 loss)
I0810 13:21:01.206332 13394 solver.cpp:228] Iteration 3100, loss = 0.0939003
I0810 13:21:01.206385 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:21:01.206403 13394 solver.cpp:244]     Train net output #1: loss = 0.0939002 (* 1 = 0.0939002 loss)
I0810 13:21:01.206419 13394 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0810 13:21:04.127704 13394 solver.cpp:228] Iteration 3110, loss = 0.062643
I0810 13:21:04.127753 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:21:04.127773 13394 solver.cpp:244]     Train net output #1: loss = 0.0626429 (* 1 = 0.0626429 loss)
I0810 13:21:04.127789 13394 sgd_solver.cpp:106] Iteration 3110, lr = 0.00816203
I0810 13:21:06.929648 13394 solver.cpp:228] Iteration 3120, loss = 0.28287
I0810 13:21:06.929694 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:21:06.929711 13394 solver.cpp:244]     Train net output #1: loss = 0.282869 (* 1 = 0.282869 loss)
I0810 13:21:06.929728 13394 sgd_solver.cpp:106] Iteration 3120, lr = 0.00815736
I0810 13:21:09.705427 13394 solver.cpp:228] Iteration 3130, loss = 0.125722
I0810 13:21:09.705597 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:21:09.705618 13394 solver.cpp:244]     Train net output #1: loss = 0.125721 (* 1 = 0.125721 loss)
I0810 13:21:09.705633 13394 sgd_solver.cpp:106] Iteration 3130, lr = 0.0081527
I0810 13:21:12.528796 13394 solver.cpp:228] Iteration 3140, loss = 0.314555
I0810 13:21:12.528838 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:21:12.528856 13394 solver.cpp:244]     Train net output #1: loss = 0.314555 (* 1 = 0.314555 loss)
I0810 13:21:12.528870 13394 sgd_solver.cpp:106] Iteration 3140, lr = 0.00814805
I0810 13:21:17.230506 13394 solver.cpp:228] Iteration 3150, loss = 0.21953
I0810 13:21:17.230552 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:21:17.230569 13394 solver.cpp:244]     Train net output #1: loss = 0.21953 (* 1 = 0.21953 loss)
I0810 13:21:17.230587 13394 sgd_solver.cpp:106] Iteration 3150, lr = 0.0081434
I0810 13:21:17.915479 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:21:30.149325 13394 solver.cpp:228] Iteration 3160, loss = 0.125791
I0810 13:21:30.149474 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:21:30.149493 13394 solver.cpp:244]     Train net output #1: loss = 0.125791 (* 1 = 0.125791 loss)
I0810 13:21:30.149508 13394 sgd_solver.cpp:106] Iteration 3160, lr = 0.00813876
I0810 13:21:34.450199 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:21:34.908849 13394 solver.cpp:228] Iteration 3170, loss = 0.219794
I0810 13:21:34.908893 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:21:34.908908 13394 solver.cpp:244]     Train net output #1: loss = 0.219794 (* 1 = 0.219794 loss)
I0810 13:21:34.908922 13394 sgd_solver.cpp:106] Iteration 3170, lr = 0.00813412
I0810 13:21:39.094338 13394 solver.cpp:228] Iteration 3180, loss = 0.253253
I0810 13:21:39.094395 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:21:39.094413 13394 solver.cpp:244]     Train net output #1: loss = 0.253253 (* 1 = 0.253253 loss)
I0810 13:21:39.094429 13394 sgd_solver.cpp:106] Iteration 3180, lr = 0.00812949
I0810 13:21:42.980262 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:21:43.481454 13394 solver.cpp:228] Iteration 3190, loss = 0.222041
I0810 13:21:43.481501 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:21:43.481516 13394 solver.cpp:244]     Train net output #1: loss = 0.222041 (* 1 = 0.222041 loss)
I0810 13:21:43.481531 13394 sgd_solver.cpp:106] Iteration 3190, lr = 0.00812487
I0810 13:21:47.771739 13394 solver.cpp:337] Iteration 3200, Testing net (#0)
I0810 13:21:50.331395 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 13:21:50.331454 13394 solver.cpp:404]     Test net output #1: loss = 1.09452 (* 1 = 1.09452 loss)
I0810 13:21:50.608490 13394 solver.cpp:228] Iteration 3200, loss = 0.125492
I0810 13:21:50.608546 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:21:50.608564 13394 solver.cpp:244]     Train net output #1: loss = 0.125492 (* 1 = 0.125492 loss)
I0810 13:21:50.608582 13394 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0810 13:21:52.783977 13403 blocking_queue.cpp:50] Waiting for data
I0810 13:21:53.638341 13394 solver.cpp:228] Iteration 3210, loss = 0.252017
I0810 13:21:53.638383 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:21:53.638398 13394 solver.cpp:244]     Train net output #1: loss = 0.252017 (* 1 = 0.252017 loss)
I0810 13:21:53.638417 13394 sgd_solver.cpp:106] Iteration 3210, lr = 0.00811564
I0810 13:21:58.017500 13394 solver.cpp:228] Iteration 3220, loss = 0.157362
I0810 13:21:58.017540 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:21:58.017559 13394 solver.cpp:244]     Train net output #1: loss = 0.157362 (* 1 = 0.157362 loss)
I0810 13:21:58.017573 13394 sgd_solver.cpp:106] Iteration 3220, lr = 0.00811104
I0810 13:22:02.371021 13394 solver.cpp:228] Iteration 3230, loss = 0.156605
I0810 13:22:02.371155 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:22:02.371176 13394 solver.cpp:244]     Train net output #1: loss = 0.156605 (* 1 = 0.156605 loss)
I0810 13:22:02.371192 13394 sgd_solver.cpp:106] Iteration 3230, lr = 0.00810644
I0810 13:22:04.342664 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:22:06.171710 13394 solver.cpp:228] Iteration 3240, loss = 0.15729
I0810 13:22:06.171757 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:22:06.171772 13394 solver.cpp:244]     Train net output #1: loss = 0.15729 (* 1 = 0.15729 loss)
I0810 13:22:06.171787 13394 sgd_solver.cpp:106] Iteration 3240, lr = 0.00810185
I0810 13:22:12.354533 13394 solver.cpp:228] Iteration 3250, loss = 0.219769
I0810 13:22:12.354583 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:22:12.354603 13394 solver.cpp:244]     Train net output #1: loss = 0.219768 (* 1 = 0.219768 loss)
I0810 13:22:12.354619 13394 sgd_solver.cpp:106] Iteration 3250, lr = 0.00809726
I0810 13:22:15.427739 13394 solver.cpp:228] Iteration 3260, loss = 0.282674
I0810 13:22:15.427786 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:22:15.427805 13394 solver.cpp:244]     Train net output #1: loss = 0.282674 (* 1 = 0.282674 loss)
I0810 13:22:15.427822 13394 sgd_solver.cpp:106] Iteration 3260, lr = 0.00809268
I0810 13:22:17.629389 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:22:19.906411 13394 solver.cpp:228] Iteration 3270, loss = 0.219118
I0810 13:22:19.906457 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:22:19.906476 13394 solver.cpp:244]     Train net output #1: loss = 0.219117 (* 1 = 0.219117 loss)
I0810 13:22:19.906493 13394 sgd_solver.cpp:106] Iteration 3270, lr = 0.00808811
I0810 13:22:24.800904 13394 solver.cpp:228] Iteration 3280, loss = 0.189277
I0810 13:22:24.801040 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:22:24.801077 13394 solver.cpp:244]     Train net output #1: loss = 0.189277 (* 1 = 0.189277 loss)
I0810 13:22:24.801108 13394 sgd_solver.cpp:106] Iteration 3280, lr = 0.00808354
I0810 13:22:26.255931 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:22:27.861057 13394 solver.cpp:228] Iteration 3290, loss = 0.188562
I0810 13:22:27.861104 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:22:27.861122 13394 solver.cpp:244]     Train net output #1: loss = 0.188562 (* 1 = 0.188562 loss)
I0810 13:22:27.861138 13394 sgd_solver.cpp:106] Iteration 3290, lr = 0.00807897
I0810 13:22:30.361752 13394 solver.cpp:337] Iteration 3300, Testing net (#0)
I0810 13:22:32.591493 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:22:32.591778 13394 solver.cpp:404]     Test net output #1: loss = 1.09186 (* 1 = 1.09186 loss)
I0810 13:22:32.886941 13394 solver.cpp:228] Iteration 3300, loss = 0.314568
I0810 13:22:32.886999 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:22:32.887015 13394 solver.cpp:244]     Train net output #1: loss = 0.314567 (* 1 = 0.314567 loss)
I0810 13:22:32.887030 13394 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0810 13:22:36.763659 13394 solver.cpp:228] Iteration 3310, loss = 0.219153
I0810 13:22:36.763725 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:22:36.763759 13394 solver.cpp:244]     Train net output #1: loss = 0.219153 (* 1 = 0.219153 loss)
I0810 13:22:36.763775 13394 sgd_solver.cpp:106] Iteration 3310, lr = 0.00806987
I0810 13:22:39.194545 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:22:39.887049 13394 solver.cpp:228] Iteration 3320, loss = 0.157316
I0810 13:22:39.887101 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:22:39.887120 13394 solver.cpp:244]     Train net output #1: loss = 0.157316 (* 1 = 0.157316 loss)
I0810 13:22:39.887135 13394 sgd_solver.cpp:106] Iteration 3320, lr = 0.00806532
I0810 13:22:43.540287 13394 solver.cpp:228] Iteration 3330, loss = 0.220171
I0810 13:22:43.540334 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:22:43.540354 13394 solver.cpp:244]     Train net output #1: loss = 0.220171 (* 1 = 0.220171 loss)
I0810 13:22:43.540367 13394 sgd_solver.cpp:106] Iteration 3330, lr = 0.00806079
I0810 13:22:46.315567 13394 solver.cpp:228] Iteration 3340, loss = 0.252511
I0810 13:22:46.315616 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:22:46.315634 13394 solver.cpp:244]     Train net output #1: loss = 0.252511 (* 1 = 0.252511 loss)
I0810 13:22:46.315650 13394 sgd_solver.cpp:106] Iteration 3340, lr = 0.00805625
I0810 13:22:49.187971 13394 solver.cpp:228] Iteration 3350, loss = 0.250816
I0810 13:22:49.188030 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:22:49.188047 13394 solver.cpp:244]     Train net output #1: loss = 0.250816 (* 1 = 0.250816 loss)
I0810 13:22:49.188061 13394 sgd_solver.cpp:106] Iteration 3350, lr = 0.00805173
I0810 13:22:52.034071 13394 solver.cpp:228] Iteration 3360, loss = 0.219308
I0810 13:22:52.034124 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:22:52.034142 13394 solver.cpp:244]     Train net output #1: loss = 0.219308 (* 1 = 0.219308 loss)
I0810 13:22:52.034159 13394 sgd_solver.cpp:106] Iteration 3360, lr = 0.00804721
I0810 13:22:54.801448 13394 solver.cpp:228] Iteration 3370, loss = 0.187589
I0810 13:22:54.801493 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:22:54.801512 13394 solver.cpp:244]     Train net output #1: loss = 0.187589 (* 1 = 0.187589 loss)
I0810 13:22:54.801527 13394 sgd_solver.cpp:106] Iteration 3370, lr = 0.00804269
I0810 13:22:57.666507 13394 solver.cpp:228] Iteration 3380, loss = 0.22045
I0810 13:22:57.666556 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:22:57.666575 13394 solver.cpp:244]     Train net output #1: loss = 0.22045 (* 1 = 0.22045 loss)
I0810 13:22:57.666591 13394 sgd_solver.cpp:106] Iteration 3380, lr = 0.00803818
I0810 13:23:00.473990 13394 solver.cpp:228] Iteration 3390, loss = 0.219147
I0810 13:23:00.474107 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:23:00.474148 13394 solver.cpp:244]     Train net output #1: loss = 0.219147 (* 1 = 0.219147 loss)
I0810 13:23:00.474167 13394 sgd_solver.cpp:106] Iteration 3390, lr = 0.00803368
I0810 13:23:03.134538 13394 solver.cpp:337] Iteration 3400, Testing net (#0)
I0810 13:23:04.170410 13403 blocking_queue.cpp:50] Waiting for data
I0810 13:23:04.984524 13394 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0810 13:23:04.984576 13394 solver.cpp:404]     Test net output #1: loss = 1.12484 (* 1 = 1.12484 loss)
I0810 13:23:05.276475 13394 solver.cpp:228] Iteration 3400, loss = 0.125944
I0810 13:23:05.276527 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:23:05.276664 13394 solver.cpp:244]     Train net output #1: loss = 0.125944 (* 1 = 0.125944 loss)
I0810 13:23:05.276732 13394 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0810 13:23:08.110994 13394 solver.cpp:228] Iteration 3410, loss = 0.251798
I0810 13:23:08.111042 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:23:08.111059 13394 solver.cpp:244]     Train net output #1: loss = 0.251798 (* 1 = 0.251798 loss)
I0810 13:23:08.111076 13394 sgd_solver.cpp:106] Iteration 3410, lr = 0.00802469
I0810 13:23:10.972714 13394 solver.cpp:228] Iteration 3420, loss = 0.125561
I0810 13:23:10.972770 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:23:10.972786 13394 solver.cpp:244]     Train net output #1: loss = 0.125561 (* 1 = 0.125561 loss)
I0810 13:23:10.972800 13394 sgd_solver.cpp:106] Iteration 3420, lr = 0.00802021
I0810 13:23:13.789533 13394 solver.cpp:228] Iteration 3430, loss = 0.251864
I0810 13:23:13.789584 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:23:13.789603 13394 solver.cpp:244]     Train net output #1: loss = 0.251864 (* 1 = 0.251864 loss)
I0810 13:23:13.789620 13394 sgd_solver.cpp:106] Iteration 3430, lr = 0.00801573
I0810 13:23:16.573220 13394 solver.cpp:228] Iteration 3440, loss = 0.219329
I0810 13:23:16.573269 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:23:16.573287 13394 solver.cpp:244]     Train net output #1: loss = 0.219329 (* 1 = 0.219329 loss)
I0810 13:23:16.573302 13394 sgd_solver.cpp:106] Iteration 3440, lr = 0.00801125
I0810 13:23:19.437320 13394 solver.cpp:228] Iteration 3450, loss = 0.156843
I0810 13:23:19.437369 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:23:19.437387 13394 solver.cpp:244]     Train net output #1: loss = 0.156843 (* 1 = 0.156843 loss)
I0810 13:23:19.437402 13394 sgd_solver.cpp:106] Iteration 3450, lr = 0.00800679
I0810 13:23:22.260334 13394 solver.cpp:228] Iteration 3460, loss = 0.0628247
I0810 13:23:22.260380 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:23:22.260397 13394 solver.cpp:244]     Train net output #1: loss = 0.0628245 (* 1 = 0.0628245 loss)
I0810 13:23:22.260416 13394 sgd_solver.cpp:106] Iteration 3460, lr = 0.00800232
I0810 13:23:25.086684 13394 solver.cpp:228] Iteration 3470, loss = 0.188313
I0810 13:23:25.086735 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:23:25.086753 13394 solver.cpp:244]     Train net output #1: loss = 0.188313 (* 1 = 0.188313 loss)
I0810 13:23:25.086771 13394 sgd_solver.cpp:106] Iteration 3470, lr = 0.00799787
I0810 13:23:27.901530 13394 solver.cpp:228] Iteration 3480, loss = 0.250642
I0810 13:23:27.901579 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:23:27.901599 13394 solver.cpp:244]     Train net output #1: loss = 0.250642 (* 1 = 0.250642 loss)
I0810 13:23:27.901615 13394 sgd_solver.cpp:106] Iteration 3480, lr = 0.00799342
I0810 13:23:30.693298 13394 solver.cpp:228] Iteration 3490, loss = 0.220113
I0810 13:23:30.693346 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:23:30.693363 13394 solver.cpp:244]     Train net output #1: loss = 0.220113 (* 1 = 0.220113 loss)
I0810 13:23:30.693379 13394 sgd_solver.cpp:106] Iteration 3490, lr = 0.00798897
I0810 13:23:33.277712 13394 solver.cpp:337] Iteration 3500, Testing net (#0)
I0810 13:23:34.828073 13394 solver.cpp:404]     Test net output #0: accuracy = 0.7
I0810 13:23:34.828196 13394 solver.cpp:404]     Test net output #1: loss = 1.04599 (* 1 = 1.04599 loss)
I0810 13:23:35.112689 13394 solver.cpp:228] Iteration 3500, loss = 0.250648
I0810 13:23:35.112792 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:23:35.112850 13394 solver.cpp:244]     Train net output #1: loss = 0.250648 (* 1 = 0.250648 loss)
I0810 13:23:35.112891 13394 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0810 13:23:37.954643 13394 solver.cpp:228] Iteration 3510, loss = 0.21888
I0810 13:23:37.954691 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:23:37.954708 13394 solver.cpp:244]     Train net output #1: loss = 0.21888 (* 1 = 0.21888 loss)
I0810 13:23:37.954725 13394 sgd_solver.cpp:106] Iteration 3510, lr = 0.0079801
I0810 13:23:40.799562 13394 solver.cpp:228] Iteration 3520, loss = 0.21893
I0810 13:23:40.799613 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:23:40.799628 13394 solver.cpp:244]     Train net output #1: loss = 0.21893 (* 1 = 0.21893 loss)
I0810 13:23:40.799643 13394 sgd_solver.cpp:106] Iteration 3520, lr = 0.00797568
I0810 13:23:43.609998 13394 solver.cpp:228] Iteration 3530, loss = 0.0948057
I0810 13:23:43.610049 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:23:43.610067 13394 solver.cpp:244]     Train net output #1: loss = 0.0948055 (* 1 = 0.0948055 loss)
I0810 13:23:43.610085 13394 sgd_solver.cpp:106] Iteration 3530, lr = 0.00797125
I0810 13:23:46.390091 13394 solver.cpp:228] Iteration 3540, loss = 0.0940338
I0810 13:23:46.390139 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:23:46.390158 13394 solver.cpp:244]     Train net output #1: loss = 0.0940336 (* 1 = 0.0940336 loss)
I0810 13:23:46.390173 13394 sgd_solver.cpp:106] Iteration 3540, lr = 0.00796684
I0810 13:23:49.231550 13394 solver.cpp:228] Iteration 3550, loss = 0.0946908
I0810 13:23:49.231595 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:23:49.231613 13394 solver.cpp:244]     Train net output #1: loss = 0.0946906 (* 1 = 0.0946906 loss)
I0810 13:23:49.231631 13394 sgd_solver.cpp:106] Iteration 3550, lr = 0.00796243
I0810 13:23:52.025341 13394 solver.cpp:228] Iteration 3560, loss = 0.0953828
I0810 13:23:52.025393 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:23:52.025410 13394 solver.cpp:244]     Train net output #1: loss = 0.0953826 (* 1 = 0.0953826 loss)
I0810 13:23:52.025427 13394 sgd_solver.cpp:106] Iteration 3560, lr = 0.00795802
I0810 13:23:54.857458 13394 solver.cpp:228] Iteration 3570, loss = 0.031298
I0810 13:23:54.857573 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:23:54.857614 13394 solver.cpp:244]     Train net output #1: loss = 0.0312978 (* 1 = 0.0312978 loss)
I0810 13:23:54.857650 13394 sgd_solver.cpp:106] Iteration 3570, lr = 0.00795363
I0810 13:23:57.641435 13394 solver.cpp:228] Iteration 3580, loss = 0.220024
I0810 13:23:57.641837 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:23:57.641969 13394 solver.cpp:244]     Train net output #1: loss = 0.220024 (* 1 = 0.220024 loss)
I0810 13:23:57.641984 13394 sgd_solver.cpp:106] Iteration 3580, lr = 0.00794923
I0810 13:24:00.443758 13394 solver.cpp:228] Iteration 3590, loss = 0.220092
I0810 13:24:00.443804 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:24:00.443823 13394 solver.cpp:244]     Train net output #1: loss = 0.220092 (* 1 = 0.220092 loss)
I0810 13:24:00.443840 13394 sgd_solver.cpp:106] Iteration 3590, lr = 0.00794484
I0810 13:24:03.004288 13394 solver.cpp:337] Iteration 3600, Testing net (#0)
I0810 13:24:04.553550 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:24:04.553702 13394 solver.cpp:404]     Test net output #1: loss = 1.09247 (* 1 = 1.09247 loss)
I0810 13:24:04.818265 13394 solver.cpp:228] Iteration 3600, loss = 0.187802
I0810 13:24:04.818312 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:24:04.818330 13394 solver.cpp:244]     Train net output #1: loss = 0.187802 (* 1 = 0.187802 loss)
I0810 13:24:04.818346 13394 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0810 13:24:07.619699 13394 solver.cpp:228] Iteration 3610, loss = 0.345929
I0810 13:24:07.619819 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:24:07.619853 13394 solver.cpp:244]     Train net output #1: loss = 0.345928 (* 1 = 0.345928 loss)
I0810 13:24:07.619884 13394 sgd_solver.cpp:106] Iteration 3610, lr = 0.00793609
I0810 13:24:10.471534 13394 solver.cpp:228] Iteration 3620, loss = 0.221401
I0810 13:24:10.471638 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:24:10.471684 13394 solver.cpp:244]     Train net output #1: loss = 0.2214 (* 1 = 0.2214 loss)
I0810 13:24:10.471721 13394 sgd_solver.cpp:106] Iteration 3620, lr = 0.00793172
I0810 13:24:13.252867 13394 solver.cpp:228] Iteration 3630, loss = 0.125296
I0810 13:24:13.252912 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:24:13.252929 13394 solver.cpp:244]     Train net output #1: loss = 0.125295 (* 1 = 0.125295 loss)
I0810 13:24:13.252946 13394 sgd_solver.cpp:106] Iteration 3630, lr = 0.00792735
I0810 13:24:16.067919 13394 solver.cpp:228] Iteration 3640, loss = 0.219527
I0810 13:24:16.067967 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:24:16.067986 13394 solver.cpp:244]     Train net output #1: loss = 0.219526 (* 1 = 0.219526 loss)
I0810 13:24:16.068001 13394 sgd_solver.cpp:106] Iteration 3640, lr = 0.00792299
I0810 13:24:18.858640 13394 solver.cpp:228] Iteration 3650, loss = 0.125192
I0810 13:24:18.858690 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:24:18.858708 13394 solver.cpp:244]     Train net output #1: loss = 0.125191 (* 1 = 0.125191 loss)
I0810 13:24:18.858724 13394 sgd_solver.cpp:106] Iteration 3650, lr = 0.00791864
I0810 13:24:21.637848 13394 solver.cpp:228] Iteration 3660, loss = 0.281327
I0810 13:24:21.638007 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:24:21.638027 13394 solver.cpp:244]     Train net output #1: loss = 0.281327 (* 1 = 0.281327 loss)
I0810 13:24:21.638042 13394 sgd_solver.cpp:106] Iteration 3660, lr = 0.00791429
I0810 13:24:24.462479 13394 solver.cpp:228] Iteration 3670, loss = 0.188844
I0810 13:24:24.462528 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:24:24.462548 13394 solver.cpp:244]     Train net output #1: loss = 0.188844 (* 1 = 0.188844 loss)
I0810 13:24:24.462565 13394 sgd_solver.cpp:106] Iteration 3670, lr = 0.00790995
I0810 13:24:27.250922 13394 solver.cpp:228] Iteration 3680, loss = 0.156905
I0810 13:24:27.250968 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:24:27.250986 13394 solver.cpp:244]     Train net output #1: loss = 0.156905 (* 1 = 0.156905 loss)
I0810 13:24:27.251004 13394 sgd_solver.cpp:106] Iteration 3680, lr = 0.00790561
I0810 13:24:29.999300 13394 solver.cpp:228] Iteration 3690, loss = 0.250505
I0810 13:24:29.999346 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:24:29.999362 13394 solver.cpp:244]     Train net output #1: loss = 0.250505 (* 1 = 0.250505 loss)
I0810 13:24:29.999378 13394 sgd_solver.cpp:106] Iteration 3690, lr = 0.00790128
I0810 13:24:32.538408 13394 solver.cpp:337] Iteration 3700, Testing net (#0)
I0810 13:24:34.078080 13394 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0810 13:24:34.078197 13394 solver.cpp:404]     Test net output #1: loss = 1.10714 (* 1 = 1.10714 loss)
I0810 13:24:34.351897 13394 solver.cpp:228] Iteration 3700, loss = 0.189113
I0810 13:24:34.351943 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:24:34.351960 13394 solver.cpp:244]     Train net output #1: loss = 0.189113 (* 1 = 0.189113 loss)
I0810 13:24:34.352010 13394 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0810 13:24:37.262804 13394 solver.cpp:228] Iteration 3710, loss = 0.345414
I0810 13:24:37.262926 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:24:37.262946 13394 solver.cpp:244]     Train net output #1: loss = 0.345414 (* 1 = 0.345414 loss)
I0810 13:24:37.262962 13394 sgd_solver.cpp:106] Iteration 3710, lr = 0.00789263
I0810 13:24:40.119256 13394 solver.cpp:228] Iteration 3720, loss = 0.314973
I0810 13:24:40.119313 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:24:40.119333 13394 solver.cpp:244]     Train net output #1: loss = 0.314973 (* 1 = 0.314973 loss)
I0810 13:24:40.119349 13394 sgd_solver.cpp:106] Iteration 3720, lr = 0.00788832
I0810 13:24:42.914816 13394 solver.cpp:228] Iteration 3730, loss = 0.157291
I0810 13:24:42.914924 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:24:42.914964 13394 solver.cpp:244]     Train net output #1: loss = 0.157291 (* 1 = 0.157291 loss)
I0810 13:24:42.914999 13394 sgd_solver.cpp:106] Iteration 3730, lr = 0.00788401
I0810 13:24:45.680874 13394 solver.cpp:228] Iteration 3740, loss = 0.126802
I0810 13:24:45.680922 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:24:45.680941 13394 solver.cpp:244]     Train net output #1: loss = 0.126801 (* 1 = 0.126801 loss)
I0810 13:24:45.680958 13394 sgd_solver.cpp:106] Iteration 3740, lr = 0.00787971
I0810 13:24:48.491632 13394 solver.cpp:228] Iteration 3750, loss = 0.251683
I0810 13:24:48.491749 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:24:48.491791 13394 solver.cpp:244]     Train net output #1: loss = 0.251683 (* 1 = 0.251683 loss)
I0810 13:24:48.491832 13394 sgd_solver.cpp:106] Iteration 3750, lr = 0.00787541
I0810 13:24:51.390915 13394 solver.cpp:228] Iteration 3760, loss = 0.284649
I0810 13:24:51.390974 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:24:51.390990 13394 solver.cpp:244]     Train net output #1: loss = 0.284649 (* 1 = 0.284649 loss)
I0810 13:24:51.391003 13394 sgd_solver.cpp:106] Iteration 3760, lr = 0.00787111
I0810 13:24:54.260963 13394 solver.cpp:228] Iteration 3770, loss = 0.126237
I0810 13:24:54.261075 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:24:54.261116 13394 solver.cpp:244]     Train net output #1: loss = 0.126237 (* 1 = 0.126237 loss)
I0810 13:24:54.261152 13394 sgd_solver.cpp:106] Iteration 3770, lr = 0.00786683
I0810 13:24:57.072403 13394 solver.cpp:228] Iteration 3780, loss = 0.219119
I0810 13:24:57.072502 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:24:57.072540 13394 solver.cpp:244]     Train net output #1: loss = 0.219119 (* 1 = 0.219119 loss)
I0810 13:24:57.072573 13394 sgd_solver.cpp:106] Iteration 3780, lr = 0.00786254
I0810 13:24:59.893076 13394 solver.cpp:228] Iteration 3790, loss = 0.314269
I0810 13:24:59.893358 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:24:59.893564 13394 solver.cpp:244]     Train net output #1: loss = 0.314269 (* 1 = 0.314269 loss)
I0810 13:24:59.893702 13394 sgd_solver.cpp:106] Iteration 3790, lr = 0.00785827
I0810 13:25:02.451313 13394 solver.cpp:337] Iteration 3800, Testing net (#0)
I0810 13:25:03.959658 13394 solver.cpp:404]     Test net output #0: accuracy = 0.692187
I0810 13:25:03.959707 13394 solver.cpp:404]     Test net output #1: loss = 1.06607 (* 1 = 1.06607 loss)
I0810 13:25:04.228801 13394 solver.cpp:228] Iteration 3800, loss = 0.18804
I0810 13:25:04.228844 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:25:04.228860 13394 solver.cpp:244]     Train net output #1: loss = 0.18804 (* 1 = 0.18804 loss)
I0810 13:25:04.228874 13394 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0810 13:25:07.006413 13394 solver.cpp:228] Iteration 3810, loss = 0.0628127
I0810 13:25:07.006460 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:25:07.006476 13394 solver.cpp:244]     Train net output #1: loss = 0.0628124 (* 1 = 0.0628124 loss)
I0810 13:25:07.006490 13394 sgd_solver.cpp:106] Iteration 3810, lr = 0.00784973
I0810 13:25:09.822707 13394 solver.cpp:228] Iteration 3820, loss = 0.0941364
I0810 13:25:09.822948 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:25:09.822968 13394 solver.cpp:244]     Train net output #1: loss = 0.0941361 (* 1 = 0.0941361 loss)
I0810 13:25:09.822983 13394 sgd_solver.cpp:106] Iteration 3820, lr = 0.00784547
I0810 13:25:12.558655 13394 solver.cpp:228] Iteration 3830, loss = 0.125847
I0810 13:25:12.558701 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:25:12.558717 13394 solver.cpp:244]     Train net output #1: loss = 0.125847 (* 1 = 0.125847 loss)
I0810 13:25:12.558733 13394 sgd_solver.cpp:106] Iteration 3830, lr = 0.00784121
I0810 13:25:24.794507 13394 solver.cpp:228] Iteration 3840, loss = 0.219038
I0810 13:25:24.794778 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:25:24.794950 13394 solver.cpp:244]     Train net output #1: loss = 0.219038 (* 1 = 0.219038 loss)
I0810 13:25:24.795085 13394 sgd_solver.cpp:106] Iteration 3840, lr = 0.00783696
I0810 13:25:28.413878 13394 solver.cpp:228] Iteration 3850, loss = 0.21942
I0810 13:25:28.413923 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:25:28.413941 13394 solver.cpp:244]     Train net output #1: loss = 0.21942 (* 1 = 0.21942 loss)
I0810 13:25:28.413955 13394 sgd_solver.cpp:106] Iteration 3850, lr = 0.00783272
I0810 13:25:31.314571 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:25:32.945839 13394 solver.cpp:228] Iteration 3860, loss = 0.0943756
I0810 13:25:32.945886 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:25:32.945904 13394 solver.cpp:244]     Train net output #1: loss = 0.0943753 (* 1 = 0.0943753 loss)
I0810 13:25:32.945919 13394 sgd_solver.cpp:106] Iteration 3860, lr = 0.00782848
I0810 13:25:35.697980 13394 solver.cpp:228] Iteration 3870, loss = 0.157036
I0810 13:25:35.698027 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:25:35.698045 13394 solver.cpp:244]     Train net output #1: loss = 0.157036 (* 1 = 0.157036 loss)
I0810 13:25:35.698061 13394 sgd_solver.cpp:106] Iteration 3870, lr = 0.00782425
I0810 13:25:38.472462 13394 solver.cpp:228] Iteration 3880, loss = 0.0943282
I0810 13:25:38.472571 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:25:38.472615 13394 solver.cpp:244]     Train net output #1: loss = 0.0943279 (* 1 = 0.0943279 loss)
I0810 13:25:38.472656 13394 sgd_solver.cpp:106] Iteration 3880, lr = 0.00782002
I0810 13:25:41.282253 13394 solver.cpp:228] Iteration 3890, loss = 0.344929
I0810 13:25:41.282413 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:25:41.282434 13394 solver.cpp:244]     Train net output #1: loss = 0.344929 (* 1 = 0.344929 loss)
I0810 13:25:41.282450 13394 sgd_solver.cpp:106] Iteration 3890, lr = 0.0078158
I0810 13:25:44.310063 13394 solver.cpp:337] Iteration 3900, Testing net (#0)
I0810 13:25:46.401787 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:25:46.402047 13394 solver.cpp:404]     Test net output #1: loss = 1.07061 (* 1 = 1.07061 loss)
I0810 13:25:46.692759 13394 solver.cpp:228] Iteration 3900, loss = 0.157214
I0810 13:25:46.692805 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:25:46.692822 13394 solver.cpp:244]     Train net output #1: loss = 0.157213 (* 1 = 0.157213 loss)
I0810 13:25:46.692837 13394 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0810 13:25:49.536260 13394 solver.cpp:228] Iteration 3910, loss = 0.127331
I0810 13:25:49.536301 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:25:49.536319 13394 solver.cpp:244]     Train net output #1: loss = 0.127331 (* 1 = 0.127331 loss)
I0810 13:25:49.536335 13394 sgd_solver.cpp:106] Iteration 3910, lr = 0.00780737
I0810 13:25:51.259836 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:25:54.541218 13394 solver.cpp:228] Iteration 3920, loss = 0.125805
I0810 13:25:54.541276 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:25:54.541293 13394 solver.cpp:244]     Train net output #1: loss = 0.125804 (* 1 = 0.125804 loss)
I0810 13:25:54.541308 13394 sgd_solver.cpp:106] Iteration 3920, lr = 0.00780316
I0810 13:25:58.873971 13394 solver.cpp:228] Iteration 3930, loss = 0.125605
I0810 13:25:58.874022 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:25:58.874040 13394 solver.cpp:244]     Train net output #1: loss = 0.125605 (* 1 = 0.125605 loss)
I0810 13:25:58.874056 13394 sgd_solver.cpp:106] Iteration 3930, lr = 0.00779896
I0810 13:26:01.796560 13394 solver.cpp:228] Iteration 3940, loss = 0.093952
I0810 13:26:01.796608 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:26:01.796627 13394 solver.cpp:244]     Train net output #1: loss = 0.0939517 (* 1 = 0.0939517 loss)
I0810 13:26:01.796641 13394 sgd_solver.cpp:106] Iteration 3940, lr = 0.00779476
I0810 13:26:04.599598 13394 solver.cpp:228] Iteration 3950, loss = 0.156405
I0810 13:26:04.599645 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:26:04.599663 13394 solver.cpp:244]     Train net output #1: loss = 0.156405 (* 1 = 0.156405 loss)
I0810 13:26:04.599678 13394 sgd_solver.cpp:106] Iteration 3950, lr = 0.00779057
I0810 13:26:07.371949 13394 solver.cpp:228] Iteration 3960, loss = 0.345656
I0810 13:26:07.371994 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:26:07.372012 13394 solver.cpp:244]     Train net output #1: loss = 0.345655 (* 1 = 0.345655 loss)
I0810 13:26:07.372028 13394 sgd_solver.cpp:106] Iteration 3960, lr = 0.00778639
I0810 13:26:10.215821 13394 solver.cpp:228] Iteration 3970, loss = 0.187554
I0810 13:26:10.215869 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:26:10.215888 13394 solver.cpp:244]     Train net output #1: loss = 0.187554 (* 1 = 0.187554 loss)
I0810 13:26:10.215906 13394 sgd_solver.cpp:106] Iteration 3970, lr = 0.00778221
I0810 13:26:13.038826 13394 solver.cpp:228] Iteration 3980, loss = 0.219993
I0810 13:26:13.038974 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:26:13.038993 13394 solver.cpp:244]     Train net output #1: loss = 0.219993 (* 1 = 0.219993 loss)
I0810 13:26:13.039011 13394 sgd_solver.cpp:106] Iteration 3980, lr = 0.00777803
I0810 13:26:15.936596 13394 solver.cpp:228] Iteration 3990, loss = 0.157465
I0810 13:26:15.936640 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:26:15.936660 13394 solver.cpp:244]     Train net output #1: loss = 0.157465 (* 1 = 0.157465 loss)
I0810 13:26:15.936674 13394 sgd_solver.cpp:106] Iteration 3990, lr = 0.00777386
I0810 13:26:18.504776 13394 solver.cpp:337] Iteration 4000, Testing net (#0)
I0810 13:26:20.001826 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 13:26:20.001935 13394 solver.cpp:404]     Test net output #1: loss = 1.09446 (* 1 = 1.09446 loss)
I0810 13:26:20.282423 13394 solver.cpp:228] Iteration 4000, loss = 0.125668
I0810 13:26:20.282469 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:26:20.282487 13394 solver.cpp:244]     Train net output #1: loss = 0.125668 (* 1 = 0.125668 loss)
I0810 13:26:20.282505 13394 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0810 13:26:23.159960 13394 solver.cpp:228] Iteration 4010, loss = 0.220094
I0810 13:26:23.160006 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:26:23.160025 13394 solver.cpp:244]     Train net output #1: loss = 0.220093 (* 1 = 0.220093 loss)
I0810 13:26:23.160042 13394 sgd_solver.cpp:106] Iteration 4010, lr = 0.00776554
I0810 13:26:25.964627 13394 solver.cpp:228] Iteration 4020, loss = 0.219431
I0810 13:26:25.964680 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:26:25.964699 13394 solver.cpp:244]     Train net output #1: loss = 0.219431 (* 1 = 0.219431 loss)
I0810 13:26:25.964715 13394 sgd_solver.cpp:106] Iteration 4020, lr = 0.00776138
I0810 13:26:30.851744 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:26:31.065577 13394 solver.cpp:228] Iteration 4030, loss = 0.188635
I0810 13:26:31.065636 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:26:31.065655 13394 solver.cpp:244]     Train net output #1: loss = 0.188635 (* 1 = 0.188635 loss)
I0810 13:26:31.065671 13394 sgd_solver.cpp:106] Iteration 4030, lr = 0.00775723
I0810 13:26:33.955694 13394 solver.cpp:228] Iteration 4040, loss = 0.28513
I0810 13:26:33.955739 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:26:33.955754 13394 solver.cpp:244]     Train net output #1: loss = 0.28513 (* 1 = 0.28513 loss)
I0810 13:26:33.955770 13394 sgd_solver.cpp:106] Iteration 4040, lr = 0.00775309
I0810 13:26:36.764430 13394 solver.cpp:228] Iteration 4050, loss = 0.0628186
I0810 13:26:36.764470 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:26:36.764485 13394 solver.cpp:244]     Train net output #1: loss = 0.0628183 (* 1 = 0.0628183 loss)
I0810 13:26:36.764498 13394 sgd_solver.cpp:106] Iteration 4050, lr = 0.00774895
I0810 13:26:39.567028 13394 solver.cpp:228] Iteration 4060, loss = 0.250762
I0810 13:26:39.567076 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:26:39.567091 13394 solver.cpp:244]     Train net output #1: loss = 0.250762 (* 1 = 0.250762 loss)
I0810 13:26:39.567106 13394 sgd_solver.cpp:106] Iteration 4060, lr = 0.00774481
I0810 13:26:42.602700 13394 solver.cpp:228] Iteration 4070, loss = 0.1574
I0810 13:26:42.602752 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:26:42.602772 13394 solver.cpp:244]     Train net output #1: loss = 0.1574 (* 1 = 0.1574 loss)
I0810 13:26:42.602790 13394 sgd_solver.cpp:106] Iteration 4070, lr = 0.00774069
I0810 13:26:45.399384 13394 solver.cpp:228] Iteration 4080, loss = 0.0951442
I0810 13:26:45.399510 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:26:45.399531 13394 solver.cpp:244]     Train net output #1: loss = 0.095144 (* 1 = 0.095144 loss)
I0810 13:26:45.399545 13394 sgd_solver.cpp:106] Iteration 4080, lr = 0.00773656
I0810 13:26:48.160151 13394 solver.cpp:228] Iteration 4090, loss = 0.281587
I0810 13:26:48.160198 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:26:48.160217 13394 solver.cpp:244]     Train net output #1: loss = 0.281587 (* 1 = 0.281587 loss)
I0810 13:26:48.160233 13394 sgd_solver.cpp:106] Iteration 4090, lr = 0.00773244
I0810 13:26:53.708554 13394 solver.cpp:337] Iteration 4100, Testing net (#0)
I0810 13:26:57.478430 13394 solver.cpp:404]     Test net output #0: accuracy = 0.696875
I0810 13:26:57.478485 13394 solver.cpp:404]     Test net output #1: loss = 1.04381 (* 1 = 1.04381 loss)
I0810 13:26:57.753885 13394 solver.cpp:228] Iteration 4100, loss = 0.282576
I0810 13:26:57.753998 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:26:57.754040 13394 solver.cpp:244]     Train net output #1: loss = 0.282575 (* 1 = 0.282575 loss)
I0810 13:26:57.754086 13394 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0810 13:27:00.578065 13394 solver.cpp:228] Iteration 4110, loss = 0.000294462
I0810 13:27:00.578114 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:27:00.578132 13394 solver.cpp:244]     Train net output #1: loss = 0.000294197 (* 1 = 0.000294197 loss)
I0810 13:27:00.578147 13394 sgd_solver.cpp:106] Iteration 4110, lr = 0.00772422
I0810 13:27:03.465317 13394 solver.cpp:228] Iteration 4120, loss = 0.18832
I0810 13:27:03.465373 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:27:03.465389 13394 solver.cpp:244]     Train net output #1: loss = 0.18832 (* 1 = 0.18832 loss)
I0810 13:27:03.465404 13394 sgd_solver.cpp:106] Iteration 4120, lr = 0.00772012
I0810 13:27:06.290549 13394 solver.cpp:228] Iteration 4130, loss = 0.251182
I0810 13:27:06.290598 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:27:06.290618 13394 solver.cpp:244]     Train net output #1: loss = 0.251181 (* 1 = 0.251181 loss)
I0810 13:27:06.290634 13394 sgd_solver.cpp:106] Iteration 4130, lr = 0.00771602
I0810 13:27:09.065874 13394 solver.cpp:228] Iteration 4140, loss = 0.21894
I0810 13:27:09.065928 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:27:09.065946 13394 solver.cpp:244]     Train net output #1: loss = 0.21894 (* 1 = 0.21894 loss)
I0810 13:27:09.065964 13394 sgd_solver.cpp:106] Iteration 4140, lr = 0.00771193
I0810 13:27:11.601166 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:27:11.829358 13394 solver.cpp:228] Iteration 4150, loss = 0.188126
I0810 13:27:11.829407 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:27:11.829424 13394 solver.cpp:244]     Train net output #1: loss = 0.188125 (* 1 = 0.188125 loss)
I0810 13:27:11.829440 13394 sgd_solver.cpp:106] Iteration 4150, lr = 0.00770784
I0810 13:27:14.605501 13394 solver.cpp:228] Iteration 4160, loss = 0.156974
I0810 13:27:14.605545 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:27:14.605562 13394 solver.cpp:244]     Train net output #1: loss = 0.156973 (* 1 = 0.156973 loss)
I0810 13:27:14.605578 13394 sgd_solver.cpp:106] Iteration 4160, lr = 0.00770376
I0810 13:27:19.549952 13401 blocking_queue.cpp:50] Waiting for data
I0810 13:27:19.776437 13394 solver.cpp:228] Iteration 4170, loss = 0.157152
I0810 13:27:19.776484 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:27:19.776502 13394 solver.cpp:244]     Train net output #1: loss = 0.157151 (* 1 = 0.157151 loss)
I0810 13:27:19.776517 13394 sgd_solver.cpp:106] Iteration 4170, lr = 0.00769968
I0810 13:27:22.593581 13394 solver.cpp:228] Iteration 4180, loss = 0.157245
I0810 13:27:22.593627 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:27:22.593647 13394 solver.cpp:244]     Train net output #1: loss = 0.157244 (* 1 = 0.157244 loss)
I0810 13:27:22.593662 13394 sgd_solver.cpp:106] Iteration 4180, lr = 0.00769561
I0810 13:27:25.367349 13394 solver.cpp:228] Iteration 4190, loss = 0.0950561
I0810 13:27:25.367398 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:27:25.367418 13394 solver.cpp:244]     Train net output #1: loss = 0.0950558 (* 1 = 0.0950558 loss)
I0810 13:27:25.367434 13394 sgd_solver.cpp:106] Iteration 4190, lr = 0.00769154
I0810 13:27:27.870726 13394 solver.cpp:337] Iteration 4200, Testing net (#0)
I0810 13:27:29.380496 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:27:29.380551 13394 solver.cpp:404]     Test net output #1: loss = 1.0593 (* 1 = 1.0593 loss)
I0810 13:27:29.701014 13394 solver.cpp:228] Iteration 4200, loss = 0.0626548
I0810 13:27:29.701061 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:27:29.701079 13394 solver.cpp:244]     Train net output #1: loss = 0.0626546 (* 1 = 0.0626546 loss)
I0810 13:27:29.701094 13394 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0810 13:27:32.471571 13394 solver.cpp:228] Iteration 4210, loss = 0.156359
I0810 13:27:32.471622 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:27:32.471640 13394 solver.cpp:244]     Train net output #1: loss = 0.156359 (* 1 = 0.156359 loss)
I0810 13:27:32.471657 13394 sgd_solver.cpp:106] Iteration 4210, lr = 0.00768342
I0810 13:27:35.236891 13394 solver.cpp:228] Iteration 4220, loss = 0.15731
I0810 13:27:35.236939 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:27:35.236958 13394 solver.cpp:244]     Train net output #1: loss = 0.15731 (* 1 = 0.15731 loss)
I0810 13:27:35.236971 13394 sgd_solver.cpp:106] Iteration 4220, lr = 0.00767937
I0810 13:27:37.983992 13394 solver.cpp:228] Iteration 4230, loss = 0.157153
I0810 13:27:37.984043 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:27:37.984061 13394 solver.cpp:244]     Train net output #1: loss = 0.157153 (* 1 = 0.157153 loss)
I0810 13:27:37.984077 13394 sgd_solver.cpp:106] Iteration 4230, lr = 0.00767532
I0810 13:27:40.743942 13394 solver.cpp:228] Iteration 4240, loss = 0.0318597
I0810 13:27:40.743995 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:27:40.744014 13394 solver.cpp:244]     Train net output #1: loss = 0.0318594 (* 1 = 0.0318594 loss)
I0810 13:27:40.744030 13394 sgd_solver.cpp:106] Iteration 4240, lr = 0.00767127
I0810 13:27:43.508291 13394 solver.cpp:228] Iteration 4250, loss = 0.15765
I0810 13:27:43.508337 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:27:43.508352 13394 solver.cpp:244]     Train net output #1: loss = 0.15765 (* 1 = 0.15765 loss)
I0810 13:27:43.508365 13394 sgd_solver.cpp:106] Iteration 4250, lr = 0.00766724
I0810 13:27:46.317203 13394 solver.cpp:228] Iteration 4260, loss = 0.224684
I0810 13:27:46.317252 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:27:46.317270 13394 solver.cpp:244]     Train net output #1: loss = 0.224684 (* 1 = 0.224684 loss)
I0810 13:27:46.317286 13394 sgd_solver.cpp:106] Iteration 4260, lr = 0.0076632
I0810 13:27:49.050961 13394 solver.cpp:228] Iteration 4270, loss = 0.188545
I0810 13:27:49.051008 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:27:49.051028 13394 solver.cpp:244]     Train net output #1: loss = 0.188545 (* 1 = 0.188545 loss)
I0810 13:27:49.051043 13394 sgd_solver.cpp:106] Iteration 4270, lr = 0.00765917
I0810 13:27:51.826236 13394 solver.cpp:228] Iteration 4280, loss = 0.189696
I0810 13:27:51.826377 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:27:51.826397 13394 solver.cpp:244]     Train net output #1: loss = 0.189696 (* 1 = 0.189696 loss)
I0810 13:27:51.826412 13394 sgd_solver.cpp:106] Iteration 4280, lr = 0.00765515
I0810 13:27:54.650693 13394 solver.cpp:228] Iteration 4290, loss = 0.159147
I0810 13:27:54.650739 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:27:54.650754 13394 solver.cpp:244]     Train net output #1: loss = 0.159146 (* 1 = 0.159146 loss)
I0810 13:27:54.650768 13394 sgd_solver.cpp:106] Iteration 4290, lr = 0.00765113
I0810 13:27:57.168498 13394 solver.cpp:337] Iteration 4300, Testing net (#0)
I0810 13:27:58.685016 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:27:58.685081 13394 solver.cpp:404]     Test net output #1: loss = 1.07532 (* 1 = 1.07532 loss)
I0810 13:27:58.960794 13394 solver.cpp:228] Iteration 4300, loss = 0.063111
I0810 13:27:58.960844 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:27:58.960862 13394 solver.cpp:244]     Train net output #1: loss = 0.0631107 (* 1 = 0.0631107 loss)
I0810 13:27:58.960878 13394 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0810 13:28:01.774873 13394 solver.cpp:228] Iteration 4310, loss = 0.0938723
I0810 13:28:01.774925 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:28:01.774946 13394 solver.cpp:244]     Train net output #1: loss = 0.0938721 (* 1 = 0.0938721 loss)
I0810 13:28:01.774962 13394 sgd_solver.cpp:106] Iteration 4310, lr = 0.00764311
I0810 13:28:04.542222 13394 solver.cpp:228] Iteration 4320, loss = 0.250206
I0810 13:28:04.542264 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:28:04.542280 13394 solver.cpp:244]     Train net output #1: loss = 0.250206 (* 1 = 0.250206 loss)
I0810 13:28:04.542294 13394 sgd_solver.cpp:106] Iteration 4320, lr = 0.00763911
I0810 13:28:07.292755 13394 solver.cpp:228] Iteration 4330, loss = 0.0945656
I0810 13:28:07.292804 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:28:07.292821 13394 solver.cpp:244]     Train net output #1: loss = 0.0945653 (* 1 = 0.0945653 loss)
I0810 13:28:07.292837 13394 sgd_solver.cpp:106] Iteration 4330, lr = 0.00763511
I0810 13:28:10.100333 13394 solver.cpp:228] Iteration 4340, loss = 0.0629176
I0810 13:28:10.100388 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:28:10.100406 13394 solver.cpp:244]     Train net output #1: loss = 0.0629173 (* 1 = 0.0629173 loss)
I0810 13:28:10.100421 13394 sgd_solver.cpp:106] Iteration 4340, lr = 0.00763112
I0810 13:28:12.874058 13394 solver.cpp:228] Iteration 4350, loss = 0.094269
I0810 13:28:12.874263 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:28:12.874310 13394 solver.cpp:244]     Train net output #1: loss = 0.0942688 (* 1 = 0.0942688 loss)
I0810 13:28:12.874327 13394 sgd_solver.cpp:106] Iteration 4350, lr = 0.00762713
I0810 13:28:15.652667 13394 solver.cpp:228] Iteration 4360, loss = 0.0625311
I0810 13:28:15.652714 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:28:15.652732 13394 solver.cpp:244]     Train net output #1: loss = 0.0625308 (* 1 = 0.0625308 loss)
I0810 13:28:15.652748 13394 sgd_solver.cpp:106] Iteration 4360, lr = 0.00762314
I0810 13:28:18.397491 13394 solver.cpp:228] Iteration 4370, loss = 0.282204
I0810 13:28:18.397608 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:28:18.397644 13394 solver.cpp:244]     Train net output #1: loss = 0.282203 (* 1 = 0.282203 loss)
I0810 13:28:18.397680 13394 sgd_solver.cpp:106] Iteration 4370, lr = 0.00761917
I0810 13:28:21.147269 13394 solver.cpp:228] Iteration 4380, loss = 0.125213
I0810 13:28:21.147323 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:28:21.147342 13394 solver.cpp:244]     Train net output #1: loss = 0.125212 (* 1 = 0.125212 loss)
I0810 13:28:21.147358 13394 sgd_solver.cpp:106] Iteration 4380, lr = 0.00761519
I0810 13:28:23.944922 13394 solver.cpp:228] Iteration 4390, loss = 0.313562
I0810 13:28:23.945094 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:28:23.945116 13394 solver.cpp:244]     Train net output #1: loss = 0.313562 (* 1 = 0.313562 loss)
I0810 13:28:23.945132 13394 sgd_solver.cpp:106] Iteration 4390, lr = 0.00761122
I0810 13:28:26.421962 13394 solver.cpp:337] Iteration 4400, Testing net (#0)
I0810 13:28:27.896682 13394 solver.cpp:404]     Test net output #0: accuracy = 0.695312
I0810 13:28:27.896739 13394 solver.cpp:404]     Test net output #1: loss = 1.04379 (* 1 = 1.04379 loss)
I0810 13:28:28.184268 13394 solver.cpp:228] Iteration 4400, loss = 0.220088
I0810 13:28:28.184320 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:28:28.184340 13394 solver.cpp:244]     Train net output #1: loss = 0.220088 (* 1 = 0.220088 loss)
I0810 13:28:28.184355 13394 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0810 13:28:30.944946 13394 solver.cpp:228] Iteration 4410, loss = 0.125542
I0810 13:28:30.944996 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:28:30.945014 13394 solver.cpp:244]     Train net output #1: loss = 0.125542 (* 1 = 0.125542 loss)
I0810 13:28:30.945030 13394 sgd_solver.cpp:106] Iteration 4410, lr = 0.0076033
I0810 13:28:33.705585 13394 solver.cpp:228] Iteration 4420, loss = 0.219628
I0810 13:28:33.705628 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:28:33.705646 13394 solver.cpp:244]     Train net output #1: loss = 0.219628 (* 1 = 0.219628 loss)
I0810 13:28:33.705660 13394 sgd_solver.cpp:106] Iteration 4420, lr = 0.00759934
I0810 13:28:36.453140 13394 solver.cpp:228] Iteration 4430, loss = 0.251541
I0810 13:28:36.453186 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:28:36.453204 13394 solver.cpp:244]     Train net output #1: loss = 0.251541 (* 1 = 0.251541 loss)
I0810 13:28:36.453220 13394 sgd_solver.cpp:106] Iteration 4430, lr = 0.00759539
I0810 13:28:39.218008 13394 solver.cpp:228] Iteration 4440, loss = 0.218967
I0810 13:28:39.218066 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:28:39.218083 13394 solver.cpp:244]     Train net output #1: loss = 0.218966 (* 1 = 0.218966 loss)
I0810 13:28:39.218098 13394 sgd_solver.cpp:106] Iteration 4440, lr = 0.00759145
I0810 13:28:42.025993 13394 solver.cpp:228] Iteration 4450, loss = 0.125643
I0810 13:28:42.026039 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:28:42.026054 13394 solver.cpp:244]     Train net output #1: loss = 0.125643 (* 1 = 0.125643 loss)
I0810 13:28:42.026067 13394 sgd_solver.cpp:106] Iteration 4450, lr = 0.00758751
I0810 13:28:44.785655 13394 solver.cpp:228] Iteration 4460, loss = 0.250597
I0810 13:28:44.785784 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:28:44.785807 13394 solver.cpp:244]     Train net output #1: loss = 0.250597 (* 1 = 0.250597 loss)
I0810 13:28:44.785823 13394 sgd_solver.cpp:106] Iteration 4460, lr = 0.00758357
I0810 13:28:47.523660 13394 solver.cpp:228] Iteration 4470, loss = 0.156437
I0810 13:28:47.523706 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:28:47.523723 13394 solver.cpp:244]     Train net output #1: loss = 0.156437 (* 1 = 0.156437 loss)
I0810 13:28:47.523739 13394 sgd_solver.cpp:106] Iteration 4470, lr = 0.00757964
I0810 13:28:50.276720 13394 solver.cpp:228] Iteration 4480, loss = 0.157522
I0810 13:28:50.276768 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:28:50.276787 13394 solver.cpp:244]     Train net output #1: loss = 0.157522 (* 1 = 0.157522 loss)
I0810 13:28:50.276803 13394 sgd_solver.cpp:106] Iteration 4480, lr = 0.00757571
I0810 13:28:53.030565 13394 solver.cpp:228] Iteration 4490, loss = 0.156325
I0810 13:28:53.030681 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:28:53.030725 13394 solver.cpp:244]     Train net output #1: loss = 0.156325 (* 1 = 0.156325 loss)
I0810 13:28:53.030772 13394 sgd_solver.cpp:106] Iteration 4490, lr = 0.00757179
I0810 13:28:55.513101 13394 solver.cpp:337] Iteration 4500, Testing net (#0)
I0810 13:28:56.999186 13394 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0810 13:28:56.999240 13394 solver.cpp:404]     Test net output #1: loss = 1.08861 (* 1 = 1.08861 loss)
I0810 13:28:57.272967 13394 solver.cpp:228] Iteration 4500, loss = 0.219932
I0810 13:28:57.273011 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:28:57.273027 13394 solver.cpp:244]     Train net output #1: loss = 0.219931 (* 1 = 0.219931 loss)
I0810 13:28:57.273041 13394 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0810 13:29:00.039005 13394 solver.cpp:228] Iteration 4510, loss = 0.282206
I0810 13:29:00.039054 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:29:00.039070 13394 solver.cpp:244]     Train net output #1: loss = 0.282206 (* 1 = 0.282206 loss)
I0810 13:29:00.039084 13394 sgd_solver.cpp:106] Iteration 4510, lr = 0.00756396
I0810 13:29:02.797317 13394 solver.cpp:228] Iteration 4520, loss = 0.219679
I0810 13:29:02.797363 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:29:02.797379 13394 solver.cpp:244]     Train net output #1: loss = 0.219679 (* 1 = 0.219679 loss)
I0810 13:29:02.797391 13394 sgd_solver.cpp:106] Iteration 4520, lr = 0.00756006
I0810 13:29:05.554921 13394 solver.cpp:228] Iteration 4530, loss = 0.188191
I0810 13:29:05.554965 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:29:05.554980 13394 solver.cpp:244]     Train net output #1: loss = 0.188191 (* 1 = 0.188191 loss)
I0810 13:29:05.554993 13394 sgd_solver.cpp:106] Iteration 4530, lr = 0.00755615
I0810 13:29:08.279155 13394 solver.cpp:228] Iteration 4540, loss = 0.188807
I0810 13:29:08.279198 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:29:08.279213 13394 solver.cpp:244]     Train net output #1: loss = 0.188807 (* 1 = 0.188807 loss)
I0810 13:29:08.279227 13394 sgd_solver.cpp:106] Iteration 4540, lr = 0.00755226
I0810 13:29:11.013005 13394 solver.cpp:228] Iteration 4550, loss = 0.314008
I0810 13:29:11.013051 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:29:11.013069 13394 solver.cpp:244]     Train net output #1: loss = 0.314007 (* 1 = 0.314007 loss)
I0810 13:29:11.013084 13394 sgd_solver.cpp:106] Iteration 4550, lr = 0.00754836
I0810 13:29:13.743374 13394 solver.cpp:228] Iteration 4560, loss = 0.219396
I0810 13:29:13.743420 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:29:13.743439 13394 solver.cpp:244]     Train net output #1: loss = 0.219396 (* 1 = 0.219396 loss)
I0810 13:29:13.743454 13394 sgd_solver.cpp:106] Iteration 4560, lr = 0.00754447
I0810 13:29:16.492406 13394 solver.cpp:228] Iteration 4570, loss = 0.157781
I0810 13:29:16.492506 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:29:16.492544 13394 solver.cpp:244]     Train net output #1: loss = 0.15778 (* 1 = 0.15778 loss)
I0810 13:29:16.492576 13394 sgd_solver.cpp:106] Iteration 4570, lr = 0.00754059
I0810 13:29:19.278486 13394 solver.cpp:228] Iteration 4580, loss = 0.219427
I0810 13:29:19.278538 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:29:19.278558 13394 solver.cpp:244]     Train net output #1: loss = 0.219426 (* 1 = 0.219426 loss)
I0810 13:29:19.278574 13394 sgd_solver.cpp:106] Iteration 4580, lr = 0.00753671
I0810 13:29:22.094771 13394 solver.cpp:228] Iteration 4590, loss = 0.252163
I0810 13:29:22.094825 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:29:22.094842 13394 solver.cpp:244]     Train net output #1: loss = 0.252162 (* 1 = 0.252162 loss)
I0810 13:29:22.094858 13394 sgd_solver.cpp:106] Iteration 4590, lr = 0.00753284
I0810 13:29:24.570775 13394 solver.cpp:337] Iteration 4600, Testing net (#0)
I0810 13:29:26.057668 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 13:29:26.057828 13394 solver.cpp:404]     Test net output #1: loss = 1.06191 (* 1 = 1.06191 loss)
I0810 13:29:26.333245 13394 solver.cpp:228] Iteration 4600, loss = 0.251934
I0810 13:29:26.333290 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:29:26.333308 13394 solver.cpp:244]     Train net output #1: loss = 0.251934 (* 1 = 0.251934 loss)
I0810 13:29:26.333324 13394 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0810 13:29:29.092536 13394 solver.cpp:228] Iteration 4610, loss = 0.219297
I0810 13:29:29.092584 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:29:29.092603 13394 solver.cpp:244]     Train net output #1: loss = 0.219296 (* 1 = 0.219296 loss)
I0810 13:29:29.092619 13394 sgd_solver.cpp:106] Iteration 4610, lr = 0.0075251
I0810 13:29:31.856590 13394 solver.cpp:228] Iteration 4620, loss = 0.188413
I0810 13:29:31.856634 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:29:31.856652 13394 solver.cpp:244]     Train net output #1: loss = 0.188413 (* 1 = 0.188413 loss)
I0810 13:29:31.856669 13394 sgd_solver.cpp:106] Iteration 4620, lr = 0.00752124
I0810 13:29:34.614656 13394 solver.cpp:228] Iteration 4630, loss = 0.220071
I0810 13:29:34.614701 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:29:34.614718 13394 solver.cpp:244]     Train net output #1: loss = 0.220071 (* 1 = 0.220071 loss)
I0810 13:29:34.614733 13394 sgd_solver.cpp:106] Iteration 4630, lr = 0.00751738
I0810 13:29:37.382800 13394 solver.cpp:228] Iteration 4640, loss = 0.219404
I0810 13:29:37.382851 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:29:37.382869 13394 solver.cpp:244]     Train net output #1: loss = 0.219404 (* 1 = 0.219404 loss)
I0810 13:29:37.382884 13394 sgd_solver.cpp:106] Iteration 4640, lr = 0.00751353
I0810 13:29:40.149694 13394 solver.cpp:228] Iteration 4650, loss = 0.125714
I0810 13:29:40.149740 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:29:40.149760 13394 solver.cpp:244]     Train net output #1: loss = 0.125713 (* 1 = 0.125713 loss)
I0810 13:29:40.149773 13394 sgd_solver.cpp:106] Iteration 4650, lr = 0.00750969
I0810 13:29:42.923619 13394 solver.cpp:228] Iteration 4660, loss = 0.25122
I0810 13:29:42.923668 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:29:42.923686 13394 solver.cpp:244]     Train net output #1: loss = 0.25122 (* 1 = 0.25122 loss)
I0810 13:29:42.923773 13394 sgd_solver.cpp:106] Iteration 4660, lr = 0.00750584
I0810 13:29:45.678977 13394 solver.cpp:228] Iteration 4670, loss = 0.125747
I0810 13:29:45.679023 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:29:45.679041 13394 solver.cpp:244]     Train net output #1: loss = 0.125746 (* 1 = 0.125746 loss)
I0810 13:29:45.679057 13394 sgd_solver.cpp:106] Iteration 4670, lr = 0.00750201
I0810 13:29:48.422761 13394 solver.cpp:228] Iteration 4680, loss = 0.251691
I0810 13:29:48.422811 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:29:48.422829 13394 solver.cpp:244]     Train net output #1: loss = 0.25169 (* 1 = 0.25169 loss)
I0810 13:29:48.422845 13394 sgd_solver.cpp:106] Iteration 4680, lr = 0.00749817
I0810 13:29:51.184936 13394 solver.cpp:228] Iteration 4690, loss = 0.21975
I0810 13:29:51.184983 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:29:51.185003 13394 solver.cpp:244]     Train net output #1: loss = 0.21975 (* 1 = 0.21975 loss)
I0810 13:29:51.185019 13394 sgd_solver.cpp:106] Iteration 4690, lr = 0.00749434
I0810 13:29:53.677165 13394 solver.cpp:337] Iteration 4700, Testing net (#0)
I0810 13:29:55.158073 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:29:55.158129 13394 solver.cpp:404]     Test net output #1: loss = 1.06296 (* 1 = 1.06296 loss)
I0810 13:29:55.439548 13394 solver.cpp:228] Iteration 4700, loss = 0.157046
I0810 13:29:55.439606 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:29:55.439623 13394 solver.cpp:244]     Train net output #1: loss = 0.157045 (* 1 = 0.157045 loss)
I0810 13:29:55.439692 13394 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0810 13:29:58.263757 13394 solver.cpp:228] Iteration 4710, loss = 0.062985
I0810 13:29:58.263898 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:29:58.263918 13394 solver.cpp:244]     Train net output #1: loss = 0.0629848 (* 1 = 0.0629848 loss)
I0810 13:29:58.263932 13394 sgd_solver.cpp:106] Iteration 4710, lr = 0.0074867
I0810 13:30:01.053539 13394 solver.cpp:228] Iteration 4720, loss = 0.188997
I0810 13:30:01.053586 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:30:01.053603 13394 solver.cpp:244]     Train net output #1: loss = 0.188997 (* 1 = 0.188997 loss)
I0810 13:30:01.053620 13394 sgd_solver.cpp:106] Iteration 4720, lr = 0.00748289
I0810 13:30:03.812085 13394 solver.cpp:228] Iteration 4730, loss = 0.2502
I0810 13:30:03.812176 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:30:03.812211 13394 solver.cpp:244]     Train net output #1: loss = 0.2502 (* 1 = 0.2502 loss)
I0810 13:30:03.812242 13394 sgd_solver.cpp:106] Iteration 4730, lr = 0.00747908
I0810 13:30:06.603823 13394 solver.cpp:228] Iteration 4740, loss = 0.219819
I0810 13:30:06.603873 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:30:06.603890 13394 solver.cpp:244]     Train net output #1: loss = 0.219819 (* 1 = 0.219819 loss)
I0810 13:30:06.603907 13394 sgd_solver.cpp:106] Iteration 4740, lr = 0.00747527
I0810 13:30:09.419183 13394 solver.cpp:228] Iteration 4750, loss = 0.252695
I0810 13:30:09.419244 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:30:09.419260 13394 solver.cpp:244]     Train net output #1: loss = 0.252695 (* 1 = 0.252695 loss)
I0810 13:30:09.419281 13394 sgd_solver.cpp:106] Iteration 4750, lr = 0.00747147
I0810 13:30:12.260325 13394 solver.cpp:228] Iteration 4760, loss = 0.220338
I0810 13:30:12.260427 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:30:12.260462 13394 solver.cpp:244]     Train net output #1: loss = 0.220338 (* 1 = 0.220338 loss)
I0810 13:30:12.260493 13394 sgd_solver.cpp:106] Iteration 4760, lr = 0.00746767
I0810 13:30:15.038118 13394 solver.cpp:228] Iteration 4770, loss = 0.219934
I0810 13:30:15.038162 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:30:15.038180 13394 solver.cpp:244]     Train net output #1: loss = 0.219934 (* 1 = 0.219934 loss)
I0810 13:30:15.038195 13394 sgd_solver.cpp:106] Iteration 4770, lr = 0.00746388
I0810 13:30:17.808681 13394 solver.cpp:228] Iteration 4780, loss = 0.0945198
I0810 13:30:17.808728 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:30:17.808746 13394 solver.cpp:244]     Train net output #1: loss = 0.0945196 (* 1 = 0.0945196 loss)
I0810 13:30:17.808761 13394 sgd_solver.cpp:106] Iteration 4780, lr = 0.00746009
I0810 13:30:20.603133 13394 solver.cpp:228] Iteration 4790, loss = 0.0944527
I0810 13:30:20.603183 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:30:20.603202 13394 solver.cpp:244]     Train net output #1: loss = 0.0944525 (* 1 = 0.0944525 loss)
I0810 13:30:20.603219 13394 sgd_solver.cpp:106] Iteration 4790, lr = 0.00745631
I0810 13:30:23.199329 13394 solver.cpp:337] Iteration 4800, Testing net (#0)
I0810 13:30:24.694524 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 13:30:24.694583 13394 solver.cpp:404]     Test net output #1: loss = 1.07791 (* 1 = 1.07791 loss)
I0810 13:30:24.969494 13394 solver.cpp:228] Iteration 4800, loss = 0.0938604
I0810 13:30:24.969544 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:30:24.969563 13394 solver.cpp:244]     Train net output #1: loss = 0.0938602 (* 1 = 0.0938602 loss)
I0810 13:30:24.969579 13394 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0810 13:30:27.762226 13394 solver.cpp:228] Iteration 4810, loss = 0.0938102
I0810 13:30:27.762275 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:30:27.762293 13394 solver.cpp:244]     Train net output #1: loss = 0.09381 (* 1 = 0.09381 loss)
I0810 13:30:27.762310 13394 sgd_solver.cpp:106] Iteration 4810, lr = 0.00744876
I0810 13:30:30.559810 13394 solver.cpp:228] Iteration 4820, loss = 0.0313156
I0810 13:30:30.559949 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:30:30.559968 13394 solver.cpp:244]     Train net output #1: loss = 0.0313153 (* 1 = 0.0313153 loss)
I0810 13:30:30.559983 13394 sgd_solver.cpp:106] Iteration 4820, lr = 0.00744499
I0810 13:30:33.321244 13394 solver.cpp:228] Iteration 4830, loss = 0.219218
I0810 13:30:33.321287 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:30:33.321305 13394 solver.cpp:244]     Train net output #1: loss = 0.219218 (* 1 = 0.219218 loss)
I0810 13:30:33.321321 13394 sgd_solver.cpp:106] Iteration 4830, lr = 0.00744122
I0810 13:30:36.144584 13394 solver.cpp:228] Iteration 4840, loss = 0.219349
I0810 13:30:36.144631 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:30:36.144650 13394 solver.cpp:244]     Train net output #1: loss = 0.219349 (* 1 = 0.219349 loss)
I0810 13:30:36.144666 13394 sgd_solver.cpp:106] Iteration 4840, lr = 0.00743746
I0810 13:30:38.965560 13394 solver.cpp:228] Iteration 4850, loss = 0.18812
I0810 13:30:38.965610 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:30:38.965629 13394 solver.cpp:244]     Train net output #1: loss = 0.18812 (* 1 = 0.18812 loss)
I0810 13:30:38.965646 13394 sgd_solver.cpp:106] Iteration 4850, lr = 0.0074337
I0810 13:30:41.752763 13394 solver.cpp:228] Iteration 4860, loss = 0.344456
I0810 13:30:41.752812 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:30:41.752831 13394 solver.cpp:244]     Train net output #1: loss = 0.344456 (* 1 = 0.344456 loss)
I0810 13:30:41.752849 13394 sgd_solver.cpp:106] Iteration 4860, lr = 0.00742995
I0810 13:30:44.529284 13394 solver.cpp:228] Iteration 4870, loss = 0.220608
I0810 13:30:44.529333 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:30:44.529352 13394 solver.cpp:244]     Train net output #1: loss = 0.220608 (* 1 = 0.220608 loss)
I0810 13:30:44.529367 13394 sgd_solver.cpp:106] Iteration 4870, lr = 0.0074262
I0810 13:30:47.284863 13394 solver.cpp:228] Iteration 4880, loss = 0.125564
I0810 13:30:47.284916 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:30:47.284935 13394 solver.cpp:244]     Train net output #1: loss = 0.125564 (* 1 = 0.125564 loss)
I0810 13:30:47.284950 13394 sgd_solver.cpp:106] Iteration 4880, lr = 0.00742246
I0810 13:30:50.070204 13394 solver.cpp:228] Iteration 4890, loss = 0.219518
I0810 13:30:50.070255 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:30:50.070273 13394 solver.cpp:244]     Train net output #1: loss = 0.219518 (* 1 = 0.219518 loss)
I0810 13:30:50.070289 13394 sgd_solver.cpp:106] Iteration 4890, lr = 0.00741872
I0810 13:30:52.563753 13394 solver.cpp:337] Iteration 4900, Testing net (#0)
I0810 13:30:54.076957 13394 solver.cpp:404]     Test net output #0: accuracy = 0.692187
I0810 13:30:54.077016 13394 solver.cpp:404]     Test net output #1: loss = 1.04932 (* 1 = 1.04932 loss)
I0810 13:30:54.355196 13394 solver.cpp:228] Iteration 4900, loss = 0.125639
I0810 13:30:54.355244 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:30:54.355262 13394 solver.cpp:244]     Train net output #1: loss = 0.125639 (* 1 = 0.125639 loss)
I0810 13:30:54.355291 13394 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0810 13:30:57.130251 13394 solver.cpp:228] Iteration 4910, loss = 0.281875
I0810 13:30:57.130358 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:30:57.130399 13394 solver.cpp:244]     Train net output #1: loss = 0.281874 (* 1 = 0.281874 loss)
I0810 13:30:57.130434 13394 sgd_solver.cpp:106] Iteration 4910, lr = 0.00741126
I0810 13:30:59.904933 13394 solver.cpp:228] Iteration 4920, loss = 0.188707
I0810 13:30:59.905052 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:30:59.905093 13394 solver.cpp:244]     Train net output #1: loss = 0.188706 (* 1 = 0.188706 loss)
I0810 13:30:59.905129 13394 sgd_solver.cpp:106] Iteration 4920, lr = 0.00740753
I0810 13:31:02.663642 13394 solver.cpp:228] Iteration 4930, loss = 0.15722
I0810 13:31:02.663779 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:31:02.663800 13394 solver.cpp:244]     Train net output #1: loss = 0.15722 (* 1 = 0.15722 loss)
I0810 13:31:02.663815 13394 sgd_solver.cpp:106] Iteration 4930, lr = 0.00740381
I0810 13:31:05.433723 13394 solver.cpp:228] Iteration 4940, loss = 0.251466
I0810 13:31:05.433773 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:31:05.433792 13394 solver.cpp:244]     Train net output #1: loss = 0.251466 (* 1 = 0.251466 loss)
I0810 13:31:05.433809 13394 sgd_solver.cpp:106] Iteration 4940, lr = 0.00740009
I0810 13:31:08.213665 13394 solver.cpp:228] Iteration 4950, loss = 0.188288
I0810 13:31:08.213776 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:31:08.213819 13394 solver.cpp:244]     Train net output #1: loss = 0.188288 (* 1 = 0.188288 loss)
I0810 13:31:08.213860 13394 sgd_solver.cpp:106] Iteration 4950, lr = 0.00739638
I0810 13:31:11.092991 13394 solver.cpp:228] Iteration 4960, loss = 0.344372
I0810 13:31:11.093042 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:31:11.093060 13394 solver.cpp:244]     Train net output #1: loss = 0.344372 (* 1 = 0.344372 loss)
I0810 13:31:11.093076 13394 sgd_solver.cpp:106] Iteration 4960, lr = 0.00739267
I0810 13:31:13.859074 13394 solver.cpp:228] Iteration 4970, loss = 0.313323
I0810 13:31:13.859196 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:31:13.859236 13394 solver.cpp:244]     Train net output #1: loss = 0.313323 (* 1 = 0.313323 loss)
I0810 13:31:13.859267 13394 sgd_solver.cpp:106] Iteration 4970, lr = 0.00738897
I0810 13:31:16.620599 13394 solver.cpp:228] Iteration 4980, loss = 0.156374
I0810 13:31:16.620645 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:31:16.620663 13394 solver.cpp:244]     Train net output #1: loss = 0.156374 (* 1 = 0.156374 loss)
I0810 13:31:16.620681 13394 sgd_solver.cpp:106] Iteration 4980, lr = 0.00738527
I0810 13:31:19.391844 13394 solver.cpp:228] Iteration 4990, loss = 0.125151
I0810 13:31:19.391896 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:31:19.391916 13394 solver.cpp:244]     Train net output #1: loss = 0.125151 (* 1 = 0.125151 loss)
I0810 13:31:19.391932 13394 sgd_solver.cpp:106] Iteration 4990, lr = 0.00738157
I0810 13:31:22.196087 13394 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_5000.caffemodel
I0810 13:31:23.261518 13394 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_5000.solverstate
I0810 13:31:23.268474 13394 solver.cpp:337] Iteration 5000, Testing net (#0)
I0810 13:31:24.775672 13394 solver.cpp:404]     Test net output #0: accuracy = 0.692187
I0810 13:31:24.775723 13394 solver.cpp:404]     Test net output #1: loss = 1.04512 (* 1 = 1.04512 loss)
I0810 13:31:25.039758 13394 solver.cpp:228] Iteration 5000, loss = 0.251714
I0810 13:31:25.039858 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:31:25.039899 13394 solver.cpp:244]     Train net output #1: loss = 0.251714 (* 1 = 0.251714 loss)
I0810 13:31:25.039942 13394 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0810 13:31:27.853257 13394 solver.cpp:228] Iteration 5010, loss = 0.283409
I0810 13:31:27.853310 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:31:27.853330 13394 solver.cpp:244]     Train net output #1: loss = 0.283409 (* 1 = 0.283409 loss)
I0810 13:31:27.853345 13394 sgd_solver.cpp:106] Iteration 5010, lr = 0.00737419
I0810 13:31:30.626924 13394 solver.cpp:228] Iteration 5020, loss = 0.125154
I0810 13:31:30.626976 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:31:30.626996 13394 solver.cpp:244]     Train net output #1: loss = 0.125153 (* 1 = 0.125153 loss)
I0810 13:31:30.627012 13394 sgd_solver.cpp:106] Iteration 5020, lr = 0.00737051
I0810 13:31:33.403802 13394 solver.cpp:228] Iteration 5030, loss = 0.219266
I0810 13:31:33.403941 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:31:33.403960 13394 solver.cpp:244]     Train net output #1: loss = 0.219266 (* 1 = 0.219266 loss)
I0810 13:31:33.403976 13394 sgd_solver.cpp:106] Iteration 5030, lr = 0.00736683
I0810 13:31:36.233443 13394 solver.cpp:228] Iteration 5040, loss = 0.313947
I0810 13:31:36.233489 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:31:36.233505 13394 solver.cpp:244]     Train net output #1: loss = 0.313947 (* 1 = 0.313947 loss)
I0810 13:31:36.233520 13394 sgd_solver.cpp:106] Iteration 5040, lr = 0.00736316
I0810 13:31:38.995008 13394 solver.cpp:228] Iteration 5050, loss = 0.18908
I0810 13:31:38.995056 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:31:38.995075 13394 solver.cpp:244]     Train net output #1: loss = 0.189079 (* 1 = 0.189079 loss)
I0810 13:31:38.995090 13394 sgd_solver.cpp:106] Iteration 5050, lr = 0.00735949
I0810 13:31:41.763319 13394 solver.cpp:228] Iteration 5060, loss = 0.0633518
I0810 13:31:41.763427 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:31:41.763469 13394 solver.cpp:244]     Train net output #1: loss = 0.0633516 (* 1 = 0.0633516 loss)
I0810 13:31:41.763486 13394 sgd_solver.cpp:106] Iteration 5060, lr = 0.00735582
I0810 13:31:44.536633 13394 solver.cpp:228] Iteration 5070, loss = 0.0938397
I0810 13:31:44.536681 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:31:44.536702 13394 solver.cpp:244]     Train net output #1: loss = 0.0938395 (* 1 = 0.0938395 loss)
I0810 13:31:44.536718 13394 sgd_solver.cpp:106] Iteration 5070, lr = 0.00735216
I0810 13:31:47.305224 13394 solver.cpp:228] Iteration 5080, loss = 0.125136
I0810 13:31:47.305480 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:31:47.305620 13394 solver.cpp:244]     Train net output #1: loss = 0.125136 (* 1 = 0.125136 loss)
I0810 13:31:47.305753 13394 sgd_solver.cpp:106] Iteration 5080, lr = 0.0073485
I0810 13:31:50.095710 13394 solver.cpp:228] Iteration 5090, loss = 0.219845
I0810 13:31:50.095810 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:31:50.095852 13394 solver.cpp:244]     Train net output #1: loss = 0.219845 (* 1 = 0.219845 loss)
I0810 13:31:50.095887 13394 sgd_solver.cpp:106] Iteration 5090, lr = 0.00734485
I0810 13:31:52.587483 13394 solver.cpp:337] Iteration 5100, Testing net (#0)
I0810 13:31:54.131685 13394 solver.cpp:404]     Test net output #0: accuracy = 0.682813
I0810 13:31:54.131732 13394 solver.cpp:404]     Test net output #1: loss = 1.0691 (* 1 = 1.0691 loss)
I0810 13:31:54.401051 13394 solver.cpp:228] Iteration 5100, loss = 0.219414
I0810 13:31:54.401093 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:31:54.401108 13394 solver.cpp:244]     Train net output #1: loss = 0.219414 (* 1 = 0.219414 loss)
I0810 13:31:54.401121 13394 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0810 13:31:57.165395 13394 solver.cpp:228] Iteration 5110, loss = 0.0942097
I0810 13:31:57.165439 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:31:57.165455 13394 solver.cpp:244]     Train net output #1: loss = 0.0942095 (* 1 = 0.0942095 loss)
I0810 13:31:57.165468 13394 sgd_solver.cpp:106] Iteration 5110, lr = 0.00733756
I0810 13:31:59.954509 13394 solver.cpp:228] Iteration 5120, loss = 0.156396
I0810 13:31:59.954558 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:31:59.954573 13394 solver.cpp:244]     Train net output #1: loss = 0.156395 (* 1 = 0.156395 loss)
I0810 13:31:59.954587 13394 sgd_solver.cpp:106] Iteration 5120, lr = 0.00733392
I0810 13:32:02.728543 13394 solver.cpp:228] Iteration 5130, loss = 0.0942801
I0810 13:32:02.728591 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:32:02.728607 13394 solver.cpp:244]     Train net output #1: loss = 0.0942798 (* 1 = 0.0942798 loss)
I0810 13:32:02.728621 13394 sgd_solver.cpp:106] Iteration 5130, lr = 0.00733028
I0810 13:32:05.494618 13394 solver.cpp:228] Iteration 5140, loss = 0.345135
I0810 13:32:05.494763 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:32:05.494783 13394 solver.cpp:244]     Train net output #1: loss = 0.345134 (* 1 = 0.345134 loss)
I0810 13:32:05.494798 13394 sgd_solver.cpp:106] Iteration 5140, lr = 0.00732665
I0810 13:32:08.247604 13394 solver.cpp:228] Iteration 5150, loss = 0.157112
I0810 13:32:08.247650 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:32:08.247668 13394 solver.cpp:244]     Train net output #1: loss = 0.157112 (* 1 = 0.157112 loss)
I0810 13:32:08.247683 13394 sgd_solver.cpp:106] Iteration 5150, lr = 0.00732303
I0810 13:32:11.017791 13394 solver.cpp:228] Iteration 5160, loss = 0.125401
I0810 13:32:11.017843 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:32:11.017864 13394 solver.cpp:244]     Train net output #1: loss = 0.125401 (* 1 = 0.125401 loss)
I0810 13:32:11.017879 13394 sgd_solver.cpp:106] Iteration 5160, lr = 0.0073194
I0810 13:32:13.803649 13394 solver.cpp:228] Iteration 5170, loss = 0.125694
I0810 13:32:13.803697 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:32:13.803716 13394 solver.cpp:244]     Train net output #1: loss = 0.125694 (* 1 = 0.125694 loss)
I0810 13:32:13.803731 13394 sgd_solver.cpp:106] Iteration 5170, lr = 0.00731578
I0810 13:32:16.577672 13394 solver.cpp:228] Iteration 5180, loss = 0.126152
I0810 13:32:16.577716 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:32:16.577733 13394 solver.cpp:244]     Train net output #1: loss = 0.126152 (* 1 = 0.126152 loss)
I0810 13:32:16.577749 13394 sgd_solver.cpp:106] Iteration 5180, lr = 0.00731217
I0810 13:32:19.328909 13394 solver.cpp:228] Iteration 5190, loss = 0.0944826
I0810 13:32:19.329010 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:32:19.329063 13394 solver.cpp:244]     Train net output #1: loss = 0.0944823 (* 1 = 0.0944823 loss)
I0810 13:32:19.329100 13394 sgd_solver.cpp:106] Iteration 5190, lr = 0.00730856
I0810 13:32:21.854389 13394 solver.cpp:337] Iteration 5200, Testing net (#0)
I0810 13:32:23.384994 13394 solver.cpp:404]     Test net output #0: accuracy = 0.698438
I0810 13:32:23.385047 13394 solver.cpp:404]     Test net output #1: loss = 1.02388 (* 1 = 1.02388 loss)
I0810 13:32:23.653689 13394 solver.cpp:228] Iteration 5200, loss = 0.156654
I0810 13:32:23.653736 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:32:23.653754 13394 solver.cpp:244]     Train net output #1: loss = 0.156654 (* 1 = 0.156654 loss)
I0810 13:32:23.653769 13394 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0810 13:32:26.406981 13394 solver.cpp:228] Iteration 5210, loss = 0.345021
I0810 13:32:26.407030 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:32:26.407049 13394 solver.cpp:244]     Train net output #1: loss = 0.345021 (* 1 = 0.345021 loss)
I0810 13:32:26.407066 13394 sgd_solver.cpp:106] Iteration 5210, lr = 0.00730135
I0810 13:32:29.209559 13394 solver.cpp:228] Iteration 5220, loss = 0.18885
I0810 13:32:29.209610 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:32:29.209630 13394 solver.cpp:244]     Train net output #1: loss = 0.18885 (* 1 = 0.18885 loss)
I0810 13:32:29.209645 13394 sgd_solver.cpp:106] Iteration 5220, lr = 0.00729775
I0810 13:32:31.993547 13394 solver.cpp:228] Iteration 5230, loss = 0.221652
I0810 13:32:31.993651 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:32:31.993692 13394 solver.cpp:244]     Train net output #1: loss = 0.221652 (* 1 = 0.221652 loss)
I0810 13:32:31.993732 13394 sgd_solver.cpp:106] Iteration 5230, lr = 0.00729416
I0810 13:32:34.763638 13394 solver.cpp:228] Iteration 5240, loss = 0.156404
I0810 13:32:34.763685 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:32:34.763702 13394 solver.cpp:244]     Train net output #1: loss = 0.156404 (* 1 = 0.156404 loss)
I0810 13:32:34.763716 13394 sgd_solver.cpp:106] Iteration 5240, lr = 0.00729057
I0810 13:32:37.529536 13394 solver.cpp:228] Iteration 5250, loss = 0.125422
I0810 13:32:37.529690 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:32:37.529708 13394 solver.cpp:244]     Train net output #1: loss = 0.125422 (* 1 = 0.125422 loss)
I0810 13:32:37.529723 13394 sgd_solver.cpp:106] Iteration 5250, lr = 0.00728698
I0810 13:32:40.295600 13394 solver.cpp:228] Iteration 5260, loss = 0.220098
I0810 13:32:40.295655 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:32:40.295673 13394 solver.cpp:244]     Train net output #1: loss = 0.220098 (* 1 = 0.220098 loss)
I0810 13:32:40.295691 13394 sgd_solver.cpp:106] Iteration 5260, lr = 0.0072834
I0810 13:32:43.122452 13394 solver.cpp:228] Iteration 5270, loss = 0.22004
I0810 13:32:43.122503 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:32:43.122521 13394 solver.cpp:244]     Train net output #1: loss = 0.220039 (* 1 = 0.220039 loss)
I0810 13:32:43.122537 13394 sgd_solver.cpp:106] Iteration 5270, lr = 0.00727982
I0810 13:32:45.890823 13394 solver.cpp:228] Iteration 5280, loss = 0.188706
I0810 13:32:45.890868 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:32:45.890887 13394 solver.cpp:244]     Train net output #1: loss = 0.188706 (* 1 = 0.188706 loss)
I0810 13:32:45.890902 13394 sgd_solver.cpp:106] Iteration 5280, lr = 0.00727625
I0810 13:32:48.668668 13394 solver.cpp:228] Iteration 5290, loss = 0.282143
I0810 13:32:48.668720 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:32:48.668736 13394 solver.cpp:244]     Train net output #1: loss = 0.282142 (* 1 = 0.282142 loss)
I0810 13:32:48.668750 13394 sgd_solver.cpp:106] Iteration 5290, lr = 0.00727268
I0810 13:32:51.231482 13394 solver.cpp:337] Iteration 5300, Testing net (#0)
I0810 13:32:52.763000 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 13:32:52.763048 13394 solver.cpp:404]     Test net output #1: loss = 1.06918 (* 1 = 1.06918 loss)
I0810 13:32:53.045984 13394 solver.cpp:228] Iteration 5300, loss = 0.0625568
I0810 13:32:53.046084 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:32:53.046125 13394 solver.cpp:244]     Train net output #1: loss = 0.0625566 (* 1 = 0.0625566 loss)
I0810 13:32:53.046165 13394 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0810 13:32:55.816691 13394 solver.cpp:228] Iteration 5310, loss = 0.25057
I0810 13:32:55.816740 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:32:55.816756 13394 solver.cpp:244]     Train net output #1: loss = 0.25057 (* 1 = 0.25057 loss)
I0810 13:32:55.816771 13394 sgd_solver.cpp:106] Iteration 5310, lr = 0.00726555
I0810 13:32:58.638654 13394 solver.cpp:228] Iteration 5320, loss = 0.15678
I0810 13:32:58.638705 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:32:58.638725 13394 solver.cpp:244]     Train net output #1: loss = 0.15678 (* 1 = 0.15678 loss)
I0810 13:32:58.638741 13394 sgd_solver.cpp:106] Iteration 5320, lr = 0.00726199
I0810 13:33:01.398365 13394 solver.cpp:228] Iteration 5330, loss = 0.0956596
I0810 13:33:01.398408 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:33:01.398425 13394 solver.cpp:244]     Train net output #1: loss = 0.0956593 (* 1 = 0.0956593 loss)
I0810 13:33:01.398440 13394 sgd_solver.cpp:106] Iteration 5330, lr = 0.00725844
I0810 13:33:04.102759 13394 solver.cpp:228] Iteration 5340, loss = 0.282234
I0810 13:33:04.103009 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:33:04.103162 13394 solver.cpp:244]     Train net output #1: loss = 0.282234 (* 1 = 0.282234 loss)
I0810 13:33:04.103302 13394 sgd_solver.cpp:106] Iteration 5340, lr = 0.00725489
I0810 13:33:06.842949 13394 solver.cpp:228] Iteration 5350, loss = 0.283222
I0810 13:33:06.842993 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:33:06.843008 13394 solver.cpp:244]     Train net output #1: loss = 0.283222 (* 1 = 0.283222 loss)
I0810 13:33:06.843021 13394 sgd_solver.cpp:106] Iteration 5350, lr = 0.00725135
I0810 13:33:09.610728 13394 solver.cpp:228] Iteration 5360, loss = 2.38419e-07
I0810 13:33:09.610898 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:33:09.610915 13394 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0810 13:33:09.610929 13394 sgd_solver.cpp:106] Iteration 5360, lr = 0.00724781
I0810 13:33:12.406528 13394 solver.cpp:228] Iteration 5370, loss = 0.187811
I0810 13:33:12.406577 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:33:12.406592 13394 solver.cpp:244]     Train net output #1: loss = 0.187811 (* 1 = 0.187811 loss)
I0810 13:33:12.406607 13394 sgd_solver.cpp:106] Iteration 5370, lr = 0.00724427
I0810 13:33:15.170492 13394 solver.cpp:228] Iteration 5380, loss = 0.250365
I0810 13:33:15.170536 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:33:15.170550 13394 solver.cpp:244]     Train net output #1: loss = 0.250365 (* 1 = 0.250365 loss)
I0810 13:33:15.170563 13394 sgd_solver.cpp:106] Iteration 5380, lr = 0.00724074
I0810 13:33:18.007498 13394 solver.cpp:228] Iteration 5390, loss = 0.220222
I0810 13:33:18.007539 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:33:18.007553 13394 solver.cpp:244]     Train net output #1: loss = 0.220222 (* 1 = 0.220222 loss)
I0810 13:33:18.007566 13394 sgd_solver.cpp:106] Iteration 5390, lr = 0.00723721
I0810 13:33:20.526093 13394 solver.cpp:337] Iteration 5400, Testing net (#0)
I0810 13:33:22.099834 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:33:22.099889 13394 solver.cpp:404]     Test net output #1: loss = 1.05431 (* 1 = 1.05431 loss)
I0810 13:33:22.366716 13394 solver.cpp:228] Iteration 5400, loss = 0.188048
I0810 13:33:22.366766 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:33:22.366785 13394 solver.cpp:244]     Train net output #1: loss = 0.188048 (* 1 = 0.188048 loss)
I0810 13:33:22.366801 13394 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0810 13:33:25.120821 13394 solver.cpp:228] Iteration 5410, loss = 0.157458
I0810 13:33:25.120869 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:33:25.120888 13394 solver.cpp:244]     Train net output #1: loss = 0.157458 (* 1 = 0.157458 loss)
I0810 13:33:25.120904 13394 sgd_solver.cpp:106] Iteration 5410, lr = 0.00723016
I0810 13:33:27.908025 13394 solver.cpp:228] Iteration 5420, loss = 0.156642
I0810 13:33:27.908076 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:33:27.908094 13394 solver.cpp:244]     Train net output #1: loss = 0.156642 (* 1 = 0.156642 loss)
I0810 13:33:27.908113 13394 sgd_solver.cpp:106] Iteration 5420, lr = 0.00722664
I0810 13:33:30.688163 13394 solver.cpp:228] Iteration 5430, loss = 0.156318
I0810 13:33:30.688210 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:33:30.688228 13394 solver.cpp:244]     Train net output #1: loss = 0.156318 (* 1 = 0.156318 loss)
I0810 13:33:30.688244 13394 sgd_solver.cpp:106] Iteration 5430, lr = 0.00722313
I0810 13:33:33.445467 13394 solver.cpp:228] Iteration 5440, loss = 0.0938387
I0810 13:33:33.445514 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:33:33.445533 13394 solver.cpp:244]     Train net output #1: loss = 0.0938385 (* 1 = 0.0938385 loss)
I0810 13:33:33.445547 13394 sgd_solver.cpp:106] Iteration 5440, lr = 0.00721962
I0810 13:33:36.193207 13394 solver.cpp:228] Iteration 5450, loss = 0.0627694
I0810 13:33:36.193254 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:33:36.193272 13394 solver.cpp:244]     Train net output #1: loss = 0.0627691 (* 1 = 0.0627691 loss)
I0810 13:33:36.193289 13394 sgd_solver.cpp:106] Iteration 5450, lr = 0.00721612
I0810 13:33:38.942419 13394 solver.cpp:228] Iteration 5460, loss = 0.156694
I0810 13:33:38.942467 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:33:38.942486 13394 solver.cpp:244]     Train net output #1: loss = 0.156694 (* 1 = 0.156694 loss)
I0810 13:33:38.942502 13394 sgd_solver.cpp:106] Iteration 5460, lr = 0.00721262
I0810 13:33:41.742842 13394 solver.cpp:228] Iteration 5470, loss = 0.156595
I0810 13:33:41.743078 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:33:41.743124 13394 solver.cpp:244]     Train net output #1: loss = 0.156595 (* 1 = 0.156595 loss)
I0810 13:33:41.743162 13394 sgd_solver.cpp:106] Iteration 5470, lr = 0.00720912
I0810 13:33:44.516202 13394 solver.cpp:228] Iteration 5480, loss = 0.156476
I0810 13:33:44.516250 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:33:44.516268 13394 solver.cpp:244]     Train net output #1: loss = 0.156476 (* 1 = 0.156476 loss)
I0810 13:33:44.516283 13394 sgd_solver.cpp:106] Iteration 5480, lr = 0.00720563
I0810 13:33:47.272538 13394 solver.cpp:228] Iteration 5490, loss = 0.0319997
I0810 13:33:47.272655 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:33:47.272694 13394 solver.cpp:244]     Train net output #1: loss = 0.0319995 (* 1 = 0.0319995 loss)
I0810 13:33:47.272712 13394 sgd_solver.cpp:106] Iteration 5490, lr = 0.00720214
I0810 13:33:49.747613 13394 solver.cpp:337] Iteration 5500, Testing net (#0)
I0810 13:33:51.278915 13394 solver.cpp:404]     Test net output #0: accuracy = 0.69375
I0810 13:33:51.278965 13394 solver.cpp:404]     Test net output #1: loss = 1.03133 (* 1 = 1.03133 loss)
I0810 13:33:51.546041 13394 solver.cpp:228] Iteration 5500, loss = 0.156407
I0810 13:33:51.546087 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:33:51.546105 13394 solver.cpp:244]     Train net output #1: loss = 0.156407 (* 1 = 0.156407 loss)
I0810 13:33:51.546120 13394 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0810 13:33:54.300828 13394 solver.cpp:228] Iteration 5510, loss = 0.221604
I0810 13:33:54.300873 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:33:54.300889 13394 solver.cpp:244]     Train net output #1: loss = 0.221603 (* 1 = 0.221603 loss)
I0810 13:33:54.300902 13394 sgd_solver.cpp:106] Iteration 5510, lr = 0.00719517
I0810 13:33:57.101881 13394 solver.cpp:228] Iteration 5520, loss = 0.188054
I0810 13:33:57.101927 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:33:57.101943 13394 solver.cpp:244]     Train net output #1: loss = 0.188053 (* 1 = 0.188053 loss)
I0810 13:33:57.101955 13394 sgd_solver.cpp:106] Iteration 5520, lr = 0.00719169
I0810 13:33:59.863358 13394 solver.cpp:228] Iteration 5530, loss = 0.187643
I0810 13:33:59.863402 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:33:59.863420 13394 solver.cpp:244]     Train net output #1: loss = 0.187642 (* 1 = 0.187642 loss)
I0810 13:33:59.863436 13394 sgd_solver.cpp:106] Iteration 5530, lr = 0.00718822
I0810 13:34:02.646034 13394 solver.cpp:228] Iteration 5540, loss = 0.15706
I0810 13:34:02.646081 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:34:02.646100 13394 solver.cpp:244]     Train net output #1: loss = 0.15706 (* 1 = 0.15706 loss)
I0810 13:34:02.646114 13394 sgd_solver.cpp:106] Iteration 5540, lr = 0.00718475
I0810 13:34:05.440260 13394 solver.cpp:228] Iteration 5550, loss = 0.062752
I0810 13:34:05.440305 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:34:05.440322 13394 solver.cpp:244]     Train net output #1: loss = 0.0627518 (* 1 = 0.0627518 loss)
I0810 13:34:05.440335 13394 sgd_solver.cpp:106] Iteration 5550, lr = 0.00718129
I0810 13:34:08.261551 13394 solver.cpp:228] Iteration 5560, loss = 0.0944935
I0810 13:34:08.261600 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:34:08.261618 13394 solver.cpp:244]     Train net output #1: loss = 0.0944933 (* 1 = 0.0944933 loss)
I0810 13:34:08.261634 13394 sgd_solver.cpp:106] Iteration 5560, lr = 0.00717782
I0810 13:34:11.025210 13394 solver.cpp:228] Iteration 5570, loss = 0.250315
I0810 13:34:11.025262 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:34:11.025280 13394 solver.cpp:244]     Train net output #1: loss = 0.250315 (* 1 = 0.250315 loss)
I0810 13:34:11.025296 13394 sgd_solver.cpp:106] Iteration 5570, lr = 0.00717437
I0810 13:34:13.812944 13394 solver.cpp:228] Iteration 5580, loss = 0.0939144
I0810 13:34:13.813091 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:34:13.813112 13394 solver.cpp:244]     Train net output #1: loss = 0.0939142 (* 1 = 0.0939142 loss)
I0810 13:34:13.813127 13394 sgd_solver.cpp:106] Iteration 5580, lr = 0.00717091
I0810 13:34:16.568094 13394 solver.cpp:228] Iteration 5590, loss = 0.0628987
I0810 13:34:16.568140 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:34:16.568159 13394 solver.cpp:244]     Train net output #1: loss = 0.0628985 (* 1 = 0.0628985 loss)
I0810 13:34:16.568176 13394 sgd_solver.cpp:106] Iteration 5590, lr = 0.00716746
I0810 13:34:19.061234 13394 solver.cpp:337] Iteration 5600, Testing net (#0)
I0810 13:34:20.589233 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 13:34:20.589282 13394 solver.cpp:404]     Test net output #1: loss = 1.04616 (* 1 = 1.04616 loss)
I0810 13:34:20.861582 13394 solver.cpp:228] Iteration 5600, loss = 0.094556
I0810 13:34:20.861632 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:34:20.861650 13394 solver.cpp:244]     Train net output #1: loss = 0.0945558 (* 1 = 0.0945558 loss)
I0810 13:34:20.861666 13394 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0810 13:34:23.672761 13394 solver.cpp:228] Iteration 5610, loss = 0.0626361
I0810 13:34:23.672806 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:34:23.672822 13394 solver.cpp:244]     Train net output #1: loss = 0.0626359 (* 1 = 0.0626359 loss)
I0810 13:34:23.672837 13394 sgd_solver.cpp:106] Iteration 5610, lr = 0.00716057
I0810 13:34:26.436954 13394 solver.cpp:228] Iteration 5620, loss = 0.282166
I0810 13:34:26.437062 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:34:26.437096 13394 solver.cpp:244]     Train net output #1: loss = 0.282166 (* 1 = 0.282166 loss)
I0810 13:34:26.437127 13394 sgd_solver.cpp:106] Iteration 5620, lr = 0.00715713
I0810 13:34:29.214202 13394 solver.cpp:228] Iteration 5630, loss = 0.125053
I0810 13:34:29.214254 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:34:29.214273 13394 solver.cpp:244]     Train net output #1: loss = 0.125053 (* 1 = 0.125053 loss)
I0810 13:34:29.214288 13394 sgd_solver.cpp:106] Iteration 5630, lr = 0.0071537
I0810 13:34:31.973633 13394 solver.cpp:228] Iteration 5640, loss = 0.313695
I0810 13:34:31.973736 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:34:31.973780 13394 solver.cpp:244]     Train net output #1: loss = 0.313694 (* 1 = 0.313694 loss)
I0810 13:34:31.973796 13394 sgd_solver.cpp:106] Iteration 5640, lr = 0.00715027
I0810 13:34:34.750560 13394 solver.cpp:228] Iteration 5650, loss = 0.220773
I0810 13:34:34.750614 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:34:34.750633 13394 solver.cpp:244]     Train net output #1: loss = 0.220773 (* 1 = 0.220773 loss)
I0810 13:34:34.750648 13394 sgd_solver.cpp:106] Iteration 5650, lr = 0.00714684
I0810 13:34:37.521961 13394 solver.cpp:228] Iteration 5660, loss = 0.125519
I0810 13:34:37.522011 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:34:37.522028 13394 solver.cpp:244]     Train net output #1: loss = 0.125519 (* 1 = 0.125519 loss)
I0810 13:34:37.522047 13394 sgd_solver.cpp:106] Iteration 5660, lr = 0.00714342
I0810 13:34:40.277288 13394 solver.cpp:228] Iteration 5670, loss = 0.219142
I0810 13:34:40.277403 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:34:40.277443 13394 solver.cpp:244]     Train net output #1: loss = 0.219142 (* 1 = 0.219142 loss)
I0810 13:34:40.277480 13394 sgd_solver.cpp:106] Iteration 5670, lr = 0.00714
I0810 13:34:43.106202 13394 solver.cpp:228] Iteration 5680, loss = 0.250823
I0810 13:34:43.106251 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:34:43.106268 13394 solver.cpp:244]     Train net output #1: loss = 0.250823 (* 1 = 0.250823 loss)
I0810 13:34:43.106284 13394 sgd_solver.cpp:106] Iteration 5680, lr = 0.00713659
I0810 13:34:45.862574 13394 solver.cpp:228] Iteration 5690, loss = 0.219327
I0810 13:34:45.862720 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:34:45.862740 13394 solver.cpp:244]     Train net output #1: loss = 0.219327 (* 1 = 0.219327 loss)
I0810 13:34:45.862754 13394 sgd_solver.cpp:106] Iteration 5690, lr = 0.00713317
I0810 13:34:48.361791 13394 solver.cpp:337] Iteration 5700, Testing net (#0)
I0810 13:34:49.881536 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 13:34:49.881589 13394 solver.cpp:404]     Test net output #1: loss = 1.04586 (* 1 = 1.04586 loss)
I0810 13:34:50.148727 13394 solver.cpp:228] Iteration 5700, loss = 0.125569
I0810 13:34:50.148775 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:34:50.148794 13394 solver.cpp:244]     Train net output #1: loss = 0.125569 (* 1 = 0.125569 loss)
I0810 13:34:50.148809 13394 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0810 13:34:52.922001 13394 solver.cpp:228] Iteration 5710, loss = 0.250781
I0810 13:34:52.922050 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:34:52.922070 13394 solver.cpp:244]     Train net output #1: loss = 0.25078 (* 1 = 0.25078 loss)
I0810 13:34:52.922086 13394 sgd_solver.cpp:106] Iteration 5710, lr = 0.00712636
I0810 13:34:55.722832 13394 solver.cpp:228] Iteration 5720, loss = 0.158466
I0810 13:34:55.722887 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:34:55.722904 13394 solver.cpp:244]     Train net output #1: loss = 0.158466 (* 1 = 0.158466 loss)
I0810 13:34:55.722920 13394 sgd_solver.cpp:106] Iteration 5720, lr = 0.00712296
I0810 13:34:58.484350 13394 solver.cpp:228] Iteration 5730, loss = 0.159048
I0810 13:34:58.484401 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:34:58.484421 13394 solver.cpp:244]     Train net output #1: loss = 0.159048 (* 1 = 0.159048 loss)
I0810 13:34:58.484438 13394 sgd_solver.cpp:106] Iteration 5730, lr = 0.00711956
I0810 13:35:01.250003 13394 solver.cpp:228] Iteration 5740, loss = 0.156829
I0810 13:35:01.250051 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:35:01.250069 13394 solver.cpp:244]     Train net output #1: loss = 0.156829 (* 1 = 0.156829 loss)
I0810 13:35:01.250084 13394 sgd_solver.cpp:106] Iteration 5740, lr = 0.00711617
I0810 13:35:04.003798 13394 solver.cpp:228] Iteration 5750, loss = 0.221171
I0810 13:35:04.003844 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:35:04.003864 13394 solver.cpp:244]     Train net output #1: loss = 0.221171 (* 1 = 0.221171 loss)
I0810 13:35:04.003878 13394 sgd_solver.cpp:106] Iteration 5750, lr = 0.00711278
I0810 13:35:06.744684 13394 solver.cpp:228] Iteration 5760, loss = 0.282402
I0810 13:35:06.744734 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:35:06.744751 13394 solver.cpp:244]     Train net output #1: loss = 0.282402 (* 1 = 0.282402 loss)
I0810 13:35:06.744770 13394 sgd_solver.cpp:106] Iteration 5760, lr = 0.0071094
I0810 13:35:09.524660 13394 solver.cpp:228] Iteration 5770, loss = 0.220462
I0810 13:35:09.524708 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:35:09.524726 13394 solver.cpp:244]     Train net output #1: loss = 0.220462 (* 1 = 0.220462 loss)
I0810 13:35:09.524741 13394 sgd_solver.cpp:106] Iteration 5770, lr = 0.00710602
I0810 13:35:12.288519 13394 solver.cpp:228] Iteration 5780, loss = 0.187787
I0810 13:35:12.288568 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:35:12.288586 13394 solver.cpp:244]     Train net output #1: loss = 0.187787 (* 1 = 0.187787 loss)
I0810 13:35:12.288602 13394 sgd_solver.cpp:106] Iteration 5780, lr = 0.00710264
I0810 13:35:15.037550 13394 solver.cpp:228] Iteration 5790, loss = 0.188335
I0810 13:35:15.037596 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:35:15.037614 13394 solver.cpp:244]     Train net output #1: loss = 0.188335 (* 1 = 0.188335 loss)
I0810 13:35:15.037629 13394 sgd_solver.cpp:106] Iteration 5790, lr = 0.00709927
I0810 13:35:17.526125 13394 solver.cpp:337] Iteration 5800, Testing net (#0)
I0810 13:35:19.036154 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:35:19.036267 13394 solver.cpp:404]     Test net output #1: loss = 1.04033 (* 1 = 1.04033 loss)
I0810 13:35:19.306033 13394 solver.cpp:228] Iteration 5800, loss = 0.314007
I0810 13:35:19.306078 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:35:19.306097 13394 solver.cpp:244]     Train net output #1: loss = 0.314007 (* 1 = 0.314007 loss)
I0810 13:35:19.306113 13394 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0810 13:35:22.103291 13394 solver.cpp:228] Iteration 5810, loss = 0.220519
I0810 13:35:22.103334 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:35:22.103351 13394 solver.cpp:244]     Train net output #1: loss = 0.220519 (* 1 = 0.220519 loss)
I0810 13:35:22.103368 13394 sgd_solver.cpp:106] Iteration 5810, lr = 0.00709253
I0810 13:35:24.855988 13394 solver.cpp:228] Iteration 5820, loss = 0.157301
I0810 13:35:24.856040 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:35:24.856057 13394 solver.cpp:244]     Train net output #1: loss = 0.1573 (* 1 = 0.1573 loss)
I0810 13:35:24.856076 13394 sgd_solver.cpp:106] Iteration 5820, lr = 0.00708917
I0810 13:35:27.625288 13394 solver.cpp:228] Iteration 5830, loss = 0.219316
I0810 13:35:27.625339 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:35:27.625358 13394 solver.cpp:244]     Train net output #1: loss = 0.219316 (* 1 = 0.219316 loss)
I0810 13:35:27.625375 13394 sgd_solver.cpp:106] Iteration 5830, lr = 0.00708581
I0810 13:35:30.392194 13394 solver.cpp:228] Iteration 5840, loss = 0.251218
I0810 13:35:30.392242 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:35:30.392261 13394 solver.cpp:244]     Train net output #1: loss = 0.251218 (* 1 = 0.251218 loss)
I0810 13:35:30.392277 13394 sgd_solver.cpp:106] Iteration 5840, lr = 0.00708245
I0810 13:35:33.140480 13394 solver.cpp:228] Iteration 5850, loss = 0.251077
I0810 13:35:33.140525 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:35:33.140544 13394 solver.cpp:244]     Train net output #1: loss = 0.251076 (* 1 = 0.251076 loss)
I0810 13:35:33.140558 13394 sgd_solver.cpp:106] Iteration 5850, lr = 0.0070791
I0810 13:35:35.892050 13394 solver.cpp:228] Iteration 5860, loss = 0.21986
I0810 13:35:35.892202 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:35:35.892240 13394 solver.cpp:244]     Train net output #1: loss = 0.21986 (* 1 = 0.21986 loss)
I0810 13:35:35.892253 13394 sgd_solver.cpp:106] Iteration 5860, lr = 0.00707575
I0810 13:35:38.672089 13394 solver.cpp:228] Iteration 5870, loss = 0.187899
I0810 13:35:38.672140 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:35:38.672159 13394 solver.cpp:244]     Train net output #1: loss = 0.187899 (* 1 = 0.187899 loss)
I0810 13:35:38.672175 13394 sgd_solver.cpp:106] Iteration 5870, lr = 0.00707241
I0810 13:35:41.519531 13394 solver.cpp:228] Iteration 5880, loss = 0.220513
I0810 13:35:41.519579 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:35:41.519595 13394 solver.cpp:244]     Train net output #1: loss = 0.220513 (* 1 = 0.220513 loss)
I0810 13:35:41.519609 13394 sgd_solver.cpp:106] Iteration 5880, lr = 0.00706907
I0810 13:35:44.371237 13394 solver.cpp:228] Iteration 5890, loss = 0.222013
I0810 13:35:44.371297 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:35:44.371316 13394 solver.cpp:244]     Train net output #1: loss = 0.222013 (* 1 = 0.222013 loss)
I0810 13:35:44.371330 13394 sgd_solver.cpp:106] Iteration 5890, lr = 0.00706573
I0810 13:35:46.849287 13394 solver.cpp:337] Iteration 5900, Testing net (#0)
I0810 13:35:48.361572 13394 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0810 13:35:48.361721 13394 solver.cpp:404]     Test net output #1: loss = 1.06666 (* 1 = 1.06666 loss)
I0810 13:35:48.631228 13394 solver.cpp:228] Iteration 5900, loss = 0.130274
I0810 13:35:48.631289 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:35:48.631309 13394 solver.cpp:244]     Train net output #1: loss = 0.130273 (* 1 = 0.130273 loss)
I0810 13:35:48.631323 13394 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0810 13:35:51.387714 13394 solver.cpp:228] Iteration 5910, loss = 0.255321
I0810 13:35:51.387759 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:35:51.387776 13394 solver.cpp:244]     Train net output #1: loss = 0.255321 (* 1 = 0.255321 loss)
I0810 13:35:51.387792 13394 sgd_solver.cpp:106] Iteration 5910, lr = 0.00705907
I0810 13:35:54.148905 13394 solver.cpp:228] Iteration 5920, loss = 0.125317
I0810 13:35:54.148954 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:35:54.148973 13394 solver.cpp:244]     Train net output #1: loss = 0.125317 (* 1 = 0.125317 loss)
I0810 13:35:54.148989 13394 sgd_solver.cpp:106] Iteration 5920, lr = 0.00705574
I0810 13:35:56.972005 13394 solver.cpp:228] Iteration 5930, loss = 0.250609
I0810 13:35:56.972062 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:35:56.972079 13394 solver.cpp:244]     Train net output #1: loss = 0.250609 (* 1 = 0.250609 loss)
I0810 13:35:56.972095 13394 sgd_solver.cpp:106] Iteration 5930, lr = 0.00705242
I0810 13:35:59.754381 13394 solver.cpp:228] Iteration 5940, loss = 0.219226
I0810 13:35:59.754523 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:35:59.754539 13394 solver.cpp:244]     Train net output #1: loss = 0.219226 (* 1 = 0.219226 loss)
I0810 13:35:59.754554 13394 sgd_solver.cpp:106] Iteration 5940, lr = 0.0070491
I0810 13:36:02.504146 13394 solver.cpp:228] Iteration 5950, loss = 0.156356
I0810 13:36:02.504191 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:36:02.504209 13394 solver.cpp:244]     Train net output #1: loss = 0.156356 (* 1 = 0.156356 loss)
I0810 13:36:02.504225 13394 sgd_solver.cpp:106] Iteration 5950, lr = 0.00704579
I0810 13:36:05.261358 13394 solver.cpp:228] Iteration 5960, loss = 0.0629017
I0810 13:36:05.261409 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:36:05.261428 13394 solver.cpp:244]     Train net output #1: loss = 0.0629016 (* 1 = 0.0629016 loss)
I0810 13:36:05.261445 13394 sgd_solver.cpp:106] Iteration 5960, lr = 0.00704248
I0810 13:36:08.024977 13394 solver.cpp:228] Iteration 5970, loss = 0.188046
I0810 13:36:08.025025 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:36:08.025043 13394 solver.cpp:244]     Train net output #1: loss = 0.188046 (* 1 = 0.188046 loss)
I0810 13:36:08.025058 13394 sgd_solver.cpp:106] Iteration 5970, lr = 0.00703917
I0810 13:36:10.781038 13394 solver.cpp:228] Iteration 5980, loss = 0.251545
I0810 13:36:10.781087 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:36:10.781105 13394 solver.cpp:244]     Train net output #1: loss = 0.251544 (* 1 = 0.251544 loss)
I0810 13:36:10.781122 13394 sgd_solver.cpp:106] Iteration 5980, lr = 0.00703586
I0810 13:36:13.541805 13394 solver.cpp:228] Iteration 5990, loss = 0.221005
I0810 13:36:13.541849 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:36:13.541868 13394 solver.cpp:244]     Train net output #1: loss = 0.221005 (* 1 = 0.221005 loss)
I0810 13:36:13.541883 13394 sgd_solver.cpp:106] Iteration 5990, lr = 0.00703256
I0810 13:36:16.010951 13394 solver.cpp:337] Iteration 6000, Testing net (#0)
I0810 13:36:17.516085 13394 solver.cpp:404]     Test net output #0: accuracy = 0.7
I0810 13:36:17.516142 13394 solver.cpp:404]     Test net output #1: loss = 0.999605 (* 1 = 0.999605 loss)
I0810 13:36:17.793298 13394 solver.cpp:228] Iteration 6000, loss = 0.251558
I0810 13:36:17.793344 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:36:17.793360 13394 solver.cpp:244]     Train net output #1: loss = 0.251557 (* 1 = 0.251557 loss)
I0810 13:36:17.793407 13394 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0810 13:36:20.556087 13394 solver.cpp:228] Iteration 6010, loss = 0.222481
I0810 13:36:20.556205 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:36:20.556221 13394 solver.cpp:244]     Train net output #1: loss = 0.222481 (* 1 = 0.222481 loss)
I0810 13:36:20.556234 13394 sgd_solver.cpp:106] Iteration 6010, lr = 0.00702597
I0810 13:36:23.369451 13394 solver.cpp:228] Iteration 6020, loss = 0.219117
I0810 13:36:23.369503 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:36:23.369520 13394 solver.cpp:244]     Train net output #1: loss = 0.219116 (* 1 = 0.219116 loss)
I0810 13:36:23.369537 13394 sgd_solver.cpp:106] Iteration 6020, lr = 0.00702268
I0810 13:36:26.182724 13394 solver.cpp:228] Iteration 6030, loss = 0.0949174
I0810 13:36:26.182778 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:36:26.182798 13394 solver.cpp:244]     Train net output #1: loss = 0.0949173 (* 1 = 0.0949173 loss)
I0810 13:36:26.182816 13394 sgd_solver.cpp:106] Iteration 6030, lr = 0.0070194
I0810 13:36:28.945379 13394 solver.cpp:228] Iteration 6040, loss = 0.0942465
I0810 13:36:28.945425 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:36:28.945442 13394 solver.cpp:244]     Train net output #1: loss = 0.0942464 (* 1 = 0.0942464 loss)
I0810 13:36:28.945457 13394 sgd_solver.cpp:106] Iteration 6040, lr = 0.00701612
I0810 13:36:31.689373 13394 solver.cpp:228] Iteration 6050, loss = 0.0943681
I0810 13:36:31.689416 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:36:31.689432 13394 solver.cpp:244]     Train net output #1: loss = 0.094368 (* 1 = 0.094368 loss)
I0810 13:36:31.689446 13394 sgd_solver.cpp:106] Iteration 6050, lr = 0.00701284
I0810 13:36:34.444095 13394 solver.cpp:228] Iteration 6060, loss = 0.0939375
I0810 13:36:34.444141 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:36:34.444157 13394 solver.cpp:244]     Train net output #1: loss = 0.0939374 (* 1 = 0.0939374 loss)
I0810 13:36:34.444176 13394 sgd_solver.cpp:106] Iteration 6060, lr = 0.00700956
I0810 13:36:37.216390 13394 solver.cpp:228] Iteration 6070, loss = 0.0314905
I0810 13:36:37.216435 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:36:37.216450 13394 solver.cpp:244]     Train net output #1: loss = 0.0314903 (* 1 = 0.0314903 loss)
I0810 13:36:37.216464 13394 sgd_solver.cpp:106] Iteration 6070, lr = 0.00700629
I0810 13:36:40.037104 13394 solver.cpp:228] Iteration 6080, loss = 0.21978
I0810 13:36:40.037251 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:36:40.037294 13394 solver.cpp:244]     Train net output #1: loss = 0.21978 (* 1 = 0.21978 loss)
I0810 13:36:40.037328 13394 sgd_solver.cpp:106] Iteration 6080, lr = 0.00700302
I0810 13:36:42.887686 13394 solver.cpp:228] Iteration 6090, loss = 0.219428
I0810 13:36:42.887729 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:36:42.887744 13394 solver.cpp:244]     Train net output #1: loss = 0.219428 (* 1 = 0.219428 loss)
I0810 13:36:42.887758 13394 sgd_solver.cpp:106] Iteration 6090, lr = 0.00699976
I0810 13:36:45.386726 13394 solver.cpp:337] Iteration 6100, Testing net (#0)
I0810 13:36:46.948807 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:36:46.948854 13394 solver.cpp:404]     Test net output #1: loss = 1.04387 (* 1 = 1.04387 loss)
I0810 13:36:47.215144 13394 solver.cpp:228] Iteration 6100, loss = 0.188143
I0810 13:36:47.215190 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:36:47.215207 13394 solver.cpp:244]     Train net output #1: loss = 0.188143 (* 1 = 0.188143 loss)
I0810 13:36:47.215224 13394 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0810 13:36:49.975934 13394 solver.cpp:228] Iteration 6110, loss = 0.344515
I0810 13:36:49.975982 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:36:49.975999 13394 solver.cpp:244]     Train net output #1: loss = 0.344515 (* 1 = 0.344515 loss)
I0810 13:36:49.976016 13394 sgd_solver.cpp:106] Iteration 6110, lr = 0.00699324
I0810 13:36:52.737253 13394 solver.cpp:228] Iteration 6120, loss = 0.218926
I0810 13:36:52.737402 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:36:52.737423 13394 solver.cpp:244]     Train net output #1: loss = 0.218925 (* 1 = 0.218925 loss)
I0810 13:36:52.737438 13394 sgd_solver.cpp:106] Iteration 6120, lr = 0.00698998
I0810 13:36:55.506213 13394 solver.cpp:228] Iteration 6130, loss = 0.126048
I0810 13:36:55.506260 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:36:55.506275 13394 solver.cpp:244]     Train net output #1: loss = 0.126048 (* 1 = 0.126048 loss)
I0810 13:36:55.506289 13394 sgd_solver.cpp:106] Iteration 6130, lr = 0.00698673
I0810 13:36:58.236819 13394 solver.cpp:228] Iteration 6140, loss = 0.218818
I0810 13:36:58.236862 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:36:58.236877 13394 solver.cpp:244]     Train net output #1: loss = 0.218818 (* 1 = 0.218818 loss)
I0810 13:36:58.236891 13394 sgd_solver.cpp:106] Iteration 6140, lr = 0.00698349
I0810 13:37:01.022008 13394 solver.cpp:228] Iteration 6150, loss = 0.125118
I0810 13:37:01.022064 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:37:01.022080 13394 solver.cpp:244]     Train net output #1: loss = 0.125118 (* 1 = 0.125118 loss)
I0810 13:37:01.022094 13394 sgd_solver.cpp:106] Iteration 6150, lr = 0.00698024
I0810 13:37:03.782147 13394 solver.cpp:228] Iteration 6160, loss = 0.282005
I0810 13:37:03.782192 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:37:03.782212 13394 solver.cpp:244]     Train net output #1: loss = 0.282005 (* 1 = 0.282005 loss)
I0810 13:37:03.782227 13394 sgd_solver.cpp:106] Iteration 6160, lr = 0.006977
I0810 13:37:06.572768 13394 solver.cpp:228] Iteration 6170, loss = 0.187787
I0810 13:37:06.572818 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:37:06.572836 13394 solver.cpp:244]     Train net output #1: loss = 0.187787 (* 1 = 0.187787 loss)
I0810 13:37:06.572852 13394 sgd_solver.cpp:106] Iteration 6170, lr = 0.00697377
I0810 13:37:09.345057 13394 solver.cpp:228] Iteration 6180, loss = 0.157396
I0810 13:37:09.345103 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:37:09.345120 13394 solver.cpp:244]     Train net output #1: loss = 0.157396 (* 1 = 0.157396 loss)
I0810 13:37:09.345135 13394 sgd_solver.cpp:106] Iteration 6180, lr = 0.00697053
I0810 13:37:12.103093 13394 solver.cpp:228] Iteration 6190, loss = 0.251251
I0810 13:37:12.103150 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:37:12.103168 13394 solver.cpp:244]     Train net output #1: loss = 0.251251 (* 1 = 0.251251 loss)
I0810 13:37:12.103183 13394 sgd_solver.cpp:106] Iteration 6190, lr = 0.00696731
I0810 13:37:14.597275 13394 solver.cpp:337] Iteration 6200, Testing net (#0)
I0810 13:37:16.121471 13394 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0810 13:37:16.121525 13394 solver.cpp:404]     Test net output #1: loss = 1.05604 (* 1 = 1.05604 loss)
I0810 13:37:16.390132 13394 solver.cpp:228] Iteration 6200, loss = 0.18801
I0810 13:37:16.390178 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:37:16.390197 13394 solver.cpp:244]     Train net output #1: loss = 0.18801 (* 1 = 0.18801 loss)
I0810 13:37:16.390213 13394 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0810 13:37:19.163429 13394 solver.cpp:228] Iteration 6210, loss = 0.346282
I0810 13:37:19.163476 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:37:19.163494 13394 solver.cpp:244]     Train net output #1: loss = 0.346282 (* 1 = 0.346282 loss)
I0810 13:37:19.163511 13394 sgd_solver.cpp:106] Iteration 6210, lr = 0.00696086
I0810 13:37:21.963641 13394 solver.cpp:228] Iteration 6220, loss = 0.313815
I0810 13:37:21.963701 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:37:21.963717 13394 solver.cpp:244]     Train net output #1: loss = 0.313815 (* 1 = 0.313815 loss)
I0810 13:37:21.963732 13394 sgd_solver.cpp:106] Iteration 6220, lr = 0.00695764
I0810 13:37:24.768414 13394 solver.cpp:228] Iteration 6230, loss = 0.157863
I0810 13:37:24.768559 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:37:24.768579 13394 solver.cpp:244]     Train net output #1: loss = 0.157863 (* 1 = 0.157863 loss)
I0810 13:37:24.768595 13394 sgd_solver.cpp:106] Iteration 6230, lr = 0.00695442
I0810 13:37:27.527897 13394 solver.cpp:228] Iteration 6240, loss = 0.125421
I0810 13:37:27.527945 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:37:27.527962 13394 solver.cpp:244]     Train net output #1: loss = 0.125421 (* 1 = 0.125421 loss)
I0810 13:37:27.527977 13394 sgd_solver.cpp:106] Iteration 6240, lr = 0.00695121
I0810 13:37:30.300983 13394 solver.cpp:228] Iteration 6250, loss = 0.253285
I0810 13:37:30.301033 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:37:30.301051 13394 solver.cpp:244]     Train net output #1: loss = 0.253285 (* 1 = 0.253285 loss)
I0810 13:37:30.301069 13394 sgd_solver.cpp:106] Iteration 6250, lr = 0.006948
I0810 13:37:33.074890 13394 solver.cpp:228] Iteration 6260, loss = 0.282254
I0810 13:37:33.074942 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:37:33.074961 13394 solver.cpp:244]     Train net output #1: loss = 0.282254 (* 1 = 0.282254 loss)
I0810 13:37:33.074978 13394 sgd_solver.cpp:106] Iteration 6260, lr = 0.0069448
I0810 13:37:35.838201 13394 solver.cpp:228] Iteration 6270, loss = 0.125178
I0810 13:37:35.838250 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:37:35.838269 13394 solver.cpp:244]     Train net output #1: loss = 0.125178 (* 1 = 0.125178 loss)
I0810 13:37:35.838285 13394 sgd_solver.cpp:106] Iteration 6270, lr = 0.0069416
I0810 13:37:38.618820 13394 solver.cpp:228] Iteration 6280, loss = 0.218827
I0810 13:37:38.618943 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:37:38.618979 13394 solver.cpp:244]     Train net output #1: loss = 0.218826 (* 1 = 0.218826 loss)
I0810 13:37:38.618993 13394 sgd_solver.cpp:106] Iteration 6280, lr = 0.0069384
I0810 13:37:41.358883 13394 solver.cpp:228] Iteration 6290, loss = 0.312978
I0810 13:37:41.358930 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:37:41.358948 13394 solver.cpp:244]     Train net output #1: loss = 0.312978 (* 1 = 0.312978 loss)
I0810 13:37:41.358963 13394 sgd_solver.cpp:106] Iteration 6290, lr = 0.0069352
I0810 13:37:43.851681 13394 solver.cpp:337] Iteration 6300, Testing net (#0)
I0810 13:37:45.358270 13394 solver.cpp:404]     Test net output #0: accuracy = 0.692187
I0810 13:37:45.358320 13394 solver.cpp:404]     Test net output #1: loss = 1.02285 (* 1 = 1.02285 loss)
I0810 13:37:45.622752 13394 solver.cpp:228] Iteration 6300, loss = 0.188323
I0810 13:37:45.622798 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:37:45.622817 13394 solver.cpp:244]     Train net output #1: loss = 0.188323 (* 1 = 0.188323 loss)
I0810 13:37:45.622831 13394 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0810 13:37:48.366093 13394 solver.cpp:228] Iteration 6310, loss = 0.0626069
I0810 13:37:48.366143 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:37:48.366163 13394 solver.cpp:244]     Train net output #1: loss = 0.0626068 (* 1 = 0.0626068 loss)
I0810 13:37:48.366179 13394 sgd_solver.cpp:106] Iteration 6310, lr = 0.00692882
I0810 13:37:51.130720 13394 solver.cpp:228] Iteration 6320, loss = 0.0940104
I0810 13:37:51.130770 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:37:51.130789 13394 solver.cpp:244]     Train net output #1: loss = 0.0940103 (* 1 = 0.0940103 loss)
I0810 13:37:51.130805 13394 sgd_solver.cpp:106] Iteration 6320, lr = 0.00692564
I0810 13:37:53.889668 13394 solver.cpp:228] Iteration 6330, loss = 0.125267
I0810 13:37:53.889717 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:37:53.889735 13394 solver.cpp:244]     Train net output #1: loss = 0.125267 (* 1 = 0.125267 loss)
I0810 13:37:53.889752 13394 sgd_solver.cpp:106] Iteration 6330, lr = 0.00692246
I0810 13:37:56.653885 13394 solver.cpp:228] Iteration 6340, loss = 0.21899
I0810 13:37:56.654043 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:37:56.654063 13394 solver.cpp:244]     Train net output #1: loss = 0.21899 (* 1 = 0.21899 loss)
I0810 13:37:56.654078 13394 sgd_solver.cpp:106] Iteration 6340, lr = 0.00691928
I0810 13:37:59.402209 13394 solver.cpp:228] Iteration 6350, loss = 0.219544
I0810 13:37:59.402251 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:37:59.402266 13394 solver.cpp:244]     Train net output #1: loss = 0.219544 (* 1 = 0.219544 loss)
I0810 13:37:59.402278 13394 sgd_solver.cpp:106] Iteration 6350, lr = 0.00691611
I0810 13:38:02.145872 13394 solver.cpp:228] Iteration 6360, loss = 0.0942901
I0810 13:38:02.145920 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:38:02.145936 13394 solver.cpp:244]     Train net output #1: loss = 0.09429 (* 1 = 0.09429 loss)
I0810 13:38:02.145951 13394 sgd_solver.cpp:106] Iteration 6360, lr = 0.00691294
I0810 13:38:04.906204 13394 solver.cpp:228] Iteration 6370, loss = 0.157397
I0810 13:38:04.906250 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:38:04.906265 13394 solver.cpp:244]     Train net output #1: loss = 0.157397 (* 1 = 0.157397 loss)
I0810 13:38:04.906278 13394 sgd_solver.cpp:106] Iteration 6370, lr = 0.00690977
I0810 13:38:07.671674 13394 solver.cpp:228] Iteration 6380, loss = 0.0938401
I0810 13:38:07.671721 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:38:07.671739 13394 solver.cpp:244]     Train net output #1: loss = 0.09384 (* 1 = 0.09384 loss)
I0810 13:38:07.671756 13394 sgd_solver.cpp:106] Iteration 6380, lr = 0.0069066
I0810 13:38:10.430091 13394 solver.cpp:228] Iteration 6390, loss = 0.346503
I0810 13:38:10.430233 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:38:10.430270 13394 solver.cpp:244]     Train net output #1: loss = 0.346502 (* 1 = 0.346502 loss)
I0810 13:38:10.430304 13394 sgd_solver.cpp:106] Iteration 6390, lr = 0.00690344
I0810 13:38:12.937641 13394 solver.cpp:337] Iteration 6400, Testing net (#0)
I0810 13:38:14.465168 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:38:14.465215 13394 solver.cpp:404]     Test net output #1: loss = 1.02381 (* 1 = 1.02381 loss)
I0810 13:38:14.733628 13394 solver.cpp:228] Iteration 6400, loss = 0.158044
I0810 13:38:14.733670 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:38:14.733685 13394 solver.cpp:244]     Train net output #1: loss = 0.158044 (* 1 = 0.158044 loss)
I0810 13:38:14.733698 13394 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0810 13:38:17.476861 13394 solver.cpp:228] Iteration 6410, loss = 0.127456
I0810 13:38:17.476902 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:38:17.476917 13394 solver.cpp:244]     Train net output #1: loss = 0.127456 (* 1 = 0.127456 loss)
I0810 13:38:17.476929 13394 sgd_solver.cpp:106] Iteration 6410, lr = 0.00689713
I0810 13:38:20.240016 13394 solver.cpp:228] Iteration 6420, loss = 0.125495
I0810 13:38:20.240062 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:38:20.240077 13394 solver.cpp:244]     Train net output #1: loss = 0.125495 (* 1 = 0.125495 loss)
I0810 13:38:20.240092 13394 sgd_solver.cpp:106] Iteration 6420, lr = 0.00689398
I0810 13:38:23.058272 13394 solver.cpp:228] Iteration 6430, loss = 0.126201
I0810 13:38:23.058322 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:38:23.058337 13394 solver.cpp:244]     Train net output #1: loss = 0.126201 (* 1 = 0.126201 loss)
I0810 13:38:23.058352 13394 sgd_solver.cpp:106] Iteration 6430, lr = 0.00689083
I0810 13:38:25.822176 13394 solver.cpp:228] Iteration 6440, loss = 0.095067
I0810 13:38:25.822219 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:38:25.822238 13394 solver.cpp:244]     Train net output #1: loss = 0.0950668 (* 1 = 0.0950668 loss)
I0810 13:38:25.822254 13394 sgd_solver.cpp:106] Iteration 6440, lr = 0.00688769
I0810 13:38:28.564651 13394 solver.cpp:228] Iteration 6450, loss = 0.156827
I0810 13:38:28.564807 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:38:28.564822 13394 solver.cpp:244]     Train net output #1: loss = 0.156827 (* 1 = 0.156827 loss)
I0810 13:38:28.564836 13394 sgd_solver.cpp:106] Iteration 6450, lr = 0.00688455
I0810 13:38:31.313266 13394 solver.cpp:228] Iteration 6460, loss = 0.346989
I0810 13:38:31.313310 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:38:31.313326 13394 solver.cpp:244]     Train net output #1: loss = 0.346989 (* 1 = 0.346989 loss)
I0810 13:38:31.313340 13394 sgd_solver.cpp:106] Iteration 6460, lr = 0.00688141
I0810 13:38:34.096242 13394 solver.cpp:228] Iteration 6470, loss = 0.189997
I0810 13:38:34.096287 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:38:34.096302 13394 solver.cpp:244]     Train net output #1: loss = 0.189997 (* 1 = 0.189997 loss)
I0810 13:38:34.096318 13394 sgd_solver.cpp:106] Iteration 6470, lr = 0.00687828
I0810 13:38:36.870306 13394 solver.cpp:228] Iteration 6480, loss = 0.219475
I0810 13:38:36.870357 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:38:36.870375 13394 solver.cpp:244]     Train net output #1: loss = 0.219475 (* 1 = 0.219475 loss)
I0810 13:38:36.870391 13394 sgd_solver.cpp:106] Iteration 6480, lr = 0.00687515
I0810 13:38:39.651593 13394 solver.cpp:228] Iteration 6490, loss = 0.157296
I0810 13:38:39.651638 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:38:39.651657 13394 solver.cpp:244]     Train net output #1: loss = 0.157296 (* 1 = 0.157296 loss)
I0810 13:38:39.651672 13394 sgd_solver.cpp:106] Iteration 6490, lr = 0.00687202
I0810 13:38:42.127805 13394 solver.cpp:337] Iteration 6500, Testing net (#0)
I0810 13:38:43.640283 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 13:38:43.640334 13394 solver.cpp:404]     Test net output #1: loss = 1.05382 (* 1 = 1.05382 loss)
I0810 13:38:43.917804 13394 solver.cpp:228] Iteration 6500, loss = 0.125813
I0810 13:38:43.917850 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:38:43.917867 13394 solver.cpp:244]     Train net output #1: loss = 0.125813 (* 1 = 0.125813 loss)
I0810 13:38:43.917882 13394 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0810 13:38:46.679775 13394 solver.cpp:228] Iteration 6510, loss = 0.220338
I0810 13:38:46.679818 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:38:46.679836 13394 solver.cpp:244]     Train net output #1: loss = 0.220338 (* 1 = 0.220338 loss)
I0810 13:38:46.679852 13394 sgd_solver.cpp:106] Iteration 6510, lr = 0.00686578
I0810 13:38:49.457207 13394 solver.cpp:228] Iteration 6520, loss = 0.219622
I0810 13:38:49.457258 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:38:49.457278 13394 solver.cpp:244]     Train net output #1: loss = 0.219622 (* 1 = 0.219622 loss)
I0810 13:38:49.457293 13394 sgd_solver.cpp:106] Iteration 6520, lr = 0.00686266
I0810 13:38:52.208508 13394 solver.cpp:228] Iteration 6530, loss = 0.189082
I0810 13:38:52.208556 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:38:52.208575 13394 solver.cpp:244]     Train net output #1: loss = 0.189082 (* 1 = 0.189082 loss)
I0810 13:38:52.208591 13394 sgd_solver.cpp:106] Iteration 6530, lr = 0.00685955
I0810 13:38:54.972230 13394 solver.cpp:228] Iteration 6540, loss = 0.283451
I0810 13:38:54.972275 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:38:54.972290 13394 solver.cpp:244]     Train net output #1: loss = 0.283451 (* 1 = 0.283451 loss)
I0810 13:38:54.972306 13394 sgd_solver.cpp:106] Iteration 6540, lr = 0.00685643
I0810 13:38:57.731173 13394 solver.cpp:228] Iteration 6550, loss = 0.0626448
I0810 13:38:57.731217 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:38:57.731236 13394 solver.cpp:244]     Train net output #1: loss = 0.0626447 (* 1 = 0.0626447 loss)
I0810 13:38:57.731251 13394 sgd_solver.cpp:106] Iteration 6550, lr = 0.00685333
I0810 13:39:00.489009 13394 solver.cpp:228] Iteration 6560, loss = 0.250602
I0810 13:39:00.489171 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:39:00.489190 13394 solver.cpp:244]     Train net output #1: loss = 0.250602 (* 1 = 0.250602 loss)
I0810 13:39:00.489205 13394 sgd_solver.cpp:106] Iteration 6560, lr = 0.00685022
I0810 13:39:03.251054 13394 solver.cpp:228] Iteration 6570, loss = 0.156632
I0810 13:39:03.251103 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:39:03.251121 13394 solver.cpp:244]     Train net output #1: loss = 0.156632 (* 1 = 0.156632 loss)
I0810 13:39:03.251137 13394 sgd_solver.cpp:106] Iteration 6570, lr = 0.00684712
I0810 13:39:06.020108 13394 solver.cpp:228] Iteration 6580, loss = 0.0945409
I0810 13:39:06.020159 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:39:06.020177 13394 solver.cpp:244]     Train net output #1: loss = 0.0945408 (* 1 = 0.0945408 loss)
I0810 13:39:06.020195 13394 sgd_solver.cpp:106] Iteration 6580, lr = 0.00684403
I0810 13:39:08.785928 13394 solver.cpp:228] Iteration 6590, loss = 0.281839
I0810 13:39:08.785976 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:39:08.785995 13394 solver.cpp:244]     Train net output #1: loss = 0.281839 (* 1 = 0.281839 loss)
I0810 13:39:08.786010 13394 sgd_solver.cpp:106] Iteration 6590, lr = 0.00684093
I0810 13:39:11.273233 13394 solver.cpp:337] Iteration 6600, Testing net (#0)
I0810 13:39:12.772143 13394 solver.cpp:404]     Test net output #0: accuracy = 0.696875
I0810 13:39:12.772202 13394 solver.cpp:404]     Test net output #1: loss = 1.0062 (* 1 = 1.0062 loss)
I0810 13:39:13.051975 13394 solver.cpp:228] Iteration 6600, loss = 0.281455
I0810 13:39:13.052018 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:39:13.052037 13394 solver.cpp:244]     Train net output #1: loss = 0.281455 (* 1 = 0.281455 loss)
I0810 13:39:13.052053 13394 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0810 13:39:15.794378 13394 solver.cpp:228] Iteration 6610, loss = 1.19209e-07
I0810 13:39:15.794425 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:39:15.794441 13394 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0810 13:39:15.794457 13394 sgd_solver.cpp:106] Iteration 6610, lr = 0.00683475
I0810 13:39:18.576055 13394 solver.cpp:228] Iteration 6620, loss = 0.187961
I0810 13:39:18.576190 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:39:18.576227 13394 solver.cpp:244]     Train net output #1: loss = 0.187961 (* 1 = 0.187961 loss)
I0810 13:39:18.576262 13394 sgd_solver.cpp:106] Iteration 6620, lr = 0.00683167
I0810 13:39:21.337369 13394 solver.cpp:228] Iteration 6630, loss = 0.250394
I0810 13:39:21.337420 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:39:21.337440 13394 solver.cpp:244]     Train net output #1: loss = 0.250394 (* 1 = 0.250394 loss)
I0810 13:39:21.337455 13394 sgd_solver.cpp:106] Iteration 6630, lr = 0.00682859
I0810 13:39:24.118592 13394 solver.cpp:228] Iteration 6640, loss = 0.219545
I0810 13:39:24.118643 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:39:24.118662 13394 solver.cpp:244]     Train net output #1: loss = 0.219545 (* 1 = 0.219545 loss)
I0810 13:39:24.118679 13394 sgd_solver.cpp:106] Iteration 6640, lr = 0.00682551
I0810 13:39:26.879576 13394 solver.cpp:228] Iteration 6650, loss = 0.188169
I0810 13:39:26.879623 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:39:26.879642 13394 solver.cpp:244]     Train net output #1: loss = 0.188169 (* 1 = 0.188169 loss)
I0810 13:39:26.879657 13394 sgd_solver.cpp:106] Iteration 6650, lr = 0.00682243
I0810 13:39:29.622444 13394 solver.cpp:228] Iteration 6660, loss = 0.156389
I0810 13:39:29.622495 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:39:29.622514 13394 solver.cpp:244]     Train net output #1: loss = 0.156389 (* 1 = 0.156389 loss)
I0810 13:39:29.622531 13394 sgd_solver.cpp:106] Iteration 6660, lr = 0.00681936
I0810 13:39:32.378384 13394 solver.cpp:228] Iteration 6670, loss = 0.157156
I0810 13:39:32.378531 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:39:32.378550 13394 solver.cpp:244]     Train net output #1: loss = 0.157156 (* 1 = 0.157156 loss)
I0810 13:39:32.378566 13394 sgd_solver.cpp:106] Iteration 6670, lr = 0.00681629
I0810 13:39:35.190992 13394 solver.cpp:228] Iteration 6680, loss = 0.156907
I0810 13:39:35.191040 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:39:35.191056 13394 solver.cpp:244]     Train net output #1: loss = 0.156907 (* 1 = 0.156907 loss)
I0810 13:39:35.191068 13394 sgd_solver.cpp:106] Iteration 6680, lr = 0.00681323
I0810 13:39:37.953706 13394 solver.cpp:228] Iteration 6690, loss = 0.0945339
I0810 13:39:37.953750 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:39:37.953766 13394 solver.cpp:244]     Train net output #1: loss = 0.0945337 (* 1 = 0.0945337 loss)
I0810 13:39:37.953780 13394 sgd_solver.cpp:106] Iteration 6690, lr = 0.00681017
I0810 13:39:40.461248 13394 solver.cpp:337] Iteration 6700, Testing net (#0)
I0810 13:39:41.967975 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:39:41.968029 13394 solver.cpp:404]     Test net output #1: loss = 1.0249 (* 1 = 1.0249 loss)
I0810 13:39:42.246244 13394 solver.cpp:228] Iteration 6700, loss = 0.0629673
I0810 13:39:42.246290 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:39:42.246309 13394 solver.cpp:244]     Train net output #1: loss = 0.0629671 (* 1 = 0.0629671 loss)
I0810 13:39:42.246325 13394 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0810 13:39:45.008049 13394 solver.cpp:228] Iteration 6710, loss = 0.156496
I0810 13:39:45.008095 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:39:45.008113 13394 solver.cpp:244]     Train net output #1: loss = 0.156496 (* 1 = 0.156496 loss)
I0810 13:39:45.008128 13394 sgd_solver.cpp:106] Iteration 6710, lr = 0.00680405
I0810 13:39:47.756222 13394 solver.cpp:228] Iteration 6720, loss = 0.156911
I0810 13:39:47.756273 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:39:47.756291 13394 solver.cpp:244]     Train net output #1: loss = 0.156911 (* 1 = 0.156911 loss)
I0810 13:39:47.756309 13394 sgd_solver.cpp:106] Iteration 6720, lr = 0.006801
I0810 13:39:50.504995 13394 solver.cpp:228] Iteration 6730, loss = 0.156555
I0810 13:39:50.505046 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:39:50.505065 13394 solver.cpp:244]     Train net output #1: loss = 0.156555 (* 1 = 0.156555 loss)
I0810 13:39:50.505080 13394 sgd_solver.cpp:106] Iteration 6730, lr = 0.00679795
I0810 13:39:53.272459 13394 solver.cpp:228] Iteration 6740, loss = 0.0325693
I0810 13:39:53.272511 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:39:53.272529 13394 solver.cpp:244]     Train net output #1: loss = 0.0325692 (* 1 = 0.0325692 loss)
I0810 13:39:53.272547 13394 sgd_solver.cpp:106] Iteration 6740, lr = 0.00679491
I0810 13:39:56.046923 13394 solver.cpp:228] Iteration 6750, loss = 0.156904
I0810 13:39:56.046967 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:39:56.046984 13394 solver.cpp:244]     Train net output #1: loss = 0.156904 (* 1 = 0.156904 loss)
I0810 13:39:56.046999 13394 sgd_solver.cpp:106] Iteration 6750, lr = 0.00679186
I0810 13:39:58.785377 13394 solver.cpp:228] Iteration 6760, loss = 0.219493
I0810 13:39:58.785423 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:39:58.785441 13394 solver.cpp:244]     Train net output #1: loss = 0.219493 (* 1 = 0.219493 loss)
I0810 13:39:58.785456 13394 sgd_solver.cpp:106] Iteration 6760, lr = 0.00678882
I0810 13:40:01.554044 13394 solver.cpp:228] Iteration 6770, loss = 0.18829
I0810 13:40:01.554095 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:40:01.554113 13394 solver.cpp:244]     Train net output #1: loss = 0.18829 (* 1 = 0.18829 loss)
I0810 13:40:01.554129 13394 sgd_solver.cpp:106] Iteration 6770, lr = 0.00678579
I0810 13:40:04.327726 13394 solver.cpp:228] Iteration 6780, loss = 0.187888
I0810 13:40:04.327888 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:40:04.327909 13394 solver.cpp:244]     Train net output #1: loss = 0.187888 (* 1 = 0.187888 loss)
I0810 13:40:04.327925 13394 sgd_solver.cpp:106] Iteration 6780, lr = 0.00678275
I0810 13:40:07.113848 13394 solver.cpp:228] Iteration 6790, loss = 0.156799
I0810 13:40:07.113894 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:40:07.113914 13394 solver.cpp:244]     Train net output #1: loss = 0.156798 (* 1 = 0.156798 loss)
I0810 13:40:07.113927 13394 sgd_solver.cpp:106] Iteration 6790, lr = 0.00677972
I0810 13:40:09.593560 13394 solver.cpp:337] Iteration 6800, Testing net (#0)
I0810 13:40:11.079577 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:40:11.079635 13394 solver.cpp:404]     Test net output #1: loss = 1.03194 (* 1 = 1.03194 loss)
I0810 13:40:11.354398 13394 solver.cpp:228] Iteration 6800, loss = 0.0626348
I0810 13:40:11.354444 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:40:11.354463 13394 solver.cpp:244]     Train net output #1: loss = 0.0626347 (* 1 = 0.0626347 loss)
I0810 13:40:11.354478 13394 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0810 13:40:14.109622 13394 solver.cpp:228] Iteration 6810, loss = 0.0943398
I0810 13:40:14.109719 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:40:14.109758 13394 solver.cpp:244]     Train net output #1: loss = 0.0943397 (* 1 = 0.0943397 loss)
I0810 13:40:14.109794 13394 sgd_solver.cpp:106] Iteration 6810, lr = 0.00677367
I0810 13:40:16.856351 13394 solver.cpp:228] Iteration 6820, loss = 0.250315
I0810 13:40:16.856400 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:40:16.856417 13394 solver.cpp:244]     Train net output #1: loss = 0.250315 (* 1 = 0.250315 loss)
I0810 13:40:16.856433 13394 sgd_solver.cpp:106] Iteration 6820, lr = 0.00677065
I0810 13:40:19.622449 13394 solver.cpp:228] Iteration 6830, loss = 0.0939368
I0810 13:40:19.622498 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:40:19.622519 13394 solver.cpp:244]     Train net output #1: loss = 0.0939367 (* 1 = 0.0939367 loss)
I0810 13:40:19.622536 13394 sgd_solver.cpp:106] Iteration 6830, lr = 0.00676763
I0810 13:40:22.456634 13394 solver.cpp:228] Iteration 6840, loss = 0.062867
I0810 13:40:22.456692 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:40:22.456709 13394 solver.cpp:244]     Train net output #1: loss = 0.0628669 (* 1 = 0.0628669 loss)
I0810 13:40:22.456723 13394 sgd_solver.cpp:106] Iteration 6840, lr = 0.00676462
I0810 13:40:25.220610 13394 solver.cpp:228] Iteration 6850, loss = 0.093934
I0810 13:40:25.220654 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:40:25.220669 13394 solver.cpp:244]     Train net output #1: loss = 0.0939339 (* 1 = 0.0939339 loss)
I0810 13:40:25.220681 13394 sgd_solver.cpp:106] Iteration 6850, lr = 0.00676161
I0810 13:40:27.960644 13394 solver.cpp:228] Iteration 6860, loss = 0.0626481
I0810 13:40:27.960692 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:40:27.960711 13394 solver.cpp:244]     Train net output #1: loss = 0.062648 (* 1 = 0.062648 loss)
I0810 13:40:27.960727 13394 sgd_solver.cpp:106] Iteration 6860, lr = 0.0067586
I0810 13:40:30.725941 13394 solver.cpp:228] Iteration 6870, loss = 0.281465
I0810 13:40:30.725992 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:40:30.726011 13394 solver.cpp:244]     Train net output #1: loss = 0.281465 (* 1 = 0.281465 loss)
I0810 13:40:30.726027 13394 sgd_solver.cpp:106] Iteration 6870, lr = 0.0067556
I0810 13:40:33.481261 13394 solver.cpp:228] Iteration 6880, loss = 0.125258
I0810 13:40:33.481310 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:40:33.481329 13394 solver.cpp:244]     Train net output #1: loss = 0.125258 (* 1 = 0.125258 loss)
I0810 13:40:33.481345 13394 sgd_solver.cpp:106] Iteration 6880, lr = 0.00675259
I0810 13:40:36.257058 13394 solver.cpp:228] Iteration 6890, loss = 0.312677
I0810 13:40:36.257203 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:40:36.257223 13394 solver.cpp:244]     Train net output #1: loss = 0.312677 (* 1 = 0.312677 loss)
I0810 13:40:36.257238 13394 sgd_solver.cpp:106] Iteration 6890, lr = 0.0067496
I0810 13:40:38.750181 13394 solver.cpp:337] Iteration 6900, Testing net (#0)
I0810 13:40:40.267228 13394 solver.cpp:404]     Test net output #0: accuracy = 0.695312
I0810 13:40:40.267287 13394 solver.cpp:404]     Test net output #1: loss = 1.00294 (* 1 = 1.00294 loss)
I0810 13:40:40.541777 13394 solver.cpp:228] Iteration 6900, loss = 0.219266
I0810 13:40:40.541826 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:40:40.541844 13394 solver.cpp:244]     Train net output #1: loss = 0.219265 (* 1 = 0.219265 loss)
I0810 13:40:40.541860 13394 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0810 13:40:43.302227 13394 solver.cpp:228] Iteration 6910, loss = 0.125979
I0810 13:40:43.302273 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:40:43.302290 13394 solver.cpp:244]     Train net output #1: loss = 0.125979 (* 1 = 0.125979 loss)
I0810 13:40:43.302305 13394 sgd_solver.cpp:106] Iteration 6910, lr = 0.00674361
I0810 13:40:46.055480 13394 solver.cpp:228] Iteration 6920, loss = 0.220501
I0810 13:40:46.055526 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:40:46.055543 13394 solver.cpp:244]     Train net output #1: loss = 0.220501 (* 1 = 0.220501 loss)
I0810 13:40:46.055560 13394 sgd_solver.cpp:106] Iteration 6920, lr = 0.00674062
I0810 13:40:48.811197 13394 solver.cpp:228] Iteration 6930, loss = 0.251236
I0810 13:40:48.811239 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:40:48.811252 13394 solver.cpp:244]     Train net output #1: loss = 0.251236 (* 1 = 0.251236 loss)
I0810 13:40:48.811265 13394 sgd_solver.cpp:106] Iteration 6930, lr = 0.00673763
I0810 13:40:51.523006 13394 solver.cpp:228] Iteration 6940, loss = 0.222427
I0810 13:40:51.523052 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:40:51.523068 13394 solver.cpp:244]     Train net output #1: loss = 0.222427 (* 1 = 0.222427 loss)
I0810 13:40:51.523082 13394 sgd_solver.cpp:106] Iteration 6940, lr = 0.00673465
I0810 13:40:54.234446 13394 solver.cpp:228] Iteration 6950, loss = 0.126039
I0810 13:40:54.234488 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:40:54.234503 13394 solver.cpp:244]     Train net output #1: loss = 0.126039 (* 1 = 0.126039 loss)
I0810 13:40:54.234520 13394 sgd_solver.cpp:106] Iteration 6950, lr = 0.00673167
I0810 13:40:56.953634 13394 solver.cpp:228] Iteration 6960, loss = 0.252125
I0810 13:40:56.953681 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:40:56.953697 13394 solver.cpp:244]     Train net output #1: loss = 0.252125 (* 1 = 0.252125 loss)
I0810 13:40:56.953709 13394 sgd_solver.cpp:106] Iteration 6960, lr = 0.00672869
I0810 13:40:59.717643 13394 solver.cpp:228] Iteration 6970, loss = 0.15638
I0810 13:40:59.717689 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:40:59.717708 13394 solver.cpp:244]     Train net output #1: loss = 0.15638 (* 1 = 0.15638 loss)
I0810 13:40:59.717725 13394 sgd_solver.cpp:106] Iteration 6970, lr = 0.00672572
I0810 13:41:02.478863 13394 solver.cpp:228] Iteration 6980, loss = 0.15655
I0810 13:41:02.478919 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:41:02.478937 13394 solver.cpp:244]     Train net output #1: loss = 0.15655 (* 1 = 0.15655 loss)
I0810 13:41:02.478953 13394 sgd_solver.cpp:106] Iteration 6980, lr = 0.00672275
I0810 13:41:05.328009 13394 solver.cpp:228] Iteration 6990, loss = 0.15662
I0810 13:41:05.328055 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:41:05.328074 13394 solver.cpp:244]     Train net output #1: loss = 0.15662 (* 1 = 0.15662 loss)
I0810 13:41:05.328089 13394 sgd_solver.cpp:106] Iteration 6990, lr = 0.00671978
I0810 13:41:07.872674 13394 solver.cpp:337] Iteration 7000, Testing net (#0)
I0810 13:41:09.416844 13394 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0810 13:41:09.416965 13394 solver.cpp:404]     Test net output #1: loss = 1.04654 (* 1 = 1.04654 loss)
I0810 13:41:09.715184 13394 solver.cpp:228] Iteration 7000, loss = 0.219392
I0810 13:41:09.715303 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:41:09.715349 13394 solver.cpp:244]     Train net output #1: loss = 0.219392 (* 1 = 0.219392 loss)
I0810 13:41:09.715394 13394 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0810 13:41:12.513819 13394 solver.cpp:228] Iteration 7010, loss = 0.282205
I0810 13:41:12.513861 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:41:12.513876 13394 solver.cpp:244]     Train net output #1: loss = 0.282205 (* 1 = 0.282205 loss)
I0810 13:41:12.513890 13394 sgd_solver.cpp:106] Iteration 7010, lr = 0.00671385
I0810 13:41:15.310392 13394 solver.cpp:228] Iteration 7020, loss = 0.220897
I0810 13:41:15.310438 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:41:15.310454 13394 solver.cpp:244]     Train net output #1: loss = 0.220897 (* 1 = 0.220897 loss)
I0810 13:41:15.310468 13394 sgd_solver.cpp:106] Iteration 7020, lr = 0.00671089
I0810 13:41:18.069720 13394 solver.cpp:228] Iteration 7030, loss = 0.190488
I0810 13:41:18.069775 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:41:18.069794 13394 solver.cpp:244]     Train net output #1: loss = 0.190488 (* 1 = 0.190488 loss)
I0810 13:41:18.069811 13394 sgd_solver.cpp:106] Iteration 7030, lr = 0.00670794
I0810 13:41:20.838865 13394 solver.cpp:228] Iteration 7040, loss = 0.188912
I0810 13:41:20.838915 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:41:20.838934 13394 solver.cpp:244]     Train net output #1: loss = 0.188912 (* 1 = 0.188912 loss)
I0810 13:41:20.838950 13394 sgd_solver.cpp:106] Iteration 7040, lr = 0.00670498
I0810 13:41:23.622947 13394 solver.cpp:228] Iteration 7050, loss = 0.317752
I0810 13:41:23.622995 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:41:23.623013 13394 solver.cpp:244]     Train net output #1: loss = 0.317752 (* 1 = 0.317752 loss)
I0810 13:41:23.623028 13394 sgd_solver.cpp:106] Iteration 7050, lr = 0.00670204
I0810 13:41:26.372822 13394 solver.cpp:228] Iteration 7060, loss = 0.222757
I0810 13:41:26.372867 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:41:26.372887 13394 solver.cpp:244]     Train net output #1: loss = 0.222757 (* 1 = 0.222757 loss)
I0810 13:41:26.372902 13394 sgd_solver.cpp:106] Iteration 7060, lr = 0.00669909
I0810 13:41:29.132376 13394 solver.cpp:228] Iteration 7070, loss = 0.159136
I0810 13:41:29.132505 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:41:29.132549 13394 solver.cpp:244]     Train net output #1: loss = 0.159136 (* 1 = 0.159136 loss)
I0810 13:41:29.132587 13394 sgd_solver.cpp:106] Iteration 7070, lr = 0.00669615
I0810 13:41:31.885103 13394 solver.cpp:228] Iteration 7080, loss = 0.220806
I0810 13:41:31.885154 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:41:31.885174 13394 solver.cpp:244]     Train net output #1: loss = 0.220806 (* 1 = 0.220806 loss)
I0810 13:41:31.885190 13394 sgd_solver.cpp:106] Iteration 7080, lr = 0.0066932
I0810 13:41:34.648174 13394 solver.cpp:228] Iteration 7090, loss = 0.252365
I0810 13:41:34.648221 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:41:34.648239 13394 solver.cpp:244]     Train net output #1: loss = 0.252365 (* 1 = 0.252365 loss)
I0810 13:41:34.648255 13394 sgd_solver.cpp:106] Iteration 7090, lr = 0.00669027
I0810 13:41:37.119122 13394 solver.cpp:337] Iteration 7100, Testing net (#0)
I0810 13:41:38.598562 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 13:41:38.598758 13394 solver.cpp:404]     Test net output #1: loss = 1.02671 (* 1 = 1.02671 loss)
I0810 13:41:38.872542 13394 solver.cpp:228] Iteration 7100, loss = 0.251109
I0810 13:41:38.872591 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:41:38.872611 13394 solver.cpp:244]     Train net output #1: loss = 0.251109 (* 1 = 0.251109 loss)
I0810 13:41:38.872627 13394 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0810 13:41:41.633625 13394 solver.cpp:228] Iteration 7110, loss = 0.219303
I0810 13:41:41.633671 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:41:41.633689 13394 solver.cpp:244]     Train net output #1: loss = 0.219303 (* 1 = 0.219303 loss)
I0810 13:41:41.633704 13394 sgd_solver.cpp:106] Iteration 7110, lr = 0.0066844
I0810 13:41:44.371135 13394 solver.cpp:228] Iteration 7120, loss = 0.187765
I0810 13:41:44.371187 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:41:44.371206 13394 solver.cpp:244]     Train net output #1: loss = 0.187765 (* 1 = 0.187765 loss)
I0810 13:41:44.371222 13394 sgd_solver.cpp:106] Iteration 7120, lr = 0.00668147
I0810 13:41:47.139870 13394 solver.cpp:228] Iteration 7130, loss = 0.218822
I0810 13:41:47.139919 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:41:47.139938 13394 solver.cpp:244]     Train net output #1: loss = 0.218822 (* 1 = 0.218822 loss)
I0810 13:41:47.139953 13394 sgd_solver.cpp:106] Iteration 7130, lr = 0.00667855
I0810 13:41:49.882868 13394 solver.cpp:228] Iteration 7140, loss = 0.219311
I0810 13:41:49.882917 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:41:49.882936 13394 solver.cpp:244]     Train net output #1: loss = 0.21931 (* 1 = 0.21931 loss)
I0810 13:41:49.882951 13394 sgd_solver.cpp:106] Iteration 7140, lr = 0.00667562
I0810 13:41:52.740226 13394 solver.cpp:228] Iteration 7150, loss = 0.125169
I0810 13:41:52.740269 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:41:52.740284 13394 solver.cpp:244]     Train net output #1: loss = 0.125169 (* 1 = 0.125169 loss)
I0810 13:41:52.740298 13394 sgd_solver.cpp:106] Iteration 7150, lr = 0.0066727
I0810 13:41:55.479487 13394 solver.cpp:228] Iteration 7160, loss = 0.250259
I0810 13:41:55.479598 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:41:55.479638 13394 solver.cpp:244]     Train net output #1: loss = 0.250259 (* 1 = 0.250259 loss)
I0810 13:41:55.479674 13394 sgd_solver.cpp:106] Iteration 7160, lr = 0.00666979
I0810 13:41:58.240494 13394 solver.cpp:228] Iteration 7170, loss = 0.125193
I0810 13:41:58.240540 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:41:58.240558 13394 solver.cpp:244]     Train net output #1: loss = 0.125193 (* 1 = 0.125193 loss)
I0810 13:41:58.240576 13394 sgd_solver.cpp:106] Iteration 7170, lr = 0.00666687
I0810 13:42:01.046408 13394 solver.cpp:228] Iteration 7180, loss = 0.251589
I0810 13:42:01.046455 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:42:01.046473 13394 solver.cpp:244]     Train net output #1: loss = 0.251589 (* 1 = 0.251589 loss)
I0810 13:42:01.046489 13394 sgd_solver.cpp:106] Iteration 7180, lr = 0.00666396
I0810 13:42:03.837364 13394 solver.cpp:228] Iteration 7190, loss = 0.219095
I0810 13:42:03.837414 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:42:03.837431 13394 solver.cpp:244]     Train net output #1: loss = 0.219095 (* 1 = 0.219095 loss)
I0810 13:42:03.837447 13394 sgd_solver.cpp:106] Iteration 7190, lr = 0.00666106
I0810 13:42:06.331312 13394 solver.cpp:337] Iteration 7200, Testing net (#0)
I0810 13:42:07.802973 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:42:07.803035 13394 solver.cpp:404]     Test net output #1: loss = 1.01904 (* 1 = 1.01904 loss)
I0810 13:42:08.078480 13394 solver.cpp:228] Iteration 7200, loss = 0.157161
I0810 13:42:08.078528 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:42:08.078547 13394 solver.cpp:244]     Train net output #1: loss = 0.157161 (* 1 = 0.157161 loss)
I0810 13:42:08.078605 13394 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0810 13:42:10.830704 13394 solver.cpp:228] Iteration 7210, loss = 0.0626101
I0810 13:42:10.830818 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:42:10.830837 13394 solver.cpp:244]     Train net output #1: loss = 0.06261 (* 1 = 0.06261 loss)
I0810 13:42:10.830852 13394 sgd_solver.cpp:106] Iteration 7210, lr = 0.00665525
I0810 13:42:13.566854 13394 solver.cpp:228] Iteration 7220, loss = 0.187866
I0810 13:42:13.566905 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:42:13.566923 13394 solver.cpp:244]     Train net output #1: loss = 0.187866 (* 1 = 0.187866 loss)
I0810 13:42:13.566938 13394 sgd_solver.cpp:106] Iteration 7220, lr = 0.00665235
I0810 13:42:16.317729 13394 solver.cpp:228] Iteration 7230, loss = 0.250904
I0810 13:42:16.317836 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:42:16.317875 13394 solver.cpp:244]     Train net output #1: loss = 0.250903 (* 1 = 0.250903 loss)
I0810 13:42:16.317911 13394 sgd_solver.cpp:106] Iteration 7230, lr = 0.00664945
I0810 13:42:19.122748 13394 solver.cpp:228] Iteration 7240, loss = 0.219309
I0810 13:42:19.122799 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:42:19.122818 13394 solver.cpp:244]     Train net output #1: loss = 0.219309 (* 1 = 0.219309 loss)
I0810 13:42:19.122833 13394 sgd_solver.cpp:106] Iteration 7240, lr = 0.00664656
I0810 13:42:21.923977 13394 solver.cpp:228] Iteration 7250, loss = 0.250677
I0810 13:42:21.924022 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:42:21.924039 13394 solver.cpp:244]     Train net output #1: loss = 0.250677 (* 1 = 0.250677 loss)
I0810 13:42:21.924057 13394 sgd_solver.cpp:106] Iteration 7250, lr = 0.00664367
I0810 13:42:24.663307 13394 solver.cpp:228] Iteration 7260, loss = 0.221252
I0810 13:42:24.663355 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:42:24.663373 13394 solver.cpp:244]     Train net output #1: loss = 0.221252 (* 1 = 0.221252 loss)
I0810 13:42:24.663389 13394 sgd_solver.cpp:106] Iteration 7260, lr = 0.00664078
I0810 13:42:27.408890 13394 solver.cpp:228] Iteration 7270, loss = 0.220517
I0810 13:42:27.408939 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:42:27.408957 13394 solver.cpp:244]     Train net output #1: loss = 0.220517 (* 1 = 0.220517 loss)
I0810 13:42:27.408973 13394 sgd_solver.cpp:106] Iteration 7270, lr = 0.0066379
I0810 13:42:30.175361 13394 solver.cpp:228] Iteration 7280, loss = 0.0937827
I0810 13:42:30.175412 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:42:30.175431 13394 solver.cpp:244]     Train net output #1: loss = 0.0937826 (* 1 = 0.0937826 loss)
I0810 13:42:30.175446 13394 sgd_solver.cpp:106] Iteration 7280, lr = 0.00663502
I0810 13:42:32.998682 13394 solver.cpp:228] Iteration 7290, loss = 0.0941602
I0810 13:42:32.998730 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:42:32.998749 13394 solver.cpp:244]     Train net output #1: loss = 0.0941601 (* 1 = 0.0941601 loss)
I0810 13:42:32.998766 13394 sgd_solver.cpp:106] Iteration 7290, lr = 0.00663214
I0810 13:42:35.518987 13394 solver.cpp:337] Iteration 7300, Testing net (#0)
I0810 13:42:37.012498 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 13:42:37.012553 13394 solver.cpp:404]     Test net output #1: loss = 1.03668 (* 1 = 1.03668 loss)
I0810 13:42:37.287811 13394 solver.cpp:228] Iteration 7300, loss = 0.0940481
I0810 13:42:37.287858 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:42:37.287873 13394 solver.cpp:244]     Train net output #1: loss = 0.094048 (* 1 = 0.094048 loss)
I0810 13:42:37.287886 13394 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0810 13:42:40.033126 13394 solver.cpp:228] Iteration 7310, loss = 0.0939037
I0810 13:42:40.033169 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:42:40.033184 13394 solver.cpp:244]     Train net output #1: loss = 0.0939037 (* 1 = 0.0939037 loss)
I0810 13:42:40.033197 13394 sgd_solver.cpp:106] Iteration 7310, lr = 0.00662639
I0810 13:42:42.767458 13394 solver.cpp:228] Iteration 7320, loss = 0.0313114
I0810 13:42:42.767616 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:42:42.767632 13394 solver.cpp:244]     Train net output #1: loss = 0.0313113 (* 1 = 0.0313113 loss)
I0810 13:42:42.767645 13394 sgd_solver.cpp:106] Iteration 7320, lr = 0.00662352
I0810 13:42:45.508035 13394 solver.cpp:228] Iteration 7330, loss = 0.219652
I0810 13:42:45.508100 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:42:45.508116 13394 solver.cpp:244]     Train net output #1: loss = 0.219652 (* 1 = 0.219652 loss)
I0810 13:42:45.508129 13394 sgd_solver.cpp:106] Iteration 7330, lr = 0.00662066
I0810 13:42:48.362187 13394 solver.cpp:228] Iteration 7340, loss = 0.219073
I0810 13:42:48.362241 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:42:48.362258 13394 solver.cpp:244]     Train net output #1: loss = 0.219073 (* 1 = 0.219073 loss)
I0810 13:42:48.362274 13394 sgd_solver.cpp:106] Iteration 7340, lr = 0.00661779
I0810 13:42:51.132437 13394 solver.cpp:228] Iteration 7350, loss = 0.187638
I0810 13:42:51.132479 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:42:51.132498 13394 solver.cpp:244]     Train net output #1: loss = 0.187638 (* 1 = 0.187638 loss)
I0810 13:42:51.132513 13394 sgd_solver.cpp:106] Iteration 7350, lr = 0.00661493
I0810 13:42:53.877624 13394 solver.cpp:228] Iteration 7360, loss = 0.344931
I0810 13:42:53.877672 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:42:53.877691 13394 solver.cpp:244]     Train net output #1: loss = 0.344931 (* 1 = 0.344931 loss)
I0810 13:42:53.877706 13394 sgd_solver.cpp:106] Iteration 7360, lr = 0.00661207
I0810 13:42:56.645989 13394 solver.cpp:228] Iteration 7370, loss = 0.219832
I0810 13:42:56.646041 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:42:56.646059 13394 solver.cpp:244]     Train net output #1: loss = 0.219832 (* 1 = 0.219832 loss)
I0810 13:42:56.646075 13394 sgd_solver.cpp:106] Iteration 7370, lr = 0.00660922
I0810 13:42:59.404220 13394 solver.cpp:228] Iteration 7380, loss = 0.125053
I0810 13:42:59.404270 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:42:59.404289 13394 solver.cpp:244]     Train net output #1: loss = 0.125053 (* 1 = 0.125053 loss)
I0810 13:42:59.404304 13394 sgd_solver.cpp:106] Iteration 7380, lr = 0.00660637
I0810 13:43:02.221846 13394 solver.cpp:228] Iteration 7390, loss = 0.220063
I0810 13:43:02.221895 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:43:02.221915 13394 solver.cpp:244]     Train net output #1: loss = 0.220062 (* 1 = 0.220062 loss)
I0810 13:43:02.221930 13394 sgd_solver.cpp:106] Iteration 7390, lr = 0.00660352
I0810 13:43:04.716768 13394 solver.cpp:337] Iteration 7400, Testing net (#0)
I0810 13:43:06.184567 13394 solver.cpp:404]     Test net output #0: accuracy = 0.692187
I0810 13:43:06.184623 13394 solver.cpp:404]     Test net output #1: loss = 1.00551 (* 1 = 1.00551 loss)
I0810 13:43:06.459318 13394 solver.cpp:228] Iteration 7400, loss = 0.12537
I0810 13:43:06.459370 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:43:06.459390 13394 solver.cpp:244]     Train net output #1: loss = 0.12537 (* 1 = 0.12537 loss)
I0810 13:43:06.459406 13394 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0810 13:43:09.231237 13394 solver.cpp:228] Iteration 7410, loss = 0.28332
I0810 13:43:09.231290 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:43:09.231308 13394 solver.cpp:244]     Train net output #1: loss = 0.28332 (* 1 = 0.28332 loss)
I0810 13:43:09.231324 13394 sgd_solver.cpp:106] Iteration 7410, lr = 0.00659783
I0810 13:43:12.026224 13394 solver.cpp:228] Iteration 7420, loss = 0.189996
I0810 13:43:12.026269 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:43:12.026288 13394 solver.cpp:244]     Train net output #1: loss = 0.189996 (* 1 = 0.189996 loss)
I0810 13:43:12.026304 13394 sgd_solver.cpp:106] Iteration 7420, lr = 0.00659499
I0810 13:43:14.889771 13394 solver.cpp:228] Iteration 7430, loss = 0.156607
I0810 13:43:14.890311 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:43:14.890327 13394 solver.cpp:244]     Train net output #1: loss = 0.156607 (* 1 = 0.156607 loss)
I0810 13:43:14.890341 13394 sgd_solver.cpp:106] Iteration 7430, lr = 0.00659215
I0810 13:43:17.692064 13394 solver.cpp:228] Iteration 7440, loss = 0.251107
I0810 13:43:17.692108 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:43:17.692124 13394 solver.cpp:244]     Train net output #1: loss = 0.251107 (* 1 = 0.251107 loss)
I0810 13:43:17.692138 13394 sgd_solver.cpp:106] Iteration 7440, lr = 0.00658931
I0810 13:43:20.455735 13394 solver.cpp:228] Iteration 7450, loss = 0.187769
I0810 13:43:20.455842 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:43:20.455883 13394 solver.cpp:244]     Train net output #1: loss = 0.187769 (* 1 = 0.187769 loss)
I0810 13:43:20.455922 13394 sgd_solver.cpp:106] Iteration 7450, lr = 0.00658648
I0810 13:43:23.323026 13394 solver.cpp:228] Iteration 7460, loss = 0.344312
I0810 13:43:23.323083 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:43:23.323099 13394 solver.cpp:244]     Train net output #1: loss = 0.344312 (* 1 = 0.344312 loss)
I0810 13:43:23.323112 13394 sgd_solver.cpp:106] Iteration 7460, lr = 0.00658365
I0810 13:43:26.176785 13394 solver.cpp:228] Iteration 7470, loss = 0.31401
I0810 13:43:26.176837 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:43:26.176856 13394 solver.cpp:244]     Train net output #1: loss = 0.31401 (* 1 = 0.31401 loss)
I0810 13:43:26.176872 13394 sgd_solver.cpp:106] Iteration 7470, lr = 0.00658082
I0810 13:43:28.947863 13394 solver.cpp:228] Iteration 7480, loss = 0.156372
I0810 13:43:28.947909 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:43:28.947927 13394 solver.cpp:244]     Train net output #1: loss = 0.156372 (* 1 = 0.156372 loss)
I0810 13:43:28.947943 13394 sgd_solver.cpp:106] Iteration 7480, lr = 0.006578
I0810 13:43:31.762109 13394 solver.cpp:228] Iteration 7490, loss = 0.1261
I0810 13:43:31.762169 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:43:31.762188 13394 solver.cpp:244]     Train net output #1: loss = 0.1261 (* 1 = 0.1261 loss)
I0810 13:43:31.762203 13394 sgd_solver.cpp:106] Iteration 7490, lr = 0.00657518
I0810 13:43:34.300634 13394 solver.cpp:337] Iteration 7500, Testing net (#0)
I0810 13:43:35.778349 13394 solver.cpp:404]     Test net output #0: accuracy = 0.692187
I0810 13:43:35.778406 13394 solver.cpp:404]     Test net output #1: loss = 1.00376 (* 1 = 1.00376 loss)
I0810 13:43:36.061079 13394 solver.cpp:228] Iteration 7500, loss = 0.251721
I0810 13:43:36.061128 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:43:36.061147 13394 solver.cpp:244]     Train net output #1: loss = 0.251721 (* 1 = 0.251721 loss)
I0810 13:43:36.061164 13394 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0810 13:43:38.828532 13394 solver.cpp:228] Iteration 7510, loss = 0.281982
I0810 13:43:38.828575 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:43:38.828593 13394 solver.cpp:244]     Train net output #1: loss = 0.281982 (* 1 = 0.281982 loss)
I0810 13:43:38.828608 13394 sgd_solver.cpp:106] Iteration 7510, lr = 0.00656955
I0810 13:43:41.602542 13394 solver.cpp:228] Iteration 7520, loss = 0.125296
I0810 13:43:41.602684 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:43:41.602732 13394 solver.cpp:244]     Train net output #1: loss = 0.125296 (* 1 = 0.125296 loss)
I0810 13:43:41.602772 13394 sgd_solver.cpp:106] Iteration 7520, lr = 0.00656673
I0810 13:43:44.353735 13394 solver.cpp:228] Iteration 7530, loss = 0.219152
I0810 13:43:44.353780 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:43:44.353797 13394 solver.cpp:244]     Train net output #1: loss = 0.219152 (* 1 = 0.219152 loss)
I0810 13:43:44.353813 13394 sgd_solver.cpp:106] Iteration 7530, lr = 0.00656392
I0810 13:43:47.123129 13394 solver.cpp:228] Iteration 7540, loss = 0.313513
I0810 13:43:47.123288 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:43:47.123304 13394 solver.cpp:244]     Train net output #1: loss = 0.313513 (* 1 = 0.313513 loss)
I0810 13:43:47.123318 13394 sgd_solver.cpp:106] Iteration 7540, lr = 0.00656112
I0810 13:43:49.880023 13394 solver.cpp:228] Iteration 7550, loss = 0.187816
I0810 13:43:49.880066 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:43:49.880081 13394 solver.cpp:244]     Train net output #1: loss = 0.187816 (* 1 = 0.187816 loss)
I0810 13:43:49.880095 13394 sgd_solver.cpp:106] Iteration 7550, lr = 0.00655831
I0810 13:43:52.668014 13394 solver.cpp:228] Iteration 7560, loss = 0.0626987
I0810 13:43:52.668061 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:43:52.668078 13394 solver.cpp:244]     Train net output #1: loss = 0.0626986 (* 1 = 0.0626986 loss)
I0810 13:43:52.668093 13394 sgd_solver.cpp:106] Iteration 7560, lr = 0.00655551
I0810 13:43:55.433411 13394 solver.cpp:228] Iteration 7570, loss = 0.0939434
I0810 13:43:55.433460 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:43:55.433480 13394 solver.cpp:244]     Train net output #1: loss = 0.0939433 (* 1 = 0.0939433 loss)
I0810 13:43:55.433495 13394 sgd_solver.cpp:106] Iteration 7570, lr = 0.00655271
I0810 13:43:58.186480 13394 solver.cpp:228] Iteration 7580, loss = 0.125062
I0810 13:43:58.186530 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:43:58.186549 13394 solver.cpp:244]     Train net output #1: loss = 0.125062 (* 1 = 0.125062 loss)
I0810 13:43:58.186566 13394 sgd_solver.cpp:106] Iteration 7580, lr = 0.00654992
I0810 13:44:00.928745 13394 solver.cpp:228] Iteration 7590, loss = 0.21922
I0810 13:44:00.928792 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:44:00.928810 13394 solver.cpp:244]     Train net output #1: loss = 0.21922 (* 1 = 0.21922 loss)
I0810 13:44:00.928828 13394 sgd_solver.cpp:106] Iteration 7590, lr = 0.00654712
I0810 13:44:03.461439 13394 solver.cpp:337] Iteration 7600, Testing net (#0)
I0810 13:44:04.936954 13394 solver.cpp:404]     Test net output #0: accuracy = 0.682813
I0810 13:44:04.937017 13394 solver.cpp:404]     Test net output #1: loss = 1.02858 (* 1 = 1.02858 loss)
I0810 13:44:05.211212 13394 solver.cpp:228] Iteration 7600, loss = 0.219706
I0810 13:44:05.211267 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:44:05.211290 13394 solver.cpp:244]     Train net output #1: loss = 0.219706 (* 1 = 0.219706 loss)
I0810 13:44:05.211308 13394 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0810 13:44:07.978303 13394 solver.cpp:228] Iteration 7610, loss = 0.0939802
I0810 13:44:07.978355 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:44:07.978375 13394 solver.cpp:244]     Train net output #1: loss = 0.0939802 (* 1 = 0.0939802 loss)
I0810 13:44:07.978391 13394 sgd_solver.cpp:106] Iteration 7610, lr = 0.00654155
I0810 13:44:10.757359 13394 solver.cpp:228] Iteration 7620, loss = 0.156591
I0810 13:44:10.757403 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:44:10.757418 13394 solver.cpp:244]     Train net output #1: loss = 0.156591 (* 1 = 0.156591 loss)
I0810 13:44:10.757431 13394 sgd_solver.cpp:106] Iteration 7620, lr = 0.00653876
I0810 13:44:13.490664 13394 solver.cpp:228] Iteration 7630, loss = 0.0941058
I0810 13:44:13.490710 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:44:13.490726 13394 solver.cpp:244]     Train net output #1: loss = 0.0941058 (* 1 = 0.0941058 loss)
I0810 13:44:13.490741 13394 sgd_solver.cpp:106] Iteration 7630, lr = 0.00653598
I0810 13:44:16.239397 13394 solver.cpp:228] Iteration 7640, loss = 0.346199
I0810 13:44:16.239445 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:44:16.239464 13394 solver.cpp:244]     Train net output #1: loss = 0.346198 (* 1 = 0.346198 loss)
I0810 13:44:16.239480 13394 sgd_solver.cpp:106] Iteration 7640, lr = 0.0065332
I0810 13:44:18.999886 13394 solver.cpp:228] Iteration 7650, loss = 0.156791
I0810 13:44:19.000016 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:44:19.000036 13394 solver.cpp:244]     Train net output #1: loss = 0.156791 (* 1 = 0.156791 loss)
I0810 13:44:19.000052 13394 sgd_solver.cpp:106] Iteration 7650, lr = 0.00653043
I0810 13:44:21.798565 13394 solver.cpp:228] Iteration 7660, loss = 0.125041
I0810 13:44:21.798669 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:44:21.798744 13394 solver.cpp:244]     Train net output #1: loss = 0.125041 (* 1 = 0.125041 loss)
I0810 13:44:21.798779 13394 sgd_solver.cpp:106] Iteration 7660, lr = 0.00652765
I0810 13:44:24.589318 13394 solver.cpp:228] Iteration 7670, loss = 0.125066
I0810 13:44:24.589361 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:44:24.589380 13394 solver.cpp:244]     Train net output #1: loss = 0.125066 (* 1 = 0.125066 loss)
I0810 13:44:24.589395 13394 sgd_solver.cpp:106] Iteration 7670, lr = 0.00652488
I0810 13:44:27.354288 13394 solver.cpp:228] Iteration 7680, loss = 0.125633
I0810 13:44:27.354337 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:44:27.354356 13394 solver.cpp:244]     Train net output #1: loss = 0.125633 (* 1 = 0.125633 loss)
I0810 13:44:27.354372 13394 sgd_solver.cpp:106] Iteration 7680, lr = 0.00652211
I0810 13:44:30.096603 13394 solver.cpp:228] Iteration 7690, loss = 0.0938879
I0810 13:44:30.096657 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:44:30.096676 13394 solver.cpp:244]     Train net output #1: loss = 0.0938879 (* 1 = 0.0938879 loss)
I0810 13:44:30.096693 13394 sgd_solver.cpp:106] Iteration 7690, lr = 0.00651935
I0810 13:44:32.576702 13394 solver.cpp:337] Iteration 7700, Testing net (#0)
I0810 13:44:34.099304 13394 solver.cpp:404]     Test net output #0: accuracy = 0.698438
I0810 13:44:34.099468 13394 solver.cpp:404]     Test net output #1: loss = 0.983189 (* 1 = 0.983189 loss)
I0810 13:44:34.384591 13394 solver.cpp:228] Iteration 7700, loss = 0.156549
I0810 13:44:34.384637 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:44:34.384654 13394 solver.cpp:244]     Train net output #1: loss = 0.156548 (* 1 = 0.156548 loss)
I0810 13:44:34.384672 13394 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0810 13:44:37.144333 13394 solver.cpp:228] Iteration 7710, loss = 0.343813
I0810 13:44:37.144381 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:44:37.144395 13394 solver.cpp:244]     Train net output #1: loss = 0.343813 (* 1 = 0.343813 loss)
I0810 13:44:37.144408 13394 sgd_solver.cpp:106] Iteration 7710, lr = 0.00651383
I0810 13:44:39.891607 13394 solver.cpp:228] Iteration 7720, loss = 0.18831
I0810 13:44:39.891650 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:44:39.891665 13394 solver.cpp:244]     Train net output #1: loss = 0.18831 (* 1 = 0.18831 loss)
I0810 13:44:39.891679 13394 sgd_solver.cpp:106] Iteration 7720, lr = 0.00651107
I0810 13:44:42.640640 13394 solver.cpp:228] Iteration 7730, loss = 0.219322
I0810 13:44:42.640686 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:44:42.640703 13394 solver.cpp:244]     Train net output #1: loss = 0.219322 (* 1 = 0.219322 loss)
I0810 13:44:42.640719 13394 sgd_solver.cpp:106] Iteration 7730, lr = 0.00650831
I0810 13:44:45.375975 13394 solver.cpp:228] Iteration 7740, loss = 0.156487
I0810 13:44:45.376030 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:44:45.376049 13394 solver.cpp:244]     Train net output #1: loss = 0.156487 (* 1 = 0.156487 loss)
I0810 13:44:45.376065 13394 sgd_solver.cpp:106] Iteration 7740, lr = 0.00650556
I0810 13:44:48.174783 13394 solver.cpp:228] Iteration 7750, loss = 0.125626
I0810 13:44:48.174828 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:44:48.174846 13394 solver.cpp:244]     Train net output #1: loss = 0.125626 (* 1 = 0.125626 loss)
I0810 13:44:48.174860 13394 sgd_solver.cpp:106] Iteration 7750, lr = 0.00650281
I0810 13:44:51.019315 13394 solver.cpp:228] Iteration 7760, loss = 0.219911
I0810 13:44:51.019570 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:44:51.019590 13394 solver.cpp:244]     Train net output #1: loss = 0.219911 (* 1 = 0.219911 loss)
I0810 13:44:51.019606 13394 sgd_solver.cpp:106] Iteration 7760, lr = 0.00650007
I0810 13:44:53.788444 13394 solver.cpp:228] Iteration 7770, loss = 0.219098
I0810 13:44:53.788487 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:44:53.788503 13394 solver.cpp:244]     Train net output #1: loss = 0.219098 (* 1 = 0.219098 loss)
I0810 13:44:53.788516 13394 sgd_solver.cpp:106] Iteration 7770, lr = 0.00649732
I0810 13:44:56.543520 13394 solver.cpp:228] Iteration 7780, loss = 0.188686
I0810 13:44:56.543658 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:44:56.543720 13394 solver.cpp:244]     Train net output #1: loss = 0.188686 (* 1 = 0.188686 loss)
I0810 13:44:56.543756 13394 sgd_solver.cpp:106] Iteration 7780, lr = 0.00649458
I0810 13:44:59.326449 13394 solver.cpp:228] Iteration 7790, loss = 0.283093
I0810 13:44:59.326499 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:44:59.326519 13394 solver.cpp:244]     Train net output #1: loss = 0.283093 (* 1 = 0.283093 loss)
I0810 13:44:59.326535 13394 sgd_solver.cpp:106] Iteration 7790, lr = 0.00649184
I0810 13:45:01.898356 13394 solver.cpp:337] Iteration 7800, Testing net (#0)
I0810 13:45:03.400499 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 13:45:03.400555 13394 solver.cpp:404]     Test net output #1: loss = 1.02861 (* 1 = 1.02861 loss)
I0810 13:45:03.688530 13394 solver.cpp:228] Iteration 7800, loss = 0.0626657
I0810 13:45:03.688580 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:45:03.688598 13394 solver.cpp:244]     Train net output #1: loss = 0.0626656 (* 1 = 0.0626656 loss)
I0810 13:45:03.688613 13394 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0810 13:45:06.510694 13394 solver.cpp:228] Iteration 7810, loss = 0.251329
I0810 13:45:06.510741 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:45:06.510759 13394 solver.cpp:244]     Train net output #1: loss = 0.251329 (* 1 = 0.251329 loss)
I0810 13:45:06.510776 13394 sgd_solver.cpp:106] Iteration 7810, lr = 0.00648638
I0810 13:45:09.310581 13394 solver.cpp:228] Iteration 7820, loss = 0.157185
I0810 13:45:09.310626 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:45:09.310643 13394 solver.cpp:244]     Train net output #1: loss = 0.157185 (* 1 = 0.157185 loss)
I0810 13:45:09.310657 13394 sgd_solver.cpp:106] Iteration 7820, lr = 0.00648364
I0810 13:45:12.112963 13394 solver.cpp:228] Iteration 7830, loss = 0.0938355
I0810 13:45:12.113198 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:45:12.113330 13394 solver.cpp:244]     Train net output #1: loss = 0.0938354 (* 1 = 0.0938354 loss)
I0810 13:45:12.113454 13394 sgd_solver.cpp:106] Iteration 7830, lr = 0.00648092
I0810 13:45:14.959995 13394 solver.cpp:228] Iteration 7840, loss = 0.28145
I0810 13:45:14.960131 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:45:14.960176 13394 solver.cpp:244]     Train net output #1: loss = 0.28145 (* 1 = 0.28145 loss)
I0810 13:45:14.960192 13394 sgd_solver.cpp:106] Iteration 7840, lr = 0.00647819
I0810 13:45:17.862516 13394 solver.cpp:228] Iteration 7850, loss = 0.282537
I0810 13:45:17.862565 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:45:17.862582 13394 solver.cpp:244]     Train net output #1: loss = 0.282537 (* 1 = 0.282537 loss)
I0810 13:45:17.862597 13394 sgd_solver.cpp:106] Iteration 7850, lr = 0.00647547
I0810 13:45:20.707335 13394 solver.cpp:228] Iteration 7860, loss = 5.96046e-08
I0810 13:45:20.707381 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:45:20.707399 13394 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0810 13:45:20.707414 13394 sgd_solver.cpp:106] Iteration 7860, lr = 0.00647275
I0810 13:45:23.533427 13394 solver.cpp:228] Iteration 7870, loss = 0.188757
I0810 13:45:23.533550 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:45:23.533568 13394 solver.cpp:244]     Train net output #1: loss = 0.188757 (* 1 = 0.188757 loss)
I0810 13:45:23.533583 13394 sgd_solver.cpp:106] Iteration 7870, lr = 0.00647003
I0810 13:45:26.352128 13394 solver.cpp:228] Iteration 7880, loss = 0.251088
I0810 13:45:26.352172 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:45:26.352191 13394 solver.cpp:244]     Train net output #1: loss = 0.251088 (* 1 = 0.251088 loss)
I0810 13:45:26.352206 13394 sgd_solver.cpp:106] Iteration 7880, lr = 0.00646732
I0810 13:45:29.209076 13394 solver.cpp:228] Iteration 7890, loss = 0.219743
I0810 13:45:29.209125 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:45:29.209143 13394 solver.cpp:244]     Train net output #1: loss = 0.219742 (* 1 = 0.219742 loss)
I0810 13:45:29.209159 13394 sgd_solver.cpp:106] Iteration 7890, lr = 0.00646461
I0810 13:45:31.725304 13394 solver.cpp:337] Iteration 7900, Testing net (#0)
I0810 13:45:33.249100 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:45:33.249155 13394 solver.cpp:404]     Test net output #1: loss = 1.01581 (* 1 = 1.01581 loss)
I0810 13:45:33.529155 13394 solver.cpp:228] Iteration 7900, loss = 0.188239
I0810 13:45:33.529203 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:45:33.529223 13394 solver.cpp:244]     Train net output #1: loss = 0.188239 (* 1 = 0.188239 loss)
I0810 13:45:33.529239 13394 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0810 13:45:36.310180 13394 solver.cpp:228] Iteration 7910, loss = 0.156497
I0810 13:45:36.310228 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:45:36.310247 13394 solver.cpp:244]     Train net output #1: loss = 0.156497 (* 1 = 0.156497 loss)
I0810 13:45:36.310263 13394 sgd_solver.cpp:106] Iteration 7910, lr = 0.00645919
I0810 13:45:39.073344 13394 solver.cpp:228] Iteration 7920, loss = 0.156979
I0810 13:45:39.073393 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:45:39.073410 13394 solver.cpp:244]     Train net output #1: loss = 0.156979 (* 1 = 0.156979 loss)
I0810 13:45:39.073427 13394 sgd_solver.cpp:106] Iteration 7920, lr = 0.00645649
I0810 13:45:41.866786 13394 solver.cpp:228] Iteration 7930, loss = 0.156553
I0810 13:45:41.866835 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:45:41.866853 13394 solver.cpp:244]     Train net output #1: loss = 0.156553 (* 1 = 0.156553 loss)
I0810 13:45:41.866868 13394 sgd_solver.cpp:106] Iteration 7930, lr = 0.00645379
I0810 13:45:44.678555 13394 solver.cpp:228] Iteration 7940, loss = 0.0938863
I0810 13:45:44.678604 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:45:44.678622 13394 solver.cpp:244]     Train net output #1: loss = 0.0938862 (* 1 = 0.0938862 loss)
I0810 13:45:44.678638 13394 sgd_solver.cpp:106] Iteration 7940, lr = 0.00645109
I0810 13:45:47.492420 13394 solver.cpp:228] Iteration 7950, loss = 0.0630633
I0810 13:45:47.492476 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:45:47.492496 13394 solver.cpp:244]     Train net output #1: loss = 0.0630633 (* 1 = 0.0630633 loss)
I0810 13:45:47.492513 13394 sgd_solver.cpp:106] Iteration 7950, lr = 0.0064484
I0810 13:45:50.280313 13394 solver.cpp:228] Iteration 7960, loss = 0.156306
I0810 13:45:50.280359 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:45:50.280376 13394 solver.cpp:244]     Train net output #1: loss = 0.156306 (* 1 = 0.156306 loss)
I0810 13:45:50.280391 13394 sgd_solver.cpp:106] Iteration 7960, lr = 0.0064457
I0810 13:45:53.051920 13394 solver.cpp:228] Iteration 7970, loss = 0.15632
I0810 13:45:53.051964 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:45:53.051982 13394 solver.cpp:244]     Train net output #1: loss = 0.15632 (* 1 = 0.15632 loss)
I0810 13:45:53.051997 13394 sgd_solver.cpp:106] Iteration 7970, lr = 0.00644301
I0810 13:45:55.819627 13394 solver.cpp:228] Iteration 7980, loss = 0.156581
I0810 13:45:55.819773 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:45:55.819793 13394 solver.cpp:244]     Train net output #1: loss = 0.156581 (* 1 = 0.156581 loss)
I0810 13:45:55.819808 13394 sgd_solver.cpp:106] Iteration 7980, lr = 0.00644032
I0810 13:45:58.601444 13394 solver.cpp:228] Iteration 7990, loss = 0.0319551
I0810 13:45:58.601493 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:45:58.601512 13394 solver.cpp:244]     Train net output #1: loss = 0.0319551 (* 1 = 0.0319551 loss)
I0810 13:45:58.601531 13394 sgd_solver.cpp:106] Iteration 7990, lr = 0.00643764
I0810 13:46:01.091883 13394 solver.cpp:337] Iteration 8000, Testing net (#0)
I0810 13:46:02.590139 13394 solver.cpp:404]     Test net output #0: accuracy = 0.69375
I0810 13:46:02.590199 13394 solver.cpp:404]     Test net output #1: loss = 0.991729 (* 1 = 0.991729 loss)
I0810 13:46:02.864398 13394 solver.cpp:228] Iteration 8000, loss = 0.159565
I0810 13:46:02.864449 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:46:02.864467 13394 solver.cpp:244]     Train net output #1: loss = 0.159565 (* 1 = 0.159565 loss)
I0810 13:46:02.864483 13394 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0810 13:46:05.644704 13394 solver.cpp:228] Iteration 8010, loss = 0.219858
I0810 13:46:05.644752 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:46:05.644770 13394 solver.cpp:244]     Train net output #1: loss = 0.219858 (* 1 = 0.219858 loss)
I0810 13:46:05.644788 13394 sgd_solver.cpp:106] Iteration 8010, lr = 0.00643228
I0810 13:46:08.451166 13394 solver.cpp:228] Iteration 8020, loss = 0.187578
I0810 13:46:08.451226 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:46:08.451244 13394 solver.cpp:244]     Train net output #1: loss = 0.187578 (* 1 = 0.187578 loss)
I0810 13:46:08.451259 13394 sgd_solver.cpp:106] Iteration 8020, lr = 0.0064296
I0810 13:46:11.293193 13394 solver.cpp:228] Iteration 8030, loss = 0.188193
I0810 13:46:11.293242 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:46:11.293259 13394 solver.cpp:244]     Train net output #1: loss = 0.188193 (* 1 = 0.188193 loss)
I0810 13:46:11.293272 13394 sgd_solver.cpp:106] Iteration 8030, lr = 0.00642692
I0810 13:46:14.169967 13394 solver.cpp:228] Iteration 8040, loss = 0.157647
I0810 13:46:14.170020 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:46:14.170038 13394 solver.cpp:244]     Train net output #1: loss = 0.157647 (* 1 = 0.157647 loss)
I0810 13:46:14.170053 13394 sgd_solver.cpp:106] Iteration 8040, lr = 0.00642425
I0810 13:46:16.920524 13394 solver.cpp:228] Iteration 8050, loss = 0.0629686
I0810 13:46:16.920645 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:46:16.920687 13394 solver.cpp:244]     Train net output #1: loss = 0.0629686 (* 1 = 0.0629686 loss)
I0810 13:46:16.920724 13394 sgd_solver.cpp:106] Iteration 8050, lr = 0.00642158
I0810 13:46:19.709166 13394 solver.cpp:228] Iteration 8060, loss = 0.0940958
I0810 13:46:19.709210 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:46:19.709229 13394 solver.cpp:244]     Train net output #1: loss = 0.0940957 (* 1 = 0.0940957 loss)
I0810 13:46:19.709245 13394 sgd_solver.cpp:106] Iteration 8060, lr = 0.00641892
I0810 13:46:22.529352 13394 solver.cpp:228] Iteration 8070, loss = 0.250247
I0810 13:46:22.529397 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:46:22.529417 13394 solver.cpp:244]     Train net output #1: loss = 0.250247 (* 1 = 0.250247 loss)
I0810 13:46:22.529431 13394 sgd_solver.cpp:106] Iteration 8070, lr = 0.00641625
I0810 13:46:25.359191 13394 solver.cpp:228] Iteration 8080, loss = 0.0941761
I0810 13:46:25.359315 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:46:25.359357 13394 solver.cpp:244]     Train net output #1: loss = 0.094176 (* 1 = 0.094176 loss)
I0810 13:46:25.359398 13394 sgd_solver.cpp:106] Iteration 8080, lr = 0.00641359
I0810 13:46:28.349047 13394 solver.cpp:228] Iteration 8090, loss = 0.062692
I0810 13:46:28.349182 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:46:28.349203 13394 solver.cpp:244]     Train net output #1: loss = 0.062692 (* 1 = 0.062692 loss)
I0810 13:46:28.349220 13394 sgd_solver.cpp:106] Iteration 8090, lr = 0.00641093
I0810 13:46:30.862629 13394 solver.cpp:337] Iteration 8100, Testing net (#0)
I0810 13:46:32.376991 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 13:46:32.377049 13394 solver.cpp:404]     Test net output #1: loss = 1.00494 (* 1 = 1.00494 loss)
I0810 13:46:32.660709 13394 solver.cpp:228] Iteration 8100, loss = 0.0938646
I0810 13:46:32.660789 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:46:32.660814 13394 solver.cpp:244]     Train net output #1: loss = 0.0938646 (* 1 = 0.0938646 loss)
I0810 13:46:32.660833 13394 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0810 13:46:35.439537 13394 solver.cpp:228] Iteration 8110, loss = 0.0635001
I0810 13:46:35.439582 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:46:35.439600 13394 solver.cpp:244]     Train net output #1: loss = 0.0635001 (* 1 = 0.0635001 loss)
I0810 13:46:35.439615 13394 sgd_solver.cpp:106] Iteration 8110, lr = 0.00640562
I0810 13:46:38.185431 13394 solver.cpp:228] Iteration 8120, loss = 0.281483
I0810 13:46:38.185475 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:46:38.185494 13394 solver.cpp:244]     Train net output #1: loss = 0.281483 (* 1 = 0.281483 loss)
I0810 13:46:38.185508 13394 sgd_solver.cpp:106] Iteration 8120, lr = 0.00640297
I0810 13:46:40.927433 13394 solver.cpp:228] Iteration 8130, loss = 0.125788
I0810 13:46:40.927485 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:46:40.927505 13394 solver.cpp:244]     Train net output #1: loss = 0.125788 (* 1 = 0.125788 loss)
I0810 13:46:40.927520 13394 sgd_solver.cpp:106] Iteration 8130, lr = 0.00640032
I0810 13:46:43.688616 13394 solver.cpp:228] Iteration 8140, loss = 0.31264
I0810 13:46:43.688664 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:46:43.688683 13394 solver.cpp:244]     Train net output #1: loss = 0.31264 (* 1 = 0.31264 loss)
I0810 13:46:43.688697 13394 sgd_solver.cpp:106] Iteration 8140, lr = 0.00639767
I0810 13:46:46.435560 13394 solver.cpp:228] Iteration 8150, loss = 0.219671
I0810 13:46:46.435611 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:46:46.435629 13394 solver.cpp:244]     Train net output #1: loss = 0.219671 (* 1 = 0.219671 loss)
I0810 13:46:46.435645 13394 sgd_solver.cpp:106] Iteration 8150, lr = 0.00639503
I0810 13:46:49.207610 13394 solver.cpp:228] Iteration 8160, loss = 0.125625
I0810 13:46:49.207655 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:46:49.207674 13394 solver.cpp:244]     Train net output #1: loss = 0.125625 (* 1 = 0.125625 loss)
I0810 13:46:49.207690 13394 sgd_solver.cpp:106] Iteration 8160, lr = 0.00639239
I0810 13:46:51.982558 13394 solver.cpp:228] Iteration 8170, loss = 0.218931
I0810 13:46:51.982602 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:46:51.982620 13394 solver.cpp:244]     Train net output #1: loss = 0.218931 (* 1 = 0.218931 loss)
I0810 13:46:51.982635 13394 sgd_solver.cpp:106] Iteration 8170, lr = 0.00638975
I0810 13:46:54.768931 13394 solver.cpp:228] Iteration 8180, loss = 0.25019
I0810 13:46:54.768982 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:46:54.769001 13394 solver.cpp:244]     Train net output #1: loss = 0.25019 (* 1 = 0.25019 loss)
I0810 13:46:54.769017 13394 sgd_solver.cpp:106] Iteration 8180, lr = 0.00638711
I0810 13:46:57.586828 13394 solver.cpp:228] Iteration 8190, loss = 0.218887
I0810 13:46:57.586879 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:46:57.586899 13394 solver.cpp:244]     Train net output #1: loss = 0.218887 (* 1 = 0.218887 loss)
I0810 13:46:57.586915 13394 sgd_solver.cpp:106] Iteration 8190, lr = 0.00638448
I0810 13:47:00.133493 13394 solver.cpp:337] Iteration 8200, Testing net (#0)
I0810 13:47:01.627904 13394 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0810 13:47:01.628015 13394 solver.cpp:404]     Test net output #1: loss = 1.00832 (* 1 = 1.00832 loss)
I0810 13:47:01.905403 13394 solver.cpp:228] Iteration 8200, loss = 0.125422
I0810 13:47:01.905449 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:47:01.905467 13394 solver.cpp:244]     Train net output #1: loss = 0.125422 (* 1 = 0.125422 loss)
I0810 13:47:01.905484 13394 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0810 13:47:04.717766 13394 solver.cpp:228] Iteration 8210, loss = 0.25091
I0810 13:47:04.717813 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:47:04.717866 13394 solver.cpp:244]     Train net output #1: loss = 0.25091 (* 1 = 0.25091 loss)
I0810 13:47:04.717885 13394 sgd_solver.cpp:106] Iteration 8210, lr = 0.00637922
I0810 13:47:07.472431 13394 solver.cpp:228] Iteration 8220, loss = 0.157487
I0810 13:47:07.472476 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:47:07.472493 13394 solver.cpp:244]     Train net output #1: loss = 0.157487 (* 1 = 0.157487 loss)
I0810 13:47:07.472508 13394 sgd_solver.cpp:106] Iteration 8220, lr = 0.00637659
I0810 13:47:10.227502 13394 solver.cpp:228] Iteration 8230, loss = 0.15675
I0810 13:47:10.227551 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:47:10.227569 13394 solver.cpp:244]     Train net output #1: loss = 0.15675 (* 1 = 0.15675 loss)
I0810 13:47:10.227584 13394 sgd_solver.cpp:106] Iteration 8230, lr = 0.00637397
I0810 13:47:13.008607 13394 solver.cpp:228] Iteration 8240, loss = 0.15658
I0810 13:47:13.008716 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:47:13.008759 13394 solver.cpp:244]     Train net output #1: loss = 0.15658 (* 1 = 0.15658 loss)
I0810 13:47:13.008797 13394 sgd_solver.cpp:106] Iteration 8240, lr = 0.00637135
I0810 13:47:15.801038 13394 solver.cpp:228] Iteration 8250, loss = 0.21921
I0810 13:47:15.801090 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:47:15.801106 13394 solver.cpp:244]     Train net output #1: loss = 0.21921 (* 1 = 0.21921 loss)
I0810 13:47:15.801122 13394 sgd_solver.cpp:106] Iteration 8250, lr = 0.00636873
I0810 13:47:18.567023 13394 solver.cpp:228] Iteration 8260, loss = 0.281621
I0810 13:47:18.567070 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:47:18.567088 13394 solver.cpp:244]     Train net output #1: loss = 0.281621 (* 1 = 0.281621 loss)
I0810 13:47:18.567104 13394 sgd_solver.cpp:106] Iteration 8260, lr = 0.00636611
I0810 13:47:21.354372 13394 solver.cpp:228] Iteration 8270, loss = 0.218977
I0810 13:47:21.354429 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:47:21.354449 13394 solver.cpp:244]     Train net output #1: loss = 0.218977 (* 1 = 0.218977 loss)
I0810 13:47:21.354463 13394 sgd_solver.cpp:106] Iteration 8270, lr = 0.0063635
I0810 13:47:24.179764 13394 solver.cpp:228] Iteration 8280, loss = 0.1876
I0810 13:47:24.179811 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:47:24.179831 13394 solver.cpp:244]     Train net output #1: loss = 0.1876 (* 1 = 0.1876 loss)
I0810 13:47:24.179847 13394 sgd_solver.cpp:106] Iteration 8280, lr = 0.00636089
I0810 13:47:26.951079 13394 solver.cpp:228] Iteration 8290, loss = 0.18828
I0810 13:47:26.951133 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:47:26.951150 13394 solver.cpp:244]     Train net output #1: loss = 0.18828 (* 1 = 0.18828 loss)
I0810 13:47:26.951166 13394 sgd_solver.cpp:106] Iteration 8290, lr = 0.00635828
I0810 13:47:29.520265 13394 solver.cpp:337] Iteration 8300, Testing net (#0)
I0810 13:47:30.999472 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:47:30.999631 13394 solver.cpp:404]     Test net output #1: loss = 1.0062 (* 1 = 1.0062 loss)
I0810 13:47:31.281225 13394 solver.cpp:228] Iteration 8300, loss = 0.314325
I0810 13:47:31.281280 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:47:31.281301 13394 solver.cpp:244]     Train net output #1: loss = 0.314325 (* 1 = 0.314325 loss)
I0810 13:47:31.281318 13394 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0810 13:47:34.142060 13394 solver.cpp:228] Iteration 8310, loss = 0.22023
I0810 13:47:34.142107 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:47:34.142122 13394 solver.cpp:244]     Train net output #1: loss = 0.22023 (* 1 = 0.22023 loss)
I0810 13:47:34.142135 13394 sgd_solver.cpp:106] Iteration 8310, lr = 0.00635307
I0810 13:47:36.914528 13394 solver.cpp:228] Iteration 8320, loss = 0.15761
I0810 13:47:36.914577 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:47:36.914595 13394 solver.cpp:244]     Train net output #1: loss = 0.15761 (* 1 = 0.15761 loss)
I0810 13:47:36.914610 13394 sgd_solver.cpp:106] Iteration 8320, lr = 0.00635047
I0810 13:47:39.657102 13394 solver.cpp:228] Iteration 8330, loss = 0.222864
I0810 13:47:39.657153 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:47:39.657171 13394 solver.cpp:244]     Train net output #1: loss = 0.222864 (* 1 = 0.222864 loss)
I0810 13:47:39.657188 13394 sgd_solver.cpp:106] Iteration 8330, lr = 0.00634787
I0810 13:47:42.415627 13394 solver.cpp:228] Iteration 8340, loss = 0.250945
I0810 13:47:42.415671 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:47:42.415688 13394 solver.cpp:244]     Train net output #1: loss = 0.250945 (* 1 = 0.250945 loss)
I0810 13:47:42.415700 13394 sgd_solver.cpp:106] Iteration 8340, lr = 0.00634528
I0810 13:47:45.179944 13394 solver.cpp:228] Iteration 8350, loss = 0.250705
I0810 13:47:45.179997 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:47:45.180016 13394 solver.cpp:244]     Train net output #1: loss = 0.250705 (* 1 = 0.250705 loss)
I0810 13:47:45.180032 13394 sgd_solver.cpp:106] Iteration 8350, lr = 0.00634268
I0810 13:47:48.014348 13394 solver.cpp:228] Iteration 8360, loss = 0.218985
I0810 13:47:48.014390 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:47:48.014410 13394 solver.cpp:244]     Train net output #1: loss = 0.218985 (* 1 = 0.218985 loss)
I0810 13:47:48.014426 13394 sgd_solver.cpp:106] Iteration 8360, lr = 0.00634009
I0810 13:47:50.789132 13394 solver.cpp:228] Iteration 8370, loss = 0.187687
I0810 13:47:50.789180 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:47:50.789197 13394 solver.cpp:244]     Train net output #1: loss = 0.187687 (* 1 = 0.187687 loss)
I0810 13:47:50.789213 13394 sgd_solver.cpp:106] Iteration 8370, lr = 0.0063375
I0810 13:47:53.542690 13394 solver.cpp:228] Iteration 8380, loss = 0.219886
I0810 13:47:53.542739 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:47:53.542758 13394 solver.cpp:244]     Train net output #1: loss = 0.219885 (* 1 = 0.219885 loss)
I0810 13:47:53.542775 13394 sgd_solver.cpp:106] Iteration 8380, lr = 0.00633492
I0810 13:47:56.304287 13394 solver.cpp:228] Iteration 8390, loss = 0.218965
I0810 13:47:56.304388 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:47:56.304427 13394 solver.cpp:244]     Train net output #1: loss = 0.218965 (* 1 = 0.218965 loss)
I0810 13:47:56.304456 13394 sgd_solver.cpp:106] Iteration 8390, lr = 0.00633233
I0810 13:47:58.794571 13394 solver.cpp:337] Iteration 8400, Testing net (#0)
I0810 13:48:00.269451 13394 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0810 13:48:00.269516 13394 solver.cpp:404]     Test net output #1: loss = 1.03428 (* 1 = 1.03428 loss)
I0810 13:48:00.544268 13394 solver.cpp:228] Iteration 8400, loss = 0.125067
I0810 13:48:00.544312 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:48:00.544330 13394 solver.cpp:244]     Train net output #1: loss = 0.125067 (* 1 = 0.125067 loss)
I0810 13:48:00.544380 13394 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0810 13:48:03.363550 13394 solver.cpp:228] Iteration 8410, loss = 0.251189
I0810 13:48:03.363661 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:48:03.363677 13394 solver.cpp:244]     Train net output #1: loss = 0.251189 (* 1 = 0.251189 loss)
I0810 13:48:03.363690 13394 sgd_solver.cpp:106] Iteration 8410, lr = 0.00632717
I0810 13:48:06.128037 13394 solver.cpp:228] Iteration 8420, loss = 0.125249
I0810 13:48:06.128082 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:48:06.128096 13394 solver.cpp:244]     Train net output #1: loss = 0.125249 (* 1 = 0.125249 loss)
I0810 13:48:06.128110 13394 sgd_solver.cpp:106] Iteration 8420, lr = 0.0063246
I0810 13:48:08.866988 13394 solver.cpp:228] Iteration 8430, loss = 0.250484
I0810 13:48:08.867038 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:48:08.867055 13394 solver.cpp:244]     Train net output #1: loss = 0.250484 (* 1 = 0.250484 loss)
I0810 13:48:08.867070 13394 sgd_solver.cpp:106] Iteration 8430, lr = 0.00632202
I0810 13:48:11.638954 13394 solver.cpp:228] Iteration 8440, loss = 0.218824
I0810 13:48:11.639003 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:48:11.639020 13394 solver.cpp:244]     Train net output #1: loss = 0.218824 (* 1 = 0.218824 loss)
I0810 13:48:11.639036 13394 sgd_solver.cpp:106] Iteration 8440, lr = 0.00631945
I0810 13:48:14.421077 13394 solver.cpp:228] Iteration 8450, loss = 0.156956
I0810 13:48:14.421126 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:48:14.421145 13394 solver.cpp:244]     Train net output #1: loss = 0.156956 (* 1 = 0.156956 loss)
I0810 13:48:14.421161 13394 sgd_solver.cpp:106] Iteration 8450, lr = 0.00631688
I0810 13:48:17.166446 13394 solver.cpp:228] Iteration 8460, loss = 0.062675
I0810 13:48:17.166498 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:48:17.166517 13394 solver.cpp:244]     Train net output #1: loss = 0.0626749 (* 1 = 0.0626749 loss)
I0810 13:48:17.166533 13394 sgd_solver.cpp:106] Iteration 8460, lr = 0.00631431
I0810 13:48:19.952522 13394 solver.cpp:228] Iteration 8470, loss = 0.188312
I0810 13:48:19.952621 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:48:19.952661 13394 solver.cpp:244]     Train net output #1: loss = 0.188312 (* 1 = 0.188312 loss)
I0810 13:48:19.952677 13394 sgd_solver.cpp:106] Iteration 8470, lr = 0.00631175
I0810 13:48:22.772979 13394 solver.cpp:228] Iteration 8480, loss = 0.250668
I0810 13:48:22.773025 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:48:22.773044 13394 solver.cpp:244]     Train net output #1: loss = 0.250668 (* 1 = 0.250668 loss)
I0810 13:48:22.773058 13394 sgd_solver.cpp:106] Iteration 8480, lr = 0.00630919
I0810 13:48:25.532138 13394 solver.cpp:228] Iteration 8490, loss = 0.219271
I0810 13:48:25.532186 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:48:25.532204 13394 solver.cpp:244]     Train net output #1: loss = 0.219271 (* 1 = 0.219271 loss)
I0810 13:48:25.532222 13394 sgd_solver.cpp:106] Iteration 8490, lr = 0.00630663
I0810 13:48:28.022959 13394 solver.cpp:337] Iteration 8500, Testing net (#0)
I0810 13:48:29.501049 13394 solver.cpp:404]     Test net output #0: accuracy = 0.7
I0810 13:48:29.501103 13394 solver.cpp:404]     Test net output #1: loss = 0.969549 (* 1 = 0.969549 loss)
I0810 13:48:29.779894 13394 solver.cpp:228] Iteration 8500, loss = 0.251878
I0810 13:48:29.779944 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:48:29.779963 13394 solver.cpp:244]     Train net output #1: loss = 0.251878 (* 1 = 0.251878 loss)
I0810 13:48:29.779978 13394 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0810 13:48:32.593969 13394 solver.cpp:228] Iteration 8510, loss = 0.221964
I0810 13:48:32.594017 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:48:32.594033 13394 solver.cpp:244]     Train net output #1: loss = 0.221964 (* 1 = 0.221964 loss)
I0810 13:48:32.594046 13394 sgd_solver.cpp:106] Iteration 8510, lr = 0.00630152
I0810 13:48:35.393740 13394 solver.cpp:228] Iteration 8520, loss = 0.218836
I0810 13:48:35.393878 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:48:35.393894 13394 solver.cpp:244]     Train net output #1: loss = 0.218836 (* 1 = 0.218836 loss)
I0810 13:48:35.393908 13394 sgd_solver.cpp:106] Iteration 8520, lr = 0.00629897
I0810 13:48:38.139379 13394 solver.cpp:228] Iteration 8530, loss = 0.0952681
I0810 13:48:38.139422 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:48:38.139437 13394 solver.cpp:244]     Train net output #1: loss = 0.0952679 (* 1 = 0.0952679 loss)
I0810 13:48:38.139451 13394 sgd_solver.cpp:106] Iteration 8530, lr = 0.00629642
I0810 13:48:40.871130 13394 solver.cpp:228] Iteration 8540, loss = 0.0938088
I0810 13:48:40.871176 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:48:40.871191 13394 solver.cpp:244]     Train net output #1: loss = 0.0938087 (* 1 = 0.0938087 loss)
I0810 13:48:40.871202 13394 sgd_solver.cpp:106] Iteration 8540, lr = 0.00629387
I0810 13:48:43.586802 13394 solver.cpp:228] Iteration 8550, loss = 0.0938224
I0810 13:48:43.586845 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:48:43.586860 13394 solver.cpp:244]     Train net output #1: loss = 0.0938223 (* 1 = 0.0938223 loss)
I0810 13:48:43.586875 13394 sgd_solver.cpp:106] Iteration 8550, lr = 0.00629132
I0810 13:48:46.302459 13394 solver.cpp:228] Iteration 8560, loss = 0.0938001
I0810 13:48:46.302500 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:48:46.302515 13394 solver.cpp:244]     Train net output #1: loss = 0.0938 (* 1 = 0.0938 loss)
I0810 13:48:46.302528 13394 sgd_solver.cpp:106] Iteration 8560, lr = 0.00628878
I0810 13:48:49.056702 13394 solver.cpp:228] Iteration 8570, loss = 0.0314188
I0810 13:48:49.056802 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:48:49.056838 13394 solver.cpp:244]     Train net output #1: loss = 0.0314186 (* 1 = 0.0314186 loss)
I0810 13:48:49.056869 13394 sgd_solver.cpp:106] Iteration 8570, lr = 0.00628624
I0810 13:48:51.834841 13394 solver.cpp:228] Iteration 8580, loss = 0.219494
I0810 13:48:51.834888 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:48:51.834903 13394 solver.cpp:244]     Train net output #1: loss = 0.219494 (* 1 = 0.219494 loss)
I0810 13:48:51.834916 13394 sgd_solver.cpp:106] Iteration 8580, lr = 0.0062837
I0810 13:48:54.588665 13394 solver.cpp:228] Iteration 8590, loss = 0.218839
I0810 13:48:54.588714 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:48:54.588729 13394 solver.cpp:244]     Train net output #1: loss = 0.218839 (* 1 = 0.218839 loss)
I0810 13:48:54.588743 13394 sgd_solver.cpp:106] Iteration 8590, lr = 0.00628117
I0810 13:48:57.056709 13394 solver.cpp:337] Iteration 8600, Testing net (#0)
I0810 13:48:58.540807 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:48:58.540858 13394 solver.cpp:404]     Test net output #1: loss = 1.00694 (* 1 = 1.00694 loss)
I0810 13:48:58.817440 13394 solver.cpp:228] Iteration 8600, loss = 0.189146
I0810 13:48:58.817492 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:48:58.817510 13394 solver.cpp:244]     Train net output #1: loss = 0.189146 (* 1 = 0.189146 loss)
I0810 13:48:58.817526 13394 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0810 13:49:01.572248 13394 solver.cpp:228] Iteration 8610, loss = 0.344204
I0810 13:49:01.572295 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:49:01.572315 13394 solver.cpp:244]     Train net output #1: loss = 0.344204 (* 1 = 0.344204 loss)
I0810 13:49:01.572330 13394 sgd_solver.cpp:106] Iteration 8610, lr = 0.00627611
I0810 13:49:04.327347 13394 solver.cpp:228] Iteration 8620, loss = 0.219146
I0810 13:49:04.327392 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:49:04.327410 13394 solver.cpp:244]     Train net output #1: loss = 0.219146 (* 1 = 0.219146 loss)
I0810 13:49:04.327426 13394 sgd_solver.cpp:106] Iteration 8620, lr = 0.00627358
I0810 13:49:07.067169 13394 solver.cpp:228] Iteration 8630, loss = 0.12563
I0810 13:49:07.067327 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:49:07.067347 13394 solver.cpp:244]     Train net output #1: loss = 0.12563 (* 1 = 0.12563 loss)
I0810 13:49:07.067360 13394 sgd_solver.cpp:106] Iteration 8630, lr = 0.00627105
I0810 13:49:09.840481 13394 solver.cpp:228] Iteration 8640, loss = 0.219839
I0810 13:49:09.840530 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:49:09.840548 13394 solver.cpp:244]     Train net output #1: loss = 0.219839 (* 1 = 0.219839 loss)
I0810 13:49:09.840564 13394 sgd_solver.cpp:106] Iteration 8640, lr = 0.00626853
I0810 13:49:12.590126 13394 solver.cpp:228] Iteration 8650, loss = 0.126007
I0810 13:49:12.590178 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:49:12.590198 13394 solver.cpp:244]     Train net output #1: loss = 0.126007 (* 1 = 0.126007 loss)
I0810 13:49:12.590214 13394 sgd_solver.cpp:106] Iteration 8650, lr = 0.00626601
I0810 13:49:15.361227 13394 solver.cpp:228] Iteration 8660, loss = 0.281826
I0810 13:49:15.361275 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:49:15.361294 13394 solver.cpp:244]     Train net output #1: loss = 0.281826 (* 1 = 0.281826 loss)
I0810 13:49:15.361310 13394 sgd_solver.cpp:106] Iteration 8660, lr = 0.00626349
I0810 13:49:18.129914 13394 solver.cpp:228] Iteration 8670, loss = 0.188346
I0810 13:49:18.129957 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:49:18.129972 13394 solver.cpp:244]     Train net output #1: loss = 0.188346 (* 1 = 0.188346 loss)
I0810 13:49:18.129987 13394 sgd_solver.cpp:106] Iteration 8670, lr = 0.00626097
I0810 13:49:20.894939 13394 solver.cpp:228] Iteration 8680, loss = 0.156579
I0810 13:49:20.894986 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:49:20.895002 13394 solver.cpp:244]     Train net output #1: loss = 0.156579 (* 1 = 0.156579 loss)
I0810 13:49:20.895015 13394 sgd_solver.cpp:106] Iteration 8680, lr = 0.00625846
I0810 13:49:23.748320 13394 solver.cpp:228] Iteration 8690, loss = 0.250246
I0810 13:49:23.748368 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:49:23.748388 13394 solver.cpp:244]     Train net output #1: loss = 0.250246 (* 1 = 0.250246 loss)
I0810 13:49:23.748402 13394 sgd_solver.cpp:106] Iteration 8690, lr = 0.00625595
I0810 13:49:26.229125 13394 solver.cpp:337] Iteration 8700, Testing net (#0)
I0810 13:49:27.699478 13394 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0810 13:49:27.699532 13394 solver.cpp:404]     Test net output #1: loss = 1.02012 (* 1 = 1.02012 loss)
I0810 13:49:27.980582 13394 solver.cpp:228] Iteration 8700, loss = 0.187836
I0810 13:49:27.980635 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:49:27.980654 13394 solver.cpp:244]     Train net output #1: loss = 0.187836 (* 1 = 0.187836 loss)
I0810 13:49:27.980670 13394 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0810 13:49:30.752033 13394 solver.cpp:228] Iteration 8710, loss = 0.344482
I0810 13:49:30.752079 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:49:30.752096 13394 solver.cpp:244]     Train net output #1: loss = 0.344482 (* 1 = 0.344482 loss)
I0810 13:49:30.752113 13394 sgd_solver.cpp:106] Iteration 8710, lr = 0.00625093
I0810 13:49:33.522351 13394 solver.cpp:228] Iteration 8720, loss = 0.31531
I0810 13:49:33.522409 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:49:33.522428 13394 solver.cpp:244]     Train net output #1: loss = 0.31531 (* 1 = 0.31531 loss)
I0810 13:49:33.522444 13394 sgd_solver.cpp:106] Iteration 8720, lr = 0.00624843
I0810 13:49:36.322080 13394 solver.cpp:228] Iteration 8730, loss = 0.156386
I0810 13:49:36.322124 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:49:36.322139 13394 solver.cpp:244]     Train net output #1: loss = 0.156385 (* 1 = 0.156385 loss)
I0810 13:49:36.322152 13394 sgd_solver.cpp:106] Iteration 8730, lr = 0.00624592
I0810 13:49:39.070694 13394 solver.cpp:228] Iteration 8740, loss = 0.125544
I0810 13:49:39.070854 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:49:39.070874 13394 solver.cpp:244]     Train net output #1: loss = 0.125544 (* 1 = 0.125544 loss)
I0810 13:49:39.070890 13394 sgd_solver.cpp:106] Iteration 8740, lr = 0.00624342
I0810 13:49:41.837010 13394 solver.cpp:228] Iteration 8750, loss = 0.250119
I0810 13:49:41.837052 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:49:41.837067 13394 solver.cpp:244]     Train net output #1: loss = 0.250119 (* 1 = 0.250119 loss)
I0810 13:49:41.837083 13394 sgd_solver.cpp:106] Iteration 8750, lr = 0.00624093
I0810 13:49:44.608903 13394 solver.cpp:228] Iteration 8760, loss = 0.281891
I0810 13:49:44.608953 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:49:44.608973 13394 solver.cpp:244]     Train net output #1: loss = 0.281891 (* 1 = 0.281891 loss)
I0810 13:49:44.608990 13394 sgd_solver.cpp:106] Iteration 8760, lr = 0.00623843
I0810 13:49:47.363634 13394 solver.cpp:228] Iteration 8770, loss = 0.125589
I0810 13:49:47.363678 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:49:47.363697 13394 solver.cpp:244]     Train net output #1: loss = 0.125589 (* 1 = 0.125589 loss)
I0810 13:49:47.363710 13394 sgd_solver.cpp:106] Iteration 8770, lr = 0.00623594
I0810 13:49:50.114527 13394 solver.cpp:228] Iteration 8780, loss = 0.218942
I0810 13:49:50.114676 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:49:50.114727 13394 solver.cpp:244]     Train net output #1: loss = 0.218942 (* 1 = 0.218942 loss)
I0810 13:49:50.114764 13394 sgd_solver.cpp:106] Iteration 8780, lr = 0.00623345
I0810 13:49:52.860961 13394 solver.cpp:228] Iteration 8790, loss = 0.319206
I0810 13:49:52.861011 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:49:52.861030 13394 solver.cpp:244]     Train net output #1: loss = 0.319205 (* 1 = 0.319205 loss)
I0810 13:49:52.861047 13394 sgd_solver.cpp:106] Iteration 8790, lr = 0.00623096
I0810 13:49:55.392797 13394 solver.cpp:337] Iteration 8800, Testing net (#0)
I0810 13:49:56.870965 13394 solver.cpp:404]     Test net output #0: accuracy = 0.692187
I0810 13:49:56.871026 13394 solver.cpp:404]     Test net output #1: loss = 0.985865 (* 1 = 0.985865 loss)
I0810 13:49:57.146170 13394 solver.cpp:228] Iteration 8800, loss = 0.1884
I0810 13:49:57.146219 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:49:57.146239 13394 solver.cpp:244]     Train net output #1: loss = 0.1884 (* 1 = 0.1884 loss)
I0810 13:49:57.146253 13394 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0810 13:49:59.908756 13394 solver.cpp:228] Iteration 8810, loss = 0.0629719
I0810 13:49:59.908805 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:49:59.908825 13394 solver.cpp:244]     Train net output #1: loss = 0.0629717 (* 1 = 0.0629717 loss)
I0810 13:49:59.908841 13394 sgd_solver.cpp:106] Iteration 8810, lr = 0.00622599
I0810 13:50:02.708282 13394 solver.cpp:228] Iteration 8820, loss = 0.0939707
I0810 13:50:02.708329 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:50:02.708346 13394 solver.cpp:244]     Train net output #1: loss = 0.0939706 (* 1 = 0.0939706 loss)
I0810 13:50:02.708361 13394 sgd_solver.cpp:106] Iteration 8820, lr = 0.00622351
I0810 13:50:05.468708 13394 solver.cpp:228] Iteration 8830, loss = 0.125622
I0810 13:50:05.468753 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:50:05.468771 13394 solver.cpp:244]     Train net output #1: loss = 0.125622 (* 1 = 0.125622 loss)
I0810 13:50:05.468786 13394 sgd_solver.cpp:106] Iteration 8830, lr = 0.00622103
I0810 13:50:08.217818 13394 solver.cpp:228] Iteration 8840, loss = 0.219595
I0810 13:50:08.217919 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:50:08.217955 13394 solver.cpp:244]     Train net output #1: loss = 0.219595 (* 1 = 0.219595 loss)
I0810 13:50:08.217986 13394 sgd_solver.cpp:106] Iteration 8840, lr = 0.00621855
I0810 13:50:10.983188 13394 solver.cpp:228] Iteration 8850, loss = 0.218898
I0810 13:50:10.983343 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:50:10.983363 13394 solver.cpp:244]     Train net output #1: loss = 0.218898 (* 1 = 0.218898 loss)
I0810 13:50:10.983379 13394 sgd_solver.cpp:106] Iteration 8850, lr = 0.00621608
I0810 13:50:13.763662 13394 solver.cpp:228] Iteration 8860, loss = 0.0937575
I0810 13:50:13.763708 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:50:13.763723 13394 solver.cpp:244]     Train net output #1: loss = 0.0937574 (* 1 = 0.0937574 loss)
I0810 13:50:13.763737 13394 sgd_solver.cpp:106] Iteration 8860, lr = 0.00621361
I0810 13:50:16.594064 13394 solver.cpp:228] Iteration 8870, loss = 0.157897
I0810 13:50:16.594202 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:50:16.594244 13394 solver.cpp:244]     Train net output #1: loss = 0.157896 (* 1 = 0.157896 loss)
I0810 13:50:16.594276 13394 sgd_solver.cpp:106] Iteration 8870, lr = 0.00621114
I0810 13:50:19.362597 13394 solver.cpp:228] Iteration 8880, loss = 0.0940781
I0810 13:50:19.362645 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:50:19.362663 13394 solver.cpp:244]     Train net output #1: loss = 0.094078 (* 1 = 0.094078 loss)
I0810 13:50:19.362679 13394 sgd_solver.cpp:106] Iteration 8880, lr = 0.00620867
I0810 13:50:22.208593 13394 solver.cpp:228] Iteration 8890, loss = 0.344004
I0810 13:50:22.208638 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:50:22.208655 13394 solver.cpp:244]     Train net output #1: loss = 0.344004 (* 1 = 0.344004 loss)
I0810 13:50:22.208668 13394 sgd_solver.cpp:106] Iteration 8890, lr = 0.0062062
I0810 13:50:24.774693 13394 solver.cpp:337] Iteration 8900, Testing net (#0)
I0810 13:50:26.288324 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:50:26.288460 13394 solver.cpp:404]     Test net output #1: loss = 0.992462 (* 1 = 0.992462 loss)
I0810 13:50:26.588300 13394 solver.cpp:228] Iteration 8900, loss = 0.156651
I0810 13:50:26.588351 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:50:26.588367 13394 solver.cpp:244]     Train net output #1: loss = 0.156651 (* 1 = 0.156651 loss)
I0810 13:50:26.588382 13394 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0810 13:50:29.444176 13394 solver.cpp:228] Iteration 8910, loss = 0.125152
I0810 13:50:29.444224 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:50:29.444242 13394 solver.cpp:244]     Train net output #1: loss = 0.125151 (* 1 = 0.125151 loss)
I0810 13:50:29.444258 13394 sgd_solver.cpp:106] Iteration 8910, lr = 0.00620128
I0810 13:50:32.287569 13394 solver.cpp:228] Iteration 8920, loss = 0.125497
I0810 13:50:32.287616 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:50:32.287636 13394 solver.cpp:244]     Train net output #1: loss = 0.125497 (* 1 = 0.125497 loss)
I0810 13:50:32.287652 13394 sgd_solver.cpp:106] Iteration 8920, lr = 0.00619882
I0810 13:50:35.092587 13394 solver.cpp:228] Iteration 8930, loss = 0.125326
I0810 13:50:35.092641 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:50:35.092659 13394 solver.cpp:244]     Train net output #1: loss = 0.125326 (* 1 = 0.125326 loss)
I0810 13:50:35.092675 13394 sgd_solver.cpp:106] Iteration 8930, lr = 0.00619637
I0810 13:50:37.981863 13394 solver.cpp:228] Iteration 8940, loss = 0.0938297
I0810 13:50:37.981987 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:50:37.982022 13394 solver.cpp:244]     Train net output #1: loss = 0.0938295 (* 1 = 0.0938295 loss)
I0810 13:50:37.982051 13394 sgd_solver.cpp:106] Iteration 8940, lr = 0.00619391
I0810 13:50:40.892688 13394 solver.cpp:228] Iteration 8950, loss = 0.156305
I0810 13:50:40.892731 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:50:40.892746 13394 solver.cpp:244]     Train net output #1: loss = 0.156305 (* 1 = 0.156305 loss)
I0810 13:50:40.892760 13394 sgd_solver.cpp:106] Iteration 8950, lr = 0.00619146
I0810 13:50:43.779523 13394 solver.cpp:228] Iteration 8960, loss = 0.344509
I0810 13:50:43.779678 13394 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0810 13:50:43.779700 13394 solver.cpp:244]     Train net output #1: loss = 0.344508 (* 1 = 0.344508 loss)
I0810 13:50:43.779716 13394 sgd_solver.cpp:106] Iteration 8960, lr = 0.00618901
I0810 13:50:46.587116 13394 solver.cpp:228] Iteration 8970, loss = 0.188132
I0810 13:50:46.587172 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:50:46.587191 13394 solver.cpp:244]     Train net output #1: loss = 0.188132 (* 1 = 0.188132 loss)
I0810 13:50:46.587208 13394 sgd_solver.cpp:106] Iteration 8970, lr = 0.00618656
I0810 13:50:49.412426 13394 solver.cpp:228] Iteration 8980, loss = 0.219539
I0810 13:50:49.412469 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:50:49.412487 13394 solver.cpp:244]     Train net output #1: loss = 0.219539 (* 1 = 0.219539 loss)
I0810 13:50:49.412503 13394 sgd_solver.cpp:106] Iteration 8980, lr = 0.00618412
I0810 13:50:52.204638 13394 solver.cpp:228] Iteration 8990, loss = 0.156451
I0810 13:50:52.204684 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:50:52.204701 13394 solver.cpp:244]     Train net output #1: loss = 0.156451 (* 1 = 0.156451 loss)
I0810 13:50:52.204716 13394 sgd_solver.cpp:106] Iteration 8990, lr = 0.00618168
I0810 13:50:54.707360 13394 solver.cpp:337] Iteration 9000, Testing net (#0)
I0810 13:50:56.254456 13394 solver.cpp:404]     Test net output #0: accuracy = 0.68125
I0810 13:50:56.254511 13394 solver.cpp:404]     Test net output #1: loss = 1.01692 (* 1 = 1.01692 loss)
I0810 13:50:56.519747 13394 solver.cpp:228] Iteration 9000, loss = 0.125501
I0810 13:50:56.519793 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:50:56.519811 13394 solver.cpp:244]     Train net output #1: loss = 0.125501 (* 1 = 0.125501 loss)
I0810 13:50:56.519829 13394 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0810 13:50:59.245424 13394 solver.cpp:228] Iteration 9010, loss = 0.218893
I0810 13:50:59.245465 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:50:59.245482 13394 solver.cpp:244]     Train net output #1: loss = 0.218893 (* 1 = 0.218893 loss)
I0810 13:50:59.245496 13394 sgd_solver.cpp:106] Iteration 9010, lr = 0.0061768
I0810 13:51:02.008977 13394 solver.cpp:228] Iteration 9020, loss = 0.219636
I0810 13:51:02.009027 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:51:02.009044 13394 solver.cpp:244]     Train net output #1: loss = 0.219635 (* 1 = 0.219635 loss)
I0810 13:51:02.009060 13394 sgd_solver.cpp:106] Iteration 9020, lr = 0.00617436
I0810 13:51:04.797669 13394 solver.cpp:228] Iteration 9030, loss = 0.188746
I0810 13:51:04.797719 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:51:04.797739 13394 solver.cpp:244]     Train net output #1: loss = 0.188746 (* 1 = 0.188746 loss)
I0810 13:51:04.797755 13394 sgd_solver.cpp:106] Iteration 9030, lr = 0.00617193
I0810 13:51:07.625530 13394 solver.cpp:228] Iteration 9040, loss = 0.282462
I0810 13:51:07.625576 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:51:07.625593 13394 solver.cpp:244]     Train net output #1: loss = 0.282462 (* 1 = 0.282462 loss)
I0810 13:51:07.625607 13394 sgd_solver.cpp:106] Iteration 9040, lr = 0.0061695
I0810 13:51:10.448595 13394 solver.cpp:228] Iteration 9050, loss = 0.0625582
I0810 13:51:10.448853 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:51:10.449003 13394 solver.cpp:244]     Train net output #1: loss = 0.062558 (* 1 = 0.062558 loss)
I0810 13:51:10.449019 13394 sgd_solver.cpp:106] Iteration 9050, lr = 0.00616707
I0810 13:51:13.236707 13394 solver.cpp:228] Iteration 9060, loss = 0.250527
I0810 13:51:13.236757 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:51:13.236775 13394 solver.cpp:244]     Train net output #1: loss = 0.250527 (* 1 = 0.250527 loss)
I0810 13:51:13.236791 13394 sgd_solver.cpp:106] Iteration 9060, lr = 0.00616464
I0810 13:51:16.008530 13394 solver.cpp:228] Iteration 9070, loss = 0.157215
I0810 13:51:16.008713 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:51:16.008734 13394 solver.cpp:244]     Train net output #1: loss = 0.157215 (* 1 = 0.157215 loss)
I0810 13:51:16.008749 13394 sgd_solver.cpp:106] Iteration 9070, lr = 0.00616222
I0810 13:51:18.843050 13394 solver.cpp:228] Iteration 9080, loss = 0.0953869
I0810 13:51:18.843096 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:51:18.843114 13394 solver.cpp:244]     Train net output #1: loss = 0.0953867 (* 1 = 0.0953867 loss)
I0810 13:51:18.843132 13394 sgd_solver.cpp:106] Iteration 9080, lr = 0.00615979
I0810 13:51:21.622376 13394 solver.cpp:228] Iteration 9090, loss = 0.281597
I0810 13:51:21.622485 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:51:21.622525 13394 solver.cpp:244]     Train net output #1: loss = 0.281597 (* 1 = 0.281597 loss)
I0810 13:51:21.622560 13394 sgd_solver.cpp:106] Iteration 9090, lr = 0.00615737
I0810 13:51:24.122628 13394 solver.cpp:337] Iteration 9100, Testing net (#0)
I0810 13:51:25.634680 13394 solver.cpp:404]     Test net output #0: accuracy = 0.696875
I0810 13:51:25.634733 13394 solver.cpp:404]     Test net output #1: loss = 0.974702 (* 1 = 0.974702 loss)
I0810 13:51:25.912958 13394 solver.cpp:228] Iteration 9100, loss = 0.283367
I0810 13:51:25.913003 13394 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0810 13:51:25.913022 13394 solver.cpp:244]     Train net output #1: loss = 0.283367 (* 1 = 0.283367 loss)
I0810 13:51:25.913036 13394 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0810 13:51:28.754866 13394 solver.cpp:228] Iteration 9110, loss = 1.49012e-07
I0810 13:51:28.754911 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:51:28.754931 13394 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0810 13:51:28.754946 13394 sgd_solver.cpp:106] Iteration 9110, lr = 0.00615254
I0810 13:51:31.583427 13394 solver.cpp:228] Iteration 9120, loss = 0.187663
I0810 13:51:31.583479 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:51:31.583498 13394 solver.cpp:244]     Train net output #1: loss = 0.187663 (* 1 = 0.187663 loss)
I0810 13:51:31.583514 13394 sgd_solver.cpp:106] Iteration 9120, lr = 0.00615013
I0810 13:51:34.405144 13394 solver.cpp:228] Iteration 9130, loss = 0.250258
I0810 13:51:34.405189 13394 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0810 13:51:34.405208 13394 solver.cpp:244]     Train net output #1: loss = 0.250258 (* 1 = 0.250258 loss)
I0810 13:51:34.405223 13394 sgd_solver.cpp:106] Iteration 9130, lr = 0.00614772
I0810 13:51:37.298137 13394 solver.cpp:228] Iteration 9140, loss = 0.219969
I0810 13:51:37.298246 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:51:37.298288 13394 solver.cpp:244]     Train net output #1: loss = 0.219969 (* 1 = 0.219969 loss)
I0810 13:51:37.298326 13394 sgd_solver.cpp:106] Iteration 9140, lr = 0.00614531
I0810 13:51:40.081739 13394 solver.cpp:228] Iteration 9150, loss = 0.18863
I0810 13:51:40.081790 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:51:40.081805 13394 solver.cpp:244]     Train net output #1: loss = 0.18863 (* 1 = 0.18863 loss)
I0810 13:51:40.081821 13394 sgd_solver.cpp:106] Iteration 9150, lr = 0.0061429
I0810 13:51:42.829874 13394 solver.cpp:228] Iteration 9160, loss = 0.157256
I0810 13:51:42.829921 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:51:42.829939 13394 solver.cpp:244]     Train net output #1: loss = 0.157256 (* 1 = 0.157256 loss)
I0810 13:51:42.829954 13394 sgd_solver.cpp:106] Iteration 9160, lr = 0.0061405
I0810 13:51:45.661248 13394 solver.cpp:228] Iteration 9170, loss = 0.156949
I0810 13:51:45.661296 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:51:45.661315 13394 solver.cpp:244]     Train net output #1: loss = 0.156948 (* 1 = 0.156948 loss)
I0810 13:51:45.661334 13394 sgd_solver.cpp:106] Iteration 9170, lr = 0.00613809
I0810 13:51:48.438441 13394 solver.cpp:228] Iteration 9180, loss = 0.15719
I0810 13:51:48.438592 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:51:48.438613 13394 solver.cpp:244]     Train net output #1: loss = 0.15719 (* 1 = 0.15719 loss)
I0810 13:51:48.438628 13394 sgd_solver.cpp:106] Iteration 9180, lr = 0.00613569
I0810 13:51:51.215888 13394 solver.cpp:228] Iteration 9190, loss = 0.094387
I0810 13:51:51.215932 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:51:51.215950 13394 solver.cpp:244]     Train net output #1: loss = 0.0943869 (* 1 = 0.0943869 loss)
I0810 13:51:51.215965 13394 sgd_solver.cpp:106] Iteration 9190, lr = 0.00613329
I0810 13:51:53.710888 13394 solver.cpp:337] Iteration 9200, Testing net (#0)
I0810 13:51:55.201505 13394 solver.cpp:404]     Test net output #0: accuracy = 0.689062
I0810 13:51:55.201560 13394 solver.cpp:404]     Test net output #1: loss = 0.988652 (* 1 = 0.988652 loss)
I0810 13:51:55.479434 13394 solver.cpp:228] Iteration 9200, loss = 0.0628462
I0810 13:51:55.479480 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:51:55.479499 13394 solver.cpp:244]     Train net output #1: loss = 0.0628461 (* 1 = 0.0628461 loss)
I0810 13:51:55.479516 13394 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0810 13:51:58.261281 13394 solver.cpp:228] Iteration 9210, loss = 0.156601
I0810 13:51:58.261324 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:51:58.261343 13394 solver.cpp:244]     Train net output #1: loss = 0.156601 (* 1 = 0.156601 loss)
I0810 13:51:58.261358 13394 sgd_solver.cpp:106] Iteration 9210, lr = 0.0061285
I0810 13:52:01.045935 13394 solver.cpp:228] Iteration 9220, loss = 0.156379
I0810 13:52:01.045979 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:52:01.045996 13394 solver.cpp:244]     Train net output #1: loss = 0.156379 (* 1 = 0.156379 loss)
I0810 13:52:01.046011 13394 sgd_solver.cpp:106] Iteration 9220, lr = 0.00612611
I0810 13:52:03.896471 13394 solver.cpp:228] Iteration 9230, loss = 0.156514
I0810 13:52:03.896518 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:52:03.896538 13394 solver.cpp:244]     Train net output #1: loss = 0.156514 (* 1 = 0.156514 loss)
I0810 13:52:03.896554 13394 sgd_solver.cpp:106] Iteration 9230, lr = 0.00612372
I0810 13:52:06.662420 13394 solver.cpp:228] Iteration 9240, loss = 0.031397
I0810 13:52:06.662479 13394 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0810 13:52:06.662495 13394 solver.cpp:244]     Train net output #1: loss = 0.0313969 (* 1 = 0.0313969 loss)
I0810 13:52:06.662509 13394 sgd_solver.cpp:106] Iteration 9240, lr = 0.00612134
I0810 13:52:09.499264 13394 solver.cpp:228] Iteration 9250, loss = 0.156464
I0810 13:52:09.499322 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:52:09.499341 13394 solver.cpp:244]     Train net output #1: loss = 0.156464 (* 1 = 0.156464 loss)
I0810 13:52:09.499356 13394 sgd_solver.cpp:106] Iteration 9250, lr = 0.00611895
I0810 13:52:12.260874 13394 solver.cpp:228] Iteration 9260, loss = 0.219172
I0810 13:52:12.260924 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:52:12.260941 13394 solver.cpp:244]     Train net output #1: loss = 0.219172 (* 1 = 0.219172 loss)
I0810 13:52:12.260957 13394 sgd_solver.cpp:106] Iteration 9260, lr = 0.00611657
I0810 13:52:15.050320 13394 solver.cpp:228] Iteration 9270, loss = 0.187919
I0810 13:52:15.050370 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:52:15.050390 13394 solver.cpp:244]     Train net output #1: loss = 0.187919 (* 1 = 0.187919 loss)
I0810 13:52:15.050405 13394 sgd_solver.cpp:106] Iteration 9270, lr = 0.00611419
I0810 13:52:17.801856 13394 solver.cpp:228] Iteration 9280, loss = 0.18788
I0810 13:52:17.801906 13394 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0810 13:52:17.801925 13394 solver.cpp:244]     Train net output #1: loss = 0.187879 (* 1 = 0.187879 loss)
I0810 13:52:17.801941 13394 sgd_solver.cpp:106] Iteration 9280, lr = 0.00611181
I0810 13:52:20.627636 13394 solver.cpp:228] Iteration 9290, loss = 0.156845
I0810 13:52:20.627799 13394 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0810 13:52:20.627820 13394 solver.cpp:244]     Train net output #1: loss = 0.156844 (* 1 = 0.156844 loss)
I0810 13:52:20.627835 13394 sgd_solver.cpp:106] Iteration 9290, lr = 0.00610943
I0810 13:52:23.213268 13394 solver.cpp:337] Iteration 9300, Testing net (#0)
I0810 13:52:24.714679 13394 solver.cpp:404]     Test net output #0: accuracy = 0.685938
I0810 13:52:24.714737 13394 solver.cpp:404]     Test net output #1: loss = 0.997582 (* 1 = 0.997582 loss)
I0810 13:52:24.989706 13394 solver.cpp:228] Iteration 9300, loss = 0.0626774
I0810 13:52:24.989759 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:52:24.989778 13394 solver.cpp:244]     Train net output #1: loss = 0.0626773 (* 1 = 0.0626773 loss)
I0810 13:52:24.989795 13394 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0810 13:52:27.809126 13394 solver.cpp:228] Iteration 9310, loss = 0.0939891
I0810 13:52:27.809224 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:52:27.809267 13394 solver.cpp:244]     Train net output #1: loss = 0.093989 (* 1 = 0.093989 loss)
I0810 13:52:27.809305 13394 sgd_solver.cpp:106] Iteration 9310, lr = 0.00610469
I0810 13:52:30.626226 13394 solver.cpp:228] Iteration 9320, loss = 0.25091
I0810 13:52:30.626284 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:52:30.626302 13394 solver.cpp:244]     Train net output #1: loss = 0.25091 (* 1 = 0.25091 loss)
I0810 13:52:30.626317 13394 sgd_solver.cpp:106] Iteration 9320, lr = 0.00610232
I0810 13:52:33.406525 13394 solver.cpp:228] Iteration 9330, loss = 0.0940806
I0810 13:52:33.406575 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:52:33.406595 13394 solver.cpp:244]     Train net output #1: loss = 0.0940805 (* 1 = 0.0940805 loss)
I0810 13:52:33.406610 13394 sgd_solver.cpp:106] Iteration 9330, lr = 0.00609995
I0810 13:52:36.158430 13394 solver.cpp:228] Iteration 9340, loss = 0.0627397
I0810 13:52:36.158474 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:52:36.158493 13394 solver.cpp:244]     Train net output #1: loss = 0.0627396 (* 1 = 0.0627396 loss)
I0810 13:52:36.158509 13394 sgd_solver.cpp:106] Iteration 9340, lr = 0.00609758
I0810 13:52:38.919950 13394 solver.cpp:228] Iteration 9350, loss = 0.0942334
I0810 13:52:38.919991 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:52:38.920007 13394 solver.cpp:244]     Train net output #1: loss = 0.0942332 (* 1 = 0.0942332 loss)
I0810 13:52:38.920020 13394 sgd_solver.cpp:106] Iteration 9350, lr = 0.00609522
I0810 13:52:41.640625 13394 solver.cpp:228] Iteration 9360, loss = 0.0631523
I0810 13:52:41.640671 13394 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0810 13:52:41.640688 13394 solver.cpp:244]     Train net output #1: loss = 0.0631522 (* 1 = 0.0631522 loss)
I0810 13:52:41.640703 13394 sgd_solver.cpp:106] Iteration 9360, lr = 0.00609286
I0810 13:52:44.376090 13394 solver.cpp:228] Iteration 9370, loss = 0.281506
I0810 13:52:44.376137 13394 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0810 13:52:44.376157 13394 solver.cpp:244]     Train net output #1: loss = 0.281506 (* 1 = 0.281506 loss)
I0810 13:52:44.376173 13394 sgd_solver.cpp:106] Iteration 9370, lr = 0.0060905
I0810 13:52:47.159886 13394 solver.cpp:228] Iteration 9380, loss = 0.125154
I0810 13:52:47.159996 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:52:47.160039 13394 solver.cpp:244]     Train net output #1: loss = 0.125154 (* 1 = 0.125154 loss)
I0810 13:52:47.160079 13394 sgd_solver.cpp:106] Iteration 9380, lr = 0.00608814
I0810 13:52:49.960953 13394 solver.cpp:228] Iteration 9390, loss = 0.313395
I0810 13:52:49.961058 13394 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0810 13:52:49.961102 13394 solver.cpp:244]     Train net output #1: loss = 0.313395 (* 1 = 0.313395 loss)
I0810 13:52:49.961141 13394 sgd_solver.cpp:106] Iteration 9390, lr = 0.00608579
I0810 13:52:52.472178 13394 solver.cpp:337] Iteration 9400, Testing net (#0)
I0810 13:52:53.999413 13394 solver.cpp:404]     Test net output #0: accuracy = 0.695312
I0810 13:52:53.999462 13394 solver.cpp:404]     Test net output #1: loss = 0.969173 (* 1 = 0.969173 loss)
I0810 13:52:54.276259 13394 solver.cpp:228] Iteration 9400, loss = 0.218906
I0810 13:52:54.276350 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:52:54.276383 13394 solver.cpp:244]     Train net output #1: loss = 0.218906 (* 1 = 0.218906 loss)
I0810 13:52:54.276413 13394 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0810 13:52:57.032878 13394 solver.cpp:228] Iteration 9410, loss = 0.125102
I0810 13:52:57.032923 13394 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0810 13:52:57.032941 13394 solver.cpp:244]     Train net output #1: loss = 0.125102 (* 1 = 0.125102 loss)
I0810 13:52:57.032958 13394 sgd_solver.cpp:106] Iteration 9410, lr = 0.00608108
I0810 13:52:59.806360 13394 solver.cpp:228] Iteration 9420, loss = 0.21915
I0810 13:52:59.806633 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:52:59.806650 13394 solver.cpp:244]     Train net output #1: loss = 0.21915 (* 1 = 0.21915 loss)
I0810 13:52:59.806663 13394 sgd_solver.cpp:106] Iteration 9420, lr = 0.00607873
I0810 13:53:02.637472 13394 solver.cpp:228] Iteration 9430, loss = 0.250359
I0810 13:53:02.637518 13394 solver.cpp:244]     Train net output #0: accuracy = 1
I0810 13:53:02.637534 13394 solver.cpp:244]     Train net output #1: loss = 0.250359 (* 1 = 0.250359 loss)
I0810 13:53:02.637547 13394 sgd_solver.cpp:106] Iteration 9430, lr = 0.00607639
I0810 13:53:05.517938 13394 solver.cpp:228] Iteration 9440, loss = 0.218926
I0810 13:53:05.517989 13394 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0810 13:53:05.518008 13394 solver.cpp:244]     Train net output #1: loss = 0.218926 (* 1 = 0.218926 loss)
I0810 13:53:05.518023 13394 sgd_solver.cpp:106] Iteration 9440, lr = 0.00607404
