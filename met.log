I0813 23:14:22.191594 21738 caffe.cpp:178] Use CPU.
I0813 23:14:22.192165 21738 solver.cpp:48] Initializing solver from parameters: 
train_net: "examples/scene/metNetTrain.prototxt"
test_net: "examples/scene/metNetTest.prototxt"
test_iter: 10
test_interval: 100
base_lr: 0.01
display: 50
max_iter: 300000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.02
snapshot: 10000
snapshot_prefix: "examples/scene/scene_met"
solver_mode: CPU
I0813 23:14:22.192385 21738 solver.cpp:81] Creating training net from train_net file: examples/scene/metNetTrain.prototxt
I0813 23:14:22.202103 21738 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 1
    mirror: false
  }
  data_param {
    source: "/home/shaogang/Datasets/FeatsDB/featsTrain20k"
    batch_size: 200
    backend: LMDB
  }
}
layer {
  name: "th"
  type: "Threshold"
  bottom: "label"
  top: "th"
  threshold_param {
    threshold: 0
  }
}
layer {
  name: "i1"
  type: "Slice"
  bottom: "data"
  top: "i1"
  top: "i2"
  top: "i3"
  top: "i4"
  top: "i5"
  top: "i6"
  top: "i7"
  top: "i8"
  top: "i9"
  top: "i10"
  top: "i11"
  top: "i12"
  top: "i13"
  top: "i14"
  top: "i15"
  top: "i16"
  top: "i17"
  top: "i18"
  top: "i19"
  top: "i20"
  slice_param {
    slice_dim: 2
    slice_point: 1
    slice_point: 2
    slice_point: 3
    slice_point: 4
    slice_point: 5
    slice_point: 6
    slice_point: 7
    slice_point: 8
    slice_point: 9
    slice_point: 10
    slice_point: 11
    slice_point: 12
    slice_point: 13
    slice_point: 14
    slice_point: 15
    slice_point: 16
    slice_point: 17
    slice_point: 18
    slice_point: 19
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "i1"
  bottom: "i11"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Concat1"
  top: "InnerProduct1"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct1"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "Dropout1"
  top: "InnerProduct2"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "InnerProduct2"
  top: "InnerProduct2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct2"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m1"
  type: "InnerProduct"
  bottom: "Dropout2"
  top: "m1"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "i1"
  bottom: "i12"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "Concat2"
  top: "InnerProduct3"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct3"
  top: "InnerProduct3"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct3"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "Dropout3"
  top: "InnerProduct4"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "InnerProduct4"
  top: "InnerProduct4"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct4"
  top: "Dropout4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m2"
  type: "InnerProduct"
  bottom: "Dropout4"
  top: "m2"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "i1"
  bottom: "i13"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct5"
  type: "InnerProduct"
  bottom: "Concat3"
  top: "InnerProduct5"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "InnerProduct5"
  top: "InnerProduct5"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct5"
  top: "Dropout5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct6"
  type: "InnerProduct"
  bottom: "Dropout5"
  top: "InnerProduct6"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "InnerProduct6"
  top: "InnerProduct6"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct6"
  top: "Dropout6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m3"
  type: "InnerProduct"
  bottom: "Dropout6"
  top: "m3"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "i1"
  bottom: "i14"
  top: "Concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct7"
  type: "InnerProduct"
  bottom: "Concat4"
  top: "InnerProduct7"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "InnerProduct7"
  top: "InnerProduct7"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct7"
  top: "Dropout7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct8"
  type: "InnerProduct"
  bottom: "Dropout7"
  top: "InnerProduct8"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "InnerProduct8"
  top: "InnerProduct8"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct8"
  top: "Dropout8"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m4"
  type: "InnerProduct"
  bottom: "Dropout8"
  top: "m4"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "i1"
  bottom: "i15"
  top: "Concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct9"
  type: "InnerProduct"
  bottom: "Concat5"
  top: "InnerProduct9"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "InnerProduct9"
  top: "InnerProduct9"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct9"
  top: "Dropout9"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct10"
  type: "InnerProduct"
  bottom: "Dropout9"
  top: "InnerProduct10"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "InnerProduct10"
  top: "InnerProduct10"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct10"
  top: "Dropout10"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m5"
  type: "InnerProduct"
  bottom: "Dropout10"
  top: "m5"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "i1"
  bottom: "i16"
  top: "Concat6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct11"
  type: "InnerProduct"
  bottom: "Concat6"
  top: "InnerProduct11"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "InnerProduct11"
  top: "InnerProduct11"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct11"
  top: "Dropout11"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct12"
  type: "InnerProduct"
  bottom: "Dropout11"
  top: "InnerProduct12"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "InnerProduct12"
  top: "InnerProduct12"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct12"
  top: "Dropout12"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m6"
  type: "InnerProduct"
  bottom: "Dropout12"
  top: "m6"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "i1"
  bottom: "i17"
  top: "Concat7"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct13"
  type: "InnerProduct"
  bottom: "Concat7"
  top: "InnerProduct13"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "InnerProduct13"
  top: "InnerProduct13"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct13"
  top: "Dropout13"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct14"
  type: "InnerProduct"
  bottom: "Dropout13"
  top: "InnerProduct14"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "InnerProduct14"
  top: "InnerProduct14"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct14"
  top: "Dropout14"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m7"
  type: "InnerProduct"
  bottom: "Dropout14"
  top: "m7"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "i1"
  bottom: "i18"
  top: "Concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct15"
  type: "InnerProduct"
  bottom: "Concat8"
  top: "InnerProduct15"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "InnerProduct15"
  top: "InnerProduct15"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct15"
  top: "Dropout15"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct16"
  type: "InnerProduct"
  bottom: "Dropout15"
  top: "InnerProduct16"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "InnerProduct16"
  top: "InnerProduct16"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct16"
  top: "Dropout16"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m8"
  type: "InnerProduct"
  bottom: "Dropout16"
  top: "m8"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "i1"
  bottom: "i19"
  top: "Concat9"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct17"
  type: "InnerProduct"
  bottom: "Concat9"
  top: "InnerProduct17"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "InnerProduct17"
  top: "InnerProduct17"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct17"
  top: "Dropout17"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct18"
  type: "InnerProduct"
  bottom: "Dropout17"
  top: "InnerProduct18"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "InnerProduct18"
  top: "InnerProduct18"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct18"
  top: "Dropout18"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m9"
  type: "InnerProduct"
  bottom: "Dropout18"
  top: "m9"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat10"
  type: "Concat"
  bottom: "i1"
  bottom: "i20"
  top: "Concat10"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct19"
  type: "InnerProduct"
  bottom: "Concat10"
  top: "InnerProduct19"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "InnerProduct19"
  top: "InnerProduct19"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct19"
  top: "Dropout19"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct20"
  type: "InnerProduct"
  bottom: "Dropout19"
  top: "InnerProduct20"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "InnerProduct20"
  top: "InnerProduct20"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct20"
  top: "Dropout20"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m10"
  type: "InnerProduct"
  bottom: "Dropout20"
  top: "m10"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat11"
  type: "Concat"
  bottom: "i2"
  bottom: "i11"
  top: "Concat11"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct21"
  type: "InnerProduct"
  bottom: "Concat11"
  top: "InnerProduct21"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "InnerProduct21"
  top: "InnerProduct21"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct21"
  top: "Dropout21"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct22"
  type: "InnerProduct"
  bottom: "Dropout21"
  top: "InnerProduct22"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "InnerProduct22"
  top: "InnerProduct22"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct22"
  top: "Dropout22"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m11"
  type: "InnerProduct"
  bottom: "Dropout22"
  top: "m11"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat12"
  type: "Concat"
  bottom: "i3"
  bottom: "i11"
  top: "Concat12"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct23"
  type: "InnerProduct"
  bottom: "Concat12"
  top: "InnerProduct23"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "InnerProduct23"
  top: "InnerProduct23"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct23"
  top: "Dropout23"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct24"
  type: "InnerProduct"
  bottom: "Dropout23"
  top: "InnerProduct24"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "InnerProduct24"
  top: "InnerProduct24"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct24"
  top: "Dropout24"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m12"
  type: "InnerProduct"
  bottom: "Dropout24"
  top: "m12"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat13"
  type: "Concat"
  bottom: "i4"
  bottom: "i11"
  top: "Concat13"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct25"
  type: "InnerProduct"
  bottom: "Concat13"
  top: "InnerProduct25"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "InnerProduct25"
  top: "InnerProduct25"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct25"
  top: "Dropout25"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct26"
  type: "InnerProduct"
  bottom: "Dropout25"
  top: "InnerProduct26"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "InnerProduct26"
  top: "InnerProduct26"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct26"
  top: "Dropout26"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m13"
  type: "InnerProduct"
  bottom: "Dropout26"
  top: "m13"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat14"
  type: "Concat"
  bottom: "i5"
  bottom: "i11"
  top: "Concat14"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct27"
  type: "InnerProduct"
  bottom: "Concat14"
  top: "InnerProduct27"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "InnerProduct27"
  top: "InnerProduct27"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct27"
  top: "Dropout27"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct28"
  type: "InnerProduct"
  bottom: "Dropout27"
  top: "InnerProduct28"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "InnerProduct28"
  top: "InnerProduct28"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct28"
  top: "Dropout28"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m14"
  type: "InnerProduct"
  bottom: "Dropout28"
  top: "m14"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat15"
  type: "Concat"
  bottom: "i6"
  bottom: "i11"
  top: "Concat15"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct29"
  type: "InnerProduct"
  bottom: "Concat15"
  top: "InnerProduct29"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "InnerProduct29"
  top: "InnerProduct29"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct29"
  top: "Dropout29"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct30"
  type: "InnerProduct"
  bottom: "Dropout29"
  top: "InnerProduct30"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "InnerProduct30"
  top: "InnerProduct30"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct30"
  top: "Dropout30"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m15"
  type: "InnerProduct"
  bottom: "Dropout30"
  top: "m15"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat16"
  type: "Concat"
  bottom: "i7"
  bottom: "i11"
  top: "Concat16"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct31"
  type: "InnerProduct"
  bottom: "Concat16"
  top: "InnerProduct31"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "InnerProduct31"
  top: "InnerProduct31"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct31"
  top: "Dropout31"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct32"
  type: "InnerProduct"
  bottom: "Dropout31"
  top: "InnerProduct32"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "InnerProduct32"
  top: "InnerProduct32"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct32"
  top: "Dropout32"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m16"
  type: "InnerProduct"
  bottom: "Dropout32"
  top: "m16"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat17"
  type: "Concat"
  bottom: "i8"
  bottom: "i11"
  top: "Concat17"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct33"
  type: "InnerProduct"
  bottom: "Concat17"
  top: "InnerProduct33"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "InnerProduct33"
  top: "InnerProduct33"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct33"
  top: "Dropout33"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct34"
  type: "InnerProduct"
  bottom: "Dropout33"
  top: "InnerProduct34"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "InnerProduct34"
  top: "InnerProduct34"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct34"
  top: "Dropout34"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m17"
  type: "InnerProduct"
  bottom: "Dropout34"
  top: "m17"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat18"
  type: "Concat"
  bottom: "i9"
  bottom: "i11"
  top: "Concat18"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct35"
  type: "InnerProduct"
  bottom: "Concat18"
  top: "InnerProduct35"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "InnerProduct35"
  top: "InnerProduct35"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct35"
  top: "Dropout35"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct36"
  type: "InnerProduct"
  bottom: "Dropout35"
  top: "InnerProduct36"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "InnerProduct36"
  top: "InnerProduct36"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct36"
  top: "Dropout36"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m18"
  type: "InnerProduct"
  bottom: "Dropout36"
  top: "m18"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat19"
  type: "Concat"
  bottom: "i10"
  bottom: "i11"
  top: "Concat19"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct37"
  type: "InnerProduct"
  bottom: "Concat19"
  top: "InnerProduct37"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU3
I0813 23:14:22.204566 21738 layer_factory.hpp:77] Creating layer data
I0813 23:14:22.206110 21738 net.cpp:91] Creating Layer data
I0813 23:14:22.206146 21738 net.cpp:399] data -> data
I0813 23:14:22.206229 21738 net.cpp:399] data -> label
I0813 23:14:22.206362 21742 db_lmdb.cpp:35] Opened lmdb /home/shaogang/Datasets/FeatsDB/featsTrain20k
I0813 23:14:22.207762 21738 data_layer.cpp:41] output data size: 200,1,20,4096
I0813 23:14:22.302897 21738 net.cpp:141] Setting up data
I0813 23:14:22.302973 21738 net.cpp:148] Top shape: 200 1 20 4096 (16384000)
I0813 23:14:22.302986 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.302994 21738 net.cpp:156] Memory required for data: 65536800
I0813 23:14:22.303016 21738 layer_factory.hpp:77] Creating layer label_data_1_split
I0813 23:14:22.303043 21738 net.cpp:91] Creating Layer label_data_1_split
I0813 23:14:22.303057 21738 net.cpp:425] label_data_1_split <- label
I0813 23:14:22.303077 21738 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0813 23:14:22.303100 21738 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0813 23:14:22.303144 21738 net.cpp:141] Setting up label_data_1_split
I0813 23:14:22.303159 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.303167 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.303174 21738 net.cpp:156] Memory required for data: 65538400
I0813 23:14:22.303189 21738 layer_factory.hpp:77] Creating layer th
I0813 23:14:22.303206 21738 net.cpp:91] Creating Layer th
I0813 23:14:22.303215 21738 net.cpp:425] th <- label_data_1_split_0
I0813 23:14:22.303227 21738 net.cpp:399] th -> th
I0813 23:14:22.303246 21738 net.cpp:141] Setting up th
I0813 23:14:22.303256 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.303262 21738 net.cpp:156] Memory required for data: 65539200
I0813 23:14:22.303269 21738 layer_factory.hpp:77] Creating layer th_th_0_split
I0813 23:14:22.303280 21738 net.cpp:91] Creating Layer th_th_0_split
I0813 23:14:22.303288 21738 net.cpp:425] th_th_0_split <- th
I0813 23:14:22.303298 21738 net.cpp:399] th_th_0_split -> th_th_0_split_0
I0813 23:14:22.303310 21738 net.cpp:399] th_th_0_split -> th_th_0_split_1
I0813 23:14:22.303323 21738 net.cpp:141] Setting up th_th_0_split
I0813 23:14:22.303333 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.303375 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.303382 21738 net.cpp:156] Memory required for data: 65540800
I0813 23:14:22.303390 21738 layer_factory.hpp:77] Creating layer i1
I0813 23:14:22.303418 21738 net.cpp:91] Creating Layer i1
I0813 23:14:22.303429 21738 net.cpp:425] i1 <- data
I0813 23:14:22.303444 21738 net.cpp:399] i1 -> i1
I0813 23:14:22.303467 21738 net.cpp:399] i1 -> i2
I0813 23:14:22.303488 21738 net.cpp:399] i1 -> i3
I0813 23:14:22.303506 21738 net.cpp:399] i1 -> i4
I0813 23:14:22.303519 21738 net.cpp:399] i1 -> i5
I0813 23:14:22.303535 21738 net.cpp:399] i1 -> i6
I0813 23:14:22.303550 21738 net.cpp:399] i1 -> i7
I0813 23:14:22.303565 21738 net.cpp:399] i1 -> i8
I0813 23:14:22.303580 21738 net.cpp:399] i1 -> i9
I0813 23:14:22.303596 21738 net.cpp:399] i1 -> i10
I0813 23:14:22.303616 21738 net.cpp:399] i1 -> i11
I0813 23:14:22.303632 21738 net.cpp:399] i1 -> i12
I0813 23:14:22.303645 21738 net.cpp:399] i1 -> i13
I0813 23:14:22.303660 21738 net.cpp:399] i1 -> i14
I0813 23:14:22.303678 21738 net.cpp:399] i1 -> i15
I0813 23:14:22.303691 21738 net.cpp:399] i1 -> i16
I0813 23:14:22.303704 21738 net.cpp:399] i1 -> i17
I0813 23:14:22.303719 21738 net.cpp:399] i1 -> i18
I0813 23:14:22.303736 21738 net.cpp:399] i1 -> i19
I0813 23:14:22.303750 21738 net.cpp:399] i1 -> i20
I0813 23:14:22.303784 21738 net.cpp:141] Setting up i1
I0813 23:14:22.303797 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303805 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303813 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303822 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303828 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303835 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303843 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303851 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303859 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303867 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303874 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303882 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303889 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303896 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303905 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303912 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303920 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303927 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303935 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303941 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.303948 21738 net.cpp:156] Memory required for data: 131076800
I0813 23:14:22.303956 21738 layer_factory.hpp:77] Creating layer i1_i1_0_split
I0813 23:14:22.303969 21738 net.cpp:91] Creating Layer i1_i1_0_split
I0813 23:14:22.303975 21738 net.cpp:425] i1_i1_0_split <- i1
I0813 23:14:22.303987 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_0
I0813 23:14:22.303999 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_1
I0813 23:14:22.304011 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_2
I0813 23:14:22.304023 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_3
I0813 23:14:22.304059 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_4
I0813 23:14:22.304093 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_5
I0813 23:14:22.304121 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_6
I0813 23:14:22.304132 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_7
I0813 23:14:22.304144 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_8
I0813 23:14:22.304157 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_9
I0813 23:14:22.304178 21738 net.cpp:141] Setting up i1_i1_0_split
I0813 23:14:22.304193 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304201 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304225 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304232 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304240 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304249 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304255 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304263 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304271 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304278 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304285 21738 net.cpp:156] Memory required for data: 163844800
I0813 23:14:22.304291 21738 layer_factory.hpp:77] Creating layer i11_i1_10_split
I0813 23:14:22.304304 21738 net.cpp:91] Creating Layer i11_i1_10_split
I0813 23:14:22.304311 21738 net.cpp:425] i11_i1_10_split <- i11
I0813 23:14:22.304323 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_0
I0813 23:14:22.304335 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_1
I0813 23:14:22.304357 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_2
I0813 23:14:22.304368 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_3
I0813 23:14:22.304379 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_4
I0813 23:14:22.304390 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_5
I0813 23:14:22.304402 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_6
I0813 23:14:22.304414 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_7
I0813 23:14:22.304425 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_8
I0813 23:14:22.304437 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_9
I0813 23:14:22.304455 21738 net.cpp:141] Setting up i11_i1_10_split
I0813 23:14:22.304464 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304472 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304479 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304486 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304493 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304500 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304508 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304515 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304522 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304529 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.304535 21738 net.cpp:156] Memory required for data: 196612800
I0813 23:14:22.304543 21738 layer_factory.hpp:77] Creating layer Concat1
I0813 23:14:22.304555 21738 net.cpp:91] Creating Layer Concat1
I0813 23:14:22.304563 21738 net.cpp:425] Concat1 <- i1_i1_0_split_0
I0813 23:14:22.304571 21738 net.cpp:425] Concat1 <- i11_i1_10_split_0
I0813 23:14:22.304582 21738 net.cpp:399] Concat1 -> Concat1
I0813 23:14:22.304602 21738 net.cpp:141] Setting up Concat1
I0813 23:14:22.304611 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.304617 21738 net.cpp:156] Memory required for data: 203166400
I0813 23:14:22.304623 21738 layer_factory.hpp:77] Creating layer InnerProduct1
I0813 23:14:22.304642 21738 net.cpp:91] Creating Layer InnerProduct1
I0813 23:14:22.304648 21738 net.cpp:425] InnerProduct1 <- Concat1
I0813 23:14:22.304661 21738 net.cpp:399] InnerProduct1 -> InnerProduct1
I0813 23:14:22.338968 21738 net.cpp:141] Setting up InnerProduct1
I0813 23:14:22.339023 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.339035 21738 net.cpp:156] Memory required for data: 203371200
I0813 23:14:22.339067 21738 layer_factory.hpp:77] Creating layer ReLU1
I0813 23:14:22.339092 21738 net.cpp:91] Creating Layer ReLU1
I0813 23:14:22.339103 21738 net.cpp:425] ReLU1 <- InnerProduct1
I0813 23:14:22.339118 21738 net.cpp:386] ReLU1 -> InnerProduct1 (in-place)
I0813 23:14:22.339138 21738 net.cpp:141] Setting up ReLU1
I0813 23:14:22.339146 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.339154 21738 net.cpp:156] Memory required for data: 203576000
I0813 23:14:22.339207 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.339236 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.339243 21738 net.cpp:425] drop1 <- InnerProduct1
I0813 23:14:22.339256 21738 net.cpp:399] drop1 -> Dropout1
I0813 23:14:22.339280 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.339300 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.339308 21738 net.cpp:156] Memory required for data: 203780800
I0813 23:14:22.339314 21738 layer_factory.hpp:77] Creating layer InnerProduct2
I0813 23:14:22.339332 21738 net.cpp:91] Creating Layer InnerProduct2
I0813 23:14:22.339340 21738 net.cpp:425] InnerProduct2 <- Dropout1
I0813 23:14:22.339354 21738 net.cpp:399] InnerProduct2 -> InnerProduct2
I0813 23:14:22.339881 21738 net.cpp:141] Setting up InnerProduct2
I0813 23:14:22.339901 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.339910 21738 net.cpp:156] Memory required for data: 203883200
I0813 23:14:22.339926 21738 layer_factory.hpp:77] Creating layer ReLU2
I0813 23:14:22.339938 21738 net.cpp:91] Creating Layer ReLU2
I0813 23:14:22.339946 21738 net.cpp:425] ReLU2 <- InnerProduct2
I0813 23:14:22.339958 21738 net.cpp:386] ReLU2 -> InnerProduct2 (in-place)
I0813 23:14:22.339972 21738 net.cpp:141] Setting up ReLU2
I0813 23:14:22.339980 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.339987 21738 net.cpp:156] Memory required for data: 203985600
I0813 23:14:22.339993 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.340005 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.340013 21738 net.cpp:425] drop2 <- InnerProduct2
I0813 23:14:22.340039 21738 net.cpp:399] drop2 -> Dropout2
I0813 23:14:22.340055 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.340065 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.340072 21738 net.cpp:156] Memory required for data: 204088000
I0813 23:14:22.340080 21738 layer_factory.hpp:77] Creating layer m1
I0813 23:14:22.340095 21738 net.cpp:91] Creating Layer m1
I0813 23:14:22.340103 21738 net.cpp:425] m1 <- Dropout2
I0813 23:14:22.340116 21738 net.cpp:399] m1 -> m1
I0813 23:14:22.340143 21738 net.cpp:141] Setting up m1
I0813 23:14:22.340154 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.340162 21738 net.cpp:156] Memory required for data: 204088800
I0813 23:14:22.340175 21738 layer_factory.hpp:77] Creating layer Concat2
I0813 23:14:22.340190 21738 net.cpp:91] Creating Layer Concat2
I0813 23:14:22.340198 21738 net.cpp:425] Concat2 <- i1_i1_0_split_1
I0813 23:14:22.340209 21738 net.cpp:425] Concat2 <- i12
I0813 23:14:22.340221 21738 net.cpp:399] Concat2 -> Concat2
I0813 23:14:22.340239 21738 net.cpp:141] Setting up Concat2
I0813 23:14:22.340248 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.340255 21738 net.cpp:156] Memory required for data: 210642400
I0813 23:14:22.340262 21738 layer_factory.hpp:77] Creating layer InnerProduct3
I0813 23:14:22.340281 21738 net.cpp:91] Creating Layer InnerProduct3
I0813 23:14:22.340292 21738 net.cpp:425] InnerProduct3 <- Concat2
I0813 23:14:22.340318 21738 net.cpp:399] InnerProduct3 -> InnerProduct3
I0813 23:14:22.374928 21738 net.cpp:141] Setting up InnerProduct3
I0813 23:14:22.374989 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.374999 21738 net.cpp:156] Memory required for data: 210847200
I0813 23:14:22.375016 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.375030 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.375041 21738 layer_factory.hpp:77] Creating layer ReLU3
I0813 23:14:22.375062 21738 net.cpp:91] Creating Layer ReLU3
I0813 23:14:22.375108 21738 net.cpp:425] ReLU3 <- InnerProduct3
I0813 23:14:22.375144 21738 net.cpp:386] ReLU3 -> InnerProduct3 (in-place)
I0813 23:14:22.375171 21738 net.cpp:141] Setting up ReLU3
I0813 23:14:22.375187 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.375196 21738 net.cpp:156] Memory required for data: 211052000
I0813 23:14:22.375208 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.375257 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.375267 21738 net.cpp:425] drop1 <- InnerProduct3
I0813 23:14:22.375283 21738 net.cpp:399] drop1 -> Dropout3
I0813 23:14:22.375305 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.375320 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.375329 21738 net.cpp:156] Memory required for data: 211256800
I0813 23:14:22.375337 21738 layer_factory.hpp:77] Creating layer InnerProduct4
I0813 23:14:22.375356 21738 net.cpp:91] Creating Layer InnerProduct4
I0813 23:14:22.375365 21738 net.cpp:425] InnerProduct4 <- Dropout3
I0813 23:14:22.375381 21738 net.cpp:399] InnerProduct4 -> InnerProduct4
I0813 23:14:22.375970 21738 net.cpp:141] Setting up InnerProduct4
I0813 23:14:22.375993 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.376001 21738 net.cpp:156] Memory required for data: 211359200
I0813 23:14:22.376019 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.376065 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.376075 21738 layer_factory.hpp:77] Creating layer ReLU4
I0813 23:14:22.376090 21738 net.cpp:91] Creating Layer ReLU4
I0813 23:14:22.376099 21738 net.cpp:425] ReLU4 <- InnerProduct4
I0813 23:14:22.376113 21738 net.cpp:386] ReLU4 -> InnerProduct4 (in-place)
I0813 23:14:22.376129 21738 net.cpp:141] Setting up ReLU4
I0813 23:14:22.376139 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.376150 21738 net.cpp:156] Memory required for data: 211461600
I0813 23:14:22.376158 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.376173 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.376180 21738 net.cpp:425] drop2 <- InnerProduct4
I0813 23:14:22.376194 21738 net.cpp:399] drop2 -> Dropout4
I0813 23:14:22.376211 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.376222 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.376230 21738 net.cpp:156] Memory required for data: 211564000
I0813 23:14:22.376238 21738 layer_factory.hpp:77] Creating layer m2
I0813 23:14:22.376255 21738 net.cpp:91] Creating Layer m2
I0813 23:14:22.376262 21738 net.cpp:425] m2 <- Dropout4
I0813 23:14:22.376277 21738 net.cpp:399] m2 -> m2
I0813 23:14:22.376312 21738 net.cpp:141] Setting up m2
I0813 23:14:22.376327 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.376337 21738 net.cpp:156] Memory required for data: 211564800
I0813 23:14:22.376345 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.376356 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.376364 21738 layer_factory.hpp:77] Creating layer Concat3
I0813 23:14:22.376379 21738 net.cpp:91] Creating Layer Concat3
I0813 23:14:22.376390 21738 net.cpp:425] Concat3 <- i1_i1_0_split_2
I0813 23:14:22.376404 21738 net.cpp:425] Concat3 <- i13
I0813 23:14:22.376417 21738 net.cpp:399] Concat3 -> Concat3
I0813 23:14:22.376436 21738 net.cpp:141] Setting up Concat3
I0813 23:14:22.376447 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.376456 21738 net.cpp:156] Memory required for data: 218118400
I0813 23:14:22.376464 21738 layer_factory.hpp:77] Creating layer InnerProduct5
I0813 23:14:22.376482 21738 net.cpp:91] Creating Layer InnerProduct5
I0813 23:14:22.376490 21738 net.cpp:425] InnerProduct5 <- Concat3
I0813 23:14:22.376504 21738 net.cpp:399] InnerProduct5 -> InnerProduct5
I0813 23:14:22.393599 21743 blocking_queue.cpp:50] Waiting for data
I0813 23:14:22.411628 21738 net.cpp:141] Setting up InnerProduct5
I0813 23:14:22.411677 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.411690 21738 net.cpp:156] Memory required for data: 218323200
I0813 23:14:22.411705 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.411716 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.411725 21738 layer_factory.hpp:77] Creating layer ReLU5
I0813 23:14:22.411775 21738 net.cpp:91] Creating Layer ReLU5
I0813 23:14:22.411788 21738 net.cpp:425] ReLU5 <- InnerProduct5
I0813 23:14:22.411803 21738 net.cpp:386] ReLU5 -> InnerProduct5 (in-place)
I0813 23:14:22.411823 21738 net.cpp:141] Setting up ReLU5
I0813 23:14:22.411834 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.411841 21738 net.cpp:156] Memory required for data: 218528000
I0813 23:14:22.411849 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.411864 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.411871 21738 net.cpp:425] drop1 <- InnerProduct5
I0813 23:14:22.411883 21738 net.cpp:399] drop1 -> Dropout5
I0813 23:14:22.411900 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.411911 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.411918 21738 net.cpp:156] Memory required for data: 218732800
I0813 23:14:22.411926 21738 layer_factory.hpp:77] Creating layer InnerProduct6
I0813 23:14:22.411942 21738 net.cpp:91] Creating Layer InnerProduct6
I0813 23:14:22.411950 21738 net.cpp:425] InnerProduct6 <- Dropout5
I0813 23:14:22.411963 21738 net.cpp:399] InnerProduct6 -> InnerProduct6
I0813 23:14:22.412467 21738 net.cpp:141] Setting up InnerProduct6
I0813 23:14:22.412485 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.412492 21738 net.cpp:156] Memory required for data: 218835200
I0813 23:14:22.412500 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.412509 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.412518 21738 layer_factory.hpp:77] Creating layer ReLU6
I0813 23:14:22.412528 21738 net.cpp:91] Creating Layer ReLU6
I0813 23:14:22.412535 21738 net.cpp:425] ReLU6 <- InnerProduct6
I0813 23:14:22.412546 21738 net.cpp:386] ReLU6 -> InnerProduct6 (in-place)
I0813 23:14:22.412559 21738 net.cpp:141] Setting up ReLU6
I0813 23:14:22.412569 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.412575 21738 net.cpp:156] Memory required for data: 218937600
I0813 23:14:22.412582 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.412592 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.412600 21738 net.cpp:425] drop2 <- InnerProduct6
I0813 23:14:22.412609 21738 net.cpp:399] drop2 -> Dropout6
I0813 23:14:22.412622 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.412632 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.412638 21738 net.cpp:156] Memory required for data: 219040000
I0813 23:14:22.412645 21738 layer_factory.hpp:77] Creating layer m3
I0813 23:14:22.412662 21738 net.cpp:91] Creating Layer m3
I0813 23:14:22.412669 21738 net.cpp:425] m3 <- Dropout6
I0813 23:14:22.412681 21738 net.cpp:399] m3 -> m3
I0813 23:14:22.412724 21738 net.cpp:141] Setting up m3
I0813 23:14:22.412735 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.412744 21738 net.cpp:156] Memory required for data: 219040800
I0813 23:14:22.412758 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.412767 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.412775 21738 layer_factory.hpp:77] Creating layer Concat4
I0813 23:14:22.412788 21738 net.cpp:91] Creating Layer Concat4
I0813 23:14:22.412797 21738 net.cpp:425] Concat4 <- i1_i1_0_split_3
I0813 23:14:22.412806 21738 net.cpp:425] Concat4 <- i14
I0813 23:14:22.412817 21738 net.cpp:399] Concat4 -> Concat4
I0813 23:14:22.412834 21738 net.cpp:141] Setting up Concat4
I0813 23:14:22.412843 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.412850 21738 net.cpp:156] Memory required for data: 225594400
I0813 23:14:22.412858 21738 layer_factory.hpp:77] Creating layer InnerProduct7
I0813 23:14:22.412878 21738 net.cpp:91] Creating Layer InnerProduct7
I0813 23:14:22.412884 21738 net.cpp:425] InnerProduct7 <- Concat4
I0813 23:14:22.412896 21738 net.cpp:399] InnerProduct7 -> InnerProduct7
I0813 23:14:22.441792 21738 net.cpp:141] Setting up InnerProduct7
I0813 23:14:22.441841 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.441891 21738 net.cpp:156] Memory required for data: 225799200
I0813 23:14:22.441949 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.442005 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.442056 21738 layer_factory.hpp:77] Creating layer ReLU7
I0813 23:14:22.442106 21738 net.cpp:91] Creating Layer ReLU7
I0813 23:14:22.442153 21738 net.cpp:425] ReLU7 <- InnerProduct7
I0813 23:14:22.442201 21738 net.cpp:386] ReLU7 -> InnerProduct7 (in-place)
I0813 23:14:22.442258 21738 net.cpp:141] Setting up ReLU7
I0813 23:14:22.442309 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.442345 21738 net.cpp:156] Memory required for data: 226004000
I0813 23:14:22.442378 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.442421 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.442437 21738 net.cpp:425] drop1 <- InnerProduct7
I0813 23:14:22.442456 21738 net.cpp:399] drop1 -> Dropout7
I0813 23:14:22.442512 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.442558 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.442594 21738 net.cpp:156] Memory required for data: 226208800
I0813 23:14:22.442626 21738 layer_factory.hpp:77] Creating layer InnerProduct8
I0813 23:14:22.442677 21738 net.cpp:91] Creating Layer InnerProduct8
I0813 23:14:22.442718 21738 net.cpp:425] InnerProduct8 <- Dropout7
I0813 23:14:22.442764 21738 net.cpp:399] InnerProduct8 -> InnerProduct8
I0813 23:14:22.443200 21738 net.cpp:141] Setting up InnerProduct8
I0813 23:14:22.443222 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.443233 21738 net.cpp:156] Memory required for data: 226311200
I0813 23:14:22.443277 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.443320 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.443358 21738 layer_factory.hpp:77] Creating layer ReLU8
I0813 23:14:22.443399 21738 net.cpp:91] Creating Layer ReLU8
I0813 23:14:22.443434 21738 net.cpp:425] ReLU8 <- InnerProduct8
I0813 23:14:22.443475 21738 net.cpp:386] ReLU8 -> InnerProduct8 (in-place)
I0813 23:14:22.443518 21738 net.cpp:141] Setting up ReLU8
I0813 23:14:22.443562 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.443595 21738 net.cpp:156] Memory required for data: 226413600
I0813 23:14:22.443629 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.443670 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.443686 21738 net.cpp:425] drop2 <- InnerProduct8
I0813 23:14:22.443702 21738 net.cpp:399] drop2 -> Dropout8
I0813 23:14:22.443755 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.443776 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.443788 21738 net.cpp:156] Memory required for data: 226516000
I0813 23:14:22.443799 21738 layer_factory.hpp:77] Creating layer m4
I0813 23:14:22.443847 21738 net.cpp:91] Creating Layer m4
I0813 23:14:22.443888 21738 net.cpp:425] m4 <- Dropout8
I0813 23:14:22.443936 21738 net.cpp:399] m4 -> m4
I0813 23:14:22.443989 21738 net.cpp:141] Setting up m4
I0813 23:14:22.444007 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.444020 21738 net.cpp:156] Memory required for data: 226516800
I0813 23:14:22.444061 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.444077 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.444089 21738 layer_factory.hpp:77] Creating layer Concat5
I0813 23:14:22.444109 21738 net.cpp:91] Creating Layer Concat5
I0813 23:14:22.444124 21738 net.cpp:425] Concat5 <- i1_i1_0_split_4
I0813 23:14:22.444139 21738 net.cpp:425] Concat5 <- i15
I0813 23:14:22.444156 21738 net.cpp:399] Concat5 -> Concat5
I0813 23:14:22.444178 21738 net.cpp:141] Setting up Concat5
I0813 23:14:22.444188 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.444195 21738 net.cpp:156] Memory required for data: 233070400
I0813 23:14:22.444201 21738 layer_factory.hpp:77] Creating layer InnerProduct9
I0813 23:14:22.444234 21738 net.cpp:91] Creating Layer InnerProduct9
I0813 23:14:22.444243 21738 net.cpp:425] InnerProduct9 <- Concat5
I0813 23:14:22.444260 21738 net.cpp:399] InnerProduct9 -> InnerProduct9
I0813 23:14:22.469813 21738 net.cpp:141] Setting up InnerProduct9
I0813 23:14:22.469849 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.469856 21738 net.cpp:156] Memory required for data: 233275200
I0813 23:14:22.469866 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.469874 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.469882 21738 layer_factory.hpp:77] Creating layer ReLU9
I0813 23:14:22.469897 21738 net.cpp:91] Creating Layer ReLU9
I0813 23:14:22.469909 21738 net.cpp:425] ReLU9 <- InnerProduct9
I0813 23:14:22.469924 21738 net.cpp:386] ReLU9 -> InnerProduct9 (in-place)
I0813 23:14:22.469944 21738 net.cpp:141] Setting up ReLU9
I0813 23:14:22.469980 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.469990 21738 net.cpp:156] Memory required for data: 233480000
I0813 23:14:22.469998 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.470015 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.470026 21738 net.cpp:425] drop1 <- InnerProduct9
I0813 23:14:22.470041 21738 net.cpp:399] drop1 -> Dropout9
I0813 23:14:22.470062 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.470077 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.470090 21738 net.cpp:156] Memory required for data: 233684800
I0813 23:14:22.470101 21738 layer_factory.hpp:77] Creating layer InnerProduct10
I0813 23:14:22.470141 21738 net.cpp:91] Creating Layer InnerProduct10
I0813 23:14:22.470151 21738 net.cpp:425] InnerProduct10 <- Dropout9
I0813 23:14:22.470162 21738 net.cpp:399] InnerProduct10 -> InnerProduct10
I0813 23:14:22.470469 21738 net.cpp:141] Setting up InnerProduct10
I0813 23:14:22.470484 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.470500 21738 net.cpp:156] Memory required for data: 233787200
I0813 23:14:22.470509 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.470515 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.470522 21738 layer_factory.hpp:77] Creating layer ReLU10
I0813 23:14:22.470531 21738 net.cpp:91] Creating Layer ReLU10
I0813 23:14:22.470540 21738 net.cpp:425] ReLU10 <- InnerProduct10
I0813 23:14:22.470547 21738 net.cpp:386] ReLU10 -> InnerProduct10 (in-place)
I0813 23:14:22.470558 21738 net.cpp:141] Setting up ReLU10
I0813 23:14:22.470566 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.470571 21738 net.cpp:156] Memory required for data: 233889600
I0813 23:14:22.470577 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.470585 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.470592 21738 net.cpp:425] drop2 <- InnerProduct10
I0813 23:14:22.470599 21738 net.cpp:399] drop2 -> Dropout10
I0813 23:14:22.470612 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.470618 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.470623 21738 net.cpp:156] Memory required for data: 233992000
I0813 23:14:22.470628 21738 layer_factory.hpp:77] Creating layer m5
I0813 23:14:22.470638 21738 net.cpp:91] Creating Layer m5
I0813 23:14:22.470643 21738 net.cpp:425] m5 <- Dropout10
I0813 23:14:22.470652 21738 net.cpp:399] m5 -> m5
I0813 23:14:22.470670 21738 net.cpp:141] Setting up m5
I0813 23:14:22.470679 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.470685 21738 net.cpp:156] Memory required for data: 233992800
I0813 23:14:22.470690 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.470696 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.470701 21738 layer_factory.hpp:77] Creating layer Concat6
I0813 23:14:22.470712 21738 net.cpp:91] Creating Layer Concat6
I0813 23:14:22.470719 21738 net.cpp:425] Concat6 <- i1_i1_0_split_5
I0813 23:14:22.470746 21738 net.cpp:425] Concat6 <- i16
I0813 23:14:22.470755 21738 net.cpp:399] Concat6 -> Concat6
I0813 23:14:22.470767 21738 net.cpp:141] Setting up Concat6
I0813 23:14:22.470774 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.470778 21738 net.cpp:156] Memory required for data: 240546400
I0813 23:14:22.470783 21738 layer_factory.hpp:77] Creating layer InnerProduct11
I0813 23:14:22.470793 21738 net.cpp:91] Creating Layer InnerProduct11
I0813 23:14:22.470798 21738 net.cpp:425] InnerProduct11 <- Concat6
I0813 23:14:22.470805 21738 net.cpp:399] InnerProduct11 -> InnerProduct11
I0813 23:14:22.496413 21738 net.cpp:141] Setting up InnerProduct11
I0813 23:14:22.496461 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.496470 21738 net.cpp:156] Memory required for data: 240751200
I0813 23:14:22.496482 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.496492 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.496500 21738 layer_factory.hpp:77] Creating layer ReLU11
I0813 23:14:22.496523 21738 net.cpp:91] Creating Layer ReLU11
I0813 23:14:22.496533 21738 net.cpp:425] ReLU11 <- InnerProduct11
I0813 23:14:22.496548 21738 net.cpp:386] ReLU11 -> InnerProduct11 (in-place)
I0813 23:14:22.496567 21738 net.cpp:141] Setting up ReLU11
I0813 23:14:22.496579 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.496585 21738 net.cpp:156] Memory required for data: 240956000
I0813 23:14:22.496592 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.496605 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.496613 21738 net.cpp:425] drop1 <- InnerProduct11
I0813 23:14:22.496624 21738 net.cpp:399] drop1 -> Dropout11
I0813 23:14:22.496639 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.496647 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.496654 21738 net.cpp:156] Memory required for data: 241160800
I0813 23:14:22.496660 21738 layer_factory.hpp:77] Creating layer InnerProduct12
I0813 23:14:22.496676 21738 net.cpp:91] Creating Layer InnerProduct12
I0813 23:14:22.496686 21738 net.cpp:425] InnerProduct12 <- Dropout11
I0813 23:14:22.496697 21738 net.cpp:399] InnerProduct12 -> InnerProduct12
I0813 23:14:22.497217 21738 net.cpp:141] Setting up InnerProduct12
I0813 23:14:22.497236 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.497241 21738 net.cpp:156] Memory required for data: 241263200
I0813 23:14:22.497262 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.497272 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.497278 21738 layer_factory.hpp:77] Creating layer ReLU12
I0813 23:14:22.497292 21738 net.cpp:91] Creating Layer ReLU12
I0813 23:14:22.497298 21738 net.cpp:425] ReLU12 <- InnerProduct12
I0813 23:14:22.497309 21738 net.cpp:386] ReLU12 -> InnerProduct12 (in-place)
I0813 23:14:22.497323 21738 net.cpp:141] Setting up ReLU12
I0813 23:14:22.497331 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.497337 21738 net.cpp:156] Memory required for data: 241365600
I0813 23:14:22.497344 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.497354 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.497360 21738 net.cpp:425] drop2 <- InnerProduct12
I0813 23:14:22.497370 21738 net.cpp:399] drop2 -> Dropout12
I0813 23:14:22.497383 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.497398 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.497406 21738 net.cpp:156] Memory required for data: 241468000
I0813 23:14:22.497412 21738 layer_factory.hpp:77] Creating layer m6
I0813 23:14:22.497426 21738 net.cpp:91] Creating Layer m6
I0813 23:14:22.497437 21738 net.cpp:425] m6 <- Dropout12
I0813 23:14:22.497449 21738 net.cpp:399] m6 -> m6
I0813 23:14:22.497473 21738 net.cpp:141] Setting up m6
I0813 23:14:22.497484 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.497493 21738 net.cpp:156] Memory required for data: 241468800
I0813 23:14:22.497524 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.497534 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.497540 21738 layer_factory.hpp:77] Creating layer Concat7
I0813 23:14:22.497558 21738 net.cpp:91] Creating Layer Concat7
I0813 23:14:22.497570 21738 net.cpp:425] Concat7 <- i1_i1_0_split_6
I0813 23:14:22.497581 21738 net.cpp:425] Concat7 <- i17
I0813 23:14:22.497591 21738 net.cpp:399] Concat7 -> Concat7
I0813 23:14:22.497608 21738 net.cpp:141] Setting up Concat7
I0813 23:14:22.497617 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.497627 21738 net.cpp:156] Memory required for data: 248022400
I0813 23:14:22.497632 21738 layer_factory.hpp:77] Creating layer InnerProduct13
I0813 23:14:22.497647 21738 net.cpp:91] Creating Layer InnerProduct13
I0813 23:14:22.497655 21738 net.cpp:425] InnerProduct13 <- Concat7
I0813 23:14:22.497666 21738 net.cpp:399] InnerProduct13 -> InnerProduct13
I0813 23:14:22.518251 21738 net.cpp:141] Setting up InnerProduct13
I0813 23:14:22.518303 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.518311 21738 net.cpp:156] Memory required for data: 248227200
I0813 23:14:22.518321 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.518329 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.518337 21738 layer_factory.hpp:77] Creating layer ReLU13
I0813 23:14:22.518362 21738 net.cpp:91] Creating Layer ReLU13
I0813 23:14:22.518373 21738 net.cpp:425] ReLU13 <- InnerProduct13
I0813 23:14:22.518389 21738 net.cpp:386] ReLU13 -> InnerProduct13 (in-place)
I0813 23:14:22.518411 21738 net.cpp:141] Setting up ReLU13
I0813 23:14:22.518422 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.518429 21738 net.cpp:156] Memory required for data: 248432000
I0813 23:14:22.518436 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.518450 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.518457 21738 net.cpp:425] drop1 <- InnerProduct13
I0813 23:14:22.518471 21738 net.cpp:399] drop1 -> Dropout13
I0813 23:14:22.518488 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.518501 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.518508 21738 net.cpp:156] Memory required for data: 248636800
I0813 23:14:22.518517 21738 layer_factory.hpp:77] Creating layer InnerProduct14
I0813 23:14:22.518533 21738 net.cpp:91] Creating Layer InnerProduct14
I0813 23:14:22.518543 21738 net.cpp:425] InnerProduct14 <- Dropout13
I0813 23:14:22.518558 21738 net.cpp:399] InnerProduct14 -> InnerProduct14
I0813 23:14:22.518890 21738 net.cpp:141] Setting up InnerProduct14
I0813 23:14:22.518904 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.518913 21738 net.cpp:156] Memory required for data: 248739200
I0813 23:14:22.518921 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.518931 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.518939 21738 layer_factory.hpp:77] Creating layer ReLU14
I0813 23:14:22.518952 21738 net.cpp:91] Creating Layer ReLU14
I0813 23:14:22.518960 21738 net.cpp:425] ReLU14 <- InnerProduct14
I0813 23:14:22.518972 21738 net.cpp:386] ReLU14 -> InnerProduct14 (in-place)
I0813 23:14:22.518988 21738 net.cpp:141] Setting up ReLU14
I0813 23:14:22.518998 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.519006 21738 net.cpp:156] Memory required for data: 248841600
I0813 23:14:22.519013 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.519026 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.519034 21738 net.cpp:425] drop2 <- InnerProduct14
I0813 23:14:22.519047 21738 net.cpp:399] drop2 -> Dropout14
I0813 23:14:22.519062 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.519073 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.519081 21738 net.cpp:156] Memory required for data: 248944000
I0813 23:14:22.519112 21738 layer_factory.hpp:77] Creating layer m7
I0813 23:14:22.519129 21738 net.cpp:91] Creating Layer m7
I0813 23:14:22.519139 21738 net.cpp:425] m7 <- Dropout14
I0813 23:14:22.519155 21738 net.cpp:399] m7 -> m7
I0813 23:14:22.519182 21738 net.cpp:141] Setting up m7
I0813 23:14:22.519192 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.519201 21738 net.cpp:156] Memory required for data: 248944800
I0813 23:14:22.519210 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.519219 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.519227 21738 layer_factory.hpp:77] Creating layer Concat8
I0813 23:14:22.519239 21738 net.cpp:91] Creating Layer Concat8
I0813 23:14:22.519249 21738 net.cpp:425] Concat8 <- i1_i1_0_split_7
I0813 23:14:22.519265 21738 net.cpp:425] Concat8 <- i18
I0813 23:14:22.519280 21738 net.cpp:399] Concat8 -> Concat8
I0813 23:14:22.519299 21738 net.cpp:141] Setting up Concat8
I0813 23:14:22.519312 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.519320 21738 net.cpp:156] Memory required for data: 255498400
I0813 23:14:22.519327 21738 layer_factory.hpp:77] Creating layer InnerProduct15
I0813 23:14:22.519352 21738 net.cpp:91] Creating Layer InnerProduct15
I0813 23:14:22.519361 21738 net.cpp:425] InnerProduct15 <- Concat8
I0813 23:14:22.519373 21738 net.cpp:399] InnerProduct15 -> InnerProduct15
I0813 23:14:22.536356 21738 net.cpp:141] Setting up InnerProduct15
I0813 23:14:22.536406 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.536412 21738 net.cpp:156] Memory required for data: 255703200
I0813 23:14:22.536425 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.536434 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.536443 21738 layer_factory.hpp:77] Creating layer ReLU15
I0813 23:14:22.536463 21738 net.cpp:91] Creating Layer ReLU15
I0813 23:14:22.536473 21738 net.cpp:425] ReLU15 <- InnerProduct15
I0813 23:14:22.536486 21738 net.cpp:386] ReLU15 -> InnerProduct15 (in-place)
I0813 23:14:22.536512 21738 net.cpp:141] Setting up ReLU15
I0813 23:14:22.536525 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.536530 21738 net.cpp:156] Memory required for data: 255908000
I0813 23:14:22.536537 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.536551 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.536558 21738 net.cpp:425] drop1 <- InnerProduct15
I0813 23:14:22.536571 21738 net.cpp:399] drop1 -> Dropout15
I0813 23:14:22.536594 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.536605 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.536612 21738 net.cpp:156] Memory required for data: 256112800
I0813 23:14:22.536619 21738 layer_factory.hpp:77] Creating layer InnerProduct16
I0813 23:14:22.536636 21738 net.cpp:91] Creating Layer InnerProduct16
I0813 23:14:22.536650 21738 net.cpp:425] InnerProduct16 <- Dropout15
I0813 23:14:22.536664 21738 net.cpp:399] InnerProduct16 -> InnerProduct16
I0813 23:14:22.536976 21738 net.cpp:141] Setting up InnerProduct16
I0813 23:14:22.536990 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.536996 21738 net.cpp:156] Memory required for data: 256215200
I0813 23:14:22.537005 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.537014 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.537021 21738 layer_factory.hpp:77] Creating layer ReLU16
I0813 23:14:22.537031 21738 net.cpp:91] Creating Layer ReLU16
I0813 23:14:22.537039 21738 net.cpp:425] ReLU16 <- InnerProduct16
I0813 23:14:22.537050 21738 net.cpp:386] ReLU16 -> InnerProduct16 (in-place)
I0813 23:14:22.537061 21738 net.cpp:141] Setting up ReLU16
I0813 23:14:22.537072 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.537080 21738 net.cpp:156] Memory required for data: 256317600
I0813 23:14:22.537108 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.537120 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.537128 21738 net.cpp:425] drop2 <- InnerProduct16
I0813 23:14:22.537139 21738 net.cpp:399] drop2 -> Dropout16
I0813 23:14:22.537153 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.537163 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.537173 21738 net.cpp:156] Memory required for data: 256420000
I0813 23:14:22.537178 21738 layer_factory.hpp:77] Creating layer m8
I0813 23:14:22.537194 21738 net.cpp:91] Creating Layer m8
I0813 23:14:22.537200 21738 net.cpp:425] m8 <- Dropout16
I0813 23:14:22.537214 21738 net.cpp:399] m8 -> m8
I0813 23:14:22.537237 21738 net.cpp:141] Setting up m8
I0813 23:14:22.537247 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.537253 21738 net.cpp:156] Memory required for data: 256420800
I0813 23:14:22.537261 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.537271 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.537278 21738 layer_factory.hpp:77] Creating layer Concat9
I0813 23:14:22.537292 21738 net.cpp:91] Creating Layer Concat9
I0813 23:14:22.537299 21738 net.cpp:425] Concat9 <- i1_i1_0_split_8
I0813 23:14:22.537310 21738 net.cpp:425] Concat9 <- i19
I0813 23:14:22.537322 21738 net.cpp:399] Concat9 -> Concat9
I0813 23:14:22.537339 21738 net.cpp:141] Setting up Concat9
I0813 23:14:22.537348 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.537355 21738 net.cpp:156] Memory required for data: 262974400
I0813 23:14:22.537363 21738 layer_factory.hpp:77] Creating layer InnerProduct17
I0813 23:14:22.537374 21738 net.cpp:91] Creating Layer InnerProduct17
I0813 23:14:22.537381 21738 net.cpp:425] InnerProduct17 <- Concat9
I0813 23:14:22.537394 21738 net.cpp:399] InnerProduct17 -> InnerProduct17
I0813 23:14:22.553850 21738 net.cpp:141] Setting up InnerProduct17
I0813 23:14:22.553890 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.553897 21738 net.cpp:156] Memory required for data: 263179200
I0813 23:14:22.553910 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.553918 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.553925 21738 layer_factory.hpp:77] Creating layer ReLU17
I0813 23:14:22.553944 21738 net.cpp:91] Creating Layer ReLU17
I0813 23:14:22.553954 21738 net.cpp:425] ReLU17 <- InnerProduct17
I0813 23:14:22.553971 21738 net.cpp:386] ReLU17 -> InnerProduct17 (in-place)
I0813 23:14:22.553999 21738 net.cpp:141] Setting up ReLU17
I0813 23:14:22.554011 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.554018 21738 net.cpp:156] Memory required for data: 263384000
I0813 23:14:22.554024 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.554038 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.554045 21738 net.cpp:425] drop1 <- InnerProduct17
I0813 23:14:22.554057 21738 net.cpp:399] drop1 -> Dropout17
I0813 23:14:22.554077 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.554088 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.554095 21738 net.cpp:156] Memory required for data: 263588800
I0813 23:14:22.554102 21738 layer_factory.hpp:77] Creating layer InnerProduct18
I0813 23:14:22.554117 21738 net.cpp:91] Creating Layer InnerProduct18
I0813 23:14:22.554127 21738 net.cpp:425] InnerProduct18 <- Dropout17
I0813 23:14:22.554141 21738 net.cpp:399] InnerProduct18 -> InnerProduct18
I0813 23:14:22.554445 21738 net.cpp:141] Setting up InnerProduct18
I0813 23:14:22.554461 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.554468 21738 net.cpp:156] Memory required for data: 263691200
I0813 23:14:22.554476 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.554486 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.554492 21738 layer_factory.hpp:77] Creating layer ReLU18
I0813 23:14:22.554523 21738 net.cpp:91] Creating Layer ReLU18
I0813 23:14:22.554532 21738 net.cpp:425] ReLU18 <- InnerProduct18
I0813 23:14:22.554541 21738 net.cpp:386] ReLU18 -> InnerProduct18 (in-place)
I0813 23:14:22.554554 21738 net.cpp:141] Setting up ReLU18
I0813 23:14:22.554563 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.554570 21738 net.cpp:156] Memory required for data: 263793600
I0813 23:14:22.554577 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.554586 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.554594 21738 net.cpp:425] drop2 <- InnerProduct18
I0813 23:14:22.554606 21738 net.cpp:399] drop2 -> Dropout18
I0813 23:14:22.554621 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.554632 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.554638 21738 net.cpp:156] Memory required for data: 263896000
I0813 23:14:22.554647 21738 layer_factory.hpp:77] Creating layer m9
I0813 23:14:22.554664 21738 net.cpp:91] Creating Layer m9
I0813 23:14:22.554672 21738 net.cpp:425] m9 <- Dropout18
I0813 23:14:22.554683 21738 net.cpp:399] m9 -> m9
I0813 23:14:22.554713 21738 net.cpp:141] Setting up m9
I0813 23:14:22.554721 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.554728 21738 net.cpp:156] Memory required for data: 263896800
I0813 23:14:22.554735 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.554744 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.554750 21738 layer_factory.hpp:77] Creating layer Concat10
I0813 23:14:22.554762 21738 net.cpp:91] Creating Layer Concat10
I0813 23:14:22.554772 21738 net.cpp:425] Concat10 <- i1_i1_0_split_9
I0813 23:14:22.554781 21738 net.cpp:425] Concat10 <- i20
I0813 23:14:22.554795 21738 net.cpp:399] Concat10 -> Concat10
I0813 23:14:22.554812 21738 net.cpp:141] Setting up Concat10
I0813 23:14:22.554821 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.554828 21738 net.cpp:156] Memory required for data: 270450400
I0813 23:14:22.554836 21738 layer_factory.hpp:77] Creating layer InnerProduct19
I0813 23:14:22.554850 21738 net.cpp:91] Creating Layer InnerProduct19
I0813 23:14:22.554859 21738 net.cpp:425] InnerProduct19 <- Concat10
I0813 23:14:22.554872 21738 net.cpp:399] InnerProduct19 -> InnerProduct19
I0813 23:14:22.571094 21738 net.cpp:141] Setting up InnerProduct19
I0813 23:14:22.571132 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.571140 21738 net.cpp:156] Memory required for data: 270655200
I0813 23:14:22.571151 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.571162 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.571169 21738 layer_factory.hpp:77] Creating layer ReLU19
I0813 23:14:22.571187 21738 net.cpp:91] Creating Layer ReLU19
I0813 23:14:22.571197 21738 net.cpp:425] ReLU19 <- InnerProduct19
I0813 23:14:22.571214 21738 net.cpp:386] ReLU19 -> InnerProduct19 (in-place)
I0813 23:14:22.571233 21738 net.cpp:141] Setting up ReLU19
I0813 23:14:22.571249 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.571256 21738 net.cpp:156] Memory required for data: 270860000
I0813 23:14:22.571264 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.571276 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.571290 21738 net.cpp:425] drop1 <- InnerProduct19
I0813 23:14:22.571300 21738 net.cpp:399] drop1 -> Dropout19
I0813 23:14:22.571316 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.571329 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.571336 21738 net.cpp:156] Memory required for data: 271064800
I0813 23:14:22.571342 21738 layer_factory.hpp:77] Creating layer InnerProduct20
I0813 23:14:22.571359 21738 net.cpp:91] Creating Layer InnerProduct20
I0813 23:14:22.571372 21738 net.cpp:425] InnerProduct20 <- Dropout19
I0813 23:14:22.571389 21738 net.cpp:399] InnerProduct20 -> InnerProduct20
I0813 23:14:22.571686 21738 net.cpp:141] Setting up InnerProduct20
I0813 23:14:22.571715 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.571722 21738 net.cpp:156] Memory required for data: 271167200
I0813 23:14:22.571730 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.571738 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.571748 21738 layer_factory.hpp:77] Creating layer ReLU20
I0813 23:14:22.571759 21738 net.cpp:91] Creating Layer ReLU20
I0813 23:14:22.571766 21738 net.cpp:425] ReLU20 <- InnerProduct20
I0813 23:14:22.571779 21738 net.cpp:386] ReLU20 -> InnerProduct20 (in-place)
I0813 23:14:22.571791 21738 net.cpp:141] Setting up ReLU20
I0813 23:14:22.571802 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.571808 21738 net.cpp:156] Memory required for data: 271269600
I0813 23:14:22.571815 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.571825 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.571832 21738 net.cpp:425] drop2 <- InnerProduct20
I0813 23:14:22.571841 21738 net.cpp:399] drop2 -> Dropout20
I0813 23:14:22.571856 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.571863 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.571869 21738 net.cpp:156] Memory required for data: 271372000
I0813 23:14:22.571877 21738 layer_factory.hpp:77] Creating layer m10
I0813 23:14:22.571892 21738 net.cpp:91] Creating Layer m10
I0813 23:14:22.571902 21738 net.cpp:425] m10 <- Dropout20
I0813 23:14:22.571916 21738 net.cpp:399] m10 -> m10
I0813 23:14:22.571941 21738 net.cpp:141] Setting up m10
I0813 23:14:22.571950 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.571956 21738 net.cpp:156] Memory required for data: 271372800
I0813 23:14:22.571964 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.571972 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.571979 21738 layer_factory.hpp:77] Creating layer Concat11
I0813 23:14:22.571992 21738 net.cpp:91] Creating Layer Concat11
I0813 23:14:22.572002 21738 net.cpp:425] Concat11 <- i2
I0813 23:14:22.572013 21738 net.cpp:425] Concat11 <- i11_i1_10_split_1
I0813 23:14:22.572043 21738 net.cpp:399] Concat11 -> Concat11
I0813 23:14:22.572063 21738 net.cpp:141] Setting up Concat11
I0813 23:14:22.572073 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.572079 21738 net.cpp:156] Memory required for data: 277926400
I0813 23:14:22.572087 21738 layer_factory.hpp:77] Creating layer InnerProduct21
I0813 23:14:22.572098 21738 net.cpp:91] Creating Layer InnerProduct21
I0813 23:14:22.572106 21738 net.cpp:425] InnerProduct21 <- Concat11
I0813 23:14:22.572121 21738 net.cpp:399] InnerProduct21 -> InnerProduct21
I0813 23:14:22.588155 21738 net.cpp:141] Setting up InnerProduct21
I0813 23:14:22.588193 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.588199 21738 net.cpp:156] Memory required for data: 278131200
I0813 23:14:22.588212 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.588222 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.588228 21738 layer_factory.hpp:77] Creating layer ReLU21
I0813 23:14:22.588248 21738 net.cpp:91] Creating Layer ReLU21
I0813 23:14:22.588258 21738 net.cpp:425] ReLU21 <- InnerProduct21
I0813 23:14:22.588275 21738 net.cpp:386] ReLU21 -> InnerProduct21 (in-place)
I0813 23:14:22.588297 21738 net.cpp:141] Setting up ReLU21
I0813 23:14:22.588309 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.588315 21738 net.cpp:156] Memory required for data: 278336000
I0813 23:14:22.588322 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.588335 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.588346 21738 net.cpp:425] drop1 <- InnerProduct21
I0813 23:14:22.588361 21738 net.cpp:399] drop1 -> Dropout21
I0813 23:14:22.588381 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.588392 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.588397 21738 net.cpp:156] Memory required for data: 278540800
I0813 23:14:22.588429 21738 layer_factory.hpp:77] Creating layer InnerProduct22
I0813 23:14:22.588445 21738 net.cpp:91] Creating Layer InnerProduct22
I0813 23:14:22.588454 21738 net.cpp:425] InnerProduct22 <- Dropout21
I0813 23:14:22.588469 21738 net.cpp:399] InnerProduct22 -> InnerProduct22
I0813 23:14:22.588778 21738 net.cpp:141] Setting up InnerProduct22
I0813 23:14:22.588788 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.588794 21738 net.cpp:156] Memory required for data: 278643200
I0813 23:14:22.588802 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.588810 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.588817 21738 layer_factory.hpp:77] Creating layer ReLU22
I0813 23:14:22.588827 21738 net.cpp:91] Creating Layer ReLU22
I0813 23:14:22.588835 21738 net.cpp:425] ReLU22 <- InnerProduct22
I0813 23:14:22.588847 21738 net.cpp:386] ReLU22 -> InnerProduct22 (in-place)
I0813 23:14:22.588860 21738 net.cpp:141] Setting up ReLU22
I0813 23:14:22.588871 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.588877 21738 net.cpp:156] Memory required for data: 278745600
I0813 23:14:22.588883 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.588893 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.588901 21738 net.cpp:425] drop2 <- InnerProduct22
I0813 23:14:22.588912 21738 net.cpp:399] drop2 -> Dropout22
I0813 23:14:22.588927 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.588938 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.588944 21738 net.cpp:156] Memory required for data: 278848000
I0813 23:14:22.588951 21738 layer_factory.hpp:77] Creating layer m11
I0813 23:14:22.588963 21738 net.cpp:91] Creating Layer m11
I0813 23:14:22.588971 21738 net.cpp:425] m11 <- Dropout22
I0813 23:14:22.588986 21738 net.cpp:399] m11 -> m11
I0813 23:14:22.589012 21738 net.cpp:141] Setting up m11
I0813 23:14:22.589021 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.589027 21738 net.cpp:156] Memory required for data: 278848800
I0813 23:14:22.589056 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.589066 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.589072 21738 layer_factory.hpp:77] Creating layer Concat12
I0813 23:14:22.589087 21738 net.cpp:91] Creating Layer Concat12
I0813 23:14:22.589095 21738 net.cpp:425] Concat12 <- i3
I0813 23:14:22.589104 21738 net.cpp:425] Concat12 <- i11_i1_10_split_2
I0813 23:14:22.589115 21738 net.cpp:399] Concat12 -> Concat12
I0813 23:14:22.589134 21738 net.cpp:141] Setting up Concat12
I0813 23:14:22.589144 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.589150 21738 net.cpp:156] Memory required for data: 285402400
I0813 23:14:22.589157 21738 layer_factory.hpp:77] Creating layer InnerProduct23
I0813 23:14:22.589174 21738 net.cpp:91] Creating Layer InnerProduct23
I0813 23:14:22.589182 21738 net.cpp:425] InnerProduct23 <- Concat12
I0813 23:14:22.589195 21738 net.cpp:399] InnerProduct23 -> InnerProduct23
I0813 23:14:22.605365 21738 net.cpp:141] Setting up InnerProduct23
I0813 23:14:22.605408 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.605417 21738 net.cpp:156] Memory required for data: 285607200
I0813 23:14:22.605427 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.605435 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.605440 21738 layer_factory.hpp:77] Creating layer ReLU23
I0813 23:14:22.605454 21738 net.cpp:91] Creating Layer ReLU23
I0813 23:14:22.605465 21738 net.cpp:425] ReLU23 <- InnerProduct23
I0813 23:14:22.605474 21738 net.cpp:386] ReLU23 -> InnerProduct23 (in-place)
I0813 23:14:22.605486 21738 net.cpp:141] Setting up ReLU23
I0813 23:14:22.605492 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.605496 21738 net.cpp:156] Memory required for data: 285812000
I0813 23:14:22.605521 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.605530 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.605535 21738 net.cpp:425] drop1 <- InnerProduct23
I0813 23:14:22.605542 21738 net.cpp:399] drop1 -> Dropout23
I0813 23:14:22.605552 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.605563 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.605566 21738 net.cpp:156] Memory required for data: 286016800
I0813 23:14:22.605571 21738 layer_factory.hpp:77] Creating layer InnerProduct24
I0813 23:14:22.605581 21738 net.cpp:91] Creating Layer InnerProduct24
I0813 23:14:22.605586 21738 net.cpp:425] InnerProduct24 <- Dropout23
I0813 23:14:22.605593 21738 net.cpp:399] InnerProduct24 -> InnerProduct24
I0813 23:14:22.605867 21738 net.cpp:141] Setting up InnerProduct24
I0813 23:14:22.605877 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.605881 21738 net.cpp:156] Memory required for data: 286119200
I0813 23:14:22.605886 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.605891 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.605895 21738 layer_factory.hpp:77] Creating layer ReLU24
I0813 23:14:22.605903 21738 net.cpp:91] Creating Layer ReLU24
I0813 23:14:22.605908 21738 net.cpp:425] ReLU24 <- InnerProduct24
I0813 23:14:22.605914 21738 net.cpp:386] ReLU24 -> InnerProduct24 (in-place)
I0813 23:14:22.605921 21738 net.cpp:141] Setting up ReLU24
I0813 23:14:22.605926 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.605929 21738 net.cpp:156] Memory required for data: 286221600
I0813 23:14:22.605933 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.605939 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.605943 21738 net.cpp:425] drop2 <- InnerProduct24
I0813 23:14:22.605950 21738 net.cpp:399] drop2 -> Dropout24
I0813 23:14:22.605958 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.605963 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.605967 21738 net.cpp:156] Memory required for data: 286324000
I0813 23:14:22.605970 21738 layer_factory.hpp:77] Creating layer m12
I0813 23:14:22.605978 21738 net.cpp:91] Creating Layer m12
I0813 23:14:22.605984 21738 net.cpp:425] m12 <- Dropout24
I0813 23:14:22.605990 21738 net.cpp:399] m12 -> m12
I0813 23:14:22.606007 21738 net.cpp:141] Setting up m12
I0813 23:14:22.606012 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.606016 21738 net.cpp:156] Memory required for data: 286324800
I0813 23:14:22.606020 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.606026 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.606030 21738 layer_factory.hpp:77] Creating layer Concat13
I0813 23:14:22.606040 21738 net.cpp:91] Creating Layer Concat13
I0813 23:14:22.606045 21738 net.cpp:425] Concat13 <- i4
I0813 23:14:22.606051 21738 net.cpp:425] Concat13 <- i11_i1_10_split_3
I0813 23:14:22.606057 21738 net.cpp:399] Concat13 -> Concat13
I0813 23:14:22.606066 21738 net.cpp:141] Setting up Concat13
I0813 23:14:22.606072 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.606076 21738 net.cpp:156] Memory required for data: 292878400
I0813 23:14:22.606081 21738 layer_factory.hpp:77] Creating layer InnerProduct25
I0813 23:14:22.606089 21738 net.cpp:91] Creating Layer InnerProduct25
I0813 23:14:22.606094 21738 net.cpp:425] InnerProduct25 <- Concat13
I0813 23:14:22.606099 21738 net.cpp:399] InnerProduct25 -> InnerProduct25
I0813 23:14:22.621948 21738 net.cpp:141] Setting up InnerProduct25
I0813 23:14:22.621986 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.621991 21738 net.cpp:156] Memory required for data: 293083200
I0813 23:14:22.622002 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.622009 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.622015 21738 layer_factory.hpp:77] Creating layer ReLU25
I0813 23:14:22.622057 21738 net.cpp:91] Creating Layer ReLU25
I0813 23:14:22.622067 21738 net.cpp:425] ReLU25 <- InnerProduct25
I0813 23:14:22.622081 21738 net.cpp:386] ReLU25 -> InnerProduct25 (in-place)
I0813 23:14:22.622098 21738 net.cpp:141] Setting up ReLU25
I0813 23:14:22.622105 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.622108 21738 net.cpp:156] Memory required for data: 293288000
I0813 23:14:22.622113 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.622123 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.622128 21738 net.cpp:425] drop1 <- InnerProduct25
I0813 23:14:22.622135 21738 net.cpp:399] drop1 -> Dropout25
I0813 23:14:22.622148 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.622153 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.622156 21738 net.cpp:156] Memory required for data: 293492800
I0813 23:14:22.622160 21738 layer_factory.hpp:77] Creating layer InnerProduct26
I0813 23:14:22.622174 21738 net.cpp:91] Creating Layer InnerProduct26
I0813 23:14:22.622179 21738 net.cpp:425] InnerProduct26 <- Dropout25
I0813 23:14:22.622187 21738 net.cpp:399] InnerProduct26 -> InnerProduct26
I0813 23:14:22.622488 21738 net.cpp:141] Setting up InnerProduct26
I0813 23:14:22.622499 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.622503 21738 net.cpp:156] Memory required for data: 293595200
I0813 23:14:22.622509 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.622514 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.622519 21738 layer_factory.hpp:77] Creating layer ReLU26
I0813 23:14:22.622527 21738 net.cpp:91] Creating Layer ReLU26
I0813 23:14:22.622532 21738 net.cpp:425] ReLU26 <- InnerProduct26
I0813 23:14:22.622540 21738 net.cpp:386] ReLU26 -> InnerProduct26 (in-place)
I0813 23:14:22.622547 21738 net.cpp:141] Setting up ReLU26
I0813 23:14:22.622552 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.622556 21738 net.cpp:156] Memory required for data: 293697600
I0813 23:14:22.622560 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.622567 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.622571 21738 net.cpp:425] drop2 <- InnerProduct26
I0813 23:14:22.622577 21738 net.cpp:399] drop2 -> Dropout26
I0813 23:14:22.622586 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.622591 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.622593 21738 net.cpp:156] Memory required for data: 293800000
I0813 23:14:22.622597 21738 layer_factory.hpp:77] Creating layer m13
I0813 23:14:22.622608 21738 net.cpp:91] Creating Layer m13
I0813 23:14:22.622612 21738 net.cpp:425] m13 <- Dropout26
I0813 23:14:22.622622 21738 net.cpp:399] m13 -> m13
I0813 23:14:22.622638 21738 net.cpp:141] Setting up m13
I0813 23:14:22.622643 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.622648 21738 net.cpp:156] Memory required for data: 293800800
I0813 23:14:22.622653 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.622658 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.622661 21738 layer_factory.hpp:77] Creating layer Concat14
I0813 23:14:22.622669 21738 net.cpp:91] Creating Layer Concat14
I0813 23:14:22.622674 21738 net.cpp:425] Concat14 <- i5
I0813 23:14:22.622680 21738 net.cpp:425] Concat14 <- i11_i1_10_split_4
I0813 23:14:22.622689 21738 net.cpp:399] Concat14 -> Concat14
I0813 23:14:22.622699 21738 net.cpp:141] Setting up Concat14
I0813 23:14:22.622704 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.622709 21738 net.cpp:156] Memory required for data: 300354400
I0813 23:14:22.622712 21738 layer_factory.hpp:77] Creating layer InnerProduct27
I0813 23:14:22.622720 21738 net.cpp:91] Creating Layer InnerProduct27
I0813 23:14:22.622725 21738 net.cpp:425] InnerProduct27 <- Concat14
I0813 23:14:22.622732 21738 net.cpp:399] InnerProduct27 -> InnerProduct27
I0813 23:14:22.638973 21738 net.cpp:141] Setting up InnerProduct27
I0813 23:14:22.639034 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.639039 21738 net.cpp:156] Memory required for data: 300559200
I0813 23:14:22.639048 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.639055 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.639060 21738 layer_factory.hpp:77] Creating layer ReLU27
I0813 23:14:22.639076 21738 net.cpp:91] Creating Layer ReLU27
I0813 23:14:22.639086 21738 net.cpp:425] ReLU27 <- InnerProduct27
I0813 23:14:22.639093 21738 net.cpp:386] ReLU27 -> InnerProduct27 (in-place)
I0813 23:14:22.639106 21738 net.cpp:141] Setting up ReLU27
I0813 23:14:22.639111 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.639114 21738 net.cpp:156] Memory required for data: 300764000
I0813 23:14:22.639118 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.639129 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.639133 21738 net.cpp:425] drop1 <- InnerProduct27
I0813 23:14:22.639140 21738 net.cpp:399] drop1 -> Dropout27
I0813 23:14:22.639152 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.639156 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.639160 21738 net.cpp:156] Memory required for data: 300968800
I0813 23:14:22.639164 21738 layer_factory.hpp:77] Creating layer InnerProduct28
I0813 23:14:22.639176 21738 net.cpp:91] Creating Layer InnerProduct28
I0813 23:14:22.639181 21738 net.cpp:425] InnerProduct28 <- Dropout27
I0813 23:14:22.639188 21738 net.cpp:399] InnerProduct28 -> InnerProduct28
I0813 23:14:22.639492 21738 net.cpp:141] Setting up InnerProduct28
I0813 23:14:22.639500 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.639504 21738 net.cpp:156] Memory required for data: 301071200
I0813 23:14:22.639510 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.639515 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.639519 21738 layer_factory.hpp:77] Creating layer ReLU28
I0813 23:14:22.639536 21738 net.cpp:91] Creating Layer ReLU28
I0813 23:14:22.639541 21738 net.cpp:425] ReLU28 <- InnerProduct28
I0813 23:14:22.639547 21738 net.cpp:386] ReLU28 -> InnerProduct28 (in-place)
I0813 23:14:22.639554 21738 net.cpp:141] Setting up ReLU28
I0813 23:14:22.639559 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.639562 21738 net.cpp:156] Memory required for data: 301173600
I0813 23:14:22.639566 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.639572 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.639576 21738 net.cpp:425] drop2 <- InnerProduct28
I0813 23:14:22.639583 21738 net.cpp:399] drop2 -> Dropout28
I0813 23:14:22.639590 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.639595 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.639600 21738 net.cpp:156] Memory required for data: 301276000
I0813 23:14:22.639603 21738 layer_factory.hpp:77] Creating layer m14
I0813 23:14:22.639611 21738 net.cpp:91] Creating Layer m14
I0813 23:14:22.639614 21738 net.cpp:425] m14 <- Dropout28
I0813 23:14:22.639623 21738 net.cpp:399] m14 -> m14
I0813 23:14:22.639638 21738 net.cpp:141] Setting up m14
I0813 23:14:22.639643 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.639647 21738 net.cpp:156] Memory required for data: 301276800
I0813 23:14:22.639652 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.639657 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.639660 21738 layer_factory.hpp:77] Creating layer Concat15
I0813 23:14:22.639672 21738 net.cpp:91] Creating Layer Concat15
I0813 23:14:22.639677 21738 net.cpp:425] Concat15 <- i6
I0813 23:14:22.639683 21738 net.cpp:425] Concat15 <- i11_i1_10_split_5
I0813 23:14:22.639688 21738 net.cpp:399] Concat15 -> Concat15
I0813 23:14:22.639698 21738 net.cpp:141] Setting up Concat15
I0813 23:14:22.639704 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.639716 21738 net.cpp:156] Memory required for data: 307830400
I0813 23:14:22.639721 21738 layer_factory.hpp:77] Creating layer InnerProduct29
I0813 23:14:22.639729 21738 net.cpp:91] Creating Layer InnerProduct29
I0813 23:14:22.639734 21738 net.cpp:425] InnerProduct29 <- Concat15
I0813 23:14:22.639739 21738 net.cpp:399] InnerProduct29 -> InnerProduct29
I0813 23:14:22.655792 21738 net.cpp:141] Setting up InnerProduct29
I0813 23:14:22.655833 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.655839 21738 net.cpp:156] Memory required for data: 308035200
I0813 23:14:22.655848 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.655855 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.655861 21738 layer_factory.hpp:77] Creating layer ReLU29
I0813 23:14:22.655874 21738 net.cpp:91] Creating Layer ReLU29
I0813 23:14:22.655882 21738 net.cpp:425] ReLU29 <- InnerProduct29
I0813 23:14:22.655894 21738 net.cpp:386] ReLU29 -> InnerProduct29 (in-place)
I0813 23:14:22.655907 21738 net.cpp:141] Setting up ReLU29
I0813 23:14:22.655920 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.655925 21738 net.cpp:156] Memory required for data: 308240000
I0813 23:14:22.655930 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.655939 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.655943 21738 net.cpp:425] drop1 <- InnerProduct29
I0813 23:14:22.655951 21738 net.cpp:399] drop1 -> Dropout29
I0813 23:14:22.655962 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.655971 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.655974 21738 net.cpp:156] Memory required for data: 308444800
I0813 23:14:22.655979 21738 layer_factory.hpp:77] Creating layer InnerProduct30
I0813 23:14:22.655992 21738 net.cpp:91] Creating Layer InnerProduct30
I0813 23:14:22.655998 21738 net.cpp:425] InnerProduct30 <- Dropout29
I0813 23:14:22.656013 21738 net.cpp:399] InnerProduct30 -> InnerProduct30
I0813 23:14:22.656352 21738 net.cpp:141] Setting up InnerProduct30
I0813 23:14:22.656365 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.656370 21738 net.cpp:156] Memory required for data: 308547200
I0813 23:14:22.656375 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.656381 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.656385 21738 layer_factory.hpp:77] Creating layer ReLU30
I0813 23:14:22.656393 21738 net.cpp:91] Creating Layer ReLU30
I0813 23:14:22.656397 21738 net.cpp:425] ReLU30 <- InnerProduct30
I0813 23:14:22.656405 21738 net.cpp:386] ReLU30 -> InnerProduct30 (in-place)
I0813 23:14:22.656414 21738 net.cpp:141] Setting up ReLU30
I0813 23:14:22.656424 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.656429 21738 net.cpp:156] Memory required for data: 308649600
I0813 23:14:22.656432 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.656440 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.656445 21738 net.cpp:425] drop2 <- InnerProduct30
I0813 23:14:22.656455 21738 net.cpp:399] drop2 -> Dropout30
I0813 23:14:22.656463 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.656469 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.656473 21738 net.cpp:156] Memory required for data: 308752000
I0813 23:14:22.656478 21738 layer_factory.hpp:77] Creating layer m15
I0813 23:14:22.656486 21738 net.cpp:91] Creating Layer m15
I0813 23:14:22.656494 21738 net.cpp:425] m15 <- Dropout30
I0813 23:14:22.656504 21738 net.cpp:399] m15 -> m15
I0813 23:14:22.656523 21738 net.cpp:141] Setting up m15
I0813 23:14:22.656530 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.656534 21738 net.cpp:156] Memory required for data: 308752800
I0813 23:14:22.656539 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.656545 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.656571 21738 layer_factory.hpp:77] Creating layer Concat16
I0813 23:14:22.656584 21738 net.cpp:91] Creating Layer Concat16
I0813 23:14:22.656591 21738 net.cpp:425] Concat16 <- i7
I0813 23:14:22.656599 21738 net.cpp:425] Concat16 <- i11_i1_10_split_6
I0813 23:14:22.656608 21738 net.cpp:399] Concat16 -> Concat16
I0813 23:14:22.656620 21738 net.cpp:141] Setting up Concat16
I0813 23:14:22.656625 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.656628 21738 net.cpp:156] Memory required for data: 315306400
I0813 23:14:22.656633 21738 layer_factory.hpp:77] Creating layer InnerProduct31
I0813 23:14:22.656668 21738 net.cpp:91] Creating Layer InnerProduct31
I0813 23:14:22.656677 21738 net.cpp:425] InnerProduct31 <- Concat16
I0813 23:14:22.656684 21738 net.cpp:399] InnerProduct31 -> InnerProduct31
I0813 23:14:22.672711 21738 net.cpp:141] Setting up InnerProduct31
I0813 23:14:22.672749 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.672755 21738 net.cpp:156] Memory required for data: 315511200
I0813 23:14:22.672763 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.672770 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.672777 21738 layer_factory.hpp:77] Creating layer ReLU31
I0813 23:14:22.672791 21738 net.cpp:91] Creating Layer ReLU31
I0813 23:14:22.672802 21738 net.cpp:425] ReLU31 <- InnerProduct31
I0813 23:14:22.672811 21738 net.cpp:386] ReLU31 -> InnerProduct31 (in-place)
I0813 23:14:22.672823 21738 net.cpp:141] Setting up ReLU31
I0813 23:14:22.672832 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.672837 21738 net.cpp:156] Memory required for data: 315716000
I0813 23:14:22.672840 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.672848 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.672852 21738 net.cpp:425] drop1 <- InnerProduct31
I0813 23:14:22.672860 21738 net.cpp:399] drop1 -> Dropout31
I0813 23:14:22.672871 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.672880 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.672885 21738 net.cpp:156] Memory required for data: 315920800
I0813 23:14:22.672889 21738 layer_factory.hpp:77] Creating layer InnerProduct32
I0813 23:14:22.672899 21738 net.cpp:91] Creating Layer InnerProduct32
I0813 23:14:22.672904 21738 net.cpp:425] InnerProduct32 <- Dropout31
I0813 23:14:22.672912 21738 net.cpp:399] InnerProduct32 -> InnerProduct32
I0813 23:14:22.673207 21738 net.cpp:141] Setting up InnerProduct32
I0813 23:14:22.673218 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.673221 21738 net.cpp:156] Memory required for data: 316023200
I0813 23:14:22.673226 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.673231 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.673236 21738 layer_factory.hpp:77] Creating layer ReLU32
I0813 23:14:22.673244 21738 net.cpp:91] Creating Layer ReLU32
I0813 23:14:22.673249 21738 net.cpp:425] ReLU32 <- InnerProduct32
I0813 23:14:22.673255 21738 net.cpp:386] ReLU32 -> InnerProduct32 (in-place)
I0813 23:14:22.673261 21738 net.cpp:141] Setting up ReLU32
I0813 23:14:22.673266 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.673270 21738 net.cpp:156] Memory required for data: 316125600
I0813 23:14:22.673275 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.673281 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.673285 21738 net.cpp:425] drop2 <- InnerProduct32
I0813 23:14:22.673293 21738 net.cpp:399] drop2 -> Dropout32
I0813 23:14:22.673300 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.673305 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.673310 21738 net.cpp:156] Memory required for data: 316228000
I0813 23:14:22.673313 21738 layer_factory.hpp:77] Creating layer m16
I0813 23:14:22.673321 21738 net.cpp:91] Creating Layer m16
I0813 23:14:22.673332 21738 net.cpp:425] m16 <- Dropout32
I0813 23:14:22.673339 21738 net.cpp:399] m16 -> m16
I0813 23:14:22.673375 21738 net.cpp:141] Setting up m16
I0813 23:14:22.673382 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.673385 21738 net.cpp:156] Memory required for data: 316228800
I0813 23:14:22.673390 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.673395 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.673399 21738 layer_factory.hpp:77] Creating layer Concat17
I0813 23:14:22.673409 21738 net.cpp:91] Creating Layer Concat17
I0813 23:14:22.673414 21738 net.cpp:425] Concat17 <- i8
I0813 23:14:22.673420 21738 net.cpp:425] Concat17 <- i11_i1_10_split_7
I0813 23:14:22.673429 21738 net.cpp:399] Concat17 -> Concat17
I0813 23:14:22.673442 21738 net.cpp:141] Setting up Concat17
I0813 23:14:22.673447 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.673451 21738 net.cpp:156] Memory required for data: 322782400
I0813 23:14:22.673455 21738 layer_factory.hpp:77] Creating layer InnerProduct33
I0813 23:14:22.673465 21738 net.cpp:91] Creating Layer InnerProduct33
I0813 23:14:22.673470 21738 net.cpp:425] InnerProduct33 <- Concat17
I0813 23:14:22.673476 21738 net.cpp:399] InnerProduct33 -> InnerProduct33
I0813 23:14:22.689628 21738 net.cpp:141] Setting up InnerProduct33
I0813 23:14:22.689666 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.689671 21738 net.cpp:156] Memory required for data: 322987200
I0813 23:14:22.689680 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.689687 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.689692 21738 layer_factory.hpp:77] Creating layer ReLU33
I0813 23:14:22.689707 21738 net.cpp:91] Creating Layer ReLU33
I0813 23:14:22.689713 21738 net.cpp:425] ReLU33 <- InnerProduct33
I0813 23:14:22.689726 21738 net.cpp:386] ReLU33 -> InnerProduct33 (in-place)
I0813 23:14:22.689741 21738 net.cpp:141] Setting up ReLU33
I0813 23:14:22.689746 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.689750 21738 net.cpp:156] Memory required for data: 323192000
I0813 23:14:22.689755 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.689764 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.689769 21738 net.cpp:425] drop1 <- InnerProduct33
I0813 23:14:22.689776 21738 net.cpp:399] drop1 -> Dropout33
I0813 23:14:22.689787 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.689793 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.689797 21738 net.cpp:156] Memory required for data: 323396800
I0813 23:14:22.689801 21738 layer_factory.hpp:77] Creating layer InnerProduct34
I0813 23:14:22.689813 21738 net.cpp:91] Creating Layer InnerProduct34
I0813 23:14:22.689826 21738 net.cpp:425] InnerProduct34 <- Dropout33
I0813 23:14:22.689836 21738 net.cpp:399] InnerProduct34 -> InnerProduct34
I0813 23:14:22.690134 21738 net.cpp:141] Setting up InnerProduct34
I0813 23:14:22.690145 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.690150 21738 net.cpp:156] Memory required for data: 323499200
I0813 23:14:22.690155 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.690160 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.690165 21738 layer_factory.hpp:77] Creating layer ReLU34
I0813 23:14:22.690172 21738 net.cpp:91] Creating Layer ReLU34
I0813 23:14:22.690178 21738 net.cpp:425] ReLU34 <- InnerProduct34
I0813 23:14:22.690191 21738 net.cpp:386] ReLU34 -> InnerProduct34 (in-place)
I0813 23:14:22.690197 21738 net.cpp:141] Setting up ReLU34
I0813 23:14:22.690202 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.690207 21738 net.cpp:156] Memory required for data: 323601600
I0813 23:14:22.690212 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.690217 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.690222 21738 net.cpp:425] drop2 <- InnerProduct34
I0813 23:14:22.690227 21738 net.cpp:399] drop2 -> Dropout34
I0813 23:14:22.690251 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.690260 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.690263 21738 net.cpp:156] Memory required for data: 323704000
I0813 23:14:22.690269 21738 layer_factory.hpp:77] Creating layer m17
I0813 23:14:22.690281 21738 net.cpp:91] Creating Layer m17
I0813 23:14:22.690287 21738 net.cpp:425] m17 <- Dropout34
I0813 23:14:22.690296 21738 net.cpp:399] m17 -> m17
I0813 23:14:22.690315 21738 net.cpp:141] Setting up m17
I0813 23:14:22.690321 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.690326 21738 net.cpp:156] Memory required for data: 323704800
I0813 23:14:22.690331 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.690336 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.690340 21738 layer_factory.hpp:77] Creating layer Concat18
I0813 23:14:22.690349 21738 net.cpp:91] Creating Layer Concat18
I0813 23:14:22.690354 21738 net.cpp:425] Concat18 <- i9
I0813 23:14:22.690361 21738 net.cpp:425] Concat18 <- i11_i1_10_split_8
I0813 23:14:22.690374 21738 net.cpp:399] Concat18 -> Concat18
I0813 23:14:22.690384 21738 net.cpp:141] Setting up Concat18
I0813 23:14:22.690390 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.690394 21738 net.cpp:156] Memory required for data: 330258400
I0813 23:14:22.690398 21738 layer_factory.hpp:77] Creating layer InnerProduct35
I0813 23:14:22.690407 21738 net.cpp:91] Creating Layer InnerProduct35
I0813 23:14:22.690413 21738 net.cpp:425] InnerProduct35 <- Concat18
I0813 23:14:22.690423 21738 net.cpp:399] InnerProduct35 -> InnerProduct35
I0813 23:14:22.706375 21738 net.cpp:141] Setting up InnerProduct35
I0813 23:14:22.706413 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.706418 21738 net.cpp:156] Memory required for data: 330463200
I0813 23:14:22.706428 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.706434 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.706439 21738 layer_factory.hpp:77] Creating layer ReLU35
I0813 23:14:22.706457 21738 net.cpp:91] Creating Layer ReLU35
I0813 23:14:22.706465 21738 net.cpp:425] ReLU35 <- InnerProduct35
I0813 23:14:22.706475 21738 net.cpp:386] ReLU35 -> InnerProduct35 (in-place)
I0813 23:14:22.706492 21738 net.cpp:141] Setting up ReLU35
I0813 23:14:22.706498 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.706502 21738 net.cpp:156] Memory required for data: 330668000
I0813 23:14:22.706506 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.706517 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.706521 21738 net.cpp:425] drop1 <- InnerProduct35
I0813 23:14:22.706528 21738 net.cpp:399] drop1 -> Dropout35
I0813 23:14:22.706539 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.706545 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.706549 21738 net.cpp:156] Memory required for data: 330872800
I0813 23:14:22.706553 21738 layer_factory.hpp:77] Creating layer InnerProduct36
I0813 23:14:22.706565 21738 net.cpp:91] Creating Layer InnerProduct36
I0813 23:14:22.706573 21738 net.cpp:425] InnerProduct36 <- Dropout35
I0813 23:14:22.706579 21738 net.cpp:399] InnerProduct36 -> InnerProduct36
I0813 23:14:22.706862 21738 net.cpp:141] Setting up InnerProduct36
I0813 23:14:22.706871 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.706874 21738 net.cpp:156] Memory required for data: 330975200
I0813 23:14:22.706879 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.706885 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.706890 21738 layer_factory.hpp:77] Creating layer ReLU36
I0813 23:14:22.706898 21738 net.cpp:91] Creating Layer ReLU36
I0813 23:14:22.706903 21738 net.cpp:425] ReLU36 <- InnerProduct36
I0813 23:14:22.706908 21738 net.cpp:386] ReLU36 -> InnerProduct36 (in-place)
I0813 23:14:22.706935 21738 net.cpp:141] Setting up ReLU36
I0813 23:14:22.706941 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.706945 21738 net.cpp:156] Memory required for data: 331077600
I0813 23:14:22.706949 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.706957 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.706961 21738 net.cpp:425] drop2 <- InnerProduct36
I0813 23:14:22.706967 21738 net.cpp:399] drop2 -> Dropout36
I0813 23:14:22.706979 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.706984 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.706986 21738 net.cpp:156] Memory required for data: 331180000
I0813 23:14:22.706990 21738 layer_factory.hpp:77] Creating layer m18
I0813 23:14:22.707000 21738 net.cpp:91] Creating Layer m18
I0813 23:14:22.707006 21738 net.cpp:425] m18 <- Dropout36
I0813 23:14:22.707015 21738 net.cpp:399] m18 -> m18
I0813 23:14:22.707032 21738 net.cpp:141] Setting up m18
I0813 23:14:22.707041 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.707044 21738 net.cpp:156] Memory required for data: 331180800
I0813 23:14:22.707048 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.707053 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.707058 21738 layer_factory.hpp:77] Creating layer Concat19
I0813 23:14:22.707067 21738 net.cpp:91] Creating Layer Concat19
I0813 23:14:22.707072 21738 net.cpp:425] Concat19 <- i10
I0813 23:14:22.707078 21738 net.cpp:425] Concat19 <- i11_i1_10_split_9
I0813 23:14:22.707087 21738 net.cpp:399] Concat19 -> Concat19
I0813 23:14:22.707099 21738 net.cpp:141] Setting up Concat19
I0813 23:14:22.707106 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.707110 21738 net.cpp:156] Memory required for data: 337734400
I0813 23:14:22.707114 21738 layer_factory.hpp:77] Creating layer InnerProduct37
I0813 23:14:22.707121 21738 net.cpp:91] Creating Layer InnerProduct37
I0813 23:14:22.707125 21738 net.cpp:425] InnerProduct37 <- Concat19
I0813 23:14:22.707134 21738 net.cpp:399] InnerProduct37 -> InnerProduct37
I0813 23:14:22.723104 21738 net.cpp:141] Setting up InnerProduct37
I0813 23:14:22.723137 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.723142 21738 net.cpp:156] Memory required for data: 337939200
I0813 23:14:22.723152 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.723158 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.723165 21738 layer_factory.hpp:77] Creating layer ReLU37
I0813 23:14:22.723178 21738 net.cpp:91] Creating Layer ReLU37
I0813 23:14:22.723187 21738 net.cpp:425] ReLU37 <- InnerProduct37
I0813 23:14:22.723199 21738 net.cpp:386] ReLU37 -> InnerProduct37 (in-place)
I0813 23:14:22.723213 21738 net.cpp:141] Setting up ReLU37
I0813 23:14:22.723218 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.723223 21738 net.cpp:156] Memory required for data: 338144000
I0813 23:14:22.723227 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.723237 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.723242 21738 net.cpp:425] drop1 <- InnerProduct37
I0813 23:14:22.723250 21738 net.cpp:399] drop1 -> Dropout37
I0813 23:14:22.723265 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.723274 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.723278 21738 net.cpp:156] Memory required for data: 338348800
I0813 23:14:22.723284 21738 layer_factory.hpp:77] Creating layer InnerProduct38
I0813 23:14:22.723294 21738 net.cpp:91] Creating Layer InnerProduct38
I0813 23:14:22.723299 21738 net.cpp:425] InnerProduct38 <- Dropout37
I0813 23:14:22.723309 21738 net.cpp:399] InnerProduct38 -> InnerProduct38
I0813 23:14:22.723595 21738 net.cpp:141] Setting up InnerProduct38
I0813 23:14:22.723604 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.723608 21738 net.cpp:156] Memory required for data: 338451200
I0813 23:14:22.723613 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.723641 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.723646 21738 layer_factory.hpp:77] Creating layer ReLU38
I0813 23:14:22.723652 21738 net.cpp:91] Creating Layer ReLU38
I0813 23:14:22.723657 21738 net.cpp:425] ReLU38 <- InnerProduct38
I0813 23:14:22.723665 21738 net.cpp:386] ReLU38 -> InnerProduct38 (in-place)
I0813 23:14:22.723671 21738 net.cpp:141] Setting up ReLU38
I0813 23:14:22.723677 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.723680 21738 net.cpp:156] Memory required for data: 338553600
I0813 23:14:22.723685 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.723690 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.723695 21738 net.cpp:425] drop2 <- InnerProduct38
I0813 23:14:22.723702 21738 net.cpp:399] drop2 -> Dropout38
I0813 23:14:22.723712 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.723717 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.723721 21738 net.cpp:156] Memory required for data: 338656000
I0813 23:14:22.723724 21738 layer_factory.hpp:77] Creating layer m19
I0813 23:14:22.723732 21738 net.cpp:91] Creating Layer m19
I0813 23:14:22.723737 21738 net.cpp:425] m19 <- Dropout38
I0813 23:14:22.723747 21738 net.cpp:399] m19 -> m19
I0813 23:14:22.723764 21738 net.cpp:141] Setting up m19
I0813 23:14:22.723770 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.723774 21738 net.cpp:156] Memory required for data: 338656800
I0813 23:14:22.723779 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.723784 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.723788 21738 layer_factory.hpp:77] Creating layer con
I0813 23:14:22.723800 21738 net.cpp:91] Creating Layer con
I0813 23:14:22.723806 21738 net.cpp:425] con <- m1
I0813 23:14:22.723811 21738 net.cpp:425] con <- m2
I0813 23:14:22.723819 21738 net.cpp:425] con <- m3
I0813 23:14:22.723822 21738 net.cpp:425] con <- m4
I0813 23:14:22.723827 21738 net.cpp:425] con <- m5
I0813 23:14:22.723832 21738 net.cpp:425] con <- m6
I0813 23:14:22.723837 21738 net.cpp:425] con <- m7
I0813 23:14:22.723841 21738 net.cpp:425] con <- m8
I0813 23:14:22.723846 21738 net.cpp:425] con <- m9
I0813 23:14:22.723851 21738 net.cpp:425] con <- m10
I0813 23:14:22.723856 21738 net.cpp:425] con <- m11
I0813 23:14:22.723860 21738 net.cpp:425] con <- m12
I0813 23:14:22.723865 21738 net.cpp:425] con <- m13
I0813 23:14:22.723870 21738 net.cpp:425] con <- m14
I0813 23:14:22.723875 21738 net.cpp:425] con <- m15
I0813 23:14:22.723878 21738 net.cpp:425] con <- m16
I0813 23:14:22.723882 21738 net.cpp:425] con <- m17
I0813 23:14:22.723887 21738 net.cpp:425] con <- m18
I0813 23:14:22.723891 21738 net.cpp:425] con <- m19
I0813 23:14:22.723901 21738 net.cpp:399] con -> con
I0813 23:14:22.723917 21738 net.cpp:141] Setting up con
I0813 23:14:22.723922 21738 net.cpp:148] Top shape: 200 19 (3800)
I0813 23:14:22.723927 21738 net.cpp:156] Memory required for data: 338672000
I0813 23:14:22.723932 21738 layer_factory.hpp:77] Creating layer r1
I0813 23:14:22.723940 21738 net.cpp:91] Creating Layer r1
I0813 23:14:22.723947 21738 net.cpp:425] r1 <- con
I0813 23:14:22.723953 21738 net.cpp:399] r1 -> r1
I0813 23:14:22.723973 21738 net.cpp:141] Setting up r1
I0813 23:14:22.723978 21738 net.cpp:148] Top shape: 200 1 1 19 (3800)
I0813 23:14:22.723983 21738 net.cpp:156] Memory required for data: 338687200
I0813 23:14:22.723986 21738 layer_factory.hpp:77] Creating layer p
I0813 23:14:22.723996 21738 net.cpp:91] Creating Layer p
I0813 23:14:22.724002 21738 net.cpp:425] p <- r1
I0813 23:14:22.724007 21738 net.cpp:399] p -> p
I0813 23:14:22.724043 21738 net.cpp:141] Setting up p
I0813 23:14:22.724053 21738 net.cpp:148] Top shape: 200 1 1 1 (200)
I0813 23:14:22.724057 21738 net.cpp:156] Memory required for data: 338688000
I0813 23:14:22.724061 21738 layer_factory.hpp:77] Creating layer r2
I0813 23:14:22.724068 21738 net.cpp:91] Creating Layer r2
I0813 23:14:22.724072 21738 net.cpp:425] r2 <- p
I0813 23:14:22.724092 21738 net.cpp:399] r2 -> r2
I0813 23:14:22.724102 21738 net.cpp:141] Setting up r2
I0813 23:14:22.724108 21738 net.cpp:148] Top shape: 200 1 1 1 (200)
I0813 23:14:22.724112 21738 net.cpp:156] Memory required for data: 338688800
I0813 23:14:22.724117 21738 layer_factory.hpp:77] Creating layer padL
I0813 23:14:22.724124 21738 net.cpp:91] Creating Layer padL
I0813 23:14:22.724131 21738 net.cpp:425] padL <- label_data_1_split_1
I0813 23:14:22.724138 21738 net.cpp:399] padL -> padL
I0813 23:14:22.724145 21738 net.cpp:141] Setting up padL
I0813 23:14:22.724153 21738 net.cpp:148] Top shape: 200 1 1 1 (200)
I0813 23:14:22.724156 21738 net.cpp:156] Memory required for data: 338689600
I0813 23:14:22.724161 21738 layer_factory.hpp:77] Creating layer pad
I0813 23:14:22.724169 21738 net.cpp:91] Creating Layer pad
I0813 23:14:22.724174 21738 net.cpp:425] pad <- r2
I0813 23:14:22.724179 21738 net.cpp:425] pad <- padL
I0813 23:14:22.724184 21738 net.cpp:399] pad -> pad
I0813 23:14:22.724192 21738 net.cpp:141] Setting up pad
I0813 23:14:22.724197 21738 net.cpp:148] Top shape: 200 2 1 1 (400)
I0813 23:14:22.724203 21738 net.cpp:156] Memory required for data: 338691200
I0813 23:14:22.724207 21738 layer_factory.hpp:77] Creating layer pad_pad_0_split
I0813 23:14:22.724215 21738 net.cpp:91] Creating Layer pad_pad_0_split
I0813 23:14:22.724218 21738 net.cpp:425] pad_pad_0_split <- pad
I0813 23:14:22.724225 21738 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_0
I0813 23:14:22.724232 21738 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_1
I0813 23:14:22.724241 21738 net.cpp:141] Setting up pad_pad_0_split
I0813 23:14:22.724247 21738 net.cpp:148] Top shape: 200 2 1 1 (400)
I0813 23:14:22.724251 21738 net.cpp:148] Top shape: 200 2 1 1 (400)
I0813 23:14:22.724256 21738 net.cpp:156] Memory required for data: 338694400
I0813 23:14:22.724259 21738 layer_factory.hpp:77] Creating layer loss
I0813 23:14:22.724267 21738 net.cpp:91] Creating Layer loss
I0813 23:14:22.724272 21738 net.cpp:425] loss <- pad_pad_0_split_0
I0813 23:14:22.724277 21738 net.cpp:425] loss <- th_th_0_split_0
I0813 23:14:22.724283 21738 net.cpp:399] loss -> loss
I0813 23:14:22.724298 21738 net.cpp:141] Setting up loss
I0813 23:14:22.724304 21738 net.cpp:148] Top shape: (1)
I0813 23:14:22.724308 21738 net.cpp:151]     with loss weight 1
I0813 23:14:22.724331 21738 net.cpp:156] Memory required for data: 338694404
I0813 23:14:22.724335 21738 layer_factory.hpp:77] Creating layer accuracy
I0813 23:14:22.724344 21738 net.cpp:91] Creating Layer accuracy
I0813 23:14:22.724349 21738 net.cpp:425] accuracy <- pad_pad_0_split_1
I0813 23:14:22.724354 21738 net.cpp:425] accuracy <- th_th_0_split_1
I0813 23:14:22.724360 21738 net.cpp:399] accuracy -> accuracy
I0813 23:14:22.724371 21738 net.cpp:141] Setting up accuracy
I0813 23:14:22.724377 21738 net.cpp:148] Top shape: (1)
I0813 23:14:22.724381 21738 net.cpp:156] Memory required for data: 338694408
I0813 23:14:22.724385 21738 net.cpp:219] accuracy does not need backward computation.
I0813 23:14:22.724390 21738 net.cpp:217] loss needs backward computation.
I0813 23:14:22.724395 21738 net.cpp:217] pad_pad_0_split needs backward computation.
I0813 23:14:22.724398 21738 net.cpp:217] pad needs backward computation.
I0813 23:14:22.724403 21738 net.cpp:219] padL does not need backward computation.
I0813 23:14:22.724407 21738 net.cpp:217] r2 needs backward computation.
I0813 23:14:22.724412 21738 net.cpp:217] p needs backward computation.
I0813 23:14:22.724416 21738 net.cpp:217] r1 needs backward computation.
I0813 23:14:22.724421 21738 net.cpp:217] con needs backward computation.
I0813 23:14:22.724428 21738 net.cpp:217] m19 needs backward computation.
I0813 23:14:22.724432 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724436 21738 net.cpp:217] ReLU38 needs backward computation.
I0813 23:14:22.724441 21738 net.cpp:217] InnerProduct38 needs backward computation.
I0813 23:14:22.724444 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724448 21738 net.cpp:217] ReLU37 needs backward computation.
I0813 23:14:22.724462 21738 net.cpp:217] InnerProduct37 needs backward computation.
I0813 23:14:22.724467 21738 net.cpp:219] Concat19 does not need backward computation.
I0813 23:14:22.724472 21738 net.cpp:217] m18 needs backward computation.
I0813 23:14:22.724478 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724481 21738 net.cpp:217] ReLU36 needs backward computation.
I0813 23:14:22.724485 21738 net.cpp:217] InnerProduct36 needs backward computation.
I0813 23:14:22.724490 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724494 21738 net.cpp:217] ReLU35 needs backward computation.
I0813 23:14:22.724499 21738 net.cpp:217] InnerProduct35 needs backward computation.
I0813 23:14:22.724503 21738 net.cpp:219] Concat18 does not need backward computation.
I0813 23:14:22.724509 21738 net.cpp:217] m17 needs backward computation.
I0813 23:14:22.724514 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724519 21738 net.cpp:217] ReLU34 needs backward computation.
I0813 23:14:22.724524 21738 net.cpp:217] InnerProduct34 needs backward computation.
I0813 23:14:22.724527 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724532 21738 net.cpp:217] ReLU33 needs backward computation.
I0813 23:14:22.724536 21738 net.cpp:217] InnerProduct33 needs backward computation.
I0813 23:14:22.724540 21738 net.cpp:219] Concat17 does not need backward computation.
I0813 23:14:22.724546 21738 net.cpp:217] m16 needs backward computation.
I0813 23:14:22.724550 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724555 21738 net.cpp:217] ReLU32 needs backward computation.
I0813 23:14:22.724560 21738 net.cpp:217] InnerProduct32 needs backward computation.
I0813 23:14:22.724563 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724568 21738 net.cpp:217] ReLU31 needs backward computation.
I0813 23:14:22.724572 21738 net.cpp:217] InnerProduct31 needs backward computation.
I0813 23:14:22.724577 21738 net.cpp:219] Concat16 does not need backward computation.
I0813 23:14:22.724582 21738 net.cpp:217] m15 needs backward computation.
I0813 23:14:22.724587 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724591 21738 net.cpp:217] ReLU30 needs backward computation.
I0813 23:14:22.724596 21738 net.cpp:217] InnerProduct30 needs backward computation.
I0813 23:14:22.724601 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724604 21738 net.cpp:217] ReLU29 needs backward computation.
I0813 23:14:22.724609 21738 net.cpp:217] InnerProduct29 needs backward computation.
I0813 23:14:22.724613 21738 net.cpp:219] Concat15 does not need backward computation.
I0813 23:14:22.724619 21738 net.cpp:217] m14 needs backward computation.
I0813 23:14:22.724627 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724632 21738 net.cpp:217] ReLU28 needs backward computation.
I0813 23:14:22.724637 21738 net.cpp:217] InnerProduct28 needs backward computation.
I0813 23:14:22.724642 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724645 21738 net.cpp:217] ReLU27 needs backward computation.
I0813 23:14:22.724649 21738 net.cpp:217] InnerProduct27 needs backward computation.
I0813 23:14:22.724654 21738 net.cpp:219] Concat14 does not need backward computation.
I0813 23:14:22.724660 21738 net.cpp:217] m13 needs backward computation.
I0813 23:14:22.724665 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724669 21738 net.cpp:217] ReLU26 needs backward computation.
I0813 23:14:22.724674 21738 net.cpp:217] InnerProduct26 needs backward computation.
I0813 23:14:22.724679 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724684 21738 net.cpp:217] ReLU25 needs backward computation.
I0813 23:14:22.724689 21738 net.cpp:217] InnerProduct25 needs backward computation.
I0813 23:14:22.724692 21738 net.cpp:219] Concat13 does not need backward computation.
I0813 23:14:22.724699 21738 net.cpp:217] m12 needs backward computation.
I0813 23:14:22.724704 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724716 21738 net.cpp:217] ReLU24 needs backward computation.
I0813 23:14:22.724720 21738 net.cpp:217] InnerProduct24 needs backward computation.
I0813 23:14:22.724725 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724730 21738 net.cpp:217] ReLU23 needs backward computation.
I0813 23:14:22.724735 21738 net.cpp:217] InnerProduct23 needs backward computation.
I0813 23:14:22.724738 21738 net.cpp:219] Concat12 does not need backward computation.
I0813 23:14:22.724745 21738 net.cpp:217] m11 needs backward computation.
I0813 23:14:22.724750 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724753 21738 net.cpp:217] ReLU22 needs backward computation.
I0813 23:14:22.724759 21738 net.cpp:217] InnerProduct22 needs backward computation.
I0813 23:14:22.724763 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724768 21738 net.cpp:217] ReLU21 needs backward computation.
I0813 23:14:22.724772 21738 net.cpp:217] InnerProduct21 needs backward computation.
I0813 23:14:22.724777 21738 net.cpp:219] Concat11 does not need backward computation.
I0813 23:14:22.724782 21738 net.cpp:217] m10 needs backward computation.
I0813 23:14:22.724787 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724792 21738 net.cpp:217] ReLU20 needs backward computation.
I0813 23:14:22.724797 21738 net.cpp:217] InnerProduct20 needs backward computation.
I0813 23:14:22.724800 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724805 21738 net.cpp:217] ReLU19 needs backward computation.
I0813 23:14:22.724809 21738 net.cpp:217] InnerProduct19 needs backward computation.
I0813 23:14:22.724814 21738 net.cpp:219] Concat10 does not need backward computation.
I0813 23:14:22.724820 21738 net.cpp:217] m9 needs backward computation.
I0813 23:14:22.724825 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724829 21738 net.cpp:217] ReLU18 needs backward computation.
I0813 23:14:22.724833 21738 net.cpp:217] InnerProduct18 needs backward computation.
I0813 23:14:22.724838 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724843 21738 net.cpp:217] ReLU17 needs backward computation.
I0813 23:14:22.724846 21738 net.cpp:217] InnerProduct17 needs backward computation.
I0813 23:14:22.724853 21738 net.cpp:219] Concat9 does not need backward computation.
I0813 23:14:22.724858 21738 net.cpp:217] m8 needs backward computation.
I0813 23:14:22.724864 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724869 21738 net.cpp:217] ReLU16 needs backward computation.
I0813 23:14:22.724872 21738 net.cpp:217] InnerProduct16 needs backward computation.
I0813 23:14:22.724877 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724882 21738 net.cpp:217] ReLU15 needs backward computation.
I0813 23:14:22.724886 21738 net.cpp:217] InnerProduct15 needs backward computation.
I0813 23:14:22.724891 21738 net.cpp:219] Concat8 does not need backward computation.
I0813 23:14:22.724897 21738 net.cpp:217] m7 needs backward computation.
I0813 23:14:22.724902 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724906 21738 net.cpp:217] ReLU14 needs backward computation.
I0813 23:14:22.724911 21738 net.cpp:217] InnerProduct14 needs backward computation.
I0813 23:14:22.724915 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724920 21738 net.cpp:217] ReLU13 needs backward computation.
I0813 23:14:22.724925 21738 net.cpp:217] InnerProduct13 needs backward computation.
I0813 23:14:22.724930 21738 net.cpp:219] Concat7 does not need backward computation.
I0813 23:14:22.724934 21738 net.cpp:217] m6 needs backward computation.
I0813 23:14:22.724939 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724944 21738 net.cpp:217] ReLU12 needs backward computation.
I0813 23:14:22.724948 21738 net.cpp:217] InnerProduct12 needs backward computation.
I0813 23:14:22.724953 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.724957 21738 net.cpp:217] ReLU11 needs backward computation.
I0813 23:14:22.724969 21738 net.cpp:217] InnerProduct11 needs backward computation.
I0813 23:14:22.724977 21738 net.cpp:219] Concat6 does not need backward computation.
I0813 23:14:22.724982 21738 net.cpp:217] m5 needs backward computation.
I0813 23:14:22.724987 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.724992 21738 net.cpp:217] ReLU10 needs backward computation.
I0813 23:14:22.724997 21738 net.cpp:217] InnerProduct10 needs backward computation.
I0813 23:14:22.725000 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.725005 21738 net.cpp:217] ReLU9 needs backward computation.
I0813 23:14:22.725010 21738 net.cpp:217] InnerProduct9 needs backward computation.
I0813 23:14:22.725015 21738 net.cpp:219] Concat5 does not need backward computation.
I0813 23:14:22.725020 21738 net.cpp:217] m4 needs backward computation.
I0813 23:14:22.725025 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.725033 21738 net.cpp:217] ReLU8 needs backward computation.
I0813 23:14:22.725036 21738 net.cpp:217] InnerProduct8 needs backward computation.
I0813 23:14:22.725041 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.725045 21738 net.cpp:217] ReLU7 needs backward computation.
I0813 23:14:22.725050 21738 net.cpp:217] InnerProduct7 needs backward computation.
I0813 23:14:22.725055 21738 net.cpp:219] Concat4 does not need backward computation.
I0813 23:14:22.725060 21738 net.cpp:217] m3 needs backward computation.
I0813 23:14:22.725065 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.725070 21738 net.cpp:217] ReLU6 needs backward computation.
I0813 23:14:22.725075 21738 net.cpp:217] InnerProduct6 needs backward computation.
I0813 23:14:22.725080 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.725083 21738 net.cpp:217] ReLU5 needs backward computation.
I0813 23:14:22.725087 21738 net.cpp:217] InnerProduct5 needs backward computation.
I0813 23:14:22.725092 21738 net.cpp:219] Concat3 does not need backward computation.
I0813 23:14:22.725097 21738 net.cpp:217] m2 needs backward computation.
I0813 23:14:22.725102 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.725106 21738 net.cpp:217] ReLU4 needs backward computation.
I0813 23:14:22.725111 21738 net.cpp:217] InnerProduct4 needs backward computation.
I0813 23:14:22.725116 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.725121 21738 net.cpp:217] ReLU3 needs backward computation.
I0813 23:14:22.725124 21738 net.cpp:217] InnerProduct3 needs backward computation.
I0813 23:14:22.725129 21738 net.cpp:219] Concat2 does not need backward computation.
I0813 23:14:22.725136 21738 net.cpp:217] m1 needs backward computation.
I0813 23:14:22.725139 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:22.725144 21738 net.cpp:217] ReLU2 needs backward computation.
I0813 23:14:22.725148 21738 net.cpp:217] InnerProduct2 needs backward computation.
I0813 23:14:22.725153 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:22.725158 21738 net.cpp:217] ReLU1 needs backward computation.
I0813 23:14:22.725162 21738 net.cpp:217] InnerProduct1 needs backward computation.
I0813 23:14:22.725167 21738 net.cpp:219] Concat1 does not need backward computation.
I0813 23:14:22.725175 21738 net.cpp:219] i11_i1_10_split does not need backward computation.
I0813 23:14:22.725184 21738 net.cpp:219] i1_i1_0_split does not need backward computation.
I0813 23:14:22.725193 21738 net.cpp:219] i1 does not need backward computation.
I0813 23:14:22.725199 21738 net.cpp:219] th_th_0_split does not need backward computation.
I0813 23:14:22.725203 21738 net.cpp:219] th does not need backward computation.
I0813 23:14:22.725209 21738 net.cpp:219] label_data_1_split does not need backward computation.
I0813 23:14:22.725214 21738 net.cpp:219] data does not need backward computation.
I0813 23:14:22.725219 21738 net.cpp:261] This network produces output accuracy
I0813 23:14:22.725222 21738 net.cpp:261] This network produces output loss
I0813 23:14:22.727138 21738 net.cpp:274] Network initialization done.
I0813 23:14:22.730834 21738 solver.cpp:181] Creating test net (#0) specified by test_net file: examples/scene/metNetTest.prototxt
I0813 23:14:22.731933 21738 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 1
    mirror: false
  }
  data_param {
    source: "/home/shaogang/Datasets/FeatsDB/featsTest1k"
    batch_size: 200
    backend: LMDB
  }
}
layer {
  name: "th"
  type: "Threshold"
  bottom: "label"
  top: "th"
  threshold_param {
    threshold: 0
  }
}
layer {
  name: "i1"
  type: "Slice"
  bottom: "data"
  top: "i1"
  top: "i2"
  top: "i3"
  top: "i4"
  top: "i5"
  top: "i6"
  top: "i7"
  top: "i8"
  top: "i9"
  top: "i10"
  top: "i11"
  top: "i12"
  top: "i13"
  top: "i14"
  top: "i15"
  top: "i16"
  top: "i17"
  top: "i18"
  top: "i19"
  top: "i20"
  slice_param {
    slice_dim: 2
    slice_point: 1
    slice_point: 2
    slice_point: 3
    slice_point: 4
    slice_point: 5
    slice_point: 6
    slice_point: 7
    slice_point: 8
    slice_point: 9
    slice_point: 10
    slice_point: 11
    slice_point: 12
    slice_point: 13
    slice_point: 14
    slice_point: 15
    slice_point: 16
    slice_point: 17
    slice_point: 18
    slice_point: 19
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "i1"
  bottom: "i11"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Concat1"
  top: "InnerProduct1"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct1"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "Dropout1"
  top: "InnerProduct2"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "InnerProduct2"
  top: "InnerProduct2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct2"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m1"
  type: "InnerProduct"
  bottom: "Dropout2"
  top: "m1"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "i1"
  bottom: "i12"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "Concat2"
  top: "InnerProduct3"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct3"
  top: "InnerProduct3"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct3"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "Dropout3"
  top: "InnerProduct4"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "InnerProduct4"
  top: "InnerProduct4"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct4"
  top: "Dropout4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m2"
  type: "InnerProduct"
  bottom: "Dropout4"
  top: "m2"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "i1"
  bottom: "i13"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct5"
  type: "InnerProduct"
  bottom: "Concat3"
  top: "InnerProduct5"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "InnerProduct5"
  top: "InnerProduct5"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct5"
  top: "Dropout5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct6"
  type: "InnerProduct"
  bottom: "Dropout5"
  top: "InnerProduct6"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "InnerProduct6"
  top: "InnerProduct6"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct6"
  top: "Dropout6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m3"
  type: "InnerProduct"
  bottom: "Dropout6"
  top: "m3"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "i1"
  bottom: "i14"
  top: "Concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct7"
  type: "InnerProduct"
  bottom: "Concat4"
  top: "InnerProduct7"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "InnerProduct7"
  top: "InnerProduct7"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct7"
  top: "Dropout7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct8"
  type: "InnerProduct"
  bottom: "Dropout7"
  top: "InnerProduct8"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "InnerProduct8"
  top: "InnerProduct8"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct8"
  top: "Dropout8"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m4"
  type: "InnerProduct"
  bottom: "Dropout8"
  top: "m4"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "i1"
  bottom: "i15"
  top: "Concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct9"
  type: "InnerProduct"
  bottom: "Concat5"
  top: "InnerProduct9"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "InnerProduct9"
  top: "InnerProduct9"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct9"
  top: "Dropout9"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct10"
  type: "InnerProduct"
  bottom: "Dropout9"
  top: "InnerProduct10"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "InnerProduct10"
  top: "InnerProduct10"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct10"
  top: "Dropout10"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m5"
  type: "InnerProduct"
  bottom: "Dropout10"
  top: "m5"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "i1"
  bottom: "i16"
  top: "Concat6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct11"
  type: "InnerProduct"
  bottom: "Concat6"
  top: "InnerProduct11"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "InnerProduct11"
  top: "InnerProduct11"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct11"
  top: "Dropout11"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct12"
  type: "InnerProduct"
  bottom: "Dropout11"
  top: "InnerProduct12"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "InnerProduct12"
  top: "InnerProduct12"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct12"
  top: "Dropout12"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m6"
  type: "InnerProduct"
  bottom: "Dropout12"
  top: "m6"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "i1"
  bottom: "i17"
  top: "Concat7"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct13"
  type: "InnerProduct"
  bottom: "Concat7"
  top: "InnerProduct13"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "InnerProduct13"
  top: "InnerProduct13"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct13"
  top: "Dropout13"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct14"
  type: "InnerProduct"
  bottom: "Dropout13"
  top: "InnerProduct14"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "InnerProduct14"
  top: "InnerProduct14"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct14"
  top: "Dropout14"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m7"
  type: "InnerProduct"
  bottom: "Dropout14"
  top: "m7"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "i1"
  bottom: "i18"
  top: "Concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct15"
  type: "InnerProduct"
  bottom: "Concat8"
  top: "InnerProduct15"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "InnerProduct15"
  top: "InnerProduct15"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct15"
  top: "Dropout15"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct16"
  type: "InnerProduct"
  bottom: "Dropout15"
  top: "InnerProduct16"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "InnerProduct16"
  top: "InnerProduct16"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct16"
  top: "Dropout16"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m8"
  type: "InnerProduct"
  bottom: "Dropout16"
  top: "m8"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "i1"
  bottom: "i19"
  top: "Concat9"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct17"
  type: "InnerProduct"
  bottom: "Concat9"
  top: "InnerProduct17"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "InnerProduct17"
  top: "InnerProduct17"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct17"
  top: "Dropout17"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct18"
  type: "InnerProduct"
  bottom: "Dropout17"
  top: "InnerProduct18"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "InnerProduct18"
  top: "InnerProduct18"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct18"
  top: "Dropout18"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m9"
  type: "InnerProduct"
  bottom: "Dropout18"
  top: "m9"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat10"
  type: "Concat"
  bottom: "i1"
  bottom: "i20"
  top: "Concat10"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct19"
  type: "InnerProduct"
  bottom: "Concat10"
  top: "InnerProduct19"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "InnerProduct19"
  top: "InnerProduct19"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct19"
  top: "Dropout19"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct20"
  type: "InnerProduct"
  bottom: "Dropout19"
  top: "InnerProduct20"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "InnerProduct20"
  top: "InnerProduct20"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct20"
  top: "Dropout20"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m10"
  type: "InnerProduct"
  bottom: "Dropout20"
  top: "m10"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat11"
  type: "Concat"
  bottom: "i2"
  bottom: "i11"
  top: "Concat11"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct21"
  type: "InnerProduct"
  bottom: "Concat11"
  top: "InnerProduct21"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "InnerProduct21"
  top: "InnerProduct21"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct21"
  top: "Dropout21"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct22"
  type: "InnerProduct"
  bottom: "Dropout21"
  top: "InnerProduct22"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "InnerProduct22"
  top: "InnerProduct22"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct22"
  top: "Dropout22"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m11"
  type: "InnerProduct"
  bottom: "Dropout22"
  top: "m11"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat12"
  type: "Concat"
  bottom: "i3"
  bottom: "i11"
  top: "Concat12"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct23"
  type: "InnerProduct"
  bottom: "Concat12"
  top: "InnerProduct23"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "InnerProduct23"
  top: "InnerProduct23"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct23"
  top: "Dropout23"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct24"
  type: "InnerProduct"
  bottom: "Dropout23"
  top: "InnerProduct24"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "InnerProduct24"
  top: "InnerProduct24"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct24"
  top: "Dropout24"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m12"
  type: "InnerProduct"
  bottom: "Dropout24"
  top: "m12"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat13"
  type: "Concat"
  bottom: "i4"
  bottom: "i11"
  top: "Concat13"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct25"
  type: "InnerProduct"
  bottom: "Concat13"
  top: "InnerProduct25"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "InnerProduct25"
  top: "InnerProduct25"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct25"
  top: "Dropout25"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct26"
  type: "InnerProduct"
  bottom: "Dropout25"
  top: "InnerProduct26"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "InnerProduct26"
  top: "InnerProduct26"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct26"
  top: "Dropout26"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m13"
  type: "InnerProduct"
  bottom: "Dropout26"
  top: "m13"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat14"
  type: "Concat"
  bottom: "i5"
  bottom: "i11"
  top: "Concat14"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct27"
  type: "InnerProduct"
  bottom: "Concat14"
  top: "InnerProduct27"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "InnerProduct27"
  top: "InnerProduct27"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct27"
  top: "Dropout27"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct28"
  type: "InnerProduct"
  bottom: "Dropout27"
  top: "InnerProduct28"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "InnerProduct28"
  top: "InnerProduct28"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct28"
  top: "Dropout28"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m14"
  type: "InnerProduct"
  bottom: "Dropout28"
  top: "m14"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat15"
  type: "Concat"
  bottom: "i6"
  bottom: "i11"
  top: "Concat15"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct29"
  type: "InnerProduct"
  bottom: "Concat15"
  top: "InnerProduct29"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "InnerProduct29"
  top: "InnerProduct29"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct29"
  top: "Dropout29"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct30"
  type: "InnerProduct"
  bottom: "Dropout29"
  top: "InnerProduct30"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "InnerProduct30"
  top: "InnerProduct30"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct30"
  top: "Dropout30"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m15"
  type: "InnerProduct"
  bottom: "Dropout30"
  top: "m15"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat16"
  type: "Concat"
  bottom: "i7"
  bottom: "i11"
  top: "Concat16"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct31"
  type: "InnerProduct"
  bottom: "Concat16"
  top: "InnerProduct31"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "InnerProduct31"
  top: "InnerProduct31"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct31"
  top: "Dropout31"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct32"
  type: "InnerProduct"
  bottom: "Dropout31"
  top: "InnerProduct32"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "InnerProduct32"
  top: "InnerProduct32"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct32"
  top: "Dropout32"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m16"
  type: "InnerProduct"
  bottom: "Dropout32"
  top: "m16"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat17"
  type: "Concat"
  bottom: "i8"
  bottom: "i11"
  top: "Concat17"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct33"
  type: "InnerProduct"
  bottom: "Concat17"
  top: "InnerProduct33"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "InnerProduct33"
  top: "InnerProduct33"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct33"
  top: "Dropout33"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct34"
  type: "InnerProduct"
  bottom: "Dropout33"
  top: "InnerProduct34"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "InnerProduct34"
  top: "InnerProduct34"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct34"
  top: "Dropout34"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m17"
  type: "InnerProduct"
  bottom: "Dropout34"
  top: "m17"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat18"
  type: "Concat"
  bottom: "i9"
  bottom: "i11"
  top: "Concat18"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct35"
  type: "InnerProduct"
  bottom: "Concat18"
  top: "InnerProduct35"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "InnerProduct35"
  top: "InnerProduct35"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct35"
  top: "Dropout35"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct36"
  type: "InnerProduct"
  bottom: "Dropout35"
  top: "InnerProduct36"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "InnerProduct36"
  top: "InnerProduct36"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct36"
  top: "Dropout36"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "m18"
  type: "InnerProduct"
  bottom: "Dropout36"
  top: "m18"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat19"
  type: "Concat"
  bottom: "i10"
  bottom: "i11"
  top: "Concat19"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct37"
  type: "InnerProduct"
  bottom: "Concat19"
  top: "InnerProduct37"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU37"
 
I0813 23:14:22.732671 21738 layer_factory.hpp:77] Creating layer data
I0813 23:14:22.732847 21738 net.cpp:91] Creating Layer data
I0813 23:14:22.732857 21738 net.cpp:399] data -> data
I0813 23:14:22.732869 21738 net.cpp:399] data -> label
I0813 23:14:22.733080 21744 db_lmdb.cpp:35] Opened lmdb /home/shaogang/Datasets/FeatsDB/featsTest1k
I0813 23:14:22.734494 21738 data_layer.cpp:41] output data size: 200,1,20,4096
I0813 23:14:22.796767 21738 net.cpp:141] Setting up data
I0813 23:14:22.796808 21738 net.cpp:148] Top shape: 200 1 20 4096 (16384000)
I0813 23:14:22.796815 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.796820 21738 net.cpp:156] Memory required for data: 65536800
I0813 23:14:22.796830 21738 layer_factory.hpp:77] Creating layer label_data_1_split
I0813 23:14:22.796849 21738 net.cpp:91] Creating Layer label_data_1_split
I0813 23:14:22.796857 21738 net.cpp:425] label_data_1_split <- label
I0813 23:14:22.796866 21738 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0813 23:14:22.796880 21738 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0813 23:14:22.796895 21738 net.cpp:141] Setting up label_data_1_split
I0813 23:14:22.796902 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.796907 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.796912 21738 net.cpp:156] Memory required for data: 65538400
I0813 23:14:22.796917 21738 layer_factory.hpp:77] Creating layer th
I0813 23:14:22.796927 21738 net.cpp:91] Creating Layer th
I0813 23:14:22.796933 21738 net.cpp:425] th <- label_data_1_split_0
I0813 23:14:22.796941 21738 net.cpp:399] th -> th
I0813 23:14:22.796950 21738 net.cpp:141] Setting up th
I0813 23:14:22.796958 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.796965 21738 net.cpp:156] Memory required for data: 65539200
I0813 23:14:22.796969 21738 layer_factory.hpp:77] Creating layer th_th_0_split
I0813 23:14:22.796977 21738 net.cpp:91] Creating Layer th_th_0_split
I0813 23:14:22.796982 21738 net.cpp:425] th_th_0_split <- th
I0813 23:14:22.796988 21738 net.cpp:399] th_th_0_split -> th_th_0_split_0
I0813 23:14:22.796993 21738 net.cpp:399] th_th_0_split -> th_th_0_split_1
I0813 23:14:22.797000 21738 net.cpp:141] Setting up th_th_0_split
I0813 23:14:22.797006 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.797011 21738 net.cpp:148] Top shape: 200 (200)
I0813 23:14:22.797014 21738 net.cpp:156] Memory required for data: 65540800
I0813 23:14:22.797019 21738 layer_factory.hpp:77] Creating layer i1
I0813 23:14:22.797032 21738 net.cpp:91] Creating Layer i1
I0813 23:14:22.797039 21738 net.cpp:425] i1 <- data
I0813 23:14:22.797047 21738 net.cpp:399] i1 -> i1
I0813 23:14:22.797077 21738 net.cpp:399] i1 -> i2
I0813 23:14:22.797087 21738 net.cpp:399] i1 -> i3
I0813 23:14:22.797096 21738 net.cpp:399] i1 -> i4
I0813 23:14:22.797103 21738 net.cpp:399] i1 -> i5
I0813 23:14:22.797111 21738 net.cpp:399] i1 -> i6
I0813 23:14:22.797119 21738 net.cpp:399] i1 -> i7
I0813 23:14:22.797127 21738 net.cpp:399] i1 -> i8
I0813 23:14:22.797139 21738 net.cpp:399] i1 -> i9
I0813 23:14:22.797147 21738 net.cpp:399] i1 -> i10
I0813 23:14:22.797158 21738 net.cpp:399] i1 -> i11
I0813 23:14:22.797168 21738 net.cpp:399] i1 -> i12
I0813 23:14:22.797175 21738 net.cpp:399] i1 -> i13
I0813 23:14:22.797184 21738 net.cpp:399] i1 -> i14
I0813 23:14:22.797193 21738 net.cpp:399] i1 -> i15
I0813 23:14:22.797202 21738 net.cpp:399] i1 -> i16
I0813 23:14:22.797210 21738 net.cpp:399] i1 -> i17
I0813 23:14:22.797219 21738 net.cpp:399] i1 -> i18
I0813 23:14:22.797227 21738 net.cpp:399] i1 -> i19
I0813 23:14:22.797236 21738 net.cpp:399] i1 -> i20
I0813 23:14:22.797258 21738 net.cpp:141] Setting up i1
I0813 23:14:22.797266 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797271 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797277 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797281 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797286 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797291 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797296 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797302 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797307 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797312 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797317 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797322 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797325 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797330 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797335 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797339 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797344 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797349 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797353 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797358 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797363 21738 net.cpp:156] Memory required for data: 131076800
I0813 23:14:22.797368 21738 layer_factory.hpp:77] Creating layer i1_i1_0_split
I0813 23:14:22.797374 21738 net.cpp:91] Creating Layer i1_i1_0_split
I0813 23:14:22.797379 21738 net.cpp:425] i1_i1_0_split <- i1
I0813 23:14:22.797386 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_0
I0813 23:14:22.797394 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_1
I0813 23:14:22.797402 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_2
I0813 23:14:22.797410 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_3
I0813 23:14:22.797417 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_4
I0813 23:14:22.797425 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_5
I0813 23:14:22.797433 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_6
I0813 23:14:22.797442 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_7
I0813 23:14:22.797448 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_8
I0813 23:14:22.797456 21738 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_9
I0813 23:14:22.797466 21738 net.cpp:141] Setting up i1_i1_0_split
I0813 23:14:22.797472 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797477 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797482 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797487 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797492 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797497 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797502 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797513 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797518 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797523 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797528 21738 net.cpp:156] Memory required for data: 163844800
I0813 23:14:22.797531 21738 layer_factory.hpp:77] Creating layer i11_i1_10_split
I0813 23:14:22.797538 21738 net.cpp:91] Creating Layer i11_i1_10_split
I0813 23:14:22.797544 21738 net.cpp:425] i11_i1_10_split <- i11
I0813 23:14:22.797550 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_0
I0813 23:14:22.797559 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_1
I0813 23:14:22.797567 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_2
I0813 23:14:22.797574 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_3
I0813 23:14:22.797580 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_4
I0813 23:14:22.797587 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_5
I0813 23:14:22.797595 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_6
I0813 23:14:22.797601 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_7
I0813 23:14:22.797611 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_8
I0813 23:14:22.797617 21738 net.cpp:399] i11_i1_10_split -> i11_i1_10_split_9
I0813 23:14:22.797628 21738 net.cpp:141] Setting up i11_i1_10_split
I0813 23:14:22.797634 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797639 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797643 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797648 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797652 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797657 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797662 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797667 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797672 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797677 21738 net.cpp:148] Top shape: 200 1 1 4096 (819200)
I0813 23:14:22.797680 21738 net.cpp:156] Memory required for data: 196612800
I0813 23:14:22.797684 21738 layer_factory.hpp:77] Creating layer Concat1
I0813 23:14:22.797693 21738 net.cpp:91] Creating Layer Concat1
I0813 23:14:22.797698 21738 net.cpp:425] Concat1 <- i1_i1_0_split_0
I0813 23:14:22.797703 21738 net.cpp:425] Concat1 <- i11_i1_10_split_0
I0813 23:14:22.797708 21738 net.cpp:399] Concat1 -> Concat1
I0813 23:14:22.797719 21738 net.cpp:141] Setting up Concat1
I0813 23:14:22.797725 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.797729 21738 net.cpp:156] Memory required for data: 203166400
I0813 23:14:22.797732 21738 layer_factory.hpp:77] Creating layer InnerProduct1
I0813 23:14:22.797744 21738 net.cpp:91] Creating Layer InnerProduct1
I0813 23:14:22.797750 21738 net.cpp:425] InnerProduct1 <- Concat1
I0813 23:14:22.797757 21738 net.cpp:399] InnerProduct1 -> InnerProduct1
I0813 23:14:22.813727 21738 net.cpp:141] Setting up InnerProduct1
I0813 23:14:22.813761 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.813767 21738 net.cpp:156] Memory required for data: 203371200
I0813 23:14:22.813784 21738 layer_factory.hpp:77] Creating layer ReLU1
I0813 23:14:22.813798 21738 net.cpp:91] Creating Layer ReLU1
I0813 23:14:22.813805 21738 net.cpp:425] ReLU1 <- InnerProduct1
I0813 23:14:22.813814 21738 net.cpp:386] ReLU1 -> InnerProduct1 (in-place)
I0813 23:14:22.813827 21738 net.cpp:141] Setting up ReLU1
I0813 23:14:22.813832 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.813837 21738 net.cpp:156] Memory required for data: 203576000
I0813 23:14:22.813840 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.813850 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.813858 21738 net.cpp:425] drop1 <- InnerProduct1
I0813 23:14:22.813865 21738 net.cpp:399] drop1 -> Dropout1
I0813 23:14:22.813875 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.813881 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.813905 21738 net.cpp:156] Memory required for data: 203780800
I0813 23:14:22.813910 21738 layer_factory.hpp:77] Creating layer InnerProduct2
I0813 23:14:22.813921 21738 net.cpp:91] Creating Layer InnerProduct2
I0813 23:14:22.813931 21738 net.cpp:425] InnerProduct2 <- Dropout1
I0813 23:14:22.813941 21738 net.cpp:399] InnerProduct2 -> InnerProduct2
I0813 23:14:22.814177 21738 net.cpp:141] Setting up InnerProduct2
I0813 23:14:22.814185 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.814189 21738 net.cpp:156] Memory required for data: 203883200
I0813 23:14:22.814198 21738 layer_factory.hpp:77] Creating layer ReLU2
I0813 23:14:22.814204 21738 net.cpp:91] Creating Layer ReLU2
I0813 23:14:22.814208 21738 net.cpp:425] ReLU2 <- InnerProduct2
I0813 23:14:22.814215 21738 net.cpp:386] ReLU2 -> InnerProduct2 (in-place)
I0813 23:14:22.814223 21738 net.cpp:141] Setting up ReLU2
I0813 23:14:22.814226 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.814230 21738 net.cpp:156] Memory required for data: 203985600
I0813 23:14:22.814234 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.814241 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.814245 21738 net.cpp:425] drop2 <- InnerProduct2
I0813 23:14:22.814252 21738 net.cpp:399] drop2 -> Dropout2
I0813 23:14:22.814260 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.814265 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.814270 21738 net.cpp:156] Memory required for data: 204088000
I0813 23:14:22.814275 21738 layer_factory.hpp:77] Creating layer m1
I0813 23:14:22.814283 21738 net.cpp:91] Creating Layer m1
I0813 23:14:22.814291 21738 net.cpp:425] m1 <- Dropout2
I0813 23:14:22.814299 21738 net.cpp:399] m1 -> m1
I0813 23:14:22.814316 21738 net.cpp:141] Setting up m1
I0813 23:14:22.814321 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.814326 21738 net.cpp:156] Memory required for data: 204088800
I0813 23:14:22.814332 21738 layer_factory.hpp:77] Creating layer Concat2
I0813 23:14:22.814342 21738 net.cpp:91] Creating Layer Concat2
I0813 23:14:22.814350 21738 net.cpp:425] Concat2 <- i1_i1_0_split_1
I0813 23:14:22.814357 21738 net.cpp:425] Concat2 <- i12
I0813 23:14:22.814364 21738 net.cpp:399] Concat2 -> Concat2
I0813 23:14:22.814373 21738 net.cpp:141] Setting up Concat2
I0813 23:14:22.814380 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.814384 21738 net.cpp:156] Memory required for data: 210642400
I0813 23:14:22.814389 21738 layer_factory.hpp:77] Creating layer InnerProduct3
I0813 23:14:22.814399 21738 net.cpp:91] Creating Layer InnerProduct3
I0813 23:14:22.814404 21738 net.cpp:425] InnerProduct3 <- Concat2
I0813 23:14:22.814411 21738 net.cpp:399] InnerProduct3 -> InnerProduct3
I0813 23:14:22.830516 21738 net.cpp:141] Setting up InnerProduct3
I0813 23:14:22.830550 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.830556 21738 net.cpp:156] Memory required for data: 210847200
I0813 23:14:22.830566 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.830574 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.830581 21738 layer_factory.hpp:77] Creating layer ReLU3
I0813 23:14:22.830597 21738 net.cpp:91] Creating Layer ReLU3
I0813 23:14:22.830605 21738 net.cpp:425] ReLU3 <- InnerProduct3
I0813 23:14:22.830615 21738 net.cpp:386] ReLU3 -> InnerProduct3 (in-place)
I0813 23:14:22.830629 21738 net.cpp:141] Setting up ReLU3
I0813 23:14:22.830636 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.830639 21738 net.cpp:156] Memory required for data: 211052000
I0813 23:14:22.830643 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.830652 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.830657 21738 net.cpp:425] drop1 <- InnerProduct3
I0813 23:14:22.830664 21738 net.cpp:399] drop1 -> Dropout3
I0813 23:14:22.830677 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.830682 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.830685 21738 net.cpp:156] Memory required for data: 211256800
I0813 23:14:22.830708 21738 layer_factory.hpp:77] Creating layer InnerProduct4
I0813 23:14:22.830718 21738 net.cpp:91] Creating Layer InnerProduct4
I0813 23:14:22.830725 21738 net.cpp:425] InnerProduct4 <- Dropout3
I0813 23:14:22.830734 21738 net.cpp:399] InnerProduct4 -> InnerProduct4
I0813 23:14:22.830970 21738 net.cpp:141] Setting up InnerProduct4
I0813 23:14:22.830978 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.830982 21738 net.cpp:156] Memory required for data: 211359200
I0813 23:14:22.830991 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.830999 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.831004 21738 layer_factory.hpp:77] Creating layer ReLU4
I0813 23:14:22.831012 21738 net.cpp:91] Creating Layer ReLU4
I0813 23:14:22.831015 21738 net.cpp:425] ReLU4 <- InnerProduct4
I0813 23:14:22.831022 21738 net.cpp:386] ReLU4 -> InnerProduct4 (in-place)
I0813 23:14:22.831028 21738 net.cpp:141] Setting up ReLU4
I0813 23:14:22.831035 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.831039 21738 net.cpp:156] Memory required for data: 211461600
I0813 23:14:22.831043 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.831051 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.831058 21738 net.cpp:425] drop2 <- InnerProduct4
I0813 23:14:22.831063 21738 net.cpp:399] drop2 -> Dropout4
I0813 23:14:22.831073 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.831078 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.831081 21738 net.cpp:156] Memory required for data: 211564000
I0813 23:14:22.831086 21738 layer_factory.hpp:77] Creating layer m2
I0813 23:14:22.831095 21738 net.cpp:91] Creating Layer m2
I0813 23:14:22.831099 21738 net.cpp:425] m2 <- Dropout4
I0813 23:14:22.831106 21738 net.cpp:399] m2 -> m2
I0813 23:14:22.831121 21738 net.cpp:141] Setting up m2
I0813 23:14:22.831128 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.831132 21738 net.cpp:156] Memory required for data: 211564800
I0813 23:14:22.831137 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.831142 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.831147 21738 layer_factory.hpp:77] Creating layer Concat3
I0813 23:14:22.831156 21738 net.cpp:91] Creating Layer Concat3
I0813 23:14:22.831163 21738 net.cpp:425] Concat3 <- i1_i1_0_split_2
I0813 23:14:22.831171 21738 net.cpp:425] Concat3 <- i13
I0813 23:14:22.831179 21738 net.cpp:399] Concat3 -> Concat3
I0813 23:14:22.831189 21738 net.cpp:141] Setting up Concat3
I0813 23:14:22.831195 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.831199 21738 net.cpp:156] Memory required for data: 218118400
I0813 23:14:22.831203 21738 layer_factory.hpp:77] Creating layer InnerProduct5
I0813 23:14:22.831212 21738 net.cpp:91] Creating Layer InnerProduct5
I0813 23:14:22.831217 21738 net.cpp:425] InnerProduct5 <- Concat3
I0813 23:14:22.831224 21738 net.cpp:399] InnerProduct5 -> InnerProduct5
I0813 23:14:22.847401 21738 net.cpp:141] Setting up InnerProduct5
I0813 23:14:22.847435 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.847441 21738 net.cpp:156] Memory required for data: 218323200
I0813 23:14:22.847452 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.847460 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.847465 21738 layer_factory.hpp:77] Creating layer ReLU5
I0813 23:14:22.847479 21738 net.cpp:91] Creating Layer ReLU5
I0813 23:14:22.847487 21738 net.cpp:425] ReLU5 <- InnerProduct5
I0813 23:14:22.847496 21738 net.cpp:386] ReLU5 -> InnerProduct5 (in-place)
I0813 23:14:22.847509 21738 net.cpp:141] Setting up ReLU5
I0813 23:14:22.847515 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.847519 21738 net.cpp:156] Memory required for data: 218528000
I0813 23:14:22.847523 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.847553 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.847558 21738 net.cpp:425] drop1 <- InnerProduct5
I0813 23:14:22.847563 21738 net.cpp:399] drop1 -> Dropout5
I0813 23:14:22.847574 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.847580 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.847584 21738 net.cpp:156] Memory required for data: 218732800
I0813 23:14:22.847589 21738 layer_factory.hpp:77] Creating layer InnerProduct6
I0813 23:14:22.847599 21738 net.cpp:91] Creating Layer InnerProduct6
I0813 23:14:22.847604 21738 net.cpp:425] InnerProduct6 <- Dropout5
I0813 23:14:22.847614 21738 net.cpp:399] InnerProduct6 -> InnerProduct6
I0813 23:14:22.847848 21738 net.cpp:141] Setting up InnerProduct6
I0813 23:14:22.847856 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.847862 21738 net.cpp:156] Memory required for data: 218835200
I0813 23:14:22.847867 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.847872 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.847877 21738 layer_factory.hpp:77] Creating layer ReLU6
I0813 23:14:22.847883 21738 net.cpp:91] Creating Layer ReLU6
I0813 23:14:22.847887 21738 net.cpp:425] ReLU6 <- InnerProduct6
I0813 23:14:22.847894 21738 net.cpp:386] ReLU6 -> InnerProduct6 (in-place)
I0813 23:14:22.847900 21738 net.cpp:141] Setting up ReLU6
I0813 23:14:22.847905 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.847909 21738 net.cpp:156] Memory required for data: 218937600
I0813 23:14:22.847913 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.847925 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.847930 21738 net.cpp:425] drop2 <- InnerProduct6
I0813 23:14:22.847936 21738 net.cpp:399] drop2 -> Dropout6
I0813 23:14:22.847944 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.847949 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.847952 21738 net.cpp:156] Memory required for data: 219040000
I0813 23:14:22.847956 21738 layer_factory.hpp:77] Creating layer m3
I0813 23:14:22.847965 21738 net.cpp:91] Creating Layer m3
I0813 23:14:22.847970 21738 net.cpp:425] m3 <- Dropout6
I0813 23:14:22.847977 21738 net.cpp:399] m3 -> m3
I0813 23:14:22.848003 21738 net.cpp:141] Setting up m3
I0813 23:14:22.848011 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.848017 21738 net.cpp:156] Memory required for data: 219040800
I0813 23:14:22.848037 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.848042 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.848047 21738 layer_factory.hpp:77] Creating layer Concat4
I0813 23:14:22.848057 21738 net.cpp:91] Creating Layer Concat4
I0813 23:14:22.848062 21738 net.cpp:425] Concat4 <- i1_i1_0_split_3
I0813 23:14:22.848067 21738 net.cpp:425] Concat4 <- i14
I0813 23:14:22.848074 21738 net.cpp:399] Concat4 -> Concat4
I0813 23:14:22.848089 21738 net.cpp:141] Setting up Concat4
I0813 23:14:22.848098 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.848104 21738 net.cpp:156] Memory required for data: 225594400
I0813 23:14:22.848109 21738 layer_factory.hpp:77] Creating layer InnerProduct7
I0813 23:14:22.848129 21738 net.cpp:91] Creating Layer InnerProduct7
I0813 23:14:22.848134 21738 net.cpp:425] InnerProduct7 <- Concat4
I0813 23:14:22.848145 21738 net.cpp:399] InnerProduct7 -> InnerProduct7
I0813 23:14:22.864327 21738 net.cpp:141] Setting up InnerProduct7
I0813 23:14:22.864362 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.864369 21738 net.cpp:156] Memory required for data: 225799200
I0813 23:14:22.864378 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.864385 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.864392 21738 layer_factory.hpp:77] Creating layer ReLU7
I0813 23:14:22.864405 21738 net.cpp:91] Creating Layer ReLU7
I0813 23:14:22.864434 21738 net.cpp:425] ReLU7 <- InnerProduct7
I0813 23:14:22.864444 21738 net.cpp:386] ReLU7 -> InnerProduct7 (in-place)
I0813 23:14:22.864456 21738 net.cpp:141] Setting up ReLU7
I0813 23:14:22.864461 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.864465 21738 net.cpp:156] Memory required for data: 226004000
I0813 23:14:22.864470 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.864480 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.864483 21738 net.cpp:425] drop1 <- InnerProduct7
I0813 23:14:22.864491 21738 net.cpp:399] drop1 -> Dropout7
I0813 23:14:22.864505 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.864509 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.864516 21738 net.cpp:156] Memory required for data: 226208800
I0813 23:14:22.864521 21738 layer_factory.hpp:77] Creating layer InnerProduct8
I0813 23:14:22.864531 21738 net.cpp:91] Creating Layer InnerProduct8
I0813 23:14:22.864537 21738 net.cpp:425] InnerProduct8 <- Dropout7
I0813 23:14:22.864547 21738 net.cpp:399] InnerProduct8 -> InnerProduct8
I0813 23:14:22.864785 21738 net.cpp:141] Setting up InnerProduct8
I0813 23:14:22.864796 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.864800 21738 net.cpp:156] Memory required for data: 226311200
I0813 23:14:22.864805 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.864811 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.864815 21738 layer_factory.hpp:77] Creating layer ReLU8
I0813 23:14:22.864821 21738 net.cpp:91] Creating Layer ReLU8
I0813 23:14:22.864826 21738 net.cpp:425] ReLU8 <- InnerProduct8
I0813 23:14:22.864832 21738 net.cpp:386] ReLU8 -> InnerProduct8 (in-place)
I0813 23:14:22.864840 21738 net.cpp:141] Setting up ReLU8
I0813 23:14:22.864845 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.864847 21738 net.cpp:156] Memory required for data: 226413600
I0813 23:14:22.864851 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.864858 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.864863 21738 net.cpp:425] drop2 <- InnerProduct8
I0813 23:14:22.864869 21738 net.cpp:399] drop2 -> Dropout8
I0813 23:14:22.864876 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.864881 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.864886 21738 net.cpp:156] Memory required for data: 226516000
I0813 23:14:22.864889 21738 layer_factory.hpp:77] Creating layer m4
I0813 23:14:22.864898 21738 net.cpp:91] Creating Layer m4
I0813 23:14:22.864902 21738 net.cpp:425] m4 <- Dropout8
I0813 23:14:22.864909 21738 net.cpp:399] m4 -> m4
I0813 23:14:22.864923 21738 net.cpp:141] Setting up m4
I0813 23:14:22.864929 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.864938 21738 net.cpp:156] Memory required for data: 226516800
I0813 23:14:22.864943 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.864948 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.864953 21738 layer_factory.hpp:77] Creating layer Concat5
I0813 23:14:22.864960 21738 net.cpp:91] Creating Layer Concat5
I0813 23:14:22.864965 21738 net.cpp:425] Concat5 <- i1_i1_0_split_4
I0813 23:14:22.864972 21738 net.cpp:425] Concat5 <- i15
I0813 23:14:22.864980 21738 net.cpp:399] Concat5 -> Concat5
I0813 23:14:22.864990 21738 net.cpp:141] Setting up Concat5
I0813 23:14:22.864996 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.865000 21738 net.cpp:156] Memory required for data: 233070400
I0813 23:14:22.865003 21738 layer_factory.hpp:77] Creating layer InnerProduct9
I0813 23:14:22.865012 21738 net.cpp:91] Creating Layer InnerProduct9
I0813 23:14:22.865017 21738 net.cpp:425] InnerProduct9 <- Concat5
I0813 23:14:22.865025 21738 net.cpp:399] InnerProduct9 -> InnerProduct9
I0813 23:14:22.884706 21738 net.cpp:141] Setting up InnerProduct9
I0813 23:14:22.884742 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.884749 21738 net.cpp:156] Memory required for data: 233275200
I0813 23:14:22.884788 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.884795 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.884801 21738 layer_factory.hpp:77] Creating layer ReLU9
I0813 23:14:22.884817 21738 net.cpp:91] Creating Layer ReLU9
I0813 23:14:22.884825 21738 net.cpp:425] ReLU9 <- InnerProduct9
I0813 23:14:22.884835 21738 net.cpp:386] ReLU9 -> InnerProduct9 (in-place)
I0813 23:14:22.884850 21738 net.cpp:141] Setting up ReLU9
I0813 23:14:22.884857 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.884861 21738 net.cpp:156] Memory required for data: 233480000
I0813 23:14:22.884866 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.884876 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.884881 21738 net.cpp:425] drop1 <- InnerProduct9
I0813 23:14:22.884891 21738 net.cpp:399] drop1 -> Dropout9
I0813 23:14:22.884901 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.884907 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.884912 21738 net.cpp:156] Memory required for data: 233684800
I0813 23:14:22.884915 21738 layer_factory.hpp:77] Creating layer InnerProduct10
I0813 23:14:22.884928 21738 net.cpp:91] Creating Layer InnerProduct10
I0813 23:14:22.884933 21738 net.cpp:425] InnerProduct10 <- Dropout9
I0813 23:14:22.884941 21738 net.cpp:399] InnerProduct10 -> InnerProduct10
I0813 23:14:22.885205 21738 net.cpp:141] Setting up InnerProduct10
I0813 23:14:22.885216 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.885221 21738 net.cpp:156] Memory required for data: 233787200
I0813 23:14:22.885226 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.885232 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.885237 21738 layer_factory.hpp:77] Creating layer ReLU10
I0813 23:14:22.885244 21738 net.cpp:91] Creating Layer ReLU10
I0813 23:14:22.885249 21738 net.cpp:425] ReLU10 <- InnerProduct10
I0813 23:14:22.885257 21738 net.cpp:386] ReLU10 -> InnerProduct10 (in-place)
I0813 23:14:22.885263 21738 net.cpp:141] Setting up ReLU10
I0813 23:14:22.885268 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.885272 21738 net.cpp:156] Memory required for data: 233889600
I0813 23:14:22.885277 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.885284 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.885289 21738 net.cpp:425] drop2 <- InnerProduct10
I0813 23:14:22.885295 21738 net.cpp:399] drop2 -> Dropout10
I0813 23:14:22.885303 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.885309 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.885313 21738 net.cpp:156] Memory required for data: 233992000
I0813 23:14:22.885318 21738 layer_factory.hpp:77] Creating layer m5
I0813 23:14:22.885327 21738 net.cpp:91] Creating Layer m5
I0813 23:14:22.885331 21738 net.cpp:425] m5 <- Dropout10
I0813 23:14:22.885340 21738 net.cpp:399] m5 -> m5
I0813 23:14:22.885355 21738 net.cpp:141] Setting up m5
I0813 23:14:22.885361 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.885366 21738 net.cpp:156] Memory required for data: 233992800
I0813 23:14:22.885371 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.885377 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.885381 21738 layer_factory.hpp:77] Creating layer Concat6
I0813 23:14:22.885390 21738 net.cpp:91] Creating Layer Concat6
I0813 23:14:22.885397 21738 net.cpp:425] Concat6 <- i1_i1_0_split_5
I0813 23:14:22.885404 21738 net.cpp:425] Concat6 <- i16
I0813 23:14:22.885412 21738 net.cpp:399] Concat6 -> Concat6
I0813 23:14:22.885423 21738 net.cpp:141] Setting up Concat6
I0813 23:14:22.885428 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.885433 21738 net.cpp:156] Memory required for data: 240546400
I0813 23:14:22.885438 21738 layer_factory.hpp:77] Creating layer InnerProduct11
I0813 23:14:22.885457 21738 net.cpp:91] Creating Layer InnerProduct11
I0813 23:14:22.885462 21738 net.cpp:425] InnerProduct11 <- Concat6
I0813 23:14:22.885470 21738 net.cpp:399] InnerProduct11 -> InnerProduct11
I0813 23:14:22.902751 21738 net.cpp:141] Setting up InnerProduct11
I0813 23:14:22.902787 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.902793 21738 net.cpp:156] Memory required for data: 240751200
I0813 23:14:22.902802 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.902809 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.902815 21738 layer_factory.hpp:77] Creating layer ReLU11
I0813 23:14:22.902830 21738 net.cpp:91] Creating Layer ReLU11
I0813 23:14:22.902838 21738 net.cpp:425] ReLU11 <- InnerProduct11
I0813 23:14:22.902848 21738 net.cpp:386] ReLU11 -> InnerProduct11 (in-place)
I0813 23:14:22.902863 21738 net.cpp:141] Setting up ReLU11
I0813 23:14:22.902869 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.902873 21738 net.cpp:156] Memory required for data: 240956000
I0813 23:14:22.902878 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.902887 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.902892 21738 net.cpp:425] drop1 <- InnerProduct11
I0813 23:14:22.902899 21738 net.cpp:399] drop1 -> Dropout11
I0813 23:14:22.902910 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.902917 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.902921 21738 net.cpp:156] Memory required for data: 241160800
I0813 23:14:22.902925 21738 layer_factory.hpp:77] Creating layer InnerProduct12
I0813 23:14:22.902936 21738 net.cpp:91] Creating Layer InnerProduct12
I0813 23:14:22.902941 21738 net.cpp:425] InnerProduct12 <- Dropout11
I0813 23:14:22.902950 21738 net.cpp:399] InnerProduct12 -> InnerProduct12
I0813 23:14:22.903203 21738 net.cpp:141] Setting up InnerProduct12
I0813 23:14:22.903211 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.903216 21738 net.cpp:156] Memory required for data: 241263200
I0813 23:14:22.903230 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.903237 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.903244 21738 layer_factory.hpp:77] Creating layer ReLU12
I0813 23:14:22.903251 21738 net.cpp:91] Creating Layer ReLU12
I0813 23:14:22.903256 21738 net.cpp:425] ReLU12 <- InnerProduct12
I0813 23:14:22.903264 21738 net.cpp:386] ReLU12 -> InnerProduct12 (in-place)
I0813 23:14:22.903271 21738 net.cpp:141] Setting up ReLU12
I0813 23:14:22.903276 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.903280 21738 net.cpp:156] Memory required for data: 241365600
I0813 23:14:22.903285 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.903291 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.903296 21738 net.cpp:425] drop2 <- InnerProduct12
I0813 23:14:22.903302 21738 net.cpp:399] drop2 -> Dropout12
I0813 23:14:22.903311 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.903316 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.903321 21738 net.cpp:156] Memory required for data: 241468000
I0813 23:14:22.903326 21738 layer_factory.hpp:77] Creating layer m6
I0813 23:14:22.903334 21738 net.cpp:91] Creating Layer m6
I0813 23:14:22.903339 21738 net.cpp:425] m6 <- Dropout12
I0813 23:14:22.903348 21738 net.cpp:399] m6 -> m6
I0813 23:14:22.903364 21738 net.cpp:141] Setting up m6
I0813 23:14:22.903372 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.903375 21738 net.cpp:156] Memory required for data: 241468800
I0813 23:14:22.903380 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.903386 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.903390 21738 layer_factory.hpp:77] Creating layer Concat7
I0813 23:14:22.903399 21738 net.cpp:91] Creating Layer Concat7
I0813 23:14:22.903406 21738 net.cpp:425] Concat7 <- i1_i1_0_split_6
I0813 23:14:22.903429 21738 net.cpp:425] Concat7 <- i17
I0813 23:14:22.903437 21738 net.cpp:399] Concat7 -> Concat7
I0813 23:14:22.903450 21738 net.cpp:141] Setting up Concat7
I0813 23:14:22.903455 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.903460 21738 net.cpp:156] Memory required for data: 248022400
I0813 23:14:22.903467 21738 layer_factory.hpp:77] Creating layer InnerProduct13
I0813 23:14:22.903476 21738 net.cpp:91] Creating Layer InnerProduct13
I0813 23:14:22.903481 21738 net.cpp:425] InnerProduct13 <- Concat7
I0813 23:14:22.903488 21738 net.cpp:399] InnerProduct13 -> InnerProduct13
I0813 23:14:22.924160 21738 net.cpp:141] Setting up InnerProduct13
I0813 23:14:22.924206 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.924216 21738 net.cpp:156] Memory required for data: 248227200
I0813 23:14:22.924232 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.924242 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.924263 21738 layer_factory.hpp:77] Creating layer ReLU13
I0813 23:14:22.924283 21738 net.cpp:91] Creating Layer ReLU13
I0813 23:14:22.924296 21738 net.cpp:425] ReLU13 <- InnerProduct13
I0813 23:14:22.924310 21738 net.cpp:386] ReLU13 -> InnerProduct13 (in-place)
I0813 23:14:22.924329 21738 net.cpp:141] Setting up ReLU13
I0813 23:14:22.924338 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.924345 21738 net.cpp:156] Memory required for data: 248432000
I0813 23:14:22.924352 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.924366 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.924376 21738 net.cpp:425] drop1 <- InnerProduct13
I0813 23:14:22.924389 21738 net.cpp:399] drop1 -> Dropout13
I0813 23:14:22.924407 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.924417 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.924422 21738 net.cpp:156] Memory required for data: 248636800
I0813 23:14:22.924428 21738 layer_factory.hpp:77] Creating layer InnerProduct14
I0813 23:14:22.924445 21738 net.cpp:91] Creating Layer InnerProduct14
I0813 23:14:22.924455 21738 net.cpp:425] InnerProduct14 <- Dropout13
I0813 23:14:22.924468 21738 net.cpp:399] InnerProduct14 -> InnerProduct14
I0813 23:14:22.924772 21738 net.cpp:141] Setting up InnerProduct14
I0813 23:14:22.924785 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.924793 21738 net.cpp:156] Memory required for data: 248739200
I0813 23:14:22.924800 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.924808 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.924816 21738 layer_factory.hpp:77] Creating layer ReLU14
I0813 23:14:22.924826 21738 net.cpp:91] Creating Layer ReLU14
I0813 23:14:22.924834 21738 net.cpp:425] ReLU14 <- InnerProduct14
I0813 23:14:22.924844 21738 net.cpp:386] ReLU14 -> InnerProduct14 (in-place)
I0813 23:14:22.924860 21738 net.cpp:141] Setting up ReLU14
I0813 23:14:22.924870 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.924875 21738 net.cpp:156] Memory required for data: 248841600
I0813 23:14:22.924881 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.924892 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.924898 21738 net.cpp:425] drop2 <- InnerProduct14
I0813 23:14:22.924908 21738 net.cpp:399] drop2 -> Dropout14
I0813 23:14:22.924921 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.924932 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.924938 21738 net.cpp:156] Memory required for data: 248944000
I0813 23:14:22.924944 21738 layer_factory.hpp:77] Creating layer m7
I0813 23:14:22.924960 21738 net.cpp:91] Creating Layer m7
I0813 23:14:22.924968 21738 net.cpp:425] m7 <- Dropout14
I0813 23:14:22.924983 21738 net.cpp:399] m7 -> m7
I0813 23:14:22.925010 21738 net.cpp:141] Setting up m7
I0813 23:14:22.925024 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.925032 21738 net.cpp:156] Memory required for data: 248944800
I0813 23:14:22.925071 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.925081 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.925087 21738 layer_factory.hpp:77] Creating layer Concat8
I0813 23:14:22.925099 21738 net.cpp:91] Creating Layer Concat8
I0813 23:14:22.925108 21738 net.cpp:425] Concat8 <- i1_i1_0_split_7
I0813 23:14:22.925119 21738 net.cpp:425] Concat8 <- i18
I0813 23:14:22.925132 21738 net.cpp:399] Concat8 -> Concat8
I0813 23:14:22.925148 21738 net.cpp:141] Setting up Concat8
I0813 23:14:22.925161 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.925169 21738 net.cpp:156] Memory required for data: 255498400
I0813 23:14:22.925176 21738 layer_factory.hpp:77] Creating layer InnerProduct15
I0813 23:14:22.925207 21738 net.cpp:91] Creating Layer InnerProduct15
I0813 23:14:22.925220 21738 net.cpp:425] InnerProduct15 <- Concat8
I0813 23:14:22.925235 21738 net.cpp:399] InnerProduct15 -> InnerProduct15
I0813 23:14:22.943570 21738 net.cpp:141] Setting up InnerProduct15
I0813 23:14:22.943608 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.943614 21738 net.cpp:156] Memory required for data: 255703200
I0813 23:14:22.943624 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.943631 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.943639 21738 layer_factory.hpp:77] Creating layer ReLU15
I0813 23:14:22.943652 21738 net.cpp:91] Creating Layer ReLU15
I0813 23:14:22.943660 21738 net.cpp:425] ReLU15 <- InnerProduct15
I0813 23:14:22.943668 21738 net.cpp:386] ReLU15 -> InnerProduct15 (in-place)
I0813 23:14:22.943681 21738 net.cpp:141] Setting up ReLU15
I0813 23:14:22.943686 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.943691 21738 net.cpp:156] Memory required for data: 255908000
I0813 23:14:22.943696 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.943707 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.943712 21738 net.cpp:425] drop1 <- InnerProduct15
I0813 23:14:22.943719 21738 net.cpp:399] drop1 -> Dropout15
I0813 23:14:22.943730 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.943737 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.943740 21738 net.cpp:156] Memory required for data: 256112800
I0813 23:14:22.943744 21738 layer_factory.hpp:77] Creating layer InnerProduct16
I0813 23:14:22.943756 21738 net.cpp:91] Creating Layer InnerProduct16
I0813 23:14:22.943760 21738 net.cpp:425] InnerProduct16 <- Dropout15
I0813 23:14:22.943768 21738 net.cpp:399] InnerProduct16 -> InnerProduct16
I0813 23:14:22.944005 21738 net.cpp:141] Setting up InnerProduct16
I0813 23:14:22.944015 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.944020 21738 net.cpp:156] Memory required for data: 256215200
I0813 23:14:22.944053 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.944059 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.944064 21738 layer_factory.hpp:77] Creating layer ReLU16
I0813 23:14:22.944072 21738 net.cpp:91] Creating Layer ReLU16
I0813 23:14:22.944077 21738 net.cpp:425] ReLU16 <- InnerProduct16
I0813 23:14:22.944082 21738 net.cpp:386] ReLU16 -> InnerProduct16 (in-place)
I0813 23:14:22.944089 21738 net.cpp:141] Setting up ReLU16
I0813 23:14:22.944094 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.944098 21738 net.cpp:156] Memory required for data: 256317600
I0813 23:14:22.944103 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.944110 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.944115 21738 net.cpp:425] drop2 <- InnerProduct16
I0813 23:14:22.944121 21738 net.cpp:399] drop2 -> Dropout16
I0813 23:14:22.944129 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.944134 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.944139 21738 net.cpp:156] Memory required for data: 256420000
I0813 23:14:22.944162 21738 layer_factory.hpp:77] Creating layer m8
I0813 23:14:22.944171 21738 net.cpp:91] Creating Layer m8
I0813 23:14:22.944176 21738 net.cpp:425] m8 <- Dropout16
I0813 23:14:22.944185 21738 net.cpp:399] m8 -> m8
I0813 23:14:22.944202 21738 net.cpp:141] Setting up m8
I0813 23:14:22.944210 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.944212 21738 net.cpp:156] Memory required for data: 256420800
I0813 23:14:22.944217 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.944223 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.944227 21738 layer_factory.hpp:77] Creating layer Concat9
I0813 23:14:22.944236 21738 net.cpp:91] Creating Layer Concat9
I0813 23:14:22.944242 21738 net.cpp:425] Concat9 <- i1_i1_0_split_8
I0813 23:14:22.944248 21738 net.cpp:425] Concat9 <- i19
I0813 23:14:22.944257 21738 net.cpp:399] Concat9 -> Concat9
I0813 23:14:22.944267 21738 net.cpp:141] Setting up Concat9
I0813 23:14:22.944272 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.944275 21738 net.cpp:156] Memory required for data: 262974400
I0813 23:14:22.944279 21738 layer_factory.hpp:77] Creating layer InnerProduct17
I0813 23:14:22.944288 21738 net.cpp:91] Creating Layer InnerProduct17
I0813 23:14:22.944293 21738 net.cpp:425] InnerProduct17 <- Concat9
I0813 23:14:22.944300 21738 net.cpp:399] InnerProduct17 -> InnerProduct17
I0813 23:14:22.960494 21738 net.cpp:141] Setting up InnerProduct17
I0813 23:14:22.960528 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.960535 21738 net.cpp:156] Memory required for data: 263179200
I0813 23:14:22.960543 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.960551 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.960556 21738 layer_factory.hpp:77] Creating layer ReLU17
I0813 23:14:22.960571 21738 net.cpp:91] Creating Layer ReLU17
I0813 23:14:22.960577 21738 net.cpp:425] ReLU17 <- InnerProduct17
I0813 23:14:22.960587 21738 net.cpp:386] ReLU17 -> InnerProduct17 (in-place)
I0813 23:14:22.960602 21738 net.cpp:141] Setting up ReLU17
I0813 23:14:22.960608 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.960613 21738 net.cpp:156] Memory required for data: 263384000
I0813 23:14:22.960616 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.960626 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.960635 21738 net.cpp:425] drop1 <- InnerProduct17
I0813 23:14:22.960645 21738 net.cpp:399] drop1 -> Dropout17
I0813 23:14:22.960656 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.960664 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.960669 21738 net.cpp:156] Memory required for data: 263588800
I0813 23:14:22.960674 21738 layer_factory.hpp:77] Creating layer InnerProduct18
I0813 23:14:22.960685 21738 net.cpp:91] Creating Layer InnerProduct18
I0813 23:14:22.960691 21738 net.cpp:425] InnerProduct18 <- Dropout17
I0813 23:14:22.960700 21738 net.cpp:399] InnerProduct18 -> InnerProduct18
I0813 23:14:22.960938 21738 net.cpp:141] Setting up InnerProduct18
I0813 23:14:22.960947 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.960952 21738 net.cpp:156] Memory required for data: 263691200
I0813 23:14:22.960957 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.960963 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.960966 21738 layer_factory.hpp:77] Creating layer ReLU18
I0813 23:14:22.960973 21738 net.cpp:91] Creating Layer ReLU18
I0813 23:14:22.960978 21738 net.cpp:425] ReLU18 <- InnerProduct18
I0813 23:14:22.960984 21738 net.cpp:386] ReLU18 -> InnerProduct18 (in-place)
I0813 23:14:22.960993 21738 net.cpp:141] Setting up ReLU18
I0813 23:14:22.960999 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.961004 21738 net.cpp:156] Memory required for data: 263793600
I0813 23:14:22.961030 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.961036 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.961041 21738 net.cpp:425] drop2 <- InnerProduct18
I0813 23:14:22.961047 21738 net.cpp:399] drop2 -> Dropout18
I0813 23:14:22.961055 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.961063 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.961067 21738 net.cpp:156] Memory required for data: 263896000
I0813 23:14:22.961072 21738 layer_factory.hpp:77] Creating layer m9
I0813 23:14:22.961081 21738 net.cpp:91] Creating Layer m9
I0813 23:14:22.961084 21738 net.cpp:425] m9 <- Dropout18
I0813 23:14:22.961093 21738 net.cpp:399] m9 -> m9
I0813 23:14:22.961109 21738 net.cpp:141] Setting up m9
I0813 23:14:22.961115 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.961119 21738 net.cpp:156] Memory required for data: 263896800
I0813 23:14:22.961124 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.961129 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.961134 21738 layer_factory.hpp:77] Creating layer Concat10
I0813 23:14:22.961143 21738 net.cpp:91] Creating Layer Concat10
I0813 23:14:22.961148 21738 net.cpp:425] Concat10 <- i1_i1_0_split_9
I0813 23:14:22.961155 21738 net.cpp:425] Concat10 <- i20
I0813 23:14:22.961163 21738 net.cpp:399] Concat10 -> Concat10
I0813 23:14:22.961172 21738 net.cpp:141] Setting up Concat10
I0813 23:14:22.961177 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.961181 21738 net.cpp:156] Memory required for data: 270450400
I0813 23:14:22.961185 21738 layer_factory.hpp:77] Creating layer InnerProduct19
I0813 23:14:22.961194 21738 net.cpp:91] Creating Layer InnerProduct19
I0813 23:14:22.961199 21738 net.cpp:425] InnerProduct19 <- Concat10
I0813 23:14:22.961205 21738 net.cpp:399] InnerProduct19 -> InnerProduct19
I0813 23:14:22.987937 21738 net.cpp:141] Setting up InnerProduct19
I0813 23:14:22.988119 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.988164 21738 net.cpp:156] Memory required for data: 270655200
I0813 23:14:22.988206 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:22.988245 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:22.988281 21738 layer_factory.hpp:77] Creating layer ReLU19
I0813 23:14:22.988328 21738 net.cpp:91] Creating Layer ReLU19
I0813 23:14:22.988368 21738 net.cpp:425] ReLU19 <- InnerProduct19
I0813 23:14:22.988411 21738 net.cpp:386] ReLU19 -> InnerProduct19 (in-place)
I0813 23:14:22.988462 21738 net.cpp:141] Setting up ReLU19
I0813 23:14:22.988504 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.988539 21738 net.cpp:156] Memory required for data: 270860000
I0813 23:14:22.988574 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:22.988618 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:22.988659 21738 net.cpp:425] drop1 <- InnerProduct19
I0813 23:14:22.988759 21738 net.cpp:399] drop1 -> Dropout19
I0813 23:14:22.988801 21738 net.cpp:141] Setting up drop1
I0813 23:14:22.988824 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:22.988839 21738 net.cpp:156] Memory required for data: 271064800
I0813 23:14:22.988854 21738 layer_factory.hpp:77] Creating layer InnerProduct20
I0813 23:14:22.988884 21738 net.cpp:91] Creating Layer InnerProduct20
I0813 23:14:22.988903 21738 net.cpp:425] InnerProduct20 <- Dropout19
I0813 23:14:22.988931 21738 net.cpp:399] InnerProduct20 -> InnerProduct20
I0813 23:14:22.989544 21738 net.cpp:141] Setting up InnerProduct20
I0813 23:14:22.989573 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.989586 21738 net.cpp:156] Memory required for data: 271167200
I0813 23:14:22.989641 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:22.989661 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:22.989675 21738 layer_factory.hpp:77] Creating layer ReLU20
I0813 23:14:22.989729 21738 net.cpp:91] Creating Layer ReLU20
I0813 23:14:22.989751 21738 net.cpp:425] ReLU20 <- InnerProduct20
I0813 23:14:22.989773 21738 net.cpp:386] ReLU20 -> InnerProduct20 (in-place)
I0813 23:14:22.989801 21738 net.cpp:141] Setting up ReLU20
I0813 23:14:22.989823 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.989842 21738 net.cpp:156] Memory required for data: 271269600
I0813 23:14:22.989852 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:22.989866 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:22.989876 21738 net.cpp:425] drop2 <- InnerProduct20
I0813 23:14:22.989887 21738 net.cpp:399] drop2 -> Dropout20
I0813 23:14:22.989907 21738 net.cpp:141] Setting up drop2
I0813 23:14:22.989917 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:22.989925 21738 net.cpp:156] Memory required for data: 271372000
I0813 23:14:22.989933 21738 layer_factory.hpp:77] Creating layer m10
I0813 23:14:22.989948 21738 net.cpp:91] Creating Layer m10
I0813 23:14:22.989958 21738 net.cpp:425] m10 <- Dropout20
I0813 23:14:22.989971 21738 net.cpp:399] m10 -> m10
I0813 23:14:22.990005 21738 net.cpp:141] Setting up m10
I0813 23:14:22.990020 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:22.990027 21738 net.cpp:156] Memory required for data: 271372800
I0813 23:14:22.990041 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:22.990052 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:22.990061 21738 layer_factory.hpp:77] Creating layer Concat11
I0813 23:14:22.990074 21738 net.cpp:91] Creating Layer Concat11
I0813 23:14:22.990084 21738 net.cpp:425] Concat11 <- i2
I0813 23:14:22.990097 21738 net.cpp:425] Concat11 <- i11_i1_10_split_1
I0813 23:14:22.990110 21738 net.cpp:399] Concat11 -> Concat11
I0813 23:14:22.990129 21738 net.cpp:141] Setting up Concat11
I0813 23:14:22.990144 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:22.990150 21738 net.cpp:156] Memory required for data: 277926400
I0813 23:14:22.990159 21738 layer_factory.hpp:77] Creating layer InnerProduct21
I0813 23:14:22.990173 21738 net.cpp:91] Creating Layer InnerProduct21
I0813 23:14:22.990181 21738 net.cpp:425] InnerProduct21 <- Concat11
I0813 23:14:22.990195 21738 net.cpp:399] InnerProduct21 -> InnerProduct21
I0813 23:14:23.023495 21738 net.cpp:141] Setting up InnerProduct21
I0813 23:14:23.023538 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.023548 21738 net.cpp:156] Memory required for data: 278131200
I0813 23:14:23.023561 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:23.023571 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:23.023581 21738 layer_factory.hpp:77] Creating layer ReLU21
I0813 23:14:23.023602 21738 net.cpp:91] Creating Layer ReLU21
I0813 23:14:23.023613 21738 net.cpp:425] ReLU21 <- InnerProduct21
I0813 23:14:23.023627 21738 net.cpp:386] ReLU21 -> InnerProduct21 (in-place)
I0813 23:14:23.023644 21738 net.cpp:141] Setting up ReLU21
I0813 23:14:23.023653 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.023659 21738 net.cpp:156] Memory required for data: 278336000
I0813 23:14:23.023666 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:23.023679 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:23.023686 21738 net.cpp:425] drop1 <- InnerProduct21
I0813 23:14:23.023699 21738 net.cpp:399] drop1 -> Dropout21
I0813 23:14:23.023715 21738 net.cpp:141] Setting up drop1
I0813 23:14:23.023725 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.023730 21738 net.cpp:156] Memory required for data: 278540800
I0813 23:14:23.023737 21738 layer_factory.hpp:77] Creating layer InnerProduct22
I0813 23:14:23.023751 21738 net.cpp:91] Creating Layer InnerProduct22
I0813 23:14:23.023758 21738 net.cpp:425] InnerProduct22 <- Dropout21
I0813 23:14:23.023769 21738 net.cpp:399] InnerProduct22 -> InnerProduct22
I0813 23:14:23.024216 21738 net.cpp:141] Setting up InnerProduct22
I0813 23:14:23.024260 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.024267 21738 net.cpp:156] Memory required for data: 278643200
I0813 23:14:23.024276 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:23.024284 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:23.024291 21738 layer_factory.hpp:77] Creating layer ReLU22
I0813 23:14:23.024304 21738 net.cpp:91] Creating Layer ReLU22
I0813 23:14:23.024315 21738 net.cpp:425] ReLU22 <- InnerProduct22
I0813 23:14:23.024325 21738 net.cpp:386] ReLU22 -> InnerProduct22 (in-place)
I0813 23:14:23.024338 21738 net.cpp:141] Setting up ReLU22
I0813 23:14:23.024345 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.024351 21738 net.cpp:156] Memory required for data: 278745600
I0813 23:14:23.024358 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:23.024368 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:23.024374 21738 net.cpp:425] drop2 <- InnerProduct22
I0813 23:14:23.024384 21738 net.cpp:399] drop2 -> Dropout22
I0813 23:14:23.024396 21738 net.cpp:141] Setting up drop2
I0813 23:14:23.024405 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.024410 21738 net.cpp:156] Memory required for data: 278848000
I0813 23:14:23.024416 21738 layer_factory.hpp:77] Creating layer m11
I0813 23:14:23.024428 21738 net.cpp:91] Creating Layer m11
I0813 23:14:23.024435 21738 net.cpp:425] m11 <- Dropout22
I0813 23:14:23.024446 21738 net.cpp:399] m11 -> m11
I0813 23:14:23.024471 21738 net.cpp:141] Setting up m11
I0813 23:14:23.024482 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:23.024487 21738 net.cpp:156] Memory required for data: 278848800
I0813 23:14:23.024512 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:23.024521 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:23.024528 21738 layer_factory.hpp:77] Creating layer Concat12
I0813 23:14:23.024540 21738 net.cpp:91] Creating Layer Concat12
I0813 23:14:23.024547 21738 net.cpp:425] Concat12 <- i3
I0813 23:14:23.024557 21738 net.cpp:425] Concat12 <- i11_i1_10_split_2
I0813 23:14:23.024567 21738 net.cpp:399] Concat12 -> Concat12
I0813 23:14:23.024583 21738 net.cpp:141] Setting up Concat12
I0813 23:14:23.024591 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:23.024597 21738 net.cpp:156] Memory required for data: 285402400
I0813 23:14:23.024605 21738 layer_factory.hpp:77] Creating layer InnerProduct23
I0813 23:14:23.024616 21738 net.cpp:91] Creating Layer InnerProduct23
I0813 23:14:23.024622 21738 net.cpp:425] InnerProduct23 <- Concat12
I0813 23:14:23.024634 21738 net.cpp:399] InnerProduct23 -> InnerProduct23
I0813 23:14:23.051070 21738 net.cpp:141] Setting up InnerProduct23
I0813 23:14:23.051112 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.051120 21738 net.cpp:156] Memory required for data: 285607200
I0813 23:14:23.051132 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:23.051141 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:23.051148 21738 layer_factory.hpp:77] Creating layer ReLU23
I0813 23:14:23.051165 21738 net.cpp:91] Creating Layer ReLU23
I0813 23:14:23.051175 21738 net.cpp:425] ReLU23 <- InnerProduct23
I0813 23:14:23.051187 21738 net.cpp:386] ReLU23 -> InnerProduct23 (in-place)
I0813 23:14:23.051203 21738 net.cpp:141] Setting up ReLU23
I0813 23:14:23.051210 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.051216 21738 net.cpp:156] Memory required for data: 285812000
I0813 23:14:23.051223 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:23.051234 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:23.051241 21738 net.cpp:425] drop1 <- InnerProduct23
I0813 23:14:23.051251 21738 net.cpp:399] drop1 -> Dropout23
I0813 23:14:23.051266 21738 net.cpp:141] Setting up drop1
I0813 23:14:23.051275 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.051308 21738 net.cpp:156] Memory required for data: 286016800
I0813 23:14:23.051316 21738 layer_factory.hpp:77] Creating layer InnerProduct24
I0813 23:14:23.051328 21738 net.cpp:91] Creating Layer InnerProduct24
I0813 23:14:23.051336 21738 net.cpp:425] InnerProduct24 <- Dropout23
I0813 23:14:23.051347 21738 net.cpp:399] InnerProduct24 -> InnerProduct24
I0813 23:14:23.051734 21738 net.cpp:141] Setting up InnerProduct24
I0813 23:14:23.051748 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.051753 21738 net.cpp:156] Memory required for data: 286119200
I0813 23:14:23.051760 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:23.051769 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:23.051775 21738 layer_factory.hpp:77] Creating layer ReLU24
I0813 23:14:23.051784 21738 net.cpp:91] Creating Layer ReLU24
I0813 23:14:23.051791 21738 net.cpp:425] ReLU24 <- InnerProduct24
I0813 23:14:23.051800 21738 net.cpp:386] ReLU24 -> InnerProduct24 (in-place)
I0813 23:14:23.051810 21738 net.cpp:141] Setting up ReLU24
I0813 23:14:23.051817 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.051823 21738 net.cpp:156] Memory required for data: 286221600
I0813 23:14:23.051828 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:23.051838 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:23.051844 21738 net.cpp:425] drop2 <- InnerProduct24
I0813 23:14:23.051853 21738 net.cpp:399] drop2 -> Dropout24
I0813 23:14:23.051865 21738 net.cpp:141] Setting up drop2
I0813 23:14:23.051877 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.051883 21738 net.cpp:156] Memory required for data: 286324000
I0813 23:14:23.051889 21738 layer_factory.hpp:77] Creating layer m12
I0813 23:14:23.051900 21738 net.cpp:91] Creating Layer m12
I0813 23:14:23.051906 21738 net.cpp:425] m12 <- Dropout24
I0813 23:14:23.051918 21738 net.cpp:399] m12 -> m12
I0813 23:14:23.051940 21738 net.cpp:141] Setting up m12
I0813 23:14:23.051950 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:23.051956 21738 net.cpp:156] Memory required for data: 286324800
I0813 23:14:23.051962 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:23.051971 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:23.051977 21738 layer_factory.hpp:77] Creating layer Concat13
I0813 23:14:23.051990 21738 net.cpp:91] Creating Layer Concat13
I0813 23:14:23.051996 21738 net.cpp:425] Concat13 <- i4
I0813 23:14:23.052006 21738 net.cpp:425] Concat13 <- i11_i1_10_split_3
I0813 23:14:23.052016 21738 net.cpp:399] Concat13 -> Concat13
I0813 23:14:23.052047 21738 net.cpp:141] Setting up Concat13
I0813 23:14:23.052057 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:23.052063 21738 net.cpp:156] Memory required for data: 292878400
I0813 23:14:23.052069 21738 layer_factory.hpp:77] Creating layer InnerProduct25
I0813 23:14:23.052080 21738 net.cpp:91] Creating Layer InnerProduct25
I0813 23:14:23.052088 21738 net.cpp:425] InnerProduct25 <- Concat13
I0813 23:14:23.052098 21738 net.cpp:399] InnerProduct25 -> InnerProduct25
I0813 23:14:23.075749 21738 net.cpp:141] Setting up InnerProduct25
I0813 23:14:23.075790 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.075796 21738 net.cpp:156] Memory required for data: 293083200
I0813 23:14:23.075808 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:23.075816 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:23.075822 21738 layer_factory.hpp:77] Creating layer ReLU25
I0813 23:14:23.075839 21738 net.cpp:91] Creating Layer ReLU25
I0813 23:14:23.075848 21738 net.cpp:425] ReLU25 <- InnerProduct25
I0813 23:14:23.075861 21738 net.cpp:386] ReLU25 -> InnerProduct25 (in-place)
I0813 23:14:23.075875 21738 net.cpp:141] Setting up ReLU25
I0813 23:14:23.075882 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.075888 21738 net.cpp:156] Memory required for data: 293288000
I0813 23:14:23.075917 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:23.075928 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:23.075934 21738 net.cpp:425] drop1 <- InnerProduct25
I0813 23:14:23.075944 21738 net.cpp:399] drop1 -> Dropout25
I0813 23:14:23.075960 21738 net.cpp:141] Setting up drop1
I0813 23:14:23.075968 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.075973 21738 net.cpp:156] Memory required for data: 293492800
I0813 23:14:23.075978 21738 layer_factory.hpp:77] Creating layer InnerProduct26
I0813 23:14:23.075991 21738 net.cpp:91] Creating Layer InnerProduct26
I0813 23:14:23.075997 21738 net.cpp:425] InnerProduct26 <- Dropout25
I0813 23:14:23.076007 21738 net.cpp:399] InnerProduct26 -> InnerProduct26
I0813 23:14:23.076375 21738 net.cpp:141] Setting up InnerProduct26
I0813 23:14:23.076388 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.076395 21738 net.cpp:156] Memory required for data: 293595200
I0813 23:14:23.076400 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:23.076407 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:23.076412 21738 layer_factory.hpp:77] Creating layer ReLU26
I0813 23:14:23.076421 21738 net.cpp:91] Creating Layer ReLU26
I0813 23:14:23.076427 21738 net.cpp:425] ReLU26 <- InnerProduct26
I0813 23:14:23.076436 21738 net.cpp:386] ReLU26 -> InnerProduct26 (in-place)
I0813 23:14:23.076445 21738 net.cpp:141] Setting up ReLU26
I0813 23:14:23.076452 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.076457 21738 net.cpp:156] Memory required for data: 293697600
I0813 23:14:23.076462 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:23.076470 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:23.076477 21738 net.cpp:425] drop2 <- InnerProduct26
I0813 23:14:23.076484 21738 net.cpp:399] drop2 -> Dropout26
I0813 23:14:23.076494 21738 net.cpp:141] Setting up drop2
I0813 23:14:23.076501 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.076506 21738 net.cpp:156] Memory required for data: 293800000
I0813 23:14:23.076511 21738 layer_factory.hpp:77] Creating layer m13
I0813 23:14:23.076522 21738 net.cpp:91] Creating Layer m13
I0813 23:14:23.076527 21738 net.cpp:425] m13 <- Dropout26
I0813 23:14:23.076537 21738 net.cpp:399] m13 -> m13
I0813 23:14:23.076557 21738 net.cpp:141] Setting up m13
I0813 23:14:23.076565 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:23.076573 21738 net.cpp:156] Memory required for data: 293800800
I0813 23:14:23.076581 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:23.076587 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:23.076592 21738 layer_factory.hpp:77] Creating layer Concat14
I0813 23:14:23.076602 21738 net.cpp:91] Creating Layer Concat14
I0813 23:14:23.076609 21738 net.cpp:425] Concat14 <- i5
I0813 23:14:23.076618 21738 net.cpp:425] Concat14 <- i11_i1_10_split_4
I0813 23:14:23.076628 21738 net.cpp:399] Concat14 -> Concat14
I0813 23:14:23.076640 21738 net.cpp:141] Setting up Concat14
I0813 23:14:23.076647 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:23.076652 21738 net.cpp:156] Memory required for data: 300354400
I0813 23:14:23.076658 21738 layer_factory.hpp:77] Creating layer InnerProduct27
I0813 23:14:23.076668 21738 net.cpp:91] Creating Layer InnerProduct27
I0813 23:14:23.076673 21738 net.cpp:425] InnerProduct27 <- Concat14
I0813 23:14:23.076683 21738 net.cpp:399] InnerProduct27 -> InnerProduct27
I0813 23:14:23.098417 21738 net.cpp:141] Setting up InnerProduct27
I0813 23:14:23.098453 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.098461 21738 net.cpp:156] Memory required for data: 300559200
I0813 23:14:23.098472 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:23.098481 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:23.098520 21738 layer_factory.hpp:77] Creating layer ReLU27
I0813 23:14:23.098537 21738 net.cpp:91] Creating Layer ReLU27
I0813 23:14:23.098547 21738 net.cpp:425] ReLU27 <- InnerProduct27
I0813 23:14:23.098561 21738 net.cpp:386] ReLU27 -> InnerProduct27 (in-place)
I0813 23:14:23.098574 21738 net.cpp:141] Setting up ReLU27
I0813 23:14:23.098582 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.098587 21738 net.cpp:156] Memory required for data: 300764000
I0813 23:14:23.098592 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:23.098601 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:23.098606 21738 net.cpp:425] drop1 <- InnerProduct27
I0813 23:14:23.098616 21738 net.cpp:399] drop1 -> Dropout27
I0813 23:14:23.098629 21738 net.cpp:141] Setting up drop1
I0813 23:14:23.098636 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.098640 21738 net.cpp:156] Memory required for data: 300968800
I0813 23:14:23.098646 21738 layer_factory.hpp:77] Creating layer InnerProduct28
I0813 23:14:23.098659 21738 net.cpp:91] Creating Layer InnerProduct28
I0813 23:14:23.098664 21738 net.cpp:425] InnerProduct28 <- Dropout27
I0813 23:14:23.098673 21738 net.cpp:399] InnerProduct28 -> InnerProduct28
I0813 23:14:23.099014 21738 net.cpp:141] Setting up InnerProduct28
I0813 23:14:23.099028 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.099033 21738 net.cpp:156] Memory required for data: 301071200
I0813 23:14:23.099040 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:23.099046 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:23.099051 21738 layer_factory.hpp:77] Creating layer ReLU28
I0813 23:14:23.099061 21738 net.cpp:91] Creating Layer ReLU28
I0813 23:14:23.099066 21738 net.cpp:425] ReLU28 <- InnerProduct28
I0813 23:14:23.099074 21738 net.cpp:386] ReLU28 -> InnerProduct28 (in-place)
I0813 23:14:23.099082 21738 net.cpp:141] Setting up ReLU28
I0813 23:14:23.099089 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.099093 21738 net.cpp:156] Memory required for data: 301173600
I0813 23:14:23.099098 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:23.099107 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:23.099112 21738 net.cpp:425] drop2 <- InnerProduct28
I0813 23:14:23.099119 21738 net.cpp:399] drop2 -> Dropout28
I0813 23:14:23.099129 21738 net.cpp:141] Setting up drop2
I0813 23:14:23.099135 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.099140 21738 net.cpp:156] Memory required for data: 301276000
I0813 23:14:23.099145 21738 layer_factory.hpp:77] Creating layer m14
I0813 23:14:23.099155 21738 net.cpp:91] Creating Layer m14
I0813 23:14:23.099160 21738 net.cpp:425] m14 <- Dropout28
I0813 23:14:23.099169 21738 net.cpp:399] m14 -> m14
I0813 23:14:23.099189 21738 net.cpp:141] Setting up m14
I0813 23:14:23.099195 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:23.099200 21738 net.cpp:156] Memory required for data: 301276800
I0813 23:14:23.099206 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:23.099213 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:23.099218 21738 layer_factory.hpp:77] Creating layer Concat15
I0813 23:14:23.099227 21738 net.cpp:91] Creating Layer Concat15
I0813 23:14:23.099234 21738 net.cpp:425] Concat15 <- i6
I0813 23:14:23.099241 21738 net.cpp:425] Concat15 <- i11_i1_10_split_5
I0813 23:14:23.099251 21738 net.cpp:399] Concat15 -> Concat15
I0813 23:14:23.099262 21738 net.cpp:141] Setting up Concat15
I0813 23:14:23.099269 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:23.099273 21738 net.cpp:156] Memory required for data: 307830400
I0813 23:14:23.099278 21738 layer_factory.hpp:77] Creating layer InnerProduct29
I0813 23:14:23.099288 21738 net.cpp:91] Creating Layer InnerProduct29
I0813 23:14:23.099293 21738 net.cpp:425] InnerProduct29 <- Concat15
I0813 23:14:23.099303 21738 net.cpp:399] InnerProduct29 -> InnerProduct29
I0813 23:14:23.119447 21738 net.cpp:141] Setting up InnerProduct29
I0813 23:14:23.119508 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.119513 21738 net.cpp:156] Memory required for data: 308035200
I0813 23:14:23.119524 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:23.119530 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:23.119536 21738 layer_factory.hpp:77] Creating layer ReLU29
I0813 23:14:23.119550 21738 net.cpp:91] Creating Layer ReLU29
I0813 23:14:23.119561 21738 net.cpp:425] ReLU29 <- InnerProduct29
I0813 23:14:23.119572 21738 net.cpp:386] ReLU29 -> InnerProduct29 (in-place)
I0813 23:14:23.119593 21738 net.cpp:141] Setting up ReLU29
I0813 23:14:23.119598 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.119603 21738 net.cpp:156] Memory required for data: 308240000
I0813 23:14:23.119608 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:23.119618 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:23.119626 21738 net.cpp:425] drop1 <- InnerProduct29
I0813 23:14:23.119635 21738 net.cpp:399] drop1 -> Dropout29
I0813 23:14:23.119647 21738 net.cpp:141] Setting up drop1
I0813 23:14:23.119653 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.119658 21738 net.cpp:156] Memory required for data: 308444800
I0813 23:14:23.119663 21738 layer_factory.hpp:77] Creating layer InnerProduct30
I0813 23:14:23.119674 21738 net.cpp:91] Creating Layer InnerProduct30
I0813 23:14:23.119680 21738 net.cpp:425] InnerProduct30 <- Dropout29
I0813 23:14:23.119688 21738 net.cpp:399] InnerProduct30 -> InnerProduct30
I0813 23:14:23.120040 21738 net.cpp:141] Setting up InnerProduct30
I0813 23:14:23.120051 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.120057 21738 net.cpp:156] Memory required for data: 308547200
I0813 23:14:23.120064 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:23.120069 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:23.120074 21738 layer_factory.hpp:77] Creating layer ReLU30
I0813 23:14:23.120081 21738 net.cpp:91] Creating Layer ReLU30
I0813 23:14:23.120087 21738 net.cpp:425] ReLU30 <- InnerProduct30
I0813 23:14:23.120095 21738 net.cpp:386] ReLU30 -> InnerProduct30 (in-place)
I0813 23:14:23.120106 21738 net.cpp:141] Setting up ReLU30
I0813 23:14:23.120111 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.120116 21738 net.cpp:156] Memory required for data: 308649600
I0813 23:14:23.120121 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:23.120129 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:23.120134 21738 net.cpp:425] drop2 <- InnerProduct30
I0813 23:14:23.120142 21738 net.cpp:399] drop2 -> Dropout30
I0813 23:14:23.120151 21738 net.cpp:141] Setting up drop2
I0813 23:14:23.120157 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.120162 21738 net.cpp:156] Memory required for data: 308752000
I0813 23:14:23.120167 21738 layer_factory.hpp:77] Creating layer m15
I0813 23:14:23.120177 21738 net.cpp:91] Creating Layer m15
I0813 23:14:23.120183 21738 net.cpp:425] m15 <- Dropout30
I0813 23:14:23.120193 21738 net.cpp:399] m15 -> m15
I0813 23:14:23.120220 21738 net.cpp:141] Setting up m15
I0813 23:14:23.120228 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:23.120232 21738 net.cpp:156] Memory required for data: 308752800
I0813 23:14:23.120237 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:23.120245 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:23.120250 21738 layer_factory.hpp:77] Creating layer Concat16
I0813 23:14:23.120260 21738 net.cpp:91] Creating Layer Concat16
I0813 23:14:23.120265 21738 net.cpp:425] Concat16 <- i7
I0813 23:14:23.120271 21738 net.cpp:425] Concat16 <- i11_i1_10_split_6
I0813 23:14:23.120280 21738 net.cpp:399] Concat16 -> Concat16
I0813 23:14:23.120291 21738 net.cpp:141] Setting up Concat16
I0813 23:14:23.120298 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:23.120314 21738 net.cpp:156] Memory required for data: 315306400
I0813 23:14:23.120319 21738 layer_factory.hpp:77] Creating layer InnerProduct31
I0813 23:14:23.120349 21738 net.cpp:91] Creating Layer InnerProduct31
I0813 23:14:23.120355 21738 net.cpp:425] InnerProduct31 <- Concat16
I0813 23:14:23.120364 21738 net.cpp:399] InnerProduct31 -> InnerProduct31
I0813 23:14:23.139302 21738 net.cpp:141] Setting up InnerProduct31
I0813 23:14:23.139343 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.139348 21738 net.cpp:156] Memory required for data: 315511200
I0813 23:14:23.139359 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:23.139366 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:23.139374 21738 layer_factory.hpp:77] Creating layer ReLU31
I0813 23:14:23.139389 21738 net.cpp:91] Creating Layer ReLU31
I0813 23:14:23.139399 21738 net.cpp:425] ReLU31 <- InnerProduct31
I0813 23:14:23.139408 21738 net.cpp:386] ReLU31 -> InnerProduct31 (in-place)
I0813 23:14:23.139422 21738 net.cpp:141] Setting up ReLU31
I0813 23:14:23.139428 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.139432 21738 net.cpp:156] Memory required for data: 315716000
I0813 23:14:23.139438 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:23.139447 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:23.139456 21738 net.cpp:425] drop1 <- InnerProduct31
I0813 23:14:23.139466 21738 net.cpp:399] drop1 -> Dropout31
I0813 23:14:23.139477 21738 net.cpp:141] Setting up drop1
I0813 23:14:23.139483 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.139487 21738 net.cpp:156] Memory required for data: 315920800
I0813 23:14:23.139492 21738 layer_factory.hpp:77] Creating layer InnerProduct32
I0813 23:14:23.139504 21738 net.cpp:91] Creating Layer InnerProduct32
I0813 23:14:23.139509 21738 net.cpp:425] InnerProduct32 <- Dropout31
I0813 23:14:23.139518 21738 net.cpp:399] InnerProduct32 -> InnerProduct32
I0813 23:14:23.139854 21738 net.cpp:141] Setting up InnerProduct32
I0813 23:14:23.139866 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.139870 21738 net.cpp:156] Memory required for data: 316023200
I0813 23:14:23.139876 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:23.139883 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:23.139889 21738 layer_factory.hpp:77] Creating layer ReLU32
I0813 23:14:23.139896 21738 net.cpp:91] Creating Layer ReLU32
I0813 23:14:23.139901 21738 net.cpp:425] ReLU32 <- InnerProduct32
I0813 23:14:23.139909 21738 net.cpp:386] ReLU32 -> InnerProduct32 (in-place)
I0813 23:14:23.139916 21738 net.cpp:141] Setting up ReLU32
I0813 23:14:23.139922 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.139927 21738 net.cpp:156] Memory required for data: 316125600
I0813 23:14:23.139931 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:23.139940 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:23.139945 21738 net.cpp:425] drop2 <- InnerProduct32
I0813 23:14:23.139950 21738 net.cpp:399] drop2 -> Dropout32
I0813 23:14:23.139960 21738 net.cpp:141] Setting up drop2
I0813 23:14:23.139972 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.139977 21738 net.cpp:156] Memory required for data: 316228000
I0813 23:14:23.139982 21738 layer_factory.hpp:77] Creating layer m16
I0813 23:14:23.139991 21738 net.cpp:91] Creating Layer m16
I0813 23:14:23.139997 21738 net.cpp:425] m16 <- Dropout32
I0813 23:14:23.140005 21738 net.cpp:399] m16 -> m16
I0813 23:14:23.140022 21738 net.cpp:141] Setting up m16
I0813 23:14:23.140050 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:23.140056 21738 net.cpp:156] Memory required for data: 316228800
I0813 23:14:23.140061 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:23.140067 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:23.140092 21738 layer_factory.hpp:77] Creating layer Concat17
I0813 23:14:23.140102 21738 net.cpp:91] Creating Layer Concat17
I0813 23:14:23.140108 21738 net.cpp:425] Concat17 <- i8
I0813 23:14:23.140115 21738 net.cpp:425] Concat17 <- i11_i1_10_split_7
I0813 23:14:23.140122 21738 net.cpp:399] Concat17 -> Concat17
I0813 23:14:23.140133 21738 net.cpp:141] Setting up Concat17
I0813 23:14:23.140139 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:23.140143 21738 net.cpp:156] Memory required for data: 322782400
I0813 23:14:23.140148 21738 layer_factory.hpp:77] Creating layer InnerProduct33
I0813 23:14:23.140156 21738 net.cpp:91] Creating Layer InnerProduct33
I0813 23:14:23.140161 21738 net.cpp:425] InnerProduct33 <- Concat17
I0813 23:14:23.140168 21738 net.cpp:399] InnerProduct33 -> InnerProduct33
I0813 23:14:23.158061 21738 net.cpp:141] Setting up InnerProduct33
I0813 23:14:23.158093 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.158098 21738 net.cpp:156] Memory required for data: 322987200
I0813 23:14:23.158107 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:23.158116 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:23.158123 21738 layer_factory.hpp:77] Creating layer ReLU33
I0813 23:14:23.158136 21738 net.cpp:91] Creating Layer ReLU33
I0813 23:14:23.158144 21738 net.cpp:425] ReLU33 <- InnerProduct33
I0813 23:14:23.158157 21738 net.cpp:386] ReLU33 -> InnerProduct33 (in-place)
I0813 23:14:23.158171 21738 net.cpp:141] Setting up ReLU33
I0813 23:14:23.158176 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.158180 21738 net.cpp:156] Memory required for data: 323192000
I0813 23:14:23.158185 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:23.158195 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:23.158198 21738 net.cpp:425] drop1 <- InnerProduct33
I0813 23:14:23.158210 21738 net.cpp:399] drop1 -> Dropout33
I0813 23:14:23.158221 21738 net.cpp:141] Setting up drop1
I0813 23:14:23.158226 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.158229 21738 net.cpp:156] Memory required for data: 323396800
I0813 23:14:23.158234 21738 layer_factory.hpp:77] Creating layer InnerProduct34
I0813 23:14:23.158246 21738 net.cpp:91] Creating Layer InnerProduct34
I0813 23:14:23.158249 21738 net.cpp:425] InnerProduct34 <- Dropout33
I0813 23:14:23.158258 21738 net.cpp:399] InnerProduct34 -> InnerProduct34
I0813 23:14:23.158568 21738 net.cpp:141] Setting up InnerProduct34
I0813 23:14:23.158577 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.158582 21738 net.cpp:156] Memory required for data: 323499200
I0813 23:14:23.158587 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:23.158592 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:23.158597 21738 layer_factory.hpp:77] Creating layer ReLU34
I0813 23:14:23.158603 21738 net.cpp:91] Creating Layer ReLU34
I0813 23:14:23.158608 21738 net.cpp:425] ReLU34 <- InnerProduct34
I0813 23:14:23.158617 21738 net.cpp:386] ReLU34 -> InnerProduct34 (in-place)
I0813 23:14:23.158623 21738 net.cpp:141] Setting up ReLU34
I0813 23:14:23.158628 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.158632 21738 net.cpp:156] Memory required for data: 323601600
I0813 23:14:23.158638 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:23.158643 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:23.158648 21738 net.cpp:425] drop2 <- InnerProduct34
I0813 23:14:23.158655 21738 net.cpp:399] drop2 -> Dropout34
I0813 23:14:23.158664 21738 net.cpp:141] Setting up drop2
I0813 23:14:23.158669 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.158674 21738 net.cpp:156] Memory required for data: 323704000
I0813 23:14:23.158677 21738 layer_factory.hpp:77] Creating layer m17
I0813 23:14:23.158685 21738 net.cpp:91] Creating Layer m17
I0813 23:14:23.158689 21738 net.cpp:425] m17 <- Dropout34
I0813 23:14:23.158720 21738 net.cpp:399] m17 -> m17
I0813 23:14:23.158736 21738 net.cpp:141] Setting up m17
I0813 23:14:23.158741 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:23.158746 21738 net.cpp:156] Memory required for data: 323704800
I0813 23:14:23.158751 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:23.158756 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:23.158761 21738 layer_factory.hpp:77] Creating layer Concat18
I0813 23:14:23.158768 21738 net.cpp:91] Creating Layer Concat18
I0813 23:14:23.158773 21738 net.cpp:425] Concat18 <- i9
I0813 23:14:23.158779 21738 net.cpp:425] Concat18 <- i11_i1_10_split_8
I0813 23:14:23.158789 21738 net.cpp:399] Concat18 -> Concat18
I0813 23:14:23.158799 21738 net.cpp:141] Setting up Concat18
I0813 23:14:23.158804 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:23.158809 21738 net.cpp:156] Memory required for data: 330258400
I0813 23:14:23.158813 21738 layer_factory.hpp:77] Creating layer InnerProduct35
I0813 23:14:23.158823 21738 net.cpp:91] Creating Layer InnerProduct35
I0813 23:14:23.158828 21738 net.cpp:425] InnerProduct35 <- Concat18
I0813 23:14:23.158834 21738 net.cpp:399] InnerProduct35 -> InnerProduct35
I0813 23:14:23.175920 21738 net.cpp:141] Setting up InnerProduct35
I0813 23:14:23.175953 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.175958 21738 net.cpp:156] Memory required for data: 330463200
I0813 23:14:23.175966 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:23.175974 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:23.175982 21738 layer_factory.hpp:77] Creating layer ReLU35
I0813 23:14:23.175997 21738 net.cpp:91] Creating Layer ReLU35
I0813 23:14:23.176005 21738 net.cpp:425] ReLU35 <- InnerProduct35
I0813 23:14:23.176015 21738 net.cpp:386] ReLU35 -> InnerProduct35 (in-place)
I0813 23:14:23.176044 21738 net.cpp:141] Setting up ReLU35
I0813 23:14:23.176051 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.176055 21738 net.cpp:156] Memory required for data: 330668000
I0813 23:14:23.176060 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:23.176072 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:23.176077 21738 net.cpp:425] drop1 <- InnerProduct35
I0813 23:14:23.176087 21738 net.cpp:399] drop1 -> Dropout35
I0813 23:14:23.176098 21738 net.cpp:141] Setting up drop1
I0813 23:14:23.176103 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.176107 21738 net.cpp:156] Memory required for data: 330872800
I0813 23:14:23.176113 21738 layer_factory.hpp:77] Creating layer InnerProduct36
I0813 23:14:23.176126 21738 net.cpp:91] Creating Layer InnerProduct36
I0813 23:14:23.176131 21738 net.cpp:425] InnerProduct36 <- Dropout35
I0813 23:14:23.176139 21738 net.cpp:399] InnerProduct36 -> InnerProduct36
I0813 23:14:23.176467 21738 net.cpp:141] Setting up InnerProduct36
I0813 23:14:23.176479 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.176483 21738 net.cpp:156] Memory required for data: 330975200
I0813 23:14:23.176489 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:23.176496 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:23.176499 21738 layer_factory.hpp:77] Creating layer ReLU36
I0813 23:14:23.176508 21738 net.cpp:91] Creating Layer ReLU36
I0813 23:14:23.176513 21738 net.cpp:425] ReLU36 <- InnerProduct36
I0813 23:14:23.176519 21738 net.cpp:386] ReLU36 -> InnerProduct36 (in-place)
I0813 23:14:23.176527 21738 net.cpp:141] Setting up ReLU36
I0813 23:14:23.176532 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.176535 21738 net.cpp:156] Memory required for data: 331077600
I0813 23:14:23.176539 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:23.176548 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:23.176553 21738 net.cpp:425] drop2 <- InnerProduct36
I0813 23:14:23.176559 21738 net.cpp:399] drop2 -> Dropout36
I0813 23:14:23.176586 21738 net.cpp:141] Setting up drop2
I0813 23:14:23.176594 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.176597 21738 net.cpp:156] Memory required for data: 331180000
I0813 23:14:23.176602 21738 layer_factory.hpp:77] Creating layer m18
I0813 23:14:23.176610 21738 net.cpp:91] Creating Layer m18
I0813 23:14:23.176614 21738 net.cpp:425] m18 <- Dropout36
I0813 23:14:23.176623 21738 net.cpp:399] m18 -> m18
I0813 23:14:23.176640 21738 net.cpp:141] Setting up m18
I0813 23:14:23.176645 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:23.176648 21738 net.cpp:156] Memory required for data: 331180800
I0813 23:14:23.176652 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:23.176658 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:23.176662 21738 layer_factory.hpp:77] Creating layer Concat19
I0813 23:14:23.176671 21738 net.cpp:91] Creating Layer Concat19
I0813 23:14:23.176674 21738 net.cpp:425] Concat19 <- i10
I0813 23:14:23.176681 21738 net.cpp:425] Concat19 <- i11_i1_10_split_9
I0813 23:14:23.176689 21738 net.cpp:399] Concat19 -> Concat19
I0813 23:14:23.176700 21738 net.cpp:141] Setting up Concat19
I0813 23:14:23.176705 21738 net.cpp:148] Top shape: 200 2 1 4096 (1638400)
I0813 23:14:23.176709 21738 net.cpp:156] Memory required for data: 337734400
I0813 23:14:23.176713 21738 layer_factory.hpp:77] Creating layer InnerProduct37
I0813 23:14:23.176722 21738 net.cpp:91] Creating Layer InnerProduct37
I0813 23:14:23.176725 21738 net.cpp:425] InnerProduct37 <- Concat19
I0813 23:14:23.176735 21738 net.cpp:399] InnerProduct37 -> InnerProduct37
I0813 23:14:23.193162 21738 net.cpp:141] Setting up InnerProduct37
I0813 23:14:23.193198 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.193203 21738 net.cpp:156] Memory required for data: 337939200
I0813 23:14:23.193217 21738 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct1', param index 0
I0813 23:14:23.193222 21738 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct1', param index 1
I0813 23:14:23.193228 21738 layer_factory.hpp:77] Creating layer ReLU37
I0813 23:14:23.193243 21738 net.cpp:91] Creating Layer ReLU37
I0813 23:14:23.193251 21738 net.cpp:425] ReLU37 <- InnerProduct37
I0813 23:14:23.193260 21738 net.cpp:386] ReLU37 -> InnerProduct37 (in-place)
I0813 23:14:23.193272 21738 net.cpp:141] Setting up ReLU37
I0813 23:14:23.193277 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.193281 21738 net.cpp:156] Memory required for data: 338144000
I0813 23:14:23.193285 21738 layer_factory.hpp:77] Creating layer drop1
I0813 23:14:23.193294 21738 net.cpp:91] Creating Layer drop1
I0813 23:14:23.193298 21738 net.cpp:425] drop1 <- InnerProduct37
I0813 23:14:23.193310 21738 net.cpp:399] drop1 -> Dropout37
I0813 23:14:23.193320 21738 net.cpp:141] Setting up drop1
I0813 23:14:23.193325 21738 net.cpp:148] Top shape: 200 256 (51200)
I0813 23:14:23.193328 21738 net.cpp:156] Memory required for data: 338348800
I0813 23:14:23.193332 21738 layer_factory.hpp:77] Creating layer InnerProduct38
I0813 23:14:23.193344 21738 net.cpp:91] Creating Layer InnerProduct38
I0813 23:14:23.193349 21738 net.cpp:425] InnerProduct38 <- Dropout37
I0813 23:14:23.193356 21738 net.cpp:399] InnerProduct38 -> InnerProduct38
I0813 23:14:23.193639 21738 net.cpp:141] Setting up InnerProduct38
I0813 23:14:23.193650 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.193655 21738 net.cpp:156] Memory required for data: 338451200
I0813 23:14:23.193660 21738 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct2', param index 0
I0813 23:14:23.193665 21738 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct2', param index 1
I0813 23:14:23.193670 21738 layer_factory.hpp:77] Creating layer ReLU38
I0813 23:14:23.193675 21738 net.cpp:91] Creating Layer ReLU38
I0813 23:14:23.193680 21738 net.cpp:425] ReLU38 <- InnerProduct38
I0813 23:14:23.193686 21738 net.cpp:386] ReLU38 -> InnerProduct38 (in-place)
I0813 23:14:23.193717 21738 net.cpp:141] Setting up ReLU38
I0813 23:14:23.193722 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.193727 21738 net.cpp:156] Memory required for data: 338553600
I0813 23:14:23.193730 21738 layer_factory.hpp:77] Creating layer drop2
I0813 23:14:23.193737 21738 net.cpp:91] Creating Layer drop2
I0813 23:14:23.193740 21738 net.cpp:425] drop2 <- InnerProduct38
I0813 23:14:23.193749 21738 net.cpp:399] drop2 -> Dropout38
I0813 23:14:23.193758 21738 net.cpp:141] Setting up drop2
I0813 23:14:23.193763 21738 net.cpp:148] Top shape: 200 128 (25600)
I0813 23:14:23.193765 21738 net.cpp:156] Memory required for data: 338656000
I0813 23:14:23.193769 21738 layer_factory.hpp:77] Creating layer m19
I0813 23:14:23.193778 21738 net.cpp:91] Creating Layer m19
I0813 23:14:23.193783 21738 net.cpp:425] m19 <- Dropout38
I0813 23:14:23.193789 21738 net.cpp:399] m19 -> m19
I0813 23:14:23.193806 21738 net.cpp:141] Setting up m19
I0813 23:14:23.193812 21738 net.cpp:148] Top shape: 200 1 (200)
I0813 23:14:23.193815 21738 net.cpp:156] Memory required for data: 338656800
I0813 23:14:23.193820 21738 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'm1', param index 0
I0813 23:14:23.193825 21738 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'm1', param index 1
I0813 23:14:23.193830 21738 layer_factory.hpp:77] Creating layer con
I0813 23:14:23.193840 21738 net.cpp:91] Creating Layer con
I0813 23:14:23.193845 21738 net.cpp:425] con <- m1
I0813 23:14:23.193850 21738 net.cpp:425] con <- m2
I0813 23:14:23.193857 21738 net.cpp:425] con <- m3
I0813 23:14:23.193862 21738 net.cpp:425] con <- m4
I0813 23:14:23.193867 21738 net.cpp:425] con <- m5
I0813 23:14:23.193872 21738 net.cpp:425] con <- m6
I0813 23:14:23.193876 21738 net.cpp:425] con <- m7
I0813 23:14:23.193881 21738 net.cpp:425] con <- m8
I0813 23:14:23.193886 21738 net.cpp:425] con <- m9
I0813 23:14:23.193891 21738 net.cpp:425] con <- m10
I0813 23:14:23.193897 21738 net.cpp:425] con <- m11
I0813 23:14:23.193900 21738 net.cpp:425] con <- m12
I0813 23:14:23.193905 21738 net.cpp:425] con <- m13
I0813 23:14:23.193909 21738 net.cpp:425] con <- m14
I0813 23:14:23.193913 21738 net.cpp:425] con <- m15
I0813 23:14:23.193918 21738 net.cpp:425] con <- m16
I0813 23:14:23.193922 21738 net.cpp:425] con <- m17
I0813 23:14:23.193928 21738 net.cpp:425] con <- m18
I0813 23:14:23.193931 21738 net.cpp:425] con <- m19
I0813 23:14:23.193940 21738 net.cpp:399] con -> con
I0813 23:14:23.193953 21738 net.cpp:141] Setting up con
I0813 23:14:23.193958 21738 net.cpp:148] Top shape: 200 19 (3800)
I0813 23:14:23.193963 21738 net.cpp:156] Memory required for data: 338672000
I0813 23:14:23.193965 21738 layer_factory.hpp:77] Creating layer r1
I0813 23:14:23.193975 21738 net.cpp:91] Creating Layer r1
I0813 23:14:23.193979 21738 net.cpp:425] r1 <- con
I0813 23:14:23.193985 21738 net.cpp:399] r1 -> r1
I0813 23:14:23.194000 21738 net.cpp:141] Setting up r1
I0813 23:14:23.194005 21738 net.cpp:148] Top shape: 200 1 1 19 (3800)
I0813 23:14:23.194008 21738 net.cpp:156] Memory required for data: 338687200
I0813 23:14:23.194012 21738 layer_factory.hpp:77] Creating layer p
I0813 23:14:23.194020 21738 net.cpp:91] Creating Layer p
I0813 23:14:23.194023 21738 net.cpp:425] p <- r1
I0813 23:14:23.194030 21738 net.cpp:399] p -> p
I0813 23:14:23.194039 21738 net.cpp:141] Setting up p
I0813 23:14:23.194044 21738 net.cpp:148] Top shape: 200 1 1 1 (200)
I0813 23:14:23.194048 21738 net.cpp:156] Memory required for data: 338688000
I0813 23:14:23.194052 21738 layer_factory.hpp:77] Creating layer r2
I0813 23:14:23.194061 21738 net.cpp:91] Creating Layer r2
I0813 23:14:23.194064 21738 net.cpp:425] r2 <- p
I0813 23:14:23.194070 21738 net.cpp:399] r2 -> r2
I0813 23:14:23.194077 21738 net.cpp:141] Setting up r2
I0813 23:14:23.194084 21738 net.cpp:148] Top shape: 200 1 1 1 (200)
I0813 23:14:23.194088 21738 net.cpp:156] Memory required for data: 338688800
I0813 23:14:23.194092 21738 layer_factory.hpp:77] Creating layer padL
I0813 23:14:23.194098 21738 net.cpp:91] Creating Layer padL
I0813 23:14:23.194103 21738 net.cpp:425] padL <- label_data_1_split_1
I0813 23:14:23.194118 21738 net.cpp:399] padL -> padL
I0813 23:14:23.194125 21738 net.cpp:141] Setting up padL
I0813 23:14:23.194130 21738 net.cpp:148] Top shape: 200 1 1 1 (200)
I0813 23:14:23.194134 21738 net.cpp:156] Memory required for data: 338689600
I0813 23:14:23.194139 21738 layer_factory.hpp:77] Creating layer pad
I0813 23:14:23.194147 21738 net.cpp:91] Creating Layer pad
I0813 23:14:23.194151 21738 net.cpp:425] pad <- r2
I0813 23:14:23.194156 21738 net.cpp:425] pad <- padL
I0813 23:14:23.194167 21738 net.cpp:399] pad -> pad
I0813 23:14:23.194175 21738 net.cpp:141] Setting up pad
I0813 23:14:23.194180 21738 net.cpp:148] Top shape: 200 2 1 1 (400)
I0813 23:14:23.194182 21738 net.cpp:156] Memory required for data: 338691200
I0813 23:14:23.194186 21738 layer_factory.hpp:77] Creating layer pad_pad_0_split
I0813 23:14:23.194193 21738 net.cpp:91] Creating Layer pad_pad_0_split
I0813 23:14:23.194200 21738 net.cpp:425] pad_pad_0_split <- pad
I0813 23:14:23.194205 21738 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_0
I0813 23:14:23.194211 21738 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_1
I0813 23:14:23.194218 21738 net.cpp:141] Setting up pad_pad_0_split
I0813 23:14:23.194223 21738 net.cpp:148] Top shape: 200 2 1 1 (400)
I0813 23:14:23.194228 21738 net.cpp:148] Top shape: 200 2 1 1 (400)
I0813 23:14:23.194231 21738 net.cpp:156] Memory required for data: 338694400
I0813 23:14:23.194236 21738 layer_factory.hpp:77] Creating layer loss
I0813 23:14:23.194242 21738 net.cpp:91] Creating Layer loss
I0813 23:14:23.194247 21738 net.cpp:425] loss <- pad_pad_0_split_0
I0813 23:14:23.194252 21738 net.cpp:425] loss <- th_th_0_split_0
I0813 23:14:23.194258 21738 net.cpp:399] loss -> loss
I0813 23:14:23.194267 21738 net.cpp:141] Setting up loss
I0813 23:14:23.194272 21738 net.cpp:148] Top shape: (1)
I0813 23:14:23.194277 21738 net.cpp:151]     with loss weight 1
I0813 23:14:23.194293 21738 net.cpp:156] Memory required for data: 338694404
I0813 23:14:23.194296 21738 layer_factory.hpp:77] Creating layer accuracy
I0813 23:14:23.194306 21738 net.cpp:91] Creating Layer accuracy
I0813 23:14:23.194310 21738 net.cpp:425] accuracy <- pad_pad_0_split_1
I0813 23:14:23.194315 21738 net.cpp:425] accuracy <- th_th_0_split_1
I0813 23:14:23.194320 21738 net.cpp:399] accuracy -> accuracy
I0813 23:14:23.194329 21738 net.cpp:141] Setting up accuracy
I0813 23:14:23.194334 21738 net.cpp:148] Top shape: (1)
I0813 23:14:23.194337 21738 net.cpp:156] Memory required for data: 338694408
I0813 23:14:23.194342 21738 net.cpp:219] accuracy does not need backward computation.
I0813 23:14:23.194347 21738 net.cpp:217] loss needs backward computation.
I0813 23:14:23.194351 21738 net.cpp:217] pad_pad_0_split needs backward computation.
I0813 23:14:23.194355 21738 net.cpp:217] pad needs backward computation.
I0813 23:14:23.194360 21738 net.cpp:219] padL does not need backward computation.
I0813 23:14:23.194365 21738 net.cpp:217] r2 needs backward computation.
I0813 23:14:23.194368 21738 net.cpp:217] p needs backward computation.
I0813 23:14:23.194372 21738 net.cpp:217] r1 needs backward computation.
I0813 23:14:23.194376 21738 net.cpp:217] con needs backward computation.
I0813 23:14:23.194385 21738 net.cpp:217] m19 needs backward computation.
I0813 23:14:23.194388 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194394 21738 net.cpp:217] ReLU38 needs backward computation.
I0813 23:14:23.194398 21738 net.cpp:217] InnerProduct38 needs backward computation.
I0813 23:14:23.194403 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194407 21738 net.cpp:217] ReLU37 needs backward computation.
I0813 23:14:23.194411 21738 net.cpp:217] InnerProduct37 needs backward computation.
I0813 23:14:23.194416 21738 net.cpp:219] Concat19 does not need backward computation.
I0813 23:14:23.194420 21738 net.cpp:217] m18 needs backward computation.
I0813 23:14:23.194425 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194429 21738 net.cpp:217] ReLU36 needs backward computation.
I0813 23:14:23.194442 21738 net.cpp:217] InnerProduct36 needs backward computation.
I0813 23:14:23.194447 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194452 21738 net.cpp:217] ReLU35 needs backward computation.
I0813 23:14:23.194455 21738 net.cpp:217] InnerProduct35 needs backward computation.
I0813 23:14:23.194460 21738 net.cpp:219] Concat18 does not need backward computation.
I0813 23:14:23.194465 21738 net.cpp:217] m17 needs backward computation.
I0813 23:14:23.194469 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194474 21738 net.cpp:217] ReLU34 needs backward computation.
I0813 23:14:23.194478 21738 net.cpp:217] InnerProduct34 needs backward computation.
I0813 23:14:23.194483 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194488 21738 net.cpp:217] ReLU33 needs backward computation.
I0813 23:14:23.194491 21738 net.cpp:217] InnerProduct33 needs backward computation.
I0813 23:14:23.194495 21738 net.cpp:219] Concat17 does not need backward computation.
I0813 23:14:23.194501 21738 net.cpp:217] m16 needs backward computation.
I0813 23:14:23.194505 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194510 21738 net.cpp:217] ReLU32 needs backward computation.
I0813 23:14:23.194514 21738 net.cpp:217] InnerProduct32 needs backward computation.
I0813 23:14:23.194519 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194524 21738 net.cpp:217] ReLU31 needs backward computation.
I0813 23:14:23.194527 21738 net.cpp:217] InnerProduct31 needs backward computation.
I0813 23:14:23.194532 21738 net.cpp:219] Concat16 does not need backward computation.
I0813 23:14:23.194537 21738 net.cpp:217] m15 needs backward computation.
I0813 23:14:23.194542 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194546 21738 net.cpp:217] ReLU30 needs backward computation.
I0813 23:14:23.194550 21738 net.cpp:217] InnerProduct30 needs backward computation.
I0813 23:14:23.194556 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194561 21738 net.cpp:217] ReLU29 needs backward computation.
I0813 23:14:23.194566 21738 net.cpp:217] InnerProduct29 needs backward computation.
I0813 23:14:23.194569 21738 net.cpp:219] Concat15 does not need backward computation.
I0813 23:14:23.194574 21738 net.cpp:217] m14 needs backward computation.
I0813 23:14:23.194579 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194583 21738 net.cpp:217] ReLU28 needs backward computation.
I0813 23:14:23.194588 21738 net.cpp:217] InnerProduct28 needs backward computation.
I0813 23:14:23.194592 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194597 21738 net.cpp:217] ReLU27 needs backward computation.
I0813 23:14:23.194602 21738 net.cpp:217] InnerProduct27 needs backward computation.
I0813 23:14:23.194605 21738 net.cpp:219] Concat14 does not need backward computation.
I0813 23:14:23.194610 21738 net.cpp:217] m13 needs backward computation.
I0813 23:14:23.194615 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194619 21738 net.cpp:217] ReLU26 needs backward computation.
I0813 23:14:23.194624 21738 net.cpp:217] InnerProduct26 needs backward computation.
I0813 23:14:23.194628 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194633 21738 net.cpp:217] ReLU25 needs backward computation.
I0813 23:14:23.194638 21738 net.cpp:217] InnerProduct25 needs backward computation.
I0813 23:14:23.194641 21738 net.cpp:219] Concat13 does not need backward computation.
I0813 23:14:23.194648 21738 net.cpp:217] m12 needs backward computation.
I0813 23:14:23.194651 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194656 21738 net.cpp:217] ReLU24 needs backward computation.
I0813 23:14:23.194660 21738 net.cpp:217] InnerProduct24 needs backward computation.
I0813 23:14:23.194664 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194669 21738 net.cpp:217] ReLU23 needs backward computation.
I0813 23:14:23.194672 21738 net.cpp:217] InnerProduct23 needs backward computation.
I0813 23:14:23.194682 21738 net.cpp:219] Concat12 does not need backward computation.
I0813 23:14:23.194687 21738 net.cpp:217] m11 needs backward computation.
I0813 23:14:23.194691 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194696 21738 net.cpp:217] ReLU22 needs backward computation.
I0813 23:14:23.194700 21738 net.cpp:217] InnerProduct22 needs backward computation.
I0813 23:14:23.194705 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194710 21738 net.cpp:217] ReLU21 needs backward computation.
I0813 23:14:23.194713 21738 net.cpp:217] InnerProduct21 needs backward computation.
I0813 23:14:23.194718 21738 net.cpp:219] Concat11 does not need backward computation.
I0813 23:14:23.194725 21738 net.cpp:217] m10 needs backward computation.
I0813 23:14:23.194730 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194735 21738 net.cpp:217] ReLU20 needs backward computation.
I0813 23:14:23.194738 21738 net.cpp:217] InnerProduct20 needs backward computation.
I0813 23:14:23.194743 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194747 21738 net.cpp:217] ReLU19 needs backward computation.
I0813 23:14:23.194752 21738 net.cpp:217] InnerProduct19 needs backward computation.
I0813 23:14:23.194756 21738 net.cpp:219] Concat10 does not need backward computation.
I0813 23:14:23.194762 21738 net.cpp:217] m9 needs backward computation.
I0813 23:14:23.194767 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194772 21738 net.cpp:217] ReLU18 needs backward computation.
I0813 23:14:23.194777 21738 net.cpp:217] InnerProduct18 needs backward computation.
I0813 23:14:23.194780 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194785 21738 net.cpp:217] ReLU17 needs backward computation.
I0813 23:14:23.194789 21738 net.cpp:217] InnerProduct17 needs backward computation.
I0813 23:14:23.194794 21738 net.cpp:219] Concat9 does not need backward computation.
I0813 23:14:23.194799 21738 net.cpp:217] m8 needs backward computation.
I0813 23:14:23.194804 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194809 21738 net.cpp:217] ReLU16 needs backward computation.
I0813 23:14:23.194813 21738 net.cpp:217] InnerProduct16 needs backward computation.
I0813 23:14:23.194818 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194823 21738 net.cpp:217] ReLU15 needs backward computation.
I0813 23:14:23.194826 21738 net.cpp:217] InnerProduct15 needs backward computation.
I0813 23:14:23.194831 21738 net.cpp:219] Concat8 does not need backward computation.
I0813 23:14:23.194838 21738 net.cpp:217] m7 needs backward computation.
I0813 23:14:23.194842 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194846 21738 net.cpp:217] ReLU14 needs backward computation.
I0813 23:14:23.194850 21738 net.cpp:217] InnerProduct14 needs backward computation.
I0813 23:14:23.194855 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194859 21738 net.cpp:217] ReLU13 needs backward computation.
I0813 23:14:23.194864 21738 net.cpp:217] InnerProduct13 needs backward computation.
I0813 23:14:23.194869 21738 net.cpp:219] Concat7 does not need backward computation.
I0813 23:14:23.194875 21738 net.cpp:217] m6 needs backward computation.
I0813 23:14:23.194880 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194883 21738 net.cpp:217] ReLU12 needs backward computation.
I0813 23:14:23.194887 21738 net.cpp:217] InnerProduct12 needs backward computation.
I0813 23:14:23.194892 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194898 21738 net.cpp:217] ReLU11 needs backward computation.
I0813 23:14:23.194902 21738 net.cpp:217] InnerProduct11 needs backward computation.
I0813 23:14:23.194907 21738 net.cpp:219] Concat6 does not need backward computation.
I0813 23:14:23.194912 21738 net.cpp:217] m5 needs backward computation.
I0813 23:14:23.194916 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194921 21738 net.cpp:217] ReLU10 needs backward computation.
I0813 23:14:23.194926 21738 net.cpp:217] InnerProduct10 needs backward computation.
I0813 23:14:23.194936 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194941 21738 net.cpp:217] ReLU9 needs backward computation.
I0813 23:14:23.194946 21738 net.cpp:217] InnerProduct9 needs backward computation.
I0813 23:14:23.194950 21738 net.cpp:219] Concat5 does not need backward computation.
I0813 23:14:23.194957 21738 net.cpp:217] m4 needs backward computation.
I0813 23:14:23.194960 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.194965 21738 net.cpp:217] ReLU8 needs backward computation.
I0813 23:14:23.194969 21738 net.cpp:217] InnerProduct8 needs backward computation.
I0813 23:14:23.194974 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.194978 21738 net.cpp:217] ReLU7 needs backward computation.
I0813 23:14:23.194983 21738 net.cpp:217] InnerProduct7 needs backward computation.
I0813 23:14:23.194988 21738 net.cpp:219] Concat4 does not need backward computation.
I0813 23:14:23.194993 21738 net.cpp:217] m3 needs backward computation.
I0813 23:14:23.194998 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.195001 21738 net.cpp:217] ReLU6 needs backward computation.
I0813 23:14:23.195006 21738 net.cpp:217] InnerProduct6 needs backward computation.
I0813 23:14:23.195010 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.195014 21738 net.cpp:217] ReLU5 needs backward computation.
I0813 23:14:23.195019 21738 net.cpp:217] InnerProduct5 needs backward computation.
I0813 23:14:23.195024 21738 net.cpp:219] Concat3 does not need backward computation.
I0813 23:14:23.195029 21738 net.cpp:217] m2 needs backward computation.
I0813 23:14:23.195034 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.195039 21738 net.cpp:217] ReLU4 needs backward computation.
I0813 23:14:23.195042 21738 net.cpp:217] InnerProduct4 needs backward computation.
I0813 23:14:23.195049 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.195053 21738 net.cpp:217] ReLU3 needs backward computation.
I0813 23:14:23.195057 21738 net.cpp:217] InnerProduct3 needs backward computation.
I0813 23:14:23.195062 21738 net.cpp:219] Concat2 does not need backward computation.
I0813 23:14:23.195068 21738 net.cpp:217] m1 needs backward computation.
I0813 23:14:23.195072 21738 net.cpp:217] drop2 needs backward computation.
I0813 23:14:23.195077 21738 net.cpp:217] ReLU2 needs backward computation.
I0813 23:14:23.195081 21738 net.cpp:217] InnerProduct2 needs backward computation.
I0813 23:14:23.195086 21738 net.cpp:217] drop1 needs backward computation.
I0813 23:14:23.195091 21738 net.cpp:217] ReLU1 needs backward computation.
I0813 23:14:23.195096 21738 net.cpp:217] InnerProduct1 needs backward computation.
I0813 23:14:23.195101 21738 net.cpp:219] Concat1 does not need backward computation.
I0813 23:14:23.195107 21738 net.cpp:219] i11_i1_10_split does not need backward computation.
I0813 23:14:23.195114 21738 net.cpp:219] i1_i1_0_split does not need backward computation.
I0813 23:14:23.195122 21738 net.cpp:219] i1 does not need backward computation.
I0813 23:14:23.195128 21738 net.cpp:219] th_th_0_split does not need backward computation.
I0813 23:14:23.195133 21738 net.cpp:219] th does not need backward computation.
I0813 23:14:23.195138 21738 net.cpp:219] label_data_1_split does not need backward computation.
I0813 23:14:23.195143 21738 net.cpp:219] data does not need backward computation.
I0813 23:14:23.195147 21738 net.cpp:261] This network produces output accuracy
I0813 23:14:23.195152 21738 net.cpp:261] This network produces output loss
I0813 23:14:23.195503 21738 net.cpp:274] Network initialization done.
I0813 23:14:23.196441 21738 solver.cpp:60] Solver scaffolding done.
I0813 23:14:23.196475 21738 caffe.cpp:219] Starting Optimization
I0813 23:14:23.196481 21738 solver.cpp:279] Solving 
I0813 23:14:23.196486 21738 solver.cpp:280] Learning Rate Policy: inv
I0813 23:14:23.198616 21738 solver.cpp:337] Iteration 0, Testing net (#0)
I0813 23:14:32.343660 21738 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 23:14:32.343770 21738 solver.cpp:404]     Test net output #1: loss = 1.10285 (* 1 = 1.10285 loss)
I0813 23:14:34.018487 21738 solver.cpp:228] Iteration 0, loss = 1.78377
I0813 23:14:34.018539 21738 solver.cpp:244]     Train net output #0: accuracy = 0.645
I0813 23:14:34.018556 21738 solver.cpp:244]     Train net output #1: loss = 1.78377 (* 1 = 1.78377 loss)
I0813 23:14:34.018584 21738 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0813 23:15:58.725703 21738 solver.cpp:228] Iteration 50, loss = 0.307739
I0813 23:15:58.725864 21738 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0813 23:15:58.725885 21738 solver.cpp:244]     Train net output #1: loss = 0.307739 (* 1 = 0.307739 loss)
I0813 23:15:58.725906 21738 sgd_solver.cpp:106] Iteration 50, lr = 0.00996266
I0813 23:17:19.078181 21738 solver.cpp:337] Iteration 100, Testing net (#0)
I0813 23:17:27.381348 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 23:17:27.381408 21738 solver.cpp:404]     Test net output #1: loss = 0.732427 (* 1 = 0.732427 loss)
I0813 23:17:29.018393 21738 solver.cpp:228] Iteration 100, loss = 0.202579
I0813 23:17:29.018460 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0813 23:17:29.018477 21738 solver.cpp:244]     Train net output #1: loss = 0.202579 (* 1 = 0.202579 loss)
I0813 23:17:29.018493 21738 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0813 23:18:55.502634 21738 solver.cpp:228] Iteration 150, loss = 0.281973
I0813 23:18:55.502776 21738 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0813 23:18:55.502794 21738 solver.cpp:244]     Train net output #1: loss = 0.281973 (* 1 = 0.281973 loss)
I0813 23:18:55.502810 21738 sgd_solver.cpp:106] Iteration 150, lr = 0.00988896
I0813 23:20:17.387451 21738 solver.cpp:337] Iteration 200, Testing net (#0)
I0813 23:20:26.168895 21738 solver.cpp:404]     Test net output #0: accuracy = 0.764
I0813 23:20:26.168962 21738 solver.cpp:404]     Test net output #1: loss = 0.691239 (* 1 = 0.691239 loss)
I0813 23:20:27.791020 21738 solver.cpp:228] Iteration 200, loss = 0.193623
I0813 23:20:27.791070 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 23:20:27.791084 21738 solver.cpp:244]     Train net output #1: loss = 0.193623 (* 1 = 0.193623 loss)
I0813 23:20:27.791098 21738 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0813 23:21:51.731933 21738 solver.cpp:228] Iteration 250, loss = 0.272775
I0813 23:21:51.732091 21738 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0813 23:21:51.732108 21738 solver.cpp:244]     Train net output #1: loss = 0.272775 (* 1 = 0.272775 loss)
I0813 23:21:51.732125 21738 sgd_solver.cpp:106] Iteration 250, lr = 0.00981651
I0813 23:23:13.214885 21738 solver.cpp:337] Iteration 300, Testing net (#0)
I0813 23:23:21.877501 21738 solver.cpp:404]     Test net output #0: accuracy = 0.694
I0813 23:23:21.877562 21738 solver.cpp:404]     Test net output #1: loss = 0.689543 (* 1 = 0.689543 loss)
I0813 23:23:23.521910 21738 solver.cpp:228] Iteration 300, loss = 0.191832
I0813 23:23:23.521976 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 23:23:23.521992 21738 solver.cpp:244]     Train net output #1: loss = 0.191832 (* 1 = 0.191832 loss)
I0813 23:23:23.522007 21738 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0813 23:24:45.926687 21738 solver.cpp:228] Iteration 350, loss = 0.270698
I0813 23:24:45.926889 21738 solver.cpp:244]     Train net output #0: accuracy = 0.925
I0813 23:24:45.926940 21738 solver.cpp:244]     Train net output #1: loss = 0.270698 (* 1 = 0.270698 loss)
I0813 23:24:45.926970 21738 sgd_solver.cpp:106] Iteration 350, lr = 0.00974529
I0813 23:26:05.927304 21738 solver.cpp:337] Iteration 400, Testing net (#0)
I0813 23:26:14.208600 21738 solver.cpp:404]     Test net output #0: accuracy = 0.994
I0813 23:26:14.208660 21738 solver.cpp:404]     Test net output #1: loss = 0.688788 (* 1 = 0.688788 loss)
I0813 23:26:15.857049 21738 solver.cpp:228] Iteration 400, loss = 0.190394
I0813 23:26:15.857125 21738 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0813 23:26:15.857141 21738 solver.cpp:244]     Train net output #1: loss = 0.190394 (* 1 = 0.190394 loss)
I0813 23:26:15.857158 21738 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0813 23:27:38.857705 21738 solver.cpp:228] Iteration 450, loss = 0.270577
I0813 23:27:38.857964 21738 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0813 23:27:38.858024 21738 solver.cpp:244]     Train net output #1: loss = 0.270577 (* 1 = 0.270577 loss)
I0813 23:27:38.858079 21738 sgd_solver.cpp:106] Iteration 450, lr = 0.00967526
I0813 23:29:00.674648 21738 solver.cpp:337] Iteration 500, Testing net (#0)
I0813 23:29:09.224825 21738 solver.cpp:404]     Test net output #0: accuracy = 1
I0813 23:29:09.224885 21738 solver.cpp:404]     Test net output #1: loss = 0.689124 (* 1 = 0.689124 loss)
I0813 23:29:10.835177 21738 solver.cpp:228] Iteration 500, loss = 0.190719
I0813 23:29:10.835253 21738 solver.cpp:244]     Train net output #0: accuracy = 0.985
I0813 23:29:10.835268 21738 solver.cpp:244]     Train net output #1: loss = 0.190719 (* 1 = 0.190719 loss)
I0813 23:29:10.835283 21738 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0813 23:30:33.076480 21738 solver.cpp:228] Iteration 550, loss = 0.270389
I0813 23:30:33.076680 21738 solver.cpp:244]     Train net output #0: accuracy = 0.965
I0813 23:30:33.076747 21738 solver.cpp:244]     Train net output #1: loss = 0.270389 (* 1 = 0.270389 loss)
I0813 23:30:33.076777 21738 sgd_solver.cpp:106] Iteration 550, lr = 0.0096064
I0813 23:31:54.313709 21738 solver.cpp:337] Iteration 600, Testing net (#0)
I0813 23:32:02.978585 21738 solver.cpp:404]     Test net output #0: accuracy = 0.712
I0813 23:32:02.978644 21738 solver.cpp:404]     Test net output #1: loss = 0.688318 (* 1 = 0.688318 loss)
I0813 23:32:04.590210 21738 solver.cpp:228] Iteration 600, loss = 0.190223
I0813 23:32:04.590260 21738 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0813 23:32:04.590273 21738 solver.cpp:244]     Train net output #1: loss = 0.190223 (* 1 = 0.190223 loss)
I0813 23:32:04.590291 21738 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0813 23:33:26.701797 21738 solver.cpp:228] Iteration 650, loss = 0.270537
I0813 23:33:26.702034 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0813 23:33:26.702101 21738 solver.cpp:244]     Train net output #1: loss = 0.270537 (* 1 = 0.270537 loss)
I0813 23:33:26.702145 21738 sgd_solver.cpp:106] Iteration 650, lr = 0.00953867
I0813 23:34:47.827793 21738 solver.cpp:337] Iteration 700, Testing net (#0)
I0813 23:34:56.460825 21738 solver.cpp:404]     Test net output #0: accuracy = 0.871
I0813 23:34:56.460882 21738 solver.cpp:404]     Test net output #1: loss = 0.688141 (* 1 = 0.688141 loss)
I0813 23:34:58.096905 21738 solver.cpp:228] Iteration 700, loss = 0.190282
I0813 23:34:58.096968 21738 solver.cpp:244]     Train net output #0: accuracy = 0.945
I0813 23:34:58.096983 21738 solver.cpp:244]     Train net output #1: loss = 0.190282 (* 1 = 0.190282 loss)
I0813 23:34:58.097000 21738 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0813 23:36:21.172546 21738 solver.cpp:228] Iteration 750, loss = 0.271541
I0813 23:36:21.172689 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0813 23:36:21.172706 21738 solver.cpp:244]     Train net output #1: loss = 0.271541 (* 1 = 0.271541 loss)
I0813 23:36:21.172732 21738 sgd_solver.cpp:106] Iteration 750, lr = 0.00947204
I0813 23:37:41.238663 21738 solver.cpp:337] Iteration 800, Testing net (#0)
I0813 23:37:50.030330 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 23:37:50.030390 21738 solver.cpp:404]     Test net output #1: loss = 0.691807 (* 1 = 0.691807 loss)
I0813 23:37:51.653875 21738 solver.cpp:228] Iteration 800, loss = 0.190913
I0813 23:37:51.653940 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0813 23:37:51.653954 21738 solver.cpp:244]     Train net output #1: loss = 0.190913 (* 1 = 0.190913 loss)
I0813 23:37:51.653970 21738 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0813 23:39:13.983624 21738 solver.cpp:228] Iteration 850, loss = 0.270577
I0813 23:39:13.983800 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0813 23:39:13.983817 21738 solver.cpp:244]     Train net output #1: loss = 0.270577 (* 1 = 0.270577 loss)
I0813 23:39:13.983832 21738 sgd_solver.cpp:106] Iteration 850, lr = 0.00940649
I0813 23:40:34.481814 21738 solver.cpp:337] Iteration 900, Testing net (#0)
I0813 23:40:42.820438 21738 solver.cpp:404]     Test net output #0: accuracy = 0.73
I0813 23:40:42.820507 21738 solver.cpp:404]     Test net output #1: loss = 0.688275 (* 1 = 0.688275 loss)
I0813 23:40:44.449926 21738 solver.cpp:228] Iteration 900, loss = 0.190589
I0813 23:40:44.449990 21738 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0813 23:40:44.450006 21738 solver.cpp:244]     Train net output #1: loss = 0.190589 (* 1 = 0.190589 loss)
I0813 23:40:44.450021 21738 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0813 23:42:08.287840 21738 solver.cpp:228] Iteration 950, loss = 0.272733
I0813 23:42:08.287972 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0813 23:42:08.287991 21738 solver.cpp:244]     Train net output #1: loss = 0.272733 (* 1 = 0.272733 loss)
I0813 23:42:08.288008 21738 sgd_solver.cpp:106] Iteration 950, lr = 0.00934199
I0813 23:43:29.802886 21738 solver.cpp:337] Iteration 1000, Testing net (#0)
I0813 23:43:38.301784 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 23:43:38.301846 21738 solver.cpp:404]     Test net output #1: loss = 0.690006 (* 1 = 0.690006 loss)
I0813 23:43:39.914732 21738 solver.cpp:228] Iteration 1000, loss = 0.190328
I0813 23:43:39.914795 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0813 23:43:39.914810 21738 solver.cpp:244]     Train net output #1: loss = 0.190328 (* 1 = 0.190328 loss)
I0813 23:43:39.914826 21738 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0813 23:45:05.506306 21738 solver.cpp:228] Iteration 1050, loss = 0.271524
I0813 23:45:05.506448 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0813 23:45:05.506469 21738 solver.cpp:244]     Train net output #1: loss = 0.271524 (* 1 = 0.271524 loss)
I0813 23:45:05.506495 21738 sgd_solver.cpp:106] Iteration 1050, lr = 0.00927851
I0813 23:46:26.411923 21738 solver.cpp:337] Iteration 1100, Testing net (#0)
I0813 23:46:34.939970 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 23:46:34.940042 21738 solver.cpp:404]     Test net output #1: loss = 0.694052 (* 1 = 0.694052 loss)
I0813 23:46:36.567294 21738 solver.cpp:228] Iteration 1100, loss = 0.191397
I0813 23:46:36.567359 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0813 23:46:36.567376 21738 solver.cpp:244]     Train net output #1: loss = 0.191396 (* 1 = 0.191396 loss)
I0813 23:46:36.567394 21738 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0813 23:47:58.712527 21738 solver.cpp:228] Iteration 1150, loss = 0.270551
I0813 23:47:58.712785 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0813 23:47:58.712862 21738 solver.cpp:244]     Train net output #1: loss = 0.270551 (* 1 = 0.270551 loss)
I0813 23:47:58.712896 21738 sgd_solver.cpp:106] Iteration 1150, lr = 0.00921603
I0813 23:49:20.984748 21738 solver.cpp:337] Iteration 1200, Testing net (#0)
I0813 23:49:29.618165 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 23:49:29.618223 21738 solver.cpp:404]     Test net output #1: loss = 0.689335 (* 1 = 0.689335 loss)
I0813 23:49:31.239954 21738 solver.cpp:228] Iteration 1200, loss = 0.190177
I0813 23:49:31.240020 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0813 23:49:31.240043 21738 solver.cpp:244]     Train net output #1: loss = 0.190177 (* 1 = 0.190177 loss)
I0813 23:49:31.240061 21738 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0813 23:50:54.522501 21738 solver.cpp:228] Iteration 1250, loss = 0.273146
I0813 23:50:54.522639 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0813 23:50:54.522653 21738 solver.cpp:244]     Train net output #1: loss = 0.273146 (* 1 = 0.273146 loss)
I0813 23:50:54.522666 21738 sgd_solver.cpp:106] Iteration 1250, lr = 0.00915452
I0813 23:52:15.725096 21738 solver.cpp:337] Iteration 1300, Testing net (#0)
I0813 23:52:23.827330 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 23:52:23.827386 21738 solver.cpp:404]     Test net output #1: loss = 0.694476 (* 1 = 0.694476 loss)
I0813 23:52:25.581881 21738 solver.cpp:228] Iteration 1300, loss = 0.191527
I0813 23:52:25.581946 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0813 23:52:25.581961 21738 solver.cpp:244]     Train net output #1: loss = 0.191527 (* 1 = 0.191527 loss)
I0813 23:52:25.581977 21738 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0813 23:53:48.539331 21738 solver.cpp:228] Iteration 1350, loss = 0.272636
I0813 23:53:48.539494 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0813 23:53:48.539510 21738 solver.cpp:244]     Train net output #1: loss = 0.272635 (* 1 = 0.272635 loss)
I0813 23:53:48.539522 21738 sgd_solver.cpp:106] Iteration 1350, lr = 0.00909396
I0813 23:55:12.617861 21738 solver.cpp:337] Iteration 1400, Testing net (#0)
I0813 23:55:21.299309 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 23:55:21.299373 21738 solver.cpp:404]     Test net output #1: loss = 0.689446 (* 1 = 0.689446 loss)
I0813 23:55:22.930590 21738 solver.cpp:228] Iteration 1400, loss = 0.190166
I0813 23:55:22.930656 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0813 23:55:22.930670 21738 solver.cpp:244]     Train net output #1: loss = 0.190166 (* 1 = 0.190166 loss)
I0813 23:55:22.930686 21738 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0813 23:56:47.665802 21738 solver.cpp:228] Iteration 1450, loss = 0.271788
I0813 23:56:47.666026 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0813 23:56:47.666095 21738 solver.cpp:244]     Train net output #1: loss = 0.271788 (* 1 = 0.271788 loss)
I0813 23:56:47.666129 21738 sgd_solver.cpp:106] Iteration 1450, lr = 0.00903433
I0813 23:58:09.546310 21738 solver.cpp:337] Iteration 1500, Testing net (#0)
I0813 23:58:18.135507 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0813 23:58:18.135565 21738 solver.cpp:404]     Test net output #1: loss = 0.693129 (* 1 = 0.693129 loss)
I0813 23:58:19.759264 21738 solver.cpp:228] Iteration 1500, loss = 0.19117
I0813 23:58:19.759325 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0813 23:58:19.759337 21738 solver.cpp:244]     Train net output #1: loss = 0.19117 (* 1 = 0.19117 loss)
I0813 23:58:19.759354 21738 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0813 23:59:42.317391 21738 solver.cpp:228] Iteration 1550, loss = 0.273458
I0813 23:59:42.317543 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0813 23:59:42.317561 21738 solver.cpp:244]     Train net output #1: loss = 0.273458 (* 1 = 0.273458 loss)
I0813 23:59:42.317579 21738 sgd_solver.cpp:106] Iteration 1550, lr = 0.0089756
I0814 00:01:03.849010 21738 solver.cpp:337] Iteration 1600, Testing net (#0)
I0814 00:01:12.470170 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:01:12.470232 21738 solver.cpp:404]     Test net output #1: loss = 0.69142 (* 1 = 0.69142 loss)
I0814 00:01:14.101977 21738 solver.cpp:228] Iteration 1600, loss = 0.190717
I0814 00:01:14.102042 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:01:14.102058 21738 solver.cpp:244]     Train net output #1: loss = 0.190717 (* 1 = 0.190717 loss)
I0814 00:01:14.102077 21738 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0814 00:02:37.165197 21738 solver.cpp:228] Iteration 1650, loss = 0.271642
I0814 00:02:37.165356 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:02:37.165374 21738 solver.cpp:244]     Train net output #1: loss = 0.271642 (* 1 = 0.271642 loss)
I0814 00:02:37.165390 21738 sgd_solver.cpp:106] Iteration 1650, lr = 0.00891776
I0814 00:03:58.724728 21738 solver.cpp:337] Iteration 1700, Testing net (#0)
I0814 00:04:06.877189 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:04:06.877261 21738 solver.cpp:404]     Test net output #1: loss = 0.68889 (* 1 = 0.68889 loss)
I0814 00:04:08.501878 21738 solver.cpp:228] Iteration 1700, loss = 0.190287
I0814 00:04:08.501930 21738 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0814 00:04:08.501948 21738 solver.cpp:244]     Train net output #1: loss = 0.190286 (* 1 = 0.190286 loss)
I0814 00:04:08.501962 21738 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0814 00:05:32.524196 21738 solver.cpp:228] Iteration 1750, loss = 0.270177
I0814 00:05:32.524353 21738 solver.cpp:244]     Train net output #0: accuracy = 0.895
I0814 00:05:32.524370 21738 solver.cpp:244]     Train net output #1: loss = 0.270177 (* 1 = 0.270177 loss)
I0814 00:05:32.524386 21738 sgd_solver.cpp:106] Iteration 1750, lr = 0.00886077
I0814 00:06:54.519173 21738 solver.cpp:337] Iteration 1800, Testing net (#0)
I0814 00:07:02.751281 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:07:02.751348 21738 solver.cpp:404]     Test net output #1: loss = 0.691478 (* 1 = 0.691478 loss)
I0814 00:07:04.362853 21738 solver.cpp:228] Iteration 1800, loss = 0.190705
I0814 00:07:04.362917 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:07:04.362936 21738 solver.cpp:244]     Train net output #1: loss = 0.190705 (* 1 = 0.190705 loss)
I0814 00:07:04.362951 21738 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0814 00:08:27.407301 21738 solver.cpp:228] Iteration 1850, loss = 0.27083
I0814 00:08:27.407454 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:08:27.407470 21738 solver.cpp:244]     Train net output #1: loss = 0.27083 (* 1 = 0.27083 loss)
I0814 00:08:27.407483 21738 sgd_solver.cpp:106] Iteration 1850, lr = 0.00880463
I0814 00:09:49.106660 21738 solver.cpp:337] Iteration 1900, Testing net (#0)
I0814 00:09:57.230605 21738 solver.cpp:404]     Test net output #0: accuracy = 1
I0814 00:09:57.230661 21738 solver.cpp:404]     Test net output #1: loss = 0.688845 (* 1 = 0.688845 loss)
I0814 00:09:58.834909 21738 solver.cpp:228] Iteration 1900, loss = 0.194045
I0814 00:09:58.834960 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 00:09:58.834972 21738 solver.cpp:244]     Train net output #1: loss = 0.194045 (* 1 = 0.194045 loss)
I0814 00:09:58.834988 21738 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0814 00:11:21.635269 21738 solver.cpp:228] Iteration 1950, loss = 0.271745
I0814 00:11:21.635437 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:11:21.635457 21738 solver.cpp:244]     Train net output #1: loss = 0.271745 (* 1 = 0.271745 loss)
I0814 00:11:21.635474 21738 sgd_solver.cpp:106] Iteration 1950, lr = 0.00874932
I0814 00:12:43.357993 21738 solver.cpp:337] Iteration 2000, Testing net (#0)
I0814 00:12:51.723749 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:12:51.723810 21738 solver.cpp:404]     Test net output #1: loss = 0.692432 (* 1 = 0.692432 loss)
I0814 00:12:53.361682 21738 solver.cpp:228] Iteration 2000, loss = 0.190961
I0814 00:12:53.361747 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:12:53.361760 21738 solver.cpp:244]     Train net output #1: loss = 0.190961 (* 1 = 0.190961 loss)
I0814 00:12:53.361776 21738 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0814 00:14:16.445077 21738 solver.cpp:228] Iteration 2050, loss = 0.271917
I0814 00:14:16.445296 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:14:16.445368 21738 solver.cpp:244]     Train net output #1: loss = 0.271917 (* 1 = 0.271917 loss)
I0814 00:14:16.445415 21738 sgd_solver.cpp:106] Iteration 2050, lr = 0.0086948
I0814 00:15:36.523747 21738 solver.cpp:337] Iteration 2100, Testing net (#0)
I0814 00:15:45.219923 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:15:45.219982 21738 solver.cpp:404]     Test net output #1: loss = 0.693297 (* 1 = 0.693297 loss)
I0814 00:15:46.857831 21738 solver.cpp:228] Iteration 2100, loss = 0.191229
I0814 00:15:46.857892 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:15:46.857908 21738 solver.cpp:244]     Train net output #1: loss = 0.191228 (* 1 = 0.191228 loss)
I0814 00:15:46.857923 21738 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0814 00:17:11.421370 21738 solver.cpp:228] Iteration 2150, loss = 0.270964
I0814 00:17:11.421648 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:17:11.421720 21738 solver.cpp:244]     Train net output #1: loss = 0.270963 (* 1 = 0.270963 loss)
I0814 00:17:11.421772 21738 sgd_solver.cpp:106] Iteration 2150, lr = 0.00864108
I0814 00:18:33.024222 21738 solver.cpp:337] Iteration 2200, Testing net (#0)
I0814 00:18:41.700089 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:18:41.700155 21738 solver.cpp:404]     Test net output #1: loss = 0.695651 (* 1 = 0.695651 loss)
I0814 00:18:43.400771 21738 solver.cpp:228] Iteration 2200, loss = 0.191833
I0814 00:18:43.400835 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:18:43.400851 21738 solver.cpp:244]     Train net output #1: loss = 0.191833 (* 1 = 0.191833 loss)
I0814 00:18:43.400866 21738 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0814 00:20:07.805639 21738 solver.cpp:228] Iteration 2250, loss = 0.271672
I0814 00:20:07.805850 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:20:07.805924 21738 solver.cpp:244]     Train net output #1: loss = 0.271672 (* 1 = 0.271672 loss)
I0814 00:20:07.805975 21738 sgd_solver.cpp:106] Iteration 2250, lr = 0.00858812
I0814 00:21:30.068279 21738 solver.cpp:337] Iteration 2300, Testing net (#0)
I0814 00:21:38.749577 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:21:38.749639 21738 solver.cpp:404]     Test net output #1: loss = 0.695543 (* 1 = 0.695543 loss)
I0814 00:21:40.358433 21738 solver.cpp:228] Iteration 2300, loss = 0.191782
I0814 00:21:40.358486 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:21:40.358500 21738 solver.cpp:244]     Train net output #1: loss = 0.191782 (* 1 = 0.191782 loss)
I0814 00:21:40.358516 21738 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0814 00:23:03.190143 21738 solver.cpp:228] Iteration 2350, loss = 0.270996
I0814 00:23:03.190280 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:23:03.190295 21738 solver.cpp:244]     Train net output #1: loss = 0.270996 (* 1 = 0.270996 loss)
I0814 00:23:03.190307 21738 sgd_solver.cpp:106] Iteration 2350, lr = 0.00853591
I0814 00:24:25.057814 21738 solver.cpp:337] Iteration 2400, Testing net (#0)
I0814 00:24:33.722283 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:24:33.722342 21738 solver.cpp:404]     Test net output #1: loss = 0.6896 (* 1 = 0.6896 loss)
I0814 00:24:35.335117 21738 solver.cpp:228] Iteration 2400, loss = 0.1902
I0814 00:24:35.335178 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 00:24:35.335194 21738 solver.cpp:244]     Train net output #1: loss = 0.1902 (* 1 = 0.1902 loss)
I0814 00:24:35.335212 21738 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0814 00:25:58.262466 21738 solver.cpp:228] Iteration 2450, loss = 0.27059
I0814 00:25:58.262672 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:25:58.262742 21738 solver.cpp:244]     Train net output #1: loss = 0.27059 (* 1 = 0.27059 loss)
I0814 00:25:58.262787 21738 sgd_solver.cpp:106] Iteration 2450, lr = 0.00848444
I0814 00:27:19.940217 21738 solver.cpp:337] Iteration 2500, Testing net (#0)
I0814 00:27:28.338982 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:27:28.339059 21738 solver.cpp:404]     Test net output #1: loss = 0.691995 (* 1 = 0.691995 loss)
I0814 00:27:30.165174 21738 solver.cpp:228] Iteration 2500, loss = 0.190772
I0814 00:27:30.165225 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:27:30.165240 21738 solver.cpp:244]     Train net output #1: loss = 0.190772 (* 1 = 0.190772 loss)
I0814 00:27:30.165256 21738 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0814 00:28:52.801718 21738 solver.cpp:228] Iteration 2550, loss = 0.270283
I0814 00:28:52.802005 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:28:52.802062 21738 solver.cpp:244]     Train net output #1: loss = 0.270283 (* 1 = 0.270283 loss)
I0814 00:28:52.802101 21738 sgd_solver.cpp:106] Iteration 2550, lr = 0.00843368
I0814 00:30:14.401641 21738 solver.cpp:337] Iteration 2600, Testing net (#0)
I0814 00:30:22.901284 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:30:22.901351 21738 solver.cpp:404]     Test net output #1: loss = 0.70471 (* 1 = 0.70471 loss)
I0814 00:30:24.510393 21738 solver.cpp:228] Iteration 2600, loss = 0.194336
I0814 00:30:24.510457 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:30:24.510471 21738 solver.cpp:244]     Train net output #1: loss = 0.194336 (* 1 = 0.194336 loss)
I0814 00:30:24.510486 21738 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0814 00:31:47.247463 21738 solver.cpp:228] Iteration 2650, loss = 0.272474
I0814 00:31:47.247659 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:31:47.247699 21738 solver.cpp:244]     Train net output #1: loss = 0.272473 (* 1 = 0.272473 loss)
I0814 00:31:47.247731 21738 sgd_solver.cpp:106] Iteration 2650, lr = 0.00838363
I0814 00:33:07.970369 21738 solver.cpp:337] Iteration 2700, Testing net (#0)
I0814 00:33:16.499420 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:33:16.499480 21738 solver.cpp:404]     Test net output #1: loss = 0.689362 (* 1 = 0.689362 loss)
I0814 00:33:18.124727 21738 solver.cpp:228] Iteration 2700, loss = 0.190162
I0814 00:33:18.124796 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 00:33:18.124811 21738 solver.cpp:244]     Train net output #1: loss = 0.190161 (* 1 = 0.190161 loss)
I0814 00:33:18.124826 21738 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0814 00:34:40.806013 21738 solver.cpp:228] Iteration 2750, loss = 0.270638
I0814 00:34:40.806161 21738 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0814 00:34:40.806181 21738 solver.cpp:244]     Train net output #1: loss = 0.270638 (* 1 = 0.270638 loss)
I0814 00:34:40.806197 21738 sgd_solver.cpp:106] Iteration 2750, lr = 0.00833427
I0814 00:36:02.362462 21738 solver.cpp:337] Iteration 2800, Testing net (#0)
I0814 00:36:11.145483 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:36:11.145540 21738 solver.cpp:404]     Test net output #1: loss = 0.693458 (* 1 = 0.693458 loss)
I0814 00:36:12.771975 21738 solver.cpp:228] Iteration 2800, loss = 0.191241
I0814 00:36:12.772047 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:36:12.772064 21738 solver.cpp:244]     Train net output #1: loss = 0.191241 (* 1 = 0.191241 loss)
I0814 00:36:12.772080 21738 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0814 00:37:40.493538 21738 solver.cpp:228] Iteration 2850, loss = 0.271229
I0814 00:37:40.493741 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:37:40.493804 21738 solver.cpp:244]     Train net output #1: loss = 0.271229 (* 1 = 0.271229 loss)
I0814 00:37:40.493844 21738 sgd_solver.cpp:106] Iteration 2850, lr = 0.00828557
I0814 00:39:06.159265 21738 solver.cpp:337] Iteration 2900, Testing net (#0)
I0814 00:39:14.427366 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:39:14.427435 21738 solver.cpp:404]     Test net output #1: loss = 0.688969 (* 1 = 0.688969 loss)
I0814 00:39:16.036768 21738 solver.cpp:228] Iteration 2900, loss = 0.190158
I0814 00:39:16.036815 21738 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0814 00:39:16.036828 21738 solver.cpp:244]     Train net output #1: loss = 0.190158 (* 1 = 0.190158 loss)
I0814 00:39:16.036844 21738 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0814 00:40:44.812809 21738 solver.cpp:228] Iteration 2950, loss = 0.274188
I0814 00:40:44.813025 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:40:44.813093 21738 solver.cpp:244]     Train net output #1: loss = 0.274188 (* 1 = 0.274188 loss)
I0814 00:40:44.813143 21738 sgd_solver.cpp:106] Iteration 2950, lr = 0.00823754
I0814 00:42:10.440371 21738 solver.cpp:337] Iteration 3000, Testing net (#0)
I0814 00:42:19.466639 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:42:19.466697 21738 solver.cpp:404]     Test net output #1: loss = 0.704383 (* 1 = 0.704383 loss)
I0814 00:42:21.064910 21738 solver.cpp:228] Iteration 3000, loss = 0.194279
I0814 00:42:21.064980 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:42:21.064997 21738 solver.cpp:244]     Train net output #1: loss = 0.194279 (* 1 = 0.194279 loss)
I0814 00:42:21.065014 21738 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0814 00:43:47.595625 21738 solver.cpp:228] Iteration 3050, loss = 0.271572
I0814 00:43:47.595887 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:43:47.595963 21738 solver.cpp:244]     Train net output #1: loss = 0.271571 (* 1 = 0.271571 loss)
I0814 00:43:47.596014 21738 sgd_solver.cpp:106] Iteration 3050, lr = 0.00819015
I0814 00:45:11.247809 21738 solver.cpp:337] Iteration 3100, Testing net (#0)
I0814 00:45:19.964692 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:45:19.964766 21738 solver.cpp:404]     Test net output #1: loss = 0.68935 (* 1 = 0.68935 loss)
I0814 00:45:21.569695 21738 solver.cpp:228] Iteration 3100, loss = 0.190184
I0814 00:45:21.569761 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 00:45:21.569777 21738 solver.cpp:244]     Train net output #1: loss = 0.190184 (* 1 = 0.190184 loss)
I0814 00:45:21.569794 21738 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0814 00:46:48.819383 21738 solver.cpp:228] Iteration 3150, loss = 0.272048
I0814 00:46:48.819555 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:46:48.819573 21738 solver.cpp:244]     Train net output #1: loss = 0.272048 (* 1 = 0.272048 loss)
I0814 00:46:48.819588 21738 sgd_solver.cpp:106] Iteration 3150, lr = 0.0081434
I0814 00:48:09.057024 21738 solver.cpp:337] Iteration 3200, Testing net (#0)
I0814 00:48:17.413975 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:48:17.414037 21738 solver.cpp:404]     Test net output #1: loss = 0.693253 (* 1 = 0.693253 loss)
I0814 00:48:19.012917 21738 solver.cpp:228] Iteration 3200, loss = 0.191233
I0814 00:48:19.012976 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:48:19.012989 21738 solver.cpp:244]     Train net output #1: loss = 0.191233 (* 1 = 0.191233 loss)
I0814 00:48:19.013003 21738 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0814 00:49:42.730142 21738 solver.cpp:228] Iteration 3250, loss = 0.273281
I0814 00:49:42.730373 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:49:42.730439 21738 solver.cpp:244]     Train net output #1: loss = 0.273281 (* 1 = 0.273281 loss)
I0814 00:49:42.730478 21738 sgd_solver.cpp:106] Iteration 3250, lr = 0.00809726
I0814 00:51:04.139158 21738 solver.cpp:337] Iteration 3300, Testing net (#0)
I0814 00:51:12.747531 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:51:12.747602 21738 solver.cpp:404]     Test net output #1: loss = 0.696135 (* 1 = 0.696135 loss)
I0814 00:51:14.352246 21738 solver.cpp:228] Iteration 3300, loss = 0.192004
I0814 00:51:14.352311 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:51:14.352326 21738 solver.cpp:244]     Train net output #1: loss = 0.192004 (* 1 = 0.192004 loss)
I0814 00:51:14.352341 21738 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0814 00:52:36.964511 21738 solver.cpp:228] Iteration 3350, loss = 0.27095
I0814 00:52:36.964650 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:52:36.964668 21738 solver.cpp:244]     Train net output #1: loss = 0.27095 (* 1 = 0.27095 loss)
I0814 00:52:36.964682 21738 sgd_solver.cpp:106] Iteration 3350, lr = 0.00805173
I0814 00:53:58.728998 21738 solver.cpp:337] Iteration 3400, Testing net (#0)
I0814 00:54:07.493212 21738 solver.cpp:404]     Test net output #0: accuracy = 0.659
I0814 00:54:07.493273 21738 solver.cpp:404]     Test net output #1: loss = 0.688846 (* 1 = 0.688846 loss)
I0814 00:54:09.105690 21738 solver.cpp:228] Iteration 3400, loss = 0.190508
I0814 00:54:09.105746 21738 solver.cpp:244]     Train net output #0: accuracy = 0.955
I0814 00:54:09.105761 21738 solver.cpp:244]     Train net output #1: loss = 0.190507 (* 1 = 0.190507 loss)
I0814 00:54:09.105775 21738 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0814 00:55:33.487278 21738 solver.cpp:228] Iteration 3450, loss = 0.272342
I0814 00:55:33.487504 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 00:55:33.487576 21738 solver.cpp:244]     Train net output #1: loss = 0.272341 (* 1 = 0.272341 loss)
I0814 00:55:33.487617 21738 sgd_solver.cpp:106] Iteration 3450, lr = 0.00800679
I0814 00:56:54.879132 21738 solver.cpp:337] Iteration 3500, Testing net (#0)
I0814 00:57:03.388087 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:57:03.388152 21738 solver.cpp:404]     Test net output #1: loss = 0.692927 (* 1 = 0.692927 loss)
I0814 00:57:04.970093 21738 solver.cpp:228] Iteration 3500, loss = 0.191111
I0814 00:57:04.970155 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:57:04.970170 21738 solver.cpp:244]     Train net output #1: loss = 0.191111 (* 1 = 0.191111 loss)
I0814 00:57:04.970183 21738 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0814 00:58:27.103008 21738 solver.cpp:228] Iteration 3550, loss = 0.270515
I0814 00:58:27.103225 21738 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0814 00:58:27.103291 21738 solver.cpp:244]     Train net output #1: loss = 0.270515 (* 1 = 0.270515 loss)
I0814 00:58:27.103330 21738 sgd_solver.cpp:106] Iteration 3550, lr = 0.00796243
I0814 00:59:49.312638 21738 solver.cpp:337] Iteration 3600, Testing net (#0)
I0814 00:59:57.494267 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 00:59:57.494326 21738 solver.cpp:404]     Test net output #1: loss = 0.693295 (* 1 = 0.693295 loss)
I0814 00:59:59.075805 21738 solver.cpp:228] Iteration 3600, loss = 0.191157
I0814 00:59:59.075872 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 00:59:59.075887 21738 solver.cpp:244]     Train net output #1: loss = 0.191157 (* 1 = 0.191157 loss)
I0814 00:59:59.075902 21738 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0814 01:01:21.753736 21738 solver.cpp:228] Iteration 3650, loss = 0.270505
I0814 01:01:21.753888 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:01:21.753902 21738 solver.cpp:244]     Train net output #1: loss = 0.270504 (* 1 = 0.270504 loss)
I0814 01:01:21.753914 21738 sgd_solver.cpp:106] Iteration 3650, lr = 0.00791864
I0814 01:02:41.284261 21738 solver.cpp:337] Iteration 3700, Testing net (#0)
I0814 01:02:49.254253 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:02:49.254325 21738 solver.cpp:404]     Test net output #1: loss = 0.691343 (* 1 = 0.691343 loss)
I0814 01:02:50.940850 21738 solver.cpp:228] Iteration 3700, loss = 0.190643
I0814 01:02:50.940915 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:02:50.940929 21738 solver.cpp:244]     Train net output #1: loss = 0.190642 (* 1 = 0.190642 loss)
I0814 01:02:50.940943 21738 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0814 01:04:12.586158 21738 solver.cpp:228] Iteration 3750, loss = 0.272557
I0814 01:04:12.586320 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:04:12.586335 21738 solver.cpp:244]     Train net output #1: loss = 0.272557 (* 1 = 0.272557 loss)
I0814 01:04:12.586361 21738 sgd_solver.cpp:106] Iteration 3750, lr = 0.00787541
I0814 01:05:32.521320 21738 solver.cpp:337] Iteration 3800, Testing net (#0)
I0814 01:05:40.465508 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:05:40.465569 21738 solver.cpp:404]     Test net output #1: loss = 0.690481 (* 1 = 0.690481 loss)
I0814 01:05:42.043449 21738 solver.cpp:228] Iteration 3800, loss = 0.19035
I0814 01:05:42.043514 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:05:42.043525 21738 solver.cpp:244]     Train net output #1: loss = 0.19035 (* 1 = 0.19035 loss)
I0814 01:05:42.043540 21738 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0814 01:07:03.982565 21738 solver.cpp:228] Iteration 3850, loss = 0.27029
I0814 01:07:03.982810 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 01:07:03.982873 21738 solver.cpp:244]     Train net output #1: loss = 0.27029 (* 1 = 0.27029 loss)
I0814 01:07:03.982921 21738 sgd_solver.cpp:106] Iteration 3850, lr = 0.00783272
I0814 01:08:22.597651 21738 solver.cpp:337] Iteration 3900, Testing net (#0)
I0814 01:08:30.955468 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:08:30.955530 21738 solver.cpp:404]     Test net output #1: loss = 0.69268 (* 1 = 0.69268 loss)
I0814 01:08:32.531901 21738 solver.cpp:228] Iteration 3900, loss = 0.191004
I0814 01:08:32.531962 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:08:32.531975 21738 solver.cpp:244]     Train net output #1: loss = 0.191004 (* 1 = 0.191004 loss)
I0814 01:08:32.531988 21738 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0814 01:09:53.252266 21738 solver.cpp:228] Iteration 3950, loss = 0.271758
I0814 01:09:53.252425 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:09:53.252441 21738 solver.cpp:244]     Train net output #1: loss = 0.271758 (* 1 = 0.271758 loss)
I0814 01:09:53.252456 21738 sgd_solver.cpp:106] Iteration 3950, lr = 0.00779057
I0814 01:11:11.559646 21738 solver.cpp:337] Iteration 4000, Testing net (#0)
I0814 01:11:19.600039 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:11:19.600106 21738 solver.cpp:404]     Test net output #1: loss = 0.692437 (* 1 = 0.692437 loss)
I0814 01:11:21.175794 21738 solver.cpp:228] Iteration 4000, loss = 0.190919
I0814 01:11:21.175858 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:11:21.175870 21738 solver.cpp:244]     Train net output #1: loss = 0.190919 (* 1 = 0.190919 loss)
I0814 01:11:21.175884 21738 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0814 01:12:41.337517 21738 solver.cpp:228] Iteration 4050, loss = 0.27046
I0814 01:12:41.337754 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:12:41.337810 21738 solver.cpp:244]     Train net output #1: loss = 0.27046 (* 1 = 0.27046 loss)
I0814 01:12:41.337852 21738 sgd_solver.cpp:106] Iteration 4050, lr = 0.00774895
I0814 01:13:59.368248 21738 solver.cpp:337] Iteration 4100, Testing net (#0)
I0814 01:14:07.308285 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:14:07.308343 21738 solver.cpp:404]     Test net output #1: loss = 0.690031 (* 1 = 0.690031 loss)
I0814 01:14:08.885875 21738 solver.cpp:228] Iteration 4100, loss = 0.190244
I0814 01:14:08.885936 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:14:08.885948 21738 solver.cpp:244]     Train net output #1: loss = 0.190244 (* 1 = 0.190244 loss)
I0814 01:14:08.885962 21738 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0814 01:15:30.554994 21738 solver.cpp:228] Iteration 4150, loss = 0.270524
I0814 01:15:30.555207 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:15:30.555264 21738 solver.cpp:244]     Train net output #1: loss = 0.270524 (* 1 = 0.270524 loss)
I0814 01:15:30.555290 21738 sgd_solver.cpp:106] Iteration 4150, lr = 0.00770784
I0814 01:16:50.393544 21738 solver.cpp:337] Iteration 4200, Testing net (#0)
I0814 01:16:58.515667 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:16:58.515733 21738 solver.cpp:404]     Test net output #1: loss = 0.69675 (* 1 = 0.69675 loss)
I0814 01:17:00.099423 21738 solver.cpp:228] Iteration 4200, loss = 0.192135
I0814 01:17:00.099486 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:17:00.099500 21738 solver.cpp:244]     Train net output #1: loss = 0.192135 (* 1 = 0.192135 loss)
I0814 01:17:00.099515 21738 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0814 01:18:20.534279 21738 solver.cpp:228] Iteration 4250, loss = 0.27032
I0814 01:18:20.534543 21738 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0814 01:18:20.534591 21738 solver.cpp:244]     Train net output #1: loss = 0.27032 (* 1 = 0.27032 loss)
I0814 01:18:20.534611 21738 sgd_solver.cpp:106] Iteration 4250, lr = 0.00766724
I0814 01:19:41.568176 21738 solver.cpp:337] Iteration 4300, Testing net (#0)
I0814 01:19:49.511409 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:19:49.511469 21738 solver.cpp:404]     Test net output #1: loss = 0.693742 (* 1 = 0.693742 loss)
I0814 01:19:51.086917 21738 solver.cpp:228] Iteration 4300, loss = 0.191304
I0814 01:19:51.086969 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:19:51.086982 21738 solver.cpp:244]     Train net output #1: loss = 0.191304 (* 1 = 0.191304 loss)
I0814 01:19:51.086997 21738 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0814 01:21:12.061030 21738 solver.cpp:228] Iteration 4350, loss = 0.271012
I0814 01:21:12.061238 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:21:12.061295 21738 solver.cpp:244]     Train net output #1: loss = 0.271012 (* 1 = 0.271012 loss)
I0814 01:21:12.061318 21738 sgd_solver.cpp:106] Iteration 4350, lr = 0.00762713
I0814 01:22:32.024116 21738 solver.cpp:337] Iteration 4400, Testing net (#0)
I0814 01:22:40.063077 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:22:40.063143 21738 solver.cpp:404]     Test net output #1: loss = 0.697013 (* 1 = 0.697013 loss)
I0814 01:22:41.638856 21738 solver.cpp:228] Iteration 4400, loss = 0.192239
I0814 01:22:41.638908 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:22:41.638921 21738 solver.cpp:244]     Train net output #1: loss = 0.192239 (* 1 = 0.192239 loss)
I0814 01:22:41.638937 21738 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0814 01:24:02.907541 21738 solver.cpp:228] Iteration 4450, loss = 0.270908
I0814 01:24:02.907758 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:24:02.907840 21738 solver.cpp:244]     Train net output #1: loss = 0.270908 (* 1 = 0.270908 loss)
I0814 01:24:02.907883 21738 sgd_solver.cpp:106] Iteration 4450, lr = 0.00758751
I0814 01:25:22.615325 21738 solver.cpp:337] Iteration 4500, Testing net (#0)
I0814 01:25:30.729854 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:25:30.729915 21738 solver.cpp:404]     Test net output #1: loss = 0.693693 (* 1 = 0.693693 loss)
I0814 01:25:32.306205 21738 solver.cpp:228] Iteration 4500, loss = 0.191321
I0814 01:25:32.306257 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:25:32.306268 21738 solver.cpp:244]     Train net output #1: loss = 0.191321 (* 1 = 0.191321 loss)
I0814 01:25:32.306283 21738 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0814 01:26:52.417974 21738 solver.cpp:228] Iteration 4550, loss = 0.271924
I0814 01:26:52.418189 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:26:52.418242 21738 solver.cpp:244]     Train net output #1: loss = 0.271924 (* 1 = 0.271924 loss)
I0814 01:26:52.418273 21738 sgd_solver.cpp:106] Iteration 4550, lr = 0.00754836
I0814 01:28:15.536649 21738 solver.cpp:337] Iteration 4600, Testing net (#0)
I0814 01:28:23.861793 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:28:23.861860 21738 solver.cpp:404]     Test net output #1: loss = 0.691509 (* 1 = 0.691509 loss)
I0814 01:28:25.437384 21738 solver.cpp:228] Iteration 4600, loss = 0.190703
I0814 01:28:25.437438 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:28:25.437450 21738 solver.cpp:244]     Train net output #1: loss = 0.190703 (* 1 = 0.190703 loss)
I0814 01:28:25.437465 21738 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0814 01:29:48.704131 21738 solver.cpp:228] Iteration 4650, loss = 0.273107
I0814 01:29:48.704349 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 01:29:48.704424 21738 solver.cpp:244]     Train net output #1: loss = 0.273107 (* 1 = 0.273107 loss)
I0814 01:29:48.704469 21738 sgd_solver.cpp:106] Iteration 4650, lr = 0.00750969
I0814 01:31:09.511497 21738 solver.cpp:337] Iteration 4700, Testing net (#0)
I0814 01:31:17.441447 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 01:31:17.441506 21738 solver.cpp:404]     Test net output #1: loss = 0.689041 (* 1 = 0.689041 loss)
I0814 01:31:19.019740 21738 solver.cpp:228] Iteration 4700, loss = 0.190239
I0814 01:31:19.019793 21738 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0814 01:31:19.019804 21738 solver.cpp:244]     Train net output #1: loss = 0.190239 (* 1 = 0.190239 loss)
I0814 01:31:19.019819 21738 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0814 01:32:40.681489 21738 solver.cpp:228] Iteration 4750, loss = 0.271708
I0814 01:32:40.681692 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:32:40.681751 21738 solver.cpp:244]     Train net output #1: loss = 0.271708 (* 1 = 0.271708 loss)
I0814 01:32:40.681782 21738 sgd_solver.cpp:106] Iteration 4750, lr = 0.00747147
I0814 01:34:00.885818 21738 solver.cpp:337] Iteration 4800, Testing net (#0)
I0814 01:34:09.100436 21738 solver.cpp:404]     Test net output #0: accuracy = 0.73
I0814 01:34:09.100499 21738 solver.cpp:404]     Test net output #1: loss = 0.688323 (* 1 = 0.688323 loss)
I0814 01:34:10.679340 21738 solver.cpp:228] Iteration 4800, loss = 0.191374
I0814 01:34:10.679407 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 01:34:10.679421 21738 solver.cpp:244]     Train net output #1: loss = 0.191374 (* 1 = 0.191374 loss)
I0814 01:34:10.679435 21738 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0814 01:35:33.294180 21738 solver.cpp:228] Iteration 4850, loss = 0.270516
I0814 01:35:33.294392 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:35:33.294442 21738 solver.cpp:244]     Train net output #1: loss = 0.270516 (* 1 = 0.270516 loss)
I0814 01:35:33.294481 21738 sgd_solver.cpp:106] Iteration 4850, lr = 0.0074337
I0814 01:36:55.317948 21738 solver.cpp:337] Iteration 4900, Testing net (#0)
I0814 01:37:03.435190 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:37:03.435251 21738 solver.cpp:404]     Test net output #1: loss = 0.690285 (* 1 = 0.690285 loss)
I0814 01:37:05.012593 21738 solver.cpp:228] Iteration 4900, loss = 0.190399
I0814 01:37:05.012657 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:37:05.012670 21738 solver.cpp:244]     Train net output #1: loss = 0.190399 (* 1 = 0.190399 loss)
I0814 01:37:05.012686 21738 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0814 01:38:25.754115 21738 solver.cpp:228] Iteration 4950, loss = 0.2715
I0814 01:38:25.754264 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:38:25.754278 21738 solver.cpp:244]     Train net output #1: loss = 0.2715 (* 1 = 0.2715 loss)
I0814 01:38:25.754292 21738 sgd_solver.cpp:106] Iteration 4950, lr = 0.00739638
I0814 01:39:46.626711 21738 solver.cpp:337] Iteration 5000, Testing net (#0)
I0814 01:39:54.566509 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:39:54.566573 21738 solver.cpp:404]     Test net output #1: loss = 0.692679 (* 1 = 0.692679 loss)
I0814 01:39:56.141512 21738 solver.cpp:228] Iteration 5000, loss = 0.191005
I0814 01:39:56.141563 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:39:56.141576 21738 solver.cpp:244]     Train net output #1: loss = 0.191005 (* 1 = 0.191005 loss)
I0814 01:39:56.141587 21738 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0814 01:41:16.852138 21738 solver.cpp:228] Iteration 5050, loss = 0.27046
I0814 01:41:16.852325 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:41:16.852388 21738 solver.cpp:244]     Train net output #1: loss = 0.27046 (* 1 = 0.27046 loss)
I0814 01:41:16.852430 21738 sgd_solver.cpp:106] Iteration 5050, lr = 0.00735949
I0814 01:42:37.644803 21738 solver.cpp:337] Iteration 5100, Testing net (#0)
I0814 01:42:45.582711 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:42:45.582774 21738 solver.cpp:404]     Test net output #1: loss = 0.69096 (* 1 = 0.69096 loss)
I0814 01:42:47.154806 21738 solver.cpp:228] Iteration 5100, loss = 0.190578
I0814 01:42:47.154855 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:42:47.154866 21738 solver.cpp:244]     Train net output #1: loss = 0.190578 (* 1 = 0.190578 loss)
I0814 01:42:47.154880 21738 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0814 01:44:08.793792 21738 solver.cpp:228] Iteration 5150, loss = 0.270487
I0814 01:44:08.793998 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:44:08.794059 21738 solver.cpp:244]     Train net output #1: loss = 0.270487 (* 1 = 0.270487 loss)
I0814 01:44:08.794098 21738 sgd_solver.cpp:106] Iteration 5150, lr = 0.00732303
I0814 01:45:28.184638 21738 solver.cpp:337] Iteration 5200, Testing net (#0)
I0814 01:45:36.133147 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:45:36.133208 21738 solver.cpp:404]     Test net output #1: loss = 0.690098 (* 1 = 0.690098 loss)
I0814 01:45:37.710355 21738 solver.cpp:228] Iteration 5200, loss = 0.19029
I0814 01:45:37.710407 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 01:45:37.710419 21738 solver.cpp:244]     Train net output #1: loss = 0.19029 (* 1 = 0.19029 loss)
I0814 01:45:37.710435 21738 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0814 01:46:59.170596 21738 solver.cpp:228] Iteration 5250, loss = 0.270718
I0814 01:46:59.170814 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:46:59.170868 21738 solver.cpp:244]     Train net output #1: loss = 0.270718 (* 1 = 0.270718 loss)
I0814 01:46:59.170904 21738 sgd_solver.cpp:106] Iteration 5250, lr = 0.00728698
I0814 01:48:19.554280 21738 solver.cpp:337] Iteration 5300, Testing net (#0)
I0814 01:48:27.962844 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:48:27.962905 21738 solver.cpp:404]     Test net output #1: loss = 0.693958 (* 1 = 0.693958 loss)
I0814 01:48:29.537485 21738 solver.cpp:228] Iteration 5300, loss = 0.191373
I0814 01:48:29.537535 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:48:29.537547 21738 solver.cpp:244]     Train net output #1: loss = 0.191373 (* 1 = 0.191373 loss)
I0814 01:48:29.537565 21738 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0814 01:49:50.356521 21738 solver.cpp:228] Iteration 5350, loss = 0.270599
I0814 01:49:50.356709 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:49:50.356776 21738 solver.cpp:244]     Train net output #1: loss = 0.270599 (* 1 = 0.270599 loss)
I0814 01:49:50.356804 21738 sgd_solver.cpp:106] Iteration 5350, lr = 0.00725135
I0814 01:51:08.700285 21738 solver.cpp:337] Iteration 5400, Testing net (#0)
I0814 01:51:16.944206 21738 solver.cpp:404]     Test net output #0: accuracy = 0.928
I0814 01:51:16.944267 21738 solver.cpp:404]     Test net output #1: loss = 0.688381 (* 1 = 0.688381 loss)
I0814 01:51:18.519764 21738 solver.cpp:228] Iteration 5400, loss = 0.192941
I0814 01:51:18.519830 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 01:51:18.519843 21738 solver.cpp:244]     Train net output #1: loss = 0.192941 (* 1 = 0.192941 loss)
I0814 01:51:18.519858 21738 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0814 01:52:38.402294 21738 solver.cpp:228] Iteration 5450, loss = 0.271658
I0814 01:52:38.402448 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 01:52:38.402462 21738 solver.cpp:244]     Train net output #1: loss = 0.271658 (* 1 = 0.271658 loss)
I0814 01:52:38.402477 21738 sgd_solver.cpp:106] Iteration 5450, lr = 0.00721612
I0814 01:53:58.400372 21738 solver.cpp:337] Iteration 5500, Testing net (#0)
I0814 01:54:06.454268 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:54:06.454334 21738 solver.cpp:404]     Test net output #1: loss = 0.691482 (* 1 = 0.691482 loss)
I0814 01:54:08.036986 21738 solver.cpp:228] Iteration 5500, loss = 0.190616
I0814 01:54:08.037039 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:54:08.037050 21738 solver.cpp:244]     Train net output #1: loss = 0.190616 (* 1 = 0.190616 loss)
I0814 01:54:08.037063 21738 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0814 01:55:29.684144 21738 solver.cpp:228] Iteration 5550, loss = 0.27171
I0814 01:55:29.684334 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 01:55:29.684350 21738 solver.cpp:244]     Train net output #1: loss = 0.27171 (* 1 = 0.27171 loss)
I0814 01:55:29.684363 21738 sgd_solver.cpp:106] Iteration 5550, lr = 0.00718129
I0814 01:56:47.817771 21738 solver.cpp:337] Iteration 5600, Testing net (#0)
I0814 01:56:55.730844 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:56:55.730906 21738 solver.cpp:404]     Test net output #1: loss = 0.692427 (* 1 = 0.692427 loss)
I0814 01:56:57.306120 21738 solver.cpp:228] Iteration 5600, loss = 0.190919
I0814 01:56:57.306170 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:56:57.306181 21738 solver.cpp:244]     Train net output #1: loss = 0.190919 (* 1 = 0.190919 loss)
I0814 01:56:57.306200 21738 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0814 01:58:19.382237 21738 solver.cpp:228] Iteration 5650, loss = 0.270679
I0814 01:58:19.382453 21738 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0814 01:58:19.382511 21738 solver.cpp:244]     Train net output #1: loss = 0.270679 (* 1 = 0.270679 loss)
I0814 01:58:19.382544 21738 sgd_solver.cpp:106] Iteration 5650, lr = 0.00714684
I0814 01:59:40.098208 21738 solver.cpp:337] Iteration 5700, Testing net (#0)
I0814 01:59:48.495451 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 01:59:48.495515 21738 solver.cpp:404]     Test net output #1: loss = 0.693928 (* 1 = 0.693928 loss)
I0814 01:59:50.072069 21738 solver.cpp:228] Iteration 5700, loss = 0.19135
I0814 01:59:50.072134 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 01:59:50.072149 21738 solver.cpp:244]     Train net output #1: loss = 0.19135 (* 1 = 0.19135 loss)
I0814 01:59:50.072163 21738 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0814 02:01:09.866761 21738 solver.cpp:228] Iteration 5750, loss = 0.270623
I0814 02:01:09.866914 21738 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0814 02:01:09.866928 21738 solver.cpp:244]     Train net output #1: loss = 0.270623 (* 1 = 0.270623 loss)
I0814 02:01:09.866940 21738 sgd_solver.cpp:106] Iteration 5750, lr = 0.00711278
I0814 02:02:30.498560 21738 solver.cpp:337] Iteration 5800, Testing net (#0)
I0814 02:02:38.790459 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:02:38.790524 21738 solver.cpp:404]     Test net output #1: loss = 0.690596 (* 1 = 0.690596 loss)
I0814 02:02:40.369804 21738 solver.cpp:228] Iteration 5800, loss = 0.190429
I0814 02:02:40.369879 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:02:40.369891 21738 solver.cpp:244]     Train net output #1: loss = 0.190429 (* 1 = 0.190429 loss)
I0814 02:02:40.369906 21738 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0814 02:04:01.776718 21738 solver.cpp:228] Iteration 5850, loss = 0.270746
I0814 02:04:01.776928 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:04:01.776983 21738 solver.cpp:244]     Train net output #1: loss = 0.270746 (* 1 = 0.270746 loss)
I0814 02:04:01.777065 21738 sgd_solver.cpp:106] Iteration 5850, lr = 0.0070791
I0814 02:05:20.635996 21738 solver.cpp:337] Iteration 5900, Testing net (#0)
I0814 02:05:28.606710 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:05:28.606782 21738 solver.cpp:404]     Test net output #1: loss = 0.694651 (* 1 = 0.694651 loss)
I0814 02:05:30.186604 21738 solver.cpp:228] Iteration 5900, loss = 0.19158
I0814 02:05:30.186684 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:05:30.186699 21738 solver.cpp:244]     Train net output #1: loss = 0.19158 (* 1 = 0.19158 loss)
I0814 02:05:30.186713 21738 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0814 02:06:49.761453 21738 solver.cpp:228] Iteration 5950, loss = 0.271871
I0814 02:06:49.761680 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:06:49.761729 21738 solver.cpp:244]     Train net output #1: loss = 0.271871 (* 1 = 0.271871 loss)
I0814 02:06:49.761760 21738 sgd_solver.cpp:106] Iteration 5950, lr = 0.00704579
I0814 02:08:08.324199 21738 solver.cpp:337] Iteration 6000, Testing net (#0)
I0814 02:08:16.594713 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:08:16.594777 21738 solver.cpp:404]     Test net output #1: loss = 0.689672 (* 1 = 0.689672 loss)
I0814 02:08:18.202740 21738 solver.cpp:228] Iteration 6000, loss = 0.190206
I0814 02:08:18.202805 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:08:18.202821 21738 solver.cpp:244]     Train net output #1: loss = 0.190206 (* 1 = 0.190206 loss)
I0814 02:08:18.202836 21738 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0814 02:09:38.384582 21738 solver.cpp:228] Iteration 6050, loss = 0.271139
I0814 02:09:38.384760 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:09:38.384814 21738 solver.cpp:244]     Train net output #1: loss = 0.271139 (* 1 = 0.271139 loss)
I0814 02:09:38.384838 21738 sgd_solver.cpp:106] Iteration 6050, lr = 0.00701284
I0814 02:10:58.673413 21738 solver.cpp:337] Iteration 6100, Testing net (#0)
I0814 02:11:06.846920 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:11:06.846985 21738 solver.cpp:404]     Test net output #1: loss = 0.692652 (* 1 = 0.692652 loss)
I0814 02:11:08.421964 21738 solver.cpp:228] Iteration 6100, loss = 0.19103
I0814 02:11:08.422019 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:11:08.422034 21738 solver.cpp:244]     Train net output #1: loss = 0.19103 (* 1 = 0.19103 loss)
I0814 02:11:08.422049 21738 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0814 02:12:29.934154 21738 solver.cpp:228] Iteration 6150, loss = 0.270247
I0814 02:12:29.934314 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:12:29.934329 21738 solver.cpp:244]     Train net output #1: loss = 0.270247 (* 1 = 0.270247 loss)
I0814 02:12:29.934341 21738 sgd_solver.cpp:106] Iteration 6150, lr = 0.00698024
I0814 02:13:50.555225 21738 solver.cpp:337] Iteration 6200, Testing net (#0)
I0814 02:13:58.750576 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:13:58.750635 21738 solver.cpp:404]     Test net output #1: loss = 0.6894 (* 1 = 0.6894 loss)
I0814 02:14:00.330989 21738 solver.cpp:228] Iteration 6200, loss = 0.190184
I0814 02:14:00.331053 21738 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0814 02:14:00.331065 21738 solver.cpp:244]     Train net output #1: loss = 0.190184 (* 1 = 0.190184 loss)
I0814 02:14:00.331080 21738 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0814 02:15:23.155735 21738 solver.cpp:228] Iteration 6250, loss = 0.271075
I0814 02:15:23.155920 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:15:23.155967 21738 solver.cpp:244]     Train net output #1: loss = 0.271075 (* 1 = 0.271075 loss)
I0814 02:15:23.155987 21738 sgd_solver.cpp:106] Iteration 6250, lr = 0.006948
I0814 02:16:46.662230 21738 solver.cpp:337] Iteration 6300, Testing net (#0)
I0814 02:16:54.784729 21738 solver.cpp:404]     Test net output #0: accuracy = 0.66
I0814 02:16:54.784793 21738 solver.cpp:404]     Test net output #1: loss = 0.688863 (* 1 = 0.688863 loss)
I0814 02:16:56.363081 21738 solver.cpp:228] Iteration 6300, loss = 0.19051
I0814 02:16:56.363147 21738 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0814 02:16:56.363160 21738 solver.cpp:244]     Train net output #1: loss = 0.19051 (* 1 = 0.19051 loss)
I0814 02:16:56.363174 21738 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0814 02:18:18.419826 21738 solver.cpp:228] Iteration 6350, loss = 0.271362
I0814 02:18:18.420022 21738 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0814 02:18:18.420114 21738 solver.cpp:244]     Train net output #1: loss = 0.271362 (* 1 = 0.271362 loss)
I0814 02:18:18.420135 21738 sgd_solver.cpp:106] Iteration 6350, lr = 0.00691611
I0814 02:19:38.200297 21738 solver.cpp:337] Iteration 6400, Testing net (#0)
I0814 02:19:46.520820 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:19:46.520884 21738 solver.cpp:404]     Test net output #1: loss = 0.692715 (* 1 = 0.692715 loss)
I0814 02:19:48.104010 21738 solver.cpp:228] Iteration 6400, loss = 0.191055
I0814 02:19:48.104080 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:19:48.104094 21738 solver.cpp:244]     Train net output #1: loss = 0.191055 (* 1 = 0.191055 loss)
I0814 02:19:48.104111 21738 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0814 02:21:08.694116 21738 solver.cpp:228] Iteration 6450, loss = 0.271736
I0814 02:21:08.694278 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:21:08.694294 21738 solver.cpp:244]     Train net output #1: loss = 0.271736 (* 1 = 0.271736 loss)
I0814 02:21:08.694306 21738 sgd_solver.cpp:106] Iteration 6450, lr = 0.00688455
I0814 02:22:27.059888 21738 solver.cpp:337] Iteration 6500, Testing net (#0)
I0814 02:22:35.228260 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:22:35.228323 21738 solver.cpp:404]     Test net output #1: loss = 0.689885 (* 1 = 0.689885 loss)
I0814 02:22:36.803220 21738 solver.cpp:228] Iteration 6500, loss = 0.190296
I0814 02:22:36.803277 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:22:36.803290 21738 solver.cpp:244]     Train net output #1: loss = 0.190296 (* 1 = 0.190296 loss)
I0814 02:22:36.803304 21738 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0814 02:23:58.103865 21738 solver.cpp:228] Iteration 6550, loss = 0.271813
I0814 02:23:58.104092 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:23:58.104156 21738 solver.cpp:244]     Train net output #1: loss = 0.271813 (* 1 = 0.271813 loss)
I0814 02:23:58.104182 21738 sgd_solver.cpp:106] Iteration 6550, lr = 0.00685333
I0814 02:25:19.859594 21738 solver.cpp:337] Iteration 6600, Testing net (#0)
I0814 02:25:27.987001 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:25:27.987067 21738 solver.cpp:404]     Test net output #1: loss = 0.693777 (* 1 = 0.693777 loss)
I0814 02:25:29.563246 21738 solver.cpp:228] Iteration 6600, loss = 0.191315
I0814 02:25:29.563295 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:25:29.563308 21738 solver.cpp:244]     Train net output #1: loss = 0.191315 (* 1 = 0.191315 loss)
I0814 02:25:29.563324 21738 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0814 02:26:50.064494 21738 solver.cpp:228] Iteration 6650, loss = 0.271495
I0814 02:26:50.064685 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:26:50.064714 21738 solver.cpp:244]     Train net output #1: loss = 0.271495 (* 1 = 0.271495 loss)
I0814 02:26:50.064733 21738 sgd_solver.cpp:106] Iteration 6650, lr = 0.00682243
I0814 02:28:09.024726 21738 solver.cpp:337] Iteration 6700, Testing net (#0)
I0814 02:28:17.180999 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:28:17.181059 21738 solver.cpp:404]     Test net output #1: loss = 0.691812 (* 1 = 0.691812 loss)
I0814 02:28:18.757156 21738 solver.cpp:228] Iteration 6700, loss = 0.190824
I0814 02:28:18.757222 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:28:18.757236 21738 solver.cpp:244]     Train net output #1: loss = 0.190824 (* 1 = 0.190824 loss)
I0814 02:28:18.757251 21738 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0814 02:29:39.247534 21738 solver.cpp:228] Iteration 6750, loss = 0.271617
I0814 02:29:39.247771 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:29:39.247825 21738 solver.cpp:244]     Train net output #1: loss = 0.271617 (* 1 = 0.271617 loss)
I0814 02:29:39.247854 21738 sgd_solver.cpp:106] Iteration 6750, lr = 0.00679186
I0814 02:31:00.073842 21738 solver.cpp:337] Iteration 6800, Testing net (#0)
I0814 02:31:08.300518 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:31:08.300582 21738 solver.cpp:404]     Test net output #1: loss = 0.689336 (* 1 = 0.689336 loss)
I0814 02:31:09.876276 21738 solver.cpp:228] Iteration 6800, loss = 0.19018
I0814 02:31:09.876340 21738 solver.cpp:244]     Train net output #0: accuracy = 0.915
I0814 02:31:09.876353 21738 solver.cpp:244]     Train net output #1: loss = 0.19018 (* 1 = 0.19018 loss)
I0814 02:31:09.876368 21738 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0814 02:32:32.706401 21738 solver.cpp:228] Iteration 6850, loss = 0.270296
I0814 02:32:32.706567 21738 solver.cpp:244]     Train net output #0: accuracy = 0.915
I0814 02:32:32.706583 21738 solver.cpp:244]     Train net output #1: loss = 0.270296 (* 1 = 0.270296 loss)
I0814 02:32:32.706596 21738 sgd_solver.cpp:106] Iteration 6850, lr = 0.00676161
I0814 02:33:54.251999 21738 solver.cpp:337] Iteration 6900, Testing net (#0)
I0814 02:34:02.457386 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:34:02.457469 21738 solver.cpp:404]     Test net output #1: loss = 0.692288 (* 1 = 0.692288 loss)
I0814 02:34:04.033829 21738 solver.cpp:228] Iteration 6900, loss = 0.19098
I0814 02:34:04.033895 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:34:04.033910 21738 solver.cpp:244]     Train net output #1: loss = 0.19098 (* 1 = 0.19098 loss)
I0814 02:34:04.033922 21738 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0814 02:35:25.920668 21738 solver.cpp:228] Iteration 6950, loss = 0.270501
I0814 02:35:25.920894 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:35:25.920943 21738 solver.cpp:244]     Train net output #1: loss = 0.270501 (* 1 = 0.270501 loss)
I0814 02:35:25.920969 21738 sgd_solver.cpp:106] Iteration 6950, lr = 0.00673167
I0814 02:36:46.680227 21738 solver.cpp:337] Iteration 7000, Testing net (#0)
I0814 02:36:54.762388 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:36:54.762449 21738 solver.cpp:404]     Test net output #1: loss = 0.68911 (* 1 = 0.68911 loss)
I0814 02:36:56.337496 21738 solver.cpp:228] Iteration 7000, loss = 0.190153
I0814 02:36:56.337564 21738 solver.cpp:244]     Train net output #0: accuracy = 0.925
I0814 02:36:56.337576 21738 solver.cpp:244]     Train net output #1: loss = 0.190153 (* 1 = 0.190153 loss)
I0814 02:36:56.337591 21738 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0814 02:38:17.065974 21738 solver.cpp:228] Iteration 7050, loss = 0.272417
I0814 02:38:17.066112 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:38:17.066124 21738 solver.cpp:244]     Train net output #1: loss = 0.272417 (* 1 = 0.272417 loss)
I0814 02:38:17.066148 21738 sgd_solver.cpp:106] Iteration 7050, lr = 0.00670204
I0814 02:39:37.682835 21738 solver.cpp:337] Iteration 7100, Testing net (#0)
I0814 02:39:45.616996 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:39:45.617058 21738 solver.cpp:404]     Test net output #1: loss = 0.692157 (* 1 = 0.692157 loss)
I0814 02:39:47.191548 21738 solver.cpp:228] Iteration 7100, loss = 0.19092
I0814 02:39:47.191599 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:39:47.191611 21738 solver.cpp:244]     Train net output #1: loss = 0.19092 (* 1 = 0.19092 loss)
I0814 02:39:47.191627 21738 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0814 02:41:10.710716 21738 solver.cpp:228] Iteration 7150, loss = 0.271101
I0814 02:41:10.710945 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:41:10.711014 21738 solver.cpp:244]     Train net output #1: loss = 0.2711 (* 1 = 0.2711 loss)
I0814 02:41:10.711050 21738 sgd_solver.cpp:106] Iteration 7150, lr = 0.0066727
I0814 02:42:28.762368 21738 solver.cpp:337] Iteration 7200, Testing net (#0)
I0814 02:42:37.108150 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:42:37.108212 21738 solver.cpp:404]     Test net output #1: loss = 0.689145 (* 1 = 0.689145 loss)
I0814 02:42:38.682345 21738 solver.cpp:228] Iteration 7200, loss = 0.190202
I0814 02:42:38.682394 21738 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0814 02:42:38.682405 21738 solver.cpp:244]     Train net output #1: loss = 0.190202 (* 1 = 0.190202 loss)
I0814 02:42:38.682422 21738 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0814 02:43:57.878067 21738 solver.cpp:228] Iteration 7250, loss = 0.271079
I0814 02:43:57.878257 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:43:57.878273 21738 solver.cpp:244]     Train net output #1: loss = 0.271079 (* 1 = 0.271079 loss)
I0814 02:43:57.878286 21738 sgd_solver.cpp:106] Iteration 7250, lr = 0.00664367
I0814 02:45:16.699730 21738 solver.cpp:337] Iteration 7300, Testing net (#0)
I0814 02:45:24.922255 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:45:24.922323 21738 solver.cpp:404]     Test net output #1: loss = 0.692489 (* 1 = 0.692489 loss)
I0814 02:45:26.498838 21738 solver.cpp:228] Iteration 7300, loss = 0.191041
I0814 02:45:26.498903 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:45:26.498917 21738 solver.cpp:244]     Train net output #1: loss = 0.191041 (* 1 = 0.191041 loss)
I0814 02:45:26.498930 21738 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0814 02:46:46.523670 21738 solver.cpp:228] Iteration 7350, loss = 0.271122
I0814 02:46:46.523866 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:46:46.523931 21738 solver.cpp:244]     Train net output #1: loss = 0.271122 (* 1 = 0.271122 loss)
I0814 02:46:46.523964 21738 sgd_solver.cpp:106] Iteration 7350, lr = 0.00661493
I0814 02:48:06.500910 21738 solver.cpp:337] Iteration 7400, Testing net (#0)
I0814 02:48:14.437716 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:48:14.437777 21738 solver.cpp:404]     Test net output #1: loss = 0.693945 (* 1 = 0.693945 loss)
I0814 02:48:16.013895 21738 solver.cpp:228] Iteration 7400, loss = 0.191406
I0814 02:48:16.013944 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:48:16.013957 21738 solver.cpp:244]     Train net output #1: loss = 0.191406 (* 1 = 0.191406 loss)
I0814 02:48:16.013972 21738 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0814 02:49:39.040221 21738 solver.cpp:228] Iteration 7450, loss = 0.270466
I0814 02:49:39.040374 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:49:39.040388 21738 solver.cpp:244]     Train net output #1: loss = 0.270466 (* 1 = 0.270466 loss)
I0814 02:49:39.040400 21738 sgd_solver.cpp:106] Iteration 7450, lr = 0.00658648
I0814 02:51:00.120096 21738 solver.cpp:337] Iteration 7500, Testing net (#0)
I0814 02:51:08.069020 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:51:08.069079 21738 solver.cpp:404]     Test net output #1: loss = 0.689792 (* 1 = 0.689792 loss)
I0814 02:51:09.644948 21738 solver.cpp:228] Iteration 7500, loss = 0.190274
I0814 02:51:09.645010 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:51:09.645023 21738 solver.cpp:244]     Train net output #1: loss = 0.190274 (* 1 = 0.190274 loss)
I0814 02:51:09.645037 21738 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0814 02:52:33.016132 21738 solver.cpp:228] Iteration 7550, loss = 0.270987
I0814 02:52:33.016345 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:52:33.016362 21738 solver.cpp:244]     Train net output #1: loss = 0.270987 (* 1 = 0.270987 loss)
I0814 02:52:33.016378 21738 sgd_solver.cpp:106] Iteration 7550, lr = 0.00655831
I0814 02:53:53.491317 21738 solver.cpp:337] Iteration 7600, Testing net (#0)
I0814 02:54:01.747040 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:54:01.747100 21738 solver.cpp:404]     Test net output #1: loss = 0.690559 (* 1 = 0.690559 loss)
I0814 02:54:03.324479 21738 solver.cpp:228] Iteration 7600, loss = 0.190485
I0814 02:54:03.324548 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:54:03.324559 21738 solver.cpp:244]     Train net output #1: loss = 0.190485 (* 1 = 0.190485 loss)
I0814 02:54:03.324574 21738 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0814 02:55:24.567821 21738 solver.cpp:228] Iteration 7650, loss = 0.272081
I0814 02:55:24.568089 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 02:55:24.568163 21738 solver.cpp:244]     Train net output #1: loss = 0.272081 (* 1 = 0.272081 loss)
I0814 02:55:24.568200 21738 sgd_solver.cpp:106] Iteration 7650, lr = 0.00653043
I0814 02:56:45.545464 21738 solver.cpp:337] Iteration 7700, Testing net (#0)
I0814 02:56:53.665093 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 02:56:53.665155 21738 solver.cpp:404]     Test net output #1: loss = 0.689847 (* 1 = 0.689847 loss)
I0814 02:56:55.236477 21738 solver.cpp:228] Iteration 7700, loss = 0.190264
I0814 02:56:55.236536 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 02:56:55.236549 21738 solver.cpp:244]     Train net output #1: loss = 0.190264 (* 1 = 0.190264 loss)
I0814 02:56:55.236563 21738 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0814 02:58:15.075094 21738 solver.cpp:228] Iteration 7750, loss = 0.27022
I0814 02:58:15.075256 21738 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0814 02:58:15.075273 21738 solver.cpp:244]     Train net output #1: loss = 0.27022 (* 1 = 0.27022 loss)
I0814 02:58:15.075287 21738 sgd_solver.cpp:106] Iteration 7750, lr = 0.00650281
I0814 02:59:33.745904 21738 solver.cpp:337] Iteration 7800, Testing net (#0)
I0814 02:59:41.821764 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 02:59:41.821830 21738 solver.cpp:404]     Test net output #1: loss = 0.688897 (* 1 = 0.688897 loss)
I0814 02:59:43.398630 21738 solver.cpp:228] Iteration 7800, loss = 0.190307
I0814 02:59:43.398684 21738 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0814 02:59:43.398694 21738 solver.cpp:244]     Train net output #1: loss = 0.190307 (* 1 = 0.190307 loss)
I0814 02:59:43.398710 21738 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0814 03:01:03.472908 21738 solver.cpp:228] Iteration 7850, loss = 0.2704
I0814 03:01:03.473054 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:01:03.473068 21738 solver.cpp:244]     Train net output #1: loss = 0.2704 (* 1 = 0.2704 loss)
I0814 03:01:03.473083 21738 sgd_solver.cpp:106] Iteration 7850, lr = 0.00647547
I0814 03:02:22.586941 21738 solver.cpp:337] Iteration 7900, Testing net (#0)
I0814 03:02:30.531873 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:02:30.531937 21738 solver.cpp:404]     Test net output #1: loss = 0.691913 (* 1 = 0.691913 loss)
I0814 03:02:32.255939 21738 solver.cpp:228] Iteration 7900, loss = 0.190857
I0814 03:02:32.256003 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:02:32.256017 21738 solver.cpp:244]     Train net output #1: loss = 0.190857 (* 1 = 0.190857 loss)
I0814 03:02:32.256039 21738 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0814 03:03:52.581409 21738 solver.cpp:228] Iteration 7950, loss = 0.27046
I0814 03:03:52.581552 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:03:52.581568 21738 solver.cpp:244]     Train net output #1: loss = 0.27046 (* 1 = 0.27046 loss)
I0814 03:03:52.581578 21738 sgd_solver.cpp:106] Iteration 7950, lr = 0.0064484
I0814 03:05:11.725535 21738 solver.cpp:337] Iteration 8000, Testing net (#0)
I0814 03:05:20.689538 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 03:05:20.689602 21738 solver.cpp:404]     Test net output #1: loss = 0.688879 (* 1 = 0.688879 loss)
I0814 03:05:22.269780 21738 solver.cpp:228] Iteration 8000, loss = 0.190302
I0814 03:05:22.269830 21738 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0814 03:05:22.269842 21738 solver.cpp:244]     Train net output #1: loss = 0.190302 (* 1 = 0.190302 loss)
I0814 03:05:22.269861 21738 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0814 03:06:42.277094 21738 solver.cpp:228] Iteration 8050, loss = 0.270904
I0814 03:06:42.277334 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:06:42.277400 21738 solver.cpp:244]     Train net output #1: loss = 0.270904 (* 1 = 0.270904 loss)
I0814 03:06:42.277437 21738 sgd_solver.cpp:106] Iteration 8050, lr = 0.00642158
I0814 03:08:02.522958 21738 solver.cpp:337] Iteration 8100, Testing net (#0)
I0814 03:08:10.527344 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:08:10.527408 21738 solver.cpp:404]     Test net output #1: loss = 0.692969 (* 1 = 0.692969 loss)
I0814 03:08:12.102754 21738 solver.cpp:228] Iteration 8100, loss = 0.191142
I0814 03:08:12.102815 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:08:12.102828 21738 solver.cpp:244]     Train net output #1: loss = 0.191142 (* 1 = 0.191142 loss)
I0814 03:08:12.102841 21738 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0814 03:09:34.590379 21738 solver.cpp:228] Iteration 8150, loss = 0.271592
I0814 03:09:34.590600 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 03:09:34.590677 21738 solver.cpp:244]     Train net output #1: loss = 0.271592 (* 1 = 0.271592 loss)
I0814 03:09:34.590718 21738 sgd_solver.cpp:106] Iteration 8150, lr = 0.00639503
I0814 03:10:52.820798 21738 solver.cpp:337] Iteration 8200, Testing net (#0)
I0814 03:11:00.832366 21738 solver.cpp:404]     Test net output #0: accuracy = 0.668
I0814 03:11:00.832443 21738 solver.cpp:404]     Test net output #1: loss = 0.688542 (* 1 = 0.688542 loss)
I0814 03:11:02.637595 21738 solver.cpp:228] Iteration 8200, loss = 0.19084
I0814 03:11:02.637662 21738 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0814 03:11:02.637676 21738 solver.cpp:244]     Train net output #1: loss = 0.19084 (* 1 = 0.19084 loss)
I0814 03:11:02.637689 21738 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0814 03:12:25.137944 21738 solver.cpp:228] Iteration 8250, loss = 0.272148
I0814 03:12:25.138133 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:12:25.138149 21738 solver.cpp:244]     Train net output #1: loss = 0.272148 (* 1 = 0.272148 loss)
I0814 03:12:25.138161 21738 sgd_solver.cpp:106] Iteration 8250, lr = 0.00636873
I0814 03:13:45.147819 21738 solver.cpp:337] Iteration 8300, Testing net (#0)
I0814 03:13:53.161978 21738 solver.cpp:404]     Test net output #0: accuracy = 0.685
I0814 03:13:53.162042 21738 solver.cpp:404]     Test net output #1: loss = 0.688404 (* 1 = 0.688404 loss)
I0814 03:13:54.737525 21738 solver.cpp:228] Iteration 8300, loss = 0.190988
I0814 03:13:54.737581 21738 solver.cpp:244]     Train net output #0: accuracy = 0.995
I0814 03:13:54.737594 21738 solver.cpp:244]     Train net output #1: loss = 0.190988 (* 1 = 0.190988 loss)
I0814 03:13:54.737608 21738 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0814 03:15:15.263638 21738 solver.cpp:228] Iteration 8350, loss = 0.271484
I0814 03:15:15.263814 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:15:15.263860 21738 solver.cpp:244]     Train net output #1: loss = 0.271484 (* 1 = 0.271484 loss)
I0814 03:15:15.263880 21738 sgd_solver.cpp:106] Iteration 8350, lr = 0.00634268
I0814 03:16:36.245098 21738 solver.cpp:337] Iteration 8400, Testing net (#0)
I0814 03:16:44.443476 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:16:44.443550 21738 solver.cpp:404]     Test net output #1: loss = 0.691819 (* 1 = 0.691819 loss)
I0814 03:16:46.019479 21738 solver.cpp:228] Iteration 8400, loss = 0.190839
I0814 03:16:46.019536 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:16:46.019551 21738 solver.cpp:244]     Train net output #1: loss = 0.190839 (* 1 = 0.190839 loss)
I0814 03:16:46.019564 21738 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0814 03:18:07.713697 21738 solver.cpp:228] Iteration 8450, loss = 0.270915
I0814 03:18:07.713841 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:18:07.713856 21738 solver.cpp:244]     Train net output #1: loss = 0.270915 (* 1 = 0.270915 loss)
I0814 03:18:07.713867 21738 sgd_solver.cpp:106] Iteration 8450, lr = 0.00631688
I0814 03:19:29.534943 21738 solver.cpp:337] Iteration 8500, Testing net (#0)
I0814 03:19:37.565237 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:19:37.565297 21738 solver.cpp:404]     Test net output #1: loss = 0.689669 (* 1 = 0.689669 loss)
I0814 03:19:39.137481 21738 solver.cpp:228] Iteration 8500, loss = 0.190219
I0814 03:19:39.137555 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:19:39.137570 21738 solver.cpp:244]     Train net output #1: loss = 0.190219 (* 1 = 0.190219 loss)
I0814 03:19:39.137585 21738 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0814 03:21:00.305415 21738 solver.cpp:228] Iteration 8550, loss = 0.270327
I0814 03:21:00.305553 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:21:00.305568 21738 solver.cpp:244]     Train net output #1: loss = 0.270327 (* 1 = 0.270327 loss)
I0814 03:21:00.305594 21738 sgd_solver.cpp:106] Iteration 8550, lr = 0.00629132
I0814 03:22:18.852704 21738 solver.cpp:337] Iteration 8600, Testing net (#0)
I0814 03:22:26.790351 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:22:26.790416 21738 solver.cpp:404]     Test net output #1: loss = 0.690754 (* 1 = 0.690754 loss)
I0814 03:22:28.366722 21738 solver.cpp:228] Iteration 8600, loss = 0.19053
I0814 03:22:28.366780 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:22:28.366792 21738 solver.cpp:244]     Train net output #1: loss = 0.19053 (* 1 = 0.19053 loss)
I0814 03:22:28.366803 21738 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0814 03:23:50.207717 21738 solver.cpp:228] Iteration 8650, loss = 0.270496
I0814 03:23:50.207868 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:23:50.207882 21738 solver.cpp:244]     Train net output #1: loss = 0.270496 (* 1 = 0.270496 loss)
I0814 03:23:50.207897 21738 sgd_solver.cpp:106] Iteration 8650, lr = 0.00626601
I0814 03:25:09.900712 21738 solver.cpp:337] Iteration 8700, Testing net (#0)
I0814 03:25:17.836696 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:25:17.836756 21738 solver.cpp:404]     Test net output #1: loss = 0.693119 (* 1 = 0.693119 loss)
I0814 03:25:19.412235 21738 solver.cpp:228] Iteration 8700, loss = 0.191168
I0814 03:25:19.412298 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:25:19.412322 21738 solver.cpp:244]     Train net output #1: loss = 0.191168 (* 1 = 0.191168 loss)
I0814 03:25:19.412338 21738 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0814 03:26:40.076577 21738 solver.cpp:228] Iteration 8750, loss = 0.271166
I0814 03:26:40.076724 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:26:40.076737 21738 solver.cpp:244]     Train net output #1: loss = 0.271166 (* 1 = 0.271166 loss)
I0814 03:26:40.076750 21738 sgd_solver.cpp:106] Iteration 8750, lr = 0.00624093
I0814 03:28:00.508285 21738 solver.cpp:337] Iteration 8800, Testing net (#0)
I0814 03:28:08.693938 21738 solver.cpp:404]     Test net output #0: accuracy = 0.661
I0814 03:28:08.694001 21738 solver.cpp:404]     Test net output #1: loss = 0.688624 (* 1 = 0.688624 loss)
I0814 03:28:10.282179 21738 solver.cpp:228] Iteration 8800, loss = 0.190587
I0814 03:28:10.282241 21738 solver.cpp:244]     Train net output #0: accuracy = 0.965
I0814 03:28:10.282255 21738 solver.cpp:244]     Train net output #1: loss = 0.190587 (* 1 = 0.190587 loss)
I0814 03:28:10.282280 21738 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0814 03:29:32.857498 21738 solver.cpp:228] Iteration 8850, loss = 0.272219
I0814 03:29:32.857735 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:29:32.857792 21738 solver.cpp:244]     Train net output #1: loss = 0.272219 (* 1 = 0.272219 loss)
I0814 03:29:32.857820 21738 sgd_solver.cpp:106] Iteration 8850, lr = 0.00621608
I0814 03:30:52.884275 21738 solver.cpp:337] Iteration 8900, Testing net (#0)
I0814 03:31:00.821410 21738 solver.cpp:404]     Test net output #0: accuracy = 0.686
I0814 03:31:00.821470 21738 solver.cpp:404]     Test net output #1: loss = 0.688449 (* 1 = 0.688449 loss)
I0814 03:31:02.446838 21738 solver.cpp:228] Iteration 8900, loss = 0.190972
I0814 03:31:02.446892 21738 solver.cpp:244]     Train net output #0: accuracy = 0.995
I0814 03:31:02.446907 21738 solver.cpp:244]     Train net output #1: loss = 0.190972 (* 1 = 0.190972 loss)
I0814 03:31:02.446923 21738 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0814 03:32:27.068035 21738 solver.cpp:228] Iteration 8950, loss = 0.271718
I0814 03:32:27.068310 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:32:27.068364 21738 solver.cpp:244]     Train net output #1: loss = 0.271718 (* 1 = 0.271718 loss)
I0814 03:32:27.068390 21738 sgd_solver.cpp:106] Iteration 8950, lr = 0.00619146
I0814 03:33:46.957432 21738 solver.cpp:337] Iteration 9000, Testing net (#0)
I0814 03:33:55.128535 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:33:55.128597 21738 solver.cpp:404]     Test net output #1: loss = 0.692516 (* 1 = 0.692516 loss)
I0814 03:33:56.703793 21738 solver.cpp:228] Iteration 9000, loss = 0.190977
I0814 03:33:56.703863 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:33:56.703888 21738 solver.cpp:244]     Train net output #1: loss = 0.190977 (* 1 = 0.190977 loss)
I0814 03:33:56.703902 21738 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0814 03:35:18.715680 21738 solver.cpp:228] Iteration 9050, loss = 0.270443
I0814 03:35:18.715880 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 03:35:18.715941 21738 solver.cpp:244]     Train net output #1: loss = 0.270443 (* 1 = 0.270443 loss)
I0814 03:35:18.715976 21738 sgd_solver.cpp:106] Iteration 9050, lr = 0.00616707
I0814 03:36:39.414059 21738 solver.cpp:337] Iteration 9100, Testing net (#0)
I0814 03:36:47.690776 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:36:47.690840 21738 solver.cpp:404]     Test net output #1: loss = 0.692739 (* 1 = 0.692739 loss)
I0814 03:36:49.266026 21738 solver.cpp:228] Iteration 9100, loss = 0.191018
I0814 03:36:49.266091 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:36:49.266103 21738 solver.cpp:244]     Train net output #1: loss = 0.191018 (* 1 = 0.191018 loss)
I0814 03:36:49.266118 21738 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0814 03:38:11.426637 21738 solver.cpp:228] Iteration 9150, loss = 0.271169
I0814 03:38:11.426854 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:38:11.426928 21738 solver.cpp:244]     Train net output #1: loss = 0.271169 (* 1 = 0.271169 loss)
I0814 03:38:11.426969 21738 sgd_solver.cpp:106] Iteration 9150, lr = 0.0061429
I0814 03:39:31.895638 21738 solver.cpp:337] Iteration 9200, Testing net (#0)
I0814 03:39:40.169581 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:39:40.169642 21738 solver.cpp:404]     Test net output #1: loss = 0.689328 (* 1 = 0.689328 loss)
I0814 03:39:41.743490 21738 solver.cpp:228] Iteration 9200, loss = 0.190187
I0814 03:39:41.743551 21738 solver.cpp:244]     Train net output #0: accuracy = 0.915
I0814 03:39:41.743564 21738 solver.cpp:244]     Train net output #1: loss = 0.190187 (* 1 = 0.190187 loss)
I0814 03:39:41.743578 21738 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0814 03:41:04.048256 21738 solver.cpp:228] Iteration 9250, loss = 0.271833
I0814 03:41:04.048403 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:41:04.048418 21738 solver.cpp:244]     Train net output #1: loss = 0.271833 (* 1 = 0.271833 loss)
I0814 03:41:04.048432 21738 sgd_solver.cpp:106] Iteration 9250, lr = 0.00611895
I0814 03:42:25.328780 21738 solver.cpp:337] Iteration 9300, Testing net (#0)
I0814 03:42:33.408951 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 03:42:33.409013 21738 solver.cpp:404]     Test net output #1: loss = 0.688899 (* 1 = 0.688899 loss)
I0814 03:42:34.982265 21738 solver.cpp:228] Iteration 9300, loss = 0.190284
I0814 03:42:34.982327 21738 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0814 03:42:34.982341 21738 solver.cpp:244]     Train net output #1: loss = 0.190284 (* 1 = 0.190284 loss)
I0814 03:42:34.982354 21738 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0814 03:43:57.685184 21738 solver.cpp:228] Iteration 9350, loss = 0.270266
I0814 03:43:57.685426 21738 solver.cpp:244]     Train net output #0: accuracy = 0.87
I0814 03:43:57.685479 21738 solver.cpp:244]     Train net output #1: loss = 0.270266 (* 1 = 0.270266 loss)
I0814 03:43:57.685505 21738 sgd_solver.cpp:106] Iteration 9350, lr = 0.00609522
I0814 03:45:19.289252 21738 solver.cpp:337] Iteration 9400, Testing net (#0)
I0814 03:45:27.469090 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:45:27.469156 21738 solver.cpp:404]     Test net output #1: loss = 0.689801 (* 1 = 0.689801 loss)
I0814 03:45:29.043524 21738 solver.cpp:228] Iteration 9400, loss = 0.190279
I0814 03:45:29.043576 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:45:29.043588 21738 solver.cpp:244]     Train net output #1: loss = 0.190279 (* 1 = 0.190279 loss)
I0814 03:45:29.043606 21738 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0814 03:46:50.794896 21738 solver.cpp:228] Iteration 9450, loss = 0.271855
I0814 03:46:50.795049 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:46:50.795064 21738 solver.cpp:244]     Train net output #1: loss = 0.271855 (* 1 = 0.271855 loss)
I0814 03:46:50.795078 21738 sgd_solver.cpp:106] Iteration 9450, lr = 0.0060717
I0814 03:48:10.228153 21738 solver.cpp:337] Iteration 9500, Testing net (#0)
I0814 03:48:18.318455 21738 solver.cpp:404]     Test net output #0: accuracy = 0.763
I0814 03:48:18.318519 21738 solver.cpp:404]     Test net output #1: loss = 0.688218 (* 1 = 0.688218 loss)
I0814 03:48:19.896095 21738 solver.cpp:228] Iteration 9500, loss = 0.191405
I0814 03:48:19.896160 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 03:48:19.896173 21738 solver.cpp:244]     Train net output #1: loss = 0.191405 (* 1 = 0.191405 loss)
I0814 03:48:19.896188 21738 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0814 03:49:43.360558 21738 solver.cpp:228] Iteration 9550, loss = 0.271006
I0814 03:49:43.360750 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:49:43.360803 21738 solver.cpp:244]     Train net output #1: loss = 0.271006 (* 1 = 0.271006 loss)
I0814 03:49:43.360842 21738 sgd_solver.cpp:106] Iteration 9550, lr = 0.00604839
I0814 03:51:02.623101 21738 solver.cpp:337] Iteration 9600, Testing net (#0)
I0814 03:51:10.832062 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:51:10.832120 21738 solver.cpp:404]     Test net output #1: loss = 0.693793 (* 1 = 0.693793 loss)
I0814 03:51:12.404076 21738 solver.cpp:228] Iteration 9600, loss = 0.191391
I0814 03:51:12.404134 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:51:12.404148 21738 solver.cpp:244]     Train net output #1: loss = 0.191391 (* 1 = 0.191391 loss)
I0814 03:51:12.404161 21738 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0814 03:52:32.922667 21738 solver.cpp:228] Iteration 9650, loss = 0.270321
I0814 03:52:32.922809 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:52:32.922823 21738 solver.cpp:244]     Train net output #1: loss = 0.270321 (* 1 = 0.270321 loss)
I0814 03:52:32.922835 21738 sgd_solver.cpp:106] Iteration 9650, lr = 0.00602529
I0814 03:53:51.663866 21738 solver.cpp:337] Iteration 9700, Testing net (#0)
I0814 03:53:59.713546 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:53:59.713608 21738 solver.cpp:404]     Test net output #1: loss = 0.693937 (* 1 = 0.693937 loss)
I0814 03:54:01.288036 21738 solver.cpp:228] Iteration 9700, loss = 0.191426
I0814 03:54:01.288094 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:54:01.288106 21738 solver.cpp:244]     Train net output #1: loss = 0.191426 (* 1 = 0.191426 loss)
I0814 03:54:01.288120 21738 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0814 03:55:21.040287 21738 solver.cpp:228] Iteration 9750, loss = 0.270807
I0814 03:55:21.040472 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:55:21.040523 21738 solver.cpp:244]     Train net output #1: loss = 0.270807 (* 1 = 0.270807 loss)
I0814 03:55:21.040542 21738 sgd_solver.cpp:106] Iteration 9750, lr = 0.0060024
I0814 03:56:40.491415 21738 solver.cpp:337] Iteration 9800, Testing net (#0)
I0814 03:56:48.547824 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:56:48.547888 21738 solver.cpp:404]     Test net output #1: loss = 0.692746 (* 1 = 0.692746 loss)
I0814 03:56:50.135171 21738 solver.cpp:228] Iteration 9800, loss = 0.191112
I0814 03:56:50.135234 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:56:50.135246 21738 solver.cpp:244]     Train net output #1: loss = 0.191112 (* 1 = 0.191112 loss)
I0814 03:56:50.135265 21738 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0814 03:58:10.388677 21738 solver.cpp:228] Iteration 9850, loss = 0.271342
I0814 03:58:10.388840 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 03:58:10.388855 21738 solver.cpp:244]     Train net output #1: loss = 0.271342 (* 1 = 0.271342 loss)
I0814 03:58:10.388869 21738 sgd_solver.cpp:106] Iteration 9850, lr = 0.0059797
I0814 03:59:29.216773 21738 solver.cpp:337] Iteration 9900, Testing net (#0)
I0814 03:59:37.609145 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 03:59:37.609212 21738 solver.cpp:404]     Test net output #1: loss = 0.692128 (* 1 = 0.692128 loss)
I0814 03:59:39.185755 21738 solver.cpp:228] Iteration 9900, loss = 0.190919
I0814 03:59:39.185822 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 03:59:39.185834 21738 solver.cpp:244]     Train net output #1: loss = 0.190919 (* 1 = 0.190919 loss)
I0814 03:59:39.185850 21738 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0814 04:01:00.004961 21738 solver.cpp:228] Iteration 9950, loss = 0.270839
I0814 04:01:00.005110 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:01:00.005126 21738 solver.cpp:244]     Train net output #1: loss = 0.270839 (* 1 = 0.270839 loss)
I0814 04:01:00.005141 21738 sgd_solver.cpp:106] Iteration 9950, lr = 0.00595721
I0814 04:02:18.038651 21738 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_10000.caffemodel
I0814 04:02:18.454429 21738 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_10000.solverstate
I0814 04:02:18.487654 21738 solver.cpp:337] Iteration 10000, Testing net (#0)
I0814 04:02:26.990731 21738 solver.cpp:404]     Test net output #0: accuracy = 0.756
I0814 04:02:26.990797 21738 solver.cpp:404]     Test net output #1: loss = 0.688266 (* 1 = 0.688266 loss)
I0814 04:02:28.568011 21738 solver.cpp:228] Iteration 10000, loss = 0.191432
I0814 04:02:28.568079 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 04:02:28.568091 21738 solver.cpp:244]     Train net output #1: loss = 0.191432 (* 1 = 0.191432 loss)
I0814 04:02:28.568106 21738 sgd_solver.cpp:106] Iteration 10000, lr = 0.00594604
I0814 04:03:48.500676 21738 solver.cpp:228] Iteration 10050, loss = 0.27048
I0814 04:03:48.500910 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:03:48.500958 21738 solver.cpp:244]     Train net output #1: loss = 0.27048 (* 1 = 0.27048 loss)
I0814 04:03:48.500985 21738 sgd_solver.cpp:106] Iteration 10050, lr = 0.00593491
I0814 04:05:07.178386 21738 solver.cpp:337] Iteration 10100, Testing net (#0)
I0814 04:05:15.110944 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:05:15.111002 21738 solver.cpp:404]     Test net output #1: loss = 0.68924 (* 1 = 0.68924 loss)
I0814 04:05:16.835289 21738 solver.cpp:228] Iteration 10100, loss = 0.190155
I0814 04:05:16.835361 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:05:16.835376 21738 solver.cpp:244]     Train net output #1: loss = 0.190154 (* 1 = 0.190154 loss)
I0814 04:05:16.835391 21738 sgd_solver.cpp:106] Iteration 10100, lr = 0.00592384
I0814 04:06:37.335388 21738 solver.cpp:228] Iteration 10150, loss = 0.270546
I0814 04:06:37.335630 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:06:37.335696 21738 solver.cpp:244]     Train net output #1: loss = 0.270546 (* 1 = 0.270546 loss)
I0814 04:06:37.335726 21738 sgd_solver.cpp:106] Iteration 10150, lr = 0.00591281
I0814 04:07:56.828269 21738 solver.cpp:337] Iteration 10200, Testing net (#0)
I0814 04:08:05.187433 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:08:05.187494 21738 solver.cpp:404]     Test net output #1: loss = 0.692178 (* 1 = 0.692178 loss)
I0814 04:08:06.766520 21738 solver.cpp:228] Iteration 10200, loss = 0.190953
I0814 04:08:06.766585 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:08:06.766598 21738 solver.cpp:244]     Train net output #1: loss = 0.190953 (* 1 = 0.190953 loss)
I0814 04:08:06.766613 21738 sgd_solver.cpp:106] Iteration 10200, lr = 0.00590183
I0814 04:09:26.853281 21738 solver.cpp:228] Iteration 10250, loss = 0.270633
I0814 04:09:26.853451 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:09:26.853472 21738 solver.cpp:244]     Train net output #1: loss = 0.270633 (* 1 = 0.270633 loss)
I0814 04:09:26.853492 21738 sgd_solver.cpp:106] Iteration 10250, lr = 0.00589089
I0814 04:10:45.064352 21738 solver.cpp:337] Iteration 10300, Testing net (#0)
I0814 04:10:53.280658 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:10:53.280717 21738 solver.cpp:404]     Test net output #1: loss = 0.689285 (* 1 = 0.689285 loss)
I0814 04:10:54.858147 21738 solver.cpp:228] Iteration 10300, loss = 0.190127
I0814 04:10:54.858220 21738 solver.cpp:244]     Train net output #0: accuracy = 0.915
I0814 04:10:54.858233 21738 solver.cpp:244]     Train net output #1: loss = 0.190127 (* 1 = 0.190127 loss)
I0814 04:10:54.858249 21738 sgd_solver.cpp:106] Iteration 10300, lr = 0.00588001
I0814 04:12:15.109733 21738 solver.cpp:228] Iteration 10350, loss = 0.271786
I0814 04:12:15.109894 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:12:15.109910 21738 solver.cpp:244]     Train net output #1: loss = 0.271786 (* 1 = 0.271786 loss)
I0814 04:12:15.109920 21738 sgd_solver.cpp:106] Iteration 10350, lr = 0.00586917
I0814 04:13:33.755995 21738 solver.cpp:337] Iteration 10400, Testing net (#0)
I0814 04:13:41.910001 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:13:41.910063 21738 solver.cpp:404]     Test net output #1: loss = 0.690877 (* 1 = 0.690877 loss)
I0814 04:13:43.485957 21738 solver.cpp:228] Iteration 10400, loss = 0.190576
I0814 04:13:43.486021 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:13:43.486032 21738 solver.cpp:244]     Train net output #1: loss = 0.190576 (* 1 = 0.190576 loss)
I0814 04:13:43.486048 21738 sgd_solver.cpp:106] Iteration 10400, lr = 0.00585838
I0814 04:15:04.230191 21738 solver.cpp:228] Iteration 10450, loss = 0.270767
I0814 04:15:04.230346 21738 solver.cpp:244]     Train net output #0: accuracy = 0.975
I0814 04:15:04.230360 21738 solver.cpp:244]     Train net output #1: loss = 0.270767 (* 1 = 0.270767 loss)
I0814 04:15:04.230372 21738 sgd_solver.cpp:106] Iteration 10450, lr = 0.00584763
I0814 04:16:23.035280 21738 solver.cpp:337] Iteration 10500, Testing net (#0)
I0814 04:16:31.021298 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 04:16:31.021358 21738 solver.cpp:404]     Test net output #1: loss = 0.688881 (* 1 = 0.688881 loss)
I0814 04:16:32.599992 21738 solver.cpp:228] Iteration 10500, loss = 0.190259
I0814 04:16:32.600061 21738 solver.cpp:244]     Train net output #0: accuracy = 0.945
I0814 04:16:32.600075 21738 solver.cpp:244]     Train net output #1: loss = 0.190259 (* 1 = 0.190259 loss)
I0814 04:16:32.600090 21738 sgd_solver.cpp:106] Iteration 10500, lr = 0.00583693
I0814 04:17:53.283499 21738 solver.cpp:228] Iteration 10550, loss = 0.270307
I0814 04:17:53.283649 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:17:53.283665 21738 solver.cpp:244]     Train net output #1: loss = 0.270307 (* 1 = 0.270307 loss)
I0814 04:17:53.283676 21738 sgd_solver.cpp:106] Iteration 10550, lr = 0.00582628
I0814 04:19:11.578668 21738 solver.cpp:337] Iteration 10600, Testing net (#0)
I0814 04:19:19.661568 21738 solver.cpp:404]     Test net output #0: accuracy = 0.658
I0814 04:19:19.661633 21738 solver.cpp:404]     Test net output #1: loss = 0.688692 (* 1 = 0.688692 loss)
I0814 04:19:21.237859 21738 solver.cpp:228] Iteration 10600, loss = 0.190379
I0814 04:19:21.237915 21738 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0814 04:19:21.237926 21738 solver.cpp:244]     Train net output #1: loss = 0.190379 (* 1 = 0.190379 loss)
I0814 04:19:21.237941 21738 sgd_solver.cpp:106] Iteration 10600, lr = 0.00581567
I0814 04:20:40.986531 21738 solver.cpp:228] Iteration 10650, loss = 0.271042
I0814 04:20:40.986685 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:20:40.986701 21738 solver.cpp:244]     Train net output #1: loss = 0.271042 (* 1 = 0.271042 loss)
I0814 04:20:40.986716 21738 sgd_solver.cpp:106] Iteration 10650, lr = 0.0058051
I0814 04:21:59.561592 21738 solver.cpp:337] Iteration 10700, Testing net (#0)
I0814 04:22:07.596158 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:22:07.596217 21738 solver.cpp:404]     Test net output #1: loss = 0.692609 (* 1 = 0.692609 loss)
I0814 04:22:09.172977 21738 solver.cpp:228] Iteration 10700, loss = 0.191047
I0814 04:22:09.173044 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:22:09.173058 21738 solver.cpp:244]     Train net output #1: loss = 0.191047 (* 1 = 0.191047 loss)
I0814 04:22:09.173074 21738 sgd_solver.cpp:106] Iteration 10700, lr = 0.00579458
I0814 04:23:29.699827 21738 solver.cpp:228] Iteration 10750, loss = 0.270272
I0814 04:23:29.699985 21738 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0814 04:23:29.700001 21738 solver.cpp:244]     Train net output #1: loss = 0.270272 (* 1 = 0.270272 loss)
I0814 04:23:29.700016 21738 sgd_solver.cpp:106] Iteration 10750, lr = 0.00578411
I0814 04:24:47.835114 21738 solver.cpp:337] Iteration 10800, Testing net (#0)
I0814 04:24:55.798010 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:24:55.798076 21738 solver.cpp:404]     Test net output #1: loss = 0.689055 (* 1 = 0.689055 loss)
I0814 04:24:57.374205 21738 solver.cpp:228] Iteration 10800, loss = 0.190134
I0814 04:24:57.374258 21738 solver.cpp:244]     Train net output #0: accuracy = 0.925
I0814 04:24:57.374270 21738 solver.cpp:244]     Train net output #1: loss = 0.190133 (* 1 = 0.190133 loss)
I0814 04:24:57.374287 21738 sgd_solver.cpp:106] Iteration 10800, lr = 0.00577368
I0814 04:26:18.403342 21738 solver.cpp:228] Iteration 10850, loss = 0.271135
I0814 04:26:18.403587 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:26:18.403648 21738 solver.cpp:244]     Train net output #1: loss = 0.271135 (* 1 = 0.271135 loss)
I0814 04:26:18.403681 21738 sgd_solver.cpp:106] Iteration 10850, lr = 0.00576329
I0814 04:27:37.393009 21738 solver.cpp:337] Iteration 10900, Testing net (#0)
I0814 04:27:45.701145 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:27:45.701213 21738 solver.cpp:404]     Test net output #1: loss = 0.693666 (* 1 = 0.693666 loss)
I0814 04:27:47.279388 21738 solver.cpp:228] Iteration 10900, loss = 0.191396
I0814 04:27:47.279455 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:27:47.279469 21738 solver.cpp:244]     Train net output #1: loss = 0.191396 (* 1 = 0.191396 loss)
I0814 04:27:47.279484 21738 sgd_solver.cpp:106] Iteration 10900, lr = 0.00575295
I0814 04:29:06.992823 21738 solver.cpp:228] Iteration 10950, loss = 0.270973
I0814 04:29:06.993077 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:29:06.993134 21738 solver.cpp:244]     Train net output #1: loss = 0.270973 (* 1 = 0.270973 loss)
I0814 04:29:06.993160 21738 sgd_solver.cpp:106] Iteration 10950, lr = 0.00574264
I0814 04:30:25.909701 21738 solver.cpp:337] Iteration 11000, Testing net (#0)
I0814 04:30:34.002935 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:30:34.002996 21738 solver.cpp:404]     Test net output #1: loss = 0.691439 (* 1 = 0.691439 loss)
I0814 04:30:35.582981 21738 solver.cpp:228] Iteration 11000, loss = 0.190756
I0814 04:30:35.583045 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:30:35.583060 21738 solver.cpp:244]     Train net output #1: loss = 0.190756 (* 1 = 0.190756 loss)
I0814 04:30:35.583076 21738 sgd_solver.cpp:106] Iteration 11000, lr = 0.00573239
I0814 04:31:56.327478 21738 solver.cpp:228] Iteration 11050, loss = 0.271395
I0814 04:31:56.327716 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:31:56.327765 21738 solver.cpp:244]     Train net output #1: loss = 0.271395 (* 1 = 0.271395 loss)
I0814 04:31:56.327802 21738 sgd_solver.cpp:106] Iteration 11050, lr = 0.00572217
I0814 04:33:15.220070 21738 solver.cpp:337] Iteration 11100, Testing net (#0)
I0814 04:33:23.233629 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:33:23.233693 21738 solver.cpp:404]     Test net output #1: loss = 0.691611 (* 1 = 0.691611 loss)
I0814 04:33:24.814286 21738 solver.cpp:228] Iteration 11100, loss = 0.190815
I0814 04:33:24.814347 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:33:24.814359 21738 solver.cpp:244]     Train net output #1: loss = 0.190815 (* 1 = 0.190815 loss)
I0814 04:33:24.814373 21738 sgd_solver.cpp:106] Iteration 11100, lr = 0.005712
I0814 04:34:45.045469 21738 solver.cpp:228] Iteration 11150, loss = 0.271157
I0814 04:34:45.045614 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:34:45.045629 21738 solver.cpp:244]     Train net output #1: loss = 0.271157 (* 1 = 0.271157 loss)
I0814 04:34:45.045642 21738 sgd_solver.cpp:106] Iteration 11150, lr = 0.00570187
I0814 04:36:04.097903 21738 solver.cpp:337] Iteration 11200, Testing net (#0)
I0814 04:36:12.059137 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:36:12.059202 21738 solver.cpp:404]     Test net output #1: loss = 0.689255 (* 1 = 0.689255 loss)
I0814 04:36:13.636384 21738 solver.cpp:228] Iteration 11200, loss = 0.190171
I0814 04:36:13.636435 21738 solver.cpp:244]     Train net output #0: accuracy = 0.915
I0814 04:36:13.636447 21738 solver.cpp:244]     Train net output #1: loss = 0.190171 (* 1 = 0.190171 loss)
I0814 04:36:13.636462 21738 sgd_solver.cpp:106] Iteration 11200, lr = 0.00569178
I0814 04:37:33.895648 21738 solver.cpp:228] Iteration 11250, loss = 0.270535
I0814 04:37:33.895812 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:37:33.895828 21738 solver.cpp:244]     Train net output #1: loss = 0.270535 (* 1 = 0.270535 loss)
I0814 04:37:33.895841 21738 sgd_solver.cpp:106] Iteration 11250, lr = 0.00568173
I0814 04:38:52.015377 21738 solver.cpp:337] Iteration 11300, Testing net (#0)
I0814 04:38:59.967926 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:38:59.967988 21738 solver.cpp:404]     Test net output #1: loss = 0.691594 (* 1 = 0.691594 loss)
I0814 04:39:01.546205 21738 solver.cpp:228] Iteration 11300, loss = 0.19082
I0814 04:39:01.546264 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:39:01.546277 21738 solver.cpp:244]     Train net output #1: loss = 0.19082 (* 1 = 0.19082 loss)
I0814 04:39:01.546290 21738 sgd_solver.cpp:106] Iteration 11300, lr = 0.00567173
I0814 04:40:21.419287 21738 solver.cpp:228] Iteration 11350, loss = 0.27045
I0814 04:40:21.419435 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:40:21.419450 21738 solver.cpp:244]     Train net output #1: loss = 0.27045 (* 1 = 0.27045 loss)
I0814 04:40:21.419466 21738 sgd_solver.cpp:106] Iteration 11350, lr = 0.00566176
I0814 04:41:39.946646 21738 solver.cpp:337] Iteration 11400, Testing net (#0)
I0814 04:41:48.035416 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:41:48.035475 21738 solver.cpp:404]     Test net output #1: loss = 0.690874 (* 1 = 0.690874 loss)
I0814 04:41:49.609472 21738 solver.cpp:228] Iteration 11400, loss = 0.190589
I0814 04:41:49.609544 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:41:49.609556 21738 solver.cpp:244]     Train net output #1: loss = 0.190589 (* 1 = 0.190589 loss)
I0814 04:41:49.609571 21738 sgd_solver.cpp:106] Iteration 11400, lr = 0.00565184
I0814 04:43:10.667032 21738 solver.cpp:228] Iteration 11450, loss = 0.270509
I0814 04:43:10.667217 21738 solver.cpp:244]     Train net output #0: accuracy = 0.965
I0814 04:43:10.667232 21738 solver.cpp:244]     Train net output #1: loss = 0.270509 (* 1 = 0.270509 loss)
I0814 04:43:10.667248 21738 sgd_solver.cpp:106] Iteration 11450, lr = 0.00564195
I0814 04:44:29.098677 21738 solver.cpp:337] Iteration 11500, Testing net (#0)
I0814 04:44:37.357915 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:44:37.357977 21738 solver.cpp:404]     Test net output #1: loss = 0.689099 (* 1 = 0.689099 loss)
I0814 04:44:38.933782 21738 solver.cpp:228] Iteration 11500, loss = 0.190125
I0814 04:44:38.933840 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 04:44:38.933853 21738 solver.cpp:244]     Train net output #1: loss = 0.190125 (* 1 = 0.190125 loss)
I0814 04:44:38.933869 21738 sgd_solver.cpp:106] Iteration 11500, lr = 0.00563211
I0814 04:45:59.167462 21738 solver.cpp:228] Iteration 11550, loss = 0.27049
I0814 04:45:59.167682 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:45:59.167729 21738 solver.cpp:244]     Train net output #1: loss = 0.27049 (* 1 = 0.27049 loss)
I0814 04:45:59.167749 21738 sgd_solver.cpp:106] Iteration 11550, lr = 0.00562231
I0814 04:47:18.282210 21738 solver.cpp:337] Iteration 11600, Testing net (#0)
I0814 04:47:26.422652 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:47:26.422718 21738 solver.cpp:404]     Test net output #1: loss = 0.690842 (* 1 = 0.690842 loss)
I0814 04:47:28.001446 21738 solver.cpp:228] Iteration 11600, loss = 0.190615
I0814 04:47:28.001513 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:47:28.001526 21738 solver.cpp:244]     Train net output #1: loss = 0.190615 (* 1 = 0.190615 loss)
I0814 04:47:28.001541 21738 sgd_solver.cpp:106] Iteration 11600, lr = 0.00561254
I0814 04:48:48.106454 21738 solver.cpp:228] Iteration 11650, loss = 0.271967
I0814 04:48:48.106665 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:48:48.106720 21738 solver.cpp:244]     Train net output #1: loss = 0.271967 (* 1 = 0.271967 loss)
I0814 04:48:48.106751 21738 sgd_solver.cpp:106] Iteration 11650, lr = 0.00560282
I0814 04:50:06.858299 21738 solver.cpp:337] Iteration 11700, Testing net (#0)
I0814 04:50:15.138461 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:50:15.138520 21738 solver.cpp:404]     Test net output #1: loss = 0.691594 (* 1 = 0.691594 loss)
I0814 04:50:16.716223 21738 solver.cpp:228] Iteration 11700, loss = 0.190808
I0814 04:50:16.716289 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:50:16.716302 21738 solver.cpp:244]     Train net output #1: loss = 0.190808 (* 1 = 0.190808 loss)
I0814 04:50:16.716317 21738 sgd_solver.cpp:106] Iteration 11700, lr = 0.00559313
I0814 04:51:36.764693 21738 solver.cpp:228] Iteration 11750, loss = 0.271118
I0814 04:51:36.764852 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:51:36.764868 21738 solver.cpp:244]     Train net output #1: loss = 0.271118 (* 1 = 0.271118 loss)
I0814 04:51:36.764880 21738 sgd_solver.cpp:106] Iteration 11750, lr = 0.00558349
I0814 04:52:55.210714 21738 solver.cpp:337] Iteration 11800, Testing net (#0)
I0814 04:53:03.258083 21738 solver.cpp:404]     Test net output #0: accuracy = 0.679
I0814 04:53:03.258155 21738 solver.cpp:404]     Test net output #1: loss = 0.688319 (* 1 = 0.688319 loss)
I0814 04:53:04.834533 21738 solver.cpp:228] Iteration 11800, loss = 0.19078
I0814 04:53:04.834585 21738 solver.cpp:244]     Train net output #0: accuracy = 0.985
I0814 04:53:04.834597 21738 solver.cpp:244]     Train net output #1: loss = 0.19078 (* 1 = 0.19078 loss)
I0814 04:53:04.834614 21738 sgd_solver.cpp:106] Iteration 11800, lr = 0.00557388
I0814 04:54:24.998127 21738 solver.cpp:228] Iteration 11850, loss = 0.270813
I0814 04:54:24.998303 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:54:24.998317 21738 solver.cpp:244]     Train net output #1: loss = 0.270813 (* 1 = 0.270813 loss)
I0814 04:54:24.998329 21738 sgd_solver.cpp:106] Iteration 11850, lr = 0.00556431
I0814 04:55:44.054651 21738 solver.cpp:337] Iteration 11900, Testing net (#0)
I0814 04:55:52.158637 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:55:52.158699 21738 solver.cpp:404]     Test net output #1: loss = 0.691092 (* 1 = 0.691092 loss)
I0814 04:55:53.739141 21738 solver.cpp:228] Iteration 11900, loss = 0.190683
I0814 04:55:53.739207 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 04:55:53.739220 21738 solver.cpp:244]     Train net output #1: loss = 0.190683 (* 1 = 0.190683 loss)
I0814 04:55:53.739234 21738 sgd_solver.cpp:106] Iteration 11900, lr = 0.00555478
I0814 04:57:13.349825 21738 solver.cpp:228] Iteration 11950, loss = 0.271182
I0814 04:57:13.349974 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 04:57:13.349989 21738 solver.cpp:244]     Train net output #1: loss = 0.271182 (* 1 = 0.271182 loss)
I0814 04:57:13.350003 21738 sgd_solver.cpp:106] Iteration 11950, lr = 0.00554529
I0814 04:58:32.502434 21738 solver.cpp:337] Iteration 12000, Testing net (#0)
I0814 04:58:40.552089 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 04:58:40.552151 21738 solver.cpp:404]     Test net output #1: loss = 0.688922 (* 1 = 0.688922 loss)
I0814 04:58:42.129552 21738 solver.cpp:228] Iteration 12000, loss = 0.190099
I0814 04:58:42.129618 21738 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0814 04:58:42.129631 21738 solver.cpp:244]     Train net output #1: loss = 0.190099 (* 1 = 0.190099 loss)
I0814 04:58:42.129645 21738 sgd_solver.cpp:106] Iteration 12000, lr = 0.00553583
I0814 05:00:02.786455 21738 solver.cpp:228] Iteration 12050, loss = 0.271575
I0814 05:00:02.786595 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:00:02.786612 21738 solver.cpp:244]     Train net output #1: loss = 0.271575 (* 1 = 0.271575 loss)
I0814 05:00:02.786626 21738 sgd_solver.cpp:106] Iteration 12050, lr = 0.00552642
I0814 05:01:21.839071 21738 solver.cpp:337] Iteration 12100, Testing net (#0)
I0814 05:01:29.916954 21738 solver.cpp:404]     Test net output #0: accuracy = 0.99
I0814 05:01:29.917019 21738 solver.cpp:404]     Test net output #1: loss = 0.68844 (* 1 = 0.68844 loss)
I0814 05:01:31.493880 21738 solver.cpp:228] Iteration 12100, loss = 0.192349
I0814 05:01:31.493932 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 05:01:31.493942 21738 solver.cpp:244]     Train net output #1: loss = 0.192349 (* 1 = 0.192349 loss)
I0814 05:01:31.493958 21738 sgd_solver.cpp:106] Iteration 12100, lr = 0.00551704
I0814 05:02:51.340965 21738 solver.cpp:228] Iteration 12150, loss = 0.271537
I0814 05:02:51.341111 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:02:51.341127 21738 solver.cpp:244]     Train net output #1: loss = 0.271537 (* 1 = 0.271537 loss)
I0814 05:02:51.341140 21738 sgd_solver.cpp:106] Iteration 12150, lr = 0.00550769
I0814 05:04:09.690866 21738 solver.cpp:337] Iteration 12200, Testing net (#0)
I0814 05:04:17.953539 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:04:17.953606 21738 solver.cpp:404]     Test net output #1: loss = 0.689095 (* 1 = 0.689095 loss)
I0814 05:04:19.533429 21738 solver.cpp:228] Iteration 12200, loss = 0.190133
I0814 05:04:19.533496 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:04:19.533510 21738 solver.cpp:244]     Train net output #1: loss = 0.190133 (* 1 = 0.190133 loss)
I0814 05:04:19.533525 21738 sgd_solver.cpp:106] Iteration 12200, lr = 0.00549839
I0814 05:05:40.354835 21738 solver.cpp:228] Iteration 12250, loss = 0.271837
I0814 05:05:40.354984 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 05:05:40.354998 21738 solver.cpp:244]     Train net output #1: loss = 0.271837 (* 1 = 0.271837 loss)
I0814 05:05:40.355024 21738 sgd_solver.cpp:106] Iteration 12250, lr = 0.00548912
I0814 05:06:58.741863 21738 solver.cpp:337] Iteration 12300, Testing net (#0)
I0814 05:07:06.909435 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:07:06.909493 21738 solver.cpp:404]     Test net output #1: loss = 0.689884 (* 1 = 0.689884 loss)
I0814 05:07:08.487084 21738 solver.cpp:228] Iteration 12300, loss = 0.190353
I0814 05:07:08.487141 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:07:08.487154 21738 solver.cpp:244]     Train net output #1: loss = 0.190353 (* 1 = 0.190353 loss)
I0814 05:07:08.487167 21738 sgd_solver.cpp:106] Iteration 12300, lr = 0.00547988
I0814 05:08:28.925431 21738 solver.cpp:228] Iteration 12350, loss = 0.270588
I0814 05:08:28.925578 21738 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0814 05:08:28.925593 21738 solver.cpp:244]     Train net output #1: loss = 0.270588 (* 1 = 0.270588 loss)
I0814 05:08:28.925617 21738 sgd_solver.cpp:106] Iteration 12350, lr = 0.00547069
I0814 05:09:47.616400 21738 solver.cpp:337] Iteration 12400, Testing net (#0)
I0814 05:09:55.720919 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:09:55.720999 21738 solver.cpp:404]     Test net output #1: loss = 0.691109 (* 1 = 0.691109 loss)
I0814 05:09:57.297649 21738 solver.cpp:228] Iteration 12400, loss = 0.190697
I0814 05:09:57.297703 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:09:57.297713 21738 solver.cpp:244]     Train net output #1: loss = 0.190697 (* 1 = 0.190697 loss)
I0814 05:09:57.297731 21738 sgd_solver.cpp:106] Iteration 12400, lr = 0.00546153
I0814 05:11:18.057092 21738 solver.cpp:228] Iteration 12450, loss = 0.271206
I0814 05:11:18.057306 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:11:18.057320 21738 solver.cpp:244]     Train net output #1: loss = 0.271206 (* 1 = 0.271206 loss)
I0814 05:11:18.057332 21738 sgd_solver.cpp:106] Iteration 12450, lr = 0.0054524
I0814 05:12:36.232519 21738 solver.cpp:337] Iteration 12500, Testing net (#0)
I0814 05:12:44.358687 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:12:44.358748 21738 solver.cpp:404]     Test net output #1: loss = 0.690417 (* 1 = 0.690417 loss)
I0814 05:12:45.934553 21738 solver.cpp:228] Iteration 12500, loss = 0.190518
I0814 05:12:45.934608 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:12:45.934619 21738 solver.cpp:244]     Train net output #1: loss = 0.190518 (* 1 = 0.190518 loss)
I0814 05:12:45.934634 21738 sgd_solver.cpp:106] Iteration 12500, lr = 0.00544331
I0814 05:14:08.346354 21738 solver.cpp:228] Iteration 12550, loss = 0.271275
I0814 05:14:08.346495 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:14:08.346511 21738 solver.cpp:244]     Train net output #1: loss = 0.271275 (* 1 = 0.271275 loss)
I0814 05:14:08.346527 21738 sgd_solver.cpp:106] Iteration 12550, lr = 0.00543426
I0814 05:15:28.804376 21738 solver.cpp:337] Iteration 12600, Testing net (#0)
I0814 05:15:36.763478 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:15:36.763538 21738 solver.cpp:404]     Test net output #1: loss = 0.691902 (* 1 = 0.691902 loss)
I0814 05:15:38.339368 21738 solver.cpp:228] Iteration 12600, loss = 0.190866
I0814 05:15:38.339421 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:15:38.339432 21738 solver.cpp:244]     Train net output #1: loss = 0.190866 (* 1 = 0.190866 loss)
I0814 05:15:38.339448 21738 sgd_solver.cpp:106] Iteration 12600, lr = 0.00542524
I0814 05:17:00.407589 21738 solver.cpp:228] Iteration 12650, loss = 0.271035
I0814 05:17:00.407757 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:17:00.407774 21738 solver.cpp:244]     Train net output #1: loss = 0.271035 (* 1 = 0.271035 loss)
I0814 05:17:00.407789 21738 sgd_solver.cpp:106] Iteration 12650, lr = 0.00541625
I0814 05:18:20.866477 21738 solver.cpp:337] Iteration 12700, Testing net (#0)
I0814 05:18:28.816864 21738 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0814 05:18:28.816926 21738 solver.cpp:404]     Test net output #1: loss = 0.688212 (* 1 = 0.688212 loss)
I0814 05:18:30.392982 21738 solver.cpp:228] Iteration 12700, loss = 0.191086
I0814 05:18:30.393034 21738 solver.cpp:244]     Train net output #0: accuracy = 0.995
I0814 05:18:30.393046 21738 solver.cpp:244]     Train net output #1: loss = 0.191086 (* 1 = 0.191086 loss)
I0814 05:18:30.393060 21738 sgd_solver.cpp:106] Iteration 12700, lr = 0.0054073
I0814 05:19:51.977231 21738 solver.cpp:228] Iteration 12750, loss = 0.27043
I0814 05:19:51.977455 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:19:51.977521 21738 solver.cpp:244]     Train net output #1: loss = 0.27043 (* 1 = 0.27043 loss)
I0814 05:19:51.977548 21738 sgd_solver.cpp:106] Iteration 12750, lr = 0.00539839
I0814 05:21:11.427438 21738 solver.cpp:337] Iteration 12800, Testing net (#0)
I0814 05:21:19.528370 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:21:19.528432 21738 solver.cpp:404]     Test net output #1: loss = 0.693012 (* 1 = 0.693012 loss)
I0814 05:21:21.106608 21738 solver.cpp:228] Iteration 12800, loss = 0.191176
I0814 05:21:21.106662 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:21:21.106674 21738 solver.cpp:244]     Train net output #1: loss = 0.191176 (* 1 = 0.191176 loss)
I0814 05:21:21.106689 21738 sgd_solver.cpp:106] Iteration 12800, lr = 0.0053895
I0814 05:22:42.382531 21738 solver.cpp:228] Iteration 12850, loss = 0.270739
I0814 05:22:42.382673 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:22:42.382686 21738 solver.cpp:244]     Train net output #1: loss = 0.270739 (* 1 = 0.270739 loss)
I0814 05:22:42.382699 21738 sgd_solver.cpp:106] Iteration 12850, lr = 0.00538066
I0814 05:24:00.665632 21738 solver.cpp:337] Iteration 12900, Testing net (#0)
I0814 05:24:08.763139 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:24:08.763200 21738 solver.cpp:404]     Test net output #1: loss = 0.691465 (* 1 = 0.691465 loss)
I0814 05:24:10.338496 21738 solver.cpp:228] Iteration 12900, loss = 0.190774
I0814 05:24:10.338562 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:24:10.338574 21738 solver.cpp:244]     Train net output #1: loss = 0.190774 (* 1 = 0.190774 loss)
I0814 05:24:10.338588 21738 sgd_solver.cpp:106] Iteration 12900, lr = 0.00537184
I0814 05:25:32.797019 21738 solver.cpp:228] Iteration 12950, loss = 0.270451
I0814 05:25:32.797255 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:25:32.797304 21738 solver.cpp:244]     Train net output #1: loss = 0.270451 (* 1 = 0.270451 loss)
I0814 05:25:32.797335 21738 sgd_solver.cpp:106] Iteration 12950, lr = 0.00536306
I0814 05:26:51.122081 21738 solver.cpp:337] Iteration 13000, Testing net (#0)
I0814 05:26:59.199379 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:26:59.199440 21738 solver.cpp:404]     Test net output #1: loss = 0.690539 (* 1 = 0.690539 loss)
I0814 05:27:00.774365 21738 solver.cpp:228] Iteration 13000, loss = 0.190527
I0814 05:27:00.774431 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:27:00.774444 21738 solver.cpp:244]     Train net output #1: loss = 0.190527 (* 1 = 0.190527 loss)
I0814 05:27:00.774461 21738 sgd_solver.cpp:106] Iteration 13000, lr = 0.00535432
I0814 05:28:20.750895 21738 solver.cpp:228] Iteration 13050, loss = 0.270289
I0814 05:28:20.751041 21738 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0814 05:28:20.751056 21738 solver.cpp:244]     Train net output #1: loss = 0.270289 (* 1 = 0.270289 loss)
I0814 05:28:20.751067 21738 sgd_solver.cpp:106] Iteration 13050, lr = 0.0053456
I0814 05:29:41.208166 21738 solver.cpp:337] Iteration 13100, Testing net (#0)
I0814 05:29:49.543607 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:29:49.543673 21738 solver.cpp:404]     Test net output #1: loss = 0.691143 (* 1 = 0.691143 loss)
I0814 05:29:51.242643 21738 solver.cpp:228] Iteration 13100, loss = 0.190715
I0814 05:29:51.242709 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:29:51.242722 21738 solver.cpp:244]     Train net output #1: loss = 0.190715 (* 1 = 0.190715 loss)
I0814 05:29:51.242738 21738 sgd_solver.cpp:106] Iteration 13100, lr = 0.00533692
I0814 05:31:12.439668 21738 solver.cpp:228] Iteration 13150, loss = 0.271456
I0814 05:31:12.439911 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:31:12.439960 21738 solver.cpp:244]     Train net output #1: loss = 0.271456 (* 1 = 0.271456 loss)
I0814 05:31:12.439980 21738 sgd_solver.cpp:106] Iteration 13150, lr = 0.00532828
I0814 05:32:32.563542 21738 solver.cpp:337] Iteration 13200, Testing net (#0)
I0814 05:32:40.610615 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:32:40.610674 21738 solver.cpp:404]     Test net output #1: loss = 0.689274 (* 1 = 0.689274 loss)
I0814 05:32:42.667965 21738 solver.cpp:228] Iteration 13200, loss = 0.190161
I0814 05:32:42.668017 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 05:32:42.668036 21738 solver.cpp:244]     Train net output #1: loss = 0.190161 (* 1 = 0.190161 loss)
I0814 05:32:42.668066 21738 sgd_solver.cpp:106] Iteration 13200, lr = 0.00531966
I0814 05:34:03.602025 21738 solver.cpp:228] Iteration 13250, loss = 0.271145
I0814 05:34:03.602174 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:34:03.602190 21738 solver.cpp:244]     Train net output #1: loss = 0.271145 (* 1 = 0.271145 loss)
I0814 05:34:03.602205 21738 sgd_solver.cpp:106] Iteration 13250, lr = 0.00531108
I0814 05:35:22.039603 21738 solver.cpp:337] Iteration 13300, Testing net (#0)
I0814 05:35:30.649361 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:35:30.649426 21738 solver.cpp:404]     Test net output #1: loss = 0.692171 (* 1 = 0.692171 loss)
I0814 05:35:32.228514 21738 solver.cpp:228] Iteration 13300, loss = 0.190956
I0814 05:35:32.228575 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:35:32.228588 21738 solver.cpp:244]     Train net output #1: loss = 0.190956 (* 1 = 0.190956 loss)
I0814 05:35:32.228605 21738 sgd_solver.cpp:106] Iteration 13300, lr = 0.00530253
I0814 05:36:54.307142 21738 solver.cpp:228] Iteration 13350, loss = 0.271234
I0814 05:36:54.307324 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:36:54.307385 21738 solver.cpp:244]     Train net output #1: loss = 0.271234 (* 1 = 0.271234 loss)
I0814 05:36:54.307420 21738 sgd_solver.cpp:106] Iteration 13350, lr = 0.00529401
I0814 05:38:14.209362 21738 solver.cpp:337] Iteration 13400, Testing net (#0)
I0814 05:38:22.246561 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:38:22.246623 21738 solver.cpp:404]     Test net output #1: loss = 0.690054 (* 1 = 0.690054 loss)
I0814 05:38:23.823232 21738 solver.cpp:228] Iteration 13400, loss = 0.190366
I0814 05:38:23.823295 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:38:23.823309 21738 solver.cpp:244]     Train net output #1: loss = 0.190366 (* 1 = 0.190366 loss)
I0814 05:38:23.823323 21738 sgd_solver.cpp:106] Iteration 13400, lr = 0.00528552
I0814 05:39:46.064016 21738 solver.cpp:228] Iteration 13450, loss = 0.271719
I0814 05:39:46.064167 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:39:46.064182 21738 solver.cpp:244]     Train net output #1: loss = 0.271719 (* 1 = 0.271719 loss)
I0814 05:39:46.064193 21738 sgd_solver.cpp:106] Iteration 13450, lr = 0.00527707
I0814 05:41:08.317076 21738 solver.cpp:337] Iteration 13500, Testing net (#0)
I0814 05:41:16.356640 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 05:41:16.356705 21738 solver.cpp:404]     Test net output #1: loss = 0.688707 (* 1 = 0.688707 loss)
I0814 05:41:18.216147 21738 solver.cpp:228] Iteration 13500, loss = 0.190206
I0814 05:41:18.216212 21738 solver.cpp:244]     Train net output #0: accuracy = 0.945
I0814 05:41:18.216225 21738 solver.cpp:244]     Train net output #1: loss = 0.190206 (* 1 = 0.190206 loss)
I0814 05:41:18.216240 21738 sgd_solver.cpp:106] Iteration 13500, lr = 0.00526865
I0814 05:42:40.782814 21738 solver.cpp:228] Iteration 13550, loss = 0.271056
I0814 05:42:40.783000 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:42:40.783016 21738 solver.cpp:244]     Train net output #1: loss = 0.271056 (* 1 = 0.271056 loss)
I0814 05:42:40.783032 21738 sgd_solver.cpp:106] Iteration 13550, lr = 0.00526026
I0814 05:44:00.457057 21738 solver.cpp:337] Iteration 13600, Testing net (#0)
I0814 05:44:08.611147 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:44:08.611209 21738 solver.cpp:404]     Test net output #1: loss = 0.688891 (* 1 = 0.688891 loss)
I0814 05:44:10.195634 21738 solver.cpp:228] Iteration 13600, loss = 0.190158
I0814 05:44:10.195698 21738 solver.cpp:244]     Train net output #0: accuracy = 0.915
I0814 05:44:10.195710 21738 solver.cpp:244]     Train net output #1: loss = 0.190158 (* 1 = 0.190158 loss)
I0814 05:44:10.195724 21738 sgd_solver.cpp:106] Iteration 13600, lr = 0.00525189
I0814 05:45:31.294682 21738 solver.cpp:228] Iteration 13650, loss = 0.270266
I0814 05:45:31.294903 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:45:31.294972 21738 solver.cpp:244]     Train net output #1: loss = 0.270266 (* 1 = 0.270266 loss)
I0814 05:45:31.295017 21738 sgd_solver.cpp:106] Iteration 13650, lr = 0.00524356
I0814 05:46:53.323438 21738 solver.cpp:337] Iteration 13700, Testing net (#0)
I0814 05:47:01.705037 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:47:01.705097 21738 solver.cpp:404]     Test net output #1: loss = 0.688741 (* 1 = 0.688741 loss)
I0814 05:47:03.426116 21738 solver.cpp:228] Iteration 13700, loss = 0.190114
I0814 05:47:03.426194 21738 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0814 05:47:03.426208 21738 solver.cpp:244]     Train net output #1: loss = 0.190114 (* 1 = 0.190114 loss)
I0814 05:47:03.426224 21738 sgd_solver.cpp:106] Iteration 13700, lr = 0.00523527
I0814 05:48:23.744004 21738 solver.cpp:228] Iteration 13750, loss = 0.270718
I0814 05:48:23.744246 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:48:23.744298 21738 solver.cpp:244]     Train net output #1: loss = 0.270718 (* 1 = 0.270718 loss)
I0814 05:48:23.744338 21738 sgd_solver.cpp:106] Iteration 13750, lr = 0.005227
I0814 05:49:44.782594 21738 solver.cpp:337] Iteration 13800, Testing net (#0)
I0814 05:49:52.716891 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:49:52.716956 21738 solver.cpp:404]     Test net output #1: loss = 0.689518 (* 1 = 0.689518 loss)
I0814 05:49:54.288295 21738 solver.cpp:228] Iteration 13800, loss = 0.190232
I0814 05:49:54.288350 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:49:54.288362 21738 solver.cpp:244]     Train net output #1: loss = 0.190232 (* 1 = 0.190232 loss)
I0814 05:49:54.288378 21738 sgd_solver.cpp:106] Iteration 13800, lr = 0.00521876
I0814 05:51:15.361820 21738 solver.cpp:228] Iteration 13850, loss = 0.270221
I0814 05:51:15.361974 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:51:15.361989 21738 solver.cpp:244]     Train net output #1: loss = 0.270221 (* 1 = 0.270221 loss)
I0814 05:51:15.361999 21738 sgd_solver.cpp:106] Iteration 13850, lr = 0.00521055
I0814 05:52:35.806350 21738 solver.cpp:337] Iteration 13900, Testing net (#0)
I0814 05:52:44.010169 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:52:44.010229 21738 solver.cpp:404]     Test net output #1: loss = 0.691092 (* 1 = 0.691092 loss)
I0814 05:52:45.586971 21738 solver.cpp:228] Iteration 13900, loss = 0.190695
I0814 05:52:45.587023 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:52:45.587035 21738 solver.cpp:244]     Train net output #1: loss = 0.190695 (* 1 = 0.190695 loss)
I0814 05:52:45.587052 21738 sgd_solver.cpp:106] Iteration 13900, lr = 0.00520237
I0814 05:54:06.932842 21738 solver.cpp:228] Iteration 13950, loss = 0.270448
I0814 05:54:06.932989 21738 solver.cpp:244]     Train net output #0: accuracy = 0.975
I0814 05:54:06.933003 21738 solver.cpp:244]     Train net output #1: loss = 0.270448 (* 1 = 0.270448 loss)
I0814 05:54:06.933014 21738 sgd_solver.cpp:106] Iteration 13950, lr = 0.00519423
I0814 05:55:26.686581 21738 solver.cpp:337] Iteration 14000, Testing net (#0)
I0814 05:55:34.650346 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:55:34.650408 21738 solver.cpp:404]     Test net output #1: loss = 0.6913 (* 1 = 0.6913 loss)
I0814 05:55:36.225458 21738 solver.cpp:228] Iteration 14000, loss = 0.190756
I0814 05:55:36.225522 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 05:55:36.225536 21738 solver.cpp:244]     Train net output #1: loss = 0.190756 (* 1 = 0.190756 loss)
I0814 05:55:36.225553 21738 sgd_solver.cpp:106] Iteration 14000, lr = 0.00518611
I0814 05:56:57.526686 21738 solver.cpp:228] Iteration 14050, loss = 0.271028
I0814 05:56:57.526922 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:56:57.526975 21738 solver.cpp:244]     Train net output #1: loss = 0.271027 (* 1 = 0.271027 loss)
I0814 05:56:57.527007 21738 sgd_solver.cpp:106] Iteration 14050, lr = 0.00517802
I0814 05:58:17.984387 21738 solver.cpp:337] Iteration 14100, Testing net (#0)
I0814 05:58:26.129813 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 05:58:26.129878 21738 solver.cpp:404]     Test net output #1: loss = 0.688709 (* 1 = 0.688709 loss)
I0814 05:58:27.704702 21738 solver.cpp:228] Iteration 14100, loss = 0.19015
I0814 05:58:27.704753 21738 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0814 05:58:27.704766 21738 solver.cpp:244]     Train net output #1: loss = 0.19015 (* 1 = 0.19015 loss)
I0814 05:58:27.704779 21738 sgd_solver.cpp:106] Iteration 14100, lr = 0.00516996
I0814 05:59:49.004699 21738 solver.cpp:228] Iteration 14150, loss = 0.270959
I0814 05:59:49.004848 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 05:59:49.004863 21738 solver.cpp:244]     Train net output #1: loss = 0.270959 (* 1 = 0.270959 loss)
I0814 05:59:49.004875 21738 sgd_solver.cpp:106] Iteration 14150, lr = 0.00516193
I0814 06:01:09.310618 21738 solver.cpp:337] Iteration 14200, Testing net (#0)
I0814 06:01:17.378192 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:01:17.378254 21738 solver.cpp:404]     Test net output #1: loss = 0.689768 (* 1 = 0.689768 loss)
I0814 06:01:18.953073 21738 solver.cpp:228] Iteration 14200, loss = 0.190334
I0814 06:01:18.953126 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:01:18.953138 21738 solver.cpp:244]     Train net output #1: loss = 0.190334 (* 1 = 0.190334 loss)
I0814 06:01:18.953153 21738 sgd_solver.cpp:106] Iteration 14200, lr = 0.00515393
I0814 06:02:40.562675 21738 solver.cpp:228] Iteration 14250, loss = 0.270506
I0814 06:02:40.562832 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:02:40.562847 21738 solver.cpp:244]     Train net output #1: loss = 0.270506 (* 1 = 0.270506 loss)
I0814 06:02:40.562863 21738 sgd_solver.cpp:106] Iteration 14250, lr = 0.00514596
I0814 06:04:00.690985 21738 solver.cpp:337] Iteration 14300, Testing net (#0)
I0814 06:04:08.635721 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:04:08.635782 21738 solver.cpp:404]     Test net output #1: loss = 0.690469 (* 1 = 0.690469 loss)
I0814 06:04:10.211081 21738 solver.cpp:228] Iteration 14300, loss = 0.190537
I0814 06:04:10.211139 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:04:10.211151 21738 solver.cpp:244]     Train net output #1: loss = 0.190537 (* 1 = 0.190537 loss)
I0814 06:04:10.211166 21738 sgd_solver.cpp:106] Iteration 14300, lr = 0.00513801
I0814 06:05:32.653617 21738 solver.cpp:228] Iteration 14350, loss = 0.271731
I0814 06:05:32.653771 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 06:05:32.653786 21738 solver.cpp:244]     Train net output #1: loss = 0.27173 (* 1 = 0.27173 loss)
I0814 06:05:32.653800 21738 sgd_solver.cpp:106] Iteration 14350, lr = 0.0051301
I0814 06:06:52.831513 21738 solver.cpp:337] Iteration 14400, Testing net (#0)
I0814 06:07:01.190403 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:07:01.190461 21738 solver.cpp:404]     Test net output #1: loss = 0.688749 (* 1 = 0.688749 loss)
I0814 06:07:02.771142 21738 solver.cpp:228] Iteration 14400, loss = 0.19011
I0814 06:07:02.771217 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 06:07:02.771229 21738 solver.cpp:244]     Train net output #1: loss = 0.19011 (* 1 = 0.19011 loss)
I0814 06:07:02.771244 21738 sgd_solver.cpp:106] Iteration 14400, lr = 0.00512221
I0814 06:08:24.468003 21738 solver.cpp:228] Iteration 14450, loss = 0.270487
I0814 06:08:24.468211 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:08:24.468271 21738 solver.cpp:244]     Train net output #1: loss = 0.270487 (* 1 = 0.270487 loss)
I0814 06:08:24.468317 21738 sgd_solver.cpp:106] Iteration 14450, lr = 0.00511435
I0814 06:09:44.722784 21738 solver.cpp:337] Iteration 14500, Testing net (#0)
I0814 06:09:53.130429 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:09:53.130493 21738 solver.cpp:404]     Test net output #1: loss = 0.692643 (* 1 = 0.692643 loss)
I0814 06:09:54.707685 21738 solver.cpp:228] Iteration 14500, loss = 0.191111
I0814 06:09:54.707736 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:09:54.707748 21738 solver.cpp:244]     Train net output #1: loss = 0.191111 (* 1 = 0.191111 loss)
I0814 06:09:54.707767 21738 sgd_solver.cpp:106] Iteration 14500, lr = 0.00510653
I0814 06:11:15.766360 21738 solver.cpp:228] Iteration 14550, loss = 0.270885
I0814 06:11:15.766516 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:11:15.766532 21738 solver.cpp:244]     Train net output #1: loss = 0.270885 (* 1 = 0.270885 loss)
I0814 06:11:15.766544 21738 sgd_solver.cpp:106] Iteration 14550, lr = 0.00509872
I0814 06:12:35.192231 21738 solver.cpp:337] Iteration 14600, Testing net (#0)
I0814 06:12:43.164580 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:12:43.164640 21738 solver.cpp:404]     Test net output #1: loss = 0.688835 (* 1 = 0.688835 loss)
I0814 06:12:44.740118 21738 solver.cpp:228] Iteration 14600, loss = 0.190131
I0814 06:12:44.740181 21738 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0814 06:12:44.740195 21738 solver.cpp:244]     Train net output #1: loss = 0.190131 (* 1 = 0.190131 loss)
I0814 06:12:44.740211 21738 sgd_solver.cpp:106] Iteration 14600, lr = 0.00509095
I0814 06:14:05.682958 21738 solver.cpp:228] Iteration 14650, loss = 0.271248
I0814 06:14:05.683104 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 06:14:05.683120 21738 solver.cpp:244]     Train net output #1: loss = 0.271248 (* 1 = 0.271248 loss)
I0814 06:14:05.683133 21738 sgd_solver.cpp:106] Iteration 14650, lr = 0.0050832
I0814 06:15:25.750632 21738 solver.cpp:337] Iteration 14700, Testing net (#0)
I0814 06:15:34.015985 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:15:34.016053 21738 solver.cpp:404]     Test net output #1: loss = 0.690712 (* 1 = 0.690712 loss)
I0814 06:15:35.592944 21738 solver.cpp:228] Iteration 14700, loss = 0.190574
I0814 06:15:35.593008 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:15:35.593022 21738 solver.cpp:244]     Train net output #1: loss = 0.190574 (* 1 = 0.190574 loss)
I0814 06:15:35.593037 21738 sgd_solver.cpp:106] Iteration 14700, lr = 0.00507548
I0814 06:16:56.980057 21738 solver.cpp:228] Iteration 14750, loss = 0.271583
I0814 06:16:56.980276 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:16:56.980355 21738 solver.cpp:244]     Train net output #1: loss = 0.271583 (* 1 = 0.271583 loss)
I0814 06:16:56.980403 21738 sgd_solver.cpp:106] Iteration 14750, lr = 0.00506779
I0814 06:18:18.284123 21738 solver.cpp:337] Iteration 14800, Testing net (#0)
I0814 06:18:26.639185 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:18:26.639248 21738 solver.cpp:404]     Test net output #1: loss = 0.694533 (* 1 = 0.694533 loss)
I0814 06:18:28.217447 21738 solver.cpp:228] Iteration 14800, loss = 0.191652
I0814 06:18:28.217516 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:18:28.217528 21738 solver.cpp:244]     Train net output #1: loss = 0.191652 (* 1 = 0.191652 loss)
I0814 06:18:28.217545 21738 sgd_solver.cpp:106] Iteration 14800, lr = 0.00506012
I0814 06:19:48.921702 21738 solver.cpp:228] Iteration 14850, loss = 0.271446
I0814 06:19:48.921957 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 06:19:48.922034 21738 solver.cpp:244]     Train net output #1: loss = 0.271446 (* 1 = 0.271446 loss)
I0814 06:19:48.922082 21738 sgd_solver.cpp:106] Iteration 14850, lr = 0.00505249
I0814 06:21:08.267984 21738 solver.cpp:337] Iteration 14900, Testing net (#0)
I0814 06:21:16.570384 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 06:21:16.570449 21738 solver.cpp:404]     Test net output #1: loss = 0.688644 (* 1 = 0.688644 loss)
I0814 06:21:18.432067 21738 solver.cpp:228] Iteration 14900, loss = 0.190137
I0814 06:21:18.432132 21738 solver.cpp:244]     Train net output #0: accuracy = 0.935
I0814 06:21:18.432145 21738 solver.cpp:244]     Train net output #1: loss = 0.190137 (* 1 = 0.190137 loss)
I0814 06:21:18.432159 21738 sgd_solver.cpp:106] Iteration 14900, lr = 0.00504488
I0814 06:22:40.957330 21738 solver.cpp:228] Iteration 14950, loss = 0.271077
I0814 06:22:40.957496 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:22:40.957512 21738 solver.cpp:244]     Train net output #1: loss = 0.271077 (* 1 = 0.271077 loss)
I0814 06:22:40.957525 21738 sgd_solver.cpp:106] Iteration 14950, lr = 0.00503729
I0814 06:24:01.036047 21738 solver.cpp:337] Iteration 15000, Testing net (#0)
I0814 06:24:09.143085 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:24:09.143146 21738 solver.cpp:404]     Test net output #1: loss = 0.693436 (* 1 = 0.693436 loss)
I0814 06:24:10.720613 21738 solver.cpp:228] Iteration 15000, loss = 0.191328
I0814 06:24:10.720667 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:24:10.720679 21738 solver.cpp:244]     Train net output #1: loss = 0.191328 (* 1 = 0.191328 loss)
I0814 06:24:10.720693 21738 sgd_solver.cpp:106] Iteration 15000, lr = 0.00502973
I0814 06:25:30.316162 21738 solver.cpp:228] Iteration 15050, loss = 0.271313
I0814 06:25:30.316355 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:25:30.316438 21738 solver.cpp:244]     Train net output #1: loss = 0.271313 (* 1 = 0.271313 loss)
I0814 06:25:30.316493 21738 sgd_solver.cpp:106] Iteration 15050, lr = 0.0050222
I0814 06:26:51.600102 21738 solver.cpp:337] Iteration 15100, Testing net (#0)
I0814 06:26:59.671432 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:26:59.671490 21738 solver.cpp:404]     Test net output #1: loss = 0.692056 (* 1 = 0.692056 loss)
I0814 06:27:01.248549 21738 solver.cpp:228] Iteration 15100, loss = 0.190971
I0814 06:27:01.248606 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:27:01.248620 21738 solver.cpp:244]     Train net output #1: loss = 0.190971 (* 1 = 0.190971 loss)
I0814 06:27:01.248633 21738 sgd_solver.cpp:106] Iteration 15100, lr = 0.0050147
I0814 06:28:25.239332 21738 solver.cpp:228] Iteration 15150, loss = 0.270804
I0814 06:28:25.239521 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:28:25.239573 21738 solver.cpp:244]     Train net output #1: loss = 0.270804 (* 1 = 0.270804 loss)
I0814 06:28:25.239599 21738 sgd_solver.cpp:106] Iteration 15150, lr = 0.00500722
I0814 06:29:44.347228 21738 solver.cpp:337] Iteration 15200, Testing net (#0)
I0814 06:29:52.422910 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:29:52.422976 21738 solver.cpp:404]     Test net output #1: loss = 0.689689 (* 1 = 0.689689 loss)
I0814 06:29:54.378455 21738 solver.cpp:228] Iteration 15200, loss = 0.190285
I0814 06:29:54.378518 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:29:54.378533 21738 solver.cpp:244]     Train net output #1: loss = 0.190285 (* 1 = 0.190285 loss)
I0814 06:29:54.378549 21738 sgd_solver.cpp:106] Iteration 15200, lr = 0.00499976
I0814 06:31:15.415344 21738 solver.cpp:228] Iteration 15250, loss = 0.270446
I0814 06:31:15.415612 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:31:15.415660 21738 solver.cpp:244]     Train net output #1: loss = 0.270446 (* 1 = 0.270446 loss)
I0814 06:31:15.415688 21738 sgd_solver.cpp:106] Iteration 15250, lr = 0.00499234
I0814 06:32:36.437156 21738 solver.cpp:337] Iteration 15300, Testing net (#0)
I0814 06:32:44.574136 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:32:44.574196 21738 solver.cpp:404]     Test net output #1: loss = 0.688946 (* 1 = 0.688946 loss)
I0814 06:32:46.149940 21738 solver.cpp:228] Iteration 15300, loss = 0.190114
I0814 06:32:46.150012 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 06:32:46.150025 21738 solver.cpp:244]     Train net output #1: loss = 0.190114 (* 1 = 0.190114 loss)
I0814 06:32:46.150040 21738 sgd_solver.cpp:106] Iteration 15300, lr = 0.00498494
I0814 06:34:07.680497 21738 solver.cpp:228] Iteration 15350, loss = 0.270649
I0814 06:34:07.680728 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:34:07.680795 21738 solver.cpp:244]     Train net output #1: loss = 0.270649 (* 1 = 0.270649 loss)
I0814 06:34:07.680835 21738 sgd_solver.cpp:106] Iteration 15350, lr = 0.00497756
I0814 06:35:30.846146 21738 solver.cpp:337] Iteration 15400, Testing net (#0)
I0814 06:35:39.129106 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:35:39.129171 21738 solver.cpp:404]     Test net output #1: loss = 0.689823 (* 1 = 0.689823 loss)
I0814 06:35:40.704627 21738 solver.cpp:228] Iteration 15400, loss = 0.190346
I0814 06:35:40.704681 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:35:40.704694 21738 solver.cpp:244]     Train net output #1: loss = 0.190346 (* 1 = 0.190346 loss)
I0814 06:35:40.704707 21738 sgd_solver.cpp:106] Iteration 15400, lr = 0.00497021
I0814 06:37:00.993213 21738 solver.cpp:228] Iteration 15450, loss = 0.271013
I0814 06:37:00.993367 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:37:00.993381 21738 solver.cpp:244]     Train net output #1: loss = 0.271013 (* 1 = 0.271013 loss)
I0814 06:37:00.993392 21738 sgd_solver.cpp:106] Iteration 15450, lr = 0.00496288
I0814 06:38:22.247020 21738 solver.cpp:337] Iteration 15500, Testing net (#0)
I0814 06:38:30.396576 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:38:30.396642 21738 solver.cpp:404]     Test net output #1: loss = 0.691548 (* 1 = 0.691548 loss)
I0814 06:38:32.362442 21738 solver.cpp:228] Iteration 15500, loss = 0.190844
I0814 06:38:32.362507 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:38:32.362521 21738 solver.cpp:244]     Train net output #1: loss = 0.190844 (* 1 = 0.190844 loss)
I0814 06:38:32.362536 21738 sgd_solver.cpp:106] Iteration 15500, lr = 0.00495558
I0814 06:39:52.759416 21738 solver.cpp:228] Iteration 15550, loss = 0.27023
I0814 06:39:52.759574 21738 solver.cpp:244]     Train net output #0: accuracy = 0.87
I0814 06:39:52.759588 21738 solver.cpp:244]     Train net output #1: loss = 0.27023 (* 1 = 0.27023 loss)
I0814 06:39:52.759599 21738 sgd_solver.cpp:106] Iteration 15550, lr = 0.00494831
I0814 06:41:11.620156 21738 solver.cpp:337] Iteration 15600, Testing net (#0)
I0814 06:41:19.547729 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:41:19.547793 21738 solver.cpp:404]     Test net output #1: loss = 0.692149 (* 1 = 0.692149 loss)
I0814 06:41:21.122130 21738 solver.cpp:228] Iteration 15600, loss = 0.190983
I0814 06:41:21.122180 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:41:21.122192 21738 solver.cpp:244]     Train net output #1: loss = 0.190983 (* 1 = 0.190983 loss)
I0814 06:41:21.122210 21738 sgd_solver.cpp:106] Iteration 15600, lr = 0.00494106
I0814 06:42:42.150910 21738 solver.cpp:228] Iteration 15650, loss = 0.270673
I0814 06:42:42.151129 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:42:42.151181 21738 solver.cpp:244]     Train net output #1: loss = 0.270673 (* 1 = 0.270673 loss)
I0814 06:42:42.151201 21738 sgd_solver.cpp:106] Iteration 15650, lr = 0.00493383
I0814 06:44:03.152413 21738 solver.cpp:337] Iteration 15700, Testing net (#0)
I0814 06:44:11.286312 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:44:11.286375 21738 solver.cpp:404]     Test net output #1: loss = 0.690147 (* 1 = 0.690147 loss)
I0814 06:44:12.860050 21738 solver.cpp:228] Iteration 15700, loss = 0.190435
I0814 06:44:12.860103 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:44:12.860116 21738 solver.cpp:244]     Train net output #1: loss = 0.190435 (* 1 = 0.190435 loss)
I0814 06:44:12.860129 21738 sgd_solver.cpp:106] Iteration 15700, lr = 0.00492663
I0814 06:45:32.374902 21738 solver.cpp:228] Iteration 15750, loss = 0.271204
I0814 06:45:32.375129 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:45:32.375192 21738 solver.cpp:244]     Train net output #1: loss = 0.271204 (* 1 = 0.271204 loss)
I0814 06:45:32.375224 21738 sgd_solver.cpp:106] Iteration 15750, lr = 0.00491946
I0814 06:46:51.741180 21738 solver.cpp:337] Iteration 15800, Testing net (#0)
I0814 06:47:00.259410 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:47:00.259475 21738 solver.cpp:404]     Test net output #1: loss = 0.688684 (* 1 = 0.688684 loss)
I0814 06:47:01.835382 21738 solver.cpp:228] Iteration 15800, loss = 0.190118
I0814 06:47:01.835438 21738 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0814 06:47:01.835450 21738 solver.cpp:244]     Train net output #1: loss = 0.190118 (* 1 = 0.190118 loss)
I0814 06:47:01.835469 21738 sgd_solver.cpp:106] Iteration 15800, lr = 0.0049123
I0814 06:48:22.132314 21738 solver.cpp:228] Iteration 15850, loss = 0.270662
I0814 06:48:22.132462 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:48:22.132477 21738 solver.cpp:244]     Train net output #1: loss = 0.270662 (* 1 = 0.270662 loss)
I0814 06:48:22.132488 21738 sgd_solver.cpp:106] Iteration 15850, lr = 0.00490518
I0814 06:49:42.181375 21738 solver.cpp:337] Iteration 15900, Testing net (#0)
I0814 06:49:50.435039 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:49:50.435103 21738 solver.cpp:404]     Test net output #1: loss = 0.690974 (* 1 = 0.690974 loss)
I0814 06:49:52.098014 21738 solver.cpp:228] Iteration 15900, loss = 0.190691
I0814 06:49:52.098080 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:49:52.098095 21738 solver.cpp:244]     Train net output #1: loss = 0.190691 (* 1 = 0.190691 loss)
I0814 06:49:52.098111 21738 sgd_solver.cpp:106] Iteration 15900, lr = 0.00489807
I0814 06:51:14.708961 21738 solver.cpp:228] Iteration 15950, loss = 0.270728
I0814 06:51:14.709144 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:51:14.709218 21738 solver.cpp:244]     Train net output #1: loss = 0.270728 (* 1 = 0.270728 loss)
I0814 06:51:14.709261 21738 sgd_solver.cpp:106] Iteration 15950, lr = 0.00489099
I0814 06:52:34.789293 21738 solver.cpp:337] Iteration 16000, Testing net (#0)
I0814 06:52:43.268769 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:52:43.268831 21738 solver.cpp:404]     Test net output #1: loss = 0.69088 (* 1 = 0.69088 loss)
I0814 06:52:44.843852 21738 solver.cpp:228] Iteration 16000, loss = 0.190668
I0814 06:52:44.843915 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:52:44.843927 21738 solver.cpp:244]     Train net output #1: loss = 0.190667 (* 1 = 0.190667 loss)
I0814 06:52:44.843942 21738 sgd_solver.cpp:106] Iteration 16000, lr = 0.00488394
I0814 06:54:07.320724 21738 solver.cpp:228] Iteration 16050, loss = 0.270167
I0814 06:54:07.320881 21738 solver.cpp:244]     Train net output #0: accuracy = 0.925
I0814 06:54:07.320896 21738 solver.cpp:244]     Train net output #1: loss = 0.270167 (* 1 = 0.270167 loss)
I0814 06:54:07.320911 21738 sgd_solver.cpp:106] Iteration 16050, lr = 0.0048769
I0814 06:55:26.501871 21738 solver.cpp:337] Iteration 16100, Testing net (#0)
I0814 06:55:34.446629 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:55:34.446688 21738 solver.cpp:404]     Test net output #1: loss = 0.688846 (* 1 = 0.688846 loss)
I0814 06:55:36.147864 21738 solver.cpp:228] Iteration 16100, loss = 0.190085
I0814 06:55:36.147920 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 06:55:36.147933 21738 solver.cpp:244]     Train net output #1: loss = 0.190085 (* 1 = 0.190085 loss)
I0814 06:55:36.147948 21738 sgd_solver.cpp:106] Iteration 16100, lr = 0.0048699
I0814 06:56:56.551445 21738 solver.cpp:228] Iteration 16150, loss = 0.271661
I0814 06:56:56.551596 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:56:56.551610 21738 solver.cpp:244]     Train net output #1: loss = 0.271661 (* 1 = 0.271661 loss)
I0814 06:56:56.551625 21738 sgd_solver.cpp:106] Iteration 16150, lr = 0.00486291
I0814 06:58:15.310848 21738 solver.cpp:337] Iteration 16200, Testing net (#0)
I0814 06:58:23.469219 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 06:58:23.469293 21738 solver.cpp:404]     Test net output #1: loss = 0.689186 (* 1 = 0.689186 loss)
I0814 06:58:25.043273 21738 solver.cpp:228] Iteration 16200, loss = 0.190185
I0814 06:58:25.043324 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 06:58:25.043335 21738 solver.cpp:244]     Train net output #1: loss = 0.190185 (* 1 = 0.190185 loss)
I0814 06:58:25.043354 21738 sgd_solver.cpp:106] Iteration 16200, lr = 0.00485595
I0814 06:59:47.502415 21738 solver.cpp:228] Iteration 16250, loss = 0.271498
I0814 06:59:47.502563 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 06:59:47.502580 21738 solver.cpp:244]     Train net output #1: loss = 0.271498 (* 1 = 0.271498 loss)
I0814 06:59:47.502595 21738 sgd_solver.cpp:106] Iteration 16250, lr = 0.00484901
I0814 07:01:07.401269 21738 solver.cpp:337] Iteration 16300, Testing net (#0)
I0814 07:01:15.686182 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:01:15.686245 21738 solver.cpp:404]     Test net output #1: loss = 0.689625 (* 1 = 0.689625 loss)
I0814 07:01:17.531318 21738 solver.cpp:228] Iteration 16300, loss = 0.190308
I0814 07:01:17.531386 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:01:17.531399 21738 solver.cpp:244]     Train net output #1: loss = 0.190308 (* 1 = 0.190308 loss)
I0814 07:01:17.531414 21738 sgd_solver.cpp:106] Iteration 16300, lr = 0.00484209
I0814 07:02:41.427356 21738 solver.cpp:228] Iteration 16350, loss = 0.271702
I0814 07:02:41.427561 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 07:02:41.427619 21738 solver.cpp:244]     Train net output #1: loss = 0.271702 (* 1 = 0.271702 loss)
I0814 07:02:41.427654 21738 sgd_solver.cpp:106] Iteration 16350, lr = 0.0048352
I0814 07:04:01.514009 21738 solver.cpp:337] Iteration 16400, Testing net (#0)
I0814 07:04:09.457460 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:04:09.457532 21738 solver.cpp:404]     Test net output #1: loss = 0.693423 (* 1 = 0.693423 loss)
I0814 07:04:11.036273 21738 solver.cpp:228] Iteration 16400, loss = 0.19133
I0814 07:04:11.036334 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:04:11.036347 21738 solver.cpp:244]     Train net output #1: loss = 0.19133 (* 1 = 0.19133 loss)
I0814 07:04:11.036361 21738 sgd_solver.cpp:106] Iteration 16400, lr = 0.00482833
I0814 07:05:33.879250 21738 solver.cpp:228] Iteration 16450, loss = 0.270128
I0814 07:05:33.879485 21738 solver.cpp:244]     Train net output #0: accuracy = 0.87
I0814 07:05:33.879536 21738 solver.cpp:244]     Train net output #1: loss = 0.270128 (* 1 = 0.270128 loss)
I0814 07:05:33.879575 21738 sgd_solver.cpp:106] Iteration 16450, lr = 0.00482148
I0814 07:06:54.212390 21738 solver.cpp:337] Iteration 16500, Testing net (#0)
I0814 07:07:02.606369 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:07:02.606429 21738 solver.cpp:404]     Test net output #1: loss = 0.691894 (* 1 = 0.691894 loss)
I0814 07:07:04.181918 21738 solver.cpp:228] Iteration 16500, loss = 0.190952
I0814 07:07:04.181983 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:07:04.181995 21738 solver.cpp:244]     Train net output #1: loss = 0.190952 (* 1 = 0.190952 loss)
I0814 07:07:04.182010 21738 sgd_solver.cpp:106] Iteration 16500, lr = 0.00481466
I0814 07:08:25.710072 21738 solver.cpp:228] Iteration 16550, loss = 0.273517
I0814 07:08:25.710319 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:08:25.710371 21738 solver.cpp:244]     Train net output #1: loss = 0.273517 (* 1 = 0.273517 loss)
I0814 07:08:25.710392 21738 sgd_solver.cpp:106] Iteration 16550, lr = 0.00480786
I0814 07:09:47.896654 21738 solver.cpp:337] Iteration 16600, Testing net (#0)
I0814 07:09:55.985862 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:09:55.985925 21738 solver.cpp:404]     Test net output #1: loss = 0.688843 (* 1 = 0.688843 loss)
I0814 07:09:57.561887 21738 solver.cpp:228] Iteration 16600, loss = 0.190122
I0814 07:09:57.561947 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 07:09:57.561961 21738 solver.cpp:244]     Train net output #1: loss = 0.190122 (* 1 = 0.190122 loss)
I0814 07:09:57.561976 21738 sgd_solver.cpp:106] Iteration 16600, lr = 0.00480108
I0814 07:11:18.197793 21738 solver.cpp:228] Iteration 16650, loss = 0.270257
I0814 07:11:18.198020 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:11:18.198077 21738 solver.cpp:244]     Train net output #1: loss = 0.270256 (* 1 = 0.270256 loss)
I0814 07:11:18.198109 21738 sgd_solver.cpp:106] Iteration 16650, lr = 0.00479432
I0814 07:12:38.038147 21738 solver.cpp:337] Iteration 16700, Testing net (#0)
I0814 07:12:46.172426 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:12:46.172488 21738 solver.cpp:404]     Test net output #1: loss = 0.690743 (* 1 = 0.690743 loss)
I0814 07:12:47.748307 21738 solver.cpp:228] Iteration 16700, loss = 0.190618
I0814 07:12:47.748370 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:12:47.748383 21738 solver.cpp:244]     Train net output #1: loss = 0.190617 (* 1 = 0.190617 loss)
I0814 07:12:47.748397 21738 sgd_solver.cpp:106] Iteration 16700, lr = 0.00478759
I0814 07:14:08.647240 21738 solver.cpp:228] Iteration 16750, loss = 0.271911
I0814 07:14:08.647452 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:14:08.647507 21738 solver.cpp:244]     Train net output #1: loss = 0.27191 (* 1 = 0.27191 loss)
I0814 07:14:08.647537 21738 sgd_solver.cpp:106] Iteration 16750, lr = 0.00478087
I0814 07:15:28.206933 21738 solver.cpp:337] Iteration 16800, Testing net (#0)
I0814 07:15:36.456444 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:15:36.456506 21738 solver.cpp:404]     Test net output #1: loss = 0.69034 (* 1 = 0.69034 loss)
I0814 07:15:38.319494 21738 solver.cpp:228] Iteration 16800, loss = 0.190519
I0814 07:15:38.319558 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:15:38.319571 21738 solver.cpp:244]     Train net output #1: loss = 0.190519 (* 1 = 0.190519 loss)
I0814 07:15:38.319587 21738 sgd_solver.cpp:106] Iteration 16800, lr = 0.00477418
I0814 07:17:00.954380 21738 solver.cpp:228] Iteration 16850, loss = 0.270928
I0814 07:17:00.954531 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:17:00.954547 21738 solver.cpp:244]     Train net output #1: loss = 0.270928 (* 1 = 0.270928 loss)
I0814 07:17:00.954561 21738 sgd_solver.cpp:106] Iteration 16850, lr = 0.00476751
I0814 07:18:20.977656 21738 solver.cpp:337] Iteration 16900, Testing net (#0)
I0814 07:18:29.438920 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:18:29.438987 21738 solver.cpp:404]     Test net output #1: loss = 0.690973 (* 1 = 0.690973 loss)
I0814 07:18:31.017341 21738 solver.cpp:228] Iteration 16900, loss = 0.190688
I0814 07:18:31.017406 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:18:31.017418 21738 solver.cpp:244]     Train net output #1: loss = 0.190688 (* 1 = 0.190688 loss)
I0814 07:18:31.017437 21738 sgd_solver.cpp:106] Iteration 16900, lr = 0.00476086
I0814 07:19:54.650997 21738 solver.cpp:228] Iteration 16950, loss = 0.270613
I0814 07:19:54.651183 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:19:54.651198 21738 solver.cpp:244]     Train net output #1: loss = 0.270613 (* 1 = 0.270613 loss)
I0814 07:19:54.651211 21738 sgd_solver.cpp:106] Iteration 16950, lr = 0.00475424
I0814 07:21:14.723464 21738 solver.cpp:337] Iteration 17000, Testing net (#0)
I0814 07:21:22.925093 21738 solver.cpp:404]     Test net output #0: accuracy = 0.737
I0814 07:21:22.925154 21738 solver.cpp:404]     Test net output #1: loss = 0.688151 (* 1 = 0.688151 loss)
I0814 07:21:24.502202 21738 solver.cpp:228] Iteration 17000, loss = 0.190835
I0814 07:21:24.502276 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 07:21:24.502291 21738 solver.cpp:244]     Train net output #1: loss = 0.190835 (* 1 = 0.190835 loss)
I0814 07:21:24.502307 21738 sgd_solver.cpp:106] Iteration 17000, lr = 0.00474763
I0814 07:22:47.204809 21738 solver.cpp:228] Iteration 17050, loss = 0.270244
I0814 07:22:47.205008 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:22:47.205059 21738 solver.cpp:244]     Train net output #1: loss = 0.270244 (* 1 = 0.270244 loss)
I0814 07:22:47.205090 21738 sgd_solver.cpp:106] Iteration 17050, lr = 0.00474105
I0814 07:24:09.344389 21738 solver.cpp:337] Iteration 17100, Testing net (#0)
I0814 07:24:17.389382 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:24:17.389447 21738 solver.cpp:404]     Test net output #1: loss = 0.691296 (* 1 = 0.691296 loss)
I0814 07:24:18.967322 21738 solver.cpp:228] Iteration 17100, loss = 0.190768
I0814 07:24:18.967388 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:24:18.967401 21738 solver.cpp:244]     Train net output #1: loss = 0.190768 (* 1 = 0.190768 loss)
I0814 07:24:18.967416 21738 sgd_solver.cpp:106] Iteration 17100, lr = 0.00473449
I0814 07:25:41.292171 21738 solver.cpp:228] Iteration 17150, loss = 0.270802
I0814 07:25:41.292309 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:25:41.292323 21738 solver.cpp:244]     Train net output #1: loss = 0.270802 (* 1 = 0.270802 loss)
I0814 07:25:41.292348 21738 sgd_solver.cpp:106] Iteration 17150, lr = 0.00472795
I0814 07:27:01.882068 21738 solver.cpp:337] Iteration 17200, Testing net (#0)
I0814 07:27:10.182451 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:27:10.182524 21738 solver.cpp:404]     Test net output #1: loss = 0.692913 (* 1 = 0.692913 loss)
I0814 07:27:11.776703 21738 solver.cpp:228] Iteration 17200, loss = 0.191201
I0814 07:27:11.776756 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:27:11.776767 21738 solver.cpp:244]     Train net output #1: loss = 0.1912 (* 1 = 0.1912 loss)
I0814 07:27:11.776784 21738 sgd_solver.cpp:106] Iteration 17200, lr = 0.00472143
I0814 07:28:34.842938 21738 solver.cpp:228] Iteration 17250, loss = 0.270342
I0814 07:28:34.843189 21738 solver.cpp:244]     Train net output #0: accuracy = 0.945
I0814 07:28:34.843246 21738 solver.cpp:244]     Train net output #1: loss = 0.270342 (* 1 = 0.270342 loss)
I0814 07:28:34.843286 21738 sgd_solver.cpp:106] Iteration 17250, lr = 0.00471493
I0814 07:29:56.823596 21738 solver.cpp:337] Iteration 17300, Testing net (#0)
I0814 07:30:04.936547 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:30:04.936611 21738 solver.cpp:404]     Test net output #1: loss = 0.69101 (* 1 = 0.69101 loss)
I0814 07:30:06.513062 21738 solver.cpp:228] Iteration 17300, loss = 0.190692
I0814 07:30:06.513128 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:30:06.513142 21738 solver.cpp:244]     Train net output #1: loss = 0.190692 (* 1 = 0.190692 loss)
I0814 07:30:06.513157 21738 sgd_solver.cpp:106] Iteration 17300, lr = 0.00470845
I0814 07:31:27.488337 21738 solver.cpp:228] Iteration 17350, loss = 0.270976
I0814 07:31:27.488575 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:31:27.488648 21738 solver.cpp:244]     Train net output #1: loss = 0.270976 (* 1 = 0.270976 loss)
I0814 07:31:27.488704 21738 sgd_solver.cpp:106] Iteration 17350, lr = 0.00470199
I0814 07:32:47.018102 21738 solver.cpp:337] Iteration 17400, Testing net (#0)
I0814 07:32:54.935840 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:32:54.935902 21738 solver.cpp:404]     Test net output #1: loss = 0.692514 (* 1 = 0.692514 loss)
I0814 07:32:56.515050 21738 solver.cpp:228] Iteration 17400, loss = 0.191103
I0814 07:32:56.515110 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:32:56.515122 21738 solver.cpp:244]     Train net output #1: loss = 0.191103 (* 1 = 0.191103 loss)
I0814 07:32:56.515136 21738 sgd_solver.cpp:106] Iteration 17400, lr = 0.00469556
I0814 07:34:18.054764 21738 solver.cpp:228] Iteration 17450, loss = 0.2702
I0814 07:34:18.054929 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:34:18.054946 21738 solver.cpp:244]     Train net output #1: loss = 0.2702 (* 1 = 0.2702 loss)
I0814 07:34:18.054960 21738 sgd_solver.cpp:106] Iteration 17450, lr = 0.00468914
I0814 07:35:40.078655 21738 solver.cpp:337] Iteration 17500, Testing net (#0)
I0814 07:35:48.181910 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:35:48.181972 21738 solver.cpp:404]     Test net output #1: loss = 0.689223 (* 1 = 0.689223 loss)
I0814 07:35:49.756777 21738 solver.cpp:228] Iteration 17500, loss = 0.190186
I0814 07:35:49.756845 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:35:49.756860 21738 solver.cpp:244]     Train net output #1: loss = 0.190186 (* 1 = 0.190186 loss)
I0814 07:35:49.756875 21738 sgd_solver.cpp:106] Iteration 17500, lr = 0.00468274
I0814 07:37:14.106093 21738 solver.cpp:228] Iteration 17550, loss = 0.270924
I0814 07:37:14.106330 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:37:14.106389 21738 solver.cpp:244]     Train net output #1: loss = 0.270924 (* 1 = 0.270924 loss)
I0814 07:37:14.106420 21738 sgd_solver.cpp:106] Iteration 17550, lr = 0.00467637
I0814 07:38:34.180516 21738 solver.cpp:337] Iteration 17600, Testing net (#0)
I0814 07:38:42.224623 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:38:42.224686 21738 solver.cpp:404]     Test net output #1: loss = 0.689289 (* 1 = 0.689289 loss)
I0814 07:38:43.805286 21738 solver.cpp:228] Iteration 17600, loss = 0.19022
I0814 07:38:43.805352 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:38:43.805364 21738 solver.cpp:244]     Train net output #1: loss = 0.190219 (* 1 = 0.190219 loss)
I0814 07:38:43.805379 21738 sgd_solver.cpp:106] Iteration 17600, lr = 0.00467001
I0814 07:40:06.157670 21738 solver.cpp:228] Iteration 17650, loss = 0.270313
I0814 07:40:06.157879 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:40:06.157932 21738 solver.cpp:244]     Train net output #1: loss = 0.270313 (* 1 = 0.270313 loss)
I0814 07:40:06.157971 21738 sgd_solver.cpp:106] Iteration 17650, lr = 0.00466368
I0814 07:41:26.611590 21738 solver.cpp:337] Iteration 17700, Testing net (#0)
I0814 07:41:35.123558 21738 solver.cpp:404]     Test net output #0: accuracy = 0.993
I0814 07:41:35.123644 21738 solver.cpp:404]     Test net output #1: loss = 0.688344 (* 1 = 0.688344 loss)
I0814 07:41:36.697468 21738 solver.cpp:228] Iteration 17700, loss = 0.191905
I0814 07:41:36.697517 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 07:41:36.697530 21738 solver.cpp:244]     Train net output #1: loss = 0.191905 (* 1 = 0.191905 loss)
I0814 07:41:36.697545 21738 sgd_solver.cpp:106] Iteration 17700, lr = 0.00465736
I0814 07:42:58.495244 21738 solver.cpp:228] Iteration 17750, loss = 0.270619
I0814 07:42:58.495456 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:42:58.495522 21738 solver.cpp:244]     Train net output #1: loss = 0.270619 (* 1 = 0.270619 loss)
I0814 07:42:58.495564 21738 sgd_solver.cpp:106] Iteration 17750, lr = 0.00465107
I0814 07:44:18.872846 21738 solver.cpp:337] Iteration 17800, Testing net (#0)
I0814 07:44:27.051081 21738 solver.cpp:404]     Test net output #0: accuracy = 0.981
I0814 07:44:27.051148 21738 solver.cpp:404]     Test net output #1: loss = 0.688298 (* 1 = 0.688298 loss)
I0814 07:44:28.627951 21738 solver.cpp:228] Iteration 17800, loss = 0.191764
I0814 07:44:28.628008 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 07:44:28.628020 21738 solver.cpp:244]     Train net output #1: loss = 0.191764 (* 1 = 0.191764 loss)
I0814 07:44:28.628078 21738 sgd_solver.cpp:106] Iteration 17800, lr = 0.00464479
I0814 07:45:50.013711 21738 solver.cpp:228] Iteration 17850, loss = 0.272206
I0814 07:45:50.013908 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 07:45:50.013962 21738 solver.cpp:244]     Train net output #1: loss = 0.272206 (* 1 = 0.272206 loss)
I0814 07:45:50.013985 21738 sgd_solver.cpp:106] Iteration 17850, lr = 0.00463854
I0814 07:47:10.042932 21738 solver.cpp:337] Iteration 17900, Testing net (#0)
I0814 07:47:18.159829 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:47:18.159893 21738 solver.cpp:404]     Test net output #1: loss = 0.691169 (* 1 = 0.691169 loss)
I0814 07:47:19.753118 21738 solver.cpp:228] Iteration 17900, loss = 0.190733
I0814 07:47:19.753177 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:47:19.753190 21738 solver.cpp:244]     Train net output #1: loss = 0.190733 (* 1 = 0.190733 loss)
I0814 07:47:19.753206 21738 sgd_solver.cpp:106] Iteration 17900, lr = 0.0046323
I0814 07:48:40.524652 21738 solver.cpp:228] Iteration 17950, loss = 0.27119
I0814 07:48:40.524798 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:48:40.524812 21738 solver.cpp:244]     Train net output #1: loss = 0.27119 (* 1 = 0.27119 loss)
I0814 07:48:40.524837 21738 sgd_solver.cpp:106] Iteration 17950, lr = 0.00462609
I0814 07:50:01.563678 21738 solver.cpp:337] Iteration 18000, Testing net (#0)
I0814 07:50:10.030804 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:50:10.030872 21738 solver.cpp:404]     Test net output #1: loss = 0.691026 (* 1 = 0.691026 loss)
I0814 07:50:11.636559 21738 solver.cpp:228] Iteration 18000, loss = 0.190678
I0814 07:50:11.636620 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:50:11.636632 21738 solver.cpp:244]     Train net output #1: loss = 0.190678 (* 1 = 0.190678 loss)
I0814 07:50:11.636647 21738 sgd_solver.cpp:106] Iteration 18000, lr = 0.00461989
I0814 07:51:32.737195 21738 solver.cpp:228] Iteration 18050, loss = 0.271548
I0814 07:51:32.737346 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:51:32.737363 21738 solver.cpp:244]     Train net output #1: loss = 0.271548 (* 1 = 0.271548 loss)
I0814 07:51:32.737377 21738 sgd_solver.cpp:106] Iteration 18050, lr = 0.00461371
I0814 07:52:54.133536 21738 solver.cpp:337] Iteration 18100, Testing net (#0)
I0814 07:53:02.326966 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:53:02.327031 21738 solver.cpp:404]     Test net output #1: loss = 0.691489 (* 1 = 0.691489 loss)
I0814 07:53:03.902626 21738 solver.cpp:228] Iteration 18100, loss = 0.1908
I0814 07:53:03.902693 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:53:03.902707 21738 solver.cpp:244]     Train net output #1: loss = 0.1908 (* 1 = 0.1908 loss)
I0814 07:53:03.902722 21738 sgd_solver.cpp:106] Iteration 18100, lr = 0.00460755
I0814 07:54:25.770506 21738 solver.cpp:228] Iteration 18150, loss = 0.271146
I0814 07:54:25.770649 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:54:25.770665 21738 solver.cpp:244]     Train net output #1: loss = 0.271146 (* 1 = 0.271146 loss)
I0814 07:54:25.770680 21738 sgd_solver.cpp:106] Iteration 18150, lr = 0.00460141
I0814 07:55:45.725754 21738 solver.cpp:337] Iteration 18200, Testing net (#0)
I0814 07:55:53.883309 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:55:53.883379 21738 solver.cpp:404]     Test net output #1: loss = 0.690283 (* 1 = 0.690283 loss)
I0814 07:55:55.516623 21738 solver.cpp:228] Iteration 18200, loss = 0.190501
I0814 07:55:55.516686 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:55:55.516701 21738 solver.cpp:244]     Train net output #1: loss = 0.190501 (* 1 = 0.190501 loss)
I0814 07:55:55.516716 21738 sgd_solver.cpp:106] Iteration 18200, lr = 0.00459529
I0814 07:57:15.626912 21738 solver.cpp:228] Iteration 18250, loss = 0.271109
I0814 07:57:15.627095 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 07:57:15.627148 21738 solver.cpp:244]     Train net output #1: loss = 0.271109 (* 1 = 0.271109 loss)
I0814 07:57:15.627177 21738 sgd_solver.cpp:106] Iteration 18250, lr = 0.00458919
I0814 07:58:36.941330 21738 solver.cpp:337] Iteration 18300, Testing net (#0)
I0814 07:58:45.019199 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 07:58:45.019263 21738 solver.cpp:404]     Test net output #1: loss = 0.690862 (* 1 = 0.690862 loss)
I0814 07:58:46.595688 21738 solver.cpp:228] Iteration 18300, loss = 0.190636
I0814 07:58:46.595757 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 07:58:46.595770 21738 solver.cpp:244]     Train net output #1: loss = 0.190636 (* 1 = 0.190636 loss)
I0814 07:58:46.595785 21738 sgd_solver.cpp:106] Iteration 18300, lr = 0.00458311
I0814 08:00:07.905930 21738 solver.cpp:228] Iteration 18350, loss = 0.27125
I0814 08:00:07.906076 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:00:07.906093 21738 solver.cpp:244]     Train net output #1: loss = 0.27125 (* 1 = 0.27125 loss)
I0814 08:00:07.906105 21738 sgd_solver.cpp:106] Iteration 18350, lr = 0.00457704
I0814 08:01:28.707517 21738 solver.cpp:337] Iteration 18400, Testing net (#0)
I0814 08:01:36.814044 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:01:36.814111 21738 solver.cpp:404]     Test net output #1: loss = 0.689965 (* 1 = 0.689965 loss)
I0814 08:01:38.390404 21738 solver.cpp:228] Iteration 18400, loss = 0.190407
I0814 08:01:38.390461 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:01:38.390473 21738 solver.cpp:244]     Train net output #1: loss = 0.190407 (* 1 = 0.190407 loss)
I0814 08:01:38.390488 21738 sgd_solver.cpp:106] Iteration 18400, lr = 0.004571
I0814 08:03:00.821635 21738 solver.cpp:228] Iteration 18450, loss = 0.271567
I0814 08:03:00.821784 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:03:00.821799 21738 solver.cpp:244]     Train net output #1: loss = 0.271567 (* 1 = 0.271567 loss)
I0814 08:03:00.821811 21738 sgd_solver.cpp:106] Iteration 18450, lr = 0.00456497
I0814 08:04:19.794569 21738 solver.cpp:337] Iteration 18500, Testing net (#0)
I0814 08:04:27.839812 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:04:27.839884 21738 solver.cpp:404]     Test net output #1: loss = 0.691488 (* 1 = 0.691488 loss)
I0814 08:04:29.414626 21738 solver.cpp:228] Iteration 18500, loss = 0.190831
I0814 08:04:29.414680 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:04:29.414692 21738 solver.cpp:244]     Train net output #1: loss = 0.190831 (* 1 = 0.190831 loss)
I0814 08:04:29.414707 21738 sgd_solver.cpp:106] Iteration 18500, lr = 0.00455897
I0814 08:05:50.352924 21738 solver.cpp:228] Iteration 18550, loss = 0.27046
I0814 08:05:50.353145 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:05:50.353204 21738 solver.cpp:244]     Train net output #1: loss = 0.270459 (* 1 = 0.270459 loss)
I0814 08:05:50.353236 21738 sgd_solver.cpp:106] Iteration 18550, lr = 0.00455298
I0814 08:07:10.668620 21738 solver.cpp:337] Iteration 18600, Testing net (#0)
I0814 08:07:19.006602 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:07:19.006675 21738 solver.cpp:404]     Test net output #1: loss = 0.689837 (* 1 = 0.689837 loss)
I0814 08:07:20.653955 21738 solver.cpp:228] Iteration 18600, loss = 0.190381
I0814 08:07:20.654018 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:07:20.654031 21738 solver.cpp:244]     Train net output #1: loss = 0.19038 (* 1 = 0.19038 loss)
I0814 08:07:20.654049 21738 sgd_solver.cpp:106] Iteration 18600, lr = 0.00454701
I0814 08:08:42.667829 21738 solver.cpp:228] Iteration 18650, loss = 0.270798
I0814 08:08:42.668120 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:08:42.668179 21738 solver.cpp:244]     Train net output #1: loss = 0.270798 (* 1 = 0.270798 loss)
I0814 08:08:42.668207 21738 sgd_solver.cpp:106] Iteration 18650, lr = 0.00454105
I0814 08:10:02.070539 21738 solver.cpp:337] Iteration 18700, Testing net (#0)
I0814 08:10:10.170512 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:10:10.170590 21738 solver.cpp:404]     Test net output #1: loss = 0.689255 (* 1 = 0.689255 loss)
I0814 08:10:11.747550 21738 solver.cpp:228] Iteration 18700, loss = 0.190195
I0814 08:10:11.747601 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:10:11.747612 21738 solver.cpp:244]     Train net output #1: loss = 0.190195 (* 1 = 0.190195 loss)
I0814 08:10:11.747629 21738 sgd_solver.cpp:106] Iteration 18700, lr = 0.00453512
I0814 08:11:35.946302 21738 solver.cpp:228] Iteration 18750, loss = 0.271047
I0814 08:11:35.946514 21738 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0814 08:11:35.946571 21738 solver.cpp:244]     Train net output #1: loss = 0.271047 (* 1 = 0.271047 loss)
I0814 08:11:35.946601 21738 sgd_solver.cpp:106] Iteration 18750, lr = 0.0045292
I0814 08:12:55.773373 21738 solver.cpp:337] Iteration 18800, Testing net (#0)
I0814 08:13:04.047004 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 08:13:04.047070 21738 solver.cpp:404]     Test net output #1: loss = 0.688512 (* 1 = 0.688512 loss)
I0814 08:13:05.663348 21738 solver.cpp:228] Iteration 18800, loss = 0.190235
I0814 08:13:05.663416 21738 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0814 08:13:05.663430 21738 solver.cpp:244]     Train net output #1: loss = 0.190235 (* 1 = 0.190235 loss)
I0814 08:13:05.663446 21738 sgd_solver.cpp:106] Iteration 18800, lr = 0.0045233
I0814 08:14:25.006995 21738 solver.cpp:228] Iteration 18850, loss = 0.271156
I0814 08:14:25.007207 21738 solver.cpp:244]     Train net output #0: accuracy = 0.995
I0814 08:14:25.007262 21738 solver.cpp:244]     Train net output #1: loss = 0.271156 (* 1 = 0.271156 loss)
I0814 08:14:25.007293 21738 sgd_solver.cpp:106] Iteration 18850, lr = 0.00451742
I0814 08:15:44.117895 21738 solver.cpp:337] Iteration 18900, Testing net (#0)
I0814 08:15:52.330788 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:15:52.330854 21738 solver.cpp:404]     Test net output #1: loss = 0.689457 (* 1 = 0.689457 loss)
I0814 08:15:53.907613 21738 solver.cpp:228] Iteration 18900, loss = 0.190245
I0814 08:15:53.907662 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:15:53.907680 21738 solver.cpp:244]     Train net output #1: loss = 0.190244 (* 1 = 0.190244 loss)
I0814 08:15:53.907694 21738 sgd_solver.cpp:106] Iteration 18900, lr = 0.00451156
I0814 08:17:13.535109 21738 solver.cpp:228] Iteration 18950, loss = 0.270296
I0814 08:17:13.535248 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:17:13.535262 21738 solver.cpp:244]     Train net output #1: loss = 0.270296 (* 1 = 0.270296 loss)
I0814 08:17:13.535274 21738 sgd_solver.cpp:106] Iteration 18950, lr = 0.00450571
I0814 08:18:32.070242 21738 solver.cpp:337] Iteration 19000, Testing net (#0)
I0814 08:18:40.008211 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:18:40.008272 21738 solver.cpp:404]     Test net output #1: loss = 0.690384 (* 1 = 0.690384 loss)
I0814 08:18:41.583700 21738 solver.cpp:228] Iteration 19000, loss = 0.190523
I0814 08:18:41.583750 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:18:41.583762 21738 solver.cpp:244]     Train net output #1: loss = 0.190523 (* 1 = 0.190523 loss)
I0814 08:18:41.583777 21738 sgd_solver.cpp:106] Iteration 19000, lr = 0.00449989
I0814 08:20:01.792521 21738 solver.cpp:228] Iteration 19050, loss = 0.271285
I0814 08:20:01.792697 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 08:20:01.792713 21738 solver.cpp:244]     Train net output #1: loss = 0.271285 (* 1 = 0.271285 loss)
I0814 08:20:01.792727 21738 sgd_solver.cpp:106] Iteration 19050, lr = 0.00449408
I0814 08:21:20.804991 21738 solver.cpp:337] Iteration 19100, Testing net (#0)
I0814 08:21:28.760776 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:21:28.760839 21738 solver.cpp:404]     Test net output #1: loss = 0.690262 (* 1 = 0.690262 loss)
I0814 08:21:30.337446 21738 solver.cpp:228] Iteration 19100, loss = 0.190506
I0814 08:21:30.337512 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:21:30.337525 21738 solver.cpp:244]     Train net output #1: loss = 0.190506 (* 1 = 0.190506 loss)
I0814 08:21:30.337539 21738 sgd_solver.cpp:106] Iteration 19100, lr = 0.00448828
I0814 08:22:51.146953 21738 solver.cpp:228] Iteration 19150, loss = 0.270615
I0814 08:22:51.147152 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:22:51.147214 21738 solver.cpp:244]     Train net output #1: loss = 0.270614 (* 1 = 0.270614 loss)
I0814 08:22:51.147238 21738 sgd_solver.cpp:106] Iteration 19150, lr = 0.00448251
I0814 08:24:11.996320 21738 solver.cpp:337] Iteration 19200, Testing net (#0)
I0814 08:24:19.937510 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:24:19.937569 21738 solver.cpp:404]     Test net output #1: loss = 0.688948 (* 1 = 0.688948 loss)
I0814 08:24:21.899536 21738 solver.cpp:228] Iteration 19200, loss = 0.190141
I0814 08:24:21.899605 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:24:21.899617 21738 solver.cpp:244]     Train net output #1: loss = 0.190141 (* 1 = 0.190141 loss)
I0814 08:24:21.899632 21738 sgd_solver.cpp:106] Iteration 19200, lr = 0.00447675
I0814 08:25:43.500331 21738 solver.cpp:228] Iteration 19250, loss = 0.270835
I0814 08:25:43.500529 21738 solver.cpp:244]     Train net output #0: accuracy = 0.985
I0814 08:25:43.500587 21738 solver.cpp:244]     Train net output #1: loss = 0.270835 (* 1 = 0.270835 loss)
I0814 08:25:43.500617 21738 sgd_solver.cpp:106] Iteration 19250, lr = 0.00447101
I0814 08:27:05.024348 21738 solver.cpp:337] Iteration 19300, Testing net (#0)
I0814 08:27:12.967126 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:27:12.967185 21738 solver.cpp:404]     Test net output #1: loss = 0.689128 (* 1 = 0.689128 loss)
I0814 08:27:14.812162 21738 solver.cpp:228] Iteration 19300, loss = 0.190168
I0814 08:27:14.812225 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:27:14.812239 21738 solver.cpp:244]     Train net output #1: loss = 0.190167 (* 1 = 0.190167 loss)
I0814 08:27:14.812254 21738 sgd_solver.cpp:106] Iteration 19300, lr = 0.00446529
I0814 08:28:37.594245 21738 solver.cpp:228] Iteration 19350, loss = 0.270181
I0814 08:28:37.594388 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:28:37.594404 21738 solver.cpp:244]     Train net output #1: loss = 0.270181 (* 1 = 0.270181 loss)
I0814 08:28:37.594416 21738 sgd_solver.cpp:106] Iteration 19350, lr = 0.00445958
I0814 08:29:57.393693 21738 solver.cpp:337] Iteration 19400, Testing net (#0)
I0814 08:30:05.415001 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 08:30:05.415063 21738 solver.cpp:404]     Test net output #1: loss = 0.688446 (* 1 = 0.688446 loss)
I0814 08:30:06.989575 21738 solver.cpp:228] Iteration 19400, loss = 0.190233
I0814 08:30:06.989640 21738 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0814 08:30:06.989655 21738 solver.cpp:244]     Train net output #1: loss = 0.190233 (* 1 = 0.190233 loss)
I0814 08:30:06.989670 21738 sgd_solver.cpp:106] Iteration 19400, lr = 0.00445389
I0814 08:31:29.733700 21738 solver.cpp:228] Iteration 19450, loss = 0.271898
I0814 08:31:29.733886 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:31:29.733903 21738 solver.cpp:244]     Train net output #1: loss = 0.271898 (* 1 = 0.271898 loss)
I0814 08:31:29.733918 21738 sgd_solver.cpp:106] Iteration 19450, lr = 0.00444822
I0814 08:32:49.763579 21738 solver.cpp:337] Iteration 19500, Testing net (#0)
I0814 08:32:58.314370 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:32:58.314434 21738 solver.cpp:404]     Test net output #1: loss = 0.689761 (* 1 = 0.689761 loss)
I0814 08:32:59.901541 21738 solver.cpp:228] Iteration 19500, loss = 0.190335
I0814 08:32:59.901593 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:32:59.901605 21738 solver.cpp:244]     Train net output #1: loss = 0.190335 (* 1 = 0.190335 loss)
I0814 08:32:59.901619 21738 sgd_solver.cpp:106] Iteration 19500, lr = 0.00444256
I0814 08:34:22.123832 21738 solver.cpp:228] Iteration 19550, loss = 0.270783
I0814 08:34:22.123986 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:34:22.123999 21738 solver.cpp:244]     Train net output #1: loss = 0.270783 (* 1 = 0.270783 loss)
I0814 08:34:22.124011 21738 sgd_solver.cpp:106] Iteration 19550, lr = 0.00443692
I0814 08:35:41.772076 21738 solver.cpp:337] Iteration 19600, Testing net (#0)
I0814 08:35:49.872556 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:35:49.872619 21738 solver.cpp:404]     Test net output #1: loss = 0.69106 (* 1 = 0.69106 loss)
I0814 08:35:51.493077 21738 solver.cpp:228] Iteration 19600, loss = 0.190717
I0814 08:35:51.493144 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:35:51.493156 21738 solver.cpp:244]     Train net output #1: loss = 0.190716 (* 1 = 0.190716 loss)
I0814 08:35:51.493171 21738 sgd_solver.cpp:106] Iteration 19600, lr = 0.0044313
I0814 08:37:12.130254 21738 solver.cpp:228] Iteration 19650, loss = 0.270258
I0814 08:37:12.130460 21738 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0814 08:37:12.130511 21738 solver.cpp:244]     Train net output #1: loss = 0.270258 (* 1 = 0.270258 loss)
I0814 08:37:12.130540 21738 sgd_solver.cpp:106] Iteration 19650, lr = 0.0044257
I0814 08:38:32.099231 21738 solver.cpp:337] Iteration 19700, Testing net (#0)
I0814 08:38:40.222759 21738 solver.cpp:404]     Test net output #0: accuracy = 0.97
I0814 08:38:40.222821 21738 solver.cpp:404]     Test net output #1: loss = 0.688238 (* 1 = 0.688238 loss)
I0814 08:38:41.801110 21738 solver.cpp:228] Iteration 19700, loss = 0.191555
I0814 08:38:41.801188 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 08:38:41.801203 21738 solver.cpp:244]     Train net output #1: loss = 0.191555 (* 1 = 0.191555 loss)
I0814 08:38:41.801218 21738 sgd_solver.cpp:106] Iteration 19700, lr = 0.00442011
I0814 08:40:02.381337 21738 solver.cpp:228] Iteration 19750, loss = 0.270424
I0814 08:40:02.381597 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:40:02.381656 21738 solver.cpp:244]     Train net output #1: loss = 0.270424 (* 1 = 0.270424 loss)
I0814 08:40:02.381690 21738 sgd_solver.cpp:106] Iteration 19750, lr = 0.00441453
I0814 08:41:25.252302 21738 solver.cpp:337] Iteration 19800, Testing net (#0)
I0814 08:41:33.498263 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:41:33.498339 21738 solver.cpp:404]     Test net output #1: loss = 0.691237 (* 1 = 0.691237 loss)
I0814 08:41:35.077692 21738 solver.cpp:228] Iteration 19800, loss = 0.190772
I0814 08:41:35.077745 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:41:35.077756 21738 solver.cpp:244]     Train net output #1: loss = 0.190772 (* 1 = 0.190772 loss)
I0814 08:41:35.077772 21738 sgd_solver.cpp:106] Iteration 19800, lr = 0.00440898
I0814 08:42:57.300304 21738 solver.cpp:228] Iteration 19850, loss = 0.270144
I0814 08:42:57.300535 21738 solver.cpp:244]     Train net output #0: accuracy = 0.895
I0814 08:42:57.300601 21738 solver.cpp:244]     Train net output #1: loss = 0.270144 (* 1 = 0.270144 loss)
I0814 08:42:57.300632 21738 sgd_solver.cpp:106] Iteration 19850, lr = 0.00440344
I0814 08:44:17.907987 21738 solver.cpp:337] Iteration 19900, Testing net (#0)
I0814 08:44:25.842171 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:44:25.842233 21738 solver.cpp:404]     Test net output #1: loss = 0.689272 (* 1 = 0.689272 loss)
I0814 08:44:27.417336 21738 solver.cpp:228] Iteration 19900, loss = 0.190241
I0814 08:44:27.417389 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:44:27.417402 21738 solver.cpp:244]     Train net output #1: loss = 0.190241 (* 1 = 0.190241 loss)
I0814 08:44:27.417418 21738 sgd_solver.cpp:106] Iteration 19900, lr = 0.00439791
I0814 08:45:48.846192 21738 solver.cpp:228] Iteration 19950, loss = 0.270437
I0814 08:45:48.846423 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:45:48.846489 21738 solver.cpp:244]     Train net output #1: loss = 0.270437 (* 1 = 0.270437 loss)
I0814 08:45:48.846514 21738 sgd_solver.cpp:106] Iteration 19950, lr = 0.00439241
I0814 08:47:10.263581 21738 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_20000.caffemodel
I0814 08:47:10.605516 21738 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_20000.solverstate
I0814 08:47:10.618316 21738 solver.cpp:337] Iteration 20000, Testing net (#0)
I0814 08:47:18.567764 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:47:18.567826 21738 solver.cpp:404]     Test net output #1: loss = 0.690779 (* 1 = 0.690779 loss)
I0814 08:47:20.145419 21738 solver.cpp:228] Iteration 20000, loss = 0.190654
I0814 08:47:20.145475 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:47:20.145488 21738 solver.cpp:244]     Train net output #1: loss = 0.190654 (* 1 = 0.190654 loss)
I0814 08:47:20.145503 21738 sgd_solver.cpp:106] Iteration 20000, lr = 0.00438691
I0814 08:48:41.719630 21738 solver.cpp:228] Iteration 20050, loss = 0.270834
I0814 08:48:41.719789 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:48:41.719805 21738 solver.cpp:244]     Train net output #1: loss = 0.270834 (* 1 = 0.270834 loss)
I0814 08:48:41.719818 21738 sgd_solver.cpp:106] Iteration 20050, lr = 0.00438144
I0814 08:50:01.672880 21738 solver.cpp:337] Iteration 20100, Testing net (#0)
I0814 08:50:09.726423 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:50:09.726485 21738 solver.cpp:404]     Test net output #1: loss = 0.691034 (* 1 = 0.691034 loss)
I0814 08:50:11.305896 21738 solver.cpp:228] Iteration 20100, loss = 0.190722
I0814 08:50:11.305948 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:50:11.305959 21738 solver.cpp:244]     Train net output #1: loss = 0.190722 (* 1 = 0.190722 loss)
I0814 08:50:11.305976 21738 sgd_solver.cpp:106] Iteration 20100, lr = 0.00437598
I0814 08:51:33.195734 21738 solver.cpp:228] Iteration 20150, loss = 0.27088
I0814 08:51:33.195945 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:51:33.196002 21738 solver.cpp:244]     Train net output #1: loss = 0.27088 (* 1 = 0.27088 loss)
I0814 08:51:33.196063 21738 sgd_solver.cpp:106] Iteration 20150, lr = 0.00437053
I0814 08:52:53.032757 21738 solver.cpp:337] Iteration 20200, Testing net (#0)
I0814 08:53:00.989078 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:53:00.989137 21738 solver.cpp:404]     Test net output #1: loss = 0.688812 (* 1 = 0.688812 loss)
I0814 08:53:02.566143 21738 solver.cpp:228] Iteration 20200, loss = 0.1901
I0814 08:53:02.566196 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 08:53:02.566208 21738 solver.cpp:244]     Train net output #1: loss = 0.1901 (* 1 = 0.1901 loss)
I0814 08:53:02.566223 21738 sgd_solver.cpp:106] Iteration 20200, lr = 0.00436511
I0814 08:54:24.099112 21738 solver.cpp:228] Iteration 20250, loss = 0.270183
I0814 08:54:24.099262 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:54:24.099277 21738 solver.cpp:244]     Train net output #1: loss = 0.270183 (* 1 = 0.270183 loss)
I0814 08:54:24.099290 21738 sgd_solver.cpp:106] Iteration 20250, lr = 0.00435969
I0814 08:55:43.341042 21738 solver.cpp:337] Iteration 20300, Testing net (#0)
I0814 08:55:51.576109 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:55:51.576174 21738 solver.cpp:404]     Test net output #1: loss = 0.688787 (* 1 = 0.688787 loss)
I0814 08:55:53.152820 21738 solver.cpp:228] Iteration 20300, loss = 0.190111
I0814 08:55:53.152881 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:55:53.152894 21738 solver.cpp:244]     Train net output #1: loss = 0.190111 (* 1 = 0.190111 loss)
I0814 08:55:53.152909 21738 sgd_solver.cpp:106] Iteration 20300, lr = 0.0043543
I0814 08:57:14.388797 21738 solver.cpp:228] Iteration 20350, loss = 0.270844
I0814 08:57:14.388953 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 08:57:14.388969 21738 solver.cpp:244]     Train net output #1: loss = 0.270843 (* 1 = 0.270843 loss)
I0814 08:57:14.388984 21738 sgd_solver.cpp:106] Iteration 20350, lr = 0.00434892
I0814 08:58:35.479565 21738 solver.cpp:337] Iteration 20400, Testing net (#0)
I0814 08:58:43.635073 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 08:58:43.635133 21738 solver.cpp:404]     Test net output #1: loss = 0.689988 (* 1 = 0.689988 loss)
I0814 08:58:45.213567 21738 solver.cpp:228] Iteration 20400, loss = 0.190421
I0814 08:58:45.213629 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 08:58:45.213641 21738 solver.cpp:244]     Train net output #1: loss = 0.190421 (* 1 = 0.190421 loss)
I0814 08:58:45.213661 21738 sgd_solver.cpp:106] Iteration 20400, lr = 0.00434355
I0814 09:00:04.895822 21738 solver.cpp:228] Iteration 20450, loss = 0.270354
I0814 09:00:04.896057 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:00:04.896111 21738 solver.cpp:244]     Train net output #1: loss = 0.270354 (* 1 = 0.270354 loss)
I0814 09:00:04.896136 21738 sgd_solver.cpp:106] Iteration 20450, lr = 0.0043382
I0814 09:01:23.535634 21738 solver.cpp:337] Iteration 20500, Testing net (#0)
I0814 09:01:31.934953 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:01:31.935016 21738 solver.cpp:404]     Test net output #1: loss = 0.691442 (* 1 = 0.691442 loss)
I0814 09:01:33.511899 21738 solver.cpp:228] Iteration 20500, loss = 0.190838
I0814 09:01:33.511965 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:01:33.511976 21738 solver.cpp:244]     Train net output #1: loss = 0.190838 (* 1 = 0.190838 loss)
I0814 09:01:33.511991 21738 sgd_solver.cpp:106] Iteration 20500, lr = 0.00433286
I0814 09:02:54.075323 21738 solver.cpp:228] Iteration 20550, loss = 0.270586
I0814 09:02:54.075479 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:02:54.075495 21738 solver.cpp:244]     Train net output #1: loss = 0.270586 (* 1 = 0.270586 loss)
I0814 09:02:54.075510 21738 sgd_solver.cpp:106] Iteration 20550, lr = 0.00432754
I0814 09:04:13.115874 21738 solver.cpp:337] Iteration 20600, Testing net (#0)
I0814 09:04:21.074839 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:04:21.074900 21738 solver.cpp:404]     Test net output #1: loss = 0.692552 (* 1 = 0.692552 loss)
I0814 09:04:22.654530 21738 solver.cpp:228] Iteration 20600, loss = 0.191112
I0814 09:04:22.654580 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:04:22.654592 21738 solver.cpp:244]     Train net output #1: loss = 0.191112 (* 1 = 0.191112 loss)
I0814 09:04:22.654606 21738 sgd_solver.cpp:106] Iteration 20600, lr = 0.00432224
I0814 09:05:42.860710 21738 solver.cpp:228] Iteration 20650, loss = 0.27056
I0814 09:05:42.860954 21738 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0814 09:05:42.861008 21738 solver.cpp:244]     Train net output #1: loss = 0.27056 (* 1 = 0.27056 loss)
I0814 09:05:42.861050 21738 sgd_solver.cpp:106] Iteration 20650, lr = 0.00431695
I0814 09:07:01.472124 21738 solver.cpp:337] Iteration 20700, Testing net (#0)
I0814 09:07:09.709122 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:07:09.709192 21738 solver.cpp:404]     Test net output #1: loss = 0.691161 (* 1 = 0.691161 loss)
I0814 09:07:11.287755 21738 solver.cpp:228] Iteration 20700, loss = 0.190745
I0814 09:07:11.287830 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:07:11.287844 21738 solver.cpp:244]     Train net output #1: loss = 0.190745 (* 1 = 0.190745 loss)
I0814 09:07:11.287858 21738 sgd_solver.cpp:106] Iteration 20700, lr = 0.00431168
I0814 09:08:31.992152 21738 solver.cpp:228] Iteration 20750, loss = 0.270654
I0814 09:08:31.992427 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:08:31.992482 21738 solver.cpp:244]     Train net output #1: loss = 0.270654 (* 1 = 0.270654 loss)
I0814 09:08:31.992504 21738 sgd_solver.cpp:106] Iteration 20750, lr = 0.00430642
I0814 09:09:51.509361 21738 solver.cpp:337] Iteration 20800, Testing net (#0)
I0814 09:09:59.864300 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:09:59.864364 21738 solver.cpp:404]     Test net output #1: loss = 0.689894 (* 1 = 0.689894 loss)
I0814 09:10:01.443011 21738 solver.cpp:228] Iteration 20800, loss = 0.190382
I0814 09:10:01.443083 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:10:01.443097 21738 solver.cpp:244]     Train net output #1: loss = 0.190382 (* 1 = 0.190382 loss)
I0814 09:10:01.443112 21738 sgd_solver.cpp:106] Iteration 20800, lr = 0.00430117
I0814 09:11:23.331228 21738 solver.cpp:228] Iteration 20850, loss = 0.271023
I0814 09:11:23.331441 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:11:23.331499 21738 solver.cpp:244]     Train net output #1: loss = 0.271023 (* 1 = 0.271023 loss)
I0814 09:11:23.331529 21738 sgd_solver.cpp:106] Iteration 20850, lr = 0.00429594
I0814 09:12:43.420974 21738 solver.cpp:337] Iteration 20900, Testing net (#0)
I0814 09:12:51.379577 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:12:51.379639 21738 solver.cpp:404]     Test net output #1: loss = 0.688524 (* 1 = 0.688524 loss)
I0814 09:12:52.956277 21738 solver.cpp:228] Iteration 20900, loss = 0.190125
I0814 09:12:52.956329 21738 solver.cpp:244]     Train net output #0: accuracy = 0.935
I0814 09:12:52.956341 21738 solver.cpp:244]     Train net output #1: loss = 0.190125 (* 1 = 0.190125 loss)
I0814 09:12:52.956357 21738 sgd_solver.cpp:106] Iteration 20900, lr = 0.00429073
I0814 09:14:15.739930 21738 solver.cpp:228] Iteration 20950, loss = 0.270954
I0814 09:14:15.740156 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:14:15.740219 21738 solver.cpp:244]     Train net output #1: loss = 0.270954 (* 1 = 0.270954 loss)
I0814 09:14:15.740249 21738 sgd_solver.cpp:106] Iteration 20950, lr = 0.00428553
I0814 09:15:35.719022 21738 solver.cpp:337] Iteration 21000, Testing net (#0)
I0814 09:15:43.891487 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:15:43.891551 21738 solver.cpp:404]     Test net output #1: loss = 0.692396 (* 1 = 0.692396 loss)
I0814 09:15:45.468713 21738 solver.cpp:228] Iteration 21000, loss = 0.191066
I0814 09:15:45.468766 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:15:45.468778 21738 solver.cpp:244]     Train net output #1: loss = 0.191066 (* 1 = 0.191066 loss)
I0814 09:15:45.468804 21738 sgd_solver.cpp:106] Iteration 21000, lr = 0.00428034
I0814 09:17:07.362648 21738 solver.cpp:228] Iteration 21050, loss = 0.270182
I0814 09:17:07.362876 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:17:07.362931 21738 solver.cpp:244]     Train net output #1: loss = 0.270182 (* 1 = 0.270182 loss)
I0814 09:17:07.362958 21738 sgd_solver.cpp:106] Iteration 21050, lr = 0.00427517
I0814 09:18:30.220827 21738 solver.cpp:337] Iteration 21100, Testing net (#0)
I0814 09:18:38.315585 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:18:38.315647 21738 solver.cpp:404]     Test net output #1: loss = 0.69376 (* 1 = 0.69376 loss)
I0814 09:18:39.904677 21738 solver.cpp:228] Iteration 21100, loss = 0.191459
I0814 09:18:39.904731 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:18:39.904744 21738 solver.cpp:244]     Train net output #1: loss = 0.191459 (* 1 = 0.191459 loss)
I0814 09:18:39.904759 21738 sgd_solver.cpp:106] Iteration 21100, lr = 0.00427002
I0814 09:20:01.860890 21738 solver.cpp:228] Iteration 21150, loss = 0.270145
I0814 09:20:01.861071 21738 solver.cpp:244]     Train net output #0: accuracy = 0.87
I0814 09:20:01.861086 21738 solver.cpp:244]     Train net output #1: loss = 0.270145 (* 1 = 0.270145 loss)
I0814 09:20:01.861098 21738 sgd_solver.cpp:106] Iteration 21150, lr = 0.00426488
I0814 09:21:22.281281 21738 solver.cpp:337] Iteration 21200, Testing net (#0)
I0814 09:21:30.453709 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:21:30.453774 21738 solver.cpp:404]     Test net output #1: loss = 0.690828 (* 1 = 0.690828 loss)
I0814 09:21:32.031013 21738 solver.cpp:228] Iteration 21200, loss = 0.19066
I0814 09:21:32.031071 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:21:32.031083 21738 solver.cpp:244]     Train net output #1: loss = 0.19066 (* 1 = 0.19066 loss)
I0814 09:21:32.031098 21738 sgd_solver.cpp:106] Iteration 21200, lr = 0.00425975
I0814 09:22:52.355917 21738 solver.cpp:228] Iteration 21250, loss = 0.270349
I0814 09:22:52.356086 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:22:52.356099 21738 solver.cpp:244]     Train net output #1: loss = 0.270348 (* 1 = 0.270348 loss)
I0814 09:22:52.356112 21738 sgd_solver.cpp:106] Iteration 21250, lr = 0.00425464
I0814 09:24:13.966747 21738 solver.cpp:337] Iteration 21300, Testing net (#0)
I0814 09:24:21.933936 21738 solver.cpp:404]     Test net output #0: accuracy = 0.999
I0814 09:24:21.933996 21738 solver.cpp:404]     Test net output #1: loss = 0.688344 (* 1 = 0.688344 loss)
I0814 09:24:23.510968 21738 solver.cpp:228] Iteration 21300, loss = 0.191792
I0814 09:24:23.511018 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 09:24:23.511030 21738 solver.cpp:244]     Train net output #1: loss = 0.191792 (* 1 = 0.191792 loss)
I0814 09:24:23.511046 21738 sgd_solver.cpp:106] Iteration 21300, lr = 0.00424954
I0814 09:25:44.733342 21738 solver.cpp:228] Iteration 21350, loss = 0.271125
I0814 09:25:44.733486 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:25:44.733501 21738 solver.cpp:244]     Train net output #1: loss = 0.271125 (* 1 = 0.271125 loss)
I0814 09:25:44.733512 21738 sgd_solver.cpp:106] Iteration 21350, lr = 0.00424445
I0814 09:27:04.790141 21738 solver.cpp:337] Iteration 21400, Testing net (#0)
I0814 09:27:12.827517 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:27:12.827574 21738 solver.cpp:404]     Test net output #1: loss = 0.690826 (* 1 = 0.690826 loss)
I0814 09:27:14.767451 21738 solver.cpp:228] Iteration 21400, loss = 0.190669
I0814 09:27:14.767515 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:27:14.767531 21738 solver.cpp:244]     Train net output #1: loss = 0.190669 (* 1 = 0.190669 loss)
I0814 09:27:14.767545 21738 sgd_solver.cpp:106] Iteration 21400, lr = 0.00423938
I0814 09:28:36.367022 21738 solver.cpp:228] Iteration 21450, loss = 0.270705
I0814 09:28:36.367234 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:28:36.367308 21738 solver.cpp:244]     Train net output #1: loss = 0.270705 (* 1 = 0.270705 loss)
I0814 09:28:36.367353 21738 sgd_solver.cpp:106] Iteration 21450, lr = 0.00423433
I0814 09:29:57.153012 21738 solver.cpp:337] Iteration 21500, Testing net (#0)
I0814 09:30:05.672631 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:30:05.672698 21738 solver.cpp:404]     Test net output #1: loss = 0.690653 (* 1 = 0.690653 loss)
I0814 09:30:07.336961 21738 solver.cpp:228] Iteration 21500, loss = 0.190605
I0814 09:30:07.337013 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:30:07.337024 21738 solver.cpp:244]     Train net output #1: loss = 0.190605 (* 1 = 0.190605 loss)
I0814 09:30:07.337039 21738 sgd_solver.cpp:106] Iteration 21500, lr = 0.00422929
I0814 09:31:28.874270 21738 solver.cpp:228] Iteration 21550, loss = 0.271771
I0814 09:31:28.874455 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:31:28.874471 21738 solver.cpp:244]     Train net output #1: loss = 0.27177 (* 1 = 0.27177 loss)
I0814 09:31:28.874486 21738 sgd_solver.cpp:106] Iteration 21550, lr = 0.00422426
I0814 09:32:49.317478 21738 solver.cpp:337] Iteration 21600, Testing net (#0)
I0814 09:32:57.618335 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:32:57.618403 21738 solver.cpp:404]     Test net output #1: loss = 0.69042 (* 1 = 0.69042 loss)
I0814 09:32:59.300801 21738 solver.cpp:228] Iteration 21600, loss = 0.19055
I0814 09:32:59.300864 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:32:59.300879 21738 solver.cpp:244]     Train net output #1: loss = 0.19055 (* 1 = 0.19055 loss)
I0814 09:32:59.300894 21738 sgd_solver.cpp:106] Iteration 21600, lr = 0.00421924
I0814 09:34:20.564195 21738 solver.cpp:228] Iteration 21650, loss = 0.270749
I0814 09:34:20.564342 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:34:20.564357 21738 solver.cpp:244]     Train net output #1: loss = 0.270749 (* 1 = 0.270749 loss)
I0814 09:34:20.564368 21738 sgd_solver.cpp:106] Iteration 21650, lr = 0.00421424
I0814 09:35:39.558388 21738 solver.cpp:337] Iteration 21700, Testing net (#0)
I0814 09:35:47.622330 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:35:47.622390 21738 solver.cpp:404]     Test net output #1: loss = 0.691615 (* 1 = 0.691615 loss)
I0814 09:35:49.199858 21738 solver.cpp:228] Iteration 21700, loss = 0.19088
I0814 09:35:49.199924 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:35:49.199937 21738 solver.cpp:244]     Train net output #1: loss = 0.19088 (* 1 = 0.19088 loss)
I0814 09:35:49.199951 21738 sgd_solver.cpp:106] Iteration 21700, lr = 0.00420926
I0814 09:37:11.908016 21738 solver.cpp:228] Iteration 21750, loss = 0.271
I0814 09:37:11.908247 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:37:11.908330 21738 solver.cpp:244]     Train net output #1: loss = 0.271 (* 1 = 0.271 loss)
I0814 09:37:11.908376 21738 sgd_solver.cpp:106] Iteration 21750, lr = 0.00420429
I0814 09:38:32.624130 21738 solver.cpp:337] Iteration 21800, Testing net (#0)
I0814 09:38:40.589454 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:38:40.589516 21738 solver.cpp:404]     Test net output #1: loss = 0.690628 (* 1 = 0.690628 loss)
I0814 09:38:42.167033 21738 solver.cpp:228] Iteration 21800, loss = 0.190622
I0814 09:38:42.167085 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:38:42.167098 21738 solver.cpp:244]     Train net output #1: loss = 0.190621 (* 1 = 0.190621 loss)
I0814 09:38:42.167112 21738 sgd_solver.cpp:106] Iteration 21800, lr = 0.00419933
I0814 09:40:05.547464 21738 solver.cpp:228] Iteration 21850, loss = 0.27164
I0814 09:40:05.547603 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 09:40:05.547619 21738 solver.cpp:244]     Train net output #1: loss = 0.271639 (* 1 = 0.271639 loss)
I0814 09:40:05.547632 21738 sgd_solver.cpp:106] Iteration 21850, lr = 0.00419438
I0814 09:41:27.229164 21738 solver.cpp:337] Iteration 21900, Testing net (#0)
I0814 09:41:35.296314 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:41:35.296378 21738 solver.cpp:404]     Test net output #1: loss = 0.688959 (* 1 = 0.688959 loss)
I0814 09:41:36.876776 21738 solver.cpp:228] Iteration 21900, loss = 0.190146
I0814 09:41:36.876849 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:41:36.876863 21738 solver.cpp:244]     Train net output #1: loss = 0.190146 (* 1 = 0.190146 loss)
I0814 09:41:36.876876 21738 sgd_solver.cpp:106] Iteration 21900, lr = 0.00418945
I0814 09:42:58.392879 21738 solver.cpp:228] Iteration 21950, loss = 0.270346
I0814 09:42:58.393086 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:42:58.393146 21738 solver.cpp:244]     Train net output #1: loss = 0.270346 (* 1 = 0.270346 loss)
I0814 09:42:58.393172 21738 sgd_solver.cpp:106] Iteration 21950, lr = 0.00418453
I0814 09:44:18.071527 21738 solver.cpp:337] Iteration 22000, Testing net (#0)
I0814 09:44:26.035774 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:44:26.035833 21738 solver.cpp:404]     Test net output #1: loss = 0.690911 (* 1 = 0.690911 loss)
I0814 09:44:27.636798 21738 solver.cpp:228] Iteration 22000, loss = 0.190679
I0814 09:44:27.636867 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:44:27.636890 21738 solver.cpp:244]     Train net output #1: loss = 0.190679 (* 1 = 0.190679 loss)
I0814 09:44:27.636904 21738 sgd_solver.cpp:106] Iteration 22000, lr = 0.00417963
I0814 09:45:52.458616 21738 solver.cpp:228] Iteration 22050, loss = 0.272057
I0814 09:45:52.458780 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 09:45:52.458798 21738 solver.cpp:244]     Train net output #1: loss = 0.272057 (* 1 = 0.272057 loss)
I0814 09:45:52.458818 21738 sgd_solver.cpp:106] Iteration 22050, lr = 0.00417474
I0814 09:47:14.886394 21738 solver.cpp:337] Iteration 22100, Testing net (#0)
I0814 09:47:22.933542 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:47:22.933598 21738 solver.cpp:404]     Test net output #1: loss = 0.690572 (* 1 = 0.690572 loss)
I0814 09:47:24.540295 21738 solver.cpp:228] Iteration 22100, loss = 0.190582
I0814 09:47:24.540354 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:47:24.540366 21738 solver.cpp:244]     Train net output #1: loss = 0.190581 (* 1 = 0.190581 loss)
I0814 09:47:24.540382 21738 sgd_solver.cpp:106] Iteration 22100, lr = 0.00416986
I0814 09:48:46.020727 21738 solver.cpp:228] Iteration 22150, loss = 0.270578
I0814 09:48:46.020926 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:48:46.020994 21738 solver.cpp:244]     Train net output #1: loss = 0.270578 (* 1 = 0.270578 loss)
I0814 09:48:46.021031 21738 sgd_solver.cpp:106] Iteration 22150, lr = 0.00416499
I0814 09:50:08.118656 21738 solver.cpp:337] Iteration 22200, Testing net (#0)
I0814 09:50:16.253741 21738 solver.cpp:404]     Test net output #0: accuracy = 0.718
I0814 09:50:16.253806 21738 solver.cpp:404]     Test net output #1: loss = 0.688166 (* 1 = 0.688166 loss)
I0814 09:50:17.830343 21738 solver.cpp:228] Iteration 22200, loss = 0.190665
I0814 09:50:17.830411 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 09:50:17.830425 21738 solver.cpp:244]     Train net output #1: loss = 0.190665 (* 1 = 0.190665 loss)
I0814 09:50:17.830440 21738 sgd_solver.cpp:106] Iteration 22200, lr = 0.00416014
I0814 09:51:37.682116 21738 solver.cpp:228] Iteration 22250, loss = 0.270113
I0814 09:51:37.682301 21738 solver.cpp:244]     Train net output #0: accuracy = 0.895
I0814 09:51:37.682353 21738 solver.cpp:244]     Train net output #1: loss = 0.270112 (* 1 = 0.270112 loss)
I0814 09:51:37.682374 21738 sgd_solver.cpp:106] Iteration 22250, lr = 0.0041553
I0814 09:52:58.027252 21738 solver.cpp:337] Iteration 22300, Testing net (#0)
I0814 09:53:05.991616 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:53:05.991674 21738 solver.cpp:404]     Test net output #1: loss = 0.691257 (* 1 = 0.691257 loss)
I0814 09:53:07.567047 21738 solver.cpp:228] Iteration 22300, loss = 0.190774
I0814 09:53:07.567118 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:53:07.567131 21738 solver.cpp:244]     Train net output #1: loss = 0.190774 (* 1 = 0.190774 loss)
I0814 09:53:07.567147 21738 sgd_solver.cpp:106] Iteration 22300, lr = 0.00415048
I0814 09:54:28.800489 21738 solver.cpp:228] Iteration 22350, loss = 0.271031
I0814 09:54:28.800640 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:54:28.800655 21738 solver.cpp:244]     Train net output #1: loss = 0.27103 (* 1 = 0.27103 loss)
I0814 09:54:28.800670 21738 sgd_solver.cpp:106] Iteration 22350, lr = 0.00414567
I0814 09:55:46.801440 21738 solver.cpp:337] Iteration 22400, Testing net (#0)
I0814 09:55:55.107481 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 09:55:55.107547 21738 solver.cpp:404]     Test net output #1: loss = 0.690864 (* 1 = 0.690864 loss)
I0814 09:55:56.682847 21738 solver.cpp:228] Iteration 22400, loss = 0.190662
I0814 09:55:56.682898 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 09:55:56.682910 21738 solver.cpp:244]     Train net output #1: loss = 0.190662 (* 1 = 0.190662 loss)
I0814 09:55:56.682929 21738 sgd_solver.cpp:106] Iteration 22400, lr = 0.00414087
I0814 09:57:15.938108 21738 solver.cpp:228] Iteration 22450, loss = 0.271099
I0814 09:57:15.938256 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 09:57:15.938271 21738 solver.cpp:244]     Train net output #1: loss = 0.271099 (* 1 = 0.271099 loss)
I0814 09:57:15.938282 21738 sgd_solver.cpp:106] Iteration 22450, lr = 0.00413608
I0814 09:58:35.505947 21738 solver.cpp:337] Iteration 22500, Testing net (#0)
I0814 09:58:43.665874 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 09:58:43.665941 21738 solver.cpp:404]     Test net output #1: loss = 0.688383 (* 1 = 0.688383 loss)
I0814 09:58:45.242569 21738 solver.cpp:228] Iteration 22500, loss = 0.190278
I0814 09:58:45.242636 21738 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0814 09:58:45.242650 21738 solver.cpp:244]     Train net output #1: loss = 0.190278 (* 1 = 0.190278 loss)
I0814 09:58:45.242665 21738 sgd_solver.cpp:106] Iteration 22500, lr = 0.00413131
I0814 10:00:05.283591 21738 solver.cpp:228] Iteration 22550, loss = 0.271061
I0814 10:00:05.283851 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:00:05.283921 21738 solver.cpp:244]     Train net output #1: loss = 0.271061 (* 1 = 0.271061 loss)
I0814 10:00:05.283968 21738 sgd_solver.cpp:106] Iteration 22550, lr = 0.00412655
I0814 10:01:24.470158 21738 solver.cpp:337] Iteration 22600, Testing net (#0)
I0814 10:01:32.741309 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:01:32.741367 21738 solver.cpp:404]     Test net output #1: loss = 0.689999 (* 1 = 0.689999 loss)
I0814 10:01:34.316488 21738 solver.cpp:228] Iteration 22600, loss = 0.19044
I0814 10:01:34.316553 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:01:34.316567 21738 solver.cpp:244]     Train net output #1: loss = 0.19044 (* 1 = 0.19044 loss)
I0814 10:01:34.316581 21738 sgd_solver.cpp:106] Iteration 22600, lr = 0.0041218
I0814 10:02:53.830559 21738 solver.cpp:228] Iteration 22650, loss = 0.2716
I0814 10:02:53.830762 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:02:53.830811 21738 solver.cpp:244]     Train net output #1: loss = 0.2716 (* 1 = 0.2716 loss)
I0814 10:02:53.830854 21738 sgd_solver.cpp:106] Iteration 22650, lr = 0.00411706
I0814 10:04:13.702024 21738 solver.cpp:337] Iteration 22700, Testing net (#0)
I0814 10:04:21.626623 21738 solver.cpp:404]     Test net output #0: accuracy = 0.874
I0814 10:04:21.626687 21738 solver.cpp:404]     Test net output #1: loss = 0.688133 (* 1 = 0.688133 loss)
I0814 10:04:23.201228 21738 solver.cpp:228] Iteration 22700, loss = 0.19118
I0814 10:04:23.201284 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 10:04:23.201297 21738 solver.cpp:244]     Train net output #1: loss = 0.19118 (* 1 = 0.19118 loss)
I0814 10:04:23.201313 21738 sgd_solver.cpp:106] Iteration 22700, lr = 0.00411234
I0814 10:05:43.823514 21738 solver.cpp:228] Iteration 22750, loss = 0.270271
I0814 10:05:43.823740 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:05:43.823786 21738 solver.cpp:244]     Train net output #1: loss = 0.270271 (* 1 = 0.270271 loss)
I0814 10:05:43.823812 21738 sgd_solver.cpp:106] Iteration 22750, lr = 0.00410763
I0814 10:07:02.834053 21738 solver.cpp:337] Iteration 22800, Testing net (#0)
I0814 10:07:10.866549 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:07:10.866608 21738 solver.cpp:404]     Test net output #1: loss = 0.689195 (* 1 = 0.689195 loss)
I0814 10:07:12.444511 21738 solver.cpp:228] Iteration 22800, loss = 0.190192
I0814 10:07:12.444577 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:07:12.444591 21738 solver.cpp:244]     Train net output #1: loss = 0.190192 (* 1 = 0.190192 loss)
I0814 10:07:12.444607 21738 sgd_solver.cpp:106] Iteration 22800, lr = 0.00410293
I0814 10:08:33.739923 21738 solver.cpp:228] Iteration 22850, loss = 0.270427
I0814 10:08:33.740180 21738 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0814 10:08:33.740238 21738 solver.cpp:244]     Train net output #1: loss = 0.270427 (* 1 = 0.270427 loss)
I0814 10:08:33.740268 21738 sgd_solver.cpp:106] Iteration 22850, lr = 0.00409825
I0814 10:09:54.765765 21738 solver.cpp:337] Iteration 22900, Testing net (#0)
I0814 10:10:03.197652 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 10:10:03.197715 21738 solver.cpp:404]     Test net output #1: loss = 0.688459 (* 1 = 0.688459 loss)
I0814 10:10:04.777758 21738 solver.cpp:228] Iteration 22900, loss = 0.190184
I0814 10:10:04.777838 21738 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0814 10:10:04.777853 21738 solver.cpp:244]     Train net output #1: loss = 0.190184 (* 1 = 0.190184 loss)
I0814 10:10:04.777868 21738 sgd_solver.cpp:106] Iteration 22900, lr = 0.00409358
I0814 10:11:25.854760 21738 solver.cpp:228] Iteration 22950, loss = 0.271062
I0814 10:11:25.854959 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:11:25.855010 21738 solver.cpp:244]     Train net output #1: loss = 0.271062 (* 1 = 0.271062 loss)
I0814 10:11:25.855034 21738 sgd_solver.cpp:106] Iteration 22950, lr = 0.00408892
I0814 10:12:45.103533 21738 solver.cpp:337] Iteration 23000, Testing net (#0)
I0814 10:12:53.230851 21738 solver.cpp:404]     Test net output #0: accuracy = 0.698
I0814 10:12:53.230914 21738 solver.cpp:404]     Test net output #1: loss = 0.688182 (* 1 = 0.688182 loss)
I0814 10:12:54.804689 21738 solver.cpp:228] Iteration 23000, loss = 0.190688
I0814 10:12:54.804739 21738 solver.cpp:244]     Train net output #0: accuracy = 0.995
I0814 10:12:54.804751 21738 solver.cpp:244]     Train net output #1: loss = 0.190687 (* 1 = 0.190687 loss)
I0814 10:12:54.804765 21738 sgd_solver.cpp:106] Iteration 23000, lr = 0.00408427
I0814 10:14:14.337946 21738 solver.cpp:228] Iteration 23050, loss = 0.270258
I0814 10:14:14.338156 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:14:14.338210 21738 solver.cpp:244]     Train net output #1: loss = 0.270258 (* 1 = 0.270258 loss)
I0814 10:14:14.338246 21738 sgd_solver.cpp:106] Iteration 23050, lr = 0.00407964
I0814 10:15:35.214191 21738 solver.cpp:337] Iteration 23100, Testing net (#0)
I0814 10:15:43.450551 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:15:43.450614 21738 solver.cpp:404]     Test net output #1: loss = 0.688546 (* 1 = 0.688546 loss)
I0814 10:15:45.380543 21738 solver.cpp:228] Iteration 23100, loss = 0.190157
I0814 10:15:45.380609 21738 solver.cpp:244]     Train net output #0: accuracy = 0.925
I0814 10:15:45.380623 21738 solver.cpp:244]     Train net output #1: loss = 0.190157 (* 1 = 0.190157 loss)
I0814 10:15:45.380637 21738 sgd_solver.cpp:106] Iteration 23100, lr = 0.00407501
I0814 10:17:07.442661 21738 solver.cpp:228] Iteration 23150, loss = 0.270468
I0814 10:17:07.442870 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:17:07.442939 21738 solver.cpp:244]     Train net output #1: loss = 0.270468 (* 1 = 0.270468 loss)
I0814 10:17:07.442986 21738 sgd_solver.cpp:106] Iteration 23150, lr = 0.0040704
I0814 10:18:26.325489 21738 solver.cpp:337] Iteration 23200, Testing net (#0)
I0814 10:18:34.463347 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:18:34.463413 21738 solver.cpp:404]     Test net output #1: loss = 0.691135 (* 1 = 0.691135 loss)
I0814 10:18:36.035137 21738 solver.cpp:228] Iteration 23200, loss = 0.190724
I0814 10:18:36.035190 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:18:36.035202 21738 solver.cpp:244]     Train net output #1: loss = 0.190724 (* 1 = 0.190724 loss)
I0814 10:18:36.035217 21738 sgd_solver.cpp:106] Iteration 23200, lr = 0.0040658
I0814 10:19:57.318260 21738 solver.cpp:228] Iteration 23250, loss = 0.270156
I0814 10:19:57.318452 21738 solver.cpp:244]     Train net output #0: accuracy = 0.895
I0814 10:19:57.318469 21738 solver.cpp:244]     Train net output #1: loss = 0.270156 (* 1 = 0.270156 loss)
I0814 10:19:57.318485 21738 sgd_solver.cpp:106] Iteration 23250, lr = 0.00406122
I0814 10:21:16.108568 21738 solver.cpp:337] Iteration 23300, Testing net (#0)
I0814 10:21:24.047967 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:21:24.048035 21738 solver.cpp:404]     Test net output #1: loss = 0.689021 (* 1 = 0.689021 loss)
I0814 10:21:25.619702 21738 solver.cpp:228] Iteration 23300, loss = 0.19017
I0814 10:21:25.619761 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:21:25.619774 21738 solver.cpp:244]     Train net output #1: loss = 0.19017 (* 1 = 0.19017 loss)
I0814 10:21:25.619788 21738 sgd_solver.cpp:106] Iteration 23300, lr = 0.00405664
I0814 10:22:48.945685 21738 solver.cpp:228] Iteration 23350, loss = 0.270544
I0814 10:22:48.945837 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:22:48.945852 21738 solver.cpp:244]     Train net output #1: loss = 0.270544 (* 1 = 0.270544 loss)
I0814 10:22:48.945864 21738 sgd_solver.cpp:106] Iteration 23350, lr = 0.00405208
I0814 10:24:07.992494 21738 solver.cpp:337] Iteration 23400, Testing net (#0)
I0814 10:24:16.265199 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:24:16.265261 21738 solver.cpp:404]     Test net output #1: loss = 0.689315 (* 1 = 0.689315 loss)
I0814 10:24:17.839978 21738 solver.cpp:228] Iteration 23400, loss = 0.190247
I0814 10:24:17.840054 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:24:17.840066 21738 solver.cpp:244]     Train net output #1: loss = 0.190247 (* 1 = 0.190247 loss)
I0814 10:24:17.840080 21738 sgd_solver.cpp:106] Iteration 23400, lr = 0.00404753
I0814 10:25:39.773845 21738 solver.cpp:228] Iteration 23450, loss = 0.270721
I0814 10:25:39.773993 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:25:39.774008 21738 solver.cpp:244]     Train net output #1: loss = 0.270721 (* 1 = 0.270721 loss)
I0814 10:25:39.774024 21738 sgd_solver.cpp:106] Iteration 23450, lr = 0.00404299
I0814 10:26:59.112988 21738 solver.cpp:337] Iteration 23500, Testing net (#0)
I0814 10:27:07.502745 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 10:27:07.502810 21738 solver.cpp:404]     Test net output #1: loss = 0.68838 (* 1 = 0.68838 loss)
I0814 10:27:09.077206 21738 solver.cpp:228] Iteration 23500, loss = 0.190254
I0814 10:27:09.077271 21738 solver.cpp:244]     Train net output #0: accuracy = 0.955
I0814 10:27:09.077285 21738 solver.cpp:244]     Train net output #1: loss = 0.190254 (* 1 = 0.190254 loss)
I0814 10:27:09.077298 21738 sgd_solver.cpp:106] Iteration 23500, lr = 0.00403847
I0814 10:28:31.697108 21738 solver.cpp:228] Iteration 23550, loss = 0.27029
I0814 10:28:31.697329 21738 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0814 10:28:31.697384 21738 solver.cpp:244]     Train net output #1: loss = 0.27029 (* 1 = 0.27029 loss)
I0814 10:28:31.697429 21738 sgd_solver.cpp:106] Iteration 23550, lr = 0.00403395
I0814 10:29:51.976653 21738 solver.cpp:337] Iteration 23600, Testing net (#0)
I0814 10:30:00.105309 21738 solver.cpp:404]     Test net output #0: accuracy = 0.98
I0814 10:30:00.105368 21738 solver.cpp:404]     Test net output #1: loss = 0.688235 (* 1 = 0.688235 loss)
I0814 10:30:01.964963 21738 solver.cpp:228] Iteration 23600, loss = 0.191443
I0814 10:30:01.965025 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 10:30:01.965037 21738 solver.cpp:244]     Train net output #1: loss = 0.191443 (* 1 = 0.191443 loss)
I0814 10:30:01.965051 21738 sgd_solver.cpp:106] Iteration 23600, lr = 0.00402945
I0814 10:31:23.939849 21738 solver.cpp:228] Iteration 23650, loss = 0.27046
I0814 10:31:23.940050 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:31:23.940065 21738 solver.cpp:244]     Train net output #1: loss = 0.27046 (* 1 = 0.27046 loss)
I0814 10:31:23.940078 21738 sgd_solver.cpp:106] Iteration 23650, lr = 0.00402496
I0814 10:32:45.158233 21738 solver.cpp:337] Iteration 23700, Testing net (#0)
I0814 10:32:53.273905 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:32:53.273972 21738 solver.cpp:404]     Test net output #1: loss = 0.691724 (* 1 = 0.691724 loss)
I0814 10:32:55.039007 21738 solver.cpp:228] Iteration 23700, loss = 0.190904
I0814 10:32:55.039074 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:32:55.039088 21738 solver.cpp:244]     Train net output #1: loss = 0.190904 (* 1 = 0.190904 loss)
I0814 10:32:55.039103 21738 sgd_solver.cpp:106] Iteration 23700, lr = 0.00402048
I0814 10:34:17.875759 21738 solver.cpp:228] Iteration 23750, loss = 0.270952
I0814 10:34:17.875970 21738 solver.cpp:244]     Train net output #0: accuracy = 0.995
I0814 10:34:17.876051 21738 solver.cpp:244]     Train net output #1: loss = 0.270952 (* 1 = 0.270952 loss)
I0814 10:34:17.876085 21738 sgd_solver.cpp:106] Iteration 23750, lr = 0.00401601
I0814 10:35:38.120882 21738 solver.cpp:337] Iteration 23800, Testing net (#0)
I0814 10:35:46.082101 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:35:46.082165 21738 solver.cpp:404]     Test net output #1: loss = 0.689403 (* 1 = 0.689403 loss)
I0814 10:35:47.656090 21738 solver.cpp:228] Iteration 23800, loss = 0.190246
I0814 10:35:47.656141 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:35:47.656152 21738 solver.cpp:244]     Train net output #1: loss = 0.190246 (* 1 = 0.190246 loss)
I0814 10:35:47.656172 21738 sgd_solver.cpp:106] Iteration 23800, lr = 0.00401155
I0814 10:37:09.510785 21738 solver.cpp:228] Iteration 23850, loss = 0.270973
I0814 10:37:09.510947 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:37:09.510963 21738 solver.cpp:244]     Train net output #1: loss = 0.270973 (* 1 = 0.270973 loss)
I0814 10:37:09.510978 21738 sgd_solver.cpp:106] Iteration 23850, lr = 0.00400711
I0814 10:38:29.880674 21738 solver.cpp:337] Iteration 23900, Testing net (#0)
I0814 10:38:37.932446 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:38:37.932509 21738 solver.cpp:404]     Test net output #1: loss = 0.692108 (* 1 = 0.692108 loss)
I0814 10:38:39.504515 21738 solver.cpp:228] Iteration 23900, loss = 0.190998
I0814 10:38:39.504576 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:38:39.504590 21738 solver.cpp:244]     Train net output #1: loss = 0.190998 (* 1 = 0.190998 loss)
I0814 10:38:39.504603 21738 sgd_solver.cpp:106] Iteration 23900, lr = 0.00400267
I0814 10:40:01.667611 21738 solver.cpp:228] Iteration 23950, loss = 0.27013
I0814 10:40:01.667841 21738 solver.cpp:244]     Train net output #0: accuracy = 0.87
I0814 10:40:01.667889 21738 solver.cpp:244]     Train net output #1: loss = 0.27013 (* 1 = 0.27013 loss)
I0814 10:40:01.667908 21738 sgd_solver.cpp:106] Iteration 23950, lr = 0.00399825
I0814 10:41:21.577613 21738 solver.cpp:337] Iteration 24000, Testing net (#0)
I0814 10:41:29.516322 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:41:29.516387 21738 solver.cpp:404]     Test net output #1: loss = 0.690647 (* 1 = 0.690647 loss)
I0814 10:41:31.091859 21738 solver.cpp:228] Iteration 24000, loss = 0.190605
I0814 10:41:31.091917 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:41:31.091929 21738 solver.cpp:244]     Train net output #1: loss = 0.190605 (* 1 = 0.190605 loss)
I0814 10:41:31.091945 21738 sgd_solver.cpp:106] Iteration 24000, lr = 0.00399384
I0814 10:42:52.091059 21738 solver.cpp:228] Iteration 24050, loss = 0.270655
I0814 10:42:52.091248 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:42:52.091298 21738 solver.cpp:244]     Train net output #1: loss = 0.270655 (* 1 = 0.270655 loss)
I0814 10:42:52.091320 21738 sgd_solver.cpp:106] Iteration 24050, lr = 0.00398944
I0814 10:44:12.256964 21738 solver.cpp:337] Iteration 24100, Testing net (#0)
I0814 10:44:20.625344 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:44:20.625406 21738 solver.cpp:404]     Test net output #1: loss = 0.688972 (* 1 = 0.688972 loss)
I0814 10:44:22.200497 21738 solver.cpp:228] Iteration 24100, loss = 0.190139
I0814 10:44:22.200551 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:44:22.200563 21738 solver.cpp:244]     Train net output #1: loss = 0.190139 (* 1 = 0.190139 loss)
I0814 10:44:22.200580 21738 sgd_solver.cpp:106] Iteration 24100, lr = 0.00398505
I0814 10:45:42.243983 21738 solver.cpp:228] Iteration 24150, loss = 0.270748
I0814 10:45:42.244158 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:45:42.244174 21738 solver.cpp:244]     Train net output #1: loss = 0.270747 (* 1 = 0.270747 loss)
I0814 10:45:42.244189 21738 sgd_solver.cpp:106] Iteration 24150, lr = 0.00398068
I0814 10:47:00.481418 21738 solver.cpp:337] Iteration 24200, Testing net (#0)
I0814 10:47:08.812302 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:47:08.812376 21738 solver.cpp:404]     Test net output #1: loss = 0.690785 (* 1 = 0.690785 loss)
I0814 10:47:10.386831 21738 solver.cpp:228] Iteration 24200, loss = 0.190661
I0814 10:47:10.386884 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:47:10.386896 21738 solver.cpp:244]     Train net output #1: loss = 0.190661 (* 1 = 0.190661 loss)
I0814 10:47:10.386914 21738 sgd_solver.cpp:106] Iteration 24200, lr = 0.00397631
I0814 10:48:32.584945 21738 solver.cpp:228] Iteration 24250, loss = 0.270716
I0814 10:48:32.585178 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:48:32.585227 21738 solver.cpp:244]     Train net output #1: loss = 0.270716 (* 1 = 0.270716 loss)
I0814 10:48:32.585258 21738 sgd_solver.cpp:106] Iteration 24250, lr = 0.00397196
I0814 10:49:54.554683 21738 solver.cpp:337] Iteration 24300, Testing net (#0)
I0814 10:50:03.028120 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:50:03.028180 21738 solver.cpp:404]     Test net output #1: loss = 0.688774 (* 1 = 0.688774 loss)
I0814 10:50:04.597801 21738 solver.cpp:228] Iteration 24300, loss = 0.190113
I0814 10:50:04.597870 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:50:04.597883 21738 solver.cpp:244]     Train net output #1: loss = 0.190112 (* 1 = 0.190112 loss)
I0814 10:50:04.597898 21738 sgd_solver.cpp:106] Iteration 24300, lr = 0.00396761
I0814 10:51:25.777412 21738 solver.cpp:228] Iteration 24350, loss = 0.271065
I0814 10:51:25.777575 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:51:25.777591 21738 solver.cpp:244]     Train net output #1: loss = 0.271064 (* 1 = 0.271064 loss)
I0814 10:51:25.777606 21738 sgd_solver.cpp:106] Iteration 24350, lr = 0.00396328
I0814 10:52:46.547003 21738 solver.cpp:337] Iteration 24400, Testing net (#0)
I0814 10:52:54.661824 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:52:54.661890 21738 solver.cpp:404]     Test net output #1: loss = 0.688827 (* 1 = 0.688827 loss)
I0814 10:52:56.239001 21738 solver.cpp:228] Iteration 24400, loss = 0.190128
I0814 10:52:56.239055 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:52:56.239068 21738 solver.cpp:244]     Train net output #1: loss = 0.190128 (* 1 = 0.190128 loss)
I0814 10:52:56.239083 21738 sgd_solver.cpp:106] Iteration 24400, lr = 0.00395896
I0814 10:54:17.070478 21738 solver.cpp:228] Iteration 24450, loss = 0.270349
I0814 10:54:17.070638 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:54:17.070653 21738 solver.cpp:244]     Train net output #1: loss = 0.270349 (* 1 = 0.270349 loss)
I0814 10:54:17.070667 21738 sgd_solver.cpp:106] Iteration 24450, lr = 0.00395465
I0814 10:55:37.353654 21738 solver.cpp:337] Iteration 24500, Testing net (#0)
I0814 10:55:45.345717 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 10:55:45.345782 21738 solver.cpp:404]     Test net output #1: loss = 0.690452 (* 1 = 0.690452 loss)
I0814 10:55:46.918972 21738 solver.cpp:228] Iteration 24500, loss = 0.190567
I0814 10:55:46.919035 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 10:55:46.919049 21738 solver.cpp:244]     Train net output #1: loss = 0.190567 (* 1 = 0.190567 loss)
I0814 10:55:46.919064 21738 sgd_solver.cpp:106] Iteration 24500, lr = 0.00395035
I0814 10:57:09.162153 21738 solver.cpp:228] Iteration 24550, loss = 0.270953
I0814 10:57:09.162401 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 10:57:09.162458 21738 solver.cpp:244]     Train net output #1: loss = 0.270953 (* 1 = 0.270953 loss)
I0814 10:57:09.162493 21738 sgd_solver.cpp:106] Iteration 24550, lr = 0.00394606
I0814 10:58:29.823626 21738 solver.cpp:337] Iteration 24600, Testing net (#0)
I0814 10:58:38.210467 21738 solver.cpp:404]     Test net output #0: accuracy = 0.661
I0814 10:58:38.210530 21738 solver.cpp:404]     Test net output #1: loss = 0.688316 (* 1 = 0.688316 loss)
I0814 10:58:39.802986 21738 solver.cpp:228] Iteration 24600, loss = 0.190362
I0814 10:58:39.803051 21738 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0814 10:58:39.803063 21738 solver.cpp:244]     Train net output #1: loss = 0.190362 (* 1 = 0.190362 loss)
I0814 10:58:39.803076 21738 sgd_solver.cpp:106] Iteration 24600, lr = 0.00394178
I0814 11:00:00.293079 21738 solver.cpp:228] Iteration 24650, loss = 0.270612
I0814 11:00:00.293287 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:00:00.293349 21738 solver.cpp:244]     Train net output #1: loss = 0.270612 (* 1 = 0.270612 loss)
I0814 11:00:00.293375 21738 sgd_solver.cpp:106] Iteration 24650, lr = 0.00393752
I0814 11:01:21.080461 21738 solver.cpp:337] Iteration 24700, Testing net (#0)
I0814 11:01:29.067363 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:01:29.067422 21738 solver.cpp:404]     Test net output #1: loss = 0.689146 (* 1 = 0.689146 loss)
I0814 11:01:30.640911 21738 solver.cpp:228] Iteration 24700, loss = 0.190195
I0814 11:01:30.640971 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:01:30.640985 21738 solver.cpp:244]     Train net output #1: loss = 0.190195 (* 1 = 0.190195 loss)
I0814 11:01:30.640998 21738 sgd_solver.cpp:106] Iteration 24700, lr = 0.00393326
I0814 11:02:51.121758 21738 solver.cpp:228] Iteration 24750, loss = 0.270727
I0814 11:02:51.121954 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:02:51.122020 21738 solver.cpp:244]     Train net output #1: loss = 0.270727 (* 1 = 0.270727 loss)
I0814 11:02:51.122050 21738 sgd_solver.cpp:106] Iteration 24750, lr = 0.00392902
I0814 11:04:11.317154 21738 solver.cpp:337] Iteration 24800, Testing net (#0)
I0814 11:04:19.612704 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:04:19.612769 21738 solver.cpp:404]     Test net output #1: loss = 0.688638 (* 1 = 0.688638 loss)
I0814 11:04:21.231156 21738 solver.cpp:228] Iteration 24800, loss = 0.190096
I0814 11:04:21.231232 21738 solver.cpp:244]     Train net output #0: accuracy = 0.915
I0814 11:04:21.231246 21738 solver.cpp:244]     Train net output #1: loss = 0.190096 (* 1 = 0.190096 loss)
I0814 11:04:21.231261 21738 sgd_solver.cpp:106] Iteration 24800, lr = 0.00392478
I0814 11:05:42.216835 21738 solver.cpp:228] Iteration 24850, loss = 0.270504
I0814 11:05:42.216984 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:05:42.217000 21738 solver.cpp:244]     Train net output #1: loss = 0.270504 (* 1 = 0.270504 loss)
I0814 11:05:42.217015 21738 sgd_solver.cpp:106] Iteration 24850, lr = 0.00392056
I0814 11:07:01.526567 21738 solver.cpp:337] Iteration 24900, Testing net (#0)
I0814 11:07:09.494820 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:07:09.494877 21738 solver.cpp:404]     Test net output #1: loss = 0.691562 (* 1 = 0.691562 loss)
I0814 11:07:11.094100 21738 solver.cpp:228] Iteration 24900, loss = 0.190854
I0814 11:07:11.094156 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:07:11.094169 21738 solver.cpp:244]     Train net output #1: loss = 0.190854 (* 1 = 0.190854 loss)
I0814 11:07:11.094182 21738 sgd_solver.cpp:106] Iteration 24900, lr = 0.00391634
I0814 11:08:34.440160 21738 solver.cpp:228] Iteration 24950, loss = 0.270182
I0814 11:08:34.440352 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:08:34.440368 21738 solver.cpp:244]     Train net output #1: loss = 0.270182 (* 1 = 0.270182 loss)
I0814 11:08:34.440382 21738 sgd_solver.cpp:106] Iteration 24950, lr = 0.00391214
I0814 11:09:54.423643 21738 solver.cpp:337] Iteration 25000, Testing net (#0)
I0814 11:10:02.654690 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:10:02.654749 21738 solver.cpp:404]     Test net output #1: loss = 0.689354 (* 1 = 0.689354 loss)
I0814 11:10:04.263025 21738 solver.cpp:228] Iteration 25000, loss = 0.19026
I0814 11:10:04.263073 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:10:04.263085 21738 solver.cpp:244]     Train net output #1: loss = 0.19026 (* 1 = 0.19026 loss)
I0814 11:10:04.263103 21738 sgd_solver.cpp:106] Iteration 25000, lr = 0.00390795
I0814 11:11:25.958744 21738 solver.cpp:228] Iteration 25050, loss = 0.270181
I0814 11:11:25.958891 21738 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0814 11:11:25.958906 21738 solver.cpp:244]     Train net output #1: loss = 0.27018 (* 1 = 0.27018 loss)
I0814 11:11:25.958919 21738 sgd_solver.cpp:106] Iteration 25050, lr = 0.00390377
I0814 11:12:46.488525 21738 solver.cpp:337] Iteration 25100, Testing net (#0)
I0814 11:12:54.591157 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:12:54.591213 21738 solver.cpp:404]     Test net output #1: loss = 0.688804 (* 1 = 0.688804 loss)
I0814 11:12:56.187132 21738 solver.cpp:228] Iteration 25100, loss = 0.190121
I0814 11:12:56.187180 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:12:56.187192 21738 solver.cpp:244]     Train net output #1: loss = 0.190121 (* 1 = 0.190121 loss)
I0814 11:12:56.187208 21738 sgd_solver.cpp:106] Iteration 25100, lr = 0.0038996
I0814 11:14:17.135710 21738 solver.cpp:228] Iteration 25150, loss = 0.270951
I0814 11:14:17.135875 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:14:17.135892 21738 solver.cpp:244]     Train net output #1: loss = 0.270951 (* 1 = 0.270951 loss)
I0814 11:14:17.135905 21738 sgd_solver.cpp:106] Iteration 25150, lr = 0.00389544
I0814 11:15:37.094748 21738 solver.cpp:337] Iteration 25200, Testing net (#0)
I0814 11:15:45.812933 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:15:45.812994 21738 solver.cpp:404]     Test net output #1: loss = 0.690181 (* 1 = 0.690181 loss)
I0814 11:15:47.409878 21738 solver.cpp:228] Iteration 25200, loss = 0.190498
I0814 11:15:47.409942 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:15:47.409955 21738 solver.cpp:244]     Train net output #1: loss = 0.190498 (* 1 = 0.190498 loss)
I0814 11:15:47.409970 21738 sgd_solver.cpp:106] Iteration 25200, lr = 0.00389128
I0814 11:17:08.561867 21738 solver.cpp:228] Iteration 25250, loss = 0.270853
I0814 11:17:08.562079 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:17:08.562146 21738 solver.cpp:244]     Train net output #1: loss = 0.270853 (* 1 = 0.270853 loss)
I0814 11:17:08.562191 21738 sgd_solver.cpp:106] Iteration 25250, lr = 0.00388714
I0814 11:18:28.525101 21738 solver.cpp:337] Iteration 25300, Testing net (#0)
I0814 11:18:36.622275 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:18:36.622334 21738 solver.cpp:404]     Test net output #1: loss = 0.689234 (* 1 = 0.689234 loss)
I0814 11:18:38.217188 21738 solver.cpp:228] Iteration 25300, loss = 0.190235
I0814 11:18:38.217264 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:18:38.217278 21738 solver.cpp:244]     Train net output #1: loss = 0.190235 (* 1 = 0.190235 loss)
I0814 11:18:38.217291 21738 sgd_solver.cpp:106] Iteration 25300, lr = 0.00388301
I0814 11:19:59.722789 21738 solver.cpp:228] Iteration 25350, loss = 0.270459
I0814 11:19:59.722981 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:19:59.723001 21738 solver.cpp:244]     Train net output #1: loss = 0.270458 (* 1 = 0.270458 loss)
I0814 11:19:59.723013 21738 sgd_solver.cpp:106] Iteration 25350, lr = 0.00387889
I0814 11:21:19.363106 21738 solver.cpp:337] Iteration 25400, Testing net (#0)
I0814 11:21:27.436522 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:21:27.436584 21738 solver.cpp:404]     Test net output #1: loss = 0.689423 (* 1 = 0.689423 loss)
I0814 11:21:29.030006 21738 solver.cpp:228] Iteration 25400, loss = 0.190286
I0814 11:21:29.030071 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:21:29.030084 21738 solver.cpp:244]     Train net output #1: loss = 0.190286 (* 1 = 0.190286 loss)
I0814 11:21:29.030098 21738 sgd_solver.cpp:106] Iteration 25400, lr = 0.00387478
I0814 11:22:50.539577 21738 solver.cpp:228] Iteration 25450, loss = 0.27042
I0814 11:22:50.539741 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:22:50.539757 21738 solver.cpp:244]     Train net output #1: loss = 0.27042 (* 1 = 0.27042 loss)
I0814 11:22:50.539772 21738 sgd_solver.cpp:106] Iteration 25450, lr = 0.00387068
I0814 11:24:10.524761 21738 solver.cpp:337] Iteration 25500, Testing net (#0)
I0814 11:24:18.836870 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:24:18.836932 21738 solver.cpp:404]     Test net output #1: loss = 0.690436 (* 1 = 0.690436 loss)
I0814 11:24:20.464388 21738 solver.cpp:228] Iteration 25500, loss = 0.190569
I0814 11:24:20.464437 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:24:20.464447 21738 solver.cpp:244]     Train net output #1: loss = 0.190569 (* 1 = 0.190569 loss)
I0814 11:24:20.464464 21738 sgd_solver.cpp:106] Iteration 25500, lr = 0.0038666
I0814 11:25:42.609381 21738 solver.cpp:228] Iteration 25550, loss = 0.270366
I0814 11:25:42.609534 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:25:42.609547 21738 solver.cpp:244]     Train net output #1: loss = 0.270366 (* 1 = 0.270366 loss)
I0814 11:25:42.609558 21738 sgd_solver.cpp:106] Iteration 25550, lr = 0.00386252
I0814 11:27:02.096935 21738 solver.cpp:337] Iteration 25600, Testing net (#0)
I0814 11:27:10.711495 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:27:10.711557 21738 solver.cpp:404]     Test net output #1: loss = 0.688531 (* 1 = 0.688531 loss)
I0814 11:27:12.316669 21738 solver.cpp:228] Iteration 25600, loss = 0.190085
I0814 11:27:12.316732 21738 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0814 11:27:12.316747 21738 solver.cpp:244]     Train net output #1: loss = 0.190085 (* 1 = 0.190085 loss)
I0814 11:27:12.316763 21738 sgd_solver.cpp:106] Iteration 25600, lr = 0.00385845
I0814 11:28:33.404047 21738 solver.cpp:228] Iteration 25650, loss = 0.270874
I0814 11:28:33.404264 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 11:28:33.404322 21738 solver.cpp:244]     Train net output #1: loss = 0.270874 (* 1 = 0.270874 loss)
I0814 11:28:33.404356 21738 sgd_solver.cpp:106] Iteration 25650, lr = 0.00385439
I0814 11:29:54.365648 21738 solver.cpp:337] Iteration 25700, Testing net (#0)
I0814 11:30:02.625005 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:30:02.625061 21738 solver.cpp:404]     Test net output #1: loss = 0.689691 (* 1 = 0.689691 loss)
I0814 11:30:04.214416 21738 solver.cpp:228] Iteration 25700, loss = 0.190366
I0814 11:30:04.214464 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:30:04.214476 21738 solver.cpp:244]     Train net output #1: loss = 0.190366 (* 1 = 0.190366 loss)
I0814 11:30:04.214490 21738 sgd_solver.cpp:106] Iteration 25700, lr = 0.00385034
I0814 11:31:26.247083 21738 solver.cpp:228] Iteration 25750, loss = 0.271191
I0814 11:31:26.247248 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 11:31:26.247263 21738 solver.cpp:244]     Train net output #1: loss = 0.271191 (* 1 = 0.271191 loss)
I0814 11:31:26.247277 21738 sgd_solver.cpp:106] Iteration 25750, lr = 0.0038463
I0814 11:32:45.601339 21738 solver.cpp:337] Iteration 25800, Testing net (#0)
I0814 11:32:53.620641 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:32:53.620700 21738 solver.cpp:404]     Test net output #1: loss = 0.690632 (* 1 = 0.690632 loss)
I0814 11:32:55.208699 21738 solver.cpp:228] Iteration 25800, loss = 0.190627
I0814 11:32:55.208748 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:32:55.208760 21738 solver.cpp:244]     Train net output #1: loss = 0.190627 (* 1 = 0.190627 loss)
I0814 11:32:55.208775 21738 sgd_solver.cpp:106] Iteration 25800, lr = 0.00384227
I0814 11:34:16.492774 21738 solver.cpp:228] Iteration 25850, loss = 0.270209
I0814 11:34:16.493033 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:34:16.493093 21738 solver.cpp:244]     Train net output #1: loss = 0.270209 (* 1 = 0.270209 loss)
I0814 11:34:16.493124 21738 sgd_solver.cpp:106] Iteration 25850, lr = 0.00383825
I0814 11:35:36.050796 21738 solver.cpp:337] Iteration 25900, Testing net (#0)
I0814 11:35:44.505467 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:35:44.505527 21738 solver.cpp:404]     Test net output #1: loss = 0.691119 (* 1 = 0.691119 loss)
I0814 11:35:46.103307 21738 solver.cpp:228] Iteration 25900, loss = 0.190756
I0814 11:35:46.103355 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:35:46.103368 21738 solver.cpp:244]     Train net output #1: loss = 0.190756 (* 1 = 0.190756 loss)
I0814 11:35:46.103382 21738 sgd_solver.cpp:106] Iteration 25900, lr = 0.00383424
I0814 11:37:06.779566 21738 solver.cpp:228] Iteration 25950, loss = 0.270492
I0814 11:37:06.779783 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:37:06.779839 21738 solver.cpp:244]     Train net output #1: loss = 0.270491 (* 1 = 0.270491 loss)
I0814 11:37:06.779881 21738 sgd_solver.cpp:106] Iteration 25950, lr = 0.00383024
I0814 11:38:28.804159 21738 solver.cpp:337] Iteration 26000, Testing net (#0)
I0814 11:38:36.886215 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:38:36.886273 21738 solver.cpp:404]     Test net output #1: loss = 0.692049 (* 1 = 0.692049 loss)
I0814 11:38:38.496345 21738 solver.cpp:228] Iteration 26000, loss = 0.191017
I0814 11:38:38.496408 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:38:38.496420 21738 solver.cpp:244]     Train net output #1: loss = 0.191017 (* 1 = 0.191017 loss)
I0814 11:38:38.496433 21738 sgd_solver.cpp:106] Iteration 26000, lr = 0.00382625
I0814 11:39:59.950997 21738 solver.cpp:228] Iteration 26050, loss = 0.27026
I0814 11:39:59.951159 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:39:59.951174 21738 solver.cpp:244]     Train net output #1: loss = 0.27026 (* 1 = 0.27026 loss)
I0814 11:39:59.951184 21738 sgd_solver.cpp:106] Iteration 26050, lr = 0.00382227
I0814 11:41:19.742065 21738 solver.cpp:337] Iteration 26100, Testing net (#0)
I0814 11:41:28.161278 21738 solver.cpp:404]     Test net output #0: accuracy = 1
I0814 11:41:28.161339 21738 solver.cpp:404]     Test net output #1: loss = 0.688359 (* 1 = 0.688359 loss)
I0814 11:41:29.768120 21738 solver.cpp:228] Iteration 26100, loss = 0.191697
I0814 11:41:29.768167 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 11:41:29.768179 21738 solver.cpp:244]     Train net output #1: loss = 0.191697 (* 1 = 0.191697 loss)
I0814 11:41:29.768194 21738 sgd_solver.cpp:106] Iteration 26100, lr = 0.0038183
I0814 11:42:50.978000 21738 solver.cpp:228] Iteration 26150, loss = 0.270779
I0814 11:42:50.978168 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:42:50.978183 21738 solver.cpp:244]     Train net output #1: loss = 0.270779 (* 1 = 0.270779 loss)
I0814 11:42:50.978196 21738 sgd_solver.cpp:106] Iteration 26150, lr = 0.00381433
I0814 11:44:10.637079 21738 solver.cpp:337] Iteration 26200, Testing net (#0)
I0814 11:44:18.766108 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:44:18.766170 21738 solver.cpp:404]     Test net output #1: loss = 0.690671 (* 1 = 0.690671 loss)
I0814 11:44:20.355821 21738 solver.cpp:228] Iteration 26200, loss = 0.190609
I0814 11:44:20.355871 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:44:20.355886 21738 solver.cpp:244]     Train net output #1: loss = 0.190608 (* 1 = 0.190608 loss)
I0814 11:44:20.355902 21738 sgd_solver.cpp:106] Iteration 26200, lr = 0.00381038
I0814 11:45:42.589853 21738 solver.cpp:228] Iteration 26250, loss = 0.270292
I0814 11:45:42.590116 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:45:42.590132 21738 solver.cpp:244]     Train net output #1: loss = 0.270292 (* 1 = 0.270292 loss)
I0814 11:45:42.590148 21738 sgd_solver.cpp:106] Iteration 26250, lr = 0.00380644
I0814 11:47:02.264979 21738 solver.cpp:337] Iteration 26300, Testing net (#0)
I0814 11:47:10.625610 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:47:10.625671 21738 solver.cpp:404]     Test net output #1: loss = 0.68931 (* 1 = 0.68931 loss)
I0814 11:47:12.231031 21738 solver.cpp:228] Iteration 26300, loss = 0.190245
I0814 11:47:12.231091 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:47:12.231104 21738 solver.cpp:244]     Train net output #1: loss = 0.190245 (* 1 = 0.190245 loss)
I0814 11:47:12.231118 21738 sgd_solver.cpp:106] Iteration 26300, lr = 0.00380251
I0814 11:48:33.639147 21738 solver.cpp:228] Iteration 26350, loss = 0.270489
I0814 11:48:33.639302 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:48:33.639317 21738 solver.cpp:244]     Train net output #1: loss = 0.270489 (* 1 = 0.270489 loss)
I0814 11:48:33.639328 21738 sgd_solver.cpp:106] Iteration 26350, lr = 0.00379858
I0814 11:49:53.833600 21738 solver.cpp:337] Iteration 26400, Testing net (#0)
I0814 11:50:02.203086 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:50:02.203155 21738 solver.cpp:404]     Test net output #1: loss = 0.691221 (* 1 = 0.691221 loss)
I0814 11:50:03.811797 21738 solver.cpp:228] Iteration 26400, loss = 0.19078
I0814 11:50:03.811857 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:50:03.811871 21738 solver.cpp:244]     Train net output #1: loss = 0.190779 (* 1 = 0.190779 loss)
I0814 11:50:03.811887 21738 sgd_solver.cpp:106] Iteration 26400, lr = 0.00379467
I0814 11:51:24.412282 21738 solver.cpp:228] Iteration 26450, loss = 0.270665
I0814 11:51:24.412433 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:51:24.412448 21738 solver.cpp:244]     Train net output #1: loss = 0.270664 (* 1 = 0.270664 loss)
I0814 11:51:24.412461 21738 sgd_solver.cpp:106] Iteration 26450, lr = 0.00379076
I0814 11:52:43.300233 21738 solver.cpp:337] Iteration 26500, Testing net (#0)
I0814 11:52:51.401832 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:52:51.401891 21738 solver.cpp:404]     Test net output #1: loss = 0.69216 (* 1 = 0.69216 loss)
I0814 11:52:52.974200 21738 solver.cpp:228] Iteration 26500, loss = 0.191053
I0814 11:52:52.974264 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:52:52.974277 21738 solver.cpp:244]     Train net output #1: loss = 0.191053 (* 1 = 0.191053 loss)
I0814 11:52:52.974290 21738 sgd_solver.cpp:106] Iteration 26500, lr = 0.00378687
I0814 11:54:13.035778 21738 solver.cpp:228] Iteration 26550, loss = 0.271783
I0814 11:54:13.035928 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:54:13.035943 21738 solver.cpp:244]     Train net output #1: loss = 0.271783 (* 1 = 0.271783 loss)
I0814 11:54:13.035954 21738 sgd_solver.cpp:106] Iteration 26550, lr = 0.00378298
I0814 11:55:31.653249 21738 solver.cpp:337] Iteration 26600, Testing net (#0)
I0814 11:55:39.789074 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:55:39.789134 21738 solver.cpp:404]     Test net output #1: loss = 0.690852 (* 1 = 0.690852 loss)
I0814 11:55:41.360756 21738 solver.cpp:228] Iteration 26600, loss = 0.190679
I0814 11:55:41.360821 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:55:41.360832 21738 solver.cpp:244]     Train net output #1: loss = 0.190679 (* 1 = 0.190679 loss)
I0814 11:55:41.360846 21738 sgd_solver.cpp:106] Iteration 26600, lr = 0.00377911
I0814 11:57:02.197295 21738 solver.cpp:228] Iteration 26650, loss = 0.270815
I0814 11:57:02.197537 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:57:02.197587 21738 solver.cpp:244]     Train net output #1: loss = 0.270815 (* 1 = 0.270815 loss)
I0814 11:57:02.197613 21738 sgd_solver.cpp:106] Iteration 26650, lr = 0.00377524
I0814 11:58:20.839102 21738 solver.cpp:337] Iteration 26700, Testing net (#0)
I0814 11:58:28.794401 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 11:58:28.794461 21738 solver.cpp:404]     Test net output #1: loss = 0.690947 (* 1 = 0.690947 loss)
I0814 11:58:30.369319 21738 solver.cpp:228] Iteration 26700, loss = 0.190701
I0814 11:58:30.369374 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 11:58:30.369386 21738 solver.cpp:244]     Train net output #1: loss = 0.190701 (* 1 = 0.190701 loss)
I0814 11:58:30.369401 21738 sgd_solver.cpp:106] Iteration 26700, lr = 0.00377138
I0814 11:59:50.371304 21738 solver.cpp:228] Iteration 26750, loss = 0.270609
I0814 11:59:50.371500 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 11:59:50.371553 21738 solver.cpp:244]     Train net output #1: loss = 0.270609 (* 1 = 0.270609 loss)
I0814 11:59:50.371573 21738 sgd_solver.cpp:106] Iteration 26750, lr = 0.00376753
I0814 12:01:08.979833 21738 solver.cpp:337] Iteration 26800, Testing net (#0)
I0814 12:01:17.286036 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:01:17.286098 21738 solver.cpp:404]     Test net output #1: loss = 0.695269 (* 1 = 0.695269 loss)
I0814 12:01:18.862815 21738 solver.cpp:228] Iteration 26800, loss = 0.191893
I0814 12:01:18.862879 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:01:18.862892 21738 solver.cpp:244]     Train net output #1: loss = 0.191893 (* 1 = 0.191893 loss)
I0814 12:01:18.862907 21738 sgd_solver.cpp:106] Iteration 26800, lr = 0.00376369
I0814 12:02:38.973182 21738 solver.cpp:228] Iteration 26850, loss = 0.270891
I0814 12:02:38.973330 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:02:38.973345 21738 solver.cpp:244]     Train net output #1: loss = 0.270891 (* 1 = 0.270891 loss)
I0814 12:02:38.973356 21738 sgd_solver.cpp:106] Iteration 26850, lr = 0.00375986
I0814 12:03:56.984167 21738 solver.cpp:337] Iteration 26900, Testing net (#0)
I0814 12:04:04.916409 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:04:04.916467 21738 solver.cpp:404]     Test net output #1: loss = 0.69026 (* 1 = 0.69026 loss)
I0814 12:04:06.492362 21738 solver.cpp:228] Iteration 26900, loss = 0.190525
I0814 12:04:06.492413 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:04:06.492424 21738 solver.cpp:244]     Train net output #1: loss = 0.190525 (* 1 = 0.190525 loss)
I0814 12:04:06.492440 21738 sgd_solver.cpp:106] Iteration 26900, lr = 0.00375604
I0814 12:05:26.755973 21738 solver.cpp:228] Iteration 26950, loss = 0.270122
I0814 12:05:26.756191 21738 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0814 12:05:26.756207 21738 solver.cpp:244]     Train net output #1: loss = 0.270122 (* 1 = 0.270122 loss)
I0814 12:05:26.756220 21738 sgd_solver.cpp:106] Iteration 26950, lr = 0.00375223
I0814 12:06:45.210938 21738 solver.cpp:337] Iteration 27000, Testing net (#0)
I0814 12:06:53.291842 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:06:53.291906 21738 solver.cpp:404]     Test net output #1: loss = 0.688753 (* 1 = 0.688753 loss)
I0814 12:06:54.868337 21738 solver.cpp:228] Iteration 27000, loss = 0.190094
I0814 12:06:54.868405 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:06:54.868418 21738 solver.cpp:244]     Train net output #1: loss = 0.190094 (* 1 = 0.190094 loss)
I0814 12:06:54.868435 21738 sgd_solver.cpp:106] Iteration 27000, lr = 0.00374842
I0814 12:08:14.981369 21738 solver.cpp:228] Iteration 27050, loss = 0.270178
I0814 12:08:14.981622 21738 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0814 12:08:14.981680 21738 solver.cpp:244]     Train net output #1: loss = 0.270178 (* 1 = 0.270178 loss)
I0814 12:08:14.981700 21738 sgd_solver.cpp:106] Iteration 27050, lr = 0.00374463
I0814 12:09:33.990424 21738 solver.cpp:337] Iteration 27100, Testing net (#0)
I0814 12:09:42.241601 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:09:42.241672 21738 solver.cpp:404]     Test net output #1: loss = 0.693352 (* 1 = 0.693352 loss)
I0814 12:09:43.818086 21738 solver.cpp:228] Iteration 27100, loss = 0.191377
I0814 12:09:43.818150 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:09:43.818164 21738 solver.cpp:244]     Train net output #1: loss = 0.191377 (* 1 = 0.191377 loss)
I0814 12:09:43.818178 21738 sgd_solver.cpp:106] Iteration 27100, lr = 0.00374084
I0814 12:11:04.191018 21738 solver.cpp:228] Iteration 27150, loss = 0.27133
I0814 12:11:04.191170 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:11:04.191186 21738 solver.cpp:244]     Train net output #1: loss = 0.271329 (* 1 = 0.271329 loss)
I0814 12:11:04.191200 21738 sgd_solver.cpp:106] Iteration 27150, lr = 0.00373707
I0814 12:12:23.003378 21738 solver.cpp:337] Iteration 27200, Testing net (#0)
I0814 12:12:31.091919 21738 solver.cpp:404]     Test net output #0: accuracy = 0.657
I0814 12:12:31.091977 21738 solver.cpp:404]     Test net output #1: loss = 0.688348 (* 1 = 0.688348 loss)
I0814 12:12:32.666810 21738 solver.cpp:228] Iteration 27200, loss = 0.190173
I0814 12:12:32.666880 21738 solver.cpp:244]     Train net output #0: accuracy = 0.945
I0814 12:12:32.666893 21738 solver.cpp:244]     Train net output #1: loss = 0.190173 (* 1 = 0.190173 loss)
I0814 12:12:32.666908 21738 sgd_solver.cpp:106] Iteration 27200, lr = 0.0037333
I0814 12:13:52.208225 21738 solver.cpp:228] Iteration 27250, loss = 0.271539
I0814 12:13:52.208375 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 12:13:52.208390 21738 solver.cpp:244]     Train net output #1: loss = 0.271539 (* 1 = 0.271539 loss)
I0814 12:13:52.208402 21738 sgd_solver.cpp:106] Iteration 27250, lr = 0.00372954
I0814 12:15:10.958865 21738 solver.cpp:337] Iteration 27300, Testing net (#0)
I0814 12:15:18.905299 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:15:18.905360 21738 solver.cpp:404]     Test net output #1: loss = 0.690555 (* 1 = 0.690555 loss)
I0814 12:15:20.497004 21738 solver.cpp:228] Iteration 27300, loss = 0.1906
I0814 12:15:20.497068 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:15:20.497082 21738 solver.cpp:244]     Train net output #1: loss = 0.1906 (* 1 = 0.1906 loss)
I0814 12:15:20.497097 21738 sgd_solver.cpp:106] Iteration 27300, lr = 0.00372579
I0814 12:16:40.897058 21738 solver.cpp:228] Iteration 27350, loss = 0.270551
I0814 12:16:40.897280 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:16:40.897338 21738 solver.cpp:244]     Train net output #1: loss = 0.270551 (* 1 = 0.270551 loss)
I0814 12:16:40.897367 21738 sgd_solver.cpp:106] Iteration 27350, lr = 0.00372205
I0814 12:17:59.781050 21738 solver.cpp:337] Iteration 27400, Testing net (#0)
I0814 12:18:07.966116 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:18:07.966187 21738 solver.cpp:404]     Test net output #1: loss = 0.691671 (* 1 = 0.691671 loss)
I0814 12:18:09.547188 21738 solver.cpp:228] Iteration 27400, loss = 0.190906
I0814 12:18:09.547250 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:18:09.547261 21738 solver.cpp:244]     Train net output #1: loss = 0.190906 (* 1 = 0.190906 loss)
I0814 12:18:09.547276 21738 sgd_solver.cpp:106] Iteration 27400, lr = 0.00371832
I0814 12:19:30.130697 21738 solver.cpp:228] Iteration 27450, loss = 0.270113
I0814 12:19:30.130923 21738 solver.cpp:244]     Train net output #0: accuracy = 0.885
I0814 12:19:30.130976 21738 solver.cpp:244]     Train net output #1: loss = 0.270112 (* 1 = 0.270112 loss)
I0814 12:19:30.130996 21738 sgd_solver.cpp:106] Iteration 27450, lr = 0.00371459
I0814 12:20:48.424621 21738 solver.cpp:337] Iteration 27500, Testing net (#0)
I0814 12:20:56.632802 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:20:56.632861 21738 solver.cpp:404]     Test net output #1: loss = 0.688861 (* 1 = 0.688861 loss)
I0814 12:20:58.207947 21738 solver.cpp:228] Iteration 27500, loss = 0.190134
I0814 12:20:58.208011 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:20:58.208030 21738 solver.cpp:244]     Train net output #1: loss = 0.190133 (* 1 = 0.190133 loss)
I0814 12:20:58.208045 21738 sgd_solver.cpp:106] Iteration 27500, lr = 0.00371088
I0814 12:22:18.399426 21738 solver.cpp:228] Iteration 27550, loss = 0.271344
I0814 12:22:18.399616 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:22:18.399664 21738 solver.cpp:244]     Train net output #1: loss = 0.271344 (* 1 = 0.271344 loss)
I0814 12:22:18.399690 21738 sgd_solver.cpp:106] Iteration 27550, lr = 0.00370717
I0814 12:23:37.621875 21738 solver.cpp:337] Iteration 27600, Testing net (#0)
I0814 12:23:45.989248 21738 solver.cpp:404]     Test net output #0: accuracy = 0.977
I0814 12:23:45.989310 21738 solver.cpp:404]     Test net output #1: loss = 0.688201 (* 1 = 0.688201 loss)
I0814 12:23:47.564760 21738 solver.cpp:228] Iteration 27600, loss = 0.191253
I0814 12:23:47.564816 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 12:23:47.564827 21738 solver.cpp:244]     Train net output #1: loss = 0.191253 (* 1 = 0.191253 loss)
I0814 12:23:47.564842 21738 sgd_solver.cpp:106] Iteration 27600, lr = 0.00370347
I0814 12:25:07.704805 21738 solver.cpp:228] Iteration 27650, loss = 0.270977
I0814 12:25:07.705003 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:25:07.705075 21738 solver.cpp:244]     Train net output #1: loss = 0.270977 (* 1 = 0.270977 loss)
I0814 12:25:07.705118 21738 sgd_solver.cpp:106] Iteration 27650, lr = 0.00369978
I0814 12:26:26.014660 21738 solver.cpp:337] Iteration 27700, Testing net (#0)
I0814 12:26:33.951841 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:26:33.951901 21738 solver.cpp:404]     Test net output #1: loss = 0.689052 (* 1 = 0.689052 loss)
I0814 12:26:35.527092 21738 solver.cpp:228] Iteration 27700, loss = 0.190183
I0814 12:26:35.527143 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:26:35.527156 21738 solver.cpp:244]     Train net output #1: loss = 0.190183 (* 1 = 0.190183 loss)
I0814 12:26:35.527170 21738 sgd_solver.cpp:106] Iteration 27700, lr = 0.0036961
I0814 12:27:56.488747 21738 solver.cpp:228] Iteration 27750, loss = 0.270429
I0814 12:27:56.488935 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:27:56.488998 21738 solver.cpp:244]     Train net output #1: loss = 0.270429 (* 1 = 0.270429 loss)
I0814 12:27:56.489032 21738 sgd_solver.cpp:106] Iteration 27750, lr = 0.00369243
I0814 12:29:15.525426 21738 solver.cpp:337] Iteration 27800, Testing net (#0)
I0814 12:29:23.493589 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:29:23.493659 21738 solver.cpp:404]     Test net output #1: loss = 0.689481 (* 1 = 0.689481 loss)
I0814 12:29:25.070317 21738 solver.cpp:228] Iteration 27800, loss = 0.190308
I0814 12:29:25.070389 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:29:25.070401 21738 solver.cpp:244]     Train net output #1: loss = 0.190308 (* 1 = 0.190308 loss)
I0814 12:29:25.070415 21738 sgd_solver.cpp:106] Iteration 27800, lr = 0.00368877
I0814 12:30:44.916606 21738 solver.cpp:228] Iteration 27850, loss = 0.270494
I0814 12:30:44.916793 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:30:44.916846 21738 solver.cpp:244]     Train net output #1: loss = 0.270494 (* 1 = 0.270494 loss)
I0814 12:30:44.916873 21738 sgd_solver.cpp:106] Iteration 27850, lr = 0.00368511
I0814 12:32:03.516141 21738 solver.cpp:337] Iteration 27900, Testing net (#0)
I0814 12:32:12.063038 21738 solver.cpp:404]     Test net output #0: accuracy = 0.667
I0814 12:32:12.063103 21738 solver.cpp:404]     Test net output #1: loss = 0.688202 (* 1 = 0.688202 loss)
I0814 12:32:13.713984 21738 solver.cpp:228] Iteration 27900, loss = 0.190458
I0814 12:32:13.714061 21738 solver.cpp:244]     Train net output #0: accuracy = 0.985
I0814 12:32:13.714076 21738 solver.cpp:244]     Train net output #1: loss = 0.190458 (* 1 = 0.190458 loss)
I0814 12:32:13.714088 21738 sgd_solver.cpp:106] Iteration 27900, lr = 0.00368146
I0814 12:33:34.130553 21738 solver.cpp:228] Iteration 27950, loss = 0.270724
I0814 12:33:34.130782 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:33:34.130841 21738 solver.cpp:244]     Train net output #1: loss = 0.270723 (* 1 = 0.270723 loss)
I0814 12:33:34.130872 21738 sgd_solver.cpp:106] Iteration 27950, lr = 0.00367783
I0814 12:34:52.708192 21738 solver.cpp:337] Iteration 28000, Testing net (#0)
I0814 12:35:00.657095 21738 solver.cpp:404]     Test net output #0: accuracy = 0.696
I0814 12:35:00.657160 21738 solver.cpp:404]     Test net output #1: loss = 0.688137 (* 1 = 0.688137 loss)
I0814 12:35:02.232302 21738 solver.cpp:228] Iteration 28000, loss = 0.190572
I0814 12:35:02.232360 21738 solver.cpp:244]     Train net output #0: accuracy = 0.995
I0814 12:35:02.232372 21738 solver.cpp:244]     Train net output #1: loss = 0.190572 (* 1 = 0.190572 loss)
I0814 12:35:02.232386 21738 sgd_solver.cpp:106] Iteration 28000, lr = 0.0036742
I0814 12:36:23.420598 21738 solver.cpp:228] Iteration 28050, loss = 0.270421
I0814 12:36:23.420804 21738 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0814 12:36:23.420868 21738 solver.cpp:244]     Train net output #1: loss = 0.270421 (* 1 = 0.270421 loss)
I0814 12:36:23.420908 21738 sgd_solver.cpp:106] Iteration 28050, lr = 0.00367057
I0814 12:37:43.095602 21738 solver.cpp:337] Iteration 28100, Testing net (#0)
I0814 12:37:51.032850 21738 solver.cpp:404]     Test net output #0: accuracy = 0.922
I0814 12:37:51.032912 21738 solver.cpp:404]     Test net output #1: loss = 0.688121 (* 1 = 0.688121 loss)
I0814 12:37:52.608644 21738 solver.cpp:228] Iteration 28100, loss = 0.191038
I0814 12:37:52.608711 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 12:37:52.608723 21738 solver.cpp:244]     Train net output #1: loss = 0.191038 (* 1 = 0.191038 loss)
I0814 12:37:52.608737 21738 sgd_solver.cpp:106] Iteration 28100, lr = 0.00366696
I0814 12:39:13.470111 21738 solver.cpp:228] Iteration 28150, loss = 0.271854
I0814 12:39:13.470348 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 12:39:13.470402 21738 solver.cpp:244]     Train net output #1: loss = 0.271853 (* 1 = 0.271853 loss)
I0814 12:39:13.470424 21738 sgd_solver.cpp:106] Iteration 28150, lr = 0.00366336
I0814 12:40:33.437075 21738 solver.cpp:337] Iteration 28200, Testing net (#0)
I0814 12:40:41.873276 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:40:41.873340 21738 solver.cpp:404]     Test net output #1: loss = 0.691142 (* 1 = 0.691142 loss)
I0814 12:40:43.488829 21738 solver.cpp:228] Iteration 28200, loss = 0.190766
I0814 12:40:43.488891 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:40:43.488904 21738 solver.cpp:244]     Train net output #1: loss = 0.190766 (* 1 = 0.190766 loss)
I0814 12:40:43.488917 21738 sgd_solver.cpp:106] Iteration 28200, lr = 0.00365976
I0814 12:42:06.230762 21738 solver.cpp:228] Iteration 28250, loss = 0.270721
I0814 12:42:06.230902 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:42:06.230916 21738 solver.cpp:244]     Train net output #1: loss = 0.270721 (* 1 = 0.270721 loss)
I0814 12:42:06.230927 21738 sgd_solver.cpp:106] Iteration 28250, lr = 0.00365617
I0814 12:43:25.276118 21738 solver.cpp:337] Iteration 28300, Testing net (#0)
I0814 12:43:33.509310 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:43:33.509371 21738 solver.cpp:404]     Test net output #1: loss = 0.690364 (* 1 = 0.690364 loss)
I0814 12:43:35.088930 21738 solver.cpp:228] Iteration 28300, loss = 0.190559
I0814 12:43:35.088997 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:43:35.089010 21738 solver.cpp:244]     Train net output #1: loss = 0.190559 (* 1 = 0.190559 loss)
I0814 12:43:35.089025 21738 sgd_solver.cpp:106] Iteration 28300, lr = 0.00365259
I0814 12:44:55.240881 21738 solver.cpp:228] Iteration 28350, loss = 0.270343
I0814 12:44:55.241160 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:44:55.241230 21738 solver.cpp:244]     Train net output #1: loss = 0.270343 (* 1 = 0.270343 loss)
I0814 12:44:55.241276 21738 sgd_solver.cpp:106] Iteration 28350, lr = 0.00364902
I0814 12:46:15.265955 21738 solver.cpp:337] Iteration 28400, Testing net (#0)
I0814 12:46:23.598985 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:46:23.599050 21738 solver.cpp:404]     Test net output #1: loss = 0.689404 (* 1 = 0.689404 loss)
I0814 12:46:25.174518 21738 solver.cpp:228] Iteration 28400, loss = 0.190291
I0814 12:46:25.174579 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:46:25.174592 21738 solver.cpp:244]     Train net output #1: loss = 0.190291 (* 1 = 0.190291 loss)
I0814 12:46:25.174607 21738 sgd_solver.cpp:106] Iteration 28400, lr = 0.00364545
I0814 12:47:48.136945 21738 solver.cpp:228] Iteration 28450, loss = 0.27108
I0814 12:47:48.137138 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:47:48.137207 21738 solver.cpp:244]     Train net output #1: loss = 0.27108 (* 1 = 0.27108 loss)
I0814 12:47:48.137244 21738 sgd_solver.cpp:106] Iteration 28450, lr = 0.0036419
I0814 12:49:08.662447 21738 solver.cpp:337] Iteration 28500, Testing net (#0)
I0814 12:49:16.935988 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:49:16.936056 21738 solver.cpp:404]     Test net output #1: loss = 0.690399 (* 1 = 0.690399 loss)
I0814 12:49:18.744951 21738 solver.cpp:228] Iteration 28500, loss = 0.190572
I0814 12:49:18.745019 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:49:18.745033 21738 solver.cpp:244]     Train net output #1: loss = 0.190572 (* 1 = 0.190572 loss)
I0814 12:49:18.745048 21738 sgd_solver.cpp:106] Iteration 28500, lr = 0.00363835
I0814 12:50:40.759022 21738 solver.cpp:228] Iteration 28550, loss = 0.270586
I0814 12:50:40.759217 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:50:40.759268 21738 solver.cpp:244]     Train net output #1: loss = 0.270586 (* 1 = 0.270586 loss)
I0814 12:50:40.759291 21738 sgd_solver.cpp:106] Iteration 28550, lr = 0.00363481
I0814 12:52:01.239277 21738 solver.cpp:337] Iteration 28600, Testing net (#0)
I0814 12:52:09.712934 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:52:09.712991 21738 solver.cpp:404]     Test net output #1: loss = 0.690736 (* 1 = 0.690736 loss)
I0814 12:52:11.397573 21738 solver.cpp:228] Iteration 28600, loss = 0.190669
I0814 12:52:11.397645 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:52:11.397660 21738 solver.cpp:244]     Train net output #1: loss = 0.190669 (* 1 = 0.190669 loss)
I0814 12:52:11.397675 21738 sgd_solver.cpp:106] Iteration 28600, lr = 0.00363128
I0814 12:53:33.441165 21738 solver.cpp:228] Iteration 28650, loss = 0.27044
I0814 12:53:33.441328 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:53:33.441341 21738 solver.cpp:244]     Train net output #1: loss = 0.27044 (* 1 = 0.27044 loss)
I0814 12:53:33.441355 21738 sgd_solver.cpp:106] Iteration 28650, lr = 0.00362775
I0814 12:54:53.399608 21738 solver.cpp:337] Iteration 28700, Testing net (#0)
I0814 12:55:01.549499 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:55:01.549557 21738 solver.cpp:404]     Test net output #1: loss = 0.689121 (* 1 = 0.689121 loss)
I0814 12:55:03.158789 21738 solver.cpp:228] Iteration 28700, loss = 0.190218
I0814 12:55:03.158839 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:55:03.158852 21738 solver.cpp:244]     Train net output #1: loss = 0.190218 (* 1 = 0.190218 loss)
I0814 12:55:03.158862 21738 sgd_solver.cpp:106] Iteration 28700, lr = 0.00362424
I0814 12:56:25.955651 21738 solver.cpp:228] Iteration 28750, loss = 0.270682
I0814 12:56:25.955795 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 12:56:25.955808 21738 solver.cpp:244]     Train net output #1: loss = 0.270682 (* 1 = 0.270682 loss)
I0814 12:56:25.955821 21738 sgd_solver.cpp:106] Iteration 28750, lr = 0.00362073
I0814 12:57:49.143260 21738 solver.cpp:337] Iteration 28800, Testing net (#0)
I0814 12:57:58.056011 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 12:57:58.056069 21738 solver.cpp:404]     Test net output #1: loss = 0.692133 (* 1 = 0.692133 loss)
I0814 12:57:59.719463 21738 solver.cpp:228] Iteration 28800, loss = 0.191039
I0814 12:57:59.719517 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 12:57:59.719529 21738 solver.cpp:244]     Train net output #1: loss = 0.191039 (* 1 = 0.191039 loss)
I0814 12:57:59.719542 21738 sgd_solver.cpp:106] Iteration 28800, lr = 0.00361723
I0814 12:59:24.602466 21738 solver.cpp:228] Iteration 28850, loss = 0.270112
I0814 12:59:24.602627 21738 solver.cpp:244]     Train net output #0: accuracy = 0.87
I0814 12:59:24.602641 21738 solver.cpp:244]     Train net output #1: loss = 0.270111 (* 1 = 0.270111 loss)
I0814 12:59:24.602653 21738 sgd_solver.cpp:106] Iteration 28850, lr = 0.00361374
I0814 13:00:48.679191 21738 solver.cpp:337] Iteration 28900, Testing net (#0)
I0814 13:00:57.366264 21738 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0814 13:00:57.366322 21738 solver.cpp:404]     Test net output #1: loss = 0.688096 (* 1 = 0.688096 loss)
I0814 13:00:59.150358 21738 solver.cpp:228] Iteration 28900, loss = 0.190656
I0814 13:00:59.150426 21738 solver.cpp:244]     Train net output #0: accuracy = 0.995
I0814 13:00:59.150440 21738 solver.cpp:244]     Train net output #1: loss = 0.190656 (* 1 = 0.190656 loss)
I0814 13:00:59.150454 21738 sgd_solver.cpp:106] Iteration 28900, lr = 0.00361025
I0814 13:02:25.750291 21738 solver.cpp:228] Iteration 28950, loss = 0.271262
I0814 13:02:25.750442 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:02:25.750458 21738 solver.cpp:244]     Train net output #1: loss = 0.271262 (* 1 = 0.271262 loss)
I0814 13:02:25.750473 21738 sgd_solver.cpp:106] Iteration 28950, lr = 0.00360678
I0814 13:03:50.075296 21738 solver.cpp:337] Iteration 29000, Testing net (#0)
I0814 13:03:58.476541 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:03:58.476594 21738 solver.cpp:404]     Test net output #1: loss = 0.688456 (* 1 = 0.688456 loss)
I0814 13:04:00.154050 21738 solver.cpp:228] Iteration 29000, loss = 0.190076
I0814 13:04:00.154112 21738 solver.cpp:244]     Train net output #0: accuracy = 0.935
I0814 13:04:00.154124 21738 solver.cpp:244]     Train net output #1: loss = 0.190076 (* 1 = 0.190076 loss)
I0814 13:04:00.154140 21738 sgd_solver.cpp:106] Iteration 29000, lr = 0.00360331
I0814 13:05:25.766444 21738 solver.cpp:228] Iteration 29050, loss = 0.271633
I0814 13:05:25.766578 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:05:25.766595 21738 solver.cpp:244]     Train net output #1: loss = 0.271632 (* 1 = 0.271632 loss)
I0814 13:05:25.766611 21738 sgd_solver.cpp:106] Iteration 29050, lr = 0.00359985
I0814 13:06:49.234210 21738 solver.cpp:337] Iteration 29100, Testing net (#0)
I0814 13:06:57.694924 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:06:57.694982 21738 solver.cpp:404]     Test net output #1: loss = 0.692089 (* 1 = 0.692089 loss)
I0814 13:06:59.380632 21738 solver.cpp:228] Iteration 29100, loss = 0.191046
I0814 13:06:59.380705 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 13:06:59.380719 21738 solver.cpp:244]     Train net output #1: loss = 0.191046 (* 1 = 0.191046 loss)
I0814 13:06:59.380733 21738 sgd_solver.cpp:106] Iteration 29100, lr = 0.0035964
I0814 13:08:23.182936 21738 solver.cpp:228] Iteration 29150, loss = 0.270785
I0814 13:08:23.183138 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:08:23.183182 21738 solver.cpp:244]     Train net output #1: loss = 0.270785 (* 1 = 0.270785 loss)
I0814 13:08:23.183212 21738 sgd_solver.cpp:106] Iteration 29150, lr = 0.00359295
I0814 13:09:44.119107 21738 solver.cpp:337] Iteration 29200, Testing net (#0)
I0814 13:09:52.421766 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:09:52.421820 21738 solver.cpp:404]     Test net output #1: loss = 0.688548 (* 1 = 0.688548 loss)
I0814 13:09:54.160220 21738 solver.cpp:228] Iteration 29200, loss = 0.190067
I0814 13:09:54.160275 21738 solver.cpp:244]     Train net output #0: accuracy = 0.915
I0814 13:09:54.160289 21738 solver.cpp:244]     Train net output #1: loss = 0.190067 (* 1 = 0.190067 loss)
I0814 13:09:54.160302 21738 sgd_solver.cpp:106] Iteration 29200, lr = 0.00358951
I0814 13:11:16.957516 21738 solver.cpp:228] Iteration 29250, loss = 0.271468
I0814 13:11:16.957667 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:11:16.957682 21738 solver.cpp:244]     Train net output #1: loss = 0.271467 (* 1 = 0.271467 loss)
I0814 13:11:16.957692 21738 sgd_solver.cpp:106] Iteration 29250, lr = 0.00358608
I0814 13:12:38.492349 21738 solver.cpp:337] Iteration 29300, Testing net (#0)
I0814 13:12:46.938045 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:12:46.938109 21738 solver.cpp:404]     Test net output #1: loss = 0.688408 (* 1 = 0.688408 loss)
I0814 13:12:48.572633 21738 solver.cpp:228] Iteration 29300, loss = 0.190094
I0814 13:12:48.572690 21738 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0814 13:12:48.572701 21738 solver.cpp:244]     Train net output #1: loss = 0.190094 (* 1 = 0.190094 loss)
I0814 13:12:48.572715 21738 sgd_solver.cpp:106] Iteration 29300, lr = 0.00358266
I0814 13:14:10.215862 21738 solver.cpp:228] Iteration 29350, loss = 0.270849
I0814 13:14:10.216008 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:14:10.216054 21738 solver.cpp:244]     Train net output #1: loss = 0.270849 (* 1 = 0.270849 loss)
I0814 13:14:10.216073 21738 sgd_solver.cpp:106] Iteration 29350, lr = 0.00357925
I0814 13:15:30.313403 21738 solver.cpp:337] Iteration 29400, Testing net (#0)
I0814 13:15:38.839237 21738 solver.cpp:404]     Test net output #0: accuracy = 0.677
I0814 13:15:38.839298 21738 solver.cpp:404]     Test net output #1: loss = 0.688143 (* 1 = 0.688143 loss)
I0814 13:15:40.592993 21738 solver.cpp:228] Iteration 29400, loss = 0.190406
I0814 13:15:40.593065 21738 solver.cpp:244]     Train net output #0: accuracy = 0.985
I0814 13:15:40.593082 21738 solver.cpp:244]     Train net output #1: loss = 0.190406 (* 1 = 0.190406 loss)
I0814 13:15:40.593101 21738 sgd_solver.cpp:106] Iteration 29400, lr = 0.00357584
I0814 13:17:03.151965 21738 solver.cpp:228] Iteration 29450, loss = 0.270536
I0814 13:17:03.152143 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:17:03.152176 21738 solver.cpp:244]     Train net output #1: loss = 0.270536 (* 1 = 0.270536 loss)
I0814 13:17:03.152194 21738 sgd_solver.cpp:106] Iteration 29450, lr = 0.00357244
I0814 13:18:24.060649 21738 solver.cpp:337] Iteration 29500, Testing net (#0)
I0814 13:18:32.712733 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:18:32.712790 21738 solver.cpp:404]     Test net output #1: loss = 0.691897 (* 1 = 0.691897 loss)
I0814 13:18:34.339362 21738 solver.cpp:228] Iteration 29500, loss = 0.190988
I0814 13:18:34.339426 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 13:18:34.339443 21738 solver.cpp:244]     Train net output #1: loss = 0.190988 (* 1 = 0.190988 loss)
I0814 13:18:34.339458 21738 sgd_solver.cpp:106] Iteration 29500, lr = 0.00356905
I0814 13:19:56.914707 21738 solver.cpp:228] Iteration 29550, loss = 0.270934
I0814 13:19:56.914988 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:19:56.915006 21738 solver.cpp:244]     Train net output #1: loss = 0.270934 (* 1 = 0.270934 loss)
I0814 13:19:56.915019 21738 sgd_solver.cpp:106] Iteration 29550, lr = 0.00356566
I0814 13:21:17.276051 21738 solver.cpp:337] Iteration 29600, Testing net (#0)
I0814 13:21:25.718279 21738 solver.cpp:404]     Test net output #0: accuracy = 1
I0814 13:21:25.718334 21738 solver.cpp:404]     Test net output #1: loss = 0.688397 (* 1 = 0.688397 loss)
I0814 13:21:27.378345 21738 solver.cpp:228] Iteration 29600, loss = 0.191685
I0814 13:21:27.378393 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:21:27.378406 21738 solver.cpp:244]     Train net output #1: loss = 0.191685 (* 1 = 0.191685 loss)
I0814 13:21:27.378422 21738 sgd_solver.cpp:106] Iteration 29600, lr = 0.00356228
I0814 13:22:49.429860 21738 solver.cpp:228] Iteration 29650, loss = 0.271399
I0814 13:22:49.429994 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:22:49.430009 21738 solver.cpp:244]     Train net output #1: loss = 0.271399 (* 1 = 0.271399 loss)
I0814 13:22:49.430022 21738 sgd_solver.cpp:106] Iteration 29650, lr = 0.00355891
I0814 13:24:10.122220 21738 solver.cpp:337] Iteration 29700, Testing net (#0)
I0814 13:24:18.553127 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:24:18.553184 21738 solver.cpp:404]     Test net output #1: loss = 0.689053 (* 1 = 0.689053 loss)
I0814 13:24:20.300730 21738 solver.cpp:228] Iteration 29700, loss = 0.190197
I0814 13:24:20.300801 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 13:24:20.300814 21738 solver.cpp:244]     Train net output #1: loss = 0.190197 (* 1 = 0.190197 loss)
I0814 13:24:20.300828 21738 sgd_solver.cpp:106] Iteration 29700, lr = 0.00355555
I0814 13:25:42.066290 21738 solver.cpp:228] Iteration 29750, loss = 0.270287
I0814 13:25:42.066447 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:25:42.066460 21738 solver.cpp:244]     Train net output #1: loss = 0.270287 (* 1 = 0.270287 loss)
I0814 13:25:42.066471 21738 sgd_solver.cpp:106] Iteration 29750, lr = 0.0035522
I0814 13:27:02.612845 21738 solver.cpp:337] Iteration 29800, Testing net (#0)
I0814 13:27:10.968435 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:27:10.968492 21738 solver.cpp:404]     Test net output #1: loss = 0.688831 (* 1 = 0.688831 loss)
I0814 13:27:12.646529 21738 solver.cpp:228] Iteration 29800, loss = 0.19014
I0814 13:27:12.646575 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 13:27:12.646586 21738 solver.cpp:244]     Train net output #1: loss = 0.19014 (* 1 = 0.19014 loss)
I0814 13:27:12.646611 21738 sgd_solver.cpp:106] Iteration 29800, lr = 0.00354885
I0814 13:28:35.431376 21738 solver.cpp:228] Iteration 29850, loss = 0.270783
I0814 13:28:35.431596 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:28:35.431650 21738 solver.cpp:244]     Train net output #1: loss = 0.270782 (* 1 = 0.270782 loss)
I0814 13:28:35.431684 21738 sgd_solver.cpp:106] Iteration 29850, lr = 0.00354551
I0814 13:29:56.771507 21738 solver.cpp:337] Iteration 29900, Testing net (#0)
I0814 13:30:05.127841 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:30:05.127894 21738 solver.cpp:404]     Test net output #1: loss = 0.693087 (* 1 = 0.693087 loss)
I0814 13:30:06.860350 21738 solver.cpp:228] Iteration 29900, loss = 0.191311
I0814 13:30:06.860411 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 13:30:06.860425 21738 solver.cpp:244]     Train net output #1: loss = 0.191311 (* 1 = 0.191311 loss)
I0814 13:30:06.860440 21738 sgd_solver.cpp:106] Iteration 29900, lr = 0.00354218
I0814 13:31:28.499797 21738 solver.cpp:228] Iteration 29950, loss = 0.270456
I0814 13:31:28.500049 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:31:28.500089 21738 solver.cpp:244]     Train net output #1: loss = 0.270455 (* 1 = 0.270455 loss)
I0814 13:31:28.500104 21738 sgd_solver.cpp:106] Iteration 29950, lr = 0.00353885
I0814 13:32:48.922216 21738 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_met_iter_30000.caffemodel
I0814 13:32:49.322994 21738 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_met_iter_30000.solverstate
I0814 13:32:49.337453 21738 solver.cpp:337] Iteration 30000, Testing net (#0)
I0814 13:32:58.068447 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:32:58.068505 21738 solver.cpp:404]     Test net output #1: loss = 0.688616 (* 1 = 0.688616 loss)
I0814 13:32:59.878500 21738 solver.cpp:228] Iteration 30000, loss = 0.190093
I0814 13:32:59.878569 21738 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0814 13:32:59.878582 21738 solver.cpp:244]     Train net output #1: loss = 0.190093 (* 1 = 0.190093 loss)
I0814 13:32:59.878597 21738 sgd_solver.cpp:106] Iteration 30000, lr = 0.00353553
I0814 13:34:23.150154 21738 solver.cpp:228] Iteration 30050, loss = 0.27021
I0814 13:34:23.150403 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:34:23.150460 21738 solver.cpp:244]     Train net output #1: loss = 0.27021 (* 1 = 0.27021 loss)
I0814 13:34:23.150498 21738 sgd_solver.cpp:106] Iteration 30050, lr = 0.00353222
I0814 13:35:43.198705 21738 solver.cpp:337] Iteration 30100, Testing net (#0)
I0814 13:35:51.459964 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:35:51.460022 21738 solver.cpp:404]     Test net output #1: loss = 0.688437 (* 1 = 0.688437 loss)
I0814 13:35:53.087085 21738 solver.cpp:228] Iteration 30100, loss = 0.190069
I0814 13:35:53.087141 21738 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0814 13:35:53.087158 21738 solver.cpp:244]     Train net output #1: loss = 0.190069 (* 1 = 0.190069 loss)
I0814 13:35:53.087174 21738 sgd_solver.cpp:106] Iteration 30100, lr = 0.00352892
I0814 13:37:15.475878 21738 solver.cpp:228] Iteration 30150, loss = 0.270323
I0814 13:37:15.476049 21738 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0814 13:37:15.476071 21738 solver.cpp:244]     Train net output #1: loss = 0.270323 (* 1 = 0.270323 loss)
I0814 13:37:15.476090 21738 sgd_solver.cpp:106] Iteration 30150, lr = 0.00352562
I0814 13:38:36.544445 21738 solver.cpp:337] Iteration 30200, Testing net (#0)
I0814 13:38:44.740331 21738 solver.cpp:404]     Test net output #0: accuracy = 0.984
I0814 13:38:44.740383 21738 solver.cpp:404]     Test net output #1: loss = 0.688177 (* 1 = 0.688177 loss)
I0814 13:38:46.447046 21738 solver.cpp:228] Iteration 30200, loss = 0.191126
I0814 13:38:46.447106 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:38:46.447124 21738 solver.cpp:244]     Train net output #1: loss = 0.191126 (* 1 = 0.191126 loss)
I0814 13:38:46.447144 21738 sgd_solver.cpp:106] Iteration 30200, lr = 0.00352233
I0814 13:40:08.906394 21738 solver.cpp:228] Iteration 30250, loss = 0.270197
I0814 13:40:08.906584 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:40:08.906616 21738 solver.cpp:244]     Train net output #1: loss = 0.270197 (* 1 = 0.270197 loss)
I0814 13:40:08.906635 21738 sgd_solver.cpp:106] Iteration 30250, lr = 0.00351905
I0814 13:41:30.254636 21738 solver.cpp:337] Iteration 30300, Testing net (#0)
I0814 13:41:38.529295 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:41:38.529350 21738 solver.cpp:404]     Test net output #1: loss = 0.691569 (* 1 = 0.691569 loss)
I0814 13:41:40.134331 21738 solver.cpp:228] Iteration 30300, loss = 0.190899
I0814 13:41:40.134400 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 13:41:40.134413 21738 solver.cpp:244]     Train net output #1: loss = 0.190899 (* 1 = 0.190899 loss)
I0814 13:41:40.134426 21738 sgd_solver.cpp:106] Iteration 30300, lr = 0.00351578
I0814 13:43:02.783931 21738 solver.cpp:228] Iteration 30350, loss = 0.270731
I0814 13:43:02.784099 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:43:02.784113 21738 solver.cpp:244]     Train net output #1: loss = 0.270731 (* 1 = 0.270731 loss)
I0814 13:43:02.784126 21738 sgd_solver.cpp:106] Iteration 30350, lr = 0.00351251
I0814 13:44:22.896250 21738 solver.cpp:337] Iteration 30400, Testing net (#0)
I0814 13:44:31.052647 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:44:31.052701 21738 solver.cpp:404]     Test net output #1: loss = 0.690481 (* 1 = 0.690481 loss)
I0814 13:44:32.658057 21738 solver.cpp:228] Iteration 30400, loss = 0.190596
I0814 13:44:32.658104 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 13:44:32.658116 21738 solver.cpp:244]     Train net output #1: loss = 0.190596 (* 1 = 0.190596 loss)
I0814 13:44:32.658133 21738 sgd_solver.cpp:106] Iteration 30400, lr = 0.00350925
I0814 13:45:54.560022 21738 solver.cpp:228] Iteration 30450, loss = 0.271295
I0814 13:45:54.560279 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:45:54.560328 21738 solver.cpp:244]     Train net output #1: loss = 0.271295 (* 1 = 0.271295 loss)
I0814 13:45:54.560366 21738 sgd_solver.cpp:106] Iteration 30450, lr = 0.00350599
I0814 13:47:13.677119 21738 solver.cpp:337] Iteration 30500, Testing net (#0)
I0814 13:47:21.771456 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:47:21.771515 21738 solver.cpp:404]     Test net output #1: loss = 0.689966 (* 1 = 0.689966 loss)
I0814 13:47:23.351511 21738 solver.cpp:228] Iteration 30500, loss = 0.190457
I0814 13:47:23.351575 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 13:47:23.351588 21738 solver.cpp:244]     Train net output #1: loss = 0.190457 (* 1 = 0.190457 loss)
I0814 13:47:23.351601 21738 sgd_solver.cpp:106] Iteration 30500, lr = 0.00350275
I0814 13:48:45.113839 21738 solver.cpp:228] Iteration 30550, loss = 0.270917
I0814 13:48:45.114058 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:48:45.114114 21738 solver.cpp:244]     Train net output #1: loss = 0.270916 (* 1 = 0.270916 loss)
I0814 13:48:45.114145 21738 sgd_solver.cpp:106] Iteration 30550, lr = 0.00349951
I0814 13:50:07.388453 21738 solver.cpp:337] Iteration 30600, Testing net (#0)
I0814 13:50:15.346223 21738 solver.cpp:404]     Test net output #0: accuracy = 0.773
I0814 13:50:15.346283 21738 solver.cpp:404]     Test net output #1: loss = 0.688074 (* 1 = 0.688074 loss)
I0814 13:50:16.922771 21738 solver.cpp:228] Iteration 30600, loss = 0.190618
I0814 13:50:16.922821 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:50:16.922832 21738 solver.cpp:244]     Train net output #1: loss = 0.190618 (* 1 = 0.190618 loss)
I0814 13:50:16.922849 21738 sgd_solver.cpp:106] Iteration 30600, lr = 0.00349627
I0814 13:51:38.454594 21738 solver.cpp:228] Iteration 30650, loss = 0.270494
I0814 13:51:38.454749 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 13:51:38.454766 21738 solver.cpp:244]     Train net output #1: loss = 0.270494 (* 1 = 0.270494 loss)
I0814 13:51:38.454778 21738 sgd_solver.cpp:106] Iteration 30650, lr = 0.00349305
I0814 13:52:57.136472 21738 solver.cpp:337] Iteration 30700, Testing net (#0)
I0814 13:53:05.508548 21738 solver.cpp:404]     Test net output #0: accuracy = 0.663
I0814 13:53:05.508615 21738 solver.cpp:404]     Test net output #1: loss = 0.688165 (* 1 = 0.688165 loss)
I0814 13:53:07.219384 21738 solver.cpp:228] Iteration 30700, loss = 0.190311
I0814 13:53:07.219447 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:53:07.219461 21738 solver.cpp:244]     Train net output #1: loss = 0.190311 (* 1 = 0.190311 loss)
I0814 13:53:07.219475 21738 sgd_solver.cpp:106] Iteration 30700, lr = 0.00348983
I0814 13:54:29.061381 21738 solver.cpp:228] Iteration 30750, loss = 0.270104
I0814 13:54:29.061583 21738 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0814 13:54:29.061651 21738 solver.cpp:244]     Train net output #1: loss = 0.270104 (* 1 = 0.270104 loss)
I0814 13:54:29.061687 21738 sgd_solver.cpp:106] Iteration 30750, lr = 0.00348662
I0814 13:55:48.546805 21738 solver.cpp:337] Iteration 30800, Testing net (#0)
I0814 13:55:56.559211 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 13:55:56.559273 21738 solver.cpp:404]     Test net output #1: loss = 0.68923 (* 1 = 0.68923 loss)
I0814 13:55:58.133492 21738 solver.cpp:228] Iteration 30800, loss = 0.190249
I0814 13:55:58.133549 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 13:55:58.133563 21738 solver.cpp:244]     Train net output #1: loss = 0.190249 (* 1 = 0.190249 loss)
I0814 13:55:58.133576 21738 sgd_solver.cpp:106] Iteration 30800, lr = 0.00348341
I0814 13:57:19.187727 21738 solver.cpp:228] Iteration 30850, loss = 0.270372
I0814 13:57:19.187922 21738 solver.cpp:244]     Train net output #0: accuracy = 0.975
I0814 13:57:19.187937 21738 solver.cpp:244]     Train net output #1: loss = 0.270372 (* 1 = 0.270372 loss)
I0814 13:57:19.187952 21738 sgd_solver.cpp:106] Iteration 30850, lr = 0.00348021
I0814 13:58:37.596211 21738 solver.cpp:337] Iteration 30900, Testing net (#0)
I0814 13:58:45.700018 21738 solver.cpp:404]     Test net output #0: accuracy = 0.764
I0814 13:58:45.700086 21738 solver.cpp:404]     Test net output #1: loss = 0.688074 (* 1 = 0.688074 loss)
I0814 13:58:47.278528 21738 solver.cpp:228] Iteration 30900, loss = 0.19057
I0814 13:58:47.278595 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 13:58:47.278607 21738 solver.cpp:244]     Train net output #1: loss = 0.19057 (* 1 = 0.19057 loss)
I0814 13:58:47.278622 21738 sgd_solver.cpp:106] Iteration 30900, lr = 0.00347702
I0814 14:00:07.510975 21738 solver.cpp:228] Iteration 30950, loss = 0.270983
I0814 14:00:07.511206 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:00:07.511268 21738 solver.cpp:244]     Train net output #1: loss = 0.270983 (* 1 = 0.270983 loss)
I0814 14:00:07.511296 21738 sgd_solver.cpp:106] Iteration 30950, lr = 0.00347384
I0814 14:01:26.127241 21738 solver.cpp:337] Iteration 31000, Testing net (#0)
I0814 14:01:34.089864 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:01:34.089925 21738 solver.cpp:404]     Test net output #1: loss = 0.68831 (* 1 = 0.68831 loss)
I0814 14:01:35.666508 21738 solver.cpp:228] Iteration 31000, loss = 0.190098
I0814 14:01:35.666560 21738 solver.cpp:244]     Train net output #0: accuracy = 0.945
I0814 14:01:35.666573 21738 solver.cpp:244]     Train net output #1: loss = 0.190098 (* 1 = 0.190098 loss)
I0814 14:01:35.666589 21738 sgd_solver.cpp:106] Iteration 31000, lr = 0.00347066
I0814 14:02:56.830461 21738 solver.cpp:228] Iteration 31050, loss = 0.270369
I0814 14:02:56.830610 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:02:56.830624 21738 solver.cpp:244]     Train net output #1: loss = 0.270369 (* 1 = 0.270369 loss)
I0814 14:02:56.830636 21738 sgd_solver.cpp:106] Iteration 31050, lr = 0.00346749
I0814 14:04:14.868515 21738 solver.cpp:337] Iteration 31100, Testing net (#0)
I0814 14:04:22.829550 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:04:22.829608 21738 solver.cpp:404]     Test net output #1: loss = 0.688541 (* 1 = 0.688541 loss)
I0814 14:04:24.406615 21738 solver.cpp:228] Iteration 31100, loss = 0.190068
I0814 14:04:24.406672 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:04:24.406684 21738 solver.cpp:244]     Train net output #1: loss = 0.190068 (* 1 = 0.190068 loss)
I0814 14:04:24.406698 21738 sgd_solver.cpp:106] Iteration 31100, lr = 0.00346433
I0814 14:05:44.981892 21738 solver.cpp:228] Iteration 31150, loss = 0.272419
I0814 14:05:44.982903 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:05:44.982961 21738 solver.cpp:244]     Train net output #1: loss = 0.272419 (* 1 = 0.272419 loss)
I0814 14:05:44.982990 21738 sgd_solver.cpp:106] Iteration 31150, lr = 0.00346117
I0814 14:07:03.711599 21738 solver.cpp:337] Iteration 31200, Testing net (#0)
I0814 14:07:11.795759 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:07:11.795819 21738 solver.cpp:404]     Test net output #1: loss = 0.691936 (* 1 = 0.691936 loss)
I0814 14:07:13.380796 21738 solver.cpp:228] Iteration 31200, loss = 0.191013
I0814 14:07:13.380873 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:07:13.380887 21738 solver.cpp:244]     Train net output #1: loss = 0.191013 (* 1 = 0.191013 loss)
I0814 14:07:13.380902 21738 sgd_solver.cpp:106] Iteration 31200, lr = 0.00345802
I0814 14:08:33.755070 21738 solver.cpp:228] Iteration 31250, loss = 0.270301
I0814 14:08:33.755347 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:08:33.755410 21738 solver.cpp:244]     Train net output #1: loss = 0.270301 (* 1 = 0.270301 loss)
I0814 14:08:33.755448 21738 sgd_solver.cpp:106] Iteration 31250, lr = 0.00345487
I0814 14:09:52.794276 21738 solver.cpp:337] Iteration 31300, Testing net (#0)
I0814 14:10:00.802348 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:10:00.802408 21738 solver.cpp:404]     Test net output #1: loss = 0.688588 (* 1 = 0.688588 loss)
I0814 14:10:02.378902 21738 solver.cpp:228] Iteration 31300, loss = 0.190081
I0814 14:10:02.378971 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:10:02.378983 21738 solver.cpp:244]     Train net output #1: loss = 0.190081 (* 1 = 0.190081 loss)
I0814 14:10:02.378998 21738 sgd_solver.cpp:106] Iteration 31300, lr = 0.00345174
I0814 14:11:22.216881 21738 solver.cpp:228] Iteration 31350, loss = 0.270832
I0814 14:11:22.217017 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:11:22.217113 21738 solver.cpp:244]     Train net output #1: loss = 0.270831 (* 1 = 0.270831 loss)
I0814 14:11:22.217126 21738 sgd_solver.cpp:106] Iteration 31350, lr = 0.0034486
I0814 14:12:40.597512 21738 solver.cpp:337] Iteration 31400, Testing net (#0)
I0814 14:12:49.187899 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:12:49.187963 21738 solver.cpp:404]     Test net output #1: loss = 0.690427 (* 1 = 0.690427 loss)
I0814 14:12:50.765662 21738 solver.cpp:228] Iteration 31400, loss = 0.190598
I0814 14:12:50.765722 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:12:50.765735 21738 solver.cpp:244]     Train net output #1: loss = 0.190598 (* 1 = 0.190598 loss)
I0814 14:12:50.765749 21738 sgd_solver.cpp:106] Iteration 31400, lr = 0.00344548
I0814 14:14:11.680682 21738 solver.cpp:228] Iteration 31450, loss = 0.271872
I0814 14:14:11.680903 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:14:11.680958 21738 solver.cpp:244]     Train net output #1: loss = 0.271871 (* 1 = 0.271871 loss)
I0814 14:14:11.680987 21738 sgd_solver.cpp:106] Iteration 31450, lr = 0.00344236
I0814 14:15:30.813021 21738 solver.cpp:337] Iteration 31500, Testing net (#0)
I0814 14:15:38.772953 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:15:38.773015 21738 solver.cpp:404]     Test net output #1: loss = 0.689572 (* 1 = 0.689572 loss)
I0814 14:15:40.349390 21738 solver.cpp:228] Iteration 31500, loss = 0.190352
I0814 14:15:40.349442 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:15:40.349453 21738 solver.cpp:244]     Train net output #1: loss = 0.190351 (* 1 = 0.190351 loss)
I0814 14:15:40.349468 21738 sgd_solver.cpp:106] Iteration 31500, lr = 0.00343925
I0814 14:16:59.766414 21738 solver.cpp:228] Iteration 31550, loss = 0.270127
I0814 14:16:59.766659 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:16:59.766728 21738 solver.cpp:244]     Train net output #1: loss = 0.270127 (* 1 = 0.270127 loss)
I0814 14:16:59.766769 21738 sgd_solver.cpp:106] Iteration 31550, lr = 0.00343615
I0814 14:18:17.851780 21738 solver.cpp:337] Iteration 31600, Testing net (#0)
I0814 14:18:26.156687 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:18:26.156751 21738 solver.cpp:404]     Test net output #1: loss = 0.688835 (* 1 = 0.688835 loss)
I0814 14:18:27.733618 21738 solver.cpp:228] Iteration 31600, loss = 0.19015
I0814 14:18:27.733681 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:18:27.733693 21738 solver.cpp:244]     Train net output #1: loss = 0.19015 (* 1 = 0.19015 loss)
I0814 14:18:27.733708 21738 sgd_solver.cpp:106] Iteration 31600, lr = 0.00343305
I0814 14:19:47.874316 21738 solver.cpp:228] Iteration 31650, loss = 0.271526
I0814 14:19:47.874466 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:19:47.874480 21738 solver.cpp:244]     Train net output #1: loss = 0.271526 (* 1 = 0.271526 loss)
I0814 14:19:47.874492 21738 sgd_solver.cpp:106] Iteration 31650, lr = 0.00342996
I0814 14:21:06.863315 21738 solver.cpp:337] Iteration 31700, Testing net (#0)
I0814 14:21:14.917003 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:21:14.917064 21738 solver.cpp:404]     Test net output #1: loss = 0.688244 (* 1 = 0.688244 loss)
I0814 14:21:16.494715 21738 solver.cpp:228] Iteration 31700, loss = 0.190159
I0814 14:21:16.494777 21738 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0814 14:21:16.494792 21738 solver.cpp:244]     Train net output #1: loss = 0.190158 (* 1 = 0.190158 loss)
I0814 14:21:16.494807 21738 sgd_solver.cpp:106] Iteration 31700, lr = 0.00342687
I0814 14:22:37.766290 21738 solver.cpp:228] Iteration 31750, loss = 0.270355
I0814 14:22:37.766439 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:22:37.766455 21738 solver.cpp:244]     Train net output #1: loss = 0.270354 (* 1 = 0.270354 loss)
I0814 14:22:37.766468 21738 sgd_solver.cpp:106] Iteration 31750, lr = 0.00342379
I0814 14:23:56.399039 21738 solver.cpp:337] Iteration 31800, Testing net (#0)
I0814 14:24:04.495311 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:24:04.495386 21738 solver.cpp:404]     Test net output #1: loss = 0.690397 (* 1 = 0.690397 loss)
I0814 14:24:06.071692 21738 solver.cpp:228] Iteration 31800, loss = 0.190591
I0814 14:24:06.071758 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:24:06.071770 21738 solver.cpp:244]     Train net output #1: loss = 0.190591 (* 1 = 0.190591 loss)
I0814 14:24:06.071784 21738 sgd_solver.cpp:106] Iteration 31800, lr = 0.00342072
I0814 14:25:27.764441 21738 solver.cpp:228] Iteration 31850, loss = 0.270803
I0814 14:25:27.764585 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:25:27.764598 21738 solver.cpp:244]     Train net output #1: loss = 0.270803 (* 1 = 0.270803 loss)
I0814 14:25:27.764611 21738 sgd_solver.cpp:106] Iteration 31850, lr = 0.00341766
I0814 14:26:47.548468 21738 solver.cpp:337] Iteration 31900, Testing net (#0)
I0814 14:26:55.701936 21738 solver.cpp:404]     Test net output #0: accuracy = 0.875
I0814 14:26:55.701997 21738 solver.cpp:404]     Test net output #1: loss = 0.688066 (* 1 = 0.688066 loss)
I0814 14:26:57.278967 21738 solver.cpp:228] Iteration 31900, loss = 0.190679
I0814 14:26:57.279033 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 14:26:57.279047 21738 solver.cpp:244]     Train net output #1: loss = 0.190679 (* 1 = 0.190679 loss)
I0814 14:26:57.279062 21738 sgd_solver.cpp:106] Iteration 31900, lr = 0.0034146
I0814 14:28:18.881562 21738 solver.cpp:228] Iteration 31950, loss = 0.270338
I0814 14:28:18.881711 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:28:18.881726 21738 solver.cpp:244]     Train net output #1: loss = 0.270338 (* 1 = 0.270338 loss)
I0814 14:28:18.881737 21738 sgd_solver.cpp:106] Iteration 31950, lr = 0.00341154
I0814 14:29:38.437258 21738 solver.cpp:337] Iteration 32000, Testing net (#0)
I0814 14:29:46.397817 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:29:46.397888 21738 solver.cpp:404]     Test net output #1: loss = 0.68869 (* 1 = 0.68869 loss)
I0814 14:29:48.381594 21738 solver.cpp:228] Iteration 32000, loss = 0.190117
I0814 14:29:48.381659 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:29:48.381671 21738 solver.cpp:244]     Train net output #1: loss = 0.190117 (* 1 = 0.190117 loss)
I0814 14:29:48.381686 21738 sgd_solver.cpp:106] Iteration 32000, lr = 0.0034085
I0814 14:31:10.114365 21738 solver.cpp:228] Iteration 32050, loss = 0.270437
I0814 14:31:10.114611 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:31:10.114684 21738 solver.cpp:244]     Train net output #1: loss = 0.270436 (* 1 = 0.270436 loss)
I0814 14:31:10.114727 21738 sgd_solver.cpp:106] Iteration 32050, lr = 0.00340546
I0814 14:32:29.015425 21738 solver.cpp:337] Iteration 32100, Testing net (#0)
I0814 14:32:37.176841 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:32:37.176906 21738 solver.cpp:404]     Test net output #1: loss = 0.689812 (* 1 = 0.689812 loss)
I0814 14:32:38.757131 21738 solver.cpp:228] Iteration 32100, loss = 0.19043
I0814 14:32:38.757194 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:32:38.757205 21738 solver.cpp:244]     Train net output #1: loss = 0.19043 (* 1 = 0.19043 loss)
I0814 14:32:38.757225 21738 sgd_solver.cpp:106] Iteration 32100, lr = 0.00340242
I0814 14:33:59.360313 21738 solver.cpp:228] Iteration 32150, loss = 0.270742
I0814 14:33:59.360462 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:33:59.360482 21738 solver.cpp:244]     Train net output #1: loss = 0.270741 (* 1 = 0.270741 loss)
I0814 14:33:59.360496 21738 sgd_solver.cpp:106] Iteration 32150, lr = 0.0033994
I0814 14:35:18.302958 21738 solver.cpp:337] Iteration 32200, Testing net (#0)
I0814 14:35:26.456511 21738 solver.cpp:404]     Test net output #0: accuracy = 0.946
I0814 14:35:26.456581 21738 solver.cpp:404]     Test net output #1: loss = 0.688099 (* 1 = 0.688099 loss)
I0814 14:35:28.043139 21738 solver.cpp:228] Iteration 32200, loss = 0.190789
I0814 14:35:28.043193 21738 solver.cpp:244]     Train net output #0: accuracy = 1
I0814 14:35:28.043205 21738 solver.cpp:244]     Train net output #1: loss = 0.190788 (* 1 = 0.190788 loss)
I0814 14:35:28.043221 21738 sgd_solver.cpp:106] Iteration 32200, lr = 0.00339637
I0814 14:36:48.750144 21738 solver.cpp:228] Iteration 32250, loss = 0.27066
I0814 14:36:48.750314 21738 solver.cpp:244]     Train net output #0: accuracy = 0.995
I0814 14:36:48.750329 21738 solver.cpp:244]     Train net output #1: loss = 0.27066 (* 1 = 0.27066 loss)
I0814 14:36:48.750342 21738 sgd_solver.cpp:106] Iteration 32250, lr = 0.00339336
I0814 14:38:07.479555 21738 solver.cpp:337] Iteration 32300, Testing net (#0)
I0814 14:38:15.853816 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:38:15.853893 21738 solver.cpp:404]     Test net output #1: loss = 0.688584 (* 1 = 0.688584 loss)
I0814 14:38:17.432585 21738 solver.cpp:228] Iteration 32300, loss = 0.190084
I0814 14:38:17.432652 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:38:17.432667 21738 solver.cpp:244]     Train net output #1: loss = 0.190084 (* 1 = 0.190084 loss)
I0814 14:38:17.432682 21738 sgd_solver.cpp:106] Iteration 32300, lr = 0.00339035
I0814 14:39:38.852246 21738 solver.cpp:228] Iteration 32350, loss = 0.270443
I0814 14:39:38.852411 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:39:38.852427 21738 solver.cpp:244]     Train net output #1: loss = 0.270443 (* 1 = 0.270443 loss)
I0814 14:39:38.852438 21738 sgd_solver.cpp:106] Iteration 32350, lr = 0.00338735
I0814 14:41:00.556416 21738 solver.cpp:337] Iteration 32400, Testing net (#0)
I0814 14:41:08.596151 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:41:08.596217 21738 solver.cpp:404]     Test net output #1: loss = 0.69045 (* 1 = 0.69045 loss)
I0814 14:41:10.173378 21738 solver.cpp:228] Iteration 32400, loss = 0.190601
I0814 14:41:10.173431 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:41:10.173444 21738 solver.cpp:244]     Train net output #1: loss = 0.190601 (* 1 = 0.190601 loss)
I0814 14:41:10.173460 21738 sgd_solver.cpp:106] Iteration 32400, lr = 0.00338435
I0814 14:42:30.982100 21738 solver.cpp:228] Iteration 32450, loss = 0.270557
I0814 14:42:30.982260 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:42:30.982275 21738 solver.cpp:244]     Train net output #1: loss = 0.270557 (* 1 = 0.270557 loss)
I0814 14:42:30.982286 21738 sgd_solver.cpp:106] Iteration 32450, lr = 0.00338136
I0814 14:43:50.994876 21738 solver.cpp:337] Iteration 32500, Testing net (#0)
I0814 14:43:59.065703 21738 solver.cpp:404]     Test net output #0: accuracy = 0.656
I0814 14:43:59.065770 21738 solver.cpp:404]     Test net output #1: loss = 0.690132 (* 1 = 0.690132 loss)
I0814 14:44:00.642469 21738 solver.cpp:228] Iteration 32500, loss = 0.190522
I0814 14:44:00.642521 21738 solver.cpp:244]     Train net output #0: accuracy = 0.905
I0814 14:44:00.642534 21738 solver.cpp:244]     Train net output #1: loss = 0.190521 (* 1 = 0.190521 loss)
I0814 14:44:00.642547 21738 sgd_solver.cpp:106] Iteration 32500, lr = 0.00337838
I0814 14:45:21.518646 21738 solver.cpp:228] Iteration 32550, loss = 0.270845
I0814 14:45:21.518831 21738 solver.cpp:244]     Train net output #0: accuracy = 0.865
I0814 14:45:21.518847 21738 solver.cpp:244]     Train net output #1: loss = 0.270845 (* 1 = 0.270845 loss)
I0814 14:45:21.518858 21738 sgd_solver.cpp:106] Iteration 32550, lr = 0.0033754
