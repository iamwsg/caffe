./build/tools/caffe: /home/shaogangwang/anaconda2/lib/libtiff.so.5: no version information available (required by /usr/local/lib/libopencv_highgui.so.2.4)
I0808 13:44:08.008299 20451 caffe.cpp:185] Using GPUs 0
I0808 13:44:08.020571 20451 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0808 13:44:08.342901 20451 solver.cpp:48] Initializing solver from parameters: 
train_net: "examples/scene/matchNetTrainHingeMini.prototxt"
test_net: "examples/scene/matchNetTestHingeMini.prototxt"
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 300000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0002
snapshot: 5000
snapshot_prefix: "examples/scene/scene"
solver_mode: GPU
device_id: 0
I0808 13:44:08.343070 20451 solver.cpp:81] Creating training net from train_net file: examples/scene/matchNetTrainHingeMini.prototxt
I0808 13:44:08.371104 20451 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215689
    mirror: true
    mean_file: "examples/scene/scene_mean.binaryproto"
  }
  data_param {
    source: "examples/scene/train11_pairs_300000_pad.lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "th"
  type: "Threshold"
  bottom: "label"
  top: "th"
  threshold_param {
    threshold: 0
  }
}
layer {
  name: "i1"
  type: "Slice"
  bottom: "data"
  top: "i1"
  top: "i2"
  slice_param {
    slice_dim: 1
    slice_point: 3
  }
}
layer {
  name: "p1"
  type: "Pooling"
  bottom: "i1"
  top: "p1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "p2"
  type: "Pooling"
  bottom: "i2"
  top: "p2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input1"
  type: "Input"
  top: "Input1"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c11"
  type: "Crop"
  bottom: "i1"
  bottom: "Input1"
  top: "c11"
  crop_param {
    axis: 2
    offset: 0
    offset: 0
  }
}
layer {
  name: "Input2"
  type: "Input"
  top: "Input2"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c12"
  type: "Crop"
  bottom: "i1"
  bottom: "Input2"
  top: "c12"
  crop_param {
    axis: 2
    offset: 0
    offset: 32
  }
}
layer {
  name: "Input3"
  type: "Input"
  top: "Input3"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c13"
  type: "Crop"
  bottom: "i1"
  bottom: "Input3"
  top: "c13"
  crop_param {
    axis: 2
    offset: 0
    offset: 64
  }
}
layer {
  name: "Input4"
  type: "Input"
  top: "Input4"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c14"
  type: "Crop"
  bottom: "i1"
  bottom: "Input4"
  top: "c14"
  crop_param {
    axis: 2
    offset: 32
    offset: 0
  }
}
layer {
  name: "Input5"
  type: "Input"
  top: "Input5"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c15"
  type: "Crop"
  bottom: "i1"
  bottom: "Input5"
  top: "c15"
  crop_param {
    axis: 2
    offset: 32
    offset: 32
  }
}
layer {
  name: "Input6"
  type: "Input"
  top: "Input6"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c16"
  type: "Crop"
  bottom: "i1"
  bottom: "Input6"
  top: "c16"
  crop_param {
    axis: 2
    offset: 32
    offset: 64
  }
}
layer {
  name: "Input7"
  type: "Input"
  top: "Input7"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c17"
  type: "Crop"
  bottom: "i1"
  bottom: "Input7"
  top: "c17"
  crop_param {
    axis: 2
    offset: 64
    offset: 0
  }
}
layer {
  name: "Input8"
  type: "Input"
  top: "Input8"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c18"
  type: "Crop"
  bottom: "i1"
  bottom: "Input8"
  top: "c18"
  crop_param {
    axis: 2
    offset: 64
    offset: 32
  }
}
layer {
  name: "Input9"
  type: "Input"
  top: "Input9"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c19"
  type: "Crop"
  bottom: "i1"
  bottom: "Input9"
  top: "c19"
  crop_param {
    axis: 2
    offset: 64
    offset: 64
  }
}
layer {
  name: "Input10"
  type: "Input"
  top: "Input10"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c21"
  type: "Crop"
  bottom: "i2"
  bottom: "Input10"
  top: "c21"
  crop_param {
    axis: 2
    offset: 0
    offset: 0
  }
}
layer {
  name: "Input11"
  type: "Input"
  top: "Input11"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c22"
  type: "Crop"
  bottom: "i2"
  bottom: "Input11"
  top: "c22"
  crop_param {
    axis: 2
    offset: 0
    offset: 32
  }
}
layer {
  name: "Input12"
  type: "Input"
  top: "Input12"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c23"
  type: "Crop"
  bottom: "i2"
  bottom: "Input12"
  top: "c23"
  crop_param {
    axis: 2
    offset: 0
    offset: 64
  }
}
layer {
  name: "Input13"
  type: "Input"
  top: "Input13"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c24"
  type: "Crop"
  bottom: "i2"
  bottom: "Input13"
  top: "c24"
  crop_param {
    axis: 2
    offset: 32
    offset: 0
  }
}
layer {
  name: "Input14"
  type: "Input"
  top: "Input14"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c25"
  type: "Crop"
  bottom: "i2"
  bottom: "Input14"
  top: "c25"
  crop_param {
    axis: 2
    offset: 32
    offset: 32
  }
}
layer {
  name: "Input15"
  type: "Input"
  top: "Input15"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c26"
  type: "Crop"
  bottom: "i2"
  bottom: "Input15"
  top: "c26"
  crop_param {
    axis: 2
    offset: 32
    offset: 64
  }
}
layer {
  name: "Input16"
  type: "Input"
  top: "Input16"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c27"
  type: "Crop"
  bottom: "i2"
  bottom: "Input16"
  top: "c27"
  crop_param {
    axis: 2
    offset: 64
    offset: 0
  }
}
layer {
  name: "Input17"
  type: "Input"
  top: "Input17"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c28"
  type: "Crop"
  bottom: "i2"
  bottom: "Input17"
  top: "c28"
  crop_param {
    axis: 2
    offset: 64
    offset: 32
  }
}
layer {
  name: "Input18"
  type: "Input"
  top: "Input18"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c29"
  type: "Crop"
  bottom: "i2"
  bottom: "Input18"
  top: "c29"
  crop_param {
    axis: 2
    offset: 64
    offset: 64
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution1"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Convolution1"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Pooling1"
  top: "Convolution2"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Convolution2"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Pooling2"
  top: "Convolution3"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Convolution3"
  top: "Pooling3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling3"
  top: "InnerProduct1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "InnerProduct1"
  top: "InnerProduct2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "p2"
  top: "Convolution4"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling4"
  type: "Pooling"
  bottom: "Convolution4"
  top: "Pooling4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Pooling4"
  top: "Convolution5"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling5"
  type: "Pooling"
  bottom: "Convolution5"
  top: "Pooling5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Pooling5"
  top: "Convolution6"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling6"
  type: "Pooling"
  bottom: "Convolution6"
  top: "Pooling6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "Pooling6"
  top: "InnerProduct3"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "InnerProduct3"
  top: "InnerProduct3"
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "InnerProduct3"
  top: "InnerProduct4"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "InnerProduct2"
  bottom: "InnerProduct4"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct5"
  type: "InnerProduct"
  bottom: "Concat1"
  top: "InnerProduct5"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct5"
  top: "InnerProduct5"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct5"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct6"
  type: "InnerProduct"
  bottom: "Dropout1"
  top: "InnerProduct6"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "InnerProduct6"
  top: "InnerProduct6"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct6"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "dt0"
  type: "InnerProduct"
  bottom: "Dropout2"
  top: "dt0"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution7"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling7"
  type: "Pooling"
  bottom: "Convolution7"
  top: "Pooling7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Pooling7"
  top: "Convolution8"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling8"
  type: "Pooling"
  bottom: "Convolution8"
  top: "Pooling8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Pooling8"
  top: "Convolution9"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling9"
  type: "Pooling"
  bottom: "Convolution9"
  top: "Pooling9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct7"
  type: "InnerProduct"
  bottom: "Pooling9"
  top: "InnerProduct7"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "InnerProduct7"
  top: "InnerProduct7"
}
layer {
  name: "InnerProduct8"
  type: "InnerProduct"
  bottom: "InnerProduct7"
  top: "InnerProduct8"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "c21"
  top: "Convolution10"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling10"
  type: "Pooling"
  bottom: "Convolution10"
  top: "Pooling10"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Pooling10"
  top: "Convolution11"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling11"
  type: "Pooling"
  bottom: "Convolution11"
  top: "Pooling11"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Pooling11"
  top: "Convolution12"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling12"
  type: "Pooling"
  bottom: "Convolution12"
  top: "Pooling12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct9"
  type: "InnerProduct"
  bottom: "Pooling12"
  top: "InnerProduct9"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "InnerProduct9"
  top: "InnerProduct9"
}
layer {
  name: "InnerProduct10"
  type: "InnerProduct"
  bottom: "InnerProduct9"
  top: "InnerProduct10"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "InnerProduct8"
  bottom: "InnerProduct10"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct11"
  type: "InnerProduct"
  bottom: "Concat2"
  top: "InnerProduct11"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "InnerProduct11"
  top: "InnerProduct11"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct11"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct12"
  type: "InnerProduct"
  bottom: "Dropout3"
  top: "InnerProduct12"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "InnerProduct12"
  top: "InnerProduct12"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct12"
  top: "Dropout4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "dt1"
  type: "InnerProduct"
  bottom: "Dropout4"
  top: "dt1"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution13"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling13"
  type: "Pooling"
  bottom: "Convolution13"
  top: "Pooling13"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Pooling13"
  top: "Convolution14"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling14"
  type: "Pooling"
  bottom: "Convolution14"
  top: "Pooling14"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Pooling14"
  top: "Convolution15"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling15"
  type: "Pooling"
  bottom: "Convolution15"
  top: "Pooling15"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct13"
  type: "InnerProduct"
  bottom: "Pooling15"
  top: "InnerProduct13"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "InnerProduct13"
  top: "InnerProduct13"
}
layer {
  name: "InnerProduct14"
  type: "InnerProduct"
  bottom: "InnerProduct13"
  top: "InnerProduct14"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "c22"
  top: "Convolution16"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling16"
  type: "Pooling"
  bottom: "Convolution16"
  top: "Pooling16"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Pooling16"
  top: "Convolution17"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling17"
  type: "Pooling"
  bottom: "Convolution17"
  top: "Pooling17"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Pooling17"
  top: "Convolution18"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling18"
  type: "Pooling"
  bottom: "Convolution18"
  top: "Pooling18"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct15"
  type: "InnerProduct"
  bottom: "Pooling18"
  top: "InnerProduct15"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "InnerProduct15"
  top: "InnerProduct15"
}
layer {
  name: "InnerProduct16"
  type: "InnerProduct"
  bottom: "InnerProduct15"
  top: "InnerProduct16"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "InnerProduct14"
  bottom: "InnerProduct16"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct17"
  type: "InnerProduct"
  bottom: "Concat3"
  top: "InnerProduct17"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "InnerProduct17"
  top: "InnerProduct17"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct17"
  top: "Dropout5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct18"
  type: "InnerProduct"
  bottom: "Dropout5"
  top: "InnerProduct18"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "InnerProduct18"
  top: "InnerProduct18"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct18"
  top: "Dropout6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "dt2"
  type: "InnerProduct"
  bottom: "Dropout6"
  top: "dt2"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution19"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling19"
  type: "Pooling"
  bottom: "Convolution19"
  top: "Pooling19"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Pooling19"
  top: "Convolution20"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling20"
  type: "Pooling"
  bottom: "Convolution20"
  top: "Pooling20"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Pooling20"
  top: "Convolution21"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling21"
  type: "Pooling"
  bottom: "Convolution21"
  top: "Pooling21"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct19"
  type: "InnerProduct"
  bottom: "Pooling21"
  top: "InnerProduct19"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "InnerProduct19"
  top: "InnerProduct19"
}
layer {
  name: "InnerProduct20"
  type: "InnerProduct"
  bottom: "InnerProduct19"
  top: "InnerProduct20"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "c23"
  top: "Convolution22"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling22"
  type: "Pooling"
  bottom: "Convolution22"
  top: "Pooling22"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Pooling22"
  top: "Convolution23"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling23"
  type: "Pooling"
  bottom: "Convolution23"
  top: "Pooling23"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Pooling23"
  top: "Convolution24"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling24"
  type: "Pooling"
  bottom: "Convolution24"
  top: "Pooling24"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct21"
  type: "InnerProduct"
  bottom: "Pooling24"
  top: "InnerProduct21"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
I0808 13:44:08.375856 20451 layer_factory.hpp:77] Creating layer data
I0808 13:44:08.376302 20451 net.cpp:91] Creating Layer data
I0808 13:44:08.376313 20451 net.cpp:399] data -> data
I0808 13:44:08.376344 20451 net.cpp:399] data -> label
I0808 13:44:08.376368 20451 data_transformer.cpp:25] Loading mean file from: examples/scene/scene_mean.binaryproto
I0808 13:44:08.377996 20457 db_lmdb.cpp:35] Opened lmdb examples/scene/train11_pairs_300000_pad.lmdb
I0808 13:44:08.398247 20451 data_layer.cpp:41] output data size: 64,6,128,128
I0808 13:44:08.462949 20451 net.cpp:141] Setting up data
I0808 13:44:08.462983 20451 net.cpp:148] Top shape: 64 6 128 128 (6291456)
I0808 13:44:08.463004 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:08.463011 20451 net.cpp:156] Memory required for data: 25166080
I0808 13:44:08.463027 20451 layer_factory.hpp:77] Creating layer label_data_1_split
I0808 13:44:08.463064 20451 net.cpp:91] Creating Layer label_data_1_split
I0808 13:44:08.463078 20451 net.cpp:425] label_data_1_split <- label
I0808 13:44:08.463093 20451 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0808 13:44:08.463114 20451 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0808 13:44:08.463294 20451 net.cpp:141] Setting up label_data_1_split
I0808 13:44:08.463309 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:08.463317 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:08.463325 20451 net.cpp:156] Memory required for data: 25166592
I0808 13:44:08.463332 20451 layer_factory.hpp:77] Creating layer th
I0808 13:44:08.463349 20451 net.cpp:91] Creating Layer th
I0808 13:44:08.463357 20451 net.cpp:425] th <- label_data_1_split_0
I0808 13:44:08.463367 20451 net.cpp:399] th -> th
I0808 13:44:08.463409 20451 net.cpp:141] Setting up th
I0808 13:44:08.463424 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:08.463431 20451 net.cpp:156] Memory required for data: 25166848
I0808 13:44:08.463439 20451 layer_factory.hpp:77] Creating layer th_th_0_split
I0808 13:44:08.463449 20451 net.cpp:91] Creating Layer th_th_0_split
I0808 13:44:08.463457 20451 net.cpp:425] th_th_0_split <- th
I0808 13:44:08.463469 20451 net.cpp:399] th_th_0_split -> th_th_0_split_0
I0808 13:44:08.463501 20451 net.cpp:399] th_th_0_split -> th_th_0_split_1
I0808 13:44:08.463554 20451 net.cpp:141] Setting up th_th_0_split
I0808 13:44:08.463569 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:08.463582 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:08.463588 20451 net.cpp:156] Memory required for data: 25167360
I0808 13:44:08.463594 20451 layer_factory.hpp:77] Creating layer i1
I0808 13:44:08.463613 20451 net.cpp:91] Creating Layer i1
I0808 13:44:08.463619 20451 net.cpp:425] i1 <- data
I0808 13:44:08.463630 20451 net.cpp:399] i1 -> i1
I0808 13:44:08.463646 20451 net.cpp:399] i1 -> i2
I0808 13:44:08.463702 20451 net.cpp:141] Setting up i1
I0808 13:44:08.463714 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.463724 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.463731 20451 net.cpp:156] Memory required for data: 50333184
I0808 13:44:08.463737 20451 layer_factory.hpp:77] Creating layer i1_i1_0_split
I0808 13:44:08.463748 20451 net.cpp:91] Creating Layer i1_i1_0_split
I0808 13:44:08.463757 20451 net.cpp:425] i1_i1_0_split <- i1
I0808 13:44:08.463769 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_0
I0808 13:44:08.463783 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_1
I0808 13:44:08.463801 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_2
I0808 13:44:08.463821 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_3
I0808 13:44:08.463840 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_4
I0808 13:44:08.463855 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_5
I0808 13:44:08.463868 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_6
I0808 13:44:08.463882 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_7
I0808 13:44:08.463898 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_8
I0808 13:44:08.463917 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_9
I0808 13:44:08.464195 20451 net.cpp:141] Setting up i1_i1_0_split
I0808 13:44:08.464211 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.464221 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.464229 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.464238 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.464247 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.464257 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.464267 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.464277 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.464287 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.464296 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.464303 20451 net.cpp:156] Memory required for data: 176162304
I0808 13:44:08.464310 20451 layer_factory.hpp:77] Creating layer i2_i1_1_split
I0808 13:44:08.464321 20451 net.cpp:91] Creating Layer i2_i1_1_split
I0808 13:44:08.464329 20451 net.cpp:425] i2_i1_1_split <- i2
I0808 13:44:08.464341 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_0
I0808 13:44:08.464356 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_1
I0808 13:44:08.464370 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_2
I0808 13:44:08.464385 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_3
I0808 13:44:08.464401 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_4
I0808 13:44:08.464416 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_5
I0808 13:44:08.464431 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_6
I0808 13:44:08.464445 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_7
I0808 13:44:08.464460 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_8
I0808 13:44:08.464476 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_9
I0808 13:44:08.468286 20451 net.cpp:141] Setting up i2_i1_1_split
I0808 13:44:08.468308 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.468317 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.468327 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.468335 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.468363 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.468370 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.468379 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.468387 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.468395 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.468403 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:08.468410 20451 net.cpp:156] Memory required for data: 301991424
I0808 13:44:08.468417 20451 layer_factory.hpp:77] Creating layer p1
I0808 13:44:08.468432 20451 net.cpp:91] Creating Layer p1
I0808 13:44:08.468439 20451 net.cpp:425] p1 <- i1_i1_0_split_0
I0808 13:44:08.468451 20451 net.cpp:399] p1 -> p1
I0808 13:44:08.468500 20451 net.cpp:141] Setting up p1
I0808 13:44:08.468511 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468518 20451 net.cpp:156] Memory required for data: 305137152
I0808 13:44:08.468525 20451 layer_factory.hpp:77] Creating layer p1_p1_0_split
I0808 13:44:08.468539 20451 net.cpp:91] Creating Layer p1_p1_0_split
I0808 13:44:08.468546 20451 net.cpp:425] p1_p1_0_split <- p1
I0808 13:44:08.468557 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_0
I0808 13:44:08.468571 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_1
I0808 13:44:08.468585 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_2
I0808 13:44:08.468602 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_3
I0808 13:44:08.468616 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_4
I0808 13:44:08.468628 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_5
I0808 13:44:08.468641 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_6
I0808 13:44:08.468654 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_7
I0808 13:44:08.468667 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_8
I0808 13:44:08.468680 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_9
I0808 13:44:08.468858 20451 net.cpp:141] Setting up p1_p1_0_split
I0808 13:44:08.468871 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468879 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468889 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468897 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468906 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468914 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468924 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468931 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468940 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468948 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.468955 20451 net.cpp:156] Memory required for data: 336594432
I0808 13:44:08.468961 20451 layer_factory.hpp:77] Creating layer p2
I0808 13:44:08.468971 20451 net.cpp:91] Creating Layer p2
I0808 13:44:08.468977 20451 net.cpp:425] p2 <- i2_i1_1_split_0
I0808 13:44:08.468987 20451 net.cpp:399] p2 -> p2
I0808 13:44:08.469017 20451 net.cpp:141] Setting up p2
I0808 13:44:08.469027 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469033 20451 net.cpp:156] Memory required for data: 339740160
I0808 13:44:08.469040 20451 layer_factory.hpp:77] Creating layer p2_p2_0_split
I0808 13:44:08.469049 20451 net.cpp:91] Creating Layer p2_p2_0_split
I0808 13:44:08.469056 20451 net.cpp:425] p2_p2_0_split <- p2
I0808 13:44:08.469068 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_0
I0808 13:44:08.469080 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_1
I0808 13:44:08.469094 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_2
I0808 13:44:08.469108 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_3
I0808 13:44:08.469120 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_4
I0808 13:44:08.469135 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_5
I0808 13:44:08.469147 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_6
I0808 13:44:08.469159 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_7
I0808 13:44:08.469172 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_8
I0808 13:44:08.469197 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_9
I0808 13:44:08.469372 20451 net.cpp:141] Setting up p2_p2_0_split
I0808 13:44:08.469383 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469393 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469400 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469408 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469416 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469424 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469434 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469441 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469449 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469457 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469463 20451 net.cpp:156] Memory required for data: 371197440
I0808 13:44:08.469470 20451 layer_factory.hpp:77] Creating layer Input1
I0808 13:44:08.469482 20451 net.cpp:91] Creating Layer Input1
I0808 13:44:08.469491 20451 net.cpp:399] Input1 -> Input1
I0808 13:44:08.469527 20451 net.cpp:141] Setting up Input1
I0808 13:44:08.469537 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469542 20451 net.cpp:156] Memory required for data: 374343168
I0808 13:44:08.469549 20451 layer_factory.hpp:77] Creating layer c11
I0808 13:44:08.469565 20451 net.cpp:91] Creating Layer c11
I0808 13:44:08.469573 20451 net.cpp:425] c11 <- i1_i1_0_split_1
I0808 13:44:08.469581 20451 net.cpp:425] c11 <- Input1
I0808 13:44:08.469591 20451 net.cpp:399] c11 -> c11
I0808 13:44:08.469630 20451 net.cpp:141] Setting up c11
I0808 13:44:08.469641 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469648 20451 net.cpp:156] Memory required for data: 377488896
I0808 13:44:08.469655 20451 layer_factory.hpp:77] Creating layer Input2
I0808 13:44:08.469665 20451 net.cpp:91] Creating Layer Input2
I0808 13:44:08.469672 20451 net.cpp:399] Input2 -> Input2
I0808 13:44:08.469702 20451 net.cpp:141] Setting up Input2
I0808 13:44:08.469712 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469717 20451 net.cpp:156] Memory required for data: 380634624
I0808 13:44:08.469724 20451 layer_factory.hpp:77] Creating layer c12
I0808 13:44:08.469733 20451 net.cpp:91] Creating Layer c12
I0808 13:44:08.469740 20451 net.cpp:425] c12 <- i1_i1_0_split_2
I0808 13:44:08.469749 20451 net.cpp:425] c12 <- Input2
I0808 13:44:08.469758 20451 net.cpp:399] c12 -> c12
I0808 13:44:08.469789 20451 net.cpp:141] Setting up c12
I0808 13:44:08.469797 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469804 20451 net.cpp:156] Memory required for data: 383780352
I0808 13:44:08.469810 20451 layer_factory.hpp:77] Creating layer Input3
I0808 13:44:08.469820 20451 net.cpp:91] Creating Layer Input3
I0808 13:44:08.469827 20451 net.cpp:399] Input3 -> Input3
I0808 13:44:08.469857 20451 net.cpp:141] Setting up Input3
I0808 13:44:08.469866 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469873 20451 net.cpp:156] Memory required for data: 386926080
I0808 13:44:08.469879 20451 layer_factory.hpp:77] Creating layer c13
I0808 13:44:08.469893 20451 net.cpp:91] Creating Layer c13
I0808 13:44:08.469900 20451 net.cpp:425] c13 <- i1_i1_0_split_3
I0808 13:44:08.469909 20451 net.cpp:425] c13 <- Input3
I0808 13:44:08.469919 20451 net.cpp:399] c13 -> c13
I0808 13:44:08.469949 20451 net.cpp:141] Setting up c13
I0808 13:44:08.469962 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.469969 20451 net.cpp:156] Memory required for data: 390071808
I0808 13:44:08.469974 20451 layer_factory.hpp:77] Creating layer Input4
I0808 13:44:08.469985 20451 net.cpp:91] Creating Layer Input4
I0808 13:44:08.469992 20451 net.cpp:399] Input4 -> Input4
I0808 13:44:08.470022 20451 net.cpp:141] Setting up Input4
I0808 13:44:08.470033 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470041 20451 net.cpp:156] Memory required for data: 393217536
I0808 13:44:08.470046 20451 layer_factory.hpp:77] Creating layer c14
I0808 13:44:08.470065 20451 net.cpp:91] Creating Layer c14
I0808 13:44:08.470072 20451 net.cpp:425] c14 <- i1_i1_0_split_4
I0808 13:44:08.470082 20451 net.cpp:425] c14 <- Input4
I0808 13:44:08.470091 20451 net.cpp:399] c14 -> c14
I0808 13:44:08.470123 20451 net.cpp:141] Setting up c14
I0808 13:44:08.470130 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470137 20451 net.cpp:156] Memory required for data: 396363264
I0808 13:44:08.470144 20451 layer_factory.hpp:77] Creating layer Input5
I0808 13:44:08.470152 20451 net.cpp:91] Creating Layer Input5
I0808 13:44:08.470161 20451 net.cpp:399] Input5 -> Input5
I0808 13:44:08.470191 20451 net.cpp:141] Setting up Input5
I0808 13:44:08.470201 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470207 20451 net.cpp:156] Memory required for data: 399508992
I0808 13:44:08.470213 20451 layer_factory.hpp:77] Creating layer c15
I0808 13:44:08.470222 20451 net.cpp:91] Creating Layer c15
I0808 13:44:08.470229 20451 net.cpp:425] c15 <- i1_i1_0_split_5
I0808 13:44:08.470238 20451 net.cpp:425] c15 <- Input5
I0808 13:44:08.470248 20451 net.cpp:399] c15 -> c15
I0808 13:44:08.470278 20451 net.cpp:141] Setting up c15
I0808 13:44:08.470288 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470293 20451 net.cpp:156] Memory required for data: 402654720
I0808 13:44:08.470300 20451 layer_factory.hpp:77] Creating layer Input6
I0808 13:44:08.470309 20451 net.cpp:91] Creating Layer Input6
I0808 13:44:08.470317 20451 net.cpp:399] Input6 -> Input6
I0808 13:44:08.470346 20451 net.cpp:141] Setting up Input6
I0808 13:44:08.470355 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470361 20451 net.cpp:156] Memory required for data: 405800448
I0808 13:44:08.470367 20451 layer_factory.hpp:77] Creating layer c16
I0808 13:44:08.470376 20451 net.cpp:91] Creating Layer c16
I0808 13:44:08.470383 20451 net.cpp:425] c16 <- i1_i1_0_split_6
I0808 13:44:08.470392 20451 net.cpp:425] c16 <- Input6
I0808 13:44:08.470402 20451 net.cpp:399] c16 -> c16
I0808 13:44:08.470432 20451 net.cpp:141] Setting up c16
I0808 13:44:08.470440 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470448 20451 net.cpp:156] Memory required for data: 408946176
I0808 13:44:08.470453 20451 layer_factory.hpp:77] Creating layer Input7
I0808 13:44:08.470463 20451 net.cpp:91] Creating Layer Input7
I0808 13:44:08.470471 20451 net.cpp:399] Input7 -> Input7
I0808 13:44:08.470499 20451 net.cpp:141] Setting up Input7
I0808 13:44:08.470510 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470516 20451 net.cpp:156] Memory required for data: 412091904
I0808 13:44:08.470523 20451 layer_factory.hpp:77] Creating layer c17
I0808 13:44:08.470532 20451 net.cpp:91] Creating Layer c17
I0808 13:44:08.470540 20451 net.cpp:425] c17 <- i1_i1_0_split_7
I0808 13:44:08.470548 20451 net.cpp:425] c17 <- Input7
I0808 13:44:08.470558 20451 net.cpp:399] c17 -> c17
I0808 13:44:08.470595 20451 net.cpp:141] Setting up c17
I0808 13:44:08.470607 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470613 20451 net.cpp:156] Memory required for data: 415237632
I0808 13:44:08.470620 20451 layer_factory.hpp:77] Creating layer Input8
I0808 13:44:08.470629 20451 net.cpp:91] Creating Layer Input8
I0808 13:44:08.470638 20451 net.cpp:399] Input8 -> Input8
I0808 13:44:08.470669 20451 net.cpp:141] Setting up Input8
I0808 13:44:08.470679 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470685 20451 net.cpp:156] Memory required for data: 418383360
I0808 13:44:08.470692 20451 layer_factory.hpp:77] Creating layer c18
I0808 13:44:08.470701 20451 net.cpp:91] Creating Layer c18
I0808 13:44:08.470707 20451 net.cpp:425] c18 <- i1_i1_0_split_8
I0808 13:44:08.470716 20451 net.cpp:425] c18 <- Input8
I0808 13:44:08.470726 20451 net.cpp:399] c18 -> c18
I0808 13:44:08.470757 20451 net.cpp:141] Setting up c18
I0808 13:44:08.470765 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470772 20451 net.cpp:156] Memory required for data: 421529088
I0808 13:44:08.470779 20451 layer_factory.hpp:77] Creating layer Input9
I0808 13:44:08.470798 20451 net.cpp:91] Creating Layer Input9
I0808 13:44:08.470806 20451 net.cpp:399] Input9 -> Input9
I0808 13:44:08.470836 20451 net.cpp:141] Setting up Input9
I0808 13:44:08.470845 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470851 20451 net.cpp:156] Memory required for data: 424674816
I0808 13:44:08.470859 20451 layer_factory.hpp:77] Creating layer c19
I0808 13:44:08.470867 20451 net.cpp:91] Creating Layer c19
I0808 13:44:08.470875 20451 net.cpp:425] c19 <- i1_i1_0_split_9
I0808 13:44:08.470882 20451 net.cpp:425] c19 <- Input9
I0808 13:44:08.470892 20451 net.cpp:399] c19 -> c19
I0808 13:44:08.470922 20451 net.cpp:141] Setting up c19
I0808 13:44:08.470932 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.470937 20451 net.cpp:156] Memory required for data: 427820544
I0808 13:44:08.470944 20451 layer_factory.hpp:77] Creating layer Input10
I0808 13:44:08.470953 20451 net.cpp:91] Creating Layer Input10
I0808 13:44:08.470963 20451 net.cpp:399] Input10 -> Input10
I0808 13:44:08.470991 20451 net.cpp:141] Setting up Input10
I0808 13:44:08.471000 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471006 20451 net.cpp:156] Memory required for data: 430966272
I0808 13:44:08.471014 20451 layer_factory.hpp:77] Creating layer c21
I0808 13:44:08.471022 20451 net.cpp:91] Creating Layer c21
I0808 13:44:08.471029 20451 net.cpp:425] c21 <- i2_i1_1_split_1
I0808 13:44:08.471037 20451 net.cpp:425] c21 <- Input10
I0808 13:44:08.471047 20451 net.cpp:399] c21 -> c21
I0808 13:44:08.471077 20451 net.cpp:141] Setting up c21
I0808 13:44:08.471086 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471092 20451 net.cpp:156] Memory required for data: 434112000
I0808 13:44:08.471099 20451 layer_factory.hpp:77] Creating layer Input11
I0808 13:44:08.471108 20451 net.cpp:91] Creating Layer Input11
I0808 13:44:08.471117 20451 net.cpp:399] Input11 -> Input11
I0808 13:44:08.471146 20451 net.cpp:141] Setting up Input11
I0808 13:44:08.471155 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471161 20451 net.cpp:156] Memory required for data: 437257728
I0808 13:44:08.471168 20451 layer_factory.hpp:77] Creating layer c22
I0808 13:44:08.471181 20451 net.cpp:91] Creating Layer c22
I0808 13:44:08.471189 20451 net.cpp:425] c22 <- i2_i1_1_split_2
I0808 13:44:08.471197 20451 net.cpp:425] c22 <- Input11
I0808 13:44:08.471207 20451 net.cpp:399] c22 -> c22
I0808 13:44:08.471237 20451 net.cpp:141] Setting up c22
I0808 13:44:08.471246 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471252 20451 net.cpp:156] Memory required for data: 440403456
I0808 13:44:08.471259 20451 layer_factory.hpp:77] Creating layer Input12
I0808 13:44:08.471268 20451 net.cpp:91] Creating Layer Input12
I0808 13:44:08.471292 20451 net.cpp:399] Input12 -> Input12
I0808 13:44:08.471325 20451 net.cpp:141] Setting up Input12
I0808 13:44:08.471338 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471343 20451 net.cpp:156] Memory required for data: 443549184
I0808 13:44:08.471350 20451 layer_factory.hpp:77] Creating layer c23
I0808 13:44:08.471359 20451 net.cpp:91] Creating Layer c23
I0808 13:44:08.471366 20451 net.cpp:425] c23 <- i2_i1_1_split_3
I0808 13:44:08.471375 20451 net.cpp:425] c23 <- Input12
I0808 13:44:08.471385 20451 net.cpp:399] c23 -> c23
I0808 13:44:08.471415 20451 net.cpp:141] Setting up c23
I0808 13:44:08.471426 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471431 20451 net.cpp:156] Memory required for data: 446694912
I0808 13:44:08.471441 20451 layer_factory.hpp:77] Creating layer Input13
I0808 13:44:08.471449 20451 net.cpp:91] Creating Layer Input13
I0808 13:44:08.471457 20451 net.cpp:399] Input13 -> Input13
I0808 13:44:08.471487 20451 net.cpp:141] Setting up Input13
I0808 13:44:08.471496 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471503 20451 net.cpp:156] Memory required for data: 449840640
I0808 13:44:08.471509 20451 layer_factory.hpp:77] Creating layer c24
I0808 13:44:08.471529 20451 net.cpp:91] Creating Layer c24
I0808 13:44:08.471536 20451 net.cpp:425] c24 <- i2_i1_1_split_4
I0808 13:44:08.471545 20451 net.cpp:425] c24 <- Input13
I0808 13:44:08.471555 20451 net.cpp:399] c24 -> c24
I0808 13:44:08.471586 20451 net.cpp:141] Setting up c24
I0808 13:44:08.471596 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471601 20451 net.cpp:156] Memory required for data: 452986368
I0808 13:44:08.471607 20451 layer_factory.hpp:77] Creating layer Input14
I0808 13:44:08.471618 20451 net.cpp:91] Creating Layer Input14
I0808 13:44:08.471626 20451 net.cpp:399] Input14 -> Input14
I0808 13:44:08.471657 20451 net.cpp:141] Setting up Input14
I0808 13:44:08.471668 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471673 20451 net.cpp:156] Memory required for data: 456132096
I0808 13:44:08.471679 20451 layer_factory.hpp:77] Creating layer c25
I0808 13:44:08.471688 20451 net.cpp:91] Creating Layer c25
I0808 13:44:08.471695 20451 net.cpp:425] c25 <- i2_i1_1_split_5
I0808 13:44:08.471704 20451 net.cpp:425] c25 <- Input14
I0808 13:44:08.471714 20451 net.cpp:399] c25 -> c25
I0808 13:44:08.471745 20451 net.cpp:141] Setting up c25
I0808 13:44:08.471752 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471760 20451 net.cpp:156] Memory required for data: 459277824
I0808 13:44:08.471765 20451 layer_factory.hpp:77] Creating layer Input15
I0808 13:44:08.471774 20451 net.cpp:91] Creating Layer Input15
I0808 13:44:08.471783 20451 net.cpp:399] Input15 -> Input15
I0808 13:44:08.471812 20451 net.cpp:141] Setting up Input15
I0808 13:44:08.471822 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471827 20451 net.cpp:156] Memory required for data: 462423552
I0808 13:44:08.471834 20451 layer_factory.hpp:77] Creating layer c26
I0808 13:44:08.471843 20451 net.cpp:91] Creating Layer c26
I0808 13:44:08.471849 20451 net.cpp:425] c26 <- i2_i1_1_split_6
I0808 13:44:08.471858 20451 net.cpp:425] c26 <- Input15
I0808 13:44:08.471868 20451 net.cpp:399] c26 -> c26
I0808 13:44:08.471899 20451 net.cpp:141] Setting up c26
I0808 13:44:08.471907 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471913 20451 net.cpp:156] Memory required for data: 465569280
I0808 13:44:08.471920 20451 layer_factory.hpp:77] Creating layer Input16
I0808 13:44:08.471928 20451 net.cpp:91] Creating Layer Input16
I0808 13:44:08.471937 20451 net.cpp:399] Input16 -> Input16
I0808 13:44:08.471966 20451 net.cpp:141] Setting up Input16
I0808 13:44:08.471976 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.471982 20451 net.cpp:156] Memory required for data: 468715008
I0808 13:44:08.471988 20451 layer_factory.hpp:77] Creating layer c27
I0808 13:44:08.471997 20451 net.cpp:91] Creating Layer c27
I0808 13:44:08.472003 20451 net.cpp:425] c27 <- i2_i1_1_split_7
I0808 13:44:08.472012 20451 net.cpp:425] c27 <- Input16
I0808 13:44:08.472023 20451 net.cpp:399] c27 -> c27
I0808 13:44:08.472053 20451 net.cpp:141] Setting up c27
I0808 13:44:08.472061 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.472067 20451 net.cpp:156] Memory required for data: 471860736
I0808 13:44:08.472074 20451 layer_factory.hpp:77] Creating layer Input17
I0808 13:44:08.472084 20451 net.cpp:91] Creating Layer Input17
I0808 13:44:08.472091 20451 net.cpp:399] Input17 -> Input17
I0808 13:44:08.472121 20451 net.cpp:141] Setting up Input17
I0808 13:44:08.472131 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.472136 20451 net.cpp:156] Memory required for data: 475006464
I0808 13:44:08.472143 20451 layer_factory.hpp:77] Creating layer c28
I0808 13:44:08.472152 20451 net.cpp:91] Creating Layer c28
I0808 13:44:08.472159 20451 net.cpp:425] c28 <- i2_i1_1_split_8
I0808 13:44:08.472167 20451 net.cpp:425] c28 <- Input17
I0808 13:44:08.472178 20451 net.cpp:399] c28 -> c28
I0808 13:44:08.472208 20451 net.cpp:141] Setting up c28
I0808 13:44:08.472218 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.472223 20451 net.cpp:156] Memory required for data: 478152192
I0808 13:44:08.472229 20451 layer_factory.hpp:77] Creating layer Input18
I0808 13:44:08.472249 20451 net.cpp:91] Creating Layer Input18
I0808 13:44:08.472257 20451 net.cpp:399] Input18 -> Input18
I0808 13:44:08.472286 20451 net.cpp:141] Setting up Input18
I0808 13:44:08.472295 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.472301 20451 net.cpp:156] Memory required for data: 481297920
I0808 13:44:08.472308 20451 layer_factory.hpp:77] Creating layer c29
I0808 13:44:08.472317 20451 net.cpp:91] Creating Layer c29
I0808 13:44:08.472324 20451 net.cpp:425] c29 <- i2_i1_1_split_9
I0808 13:44:08.472332 20451 net.cpp:425] c29 <- Input18
I0808 13:44:08.472342 20451 net.cpp:399] c29 -> c29
I0808 13:44:08.472373 20451 net.cpp:141] Setting up c29
I0808 13:44:08.472381 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:08.472388 20451 net.cpp:156] Memory required for data: 484443648
I0808 13:44:08.472394 20451 layer_factory.hpp:77] Creating layer Convolution1
I0808 13:44:08.472414 20451 net.cpp:91] Creating Layer Convolution1
I0808 13:44:08.472421 20451 net.cpp:425] Convolution1 <- p1_p1_0_split_0
I0808 13:44:08.472432 20451 net.cpp:399] Convolution1 -> Convolution1
I0808 13:44:08.473487 20451 net.cpp:141] Setting up Convolution1
I0808 13:44:08.473501 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.473507 20451 net.cpp:156] Memory required for data: 502875648
I0808 13:44:08.473526 20451 layer_factory.hpp:77] Creating layer Pooling1
I0808 13:44:08.473536 20451 net.cpp:91] Creating Layer Pooling1
I0808 13:44:08.473543 20451 net.cpp:425] Pooling1 <- Convolution1
I0808 13:44:08.473554 20451 net.cpp:399] Pooling1 -> Pooling1
I0808 13:44:08.473603 20451 net.cpp:141] Setting up Pooling1
I0808 13:44:08.473613 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.473618 20451 net.cpp:156] Memory required for data: 507483648
I0808 13:44:08.473625 20451 layer_factory.hpp:77] Creating layer Convolution2
I0808 13:44:08.473639 20451 net.cpp:91] Creating Layer Convolution2
I0808 13:44:08.473646 20451 net.cpp:425] Convolution2 <- Pooling1
I0808 13:44:08.473657 20451 net.cpp:399] Convolution2 -> Convolution2
I0808 13:44:08.475450 20451 net.cpp:141] Setting up Convolution2
I0808 13:44:08.475466 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.475473 20451 net.cpp:156] Memory required for data: 516136448
I0808 13:44:08.475487 20451 layer_factory.hpp:77] Creating layer Pooling2
I0808 13:44:08.475498 20451 net.cpp:91] Creating Layer Pooling2
I0808 13:44:08.475507 20451 net.cpp:425] Pooling2 <- Convolution2
I0808 13:44:08.475517 20451 net.cpp:399] Pooling2 -> Pooling2
I0808 13:44:08.475570 20451 net.cpp:141] Setting up Pooling2
I0808 13:44:08.475579 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.475585 20451 net.cpp:156] Memory required for data: 518299648
I0808 13:44:08.475592 20451 layer_factory.hpp:77] Creating layer Convolution3
I0808 13:44:08.475606 20451 net.cpp:91] Creating Layer Convolution3
I0808 13:44:08.475613 20451 net.cpp:425] Convolution3 <- Pooling2
I0808 13:44:08.475625 20451 net.cpp:399] Convolution3 -> Convolution3
I0808 13:44:08.476485 20451 net.cpp:141] Setting up Convolution3
I0808 13:44:08.476495 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.476501 20451 net.cpp:156] Memory required for data: 519336448
I0808 13:44:08.476513 20451 layer_factory.hpp:77] Creating layer Pooling3
I0808 13:44:08.476522 20451 net.cpp:91] Creating Layer Pooling3
I0808 13:44:08.476529 20451 net.cpp:425] Pooling3 <- Convolution3
I0808 13:44:08.476541 20451 net.cpp:399] Pooling3 -> Pooling3
I0808 13:44:08.476590 20451 net.cpp:141] Setting up Pooling3
I0808 13:44:08.476599 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.476606 20451 net.cpp:156] Memory required for data: 519656448
I0808 13:44:08.476613 20451 layer_factory.hpp:77] Creating layer InnerProduct1
I0808 13:44:08.476624 20451 net.cpp:91] Creating Layer InnerProduct1
I0808 13:44:08.476630 20451 net.cpp:425] InnerProduct1 <- Pooling3
I0808 13:44:08.476642 20451 net.cpp:399] InnerProduct1 -> InnerProduct1
I0808 13:44:08.477965 20451 net.cpp:141] Setting up InnerProduct1
I0808 13:44:08.477975 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.477982 20451 net.cpp:156] Memory required for data: 519682048
I0808 13:44:08.477991 20451 layer_factory.hpp:77] Creating layer ReLU1
I0808 13:44:08.478000 20451 net.cpp:91] Creating Layer ReLU1
I0808 13:44:08.478008 20451 net.cpp:425] ReLU1 <- InnerProduct1
I0808 13:44:08.478018 20451 net.cpp:386] ReLU1 -> InnerProduct1 (in-place)
I0808 13:44:08.478029 20451 net.cpp:141] Setting up ReLU1
I0808 13:44:08.478037 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.478044 20451 net.cpp:156] Memory required for data: 519707648
I0808 13:44:08.478050 20451 layer_factory.hpp:77] Creating layer InnerProduct2
I0808 13:44:08.478060 20451 net.cpp:91] Creating Layer InnerProduct2
I0808 13:44:08.478067 20451 net.cpp:425] InnerProduct2 <- InnerProduct1
I0808 13:44:08.478080 20451 net.cpp:399] InnerProduct2 -> InnerProduct2
I0808 13:44:08.478919 20451 net.cpp:141] Setting up InnerProduct2
I0808 13:44:08.478932 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.478938 20451 net.cpp:156] Memory required for data: 519720448
I0808 13:44:08.478953 20451 layer_factory.hpp:77] Creating layer Convolution4
I0808 13:44:08.478968 20451 net.cpp:91] Creating Layer Convolution4
I0808 13:44:08.478976 20451 net.cpp:425] Convolution4 <- p2_p2_0_split_0
I0808 13:44:08.478989 20451 net.cpp:399] Convolution4 -> Convolution4
I0808 13:44:08.479367 20451 net.cpp:141] Setting up Convolution4
I0808 13:44:08.479377 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.479382 20451 net.cpp:156] Memory required for data: 538152448
I0808 13:44:08.479388 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.479396 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.479403 20451 layer_factory.hpp:77] Creating layer Pooling4
I0808 13:44:08.479411 20451 net.cpp:91] Creating Layer Pooling4
I0808 13:44:08.479418 20451 net.cpp:425] Pooling4 <- Convolution4
I0808 13:44:08.479427 20451 net.cpp:399] Pooling4 -> Pooling4
I0808 13:44:08.479473 20451 net.cpp:141] Setting up Pooling4
I0808 13:44:08.479481 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.479487 20451 net.cpp:156] Memory required for data: 542760448
I0808 13:44:08.479492 20451 layer_factory.hpp:77] Creating layer Convolution5
I0808 13:44:08.479506 20451 net.cpp:91] Creating Layer Convolution5
I0808 13:44:08.479513 20451 net.cpp:425] Convolution5 <- Pooling4
I0808 13:44:08.479523 20451 net.cpp:399] Convolution5 -> Convolution5
I0808 13:44:08.480015 20451 net.cpp:141] Setting up Convolution5
I0808 13:44:08.480023 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.480029 20451 net.cpp:156] Memory required for data: 551413248
I0808 13:44:08.480036 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.480043 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.480049 20451 layer_factory.hpp:77] Creating layer Pooling5
I0808 13:44:08.480060 20451 net.cpp:91] Creating Layer Pooling5
I0808 13:44:08.480067 20451 net.cpp:425] Pooling5 <- Convolution5
I0808 13:44:08.480075 20451 net.cpp:399] Pooling5 -> Pooling5
I0808 13:44:08.480121 20451 net.cpp:141] Setting up Pooling5
I0808 13:44:08.480129 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.480135 20451 net.cpp:156] Memory required for data: 553576448
I0808 13:44:08.480141 20451 layer_factory.hpp:77] Creating layer Convolution6
I0808 13:44:08.480154 20451 net.cpp:91] Creating Layer Convolution6
I0808 13:44:08.480161 20451 net.cpp:425] Convolution6 <- Pooling5
I0808 13:44:08.480171 20451 net.cpp:399] Convolution6 -> Convolution6
I0808 13:44:08.480957 20451 net.cpp:141] Setting up Convolution6
I0808 13:44:08.480965 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.480972 20451 net.cpp:156] Memory required for data: 554613248
I0808 13:44:08.480993 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.480999 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.481005 20451 layer_factory.hpp:77] Creating layer Pooling6
I0808 13:44:08.481015 20451 net.cpp:91] Creating Layer Pooling6
I0808 13:44:08.481022 20451 net.cpp:425] Pooling6 <- Convolution6
I0808 13:44:08.481034 20451 net.cpp:399] Pooling6 -> Pooling6
I0808 13:44:08.481081 20451 net.cpp:141] Setting up Pooling6
I0808 13:44:08.481088 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.481094 20451 net.cpp:156] Memory required for data: 554933248
I0808 13:44:08.481101 20451 layer_factory.hpp:77] Creating layer InnerProduct3
I0808 13:44:08.481112 20451 net.cpp:91] Creating Layer InnerProduct3
I0808 13:44:08.481118 20451 net.cpp:425] InnerProduct3 <- Pooling6
I0808 13:44:08.481128 20451 net.cpp:399] InnerProduct3 -> InnerProduct3
I0808 13:44:08.482895 20451 net.cpp:141] Setting up InnerProduct3
I0808 13:44:08.482910 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.482916 20451 net.cpp:156] Memory required for data: 554958848
I0808 13:44:08.482928 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.482936 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.482944 20451 layer_factory.hpp:77] Creating layer ReLU2
I0808 13:44:08.482955 20451 net.cpp:91] Creating Layer ReLU2
I0808 13:44:08.482962 20451 net.cpp:425] ReLU2 <- InnerProduct3
I0808 13:44:08.482971 20451 net.cpp:386] ReLU2 -> InnerProduct3 (in-place)
I0808 13:44:08.482982 20451 net.cpp:141] Setting up ReLU2
I0808 13:44:08.482990 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.482995 20451 net.cpp:156] Memory required for data: 554984448
I0808 13:44:08.483001 20451 layer_factory.hpp:77] Creating layer InnerProduct4
I0808 13:44:08.483028 20451 net.cpp:91] Creating Layer InnerProduct4
I0808 13:44:08.483036 20451 net.cpp:425] InnerProduct4 <- InnerProduct3
I0808 13:44:08.483045 20451 net.cpp:399] InnerProduct4 -> InnerProduct4
I0808 13:44:08.483214 20451 net.cpp:141] Setting up InnerProduct4
I0808 13:44:08.483222 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.483228 20451 net.cpp:156] Memory required for data: 554997248
I0808 13:44:08.483234 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.483242 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.483249 20451 layer_factory.hpp:77] Creating layer Concat1
I0808 13:44:08.483265 20451 net.cpp:91] Creating Layer Concat1
I0808 13:44:08.483278 20451 net.cpp:425] Concat1 <- InnerProduct2
I0808 13:44:08.483286 20451 net.cpp:425] Concat1 <- InnerProduct4
I0808 13:44:08.483295 20451 net.cpp:399] Concat1 -> Concat1
I0808 13:44:08.483326 20451 net.cpp:141] Setting up Concat1
I0808 13:44:08.483335 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.483340 20451 net.cpp:156] Memory required for data: 555022848
I0808 13:44:08.483346 20451 layer_factory.hpp:77] Creating layer InnerProduct5
I0808 13:44:08.483357 20451 net.cpp:91] Creating Layer InnerProduct5
I0808 13:44:08.483364 20451 net.cpp:425] InnerProduct5 <- Concat1
I0808 13:44:08.483374 20451 net.cpp:399] InnerProduct5 -> InnerProduct5
I0808 13:44:08.483548 20451 net.cpp:141] Setting up InnerProduct5
I0808 13:44:08.483556 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.483561 20451 net.cpp:156] Memory required for data: 555039232
I0808 13:44:08.483571 20451 layer_factory.hpp:77] Creating layer ReLU3
I0808 13:44:08.483578 20451 net.cpp:91] Creating Layer ReLU3
I0808 13:44:08.483585 20451 net.cpp:425] ReLU3 <- InnerProduct5
I0808 13:44:08.483593 20451 net.cpp:386] ReLU3 -> InnerProduct5 (in-place)
I0808 13:44:08.483603 20451 net.cpp:141] Setting up ReLU3
I0808 13:44:08.483610 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.483615 20451 net.cpp:156] Memory required for data: 555055616
I0808 13:44:08.483635 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.483644 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.483650 20451 net.cpp:425] drop1 <- InnerProduct5
I0808 13:44:08.483664 20451 net.cpp:399] drop1 -> Dropout1
I0808 13:44:08.483713 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.483721 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.483726 20451 net.cpp:156] Memory required for data: 555072000
I0808 13:44:08.483732 20451 layer_factory.hpp:77] Creating layer InnerProduct6
I0808 13:44:08.483743 20451 net.cpp:91] Creating Layer InnerProduct6
I0808 13:44:08.483749 20451 net.cpp:425] InnerProduct6 <- Dropout1
I0808 13:44:08.483763 20451 net.cpp:399] InnerProduct6 -> InnerProduct6
I0808 13:44:08.483922 20451 net.cpp:141] Setting up InnerProduct6
I0808 13:44:08.483930 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.483935 20451 net.cpp:156] Memory required for data: 555080192
I0808 13:44:08.483944 20451 layer_factory.hpp:77] Creating layer ReLU4
I0808 13:44:08.483952 20451 net.cpp:91] Creating Layer ReLU4
I0808 13:44:08.483958 20451 net.cpp:425] ReLU4 <- InnerProduct6
I0808 13:44:08.483965 20451 net.cpp:386] ReLU4 -> InnerProduct6 (in-place)
I0808 13:44:08.483974 20451 net.cpp:141] Setting up ReLU4
I0808 13:44:08.483983 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.483989 20451 net.cpp:156] Memory required for data: 555088384
I0808 13:44:08.483994 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.484004 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.484010 20451 net.cpp:425] drop2 <- InnerProduct6
I0808 13:44:08.484019 20451 net.cpp:399] drop2 -> Dropout2
I0808 13:44:08.484064 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.484072 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.484078 20451 net.cpp:156] Memory required for data: 555096576
I0808 13:44:08.484084 20451 layer_factory.hpp:77] Creating layer dt0
I0808 13:44:08.484092 20451 net.cpp:91] Creating Layer dt0
I0808 13:44:08.484098 20451 net.cpp:425] dt0 <- Dropout2
I0808 13:44:08.484108 20451 net.cpp:399] dt0 -> dt0
I0808 13:44:08.484232 20451 net.cpp:141] Setting up dt0
I0808 13:44:08.484241 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.484246 20451 net.cpp:156] Memory required for data: 555096832
I0808 13:44:08.484254 20451 layer_factory.hpp:77] Creating layer Convolution7
I0808 13:44:08.484269 20451 net.cpp:91] Creating Layer Convolution7
I0808 13:44:08.484277 20451 net.cpp:425] Convolution7 <- p1_p1_0_split_1
I0808 13:44:08.484289 20451 net.cpp:399] Convolution7 -> Convolution7
I0808 13:44:08.484593 20451 net.cpp:141] Setting up Convolution7
I0808 13:44:08.484601 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.484606 20451 net.cpp:156] Memory required for data: 573528832
I0808 13:44:08.484612 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.484619 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.484625 20451 layer_factory.hpp:77] Creating layer Pooling7
I0808 13:44:08.484634 20451 net.cpp:91] Creating Layer Pooling7
I0808 13:44:08.484640 20451 net.cpp:425] Pooling7 <- Convolution7
I0808 13:44:08.484652 20451 net.cpp:399] Pooling7 -> Pooling7
I0808 13:44:08.484697 20451 net.cpp:141] Setting up Pooling7
I0808 13:44:08.484704 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.484710 20451 net.cpp:156] Memory required for data: 578136832
I0808 13:44:08.484715 20451 layer_factory.hpp:77] Creating layer Convolution8
I0808 13:44:08.484729 20451 net.cpp:91] Creating Layer Convolution8
I0808 13:44:08.484735 20451 net.cpp:425] Convolution8 <- Pooling7
I0808 13:44:08.484747 20451 net.cpp:399] Convolution8 -> Convolution8
I0808 13:44:08.485245 20451 net.cpp:141] Setting up Convolution8
I0808 13:44:08.485254 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.485260 20451 net.cpp:156] Memory required for data: 586789632
I0808 13:44:08.485265 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.485280 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.485287 20451 layer_factory.hpp:77] Creating layer Pooling8
I0808 13:44:08.485298 20451 net.cpp:91] Creating Layer Pooling8
I0808 13:44:08.485304 20451 net.cpp:425] Pooling8 <- Convolution8
I0808 13:44:08.485313 20451 net.cpp:399] Pooling8 -> Pooling8
I0808 13:44:08.485359 20451 net.cpp:141] Setting up Pooling8
I0808 13:44:08.485368 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.485373 20451 net.cpp:156] Memory required for data: 588952832
I0808 13:44:08.485378 20451 layer_factory.hpp:77] Creating layer Convolution9
I0808 13:44:08.485402 20451 net.cpp:91] Creating Layer Convolution9
I0808 13:44:08.485409 20451 net.cpp:425] Convolution9 <- Pooling8
I0808 13:44:08.485419 20451 net.cpp:399] Convolution9 -> Convolution9
I0808 13:44:08.486872 20451 net.cpp:141] Setting up Convolution9
I0808 13:44:08.486886 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.486892 20451 net.cpp:156] Memory required for data: 589989632
I0808 13:44:08.486901 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.486908 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.486915 20451 layer_factory.hpp:77] Creating layer Pooling9
I0808 13:44:08.486928 20451 net.cpp:91] Creating Layer Pooling9
I0808 13:44:08.486937 20451 net.cpp:425] Pooling9 <- Convolution9
I0808 13:44:08.486948 20451 net.cpp:399] Pooling9 -> Pooling9
I0808 13:44:08.487004 20451 net.cpp:141] Setting up Pooling9
I0808 13:44:08.487011 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.487018 20451 net.cpp:156] Memory required for data: 590309632
I0808 13:44:08.487025 20451 layer_factory.hpp:77] Creating layer InnerProduct7
I0808 13:44:08.487036 20451 net.cpp:91] Creating Layer InnerProduct7
I0808 13:44:08.487043 20451 net.cpp:425] InnerProduct7 <- Pooling9
I0808 13:44:08.487054 20451 net.cpp:399] InnerProduct7 -> InnerProduct7
I0808 13:44:08.488293 20451 net.cpp:141] Setting up InnerProduct7
I0808 13:44:08.488303 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.488309 20451 net.cpp:156] Memory required for data: 590335232
I0808 13:44:08.488328 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.488337 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.488344 20451 layer_factory.hpp:77] Creating layer ReLU5
I0808 13:44:08.488353 20451 net.cpp:91] Creating Layer ReLU5
I0808 13:44:08.488360 20451 net.cpp:425] ReLU5 <- InnerProduct7
I0808 13:44:08.488373 20451 net.cpp:386] ReLU5 -> InnerProduct7 (in-place)
I0808 13:44:08.488384 20451 net.cpp:141] Setting up ReLU5
I0808 13:44:08.488391 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.488397 20451 net.cpp:156] Memory required for data: 590360832
I0808 13:44:08.488404 20451 layer_factory.hpp:77] Creating layer InnerProduct8
I0808 13:44:08.488415 20451 net.cpp:91] Creating Layer InnerProduct8
I0808 13:44:08.488420 20451 net.cpp:425] InnerProduct8 <- InnerProduct7
I0808 13:44:08.488433 20451 net.cpp:399] InnerProduct8 -> InnerProduct8
I0808 13:44:08.488611 20451 net.cpp:141] Setting up InnerProduct8
I0808 13:44:08.488620 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.488625 20451 net.cpp:156] Memory required for data: 590373632
I0808 13:44:08.488631 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.488638 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.488644 20451 layer_factory.hpp:77] Creating layer Convolution10
I0808 13:44:08.488658 20451 net.cpp:91] Creating Layer Convolution10
I0808 13:44:08.488665 20451 net.cpp:425] Convolution10 <- c21
I0808 13:44:08.488679 20451 net.cpp:399] Convolution10 -> Convolution10
I0808 13:44:08.488992 20451 net.cpp:141] Setting up Convolution10
I0808 13:44:08.489015 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.489022 20451 net.cpp:156] Memory required for data: 608805632
I0808 13:44:08.489027 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.489034 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.489040 20451 layer_factory.hpp:77] Creating layer Pooling10
I0808 13:44:08.489053 20451 net.cpp:91] Creating Layer Pooling10
I0808 13:44:08.489059 20451 net.cpp:425] Pooling10 <- Convolution10
I0808 13:44:08.489068 20451 net.cpp:399] Pooling10 -> Pooling10
I0808 13:44:08.489117 20451 net.cpp:141] Setting up Pooling10
I0808 13:44:08.489125 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.489131 20451 net.cpp:156] Memory required for data: 613413632
I0808 13:44:08.489136 20451 layer_factory.hpp:77] Creating layer Convolution11
I0808 13:44:08.489151 20451 net.cpp:91] Creating Layer Convolution11
I0808 13:44:08.489157 20451 net.cpp:425] Convolution11 <- Pooling10
I0808 13:44:08.489171 20451 net.cpp:399] Convolution11 -> Convolution11
I0808 13:44:08.489673 20451 net.cpp:141] Setting up Convolution11
I0808 13:44:08.489681 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.489687 20451 net.cpp:156] Memory required for data: 622066432
I0808 13:44:08.489694 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.489701 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.489707 20451 layer_factory.hpp:77] Creating layer Pooling11
I0808 13:44:08.489715 20451 net.cpp:91] Creating Layer Pooling11
I0808 13:44:08.489722 20451 net.cpp:425] Pooling11 <- Convolution11
I0808 13:44:08.489733 20451 net.cpp:399] Pooling11 -> Pooling11
I0808 13:44:08.489778 20451 net.cpp:141] Setting up Pooling11
I0808 13:44:08.489787 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.489802 20451 net.cpp:156] Memory required for data: 624229632
I0808 13:44:08.489807 20451 layer_factory.hpp:77] Creating layer Convolution12
I0808 13:44:08.489821 20451 net.cpp:91] Creating Layer Convolution12
I0808 13:44:08.489827 20451 net.cpp:425] Convolution12 <- Pooling11
I0808 13:44:08.489840 20451 net.cpp:399] Convolution12 -> Convolution12
I0808 13:44:08.490610 20451 net.cpp:141] Setting up Convolution12
I0808 13:44:08.490619 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.490624 20451 net.cpp:156] Memory required for data: 625266432
I0808 13:44:08.490630 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.490638 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.490643 20451 layer_factory.hpp:77] Creating layer Pooling12
I0808 13:44:08.490651 20451 net.cpp:91] Creating Layer Pooling12
I0808 13:44:08.490658 20451 net.cpp:425] Pooling12 <- Convolution12
I0808 13:44:08.490669 20451 net.cpp:399] Pooling12 -> Pooling12
I0808 13:44:08.490712 20451 net.cpp:141] Setting up Pooling12
I0808 13:44:08.490720 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.490725 20451 net.cpp:156] Memory required for data: 625586432
I0808 13:44:08.490731 20451 layer_factory.hpp:77] Creating layer InnerProduct9
I0808 13:44:08.490742 20451 net.cpp:91] Creating Layer InnerProduct9
I0808 13:44:08.490748 20451 net.cpp:425] InnerProduct9 <- Pooling12
I0808 13:44:08.490761 20451 net.cpp:399] InnerProduct9 -> InnerProduct9
I0808 13:44:08.492533 20451 net.cpp:141] Setting up InnerProduct9
I0808 13:44:08.492549 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.492555 20451 net.cpp:156] Memory required for data: 625612032
I0808 13:44:08.492564 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.492573 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.492580 20451 layer_factory.hpp:77] Creating layer ReLU6
I0808 13:44:08.492609 20451 net.cpp:91] Creating Layer ReLU6
I0808 13:44:08.492617 20451 net.cpp:425] ReLU6 <- InnerProduct9
I0808 13:44:08.492627 20451 net.cpp:386] ReLU6 -> InnerProduct9 (in-place)
I0808 13:44:08.492640 20451 net.cpp:141] Setting up ReLU6
I0808 13:44:08.492648 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.492655 20451 net.cpp:156] Memory required for data: 625637632
I0808 13:44:08.492661 20451 layer_factory.hpp:77] Creating layer InnerProduct10
I0808 13:44:08.492676 20451 net.cpp:91] Creating Layer InnerProduct10
I0808 13:44:08.492682 20451 net.cpp:425] InnerProduct10 <- InnerProduct9
I0808 13:44:08.492692 20451 net.cpp:399] InnerProduct10 -> InnerProduct10
I0808 13:44:08.492882 20451 net.cpp:141] Setting up InnerProduct10
I0808 13:44:08.492890 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.492897 20451 net.cpp:156] Memory required for data: 625650432
I0808 13:44:08.492903 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.492913 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.492920 20451 layer_factory.hpp:77] Creating layer Concat2
I0808 13:44:08.492934 20451 net.cpp:91] Creating Layer Concat2
I0808 13:44:08.492943 20451 net.cpp:425] Concat2 <- InnerProduct8
I0808 13:44:08.492951 20451 net.cpp:425] Concat2 <- InnerProduct10
I0808 13:44:08.492961 20451 net.cpp:399] Concat2 -> Concat2
I0808 13:44:08.493000 20451 net.cpp:141] Setting up Concat2
I0808 13:44:08.493010 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.493016 20451 net.cpp:156] Memory required for data: 625676032
I0808 13:44:08.493026 20451 layer_factory.hpp:77] Creating layer InnerProduct11
I0808 13:44:08.493036 20451 net.cpp:91] Creating Layer InnerProduct11
I0808 13:44:08.493043 20451 net.cpp:425] InnerProduct11 <- Concat2
I0808 13:44:08.493059 20451 net.cpp:399] InnerProduct11 -> InnerProduct11
I0808 13:44:08.493258 20451 net.cpp:141] Setting up InnerProduct11
I0808 13:44:08.493268 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.493273 20451 net.cpp:156] Memory required for data: 625692416
I0808 13:44:08.493281 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.493289 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.493296 20451 layer_factory.hpp:77] Creating layer ReLU7
I0808 13:44:08.493304 20451 net.cpp:91] Creating Layer ReLU7
I0808 13:44:08.493311 20451 net.cpp:425] ReLU7 <- InnerProduct11
I0808 13:44:08.493324 20451 net.cpp:386] ReLU7 -> InnerProduct11 (in-place)
I0808 13:44:08.493335 20451 net.cpp:141] Setting up ReLU7
I0808 13:44:08.493345 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.493353 20451 net.cpp:156] Memory required for data: 625708800
I0808 13:44:08.493360 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.493372 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.493379 20451 net.cpp:425] drop1 <- InnerProduct11
I0808 13:44:08.493391 20451 net.cpp:399] drop1 -> Dropout3
I0808 13:44:08.493449 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.493460 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.493468 20451 net.cpp:156] Memory required for data: 625725184
I0808 13:44:08.493474 20451 layer_factory.hpp:77] Creating layer InnerProduct12
I0808 13:44:08.493495 20451 net.cpp:91] Creating Layer InnerProduct12
I0808 13:44:08.493502 20451 net.cpp:425] InnerProduct12 <- Dropout3
I0808 13:44:08.493517 20451 net.cpp:399] InnerProduct12 -> InnerProduct12
I0808 13:44:08.493724 20451 net.cpp:141] Setting up InnerProduct12
I0808 13:44:08.493739 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.493746 20451 net.cpp:156] Memory required for data: 625733376
I0808 13:44:08.493754 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.493763 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.493772 20451 layer_factory.hpp:77] Creating layer ReLU8
I0808 13:44:08.493793 20451 net.cpp:91] Creating Layer ReLU8
I0808 13:44:08.493800 20451 net.cpp:425] ReLU8 <- InnerProduct12
I0808 13:44:08.493809 20451 net.cpp:386] ReLU8 -> InnerProduct12 (in-place)
I0808 13:44:08.493820 20451 net.cpp:141] Setting up ReLU8
I0808 13:44:08.493829 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.493835 20451 net.cpp:156] Memory required for data: 625741568
I0808 13:44:08.493842 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.493851 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.493859 20451 net.cpp:425] drop2 <- InnerProduct12
I0808 13:44:08.493867 20451 net.cpp:399] drop2 -> Dropout4
I0808 13:44:08.493918 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.493928 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.493935 20451 net.cpp:156] Memory required for data: 625749760
I0808 13:44:08.493943 20451 layer_factory.hpp:77] Creating layer dt1
I0808 13:44:08.493957 20451 net.cpp:91] Creating Layer dt1
I0808 13:44:08.493963 20451 net.cpp:425] dt1 <- Dropout4
I0808 13:44:08.493978 20451 net.cpp:399] dt1 -> dt1
I0808 13:44:08.494138 20451 net.cpp:141] Setting up dt1
I0808 13:44:08.494151 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.494159 20451 net.cpp:156] Memory required for data: 625750016
I0808 13:44:08.494168 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.494176 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.494184 20451 layer_factory.hpp:77] Creating layer Convolution13
I0808 13:44:08.494199 20451 net.cpp:91] Creating Layer Convolution13
I0808 13:44:08.494209 20451 net.cpp:425] Convolution13 <- p1_p1_0_split_2
I0808 13:44:08.494225 20451 net.cpp:399] Convolution13 -> Convolution13
I0808 13:44:08.494602 20451 net.cpp:141] Setting up Convolution13
I0808 13:44:08.494613 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.494621 20451 net.cpp:156] Memory required for data: 644182016
I0808 13:44:08.494628 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.494637 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.494644 20451 layer_factory.hpp:77] Creating layer Pooling13
I0808 13:44:08.494655 20451 net.cpp:91] Creating Layer Pooling13
I0808 13:44:08.494663 20451 net.cpp:425] Pooling13 <- Convolution13
I0808 13:44:08.494676 20451 net.cpp:399] Pooling13 -> Pooling13
I0808 13:44:08.494729 20451 net.cpp:141] Setting up Pooling13
I0808 13:44:08.494740 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.494745 20451 net.cpp:156] Memory required for data: 648790016
I0808 13:44:08.494752 20451 layer_factory.hpp:77] Creating layer Convolution14
I0808 13:44:08.494771 20451 net.cpp:91] Creating Layer Convolution14
I0808 13:44:08.494777 20451 net.cpp:425] Convolution14 <- Pooling13
I0808 13:44:08.494788 20451 net.cpp:399] Convolution14 -> Convolution14
I0808 13:44:08.495409 20451 net.cpp:141] Setting up Convolution14
I0808 13:44:08.495427 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.495436 20451 net.cpp:156] Memory required for data: 657442816
I0808 13:44:08.495446 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.495456 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.495465 20451 layer_factory.hpp:77] Creating layer Pooling14
I0808 13:44:08.495478 20451 net.cpp:91] Creating Layer Pooling14
I0808 13:44:08.495486 20451 net.cpp:425] Pooling14 <- Convolution14
I0808 13:44:08.495499 20451 net.cpp:399] Pooling14 -> Pooling14
I0808 13:44:08.495565 20451 net.cpp:141] Setting up Pooling14
I0808 13:44:08.495578 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.495585 20451 net.cpp:156] Memory required for data: 659606016
I0808 13:44:08.495594 20451 layer_factory.hpp:77] Creating layer Convolution15
I0808 13:44:08.495614 20451 net.cpp:91] Creating Layer Convolution15
I0808 13:44:08.495640 20451 net.cpp:425] Convolution15 <- Pooling14
I0808 13:44:08.495657 20451 net.cpp:399] Convolution15 -> Convolution15
I0808 13:44:08.496551 20451 net.cpp:141] Setting up Convolution15
I0808 13:44:08.496562 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.496568 20451 net.cpp:156] Memory required for data: 660642816
I0808 13:44:08.496575 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.496583 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.496589 20451 layer_factory.hpp:77] Creating layer Pooling15
I0808 13:44:08.496598 20451 net.cpp:91] Creating Layer Pooling15
I0808 13:44:08.496605 20451 net.cpp:425] Pooling15 <- Convolution15
I0808 13:44:08.496616 20451 net.cpp:399] Pooling15 -> Pooling15
I0808 13:44:08.496666 20451 net.cpp:141] Setting up Pooling15
I0808 13:44:08.496676 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.496682 20451 net.cpp:156] Memory required for data: 660962816
I0808 13:44:08.496688 20451 layer_factory.hpp:77] Creating layer InnerProduct13
I0808 13:44:08.496698 20451 net.cpp:91] Creating Layer InnerProduct13
I0808 13:44:08.496704 20451 net.cpp:425] InnerProduct13 <- Pooling15
I0808 13:44:08.496716 20451 net.cpp:399] InnerProduct13 -> InnerProduct13
I0808 13:44:08.497906 20451 net.cpp:141] Setting up InnerProduct13
I0808 13:44:08.497923 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.497931 20451 net.cpp:156] Memory required for data: 660988416
I0808 13:44:08.497941 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.497949 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.497956 20451 layer_factory.hpp:77] Creating layer ReLU9
I0808 13:44:08.497968 20451 net.cpp:91] Creating Layer ReLU9
I0808 13:44:08.497977 20451 net.cpp:425] ReLU9 <- InnerProduct13
I0808 13:44:08.497987 20451 net.cpp:386] ReLU9 -> InnerProduct13 (in-place)
I0808 13:44:08.498003 20451 net.cpp:141] Setting up ReLU9
I0808 13:44:08.498010 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.498018 20451 net.cpp:156] Memory required for data: 661014016
I0808 13:44:08.498023 20451 layer_factory.hpp:77] Creating layer InnerProduct14
I0808 13:44:08.498034 20451 net.cpp:91] Creating Layer InnerProduct14
I0808 13:44:08.498041 20451 net.cpp:425] InnerProduct14 <- InnerProduct13
I0808 13:44:08.498051 20451 net.cpp:399] InnerProduct14 -> InnerProduct14
I0808 13:44:08.498245 20451 net.cpp:141] Setting up InnerProduct14
I0808 13:44:08.498256 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.498263 20451 net.cpp:156] Memory required for data: 661026816
I0808 13:44:08.498271 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.498281 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.498288 20451 layer_factory.hpp:77] Creating layer Convolution16
I0808 13:44:08.498307 20451 net.cpp:91] Creating Layer Convolution16
I0808 13:44:08.498317 20451 net.cpp:425] Convolution16 <- c22
I0808 13:44:08.498330 20451 net.cpp:399] Convolution16 -> Convolution16
I0808 13:44:08.498742 20451 net.cpp:141] Setting up Convolution16
I0808 13:44:08.498756 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.498764 20451 net.cpp:156] Memory required for data: 679458816
I0808 13:44:08.498772 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.498781 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.498790 20451 layer_factory.hpp:77] Creating layer Pooling16
I0808 13:44:08.498803 20451 net.cpp:91] Creating Layer Pooling16
I0808 13:44:08.498811 20451 net.cpp:425] Pooling16 <- Convolution16
I0808 13:44:08.498822 20451 net.cpp:399] Pooling16 -> Pooling16
I0808 13:44:08.498924 20451 net.cpp:141] Setting up Pooling16
I0808 13:44:08.498970 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.498983 20451 net.cpp:156] Memory required for data: 684066816
I0808 13:44:08.498994 20451 layer_factory.hpp:77] Creating layer Convolution17
I0808 13:44:08.499013 20451 net.cpp:91] Creating Layer Convolution17
I0808 13:44:08.499022 20451 net.cpp:425] Convolution17 <- Pooling16
I0808 13:44:08.499033 20451 net.cpp:399] Convolution17 -> Convolution17
I0808 13:44:08.499634 20451 net.cpp:141] Setting up Convolution17
I0808 13:44:08.499649 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.499655 20451 net.cpp:156] Memory required for data: 692719616
I0808 13:44:08.499686 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.499694 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.499701 20451 layer_factory.hpp:77] Creating layer Pooling17
I0808 13:44:08.499711 20451 net.cpp:91] Creating Layer Pooling17
I0808 13:44:08.499717 20451 net.cpp:425] Pooling17 <- Convolution17
I0808 13:44:08.499730 20451 net.cpp:399] Pooling17 -> Pooling17
I0808 13:44:08.499778 20451 net.cpp:141] Setting up Pooling17
I0808 13:44:08.499786 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.499791 20451 net.cpp:156] Memory required for data: 694882816
I0808 13:44:08.499797 20451 layer_factory.hpp:77] Creating layer Convolution18
I0808 13:44:08.499814 20451 net.cpp:91] Creating Layer Convolution18
I0808 13:44:08.499819 20451 net.cpp:425] Convolution18 <- Pooling17
I0808 13:44:08.499830 20451 net.cpp:399] Convolution18 -> Convolution18
I0808 13:44:08.501294 20451 net.cpp:141] Setting up Convolution18
I0808 13:44:08.501309 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.501315 20451 net.cpp:156] Memory required for data: 695919616
I0808 13:44:08.501322 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.501330 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.501337 20451 layer_factory.hpp:77] Creating layer Pooling18
I0808 13:44:08.501346 20451 net.cpp:91] Creating Layer Pooling18
I0808 13:44:08.501353 20451 net.cpp:425] Pooling18 <- Convolution18
I0808 13:44:08.501363 20451 net.cpp:399] Pooling18 -> Pooling18
I0808 13:44:08.501418 20451 net.cpp:141] Setting up Pooling18
I0808 13:44:08.501426 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.501432 20451 net.cpp:156] Memory required for data: 696239616
I0808 13:44:08.501437 20451 layer_factory.hpp:77] Creating layer InnerProduct15
I0808 13:44:08.501447 20451 net.cpp:91] Creating Layer InnerProduct15
I0808 13:44:08.501453 20451 net.cpp:425] InnerProduct15 <- Pooling18
I0808 13:44:08.501466 20451 net.cpp:399] InnerProduct15 -> InnerProduct15
I0808 13:44:08.509694 20451 net.cpp:141] Setting up InnerProduct15
I0808 13:44:08.509711 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.509717 20451 net.cpp:156] Memory required for data: 696265216
I0808 13:44:08.509726 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.509732 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.509739 20451 layer_factory.hpp:77] Creating layer ReLU10
I0808 13:44:08.509748 20451 net.cpp:91] Creating Layer ReLU10
I0808 13:44:08.509755 20451 net.cpp:425] ReLU10 <- InnerProduct15
I0808 13:44:08.509764 20451 net.cpp:386] ReLU10 -> InnerProduct15 (in-place)
I0808 13:44:08.509776 20451 net.cpp:141] Setting up ReLU10
I0808 13:44:08.509783 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.509789 20451 net.cpp:156] Memory required for data: 696290816
I0808 13:44:08.509794 20451 layer_factory.hpp:77] Creating layer InnerProduct16
I0808 13:44:08.509806 20451 net.cpp:91] Creating Layer InnerProduct16
I0808 13:44:08.509814 20451 net.cpp:425] InnerProduct16 <- InnerProduct15
I0808 13:44:08.509824 20451 net.cpp:399] InnerProduct16 -> InnerProduct16
I0808 13:44:08.510012 20451 net.cpp:141] Setting up InnerProduct16
I0808 13:44:08.510020 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.510026 20451 net.cpp:156] Memory required for data: 696303616
I0808 13:44:08.510032 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.510040 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.510046 20451 layer_factory.hpp:77] Creating layer Concat3
I0808 13:44:08.510056 20451 net.cpp:91] Creating Layer Concat3
I0808 13:44:08.510061 20451 net.cpp:425] Concat3 <- InnerProduct14
I0808 13:44:08.510068 20451 net.cpp:425] Concat3 <- InnerProduct16
I0808 13:44:08.510077 20451 net.cpp:399] Concat3 -> Concat3
I0808 13:44:08.510108 20451 net.cpp:141] Setting up Concat3
I0808 13:44:08.510116 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.510121 20451 net.cpp:156] Memory required for data: 696329216
I0808 13:44:08.510128 20451 layer_factory.hpp:77] Creating layer InnerProduct17
I0808 13:44:08.510138 20451 net.cpp:91] Creating Layer InnerProduct17
I0808 13:44:08.510144 20451 net.cpp:425] InnerProduct17 <- Concat3
I0808 13:44:08.510154 20451 net.cpp:399] InnerProduct17 -> InnerProduct17
I0808 13:44:08.510334 20451 net.cpp:141] Setting up InnerProduct17
I0808 13:44:08.510341 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.510346 20451 net.cpp:156] Memory required for data: 696345600
I0808 13:44:08.510354 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.510360 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.510366 20451 layer_factory.hpp:77] Creating layer ReLU11
I0808 13:44:08.510373 20451 net.cpp:91] Creating Layer ReLU11
I0808 13:44:08.510380 20451 net.cpp:425] ReLU11 <- InnerProduct17
I0808 13:44:08.510390 20451 net.cpp:386] ReLU11 -> InnerProduct17 (in-place)
I0808 13:44:08.510399 20451 net.cpp:141] Setting up ReLU11
I0808 13:44:08.510407 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.510412 20451 net.cpp:156] Memory required for data: 696361984
I0808 13:44:08.510418 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.510426 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.510432 20451 net.cpp:425] drop1 <- InnerProduct17
I0808 13:44:08.510444 20451 net.cpp:399] drop1 -> Dropout5
I0808 13:44:08.510489 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.510498 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.510505 20451 net.cpp:156] Memory required for data: 696378368
I0808 13:44:08.510511 20451 layer_factory.hpp:77] Creating layer InnerProduct18
I0808 13:44:08.510519 20451 net.cpp:91] Creating Layer InnerProduct18
I0808 13:44:08.510525 20451 net.cpp:425] InnerProduct18 <- Dropout5
I0808 13:44:08.510537 20451 net.cpp:399] InnerProduct18 -> InnerProduct18
I0808 13:44:08.510684 20451 net.cpp:141] Setting up InnerProduct18
I0808 13:44:08.510691 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.510697 20451 net.cpp:156] Memory required for data: 696386560
I0808 13:44:08.510704 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.510710 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.510716 20451 layer_factory.hpp:77] Creating layer ReLU12
I0808 13:44:08.510726 20451 net.cpp:91] Creating Layer ReLU12
I0808 13:44:08.510732 20451 net.cpp:425] ReLU12 <- InnerProduct18
I0808 13:44:08.510740 20451 net.cpp:386] ReLU12 -> InnerProduct18 (in-place)
I0808 13:44:08.510749 20451 net.cpp:141] Setting up ReLU12
I0808 13:44:08.510757 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.510762 20451 net.cpp:156] Memory required for data: 696394752
I0808 13:44:08.510768 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.510778 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.510784 20451 net.cpp:425] drop2 <- InnerProduct18
I0808 13:44:08.510793 20451 net.cpp:399] drop2 -> Dropout6
I0808 13:44:08.510845 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.510854 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.510859 20451 net.cpp:156] Memory required for data: 696402944
I0808 13:44:08.510864 20451 layer_factory.hpp:77] Creating layer dt2
I0808 13:44:08.510874 20451 net.cpp:91] Creating Layer dt2
I0808 13:44:08.510879 20451 net.cpp:425] dt2 <- Dropout6
I0808 13:44:08.510892 20451 net.cpp:399] dt2 -> dt2
I0808 13:44:08.511019 20451 net.cpp:141] Setting up dt2
I0808 13:44:08.511026 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.511032 20451 net.cpp:156] Memory required for data: 696403200
I0808 13:44:08.511039 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.511045 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.511051 20451 layer_factory.hpp:77] Creating layer Convolution19
I0808 13:44:08.511066 20451 net.cpp:91] Creating Layer Convolution19
I0808 13:44:08.511072 20451 net.cpp:425] Convolution19 <- p1_p1_0_split_3
I0808 13:44:08.511083 20451 net.cpp:399] Convolution19 -> Convolution19
I0808 13:44:08.511406 20451 net.cpp:141] Setting up Convolution19
I0808 13:44:08.511416 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.511422 20451 net.cpp:156] Memory required for data: 714835200
I0808 13:44:08.511428 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.511435 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.511442 20451 layer_factory.hpp:77] Creating layer Pooling19
I0808 13:44:08.511451 20451 net.cpp:91] Creating Layer Pooling19
I0808 13:44:08.511456 20451 net.cpp:425] Pooling19 <- Convolution19
I0808 13:44:08.511466 20451 net.cpp:399] Pooling19 -> Pooling19
I0808 13:44:08.511513 20451 net.cpp:141] Setting up Pooling19
I0808 13:44:08.511521 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.511528 20451 net.cpp:156] Memory required for data: 719443200
I0808 13:44:08.511533 20451 layer_factory.hpp:77] Creating layer Convolution20
I0808 13:44:08.511548 20451 net.cpp:91] Creating Layer Convolution20
I0808 13:44:08.511554 20451 net.cpp:425] Convolution20 <- Pooling19
I0808 13:44:08.511569 20451 net.cpp:399] Convolution20 -> Convolution20
I0808 13:44:08.512079 20451 net.cpp:141] Setting up Convolution20
I0808 13:44:08.512087 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.512094 20451 net.cpp:156] Memory required for data: 728096000
I0808 13:44:08.512099 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.512106 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.512112 20451 layer_factory.hpp:77] Creating layer Pooling20
I0808 13:44:08.512156 20451 net.cpp:91] Creating Layer Pooling20
I0808 13:44:08.512162 20451 net.cpp:425] Pooling20 <- Convolution20
I0808 13:44:08.512172 20451 net.cpp:399] Pooling20 -> Pooling20
I0808 13:44:08.512220 20451 net.cpp:141] Setting up Pooling20
I0808 13:44:08.512228 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.512235 20451 net.cpp:156] Memory required for data: 730259200
I0808 13:44:08.512241 20451 layer_factory.hpp:77] Creating layer Convolution21
I0808 13:44:08.512256 20451 net.cpp:91] Creating Layer Convolution21
I0808 13:44:08.512262 20451 net.cpp:425] Convolution21 <- Pooling20
I0808 13:44:08.512274 20451 net.cpp:399] Convolution21 -> Convolution21
I0808 13:44:08.513064 20451 net.cpp:141] Setting up Convolution21
I0808 13:44:08.513075 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.513082 20451 net.cpp:156] Memory required for data: 731296000
I0808 13:44:08.513089 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.513098 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.513105 20451 layer_factory.hpp:77] Creating layer Pooling21
I0808 13:44:08.513129 20451 net.cpp:91] Creating Layer Pooling21
I0808 13:44:08.513139 20451 net.cpp:425] Pooling21 <- Convolution21
I0808 13:44:08.513150 20451 net.cpp:399] Pooling21 -> Pooling21
I0808 13:44:08.513202 20451 net.cpp:141] Setting up Pooling21
I0808 13:44:08.513211 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.513216 20451 net.cpp:156] Memory required for data: 731616000
I0808 13:44:08.513221 20451 layer_factory.hpp:77] Creating layer InnerProduct19
I0808 13:44:08.513232 20451 net.cpp:91] Creating Layer InnerProduct19
I0808 13:44:08.513239 20451 net.cpp:425] InnerProduct19 <- Pooling21
I0808 13:44:08.513250 20451 net.cpp:399] InnerProduct19 -> InnerProduct19
I0808 13:44:08.514366 20451 net.cpp:141] Setting up InnerProduct19
I0808 13:44:08.514376 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.514382 20451 net.cpp:156] Memory required for data: 731641600
I0808 13:44:08.514390 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.514400 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.514406 20451 layer_factory.hpp:77] Creating layer ReLU13
I0808 13:44:08.514417 20451 net.cpp:91] Creating Layer ReLU13
I0808 13:44:08.514426 20451 net.cpp:425] ReLU13 <- InnerProduct19
I0808 13:44:08.514436 20451 net.cpp:386] ReLU13 -> InnerProduct19 (in-place)
I0808 13:44:08.514448 20451 net.cpp:141] Setting up ReLU13
I0808 13:44:08.514459 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.514467 20451 net.cpp:156] Memory required for data: 731667200
I0808 13:44:08.514474 20451 layer_factory.hpp:77] Creating layer InnerProduct20
I0808 13:44:08.514489 20451 net.cpp:91] Creating Layer InnerProduct20
I0808 13:44:08.514497 20451 net.cpp:425] InnerProduct20 <- InnerProduct19
I0808 13:44:08.514513 20451 net.cpp:399] InnerProduct20 -> InnerProduct20
I0808 13:44:08.514684 20451 net.cpp:141] Setting up InnerProduct20
I0808 13:44:08.514693 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.514698 20451 net.cpp:156] Memory required for data: 731680000
I0808 13:44:08.514704 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.514711 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.514717 20451 layer_factory.hpp:77] Creating layer Convolution22
I0808 13:44:08.514729 20451 net.cpp:91] Creating Layer Convolution22
I0808 13:44:08.514735 20451 net.cpp:425] Convolution22 <- c23
I0808 13:44:08.514749 20451 net.cpp:399] Convolution22 -> Convolution22
I0808 13:44:08.515081 20451 net.cpp:141] Setting up Convolution22
I0808 13:44:08.515089 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.515094 20451 net.cpp:156] Memory required for data: 750112000
I0808 13:44:08.515101 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.515108 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.515115 20451 layer_factory.hpp:77] Creating layer Pooling22
I0808 13:44:08.515122 20451 net.cpp:91] Creating Layer Pooling22
I0808 13:44:08.515128 20451 net.cpp:425] Pooling22 <- Convolution22
I0808 13:44:08.515139 20451 net.cpp:399] Pooling22 -> Pooling22
I0808 13:44:08.515187 20451 net.cpp:141] Setting up Pooling22
I0808 13:44:08.515193 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.515199 20451 net.cpp:156] Memory required for data: 754720000
I0808 13:44:08.515204 20451 layer_factory.hpp:77] Creating layer Convolution23
I0808 13:44:08.515220 20451 net.cpp:91] Creating Layer Convolution23
I0808 13:44:08.515226 20451 net.cpp:425] Convolution23 <- Pooling22
I0808 13:44:08.515236 20451 net.cpp:399] Convolution23 -> Convolution23
I0808 13:44:08.515825 20451 net.cpp:141] Setting up Convolution23
I0808 13:44:08.515836 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.515841 20451 net.cpp:156] Memory required for data: 763372800
I0808 13:44:08.515849 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.515871 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.515877 20451 layer_factory.hpp:77] Creating layer Pooling23
I0808 13:44:08.515887 20451 net.cpp:91] Creating Layer Pooling23
I0808 13:44:08.515893 20451 net.cpp:425] Pooling23 <- Convolution23
I0808 13:44:08.515903 20451 net.cpp:399] Pooling23 -> Pooling23
I0808 13:44:08.515959 20451 net.cpp:141] Setting up Pooling23
I0808 13:44:08.515967 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.515974 20451 net.cpp:156] Memory required for data: 765536000
I0808 13:44:08.515980 20451 layer_factory.hpp:77] Creating layer Convolution24
I0808 13:44:08.515995 20451 net.cpp:91] Creating Layer Convolution24
I0808 13:44:08.516001 20451 net.cpp:425] Convolution24 <- Pooling23
I0808 13:44:08.516016 20451 net.cpp:399] Convolution24 -> Convolution24
I0808 13:44:08.516914 20451 net.cpp:141] Setting up Convolution24
I0808 13:44:08.516924 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.516930 20451 net.cpp:156] Memory required for data: 766572800
I0808 13:44:08.516937 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.516944 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.516952 20451 layer_factory.hpp:77] Creating layer Pooling24
I0808 13:44:08.516960 20451 net.cpp:91] Creating Layer Pooling24
I0808 13:44:08.516969 20451 net.cpp:425] Pooling24 <- Convolution24
I0808 13:44:08.516979 20451 net.cpp:399] Pooling24 -> Pooling24
I0808 13:44:08.517035 20451 net.cpp:141] Setting up Pooling24
I0808 13:44:08.517043 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.517050 20451 net.cpp:156] Memory required for data: 766892800
I0808 13:44:08.517055 20451 layer_factory.hpp:77] Creating layer InnerProduct21
I0808 13:44:08.517066 20451 net.cpp:91] Creating Layer InnerProduct21
I0808 13:44:08.517072 20451 net.cpp:425] InnerProduct21 <- Pooling24
I0808 13:44:08.517086 20451 net.cpp:399] InnerProduct21 -> InnerProduct21
I0808 13:44:08.519049 20451 net.cpp:141] Setting up InnerProduct21
I0808 13:44:08.519065 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.519073 20451 net.cpp:156] Memory required for data: 766918400
I0808 13:44:08.519080 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.519088 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.519095 20451 layer_factory.hpp:77] Creating layer ReLU14
I0808 13:44:08.519105 20451 net.cpp:91] Creating Layer ReLU14
I0808 13:44:08.519112 20451 net.cpp:425] ReLU14 <- InnerProduct21
I0808 13:44:08.519122 20451 net.cpp:386] ReLU14 -> InnerProduct21 (in-place)
I0808 13:44:08.519134 20451 net.cpp:141] Setting up ReLU14
I0808 13:44:08.519142 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.519148 20451 net.cpp:156] Memory required for data: 766944000
I0808 13:44:08.519155 20451 layer_factory.hpp:77] Creating layer InnerProduct22
I0808 13:44:08.519165 20451 net.cpp:91] Creating Layer InnerProduct22
I0808 13:44:08.519172 20451 net.cpp:425] InnerProduct22 <- InnerProduct21
I0808 13:44:08.519197 20451 net.cpp:399] InnerProduct22 -> InnerProduct22
I0808 13:44:08.519402 20451 net.cpp:141] Setting up InnerProduct22
I0808 13:44:08.519412 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.519418 20451 net.cpp:156] Memory required for data: 766956800
I0808 13:44:08.519424 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.519431 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.519438 20451 layer_factory.hpp:77] Creating layer Concat4
I0808 13:44:08.519448 20451 net.cpp:91] Creating Layer Concat4
I0808 13:44:08.519455 20451 net.cpp:425] Concat4 <- InnerProduct20
I0808 13:44:08.519464 20451 net.cpp:425] Concat4 <- InnerProduct22
I0808 13:44:08.519490 20451 net.cpp:399] Concat4 -> Concat4
I0808 13:44:08.519521 20451 net.cpp:141] Setting up Concat4
I0808 13:44:08.519531 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.519536 20451 net.cpp:156] Memory required for data: 766982400
I0808 13:44:08.519542 20451 layer_factory.hpp:77] Creating layer InnerProduct23
I0808 13:44:08.519558 20451 net.cpp:91] Creating Layer InnerProduct23
I0808 13:44:08.519567 20451 net.cpp:425] InnerProduct23 <- Concat4
I0808 13:44:08.519587 20451 net.cpp:399] InnerProduct23 -> InnerProduct23
I0808 13:44:08.519798 20451 net.cpp:141] Setting up InnerProduct23
I0808 13:44:08.519807 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.519814 20451 net.cpp:156] Memory required for data: 766998784
I0808 13:44:08.519820 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.519829 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.519837 20451 layer_factory.hpp:77] Creating layer ReLU15
I0808 13:44:08.519845 20451 net.cpp:91] Creating Layer ReLU15
I0808 13:44:08.519852 20451 net.cpp:425] ReLU15 <- InnerProduct23
I0808 13:44:08.519861 20451 net.cpp:386] ReLU15 -> InnerProduct23 (in-place)
I0808 13:44:08.519872 20451 net.cpp:141] Setting up ReLU15
I0808 13:44:08.519881 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.519887 20451 net.cpp:156] Memory required for data: 767015168
I0808 13:44:08.519893 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.519906 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.519912 20451 net.cpp:425] drop1 <- InnerProduct23
I0808 13:44:08.519922 20451 net.cpp:399] drop1 -> Dropout7
I0808 13:44:08.519976 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.519984 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.519990 20451 net.cpp:156] Memory required for data: 767031552
I0808 13:44:08.519996 20451 layer_factory.hpp:77] Creating layer InnerProduct24
I0808 13:44:08.520009 20451 net.cpp:91] Creating Layer InnerProduct24
I0808 13:44:08.520015 20451 net.cpp:425] InnerProduct24 <- Dropout7
I0808 13:44:08.520026 20451 net.cpp:399] InnerProduct24 -> InnerProduct24
I0808 13:44:08.520192 20451 net.cpp:141] Setting up InnerProduct24
I0808 13:44:08.520201 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.520207 20451 net.cpp:156] Memory required for data: 767039744
I0808 13:44:08.520215 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.520222 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.520229 20451 layer_factory.hpp:77] Creating layer ReLU16
I0808 13:44:08.520237 20451 net.cpp:91] Creating Layer ReLU16
I0808 13:44:08.520244 20451 net.cpp:425] ReLU16 <- InnerProduct24
I0808 13:44:08.520256 20451 net.cpp:386] ReLU16 -> InnerProduct24 (in-place)
I0808 13:44:08.520267 20451 net.cpp:141] Setting up ReLU16
I0808 13:44:08.520274 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.520280 20451 net.cpp:156] Memory required for data: 767047936
I0808 13:44:08.520287 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.520297 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.520303 20451 net.cpp:425] drop2 <- InnerProduct24
I0808 13:44:08.520318 20451 net.cpp:399] drop2 -> Dropout8
I0808 13:44:08.520368 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.520376 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.520382 20451 net.cpp:156] Memory required for data: 767056128
I0808 13:44:08.520390 20451 layer_factory.hpp:77] Creating layer dt3
I0808 13:44:08.520398 20451 net.cpp:91] Creating Layer dt3
I0808 13:44:08.520406 20451 net.cpp:425] dt3 <- Dropout8
I0808 13:44:08.520416 20451 net.cpp:399] dt3 -> dt3
I0808 13:44:08.520561 20451 net.cpp:141] Setting up dt3
I0808 13:44:08.520570 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.520576 20451 net.cpp:156] Memory required for data: 767056384
I0808 13:44:08.520583 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.520602 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.520609 20451 layer_factory.hpp:77] Creating layer Convolution25
I0808 13:44:08.520627 20451 net.cpp:91] Creating Layer Convolution25
I0808 13:44:08.520634 20451 net.cpp:425] Convolution25 <- p1_p1_0_split_4
I0808 13:44:08.520647 20451 net.cpp:399] Convolution25 -> Convolution25
I0808 13:44:08.521008 20451 net.cpp:141] Setting up Convolution25
I0808 13:44:08.521018 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.521023 20451 net.cpp:156] Memory required for data: 785488384
I0808 13:44:08.521030 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.521039 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.521044 20451 layer_factory.hpp:77] Creating layer Pooling25
I0808 13:44:08.521057 20451 net.cpp:91] Creating Layer Pooling25
I0808 13:44:08.521064 20451 net.cpp:425] Pooling25 <- Convolution25
I0808 13:44:08.521075 20451 net.cpp:399] Pooling25 -> Pooling25
I0808 13:44:08.521129 20451 net.cpp:141] Setting up Pooling25
I0808 13:44:08.521138 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.521144 20451 net.cpp:156] Memory required for data: 790096384
I0808 13:44:08.521150 20451 layer_factory.hpp:77] Creating layer Convolution26
I0808 13:44:08.521165 20451 net.cpp:91] Creating Layer Convolution26
I0808 13:44:08.521173 20451 net.cpp:425] Convolution26 <- Pooling25
I0808 13:44:08.521184 20451 net.cpp:399] Convolution26 -> Convolution26
I0808 13:44:08.521762 20451 net.cpp:141] Setting up Convolution26
I0808 13:44:08.521771 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.521777 20451 net.cpp:156] Memory required for data: 798749184
I0808 13:44:08.521785 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.521792 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.521800 20451 layer_factory.hpp:77] Creating layer Pooling26
I0808 13:44:08.521811 20451 net.cpp:91] Creating Layer Pooling26
I0808 13:44:08.521818 20451 net.cpp:425] Pooling26 <- Convolution26
I0808 13:44:08.521828 20451 net.cpp:399] Pooling26 -> Pooling26
I0808 13:44:08.521881 20451 net.cpp:141] Setting up Pooling26
I0808 13:44:08.521890 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.521896 20451 net.cpp:156] Memory required for data: 800912384
I0808 13:44:08.521903 20451 layer_factory.hpp:77] Creating layer Convolution27
I0808 13:44:08.521917 20451 net.cpp:91] Creating Layer Convolution27
I0808 13:44:08.521924 20451 net.cpp:425] Convolution27 <- Pooling26
I0808 13:44:08.521939 20451 net.cpp:399] Convolution27 -> Convolution27
I0808 13:44:08.523602 20451 net.cpp:141] Setting up Convolution27
I0808 13:44:08.523619 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.523627 20451 net.cpp:156] Memory required for data: 801949184
I0808 13:44:08.523636 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.523646 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.523654 20451 layer_factory.hpp:77] Creating layer Pooling27
I0808 13:44:08.523668 20451 net.cpp:91] Creating Layer Pooling27
I0808 13:44:08.523676 20451 net.cpp:425] Pooling27 <- Convolution27
I0808 13:44:08.523692 20451 net.cpp:399] Pooling27 -> Pooling27
I0808 13:44:08.523757 20451 net.cpp:141] Setting up Pooling27
I0808 13:44:08.523768 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.523775 20451 net.cpp:156] Memory required for data: 802269184
I0808 13:44:08.523782 20451 layer_factory.hpp:77] Creating layer InnerProduct25
I0808 13:44:08.523797 20451 net.cpp:91] Creating Layer InnerProduct25
I0808 13:44:08.523805 20451 net.cpp:425] InnerProduct25 <- Pooling27
I0808 13:44:08.523818 20451 net.cpp:399] InnerProduct25 -> InnerProduct25
I0808 13:44:08.525169 20451 net.cpp:141] Setting up InnerProduct25
I0808 13:44:08.525185 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.525192 20451 net.cpp:156] Memory required for data: 802294784
I0808 13:44:08.525202 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.525215 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.525224 20451 layer_factory.hpp:77] Creating layer ReLU17
I0808 13:44:08.525243 20451 net.cpp:91] Creating Layer ReLU17
I0808 13:44:08.525250 20451 net.cpp:425] ReLU17 <- InnerProduct25
I0808 13:44:08.525261 20451 net.cpp:386] ReLU17 -> InnerProduct25 (in-place)
I0808 13:44:08.525275 20451 net.cpp:141] Setting up ReLU17
I0808 13:44:08.525285 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.525291 20451 net.cpp:156] Memory required for data: 802320384
I0808 13:44:08.525298 20451 layer_factory.hpp:77] Creating layer InnerProduct26
I0808 13:44:08.525315 20451 net.cpp:91] Creating Layer InnerProduct26
I0808 13:44:08.525324 20451 net.cpp:425] InnerProduct26 <- InnerProduct25
I0808 13:44:08.525337 20451 net.cpp:399] InnerProduct26 -> InnerProduct26
I0808 13:44:08.525568 20451 net.cpp:141] Setting up InnerProduct26
I0808 13:44:08.525581 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.525590 20451 net.cpp:156] Memory required for data: 802333184
I0808 13:44:08.525599 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.525610 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.525619 20451 layer_factory.hpp:77] Creating layer Convolution28
I0808 13:44:08.525640 20451 net.cpp:91] Creating Layer Convolution28
I0808 13:44:08.525650 20451 net.cpp:425] Convolution28 <- c24
I0808 13:44:08.525668 20451 net.cpp:399] Convolution28 -> Convolution28
I0808 13:44:08.526108 20451 net.cpp:141] Setting up Convolution28
I0808 13:44:08.526118 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.526126 20451 net.cpp:156] Memory required for data: 820765184
I0808 13:44:08.526134 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.526144 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.526154 20451 layer_factory.hpp:77] Creating layer Pooling28
I0808 13:44:08.526165 20451 net.cpp:91] Creating Layer Pooling28
I0808 13:44:08.526175 20451 net.cpp:425] Pooling28 <- Convolution28
I0808 13:44:08.526191 20451 net.cpp:399] Pooling28 -> Pooling28
I0808 13:44:08.526263 20451 net.cpp:141] Setting up Pooling28
I0808 13:44:08.526276 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.526284 20451 net.cpp:156] Memory required for data: 825373184
I0808 13:44:08.526293 20451 layer_factory.hpp:77] Creating layer Convolution29
I0808 13:44:08.526310 20451 net.cpp:91] Creating Layer Convolution29
I0808 13:44:08.526319 20451 net.cpp:425] Convolution29 <- Pooling28
I0808 13:44:08.526336 20451 net.cpp:399] Convolution29 -> Convolution29
I0808 13:44:08.527020 20451 net.cpp:141] Setting up Convolution29
I0808 13:44:08.527034 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.527042 20451 net.cpp:156] Memory required for data: 834025984
I0808 13:44:08.527052 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.527062 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.527072 20451 layer_factory.hpp:77] Creating layer Pooling29
I0808 13:44:08.527086 20451 net.cpp:91] Creating Layer Pooling29
I0808 13:44:08.527096 20451 net.cpp:425] Pooling29 <- Convolution29
I0808 13:44:08.527109 20451 net.cpp:399] Pooling29 -> Pooling29
I0808 13:44:08.527182 20451 net.cpp:141] Setting up Pooling29
I0808 13:44:08.527194 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.527204 20451 net.cpp:156] Memory required for data: 836189184
I0808 13:44:08.527235 20451 layer_factory.hpp:77] Creating layer Convolution30
I0808 13:44:08.527254 20451 net.cpp:91] Creating Layer Convolution30
I0808 13:44:08.527263 20451 net.cpp:425] Convolution30 <- Pooling29
I0808 13:44:08.527307 20451 net.cpp:399] Convolution30 -> Convolution30
I0808 13:44:08.528180 20451 net.cpp:141] Setting up Convolution30
I0808 13:44:08.528192 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.528198 20451 net.cpp:156] Memory required for data: 837225984
I0808 13:44:08.528204 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.528213 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.528218 20451 layer_factory.hpp:77] Creating layer Pooling30
I0808 13:44:08.528228 20451 net.cpp:91] Creating Layer Pooling30
I0808 13:44:08.528234 20451 net.cpp:425] Pooling30 <- Convolution30
I0808 13:44:08.528246 20451 net.cpp:399] Pooling30 -> Pooling30
I0808 13:44:08.528295 20451 net.cpp:141] Setting up Pooling30
I0808 13:44:08.528303 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.528309 20451 net.cpp:156] Memory required for data: 837545984
I0808 13:44:08.528314 20451 layer_factory.hpp:77] Creating layer InnerProduct27
I0808 13:44:08.528326 20451 net.cpp:91] Creating Layer InnerProduct27
I0808 13:44:08.528333 20451 net.cpp:425] InnerProduct27 <- Pooling30
I0808 13:44:08.528347 20451 net.cpp:399] InnerProduct27 -> InnerProduct27
I0808 13:44:08.530311 20451 net.cpp:141] Setting up InnerProduct27
I0808 13:44:08.530338 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.530344 20451 net.cpp:156] Memory required for data: 837571584
I0808 13:44:08.530354 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.530362 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.530369 20451 layer_factory.hpp:77] Creating layer ReLU18
I0808 13:44:08.530381 20451 net.cpp:91] Creating Layer ReLU18
I0808 13:44:08.530393 20451 net.cpp:425] ReLU18 <- InnerProduct27
I0808 13:44:08.530408 20451 net.cpp:386] ReLU18 -> InnerProduct27 (in-place)
I0808 13:44:08.530423 20451 net.cpp:141] Setting up ReLU18
I0808 13:44:08.530436 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.530443 20451 net.cpp:156] Memory required for data: 837597184
I0808 13:44:08.530450 20451 layer_factory.hpp:77] Creating layer InnerProduct28
I0808 13:44:08.530465 20451 net.cpp:91] Creating Layer InnerProduct28
I0808 13:44:08.530473 20451 net.cpp:425] InnerProduct28 <- InnerProduct27
I0808 13:44:08.530488 20451 net.cpp:399] InnerProduct28 -> InnerProduct28
I0808 13:44:08.530714 20451 net.cpp:141] Setting up InnerProduct28
I0808 13:44:08.530727 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.530735 20451 net.cpp:156] Memory required for data: 837609984
I0808 13:44:08.530745 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.530753 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.530761 20451 layer_factory.hpp:77] Creating layer Concat5
I0808 13:44:08.530771 20451 net.cpp:91] Creating Layer Concat5
I0808 13:44:08.530778 20451 net.cpp:425] Concat5 <- InnerProduct26
I0808 13:44:08.530786 20451 net.cpp:425] Concat5 <- InnerProduct28
I0808 13:44:08.530799 20451 net.cpp:399] Concat5 -> Concat5
I0808 13:44:08.530832 20451 net.cpp:141] Setting up Concat5
I0808 13:44:08.530843 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.530849 20451 net.cpp:156] Memory required for data: 837635584
I0808 13:44:08.530854 20451 layer_factory.hpp:77] Creating layer InnerProduct29
I0808 13:44:08.530864 20451 net.cpp:91] Creating Layer InnerProduct29
I0808 13:44:08.530870 20451 net.cpp:425] InnerProduct29 <- Concat5
I0808 13:44:08.530882 20451 net.cpp:399] InnerProduct29 -> InnerProduct29
I0808 13:44:08.531071 20451 net.cpp:141] Setting up InnerProduct29
I0808 13:44:08.531080 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.531101 20451 net.cpp:156] Memory required for data: 837651968
I0808 13:44:08.531108 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.531116 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.531122 20451 layer_factory.hpp:77] Creating layer ReLU19
I0808 13:44:08.531132 20451 net.cpp:91] Creating Layer ReLU19
I0808 13:44:08.531138 20451 net.cpp:425] ReLU19 <- InnerProduct29
I0808 13:44:08.531147 20451 net.cpp:386] ReLU19 -> InnerProduct29 (in-place)
I0808 13:44:08.531157 20451 net.cpp:141] Setting up ReLU19
I0808 13:44:08.531164 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.531170 20451 net.cpp:156] Memory required for data: 837668352
I0808 13:44:08.531175 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.531188 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.531193 20451 net.cpp:425] drop1 <- InnerProduct29
I0808 13:44:08.531203 20451 net.cpp:399] drop1 -> Dropout9
I0808 13:44:08.531252 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.531260 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.531265 20451 net.cpp:156] Memory required for data: 837684736
I0808 13:44:08.531277 20451 layer_factory.hpp:77] Creating layer InnerProduct30
I0808 13:44:08.531287 20451 net.cpp:91] Creating Layer InnerProduct30
I0808 13:44:08.531292 20451 net.cpp:425] InnerProduct30 <- Dropout9
I0808 13:44:08.531304 20451 net.cpp:399] InnerProduct30 -> InnerProduct30
I0808 13:44:08.531456 20451 net.cpp:141] Setting up InnerProduct30
I0808 13:44:08.531464 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.531469 20451 net.cpp:156] Memory required for data: 837692928
I0808 13:44:08.531476 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.531483 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.531489 20451 layer_factory.hpp:77] Creating layer ReLU20
I0808 13:44:08.531497 20451 net.cpp:91] Creating Layer ReLU20
I0808 13:44:08.531502 20451 net.cpp:425] ReLU20 <- InnerProduct30
I0808 13:44:08.531513 20451 net.cpp:386] ReLU20 -> InnerProduct30 (in-place)
I0808 13:44:08.531523 20451 net.cpp:141] Setting up ReLU20
I0808 13:44:08.531530 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.531536 20451 net.cpp:156] Memory required for data: 837701120
I0808 13:44:08.531541 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.531550 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.531558 20451 net.cpp:425] drop2 <- InnerProduct30
I0808 13:44:08.531566 20451 net.cpp:399] drop2 -> Dropout10
I0808 13:44:08.531612 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.531620 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.531625 20451 net.cpp:156] Memory required for data: 837709312
I0808 13:44:08.531631 20451 layer_factory.hpp:77] Creating layer dt4
I0808 13:44:08.531642 20451 net.cpp:91] Creating Layer dt4
I0808 13:44:08.531648 20451 net.cpp:425] dt4 <- Dropout10
I0808 13:44:08.531658 20451 net.cpp:399] dt4 -> dt4
I0808 13:44:08.531786 20451 net.cpp:141] Setting up dt4
I0808 13:44:08.531795 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.531800 20451 net.cpp:156] Memory required for data: 837709568
I0808 13:44:08.531847 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.531857 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.531862 20451 layer_factory.hpp:77] Creating layer Convolution31
I0808 13:44:08.531877 20451 net.cpp:91] Creating Layer Convolution31
I0808 13:44:08.531884 20451 net.cpp:425] Convolution31 <- p1_p1_0_split_5
I0808 13:44:08.531895 20451 net.cpp:399] Convolution31 -> Convolution31
I0808 13:44:08.532230 20451 net.cpp:141] Setting up Convolution31
I0808 13:44:08.532239 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.532245 20451 net.cpp:156] Memory required for data: 856141568
I0808 13:44:08.532251 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.532269 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.532275 20451 layer_factory.hpp:77] Creating layer Pooling31
I0808 13:44:08.532286 20451 net.cpp:91] Creating Layer Pooling31
I0808 13:44:08.532292 20451 net.cpp:425] Pooling31 <- Convolution31
I0808 13:44:08.532302 20451 net.cpp:399] Pooling31 -> Pooling31
I0808 13:44:08.532353 20451 net.cpp:141] Setting up Pooling31
I0808 13:44:08.532361 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.532367 20451 net.cpp:156] Memory required for data: 860749568
I0808 13:44:08.532372 20451 layer_factory.hpp:77] Creating layer Convolution32
I0808 13:44:08.532385 20451 net.cpp:91] Creating Layer Convolution32
I0808 13:44:08.532392 20451 net.cpp:425] Convolution32 <- Pooling31
I0808 13:44:08.532404 20451 net.cpp:399] Convolution32 -> Convolution32
I0808 13:44:08.532930 20451 net.cpp:141] Setting up Convolution32
I0808 13:44:08.532938 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.532944 20451 net.cpp:156] Memory required for data: 869402368
I0808 13:44:08.532950 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.532958 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.532963 20451 layer_factory.hpp:77] Creating layer Pooling32
I0808 13:44:08.532971 20451 net.cpp:91] Creating Layer Pooling32
I0808 13:44:08.532977 20451 net.cpp:425] Pooling32 <- Convolution32
I0808 13:44:08.532989 20451 net.cpp:399] Pooling32 -> Pooling32
I0808 13:44:08.533035 20451 net.cpp:141] Setting up Pooling32
I0808 13:44:08.533043 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.533048 20451 net.cpp:156] Memory required for data: 871565568
I0808 13:44:08.533054 20451 layer_factory.hpp:77] Creating layer Convolution33
I0808 13:44:08.533069 20451 net.cpp:91] Creating Layer Convolution33
I0808 13:44:08.533076 20451 net.cpp:425] Convolution33 <- Pooling32
I0808 13:44:08.533085 20451 net.cpp:399] Convolution33 -> Convolution33
I0808 13:44:08.533910 20451 net.cpp:141] Setting up Convolution33
I0808 13:44:08.533920 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.533926 20451 net.cpp:156] Memory required for data: 872602368
I0808 13:44:08.533931 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.533938 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.533946 20451 layer_factory.hpp:77] Creating layer Pooling33
I0808 13:44:08.533953 20451 net.cpp:91] Creating Layer Pooling33
I0808 13:44:08.533959 20451 net.cpp:425] Pooling33 <- Convolution33
I0808 13:44:08.533968 20451 net.cpp:399] Pooling33 -> Pooling33
I0808 13:44:08.534019 20451 net.cpp:141] Setting up Pooling33
I0808 13:44:08.534027 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.534034 20451 net.cpp:156] Memory required for data: 872922368
I0808 13:44:08.534039 20451 layer_factory.hpp:77] Creating layer InnerProduct31
I0808 13:44:08.534047 20451 net.cpp:91] Creating Layer InnerProduct31
I0808 13:44:08.534054 20451 net.cpp:425] InnerProduct31 <- Pooling33
I0808 13:44:08.534065 20451 net.cpp:399] InnerProduct31 -> InnerProduct31
I0808 13:44:08.535193 20451 net.cpp:141] Setting up InnerProduct31
I0808 13:44:08.535202 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.535207 20451 net.cpp:156] Memory required for data: 872947968
I0808 13:44:08.535213 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.535220 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.535226 20451 layer_factory.hpp:77] Creating layer ReLU21
I0808 13:44:08.535234 20451 net.cpp:91] Creating Layer ReLU21
I0808 13:44:08.535243 20451 net.cpp:425] ReLU21 <- InnerProduct31
I0808 13:44:08.535250 20451 net.cpp:386] ReLU21 -> InnerProduct31 (in-place)
I0808 13:44:08.535270 20451 net.cpp:141] Setting up ReLU21
I0808 13:44:08.535284 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.535289 20451 net.cpp:156] Memory required for data: 872973568
I0808 13:44:08.535295 20451 layer_factory.hpp:77] Creating layer InnerProduct32
I0808 13:44:08.535303 20451 net.cpp:91] Creating Layer InnerProduct32
I0808 13:44:08.535310 20451 net.cpp:425] InnerProduct32 <- InnerProduct31
I0808 13:44:08.535321 20451 net.cpp:399] InnerProduct32 -> InnerProduct32
I0808 13:44:08.535490 20451 net.cpp:141] Setting up InnerProduct32
I0808 13:44:08.535497 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.535503 20451 net.cpp:156] Memory required for data: 872986368
I0808 13:44:08.535509 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.535516 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.535522 20451 layer_factory.hpp:77] Creating layer Convolution34
I0808 13:44:08.535537 20451 net.cpp:91] Creating Layer Convolution34
I0808 13:44:08.535542 20451 net.cpp:425] Convolution34 <- c25
I0808 13:44:08.535553 20451 net.cpp:399] Convolution34 -> Convolution34
I0808 13:44:08.535887 20451 net.cpp:141] Setting up Convolution34
I0808 13:44:08.535897 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.535903 20451 net.cpp:156] Memory required for data: 891418368
I0808 13:44:08.535909 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.535917 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.535923 20451 layer_factory.hpp:77] Creating layer Pooling34
I0808 13:44:08.535930 20451 net.cpp:91] Creating Layer Pooling34
I0808 13:44:08.535936 20451 net.cpp:425] Pooling34 <- Convolution34
I0808 13:44:08.535945 20451 net.cpp:399] Pooling34 -> Pooling34
I0808 13:44:08.535996 20451 net.cpp:141] Setting up Pooling34
I0808 13:44:08.536005 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.536010 20451 net.cpp:156] Memory required for data: 896026368
I0808 13:44:08.536015 20451 layer_factory.hpp:77] Creating layer Convolution35
I0808 13:44:08.536028 20451 net.cpp:91] Creating Layer Convolution35
I0808 13:44:08.536034 20451 net.cpp:425] Convolution35 <- Pooling34
I0808 13:44:08.536046 20451 net.cpp:399] Convolution35 -> Convolution35
I0808 13:44:08.537228 20451 net.cpp:141] Setting up Convolution35
I0808 13:44:08.537241 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.537247 20451 net.cpp:156] Memory required for data: 904679168
I0808 13:44:08.537255 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.537261 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.537267 20451 layer_factory.hpp:77] Creating layer Pooling35
I0808 13:44:08.537276 20451 net.cpp:91] Creating Layer Pooling35
I0808 13:44:08.537283 20451 net.cpp:425] Pooling35 <- Convolution35
I0808 13:44:08.537293 20451 net.cpp:399] Pooling35 -> Pooling35
I0808 13:44:08.537344 20451 net.cpp:141] Setting up Pooling35
I0808 13:44:08.537353 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.537358 20451 net.cpp:156] Memory required for data: 906842368
I0808 13:44:08.537364 20451 layer_factory.hpp:77] Creating layer Convolution36
I0808 13:44:08.537377 20451 net.cpp:91] Creating Layer Convolution36
I0808 13:44:08.537384 20451 net.cpp:425] Convolution36 <- Pooling35
I0808 13:44:08.537396 20451 net.cpp:399] Convolution36 -> Convolution36
I0808 13:44:08.538183 20451 net.cpp:141] Setting up Convolution36
I0808 13:44:08.538192 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.538197 20451 net.cpp:156] Memory required for data: 907879168
I0808 13:44:08.538203 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.538210 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.538231 20451 layer_factory.hpp:77] Creating layer Pooling36
I0808 13:44:08.538244 20451 net.cpp:91] Creating Layer Pooling36
I0808 13:44:08.538249 20451 net.cpp:425] Pooling36 <- Convolution36
I0808 13:44:08.538259 20451 net.cpp:399] Pooling36 -> Pooling36
I0808 13:44:08.538311 20451 net.cpp:141] Setting up Pooling36
I0808 13:44:08.538318 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.538324 20451 net.cpp:156] Memory required for data: 908199168
I0808 13:44:08.538329 20451 layer_factory.hpp:77] Creating layer InnerProduct33
I0808 13:44:08.538339 20451 net.cpp:91] Creating Layer InnerProduct33
I0808 13:44:08.538346 20451 net.cpp:425] InnerProduct33 <- Pooling36
I0808 13:44:08.538359 20451 net.cpp:399] InnerProduct33 -> InnerProduct33
I0808 13:44:08.555948 20451 net.cpp:141] Setting up InnerProduct33
I0808 13:44:08.555979 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.555987 20451 net.cpp:156] Memory required for data: 908224768
I0808 13:44:08.555999 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.556010 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.556016 20451 layer_factory.hpp:77] Creating layer ReLU22
I0808 13:44:08.556031 20451 net.cpp:91] Creating Layer ReLU22
I0808 13:44:08.556041 20451 net.cpp:425] ReLU22 <- InnerProduct33
I0808 13:44:08.556053 20451 net.cpp:386] ReLU22 -> InnerProduct33 (in-place)
I0808 13:44:08.556067 20451 net.cpp:141] Setting up ReLU22
I0808 13:44:08.556077 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.556084 20451 net.cpp:156] Memory required for data: 908250368
I0808 13:44:08.556092 20451 layer_factory.hpp:77] Creating layer InnerProduct34
I0808 13:44:08.556110 20451 net.cpp:91] Creating Layer InnerProduct34
I0808 13:44:08.556118 20451 net.cpp:425] InnerProduct34 <- InnerProduct33
I0808 13:44:08.556133 20451 net.cpp:399] InnerProduct34 -> InnerProduct34
I0808 13:44:08.556359 20451 net.cpp:141] Setting up InnerProduct34
I0808 13:44:08.556370 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.556375 20451 net.cpp:156] Memory required for data: 908263168
I0808 13:44:08.556383 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.556393 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.556401 20451 layer_factory.hpp:77] Creating layer Concat6
I0808 13:44:08.556412 20451 net.cpp:91] Creating Layer Concat6
I0808 13:44:08.556421 20451 net.cpp:425] Concat6 <- InnerProduct32
I0808 13:44:08.556430 20451 net.cpp:425] Concat6 <- InnerProduct34
I0808 13:44:08.556442 20451 net.cpp:399] Concat6 -> Concat6
I0808 13:44:08.556479 20451 net.cpp:141] Setting up Concat6
I0808 13:44:08.556489 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.556496 20451 net.cpp:156] Memory required for data: 908288768
I0808 13:44:08.556502 20451 layer_factory.hpp:77] Creating layer InnerProduct35
I0808 13:44:08.556514 20451 net.cpp:91] Creating Layer InnerProduct35
I0808 13:44:08.556520 20451 net.cpp:425] InnerProduct35 <- Concat6
I0808 13:44:08.556535 20451 net.cpp:399] InnerProduct35 -> InnerProduct35
I0808 13:44:08.556757 20451 net.cpp:141] Setting up InnerProduct35
I0808 13:44:08.556768 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.556777 20451 net.cpp:156] Memory required for data: 908305152
I0808 13:44:08.556784 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.556794 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.556802 20451 layer_factory.hpp:77] Creating layer ReLU23
I0808 13:44:08.556815 20451 net.cpp:91] Creating Layer ReLU23
I0808 13:44:08.556823 20451 net.cpp:425] ReLU23 <- InnerProduct35
I0808 13:44:08.556838 20451 net.cpp:386] ReLU23 -> InnerProduct35 (in-place)
I0808 13:44:08.556850 20451 net.cpp:141] Setting up ReLU23
I0808 13:44:08.556860 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.556890 20451 net.cpp:156] Memory required for data: 908321536
I0808 13:44:08.556896 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.556906 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.556913 20451 net.cpp:425] drop1 <- InnerProduct35
I0808 13:44:08.556923 20451 net.cpp:399] drop1 -> Dropout11
I0808 13:44:08.556984 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.556995 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.557004 20451 net.cpp:156] Memory required for data: 908337920
I0808 13:44:08.557010 20451 layer_factory.hpp:77] Creating layer InnerProduct36
I0808 13:44:08.557025 20451 net.cpp:91] Creating Layer InnerProduct36
I0808 13:44:08.557032 20451 net.cpp:425] InnerProduct36 <- Dropout11
I0808 13:44:08.557044 20451 net.cpp:399] InnerProduct36 -> InnerProduct36
I0808 13:44:08.557260 20451 net.cpp:141] Setting up InnerProduct36
I0808 13:44:08.557271 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.557279 20451 net.cpp:156] Memory required for data: 908346112
I0808 13:44:08.557288 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.557299 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.557308 20451 layer_factory.hpp:77] Creating layer ReLU24
I0808 13:44:08.557319 20451 net.cpp:91] Creating Layer ReLU24
I0808 13:44:08.557327 20451 net.cpp:425] ReLU24 <- InnerProduct36
I0808 13:44:08.557343 20451 net.cpp:386] ReLU24 -> InnerProduct36 (in-place)
I0808 13:44:08.557355 20451 net.cpp:141] Setting up ReLU24
I0808 13:44:08.557366 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.557374 20451 net.cpp:156] Memory required for data: 908354304
I0808 13:44:08.557382 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.557392 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.557401 20451 net.cpp:425] drop2 <- InnerProduct36
I0808 13:44:08.557416 20451 net.cpp:399] drop2 -> Dropout12
I0808 13:44:08.557482 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.557492 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.557499 20451 net.cpp:156] Memory required for data: 908362496
I0808 13:44:08.557507 20451 layer_factory.hpp:77] Creating layer dt5
I0808 13:44:08.557518 20451 net.cpp:91] Creating Layer dt5
I0808 13:44:08.557528 20451 net.cpp:425] dt5 <- Dropout12
I0808 13:44:08.557546 20451 net.cpp:399] dt5 -> dt5
I0808 13:44:08.557729 20451 net.cpp:141] Setting up dt5
I0808 13:44:08.557741 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.557749 20451 net.cpp:156] Memory required for data: 908362752
I0808 13:44:08.557757 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.557766 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.557775 20451 layer_factory.hpp:77] Creating layer Convolution37
I0808 13:44:08.557798 20451 net.cpp:91] Creating Layer Convolution37
I0808 13:44:08.557808 20451 net.cpp:425] Convolution37 <- p1_p1_0_split_6
I0808 13:44:08.557824 20451 net.cpp:399] Convolution37 -> Convolution37
I0808 13:44:08.558249 20451 net.cpp:141] Setting up Convolution37
I0808 13:44:08.558260 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.558266 20451 net.cpp:156] Memory required for data: 926794752
I0808 13:44:08.558274 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.558281 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.558287 20451 layer_factory.hpp:77] Creating layer Pooling37
I0808 13:44:08.558300 20451 net.cpp:91] Creating Layer Pooling37
I0808 13:44:08.558306 20451 net.cpp:425] Pooling37 <- Convolution37
I0808 13:44:08.558316 20451 net.cpp:399] Pooling37 -> Pooling37
I0808 13:44:08.558372 20451 net.cpp:141] Setting up Pooling37
I0808 13:44:08.558380 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.558385 20451 net.cpp:156] Memory required for data: 931402752
I0808 13:44:08.558403 20451 layer_factory.hpp:77] Creating layer Convolution38
I0808 13:44:08.558418 20451 net.cpp:91] Creating Layer Convolution38
I0808 13:44:08.558423 20451 net.cpp:425] Convolution38 <- Pooling37
I0808 13:44:08.558434 20451 net.cpp:399] Convolution38 -> Convolution38
I0808 13:44:08.558969 20451 net.cpp:141] Setting up Convolution38
I0808 13:44:08.558977 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.558982 20451 net.cpp:156] Memory required for data: 940055552
I0808 13:44:08.558990 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.558996 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.559002 20451 layer_factory.hpp:77] Creating layer Pooling38
I0808 13:44:08.559013 20451 net.cpp:91] Creating Layer Pooling38
I0808 13:44:08.559020 20451 net.cpp:425] Pooling38 <- Convolution38
I0808 13:44:08.559031 20451 net.cpp:399] Pooling38 -> Pooling38
I0808 13:44:08.559085 20451 net.cpp:141] Setting up Pooling38
I0808 13:44:08.559097 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.559103 20451 net.cpp:156] Memory required for data: 942218752
I0808 13:44:08.559110 20451 layer_factory.hpp:77] Creating layer Convolution39
I0808 13:44:08.559129 20451 net.cpp:91] Creating Layer Convolution39
I0808 13:44:08.559139 20451 net.cpp:425] Convolution39 <- Pooling38
I0808 13:44:08.559152 20451 net.cpp:399] Convolution39 -> Convolution39
I0808 13:44:08.560091 20451 net.cpp:141] Setting up Convolution39
I0808 13:44:08.560109 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.560117 20451 net.cpp:156] Memory required for data: 943255552
I0808 13:44:08.560127 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.560137 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.560144 20451 layer_factory.hpp:77] Creating layer Pooling39
I0808 13:44:08.560156 20451 net.cpp:91] Creating Layer Pooling39
I0808 13:44:08.560165 20451 net.cpp:425] Pooling39 <- Convolution39
I0808 13:44:08.560183 20451 net.cpp:399] Pooling39 -> Pooling39
I0808 13:44:08.560250 20451 net.cpp:141] Setting up Pooling39
I0808 13:44:08.560261 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.560268 20451 net.cpp:156] Memory required for data: 943575552
I0808 13:44:08.560276 20451 layer_factory.hpp:77] Creating layer InnerProduct37
I0808 13:44:08.560293 20451 net.cpp:91] Creating Layer InnerProduct37
I0808 13:44:08.560302 20451 net.cpp:425] InnerProduct37 <- Pooling39
I0808 13:44:08.560320 20451 net.cpp:399] InnerProduct37 -> InnerProduct37
I0808 13:44:08.561528 20451 net.cpp:141] Setting up InnerProduct37
I0808 13:44:08.561544 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.561550 20451 net.cpp:156] Memory required for data: 943601152
I0808 13:44:08.561558 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.561566 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.561573 20451 layer_factory.hpp:77] Creating layer ReLU25
I0808 13:44:08.561583 20451 net.cpp:91] Creating Layer ReLU25
I0808 13:44:08.561591 20451 net.cpp:425] ReLU25 <- InnerProduct37
I0808 13:44:08.561600 20451 net.cpp:386] ReLU25 -> InnerProduct37 (in-place)
I0808 13:44:08.561611 20451 net.cpp:141] Setting up ReLU25
I0808 13:44:08.561619 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.561625 20451 net.cpp:156] Memory required for data: 943626752
I0808 13:44:08.561630 20451 layer_factory.hpp:77] Creating layer InnerProduct38
I0808 13:44:08.561643 20451 net.cpp:91] Creating Layer InnerProduct38
I0808 13:44:08.561650 20451 net.cpp:425] InnerProduct38 <- InnerProduct37
I0808 13:44:08.561661 20451 net.cpp:399] InnerProduct38 -> InnerProduct38
I0808 13:44:08.561844 20451 net.cpp:141] Setting up InnerProduct38
I0808 13:44:08.561853 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.561874 20451 net.cpp:156] Memory required for data: 943639552
I0808 13:44:08.561882 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.561888 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.561895 20451 layer_factory.hpp:77] Creating layer Convolution40
I0808 13:44:08.561908 20451 net.cpp:91] Creating Layer Convolution40
I0808 13:44:08.561914 20451 net.cpp:425] Convolution40 <- c26
I0808 13:44:08.561931 20451 net.cpp:399] Convolution40 -> Convolution40
I0808 13:44:08.562283 20451 net.cpp:141] Setting up Convolution40
I0808 13:44:08.562292 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.562297 20451 net.cpp:156] Memory required for data: 962071552
I0808 13:44:08.562304 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.562311 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.562317 20451 layer_factory.hpp:77] Creating layer Pooling40
I0808 13:44:08.562328 20451 net.cpp:91] Creating Layer Pooling40
I0808 13:44:08.562335 20451 net.cpp:425] Pooling40 <- Convolution40
I0808 13:44:08.562343 20451 net.cpp:399] Pooling40 -> Pooling40
I0808 13:44:08.562396 20451 net.cpp:141] Setting up Pooling40
I0808 13:44:08.562403 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.562408 20451 net.cpp:156] Memory required for data: 966679552
I0808 13:44:08.562414 20451 layer_factory.hpp:77] Creating layer Convolution41
I0808 13:44:08.562427 20451 net.cpp:91] Creating Layer Convolution41
I0808 13:44:08.562433 20451 net.cpp:425] Convolution41 <- Pooling40
I0808 13:44:08.562443 20451 net.cpp:399] Convolution41 -> Convolution41
I0808 13:44:08.562971 20451 net.cpp:141] Setting up Convolution41
I0808 13:44:08.562979 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.562985 20451 net.cpp:156] Memory required for data: 975332352
I0808 13:44:08.562991 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.562999 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.563005 20451 layer_factory.hpp:77] Creating layer Pooling41
I0808 13:44:08.563014 20451 net.cpp:91] Creating Layer Pooling41
I0808 13:44:08.563019 20451 net.cpp:425] Pooling41 <- Convolution41
I0808 13:44:08.563029 20451 net.cpp:399] Pooling41 -> Pooling41
I0808 13:44:08.563078 20451 net.cpp:141] Setting up Pooling41
I0808 13:44:08.563086 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.563091 20451 net.cpp:156] Memory required for data: 977495552
I0808 13:44:08.563097 20451 layer_factory.hpp:77] Creating layer Convolution42
I0808 13:44:08.563110 20451 net.cpp:91] Creating Layer Convolution42
I0808 13:44:08.563117 20451 net.cpp:425] Convolution42 <- Pooling41
I0808 13:44:08.563130 20451 net.cpp:399] Convolution42 -> Convolution42
I0808 13:44:08.564649 20451 net.cpp:141] Setting up Convolution42
I0808 13:44:08.564668 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.564676 20451 net.cpp:156] Memory required for data: 978532352
I0808 13:44:08.564683 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.564692 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.564700 20451 layer_factory.hpp:77] Creating layer Pooling42
I0808 13:44:08.564713 20451 net.cpp:91] Creating Layer Pooling42
I0808 13:44:08.564723 20451 net.cpp:425] Pooling42 <- Convolution42
I0808 13:44:08.564738 20451 net.cpp:399] Pooling42 -> Pooling42
I0808 13:44:08.564805 20451 net.cpp:141] Setting up Pooling42
I0808 13:44:08.564815 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.564821 20451 net.cpp:156] Memory required for data: 978852352
I0808 13:44:08.564827 20451 layer_factory.hpp:77] Creating layer InnerProduct39
I0808 13:44:08.564841 20451 net.cpp:91] Creating Layer InnerProduct39
I0808 13:44:08.564862 20451 net.cpp:425] InnerProduct39 <- Pooling42
I0808 13:44:08.564874 20451 net.cpp:399] InnerProduct39 -> InnerProduct39
I0808 13:44:08.566584 20451 net.cpp:141] Setting up InnerProduct39
I0808 13:44:08.566596 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.566602 20451 net.cpp:156] Memory required for data: 978877952
I0808 13:44:08.566609 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.566617 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.566623 20451 layer_factory.hpp:77] Creating layer ReLU26
I0808 13:44:08.591927 20451 net.cpp:91] Creating Layer ReLU26
I0808 13:44:08.591969 20451 net.cpp:425] ReLU26 <- InnerProduct39
I0808 13:44:08.591987 20451 net.cpp:386] ReLU26 -> InnerProduct39 (in-place)
I0808 13:44:08.592005 20451 net.cpp:141] Setting up ReLU26
I0808 13:44:08.592015 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.592020 20451 net.cpp:156] Memory required for data: 978903552
I0808 13:44:08.592027 20451 layer_factory.hpp:77] Creating layer InnerProduct40
I0808 13:44:08.592041 20451 net.cpp:91] Creating Layer InnerProduct40
I0808 13:44:08.592048 20451 net.cpp:425] InnerProduct40 <- InnerProduct39
I0808 13:44:08.592059 20451 net.cpp:399] InnerProduct40 -> InnerProduct40
I0808 13:44:08.592321 20451 net.cpp:141] Setting up InnerProduct40
I0808 13:44:08.592334 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.592339 20451 net.cpp:156] Memory required for data: 978916352
I0808 13:44:08.592350 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.592360 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.592368 20451 layer_factory.hpp:77] Creating layer Concat7
I0808 13:44:08.592381 20451 net.cpp:91] Creating Layer Concat7
I0808 13:44:08.592388 20451 net.cpp:425] Concat7 <- InnerProduct38
I0808 13:44:08.592399 20451 net.cpp:425] Concat7 <- InnerProduct40
I0808 13:44:08.592416 20451 net.cpp:399] Concat7 -> Concat7
I0808 13:44:08.592458 20451 net.cpp:141] Setting up Concat7
I0808 13:44:08.592473 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.592479 20451 net.cpp:156] Memory required for data: 978941952
I0808 13:44:08.592485 20451 layer_factory.hpp:77] Creating layer InnerProduct41
I0808 13:44:08.592496 20451 net.cpp:91] Creating Layer InnerProduct41
I0808 13:44:08.592504 20451 net.cpp:425] InnerProduct41 <- Concat7
I0808 13:44:08.592517 20451 net.cpp:399] InnerProduct41 -> InnerProduct41
I0808 13:44:08.592742 20451 net.cpp:141] Setting up InnerProduct41
I0808 13:44:08.592753 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.592759 20451 net.cpp:156] Memory required for data: 978958336
I0808 13:44:08.592767 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.592775 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.592782 20451 layer_factory.hpp:77] Creating layer ReLU27
I0808 13:44:08.592792 20451 net.cpp:91] Creating Layer ReLU27
I0808 13:44:08.592798 20451 net.cpp:425] ReLU27 <- InnerProduct41
I0808 13:44:08.592808 20451 net.cpp:386] ReLU27 -> InnerProduct41 (in-place)
I0808 13:44:08.592821 20451 net.cpp:141] Setting up ReLU27
I0808 13:44:08.592830 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.592836 20451 net.cpp:156] Memory required for data: 978974720
I0808 13:44:08.592844 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.592852 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.592859 20451 net.cpp:425] drop1 <- InnerProduct41
I0808 13:44:08.592871 20451 net.cpp:399] drop1 -> Dropout13
I0808 13:44:08.592932 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.592941 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.592947 20451 net.cpp:156] Memory required for data: 978991104
I0808 13:44:08.592954 20451 layer_factory.hpp:77] Creating layer InnerProduct42
I0808 13:44:08.592965 20451 net.cpp:91] Creating Layer InnerProduct42
I0808 13:44:08.592991 20451 net.cpp:425] InnerProduct42 <- Dropout13
I0808 13:44:08.593005 20451 net.cpp:399] InnerProduct42 -> InnerProduct42
I0808 13:44:08.593202 20451 net.cpp:141] Setting up InnerProduct42
I0808 13:44:08.593214 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.593222 20451 net.cpp:156] Memory required for data: 978999296
I0808 13:44:08.593231 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.593240 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.593250 20451 layer_factory.hpp:77] Creating layer ReLU28
I0808 13:44:08.593261 20451 net.cpp:91] Creating Layer ReLU28
I0808 13:44:08.593268 20451 net.cpp:425] ReLU28 <- InnerProduct42
I0808 13:44:08.593282 20451 net.cpp:386] ReLU28 -> InnerProduct42 (in-place)
I0808 13:44:08.593296 20451 net.cpp:141] Setting up ReLU28
I0808 13:44:08.593307 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.593313 20451 net.cpp:156] Memory required for data: 979007488
I0808 13:44:08.593320 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.593330 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.593338 20451 net.cpp:425] drop2 <- InnerProduct42
I0808 13:44:08.593350 20451 net.cpp:399] drop2 -> Dropout14
I0808 13:44:08.593416 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.593427 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.593435 20451 net.cpp:156] Memory required for data: 979015680
I0808 13:44:08.593442 20451 layer_factory.hpp:77] Creating layer dt6
I0808 13:44:08.593458 20451 net.cpp:91] Creating Layer dt6
I0808 13:44:08.593466 20451 net.cpp:425] dt6 <- Dropout14
I0808 13:44:08.593480 20451 net.cpp:399] dt6 -> dt6
I0808 13:44:08.593644 20451 net.cpp:141] Setting up dt6
I0808 13:44:08.593659 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.593667 20451 net.cpp:156] Memory required for data: 979015936
I0808 13:44:08.593674 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.593682 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.593690 20451 layer_factory.hpp:77] Creating layer Convolution43
I0808 13:44:08.593706 20451 net.cpp:91] Creating Layer Convolution43
I0808 13:44:08.593715 20451 net.cpp:425] Convolution43 <- p1_p1_0_split_7
I0808 13:44:08.593734 20451 net.cpp:399] Convolution43 -> Convolution43
I0808 13:44:08.594243 20451 net.cpp:141] Setting up Convolution43
I0808 13:44:08.594255 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.594261 20451 net.cpp:156] Memory required for data: 997447936
I0808 13:44:08.594270 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.594280 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.594288 20451 layer_factory.hpp:77] Creating layer Pooling43
I0808 13:44:08.594302 20451 net.cpp:91] Creating Layer Pooling43
I0808 13:44:08.594310 20451 net.cpp:425] Pooling43 <- Convolution43
I0808 13:44:08.594379 20451 net.cpp:399] Pooling43 -> Pooling43
I0808 13:44:08.594437 20451 net.cpp:141] Setting up Pooling43
I0808 13:44:08.594445 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.594451 20451 net.cpp:156] Memory required for data: 1002055936
I0808 13:44:08.594456 20451 layer_factory.hpp:77] Creating layer Convolution44
I0808 13:44:08.594473 20451 net.cpp:91] Creating Layer Convolution44
I0808 13:44:08.594480 20451 net.cpp:425] Convolution44 <- Pooling43
I0808 13:44:08.594491 20451 net.cpp:399] Convolution44 -> Convolution44
I0808 13:44:08.595027 20451 net.cpp:141] Setting up Convolution44
I0808 13:44:08.595038 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.595044 20451 net.cpp:156] Memory required for data: 1010708736
I0808 13:44:08.595051 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.595058 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.595077 20451 layer_factory.hpp:77] Creating layer Pooling44
I0808 13:44:08.595087 20451 net.cpp:91] Creating Layer Pooling44
I0808 13:44:08.595093 20451 net.cpp:425] Pooling44 <- Convolution44
I0808 13:44:08.595101 20451 net.cpp:399] Pooling44 -> Pooling44
I0808 13:44:08.595152 20451 net.cpp:141] Setting up Pooling44
I0808 13:44:08.595160 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.595165 20451 net.cpp:156] Memory required for data: 1012871936
I0808 13:44:08.621479 20451 layer_factory.hpp:77] Creating layer Convolution45
I0808 13:44:08.621513 20451 net.cpp:91] Creating Layer Convolution45
I0808 13:44:08.621526 20451 net.cpp:425] Convolution45 <- Pooling44
I0808 13:44:08.621546 20451 net.cpp:399] Convolution45 -> Convolution45
I0808 13:44:08.622843 20451 net.cpp:141] Setting up Convolution45
I0808 13:44:08.622865 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.622877 20451 net.cpp:156] Memory required for data: 1013908736
I0808 13:44:08.622891 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.622905 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.622918 20451 layer_factory.hpp:77] Creating layer Pooling45
I0808 13:44:08.622936 20451 net.cpp:91] Creating Layer Pooling45
I0808 13:44:08.622951 20451 net.cpp:425] Pooling45 <- Convolution45
I0808 13:44:08.622978 20451 net.cpp:399] Pooling45 -> Pooling45
I0808 13:44:08.623080 20451 net.cpp:141] Setting up Pooling45
I0808 13:44:08.623101 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.623112 20451 net.cpp:156] Memory required for data: 1014228736
I0808 13:44:08.623123 20451 layer_factory.hpp:77] Creating layer InnerProduct43
I0808 13:44:08.623143 20451 net.cpp:91] Creating Layer InnerProduct43
I0808 13:44:08.623155 20451 net.cpp:425] InnerProduct43 <- Pooling45
I0808 13:44:08.623180 20451 net.cpp:399] InnerProduct43 -> InnerProduct43
I0808 13:44:08.624584 20451 net.cpp:141] Setting up InnerProduct43
I0808 13:44:08.624605 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.624613 20451 net.cpp:156] Memory required for data: 1014254336
I0808 13:44:08.624621 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.624630 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.624637 20451 layer_factory.hpp:77] Creating layer ReLU29
I0808 13:44:08.624650 20451 net.cpp:91] Creating Layer ReLU29
I0808 13:44:08.624658 20451 net.cpp:425] ReLU29 <- InnerProduct43
I0808 13:44:08.624668 20451 net.cpp:386] ReLU29 -> InnerProduct43 (in-place)
I0808 13:44:08.624681 20451 net.cpp:141] Setting up ReLU29
I0808 13:44:08.624691 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.624696 20451 net.cpp:156] Memory required for data: 1014279936
I0808 13:44:08.624702 20451 layer_factory.hpp:77] Creating layer InnerProduct44
I0808 13:44:08.624719 20451 net.cpp:91] Creating Layer InnerProduct44
I0808 13:44:08.624727 20451 net.cpp:425] InnerProduct44 <- InnerProduct43
I0808 13:44:08.624737 20451 net.cpp:399] InnerProduct44 -> InnerProduct44
I0808 13:44:08.624938 20451 net.cpp:141] Setting up InnerProduct44
I0808 13:44:08.624946 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.624953 20451 net.cpp:156] Memory required for data: 1014292736
I0808 13:44:08.624959 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.624968 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.624974 20451 layer_factory.hpp:77] Creating layer Convolution46
I0808 13:44:08.624989 20451 net.cpp:91] Creating Layer Convolution46
I0808 13:44:08.624997 20451 net.cpp:425] Convolution46 <- c27
I0808 13:44:08.625010 20451 net.cpp:399] Convolution46 -> Convolution46
I0808 13:44:08.625409 20451 net.cpp:141] Setting up Convolution46
I0808 13:44:08.625419 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.625443 20451 net.cpp:156] Memory required for data: 1032724736
I0808 13:44:08.625453 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.625463 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.625473 20451 layer_factory.hpp:77] Creating layer Pooling46
I0808 13:44:08.625483 20451 net.cpp:91] Creating Layer Pooling46
I0808 13:44:08.625489 20451 net.cpp:425] Pooling46 <- Convolution46
I0808 13:44:08.625502 20451 net.cpp:399] Pooling46 -> Pooling46
I0808 13:44:08.625561 20451 net.cpp:141] Setting up Pooling46
I0808 13:44:08.625576 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.625581 20451 net.cpp:156] Memory required for data: 1037332736
I0808 13:44:08.625587 20451 layer_factory.hpp:77] Creating layer Convolution47
I0808 13:44:08.625602 20451 net.cpp:91] Creating Layer Convolution47
I0808 13:44:08.625608 20451 net.cpp:425] Convolution47 <- Pooling46
I0808 13:44:08.625620 20451 net.cpp:399] Convolution47 -> Convolution47
I0808 13:44:08.626214 20451 net.cpp:141] Setting up Convolution47
I0808 13:44:08.626224 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.626230 20451 net.cpp:156] Memory required for data: 1045985536
I0808 13:44:08.626237 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.626245 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.626251 20451 layer_factory.hpp:77] Creating layer Pooling47
I0808 13:44:08.626265 20451 net.cpp:91] Creating Layer Pooling47
I0808 13:44:08.626271 20451 net.cpp:425] Pooling47 <- Convolution47
I0808 13:44:08.626281 20451 net.cpp:399] Pooling47 -> Pooling47
I0808 13:44:08.626338 20451 net.cpp:141] Setting up Pooling47
I0808 13:44:08.626348 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.626353 20451 net.cpp:156] Memory required for data: 1048148736
I0808 13:44:08.626359 20451 layer_factory.hpp:77] Creating layer Convolution48
I0808 13:44:08.626374 20451 net.cpp:91] Creating Layer Convolution48
I0808 13:44:08.626380 20451 net.cpp:425] Convolution48 <- Pooling47
I0808 13:44:08.626394 20451 net.cpp:399] Convolution48 -> Convolution48
I0808 13:44:08.627312 20451 net.cpp:141] Setting up Convolution48
I0808 13:44:08.627321 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.627327 20451 net.cpp:156] Memory required for data: 1049185536
I0808 13:44:08.627334 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.627342 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.627349 20451 layer_factory.hpp:77] Creating layer Pooling48
I0808 13:44:08.627358 20451 net.cpp:91] Creating Layer Pooling48
I0808 13:44:08.627365 20451 net.cpp:425] Pooling48 <- Convolution48
I0808 13:44:08.627377 20451 net.cpp:399] Pooling48 -> Pooling48
I0808 13:44:08.627432 20451 net.cpp:141] Setting up Pooling48
I0808 13:44:08.627441 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.627447 20451 net.cpp:156] Memory required for data: 1049505536
I0808 13:44:08.627454 20451 layer_factory.hpp:77] Creating layer InnerProduct45
I0808 13:44:08.627465 20451 net.cpp:91] Creating Layer InnerProduct45
I0808 13:44:08.627472 20451 net.cpp:425] InnerProduct45 <- Pooling48
I0808 13:44:08.627485 20451 net.cpp:399] InnerProduct45 -> InnerProduct45
I0808 13:44:08.629395 20451 net.cpp:141] Setting up InnerProduct45
I0808 13:44:08.629408 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.629415 20451 net.cpp:156] Memory required for data: 1049531136
I0808 13:44:08.629423 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.629431 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.629438 20451 layer_factory.hpp:77] Creating layer ReLU30
I0808 13:44:08.629451 20451 net.cpp:91] Creating Layer ReLU30
I0808 13:44:08.629472 20451 net.cpp:425] ReLU30 <- InnerProduct45
I0808 13:44:08.629482 20451 net.cpp:386] ReLU30 -> InnerProduct45 (in-place)
I0808 13:44:08.629494 20451 net.cpp:141] Setting up ReLU30
I0808 13:44:08.629503 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.629509 20451 net.cpp:156] Memory required for data: 1049556736
I0808 13:44:08.629515 20451 layer_factory.hpp:77] Creating layer InnerProduct46
I0808 13:44:08.629528 20451 net.cpp:91] Creating Layer InnerProduct46
I0808 13:44:08.629535 20451 net.cpp:425] InnerProduct46 <- InnerProduct45
I0808 13:44:08.629546 20451 net.cpp:399] InnerProduct46 -> InnerProduct46
I0808 13:44:08.629817 20451 net.cpp:141] Setting up InnerProduct46
I0808 13:44:08.629830 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.629837 20451 net.cpp:156] Memory required for data: 1049569536
I0808 13:44:08.629843 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.629853 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.629859 20451 layer_factory.hpp:77] Creating layer Concat8
I0808 13:44:08.629868 20451 net.cpp:91] Creating Layer Concat8
I0808 13:44:08.629875 20451 net.cpp:425] Concat8 <- InnerProduct44
I0808 13:44:08.629884 20451 net.cpp:425] Concat8 <- InnerProduct46
I0808 13:44:08.629894 20451 net.cpp:399] Concat8 -> Concat8
I0808 13:44:08.629931 20451 net.cpp:141] Setting up Concat8
I0808 13:44:08.629940 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.629946 20451 net.cpp:156] Memory required for data: 1049595136
I0808 13:44:08.629952 20451 layer_factory.hpp:77] Creating layer InnerProduct47
I0808 13:44:08.629962 20451 net.cpp:91] Creating Layer InnerProduct47
I0808 13:44:08.629968 20451 net.cpp:425] InnerProduct47 <- Concat8
I0808 13:44:08.629979 20451 net.cpp:399] InnerProduct47 -> InnerProduct47
I0808 13:44:08.630195 20451 net.cpp:141] Setting up InnerProduct47
I0808 13:44:08.630204 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.630210 20451 net.cpp:156] Memory required for data: 1049611520
I0808 13:44:08.630216 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.630224 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.630231 20451 layer_factory.hpp:77] Creating layer ReLU31
I0808 13:44:08.630242 20451 net.cpp:91] Creating Layer ReLU31
I0808 13:44:08.630249 20451 net.cpp:425] ReLU31 <- InnerProduct47
I0808 13:44:08.630259 20451 net.cpp:386] ReLU31 -> InnerProduct47 (in-place)
I0808 13:44:08.630269 20451 net.cpp:141] Setting up ReLU31
I0808 13:44:08.630276 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.630282 20451 net.cpp:156] Memory required for data: 1049627904
I0808 13:44:08.630290 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.630298 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.630307 20451 net.cpp:425] drop1 <- InnerProduct47
I0808 13:44:08.630317 20451 net.cpp:399] drop1 -> Dropout15
I0808 13:44:08.630373 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.630383 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.630389 20451 net.cpp:156] Memory required for data: 1049644288
I0808 13:44:08.630396 20451 layer_factory.hpp:77] Creating layer InnerProduct48
I0808 13:44:08.630406 20451 net.cpp:91] Creating Layer InnerProduct48
I0808 13:44:08.630412 20451 net.cpp:425] InnerProduct48 <- Dropout15
I0808 13:44:08.630425 20451 net.cpp:399] InnerProduct48 -> InnerProduct48
I0808 13:44:08.630602 20451 net.cpp:141] Setting up InnerProduct48
I0808 13:44:08.630611 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.630617 20451 net.cpp:156] Memory required for data: 1049652480
I0808 13:44:08.630625 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.630632 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.630640 20451 layer_factory.hpp:77] Creating layer ReLU32
I0808 13:44:08.630659 20451 net.cpp:91] Creating Layer ReLU32
I0808 13:44:08.630666 20451 net.cpp:425] ReLU32 <- InnerProduct48
I0808 13:44:08.630676 20451 net.cpp:386] ReLU32 -> InnerProduct48 (in-place)
I0808 13:44:08.630686 20451 net.cpp:141] Setting up ReLU32
I0808 13:44:08.630694 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.630700 20451 net.cpp:156] Memory required for data: 1049660672
I0808 13:44:08.630707 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.630717 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.630724 20451 net.cpp:425] drop2 <- InnerProduct48
I0808 13:44:08.630734 20451 net.cpp:399] drop2 -> Dropout16
I0808 13:44:08.630789 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.630798 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.630805 20451 net.cpp:156] Memory required for data: 1049668864
I0808 13:44:08.630811 20451 layer_factory.hpp:77] Creating layer dt7
I0808 13:44:08.630820 20451 net.cpp:91] Creating Layer dt7
I0808 13:44:08.630827 20451 net.cpp:425] dt7 <- Dropout16
I0808 13:44:08.630841 20451 net.cpp:399] dt7 -> dt7
I0808 13:44:08.630993 20451 net.cpp:141] Setting up dt7
I0808 13:44:08.631002 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.631008 20451 net.cpp:156] Memory required for data: 1049669120
I0808 13:44:08.631016 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.631023 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.631029 20451 layer_factory.hpp:77] Creating layer Convolution49
I0808 13:44:08.631044 20451 net.cpp:91] Creating Layer Convolution49
I0808 13:44:08.631052 20451 net.cpp:425] Convolution49 <- p1_p1_0_split_8
I0808 13:44:08.631065 20451 net.cpp:399] Convolution49 -> Convolution49
I0808 13:44:08.631472 20451 net.cpp:141] Setting up Convolution49
I0808 13:44:08.631484 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.631490 20451 net.cpp:156] Memory required for data: 1068101120
I0808 13:44:08.631497 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.631505 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.631511 20451 layer_factory.hpp:77] Creating layer Pooling49
I0808 13:44:08.631602 20451 net.cpp:91] Creating Layer Pooling49
I0808 13:44:08.631608 20451 net.cpp:425] Pooling49 <- Convolution49
I0808 13:44:08.631619 20451 net.cpp:399] Pooling49 -> Pooling49
I0808 13:44:08.631675 20451 net.cpp:141] Setting up Pooling49
I0808 13:44:08.631685 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.631690 20451 net.cpp:156] Memory required for data: 1072709120
I0808 13:44:08.631697 20451 layer_factory.hpp:77] Creating layer Convolution50
I0808 13:44:08.631712 20451 net.cpp:91] Creating Layer Convolution50
I0808 13:44:08.631719 20451 net.cpp:425] Convolution50 <- Pooling49
I0808 13:44:08.631736 20451 net.cpp:399] Convolution50 -> Convolution50
I0808 13:44:08.632325 20451 net.cpp:141] Setting up Convolution50
I0808 13:44:08.632334 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.632340 20451 net.cpp:156] Memory required for data: 1081361920
I0808 13:44:08.632347 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.632355 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.632362 20451 layer_factory.hpp:77] Creating layer Pooling50
I0808 13:44:08.632370 20451 net.cpp:91] Creating Layer Pooling50
I0808 13:44:08.632377 20451 net.cpp:425] Pooling50 <- Convolution50
I0808 13:44:08.632390 20451 net.cpp:399] Pooling50 -> Pooling50
I0808 13:44:08.632452 20451 net.cpp:141] Setting up Pooling50
I0808 13:44:08.632459 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.632467 20451 net.cpp:156] Memory required for data: 1083525120
I0808 13:44:08.632472 20451 layer_factory.hpp:77] Creating layer Convolution51
I0808 13:44:08.632489 20451 net.cpp:91] Creating Layer Convolution51
I0808 13:44:08.632509 20451 net.cpp:425] Convolution51 <- Pooling50
I0808 13:44:08.632521 20451 net.cpp:399] Convolution51 -> Convolution51
I0808 13:44:08.634073 20451 net.cpp:141] Setting up Convolution51
I0808 13:44:08.634085 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.634093 20451 net.cpp:156] Memory required for data: 1084561920
I0808 13:44:08.651571 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.651612 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.651633 20451 layer_factory.hpp:77] Creating layer Pooling51
I0808 13:44:08.651662 20451 net.cpp:91] Creating Layer Pooling51
I0808 13:44:08.651672 20451 net.cpp:425] Pooling51 <- Convolution51
I0808 13:44:08.651684 20451 net.cpp:399] Pooling51 -> Pooling51
I0808 13:44:08.651768 20451 net.cpp:141] Setting up Pooling51
I0808 13:44:08.651782 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.651789 20451 net.cpp:156] Memory required for data: 1084881920
I0808 13:44:08.651798 20451 layer_factory.hpp:77] Creating layer InnerProduct49
I0808 13:44:08.651813 20451 net.cpp:91] Creating Layer InnerProduct49
I0808 13:44:08.651821 20451 net.cpp:425] InnerProduct49 <- Pooling51
I0808 13:44:08.651837 20451 net.cpp:399] InnerProduct49 -> InnerProduct49
I0808 13:44:08.653118 20451 net.cpp:141] Setting up InnerProduct49
I0808 13:44:08.653129 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.653136 20451 net.cpp:156] Memory required for data: 1084907520
I0808 13:44:08.653142 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.653151 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.653157 20451 layer_factory.hpp:77] Creating layer ReLU33
I0808 13:44:08.653167 20451 net.cpp:91] Creating Layer ReLU33
I0808 13:44:08.653174 20451 net.cpp:425] ReLU33 <- InnerProduct49
I0808 13:44:08.653185 20451 net.cpp:386] ReLU33 -> InnerProduct49 (in-place)
I0808 13:44:08.653198 20451 net.cpp:141] Setting up ReLU33
I0808 13:44:08.653205 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.653213 20451 net.cpp:156] Memory required for data: 1084933120
I0808 13:44:08.653218 20451 layer_factory.hpp:77] Creating layer InnerProduct50
I0808 13:44:08.653228 20451 net.cpp:91] Creating Layer InnerProduct50
I0808 13:44:08.653235 20451 net.cpp:425] InnerProduct50 <- InnerProduct49
I0808 13:44:08.653249 20451 net.cpp:399] InnerProduct50 -> InnerProduct50
I0808 13:44:08.653466 20451 net.cpp:141] Setting up InnerProduct50
I0808 13:44:08.653477 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.653483 20451 net.cpp:156] Memory required for data: 1084945920
I0808 13:44:08.653491 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.653498 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.653506 20451 layer_factory.hpp:77] Creating layer Convolution52
I0808 13:44:08.653518 20451 net.cpp:91] Creating Layer Convolution52
I0808 13:44:08.653527 20451 net.cpp:425] Convolution52 <- c28
I0808 13:44:08.653540 20451 net.cpp:399] Convolution52 -> Convolution52
I0808 13:44:08.653940 20451 net.cpp:141] Setting up Convolution52
I0808 13:44:08.653950 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.653956 20451 net.cpp:156] Memory required for data: 1103377920
I0808 13:44:08.653964 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.653971 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.653978 20451 layer_factory.hpp:77] Creating layer Pooling52
I0808 13:44:08.653990 20451 net.cpp:91] Creating Layer Pooling52
I0808 13:44:08.653996 20451 net.cpp:425] Pooling52 <- Convolution52
I0808 13:44:08.654006 20451 net.cpp:399] Pooling52 -> Pooling52
I0808 13:44:08.654065 20451 net.cpp:141] Setting up Pooling52
I0808 13:44:08.654093 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.654100 20451 net.cpp:156] Memory required for data: 1107985920
I0808 13:44:08.654109 20451 layer_factory.hpp:77] Creating layer Convolution53
I0808 13:44:08.654127 20451 net.cpp:91] Creating Layer Convolution53
I0808 13:44:08.654137 20451 net.cpp:425] Convolution53 <- Pooling52
I0808 13:44:08.654151 20451 net.cpp:399] Convolution53 -> Convolution53
I0808 13:44:08.654754 20451 net.cpp:141] Setting up Convolution53
I0808 13:44:08.654764 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.654770 20451 net.cpp:156] Memory required for data: 1116638720
I0808 13:44:08.654778 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.654785 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.654793 20451 layer_factory.hpp:77] Creating layer Pooling53
I0808 13:44:08.654801 20451 net.cpp:91] Creating Layer Pooling53
I0808 13:44:08.654808 20451 net.cpp:425] Pooling53 <- Convolution53
I0808 13:44:08.654821 20451 net.cpp:399] Pooling53 -> Pooling53
I0808 13:44:08.654876 20451 net.cpp:141] Setting up Pooling53
I0808 13:44:08.654886 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.654891 20451 net.cpp:156] Memory required for data: 1118801920
I0808 13:44:08.654897 20451 layer_factory.hpp:77] Creating layer Convolution54
I0808 13:44:08.654914 20451 net.cpp:91] Creating Layer Convolution54
I0808 13:44:08.654922 20451 net.cpp:425] Convolution54 <- Pooling53
I0808 13:44:08.654932 20451 net.cpp:399] Convolution54 -> Convolution54
I0808 13:44:08.655854 20451 net.cpp:141] Setting up Convolution54
I0808 13:44:08.655864 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.655870 20451 net.cpp:156] Memory required for data: 1119838720
I0808 13:44:08.655877 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.655885 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.655891 20451 layer_factory.hpp:77] Creating layer Pooling54
I0808 13:44:08.655905 20451 net.cpp:91] Creating Layer Pooling54
I0808 13:44:08.655912 20451 net.cpp:425] Pooling54 <- Convolution54
I0808 13:44:08.655922 20451 net.cpp:399] Pooling54 -> Pooling54
I0808 13:44:08.655982 20451 net.cpp:141] Setting up Pooling54
I0808 13:44:08.655989 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.655995 20451 net.cpp:156] Memory required for data: 1120158720
I0808 13:44:08.656002 20451 layer_factory.hpp:77] Creating layer InnerProduct51
I0808 13:44:08.656013 20451 net.cpp:91] Creating Layer InnerProduct51
I0808 13:44:08.656018 20451 net.cpp:425] InnerProduct51 <- Pooling54
I0808 13:44:08.656031 20451 net.cpp:399] InnerProduct51 -> InnerProduct51
I0808 13:44:08.657932 20451 net.cpp:141] Setting up InnerProduct51
I0808 13:44:08.657944 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.657951 20451 net.cpp:156] Memory required for data: 1120184320
I0808 13:44:08.657959 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.657968 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.657974 20451 layer_factory.hpp:77] Creating layer ReLU34
I0808 13:44:08.657984 20451 net.cpp:91] Creating Layer ReLU34
I0808 13:44:08.657991 20451 net.cpp:425] ReLU34 <- InnerProduct51
I0808 13:44:08.658001 20451 net.cpp:386] ReLU34 -> InnerProduct51 (in-place)
I0808 13:44:08.658012 20451 net.cpp:141] Setting up ReLU34
I0808 13:44:08.658020 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.658026 20451 net.cpp:156] Memory required for data: 1120209920
I0808 13:44:08.658033 20451 layer_factory.hpp:77] Creating layer InnerProduct52
I0808 13:44:08.658046 20451 net.cpp:91] Creating Layer InnerProduct52
I0808 13:44:08.658053 20451 net.cpp:425] InnerProduct52 <- InnerProduct51
I0808 13:44:08.658066 20451 net.cpp:399] InnerProduct52 -> InnerProduct52
I0808 13:44:08.658284 20451 net.cpp:141] Setting up InnerProduct52
I0808 13:44:08.658293 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.658299 20451 net.cpp:156] Memory required for data: 1120222720
I0808 13:44:08.658306 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.681877 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.681911 20451 layer_factory.hpp:77] Creating layer Concat9
I0808 13:44:08.681941 20451 net.cpp:91] Creating Layer Concat9
I0808 13:44:08.681962 20451 net.cpp:425] Concat9 <- InnerProduct50
I0808 13:44:08.681987 20451 net.cpp:425] Concat9 <- InnerProduct52
I0808 13:44:08.682015 20451 net.cpp:399] Concat9 -> Concat9
I0808 13:44:08.682164 20451 net.cpp:141] Setting up Concat9
I0808 13:44:08.682191 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.682207 20451 net.cpp:156] Memory required for data: 1120248320
I0808 13:44:08.682224 20451 layer_factory.hpp:77] Creating layer InnerProduct53
I0808 13:44:08.682340 20451 net.cpp:91] Creating Layer InnerProduct53
I0808 13:44:08.682361 20451 net.cpp:425] InnerProduct53 <- Concat9
I0808 13:44:08.682391 20451 net.cpp:399] InnerProduct53 -> InnerProduct53
I0808 13:44:08.682935 20451 net.cpp:141] Setting up InnerProduct53
I0808 13:44:08.682961 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.682977 20451 net.cpp:156] Memory required for data: 1120264704
I0808 13:44:08.682996 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.683017 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.683034 20451 layer_factory.hpp:77] Creating layer ReLU35
I0808 13:44:08.683058 20451 net.cpp:91] Creating Layer ReLU35
I0808 13:44:08.683075 20451 net.cpp:425] ReLU35 <- InnerProduct53
I0808 13:44:08.683105 20451 net.cpp:386] ReLU35 -> InnerProduct53 (in-place)
I0808 13:44:08.683133 20451 net.cpp:141] Setting up ReLU35
I0808 13:44:08.683156 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.683171 20451 net.cpp:156] Memory required for data: 1120281088
I0808 13:44:08.683187 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.683209 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.683226 20451 net.cpp:425] drop1 <- InnerProduct53
I0808 13:44:08.683259 20451 net.cpp:399] drop1 -> Dropout17
I0808 13:44:08.683372 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.683385 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.683395 20451 net.cpp:156] Memory required for data: 1120297472
I0808 13:44:08.683403 20451 layer_factory.hpp:77] Creating layer InnerProduct54
I0808 13:44:08.683420 20451 net.cpp:91] Creating Layer InnerProduct54
I0808 13:44:08.683429 20451 net.cpp:425] InnerProduct54 <- Dropout17
I0808 13:44:08.683444 20451 net.cpp:399] InnerProduct54 -> InnerProduct54
I0808 13:44:08.683650 20451 net.cpp:141] Setting up InnerProduct54
I0808 13:44:08.683658 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.683665 20451 net.cpp:156] Memory required for data: 1120305664
I0808 13:44:08.683672 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.683681 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.683687 20451 layer_factory.hpp:77] Creating layer ReLU36
I0808 13:44:08.683701 20451 net.cpp:91] Creating Layer ReLU36
I0808 13:44:08.683708 20451 net.cpp:425] ReLU36 <- InnerProduct54
I0808 13:44:08.683717 20451 net.cpp:386] ReLU36 -> InnerProduct54 (in-place)
I0808 13:44:08.683728 20451 net.cpp:141] Setting up ReLU36
I0808 13:44:08.683737 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.683743 20451 net.cpp:156] Memory required for data: 1120313856
I0808 13:44:08.683748 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.683760 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.683768 20451 net.cpp:425] drop2 <- InnerProduct54
I0808 13:44:08.683776 20451 net.cpp:399] drop2 -> Dropout18
I0808 13:44:08.683848 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.683857 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.683863 20451 net.cpp:156] Memory required for data: 1120322048
I0808 13:44:08.683869 20451 layer_factory.hpp:77] Creating layer dt8
I0808 13:44:08.683879 20451 net.cpp:91] Creating Layer dt8
I0808 13:44:08.683887 20451 net.cpp:425] dt8 <- Dropout18
I0808 13:44:08.683900 20451 net.cpp:399] dt8 -> dt8
I0808 13:44:08.684065 20451 net.cpp:141] Setting up dt8
I0808 13:44:08.684074 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.684080 20451 net.cpp:156] Memory required for data: 1120322304
I0808 13:44:08.684087 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.684095 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.684103 20451 layer_factory.hpp:77] Creating layer Convolution55
I0808 13:44:08.684118 20451 net.cpp:91] Creating Layer Convolution55
I0808 13:44:08.684126 20451 net.cpp:425] Convolution55 <- p1_p1_0_split_9
I0808 13:44:08.684139 20451 net.cpp:399] Convolution55 -> Convolution55
I0808 13:44:08.684535 20451 net.cpp:141] Setting up Convolution55
I0808 13:44:08.684550 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.684556 20451 net.cpp:156] Memory required for data: 1138754304
I0808 13:44:08.684562 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.684571 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.684577 20451 layer_factory.hpp:77] Creating layer Pooling55
I0808 13:44:08.684587 20451 net.cpp:91] Creating Layer Pooling55
I0808 13:44:08.684595 20451 net.cpp:425] Pooling55 <- Convolution55
I0808 13:44:08.684605 20451 net.cpp:399] Pooling55 -> Pooling55
I0808 13:44:08.684664 20451 net.cpp:141] Setting up Pooling55
I0808 13:44:08.684674 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.684679 20451 net.cpp:156] Memory required for data: 1143362304
I0808 13:44:08.684685 20451 layer_factory.hpp:77] Creating layer Convolution56
I0808 13:44:08.684701 20451 net.cpp:91] Creating Layer Convolution56
I0808 13:44:08.684708 20451 net.cpp:425] Convolution56 <- Pooling55
I0808 13:44:08.684721 20451 net.cpp:399] Convolution56 -> Convolution56
I0808 13:44:08.685323 20451 net.cpp:141] Setting up Convolution56
I0808 13:44:08.685333 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.685338 20451 net.cpp:156] Memory required for data: 1152015104
I0808 13:44:08.685345 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.685353 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.685359 20451 layer_factory.hpp:77] Creating layer Pooling56
I0808 13:44:08.685369 20451 net.cpp:91] Creating Layer Pooling56
I0808 13:44:08.685375 20451 net.cpp:425] Pooling56 <- Convolution56
I0808 13:44:08.685389 20451 net.cpp:399] Pooling56 -> Pooling56
I0808 13:44:08.685442 20451 net.cpp:141] Setting up Pooling56
I0808 13:44:08.685453 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.685459 20451 net.cpp:156] Memory required for data: 1154178304
I0808 13:44:08.685466 20451 layer_factory.hpp:77] Creating layer Convolution57
I0808 13:44:08.685477 20451 net.cpp:91] Creating Layer Convolution57
I0808 13:44:08.685484 20451 net.cpp:425] Convolution57 <- Pooling56
I0808 13:44:08.685498 20451 net.cpp:399] Convolution57 -> Convolution57
I0808 13:44:08.686414 20451 net.cpp:141] Setting up Convolution57
I0808 13:44:08.686424 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.686429 20451 net.cpp:156] Memory required for data: 1155215104
I0808 13:44:08.686436 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.686444 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.686451 20451 layer_factory.hpp:77] Creating layer Pooling57
I0808 13:44:08.686471 20451 net.cpp:91] Creating Layer Pooling57
I0808 13:44:08.686480 20451 net.cpp:425] Pooling57 <- Convolution57
I0808 13:44:08.686489 20451 net.cpp:399] Pooling57 -> Pooling57
I0808 13:44:08.686548 20451 net.cpp:141] Setting up Pooling57
I0808 13:44:08.686558 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.686563 20451 net.cpp:156] Memory required for data: 1155535104
I0808 13:44:08.686570 20451 layer_factory.hpp:77] Creating layer InnerProduct55
I0808 13:44:08.686583 20451 net.cpp:91] Creating Layer InnerProduct55
I0808 13:44:08.686589 20451 net.cpp:425] InnerProduct55 <- Pooling57
I0808 13:44:08.686599 20451 net.cpp:399] InnerProduct55 -> InnerProduct55
I0808 13:44:08.687872 20451 net.cpp:141] Setting up InnerProduct55
I0808 13:44:08.687882 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.687888 20451 net.cpp:156] Memory required for data: 1155560704
I0808 13:44:08.687896 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.687904 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.687911 20451 layer_factory.hpp:77] Creating layer ReLU37
I0808 13:44:08.687921 20451 net.cpp:91] Creating Layer ReLU37
I0808 13:44:08.687927 20451 net.cpp:425] ReLU37 <- InnerProduct55
I0808 13:44:08.687939 20451 net.cpp:386] ReLU37 -> InnerProduct55 (in-place)
I0808 13:44:08.687950 20451 net.cpp:141] Setting up ReLU37
I0808 13:44:08.687958 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.687964 20451 net.cpp:156] Memory required for data: 1155586304
I0808 13:44:08.687970 20451 layer_factory.hpp:77] Creating layer InnerProduct56
I0808 13:44:08.687980 20451 net.cpp:91] Creating Layer InnerProduct56
I0808 13:44:08.687988 20451 net.cpp:425] InnerProduct56 <- InnerProduct55
I0808 13:44:08.688000 20451 net.cpp:399] InnerProduct56 -> InnerProduct56
I0808 13:44:08.688197 20451 net.cpp:141] Setting up InnerProduct56
I0808 13:44:08.688206 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.688212 20451 net.cpp:156] Memory required for data: 1155599104
I0808 13:44:08.688220 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.688227 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.688235 20451 layer_factory.hpp:77] Creating layer Convolution58
I0808 13:44:08.688246 20451 net.cpp:91] Creating Layer Convolution58
I0808 13:44:08.688253 20451 net.cpp:425] Convolution58 <- c29
I0808 13:44:08.688268 20451 net.cpp:399] Convolution58 -> Convolution58
I0808 13:44:08.688664 20451 net.cpp:141] Setting up Convolution58
I0808 13:44:08.688673 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.688679 20451 net.cpp:156] Memory required for data: 1174031104
I0808 13:44:08.688686 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.688694 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.688700 20451 layer_factory.hpp:77] Creating layer Pooling58
I0808 13:44:08.688711 20451 net.cpp:91] Creating Layer Pooling58
I0808 13:44:08.688719 20451 net.cpp:425] Pooling58 <- Convolution58
I0808 13:44:08.688729 20451 net.cpp:399] Pooling58 -> Pooling58
I0808 13:44:08.688786 20451 net.cpp:141] Setting up Pooling58
I0808 13:44:08.688794 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.688801 20451 net.cpp:156] Memory required for data: 1178639104
I0808 13:44:08.688807 20451 layer_factory.hpp:77] Creating layer Convolution59
I0808 13:44:08.688822 20451 net.cpp:91] Creating Layer Convolution59
I0808 13:44:08.688827 20451 net.cpp:425] Convolution59 <- Pooling58
I0808 13:44:08.688841 20451 net.cpp:399] Convolution59 -> Convolution59
I0808 13:44:08.689440 20451 net.cpp:141] Setting up Convolution59
I0808 13:44:08.689450 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.689455 20451 net.cpp:156] Memory required for data: 1187291904
I0808 13:44:08.689476 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.689483 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.689492 20451 layer_factory.hpp:77] Creating layer Pooling59
I0808 13:44:08.689502 20451 net.cpp:91] Creating Layer Pooling59
I0808 13:44:08.689509 20451 net.cpp:425] Pooling59 <- Convolution59
I0808 13:44:08.689522 20451 net.cpp:399] Pooling59 -> Pooling59
I0808 13:44:08.689577 20451 net.cpp:141] Setting up Pooling59
I0808 13:44:08.689585 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.689591 20451 net.cpp:156] Memory required for data: 1189455104
I0808 13:44:08.689597 20451 layer_factory.hpp:77] Creating layer Convolution60
I0808 13:44:08.689615 20451 net.cpp:91] Creating Layer Convolution60
I0808 13:44:08.689621 20451 net.cpp:425] Convolution60 <- Pooling59
I0808 13:44:08.689632 20451 net.cpp:399] Convolution60 -> Convolution60
I0808 13:44:08.691237 20451 net.cpp:141] Setting up Convolution60
I0808 13:44:08.691251 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.691256 20451 net.cpp:156] Memory required for data: 1190491904
I0808 13:44:08.691264 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.691280 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.691288 20451 layer_factory.hpp:77] Creating layer Pooling60
I0808 13:44:08.691298 20451 net.cpp:91] Creating Layer Pooling60
I0808 13:44:08.691305 20451 net.cpp:425] Pooling60 <- Convolution60
I0808 13:44:08.691323 20451 net.cpp:399] Pooling60 -> Pooling60
I0808 13:44:08.691380 20451 net.cpp:141] Setting up Pooling60
I0808 13:44:08.691390 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.691396 20451 net.cpp:156] Memory required for data: 1190811904
I0808 13:44:08.691402 20451 layer_factory.hpp:77] Creating layer InnerProduct57
I0808 13:44:08.691416 20451 net.cpp:91] Creating Layer InnerProduct57
I0808 13:44:08.691422 20451 net.cpp:425] InnerProduct57 <- Pooling60
I0808 13:44:08.691436 20451 net.cpp:399] InnerProduct57 -> InnerProduct57
I0808 13:44:08.693311 20451 net.cpp:141] Setting up InnerProduct57
I0808 13:44:08.693325 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.693332 20451 net.cpp:156] Memory required for data: 1190837504
I0808 13:44:08.693341 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.693348 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.693356 20451 layer_factory.hpp:77] Creating layer ReLU38
I0808 13:44:08.693368 20451 net.cpp:91] Creating Layer ReLU38
I0808 13:44:08.693375 20451 net.cpp:425] ReLU38 <- InnerProduct57
I0808 13:44:08.693385 20451 net.cpp:386] ReLU38 -> InnerProduct57 (in-place)
I0808 13:44:08.693397 20451 net.cpp:141] Setting up ReLU38
I0808 13:44:08.693405 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.693411 20451 net.cpp:156] Memory required for data: 1190863104
I0808 13:44:08.693418 20451 layer_factory.hpp:77] Creating layer InnerProduct58
I0808 13:44:08.693430 20451 net.cpp:91] Creating Layer InnerProduct58
I0808 13:44:08.693437 20451 net.cpp:425] InnerProduct58 <- InnerProduct57
I0808 13:44:08.693447 20451 net.cpp:399] InnerProduct58 -> InnerProduct58
I0808 13:44:08.693652 20451 net.cpp:141] Setting up InnerProduct58
I0808 13:44:08.693661 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.693667 20451 net.cpp:156] Memory required for data: 1190875904
I0808 13:44:08.693675 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.693682 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.693688 20451 layer_factory.hpp:77] Creating layer Concat10
I0808 13:44:08.693698 20451 net.cpp:91] Creating Layer Concat10
I0808 13:44:08.693704 20451 net.cpp:425] Concat10 <- InnerProduct56
I0808 13:44:08.693728 20451 net.cpp:425] Concat10 <- InnerProduct58
I0808 13:44:08.693742 20451 net.cpp:399] Concat10 -> Concat10
I0808 13:44:08.712023 20451 net.cpp:141] Setting up Concat10
I0808 13:44:08.712040 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.712049 20451 net.cpp:156] Memory required for data: 1190901504
I0808 13:44:08.712059 20451 layer_factory.hpp:77] Creating layer InnerProduct59
I0808 13:44:08.712074 20451 net.cpp:91] Creating Layer InnerProduct59
I0808 13:44:08.712083 20451 net.cpp:425] InnerProduct59 <- Concat10
I0808 13:44:08.712103 20451 net.cpp:399] InnerProduct59 -> InnerProduct59
I0808 13:44:08.712371 20451 net.cpp:141] Setting up InnerProduct59
I0808 13:44:08.712383 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.712390 20451 net.cpp:156] Memory required for data: 1190917888
I0808 13:44:08.712404 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.712416 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.712424 20451 layer_factory.hpp:77] Creating layer ReLU39
I0808 13:44:08.712432 20451 net.cpp:91] Creating Layer ReLU39
I0808 13:44:08.712440 20451 net.cpp:425] ReLU39 <- InnerProduct59
I0808 13:44:08.712452 20451 net.cpp:386] ReLU39 -> InnerProduct59 (in-place)
I0808 13:44:08.712463 20451 net.cpp:141] Setting up ReLU39
I0808 13:44:08.712471 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.712477 20451 net.cpp:156] Memory required for data: 1190934272
I0808 13:44:08.712484 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.712493 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.712501 20451 net.cpp:425] drop1 <- InnerProduct59
I0808 13:44:08.712512 20451 net.cpp:399] drop1 -> Dropout19
I0808 13:44:08.712569 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.712579 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.712584 20451 net.cpp:156] Memory required for data: 1190950656
I0808 13:44:08.712590 20451 layer_factory.hpp:77] Creating layer InnerProduct60
I0808 13:44:08.712611 20451 net.cpp:91] Creating Layer InnerProduct60
I0808 13:44:08.712620 20451 net.cpp:425] InnerProduct60 <- Dropout19
I0808 13:44:08.712630 20451 net.cpp:399] InnerProduct60 -> InnerProduct60
I0808 13:44:08.712841 20451 net.cpp:141] Setting up InnerProduct60
I0808 13:44:08.712852 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.712858 20451 net.cpp:156] Memory required for data: 1190958848
I0808 13:44:08.712949 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.712961 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.712971 20451 layer_factory.hpp:77] Creating layer ReLU40
I0808 13:44:08.712982 20451 net.cpp:91] Creating Layer ReLU40
I0808 13:44:08.712990 20451 net.cpp:425] ReLU40 <- InnerProduct60
I0808 13:44:08.713001 20451 net.cpp:386] ReLU40 -> InnerProduct60 (in-place)
I0808 13:44:08.713011 20451 net.cpp:141] Setting up ReLU40
I0808 13:44:08.713021 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.713027 20451 net.cpp:156] Memory required for data: 1190967040
I0808 13:44:08.713032 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.713042 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.713048 20451 net.cpp:425] drop2 <- InnerProduct60
I0808 13:44:08.713058 20451 net.cpp:399] drop2 -> Dropout20
I0808 13:44:08.713115 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.713124 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.713131 20451 net.cpp:156] Memory required for data: 1190975232
I0808 13:44:08.713137 20451 layer_factory.hpp:77] Creating layer dt9
I0808 13:44:08.713147 20451 net.cpp:91] Creating Layer dt9
I0808 13:44:08.713155 20451 net.cpp:425] dt9 <- Dropout20
I0808 13:44:08.713167 20451 net.cpp:399] dt9 -> dt9
I0808 13:44:08.713328 20451 net.cpp:141] Setting up dt9
I0808 13:44:08.713336 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.713342 20451 net.cpp:156] Memory required for data: 1190975488
I0808 13:44:08.713364 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.713372 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.713379 20451 layer_factory.hpp:77] Creating layer Convolution61
I0808 13:44:08.713398 20451 net.cpp:91] Creating Layer Convolution61
I0808 13:44:08.713405 20451 net.cpp:425] Convolution61 <- p2_p2_0_split_1
I0808 13:44:08.713418 20451 net.cpp:399] Convolution61 -> Convolution61
I0808 13:44:08.713817 20451 net.cpp:141] Setting up Convolution61
I0808 13:44:08.713830 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.713838 20451 net.cpp:156] Memory required for data: 1209407488
I0808 13:44:08.713847 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.713858 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.713866 20451 layer_factory.hpp:77] Creating layer Pooling61
I0808 13:44:08.713881 20451 net.cpp:91] Creating Layer Pooling61
I0808 13:44:08.713891 20451 net.cpp:425] Pooling61 <- Convolution61
I0808 13:44:08.713904 20451 net.cpp:399] Pooling61 -> Pooling61
I0808 13:44:08.713968 20451 net.cpp:141] Setting up Pooling61
I0808 13:44:08.713976 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.713982 20451 net.cpp:156] Memory required for data: 1214015488
I0808 13:44:08.713989 20451 layer_factory.hpp:77] Creating layer Convolution62
I0808 13:44:08.714006 20451 net.cpp:91] Creating Layer Convolution62
I0808 13:44:08.714015 20451 net.cpp:425] Convolution62 <- Pooling61
I0808 13:44:08.714030 20451 net.cpp:399] Convolution62 -> Convolution62
I0808 13:44:08.714674 20451 net.cpp:141] Setting up Convolution62
I0808 13:44:08.714686 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.714694 20451 net.cpp:156] Memory required for data: 1222668288
I0808 13:44:08.714700 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.714709 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.714716 20451 layer_factory.hpp:77] Creating layer Pooling62
I0808 13:44:08.714728 20451 net.cpp:91] Creating Layer Pooling62
I0808 13:44:08.714735 20451 net.cpp:425] Pooling62 <- Convolution62
I0808 13:44:08.714745 20451 net.cpp:399] Pooling62 -> Pooling62
I0808 13:44:08.714804 20451 net.cpp:141] Setting up Pooling62
I0808 13:44:08.714813 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.714819 20451 net.cpp:156] Memory required for data: 1224831488
I0808 13:44:08.714825 20451 layer_factory.hpp:77] Creating layer Convolution63
I0808 13:44:08.714843 20451 net.cpp:91] Creating Layer Convolution63
I0808 13:44:08.714850 20451 net.cpp:425] Convolution63 <- Pooling62
I0808 13:44:08.714864 20451 net.cpp:399] Convolution63 -> Convolution63
I0808 13:44:08.715813 20451 net.cpp:141] Setting up Convolution63
I0808 13:44:08.715823 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.715829 20451 net.cpp:156] Memory required for data: 1225868288
I0808 13:44:08.715837 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.715845 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.715852 20451 layer_factory.hpp:77] Creating layer Pooling63
I0808 13:44:08.715862 20451 net.cpp:91] Creating Layer Pooling63
I0808 13:44:08.715868 20451 net.cpp:425] Pooling63 <- Convolution63
I0808 13:44:08.715883 20451 net.cpp:399] Pooling63 -> Pooling63
I0808 13:44:08.715939 20451 net.cpp:141] Setting up Pooling63
I0808 13:44:08.715947 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.715953 20451 net.cpp:156] Memory required for data: 1226188288
I0808 13:44:08.715960 20451 layer_factory.hpp:77] Creating layer InnerProduct61
I0808 13:44:08.715972 20451 net.cpp:91] Creating Layer InnerProduct61
I0808 13:44:08.715979 20451 net.cpp:425] InnerProduct61 <- Pooling63
I0808 13:44:08.716006 20451 net.cpp:399] InnerProduct61 -> InnerProduct61
I0808 13:44:08.744369 20451 net.cpp:141] Setting up InnerProduct61
I0808 13:44:08.744395 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.744406 20451 net.cpp:156] Memory required for data: 1226213888
I0808 13:44:08.744421 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.744436 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.744447 20451 layer_factory.hpp:77] Creating layer ReLU41
I0808 13:44:08.744465 20451 net.cpp:91] Creating Layer ReLU41
I0808 13:44:08.744475 20451 net.cpp:425] ReLU41 <- InnerProduct61
I0808 13:44:08.744488 20451 net.cpp:386] ReLU41 -> InnerProduct61 (in-place)
I0808 13:44:08.744504 20451 net.cpp:141] Setting up ReLU41
I0808 13:44:08.744515 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.744524 20451 net.cpp:156] Memory required for data: 1226239488
I0808 13:44:08.744531 20451 layer_factory.hpp:77] Creating layer InnerProduct62
I0808 13:44:08.744549 20451 net.cpp:91] Creating Layer InnerProduct62
I0808 13:44:08.744559 20451 net.cpp:425] InnerProduct62 <- InnerProduct61
I0808 13:44:08.744575 20451 net.cpp:399] InnerProduct62 -> InnerProduct62
I0808 13:44:08.744859 20451 net.cpp:141] Setting up InnerProduct62
I0808 13:44:08.744874 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.744881 20451 net.cpp:156] Memory required for data: 1226252288
I0808 13:44:08.744890 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.744901 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.744910 20451 layer_factory.hpp:77] Creating layer Convolution64
I0808 13:44:08.744935 20451 net.cpp:91] Creating Layer Convolution64
I0808 13:44:08.744948 20451 net.cpp:425] Convolution64 <- c11
I0808 13:44:08.744976 20451 net.cpp:399] Convolution64 -> Convolution64
I0808 13:44:08.745515 20451 net.cpp:141] Setting up Convolution64
I0808 13:44:08.745528 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.745537 20451 net.cpp:156] Memory required for data: 1244684288
I0808 13:44:08.745546 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.745556 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.745565 20451 layer_factory.hpp:77] Creating layer Pooling64
I0808 13:44:08.745580 20451 net.cpp:91] Creating Layer Pooling64
I0808 13:44:08.745589 20451 net.cpp:425] Pooling64 <- Convolution64
I0808 13:44:08.745606 20451 net.cpp:399] Pooling64 -> Pooling64
I0808 13:44:08.745681 20451 net.cpp:141] Setting up Pooling64
I0808 13:44:08.745692 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.745700 20451 net.cpp:156] Memory required for data: 1249292288
I0808 13:44:08.745708 20451 layer_factory.hpp:77] Creating layer Convolution65
I0808 13:44:08.745729 20451 net.cpp:91] Creating Layer Convolution65
I0808 13:44:08.745738 20451 net.cpp:425] Convolution65 <- Pooling64
I0808 13:44:08.745754 20451 net.cpp:399] Convolution65 -> Convolution65
I0808 13:44:08.746533 20451 net.cpp:141] Setting up Convolution65
I0808 13:44:08.746546 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.746552 20451 net.cpp:156] Memory required for data: 1257945088
I0808 13:44:08.746562 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.746572 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.746580 20451 layer_factory.hpp:77] Creating layer Pooling65
I0808 13:44:08.746592 20451 net.cpp:91] Creating Layer Pooling65
I0808 13:44:08.746601 20451 net.cpp:425] Pooling65 <- Convolution65
I0808 13:44:08.746614 20451 net.cpp:399] Pooling65 -> Pooling65
I0808 13:44:08.746688 20451 net.cpp:141] Setting up Pooling65
I0808 13:44:08.746700 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.746726 20451 net.cpp:156] Memory required for data: 1260108288
I0808 13:44:08.746736 20451 layer_factory.hpp:77] Creating layer Convolution66
I0808 13:44:08.746753 20451 net.cpp:91] Creating Layer Convolution66
I0808 13:44:08.746763 20451 net.cpp:425] Convolution66 <- Pooling65
I0808 13:44:08.746780 20451 net.cpp:399] Convolution66 -> Convolution66
I0808 13:44:08.748028 20451 net.cpp:141] Setting up Convolution66
I0808 13:44:08.748045 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.748054 20451 net.cpp:156] Memory required for data: 1261145088
I0808 13:44:08.748064 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.748075 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.748085 20451 layer_factory.hpp:77] Creating layer Pooling66
I0808 13:44:08.748100 20451 net.cpp:91] Creating Layer Pooling66
I0808 13:44:08.748109 20451 net.cpp:425] Pooling66 <- Convolution66
I0808 13:44:08.748123 20451 net.cpp:399] Pooling66 -> Pooling66
I0808 13:44:08.748201 20451 net.cpp:141] Setting up Pooling66
I0808 13:44:08.748214 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.748221 20451 net.cpp:156] Memory required for data: 1261465088
I0808 13:44:08.748229 20451 layer_factory.hpp:77] Creating layer InnerProduct63
I0808 13:44:08.748244 20451 net.cpp:91] Creating Layer InnerProduct63
I0808 13:44:08.748252 20451 net.cpp:425] InnerProduct63 <- Pooling66
I0808 13:44:08.748270 20451 net.cpp:399] InnerProduct63 -> InnerProduct63
I0808 13:44:08.750691 20451 net.cpp:141] Setting up InnerProduct63
I0808 13:44:08.750710 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.750718 20451 net.cpp:156] Memory required for data: 1261490688
I0808 13:44:08.750728 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.750740 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.750748 20451 layer_factory.hpp:77] Creating layer ReLU42
I0808 13:44:08.750761 20451 net.cpp:91] Creating Layer ReLU42
I0808 13:44:08.750771 20451 net.cpp:425] ReLU42 <- InnerProduct63
I0808 13:44:08.750783 20451 net.cpp:386] ReLU42 -> InnerProduct63 (in-place)
I0808 13:44:08.750798 20451 net.cpp:141] Setting up ReLU42
I0808 13:44:08.750809 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.750818 20451 net.cpp:156] Memory required for data: 1261516288
I0808 13:44:08.750825 20451 layer_factory.hpp:77] Creating layer InnerProduct64
I0808 13:44:08.750843 20451 net.cpp:91] Creating Layer InnerProduct64
I0808 13:44:08.750851 20451 net.cpp:425] InnerProduct64 <- InnerProduct63
I0808 13:44:08.750886 20451 net.cpp:399] InnerProduct64 -> InnerProduct64
I0808 13:44:08.751159 20451 net.cpp:141] Setting up InnerProduct64
I0808 13:44:08.751171 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.751179 20451 net.cpp:156] Memory required for data: 1261529088
I0808 13:44:08.751188 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.751199 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.751206 20451 layer_factory.hpp:77] Creating layer Concat11
I0808 13:44:08.751219 20451 net.cpp:91] Creating Layer Concat11
I0808 13:44:08.751229 20451 net.cpp:425] Concat11 <- InnerProduct62
I0808 13:44:08.751240 20451 net.cpp:425] Concat11 <- InnerProduct64
I0808 13:44:08.751253 20451 net.cpp:399] Concat11 -> Concat11
I0808 13:44:08.751308 20451 net.cpp:141] Setting up Concat11
I0808 13:44:08.751320 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.751328 20451 net.cpp:156] Memory required for data: 1261554688
I0808 13:44:08.751337 20451 layer_factory.hpp:77] Creating layer InnerProduct65
I0808 13:44:08.751353 20451 net.cpp:91] Creating Layer InnerProduct65
I0808 13:44:08.751361 20451 net.cpp:425] InnerProduct65 <- Concat11
I0808 13:44:08.751375 20451 net.cpp:399] InnerProduct65 -> InnerProduct65
I0808 13:44:08.751659 20451 net.cpp:141] Setting up InnerProduct65
I0808 13:44:08.751699 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.751708 20451 net.cpp:156] Memory required for data: 1261571072
I0808 13:44:08.751716 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.751727 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.751736 20451 layer_factory.hpp:77] Creating layer ReLU43
I0808 13:44:08.751747 20451 net.cpp:91] Creating Layer ReLU43
I0808 13:44:08.751756 20451 net.cpp:425] ReLU43 <- InnerProduct65
I0808 13:44:08.751771 20451 net.cpp:386] ReLU43 -> InnerProduct65 (in-place)
I0808 13:44:08.751785 20451 net.cpp:141] Setting up ReLU43
I0808 13:44:08.751796 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.751804 20451 net.cpp:156] Memory required for data: 1261587456
I0808 13:44:08.751812 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.751827 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.751835 20451 net.cpp:425] drop1 <- InnerProduct65
I0808 13:44:08.751852 20451 net.cpp:399] drop1 -> Dropout21
I0808 13:44:08.751924 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.751935 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.751943 20451 net.cpp:156] Memory required for data: 1261603840
I0808 13:44:08.751951 20451 layer_factory.hpp:77] Creating layer InnerProduct66
I0808 13:44:08.751966 20451 net.cpp:91] Creating Layer InnerProduct66
I0808 13:44:08.751976 20451 net.cpp:425] InnerProduct66 <- Dropout21
I0808 13:44:08.751989 20451 net.cpp:399] InnerProduct66 -> InnerProduct66
I0808 13:44:08.752327 20451 net.cpp:141] Setting up InnerProduct66
I0808 13:44:08.752341 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.752348 20451 net.cpp:156] Memory required for data: 1261612032
I0808 13:44:08.752357 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.752368 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.752377 20451 layer_factory.hpp:77] Creating layer ReLU44
I0808 13:44:08.752391 20451 net.cpp:91] Creating Layer ReLU44
I0808 13:44:08.752400 20451 net.cpp:425] ReLU44 <- InnerProduct66
I0808 13:44:08.752413 20451 net.cpp:386] ReLU44 -> InnerProduct66 (in-place)
I0808 13:44:08.752429 20451 net.cpp:141] Setting up ReLU44
I0808 13:44:08.752439 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.752447 20451 net.cpp:156] Memory required for data: 1261620224
I0808 13:44:08.752455 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.752466 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.752475 20451 net.cpp:425] drop2 <- InnerProduct66
I0808 13:44:08.752491 20451 net.cpp:399] drop2 -> Dropout22
I0808 13:44:08.752563 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.752574 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.752583 20451 net.cpp:156] Memory required for data: 1261628416
I0808 13:44:08.752591 20451 layer_factory.hpp:77] Creating layer dt10
I0808 13:44:08.752604 20451 net.cpp:91] Creating Layer dt10
I0808 13:44:08.752612 20451 net.cpp:425] dt10 <- Dropout22
I0808 13:44:08.752643 20451 net.cpp:399] dt10 -> dt10
I0808 13:44:08.752854 20451 net.cpp:141] Setting up dt10
I0808 13:44:08.752866 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.752874 20451 net.cpp:156] Memory required for data: 1261628672
I0808 13:44:08.752883 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.752894 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.752903 20451 layer_factory.hpp:77] Creating layer Convolution67
I0808 13:44:08.752925 20451 net.cpp:91] Creating Layer Convolution67
I0808 13:44:08.752938 20451 net.cpp:425] Convolution67 <- p2_p2_0_split_2
I0808 13:44:08.752954 20451 net.cpp:399] Convolution67 -> Convolution67
I0808 13:44:08.753458 20451 net.cpp:141] Setting up Convolution67
I0808 13:44:08.753470 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.753492 20451 net.cpp:156] Memory required for data: 1280060672
I0808 13:44:08.753501 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.753511 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.753520 20451 layer_factory.hpp:77] Creating layer Pooling67
I0808 13:44:08.753536 20451 net.cpp:91] Creating Layer Pooling67
I0808 13:44:08.753545 20451 net.cpp:425] Pooling67 <- Convolution67
I0808 13:44:08.753559 20451 net.cpp:399] Pooling67 -> Pooling67
I0808 13:44:08.753635 20451 net.cpp:141] Setting up Pooling67
I0808 13:44:08.753648 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.753655 20451 net.cpp:156] Memory required for data: 1284668672
I0808 13:44:08.753664 20451 layer_factory.hpp:77] Creating layer Convolution68
I0808 13:44:08.753682 20451 net.cpp:91] Creating Layer Convolution68
I0808 13:44:08.753692 20451 net.cpp:425] Convolution68 <- Pooling67
I0808 13:44:08.753710 20451 net.cpp:399] Convolution68 -> Convolution68
I0808 13:44:08.755314 20451 net.cpp:141] Setting up Convolution68
I0808 13:44:08.755336 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.755345 20451 net.cpp:156] Memory required for data: 1293321472
I0808 13:44:08.755355 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.755365 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.755374 20451 layer_factory.hpp:77] Creating layer Pooling68
I0808 13:44:08.755393 20451 net.cpp:91] Creating Layer Pooling68
I0808 13:44:08.755399 20451 net.cpp:425] Pooling68 <- Convolution68
I0808 13:44:08.755409 20451 net.cpp:399] Pooling68 -> Pooling68
I0808 13:44:08.755461 20451 net.cpp:141] Setting up Pooling68
I0808 13:44:08.755470 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.755475 20451 net.cpp:156] Memory required for data: 1295484672
I0808 13:44:08.755480 20451 layer_factory.hpp:77] Creating layer Convolution69
I0808 13:44:08.755492 20451 net.cpp:91] Creating Layer Convolution69
I0808 13:44:08.755498 20451 net.cpp:425] Convolution69 <- Pooling68
I0808 13:44:08.755511 20451 net.cpp:399] Convolution69 -> Convolution69
I0808 13:44:08.756305 20451 net.cpp:141] Setting up Convolution69
I0808 13:44:08.756314 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.756319 20451 net.cpp:156] Memory required for data: 1296521472
I0808 13:44:08.756325 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.756331 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.756337 20451 layer_factory.hpp:77] Creating layer Pooling69
I0808 13:44:08.756345 20451 net.cpp:91] Creating Layer Pooling69
I0808 13:44:08.756350 20451 net.cpp:425] Pooling69 <- Convolution69
I0808 13:44:08.756361 20451 net.cpp:399] Pooling69 -> Pooling69
I0808 13:44:08.756412 20451 net.cpp:141] Setting up Pooling69
I0808 13:44:08.756422 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.756427 20451 net.cpp:156] Memory required for data: 1296841472
I0808 13:44:08.756431 20451 layer_factory.hpp:77] Creating layer InnerProduct67
I0808 13:44:08.756440 20451 net.cpp:91] Creating Layer InnerProduct67
I0808 13:44:08.756446 20451 net.cpp:425] InnerProduct67 <- Pooling69
I0808 13:44:08.756461 20451 net.cpp:399] InnerProduct67 -> InnerProduct67
I0808 13:44:08.757539 20451 net.cpp:141] Setting up InnerProduct67
I0808 13:44:08.757547 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.757552 20451 net.cpp:156] Memory required for data: 1296867072
I0808 13:44:08.757558 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.757565 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.757571 20451 layer_factory.hpp:77] Creating layer ReLU45
I0808 13:44:08.775516 20451 net.cpp:91] Creating Layer ReLU45
I0808 13:44:08.775575 20451 net.cpp:425] ReLU45 <- InnerProduct67
I0808 13:44:08.775601 20451 net.cpp:386] ReLU45 -> InnerProduct67 (in-place)
I0808 13:44:08.775635 20451 net.cpp:141] Setting up ReLU45
I0808 13:44:08.775660 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.775676 20451 net.cpp:156] Memory required for data: 1296892672
I0808 13:44:08.775693 20451 layer_factory.hpp:77] Creating layer InnerProduct68
I0808 13:44:08.775727 20451 net.cpp:91] Creating Layer InnerProduct68
I0808 13:44:08.775743 20451 net.cpp:425] InnerProduct68 <- InnerProduct67
I0808 13:44:08.775770 20451 net.cpp:399] InnerProduct68 -> InnerProduct68
I0808 13:44:08.776278 20451 net.cpp:141] Setting up InnerProduct68
I0808 13:44:08.776298 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.776309 20451 net.cpp:156] Memory required for data: 1296905472
I0808 13:44:08.776324 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.776340 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.776352 20451 layer_factory.hpp:77] Creating layer Convolution70
I0808 13:44:08.776382 20451 net.cpp:91] Creating Layer Convolution70
I0808 13:44:08.776396 20451 net.cpp:425] Convolution70 <- c12
I0808 13:44:08.776420 20451 net.cpp:399] Convolution70 -> Convolution70
I0808 13:44:08.777204 20451 net.cpp:141] Setting up Convolution70
I0808 13:44:08.777221 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.777233 20451 net.cpp:156] Memory required for data: 1315337472
I0808 13:44:08.777246 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.777261 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.777274 20451 layer_factory.hpp:77] Creating layer Pooling70
I0808 13:44:08.777292 20451 net.cpp:91] Creating Layer Pooling70
I0808 13:44:08.777305 20451 net.cpp:425] Pooling70 <- Convolution70
I0808 13:44:08.777330 20451 net.cpp:399] Pooling70 -> Pooling70
I0808 13:44:08.777439 20451 net.cpp:141] Setting up Pooling70
I0808 13:44:08.777463 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.777475 20451 net.cpp:156] Memory required for data: 1319945472
I0808 13:44:08.777487 20451 layer_factory.hpp:77] Creating layer Convolution71
I0808 13:44:08.777509 20451 net.cpp:91] Creating Layer Convolution71
I0808 13:44:08.777523 20451 net.cpp:425] Convolution71 <- Pooling70
I0808 13:44:08.777549 20451 net.cpp:399] Convolution71 -> Convolution71
I0808 13:44:08.778700 20451 net.cpp:141] Setting up Convolution71
I0808 13:44:08.778718 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.778729 20451 net.cpp:156] Memory required for data: 1328598272
I0808 13:44:08.778743 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.778759 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.778771 20451 layer_factory.hpp:77] Creating layer Pooling71
I0808 13:44:08.778792 20451 net.cpp:91] Creating Layer Pooling71
I0808 13:44:08.778806 20451 net.cpp:425] Pooling71 <- Convolution71
I0808 13:44:08.778826 20451 net.cpp:399] Pooling71 -> Pooling71
I0808 13:44:08.778936 20451 net.cpp:141] Setting up Pooling71
I0808 13:44:08.778954 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.778964 20451 net.cpp:156] Memory required for data: 1330761472
I0808 13:44:08.778976 20451 layer_factory.hpp:77] Creating layer Convolution72
I0808 13:44:08.779003 20451 net.cpp:91] Creating Layer Convolution72
I0808 13:44:08.779017 20451 net.cpp:425] Convolution72 <- Pooling71
I0808 13:44:08.779042 20451 net.cpp:399] Convolution72 -> Convolution72
I0808 13:44:08.780169 20451 net.cpp:141] Setting up Convolution72
I0808 13:44:08.780179 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.780184 20451 net.cpp:156] Memory required for data: 1331798272
I0808 13:44:08.780192 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.780212 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.780220 20451 layer_factory.hpp:77] Creating layer Pooling72
I0808 13:44:08.780228 20451 net.cpp:91] Creating Layer Pooling72
I0808 13:44:08.780236 20451 net.cpp:425] Pooling72 <- Convolution72
I0808 13:44:08.780251 20451 net.cpp:399] Pooling72 -> Pooling72
I0808 13:44:08.780309 20451 net.cpp:141] Setting up Pooling72
I0808 13:44:08.780318 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.780324 20451 net.cpp:156] Memory required for data: 1332118272
I0808 13:44:08.780330 20451 layer_factory.hpp:77] Creating layer InnerProduct69
I0808 13:44:08.780344 20451 net.cpp:91] Creating Layer InnerProduct69
I0808 13:44:08.780350 20451 net.cpp:425] InnerProduct69 <- Pooling72
I0808 13:44:08.780364 20451 net.cpp:399] InnerProduct69 -> InnerProduct69
I0808 13:44:08.782285 20451 net.cpp:141] Setting up InnerProduct69
I0808 13:44:08.782300 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.782307 20451 net.cpp:156] Memory required for data: 1332143872
I0808 13:44:08.782316 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.782325 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.782331 20451 layer_factory.hpp:77] Creating layer ReLU46
I0808 13:44:08.782343 20451 net.cpp:91] Creating Layer ReLU46
I0808 13:44:08.782351 20451 net.cpp:425] ReLU46 <- InnerProduct69
I0808 13:44:08.782361 20451 net.cpp:386] ReLU46 -> InnerProduct69 (in-place)
I0808 13:44:08.782372 20451 net.cpp:141] Setting up ReLU46
I0808 13:44:08.782382 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.782387 20451 net.cpp:156] Memory required for data: 1332169472
I0808 13:44:08.782393 20451 layer_factory.hpp:77] Creating layer InnerProduct70
I0808 13:44:08.782407 20451 net.cpp:91] Creating Layer InnerProduct70
I0808 13:44:08.782413 20451 net.cpp:425] InnerProduct70 <- InnerProduct69
I0808 13:44:08.782424 20451 net.cpp:399] InnerProduct70 -> InnerProduct70
I0808 13:44:08.782635 20451 net.cpp:141] Setting up InnerProduct70
I0808 13:44:08.782644 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.782650 20451 net.cpp:156] Memory required for data: 1332182272
I0808 13:44:08.782657 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.782665 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.782672 20451 layer_factory.hpp:77] Creating layer Concat12
I0808 13:44:08.782681 20451 net.cpp:91] Creating Layer Concat12
I0808 13:44:08.782688 20451 net.cpp:425] Concat12 <- InnerProduct68
I0808 13:44:08.782697 20451 net.cpp:425] Concat12 <- InnerProduct70
I0808 13:44:08.782712 20451 net.cpp:399] Concat12 -> Concat12
I0808 13:44:08.782745 20451 net.cpp:141] Setting up Concat12
I0808 13:44:08.782757 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.782763 20451 net.cpp:156] Memory required for data: 1332207872
I0808 13:44:08.782768 20451 layer_factory.hpp:77] Creating layer InnerProduct71
I0808 13:44:08.782778 20451 net.cpp:91] Creating Layer InnerProduct71
I0808 13:44:08.782785 20451 net.cpp:425] InnerProduct71 <- Concat12
I0808 13:44:08.782798 20451 net.cpp:399] InnerProduct71 -> InnerProduct71
I0808 13:44:08.783018 20451 net.cpp:141] Setting up InnerProduct71
I0808 13:44:08.783026 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.783032 20451 net.cpp:156] Memory required for data: 1332224256
I0808 13:44:08.783041 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.783047 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.783054 20451 layer_factory.hpp:77] Creating layer ReLU47
I0808 13:44:08.783063 20451 net.cpp:91] Creating Layer ReLU47
I0808 13:44:08.805354 20451 net.cpp:425] ReLU47 <- InnerProduct71
I0808 13:44:08.805380 20451 net.cpp:386] ReLU47 -> InnerProduct71 (in-place)
I0808 13:44:08.805414 20451 net.cpp:141] Setting up ReLU47
I0808 13:44:08.805428 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.805435 20451 net.cpp:156] Memory required for data: 1332240640
I0808 13:44:08.805444 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.805457 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.805466 20451 net.cpp:425] drop1 <- InnerProduct71
I0808 13:44:08.805480 20451 net.cpp:399] drop1 -> Dropout23
I0808 13:44:08.805575 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.805586 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.805594 20451 net.cpp:156] Memory required for data: 1332257024
I0808 13:44:08.805603 20451 layer_factory.hpp:77] Creating layer InnerProduct72
I0808 13:44:08.805616 20451 net.cpp:91] Creating Layer InnerProduct72
I0808 13:44:08.805625 20451 net.cpp:425] InnerProduct72 <- Dropout23
I0808 13:44:08.805642 20451 net.cpp:399] InnerProduct72 -> InnerProduct72
I0808 13:44:08.805877 20451 net.cpp:141] Setting up InnerProduct72
I0808 13:44:08.805889 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.805897 20451 net.cpp:156] Memory required for data: 1332265216
I0808 13:44:08.805907 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.805917 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.805927 20451 layer_factory.hpp:77] Creating layer ReLU48
I0808 13:44:08.805938 20451 net.cpp:91] Creating Layer ReLU48
I0808 13:44:08.805946 20451 net.cpp:425] ReLU48 <- InnerProduct72
I0808 13:44:08.805961 20451 net.cpp:386] ReLU48 -> InnerProduct72 (in-place)
I0808 13:44:08.805976 20451 net.cpp:141] Setting up ReLU48
I0808 13:44:08.805989 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.805997 20451 net.cpp:156] Memory required for data: 1332273408
I0808 13:44:08.806005 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.806018 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.806026 20451 net.cpp:425] drop2 <- InnerProduct72
I0808 13:44:08.806046 20451 net.cpp:399] drop2 -> Dropout24
I0808 13:44:08.806113 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.806123 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.806129 20451 net.cpp:156] Memory required for data: 1332281600
I0808 13:44:08.806135 20451 layer_factory.hpp:77] Creating layer dt11
I0808 13:44:08.806149 20451 net.cpp:91] Creating Layer dt11
I0808 13:44:08.806154 20451 net.cpp:425] dt11 <- Dropout24
I0808 13:44:08.806166 20451 net.cpp:399] dt11 -> dt11
I0808 13:44:08.806325 20451 net.cpp:141] Setting up dt11
I0808 13:44:08.806336 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.806342 20451 net.cpp:156] Memory required for data: 1332281856
I0808 13:44:08.806349 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.806357 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.806365 20451 layer_factory.hpp:77] Creating layer Convolution73
I0808 13:44:08.806377 20451 net.cpp:91] Creating Layer Convolution73
I0808 13:44:08.806385 20451 net.cpp:425] Convolution73 <- p2_p2_0_split_3
I0808 13:44:08.806399 20451 net.cpp:399] Convolution73 -> Convolution73
I0808 13:44:08.806800 20451 net.cpp:141] Setting up Convolution73
I0808 13:44:08.806809 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.806816 20451 net.cpp:156] Memory required for data: 1350713856
I0808 13:44:08.806823 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.806831 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.806838 20451 layer_factory.hpp:77] Creating layer Pooling73
I0808 13:44:08.806848 20451 net.cpp:91] Creating Layer Pooling73
I0808 13:44:08.806854 20451 net.cpp:425] Pooling73 <- Convolution73
I0808 13:44:08.806871 20451 net.cpp:399] Pooling73 -> Pooling73
I0808 13:44:08.806929 20451 net.cpp:141] Setting up Pooling73
I0808 13:44:08.806948 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.806954 20451 net.cpp:156] Memory required for data: 1355321856
I0808 13:44:08.806960 20451 layer_factory.hpp:77] Creating layer Convolution74
I0808 13:44:08.806977 20451 net.cpp:91] Creating Layer Convolution74
I0808 13:44:08.806984 20451 net.cpp:425] Convolution74 <- Pooling73
I0808 13:44:08.806995 20451 net.cpp:399] Convolution74 -> Convolution74
I0808 13:44:08.807613 20451 net.cpp:141] Setting up Convolution74
I0808 13:44:08.807626 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.807632 20451 net.cpp:156] Memory required for data: 1363974656
I0808 13:44:08.807639 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.807647 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.807654 20451 layer_factory.hpp:77] Creating layer Pooling74
I0808 13:44:08.807663 20451 net.cpp:91] Creating Layer Pooling74
I0808 13:44:08.807670 20451 net.cpp:425] Pooling74 <- Convolution74
I0808 13:44:08.807680 20451 net.cpp:399] Pooling74 -> Pooling74
I0808 13:44:08.807736 20451 net.cpp:141] Setting up Pooling74
I0808 13:44:08.807745 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.807751 20451 net.cpp:156] Memory required for data: 1366137856
I0808 13:44:08.807757 20451 layer_factory.hpp:77] Creating layer Convolution75
I0808 13:44:08.807772 20451 net.cpp:91] Creating Layer Convolution75
I0808 13:44:08.807780 20451 net.cpp:425] Convolution75 <- Pooling74
I0808 13:44:08.807792 20451 net.cpp:399] Convolution75 -> Convolution75
I0808 13:44:08.809393 20451 net.cpp:141] Setting up Convolution75
I0808 13:44:08.809406 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.809413 20451 net.cpp:156] Memory required for data: 1367174656
I0808 13:44:08.809422 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.809429 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.809437 20451 layer_factory.hpp:77] Creating layer Pooling75
I0808 13:44:08.809447 20451 net.cpp:91] Creating Layer Pooling75
I0808 13:44:08.809454 20451 net.cpp:425] Pooling75 <- Convolution75
I0808 13:44:08.809464 20451 net.cpp:399] Pooling75 -> Pooling75
I0808 13:44:08.810148 20451 net.cpp:141] Setting up Pooling75
I0808 13:44:08.810160 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.810166 20451 net.cpp:156] Memory required for data: 1367494656
I0808 13:44:08.810173 20451 layer_factory.hpp:77] Creating layer InnerProduct73
I0808 13:44:08.810184 20451 net.cpp:91] Creating Layer InnerProduct73
I0808 13:44:08.810204 20451 net.cpp:425] InnerProduct73 <- Pooling75
I0808 13:44:08.810219 20451 net.cpp:399] InnerProduct73 -> InnerProduct73
I0808 13:44:08.811491 20451 net.cpp:141] Setting up InnerProduct73
I0808 13:44:08.811501 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.811507 20451 net.cpp:156] Memory required for data: 1367520256
I0808 13:44:08.811514 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.811522 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.811529 20451 layer_factory.hpp:77] Creating layer ReLU49
I0808 13:44:08.811538 20451 net.cpp:91] Creating Layer ReLU49
I0808 13:44:08.811545 20451 net.cpp:425] ReLU49 <- InnerProduct73
I0808 13:44:08.811558 20451 net.cpp:386] ReLU49 -> InnerProduct73 (in-place)
I0808 13:44:08.811568 20451 net.cpp:141] Setting up ReLU49
I0808 13:44:08.811576 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.811583 20451 net.cpp:156] Memory required for data: 1367545856
I0808 13:44:08.811589 20451 layer_factory.hpp:77] Creating layer InnerProduct74
I0808 13:44:08.811599 20451 net.cpp:91] Creating Layer InnerProduct74
I0808 13:44:08.811605 20451 net.cpp:425] InnerProduct74 <- InnerProduct73
I0808 13:44:08.811619 20451 net.cpp:399] InnerProduct74 -> InnerProduct74
I0808 13:44:08.811826 20451 net.cpp:141] Setting up InnerProduct74
I0808 13:44:08.811836 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.811841 20451 net.cpp:156] Memory required for data: 1367558656
I0808 13:44:08.811848 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.811857 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.811863 20451 layer_factory.hpp:77] Creating layer Convolution76
I0808 13:44:08.811877 20451 net.cpp:91] Creating Layer Convolution76
I0808 13:44:08.811883 20451 net.cpp:425] Convolution76 <- c13
I0808 13:44:08.811900 20451 net.cpp:399] Convolution76 -> Convolution76
I0808 13:44:08.812271 20451 net.cpp:141] Setting up Convolution76
I0808 13:44:08.812281 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.812288 20451 net.cpp:156] Memory required for data: 1385990656
I0808 13:44:08.812294 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.812301 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.812309 20451 layer_factory.hpp:77] Creating layer Pooling76
I0808 13:44:08.812320 20451 net.cpp:91] Creating Layer Pooling76
I0808 13:44:08.812327 20451 net.cpp:425] Pooling76 <- Convolution76
I0808 13:44:08.812337 20451 net.cpp:399] Pooling76 -> Pooling76
I0808 13:44:08.812391 20451 net.cpp:141] Setting up Pooling76
I0808 13:44:08.812398 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.812404 20451 net.cpp:156] Memory required for data: 1390598656
I0808 13:44:08.812412 20451 layer_factory.hpp:77] Creating layer Convolution77
I0808 13:44:08.812425 20451 net.cpp:91] Creating Layer Convolution77
I0808 13:44:08.812433 20451 net.cpp:425] Convolution77 <- Pooling76
I0808 13:44:08.812443 20451 net.cpp:399] Convolution77 -> Convolution77
I0808 13:44:08.813007 20451 net.cpp:141] Setting up Convolution77
I0808 13:44:08.813016 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.813022 20451 net.cpp:156] Memory required for data: 1399251456
I0808 13:44:08.813030 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.813037 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.813043 20451 layer_factory.hpp:77] Creating layer Pooling77
I0808 13:44:08.813052 20451 net.cpp:91] Creating Layer Pooling77
I0808 13:44:08.813060 20451 net.cpp:425] Pooling77 <- Convolution77
I0808 13:44:08.813069 20451 net.cpp:399] Pooling77 -> Pooling77
I0808 13:44:08.813122 20451 net.cpp:141] Setting up Pooling77
I0808 13:44:08.813130 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.813136 20451 net.cpp:156] Memory required for data: 1401414656
I0808 13:44:08.813143 20451 layer_factory.hpp:77] Creating layer Convolution78
I0808 13:44:08.813159 20451 net.cpp:91] Creating Layer Convolution78
I0808 13:44:08.813166 20451 net.cpp:425] Convolution78 <- Pooling77
I0808 13:44:08.813177 20451 net.cpp:399] Convolution78 -> Convolution78
I0808 13:44:08.814060 20451 net.cpp:141] Setting up Convolution78
I0808 13:44:08.814071 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.814077 20451 net.cpp:156] Memory required for data: 1402451456
I0808 13:44:08.814085 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.814091 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.814101 20451 layer_factory.hpp:77] Creating layer Pooling78
I0808 13:44:08.814117 20451 net.cpp:91] Creating Layer Pooling78
I0808 13:44:08.814126 20451 net.cpp:425] Pooling78 <- Convolution78
I0808 13:44:08.814141 20451 net.cpp:399] Pooling78 -> Pooling78
I0808 13:44:08.814204 20451 net.cpp:141] Setting up Pooling78
I0808 13:44:08.814214 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.814220 20451 net.cpp:156] Memory required for data: 1402771456
I0808 13:44:08.814239 20451 layer_factory.hpp:77] Creating layer InnerProduct75
I0808 13:44:08.814249 20451 net.cpp:91] Creating Layer InnerProduct75
I0808 13:44:08.814256 20451 net.cpp:425] InnerProduct75 <- Pooling78
I0808 13:44:08.814270 20451 net.cpp:399] InnerProduct75 -> InnerProduct75
I0808 13:44:08.816151 20451 net.cpp:141] Setting up InnerProduct75
I0808 13:44:08.816166 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.816172 20451 net.cpp:156] Memory required for data: 1402797056
I0808 13:44:08.816181 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.816190 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.816196 20451 layer_factory.hpp:77] Creating layer ReLU50
I0808 13:44:08.816206 20451 net.cpp:91] Creating Layer ReLU50
I0808 13:44:08.816213 20451 net.cpp:425] ReLU50 <- InnerProduct75
I0808 13:44:08.816223 20451 net.cpp:386] ReLU50 -> InnerProduct75 (in-place)
I0808 13:44:08.816234 20451 net.cpp:141] Setting up ReLU50
I0808 13:44:08.816242 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.816248 20451 net.cpp:156] Memory required for data: 1402822656
I0808 13:44:08.816254 20451 layer_factory.hpp:77] Creating layer InnerProduct76
I0808 13:44:08.816268 20451 net.cpp:91] Creating Layer InnerProduct76
I0808 13:44:08.816275 20451 net.cpp:425] InnerProduct76 <- InnerProduct75
I0808 13:44:08.816288 20451 net.cpp:399] InnerProduct76 -> InnerProduct76
I0808 13:44:08.816486 20451 net.cpp:141] Setting up InnerProduct76
I0808 13:44:08.816495 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.816501 20451 net.cpp:156] Memory required for data: 1402835456
I0808 13:44:08.816509 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.816516 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.816522 20451 layer_factory.hpp:77] Creating layer Concat13
I0808 13:44:08.816532 20451 net.cpp:91] Creating Layer Concat13
I0808 13:44:08.816540 20451 net.cpp:425] Concat13 <- InnerProduct74
I0808 13:44:08.816547 20451 net.cpp:425] Concat13 <- InnerProduct76
I0808 13:44:08.816558 20451 net.cpp:399] Concat13 -> Concat13
I0808 13:44:08.816592 20451 net.cpp:141] Setting up Concat13
I0808 13:44:08.816601 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.816607 20451 net.cpp:156] Memory required for data: 1402861056
I0808 13:44:08.816613 20451 layer_factory.hpp:77] Creating layer InnerProduct77
I0808 13:44:08.816625 20451 net.cpp:91] Creating Layer InnerProduct77
I0808 13:44:08.816632 20451 net.cpp:425] InnerProduct77 <- Concat13
I0808 13:44:08.816642 20451 net.cpp:399] InnerProduct77 -> InnerProduct77
I0808 13:44:08.816851 20451 net.cpp:141] Setting up InnerProduct77
I0808 13:44:08.816860 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.816866 20451 net.cpp:156] Memory required for data: 1402877440
I0808 13:44:08.816874 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.816881 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.816889 20451 layer_factory.hpp:77] Creating layer ReLU51
I0808 13:44:08.816896 20451 net.cpp:91] Creating Layer ReLU51
I0808 13:44:08.816902 20451 net.cpp:425] ReLU51 <- InnerProduct77
I0808 13:44:08.816915 20451 net.cpp:386] ReLU51 -> InnerProduct77 (in-place)
I0808 13:44:08.816925 20451 net.cpp:141] Setting up ReLU51
I0808 13:44:08.816932 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.816939 20451 net.cpp:156] Memory required for data: 1402893824
I0808 13:44:08.816946 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.816954 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.838440 20451 net.cpp:425] drop1 <- InnerProduct77
I0808 13:44:08.838490 20451 net.cpp:399] drop1 -> Dropout25
I0808 13:44:08.838635 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.838655 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.838668 20451 net.cpp:156] Memory required for data: 1402910208
I0808 13:44:08.838712 20451 layer_factory.hpp:77] Creating layer InnerProduct78
I0808 13:44:08.838739 20451 net.cpp:91] Creating Layer InnerProduct78
I0808 13:44:08.838753 20451 net.cpp:425] InnerProduct78 <- Dropout25
I0808 13:44:08.838774 20451 net.cpp:399] InnerProduct78 -> InnerProduct78
I0808 13:44:08.839133 20451 net.cpp:141] Setting up InnerProduct78
I0808 13:44:08.839149 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.839161 20451 net.cpp:156] Memory required for data: 1402918400
I0808 13:44:08.839176 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.839192 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.839205 20451 layer_factory.hpp:77] Creating layer ReLU52
I0808 13:44:08.839229 20451 net.cpp:91] Creating Layer ReLU52
I0808 13:44:08.839243 20451 net.cpp:425] ReLU52 <- InnerProduct78
I0808 13:44:08.839260 20451 net.cpp:386] ReLU52 -> InnerProduct78 (in-place)
I0808 13:44:08.839313 20451 net.cpp:141] Setting up ReLU52
I0808 13:44:08.839330 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.839342 20451 net.cpp:156] Memory required for data: 1402926592
I0808 13:44:08.839354 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.839376 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.839386 20451 net.cpp:425] drop2 <- InnerProduct78
I0808 13:44:08.839399 20451 net.cpp:399] drop2 -> Dropout26
I0808 13:44:08.839468 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.839480 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.839488 20451 net.cpp:156] Memory required for data: 1402934784
I0808 13:44:08.839496 20451 layer_factory.hpp:77] Creating layer dt12
I0808 13:44:08.839509 20451 net.cpp:91] Creating Layer dt12
I0808 13:44:08.839519 20451 net.cpp:425] dt12 <- Dropout26
I0808 13:44:08.839540 20451 net.cpp:399] dt12 -> dt12
I0808 13:44:08.839737 20451 net.cpp:141] Setting up dt12
I0808 13:44:08.839748 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.839756 20451 net.cpp:156] Memory required for data: 1402935040
I0808 13:44:08.839766 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.839776 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.839785 20451 layer_factory.hpp:77] Creating layer Convolution79
I0808 13:44:08.839807 20451 net.cpp:91] Creating Layer Convolution79
I0808 13:44:08.839815 20451 net.cpp:425] Convolution79 <- p2_p2_0_split_4
I0808 13:44:08.839833 20451 net.cpp:399] Convolution79 -> Convolution79
I0808 13:44:08.840329 20451 net.cpp:141] Setting up Convolution79
I0808 13:44:08.840348 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.840359 20451 net.cpp:156] Memory required for data: 1421367040
I0808 13:44:08.840374 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.840389 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.840399 20451 layer_factory.hpp:77] Creating layer Pooling79
I0808 13:44:08.840420 20451 net.cpp:91] Creating Layer Pooling79
I0808 13:44:08.840431 20451 net.cpp:425] Pooling79 <- Convolution79
I0808 13:44:08.840450 20451 net.cpp:399] Pooling79 -> Pooling79
I0808 13:44:08.840539 20451 net.cpp:141] Setting up Pooling79
I0808 13:44:08.840553 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.840560 20451 net.cpp:156] Memory required for data: 1425975040
I0808 13:44:08.840569 20451 layer_factory.hpp:77] Creating layer Convolution80
I0808 13:44:08.840589 20451 net.cpp:91] Creating Layer Convolution80
I0808 13:44:08.840597 20451 net.cpp:425] Convolution80 <- Pooling79
I0808 13:44:08.840616 20451 net.cpp:399] Convolution80 -> Convolution80
I0808 13:44:08.841389 20451 net.cpp:141] Setting up Convolution80
I0808 13:44:08.841405 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.841415 20451 net.cpp:156] Memory required for data: 1434627840
I0808 13:44:08.841447 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.841461 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.841473 20451 layer_factory.hpp:77] Creating layer Pooling80
I0808 13:44:08.841490 20451 net.cpp:91] Creating Layer Pooling80
I0808 13:44:08.841500 20451 net.cpp:425] Pooling80 <- Convolution80
I0808 13:44:08.841522 20451 net.cpp:399] Pooling80 -> Pooling80
I0808 13:44:08.841603 20451 net.cpp:141] Setting up Pooling80
I0808 13:44:08.841614 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.841624 20451 net.cpp:156] Memory required for data: 1436791040
I0808 13:44:08.841631 20451 layer_factory.hpp:77] Creating layer Convolution81
I0808 13:44:08.841651 20451 net.cpp:91] Creating Layer Convolution81
I0808 13:44:08.841660 20451 net.cpp:425] Convolution81 <- Pooling80
I0808 13:44:08.841678 20451 net.cpp:399] Convolution81 -> Convolution81
I0808 13:44:08.842928 20451 net.cpp:141] Setting up Convolution81
I0808 13:44:08.842946 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.842953 20451 net.cpp:156] Memory required for data: 1437827840
I0808 13:44:08.842963 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.842973 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.842983 20451 layer_factory.hpp:77] Creating layer Pooling81
I0808 13:44:08.842998 20451 net.cpp:91] Creating Layer Pooling81
I0808 13:44:08.843008 20451 net.cpp:425] Pooling81 <- Convolution81
I0808 13:44:08.843020 20451 net.cpp:399] Pooling81 -> Pooling81
I0808 13:44:08.843096 20451 net.cpp:141] Setting up Pooling81
I0808 13:44:08.843108 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.843116 20451 net.cpp:156] Memory required for data: 1438147840
I0808 13:44:08.843124 20451 layer_factory.hpp:77] Creating layer InnerProduct79
I0808 13:44:08.843143 20451 net.cpp:91] Creating Layer InnerProduct79
I0808 13:44:08.843152 20451 net.cpp:425] InnerProduct79 <- Pooling81
I0808 13:44:08.843166 20451 net.cpp:399] InnerProduct79 -> InnerProduct79
I0808 13:44:08.844832 20451 net.cpp:141] Setting up InnerProduct79
I0808 13:44:08.844846 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.844853 20451 net.cpp:156] Memory required for data: 1438173440
I0808 13:44:08.844863 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.844874 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.844882 20451 layer_factory.hpp:77] Creating layer ReLU53
I0808 13:44:08.844894 20451 net.cpp:91] Creating Layer ReLU53
I0808 13:44:08.844903 20451 net.cpp:425] ReLU53 <- InnerProduct79
I0808 13:44:08.844918 20451 net.cpp:386] ReLU53 -> InnerProduct79 (in-place)
I0808 13:44:08.844933 20451 net.cpp:141] Setting up ReLU53
I0808 13:44:08.844944 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.844951 20451 net.cpp:156] Memory required for data: 1438199040
I0808 13:44:08.844959 20451 layer_factory.hpp:77] Creating layer InnerProduct80
I0808 13:44:08.844975 20451 net.cpp:91] Creating Layer InnerProduct80
I0808 13:44:08.844985 20451 net.cpp:425] InnerProduct80 <- InnerProduct79
I0808 13:44:08.845000 20451 net.cpp:399] InnerProduct80 -> InnerProduct80
I0808 13:44:08.845250 20451 net.cpp:141] Setting up InnerProduct80
I0808 13:44:08.845263 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.845270 20451 net.cpp:156] Memory required for data: 1438211840
I0808 13:44:08.845279 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.867383 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.867413 20451 layer_factory.hpp:77] Creating layer Convolution82
I0808 13:44:08.867434 20451 net.cpp:91] Creating Layer Convolution82
I0808 13:44:08.867444 20451 net.cpp:425] Convolution82 <- c14
I0808 13:44:08.867491 20451 net.cpp:399] Convolution82 -> Convolution82
I0808 13:44:08.868042 20451 net.cpp:141] Setting up Convolution82
I0808 13:44:08.868057 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.868065 20451 net.cpp:156] Memory required for data: 1456643840
I0808 13:44:08.868075 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.868085 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.868094 20451 layer_factory.hpp:77] Creating layer Pooling82
I0808 13:44:08.868109 20451 net.cpp:91] Creating Layer Pooling82
I0808 13:44:08.868119 20451 net.cpp:425] Pooling82 <- Convolution82
I0808 13:44:08.868134 20451 net.cpp:399] Pooling82 -> Pooling82
I0808 13:44:08.868217 20451 net.cpp:141] Setting up Pooling82
I0808 13:44:08.868242 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.868250 20451 net.cpp:156] Memory required for data: 1461251840
I0808 13:44:08.868260 20451 layer_factory.hpp:77] Creating layer Convolution83
I0808 13:44:08.868288 20451 net.cpp:91] Creating Layer Convolution83
I0808 13:44:08.868299 20451 net.cpp:425] Convolution83 <- Pooling82
I0808 13:44:08.868321 20451 net.cpp:399] Convolution83 -> Convolution83
I0808 13:44:08.869213 20451 net.cpp:141] Setting up Convolution83
I0808 13:44:08.869236 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.869247 20451 net.cpp:156] Memory required for data: 1469904640
I0808 13:44:08.869261 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.869277 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.869288 20451 layer_factory.hpp:77] Creating layer Pooling83
I0808 13:44:08.869305 20451 net.cpp:91] Creating Layer Pooling83
I0808 13:44:08.869319 20451 net.cpp:425] Pooling83 <- Convolution83
I0808 13:44:08.869343 20451 net.cpp:399] Pooling83 -> Pooling83
I0808 13:44:08.869437 20451 net.cpp:141] Setting up Pooling83
I0808 13:44:08.869451 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.869458 20451 net.cpp:156] Memory required for data: 1472067840
I0808 13:44:08.869467 20451 layer_factory.hpp:77] Creating layer Convolution84
I0808 13:44:08.869493 20451 net.cpp:91] Creating Layer Convolution84
I0808 13:44:08.869501 20451 net.cpp:425] Convolution84 <- Pooling83
I0808 13:44:08.869516 20451 net.cpp:399] Convolution84 -> Convolution84
I0808 13:44:08.871811 20451 net.cpp:141] Setting up Convolution84
I0808 13:44:08.871834 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.871843 20451 net.cpp:156] Memory required for data: 1473104640
I0808 13:44:08.871855 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.871865 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.871876 20451 layer_factory.hpp:77] Creating layer Pooling84
I0808 13:44:08.871889 20451 net.cpp:91] Creating Layer Pooling84
I0808 13:44:08.871901 20451 net.cpp:425] Pooling84 <- Convolution84
I0808 13:44:08.871918 20451 net.cpp:399] Pooling84 -> Pooling84
I0808 13:44:08.871994 20451 net.cpp:141] Setting up Pooling84
I0808 13:44:08.872005 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.872016 20451 net.cpp:156] Memory required for data: 1473424640
I0808 13:44:08.872025 20451 layer_factory.hpp:77] Creating layer InnerProduct81
I0808 13:44:08.872041 20451 net.cpp:91] Creating Layer InnerProduct81
I0808 13:44:08.872051 20451 net.cpp:425] InnerProduct81 <- Pooling84
I0808 13:44:08.872072 20451 net.cpp:399] InnerProduct81 -> InnerProduct81
I0808 13:44:08.874455 20451 net.cpp:141] Setting up InnerProduct81
I0808 13:44:08.874472 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.874481 20451 net.cpp:156] Memory required for data: 1473450240
I0808 13:44:08.874491 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.874502 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.874533 20451 layer_factory.hpp:77] Creating layer ReLU54
I0808 13:44:08.874549 20451 net.cpp:91] Creating Layer ReLU54
I0808 13:44:08.874559 20451 net.cpp:425] ReLU54 <- InnerProduct81
I0808 13:44:08.874572 20451 net.cpp:386] ReLU54 -> InnerProduct81 (in-place)
I0808 13:44:08.874588 20451 net.cpp:141] Setting up ReLU54
I0808 13:44:08.874598 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.874606 20451 net.cpp:156] Memory required for data: 1473475840
I0808 13:44:08.874615 20451 layer_factory.hpp:77] Creating layer InnerProduct82
I0808 13:44:08.874634 20451 net.cpp:91] Creating Layer InnerProduct82
I0808 13:44:08.874644 20451 net.cpp:425] InnerProduct82 <- InnerProduct81
I0808 13:44:08.874657 20451 net.cpp:399] InnerProduct82 -> InnerProduct82
I0808 13:44:08.874927 20451 net.cpp:141] Setting up InnerProduct82
I0808 13:44:08.874939 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.874948 20451 net.cpp:156] Memory required for data: 1473488640
I0808 13:44:08.874956 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.874966 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.874974 20451 layer_factory.hpp:77] Creating layer Concat14
I0808 13:44:08.874987 20451 net.cpp:91] Creating Layer Concat14
I0808 13:44:08.874996 20451 net.cpp:425] Concat14 <- InnerProduct80
I0808 13:44:08.875008 20451 net.cpp:425] Concat14 <- InnerProduct82
I0808 13:44:08.875025 20451 net.cpp:399] Concat14 -> Concat14
I0808 13:44:08.875071 20451 net.cpp:141] Setting up Concat14
I0808 13:44:08.875082 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.875090 20451 net.cpp:156] Memory required for data: 1473514240
I0808 13:44:08.875098 20451 layer_factory.hpp:77] Creating layer InnerProduct83
I0808 13:44:08.875111 20451 net.cpp:91] Creating Layer InnerProduct83
I0808 13:44:08.875119 20451 net.cpp:425] InnerProduct83 <- Concat14
I0808 13:44:08.875138 20451 net.cpp:399] InnerProduct83 -> InnerProduct83
I0808 13:44:08.875442 20451 net.cpp:141] Setting up InnerProduct83
I0808 13:44:08.875450 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.875457 20451 net.cpp:156] Memory required for data: 1473530624
I0808 13:44:08.875463 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.875469 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.875475 20451 layer_factory.hpp:77] Creating layer ReLU55
I0808 13:44:08.875483 20451 net.cpp:91] Creating Layer ReLU55
I0808 13:44:08.875488 20451 net.cpp:425] ReLU55 <- InnerProduct83
I0808 13:44:08.875499 20451 net.cpp:386] ReLU55 -> InnerProduct83 (in-place)
I0808 13:44:08.875509 20451 net.cpp:141] Setting up ReLU55
I0808 13:44:08.875516 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.875521 20451 net.cpp:156] Memory required for data: 1473547008
I0808 13:44:08.875527 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.875535 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.875541 20451 net.cpp:425] drop1 <- InnerProduct83
I0808 13:44:08.875550 20451 net.cpp:399] drop1 -> Dropout27
I0808 13:44:08.875599 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.875607 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.875612 20451 net.cpp:156] Memory required for data: 1473563392
I0808 13:44:08.875617 20451 layer_factory.hpp:77] Creating layer InnerProduct84
I0808 13:44:08.875628 20451 net.cpp:91] Creating Layer InnerProduct84
I0808 13:44:08.892683 20451 net.cpp:425] InnerProduct84 <- Dropout27
I0808 13:44:08.892714 20451 net.cpp:399] InnerProduct84 -> InnerProduct84
I0808 13:44:08.892920 20451 net.cpp:141] Setting up InnerProduct84
I0808 13:44:08.892930 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.892935 20451 net.cpp:156] Memory required for data: 1473571584
I0808 13:44:08.892942 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.892966 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.892972 20451 layer_factory.hpp:77] Creating layer ReLU56
I0808 13:44:08.892983 20451 net.cpp:91] Creating Layer ReLU56
I0808 13:44:08.892989 20451 net.cpp:425] ReLU56 <- InnerProduct84
I0808 13:44:08.892997 20451 net.cpp:386] ReLU56 -> InnerProduct84 (in-place)
I0808 13:44:08.893007 20451 net.cpp:141] Setting up ReLU56
I0808 13:44:08.893015 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.893020 20451 net.cpp:156] Memory required for data: 1473579776
I0808 13:44:08.893026 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.893034 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.893040 20451 net.cpp:425] drop2 <- InnerProduct84
I0808 13:44:08.893051 20451 net.cpp:399] drop2 -> Dropout28
I0808 13:44:08.893100 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.893107 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.893113 20451 net.cpp:156] Memory required for data: 1473587968
I0808 13:44:08.893120 20451 layer_factory.hpp:77] Creating layer dt13
I0808 13:44:08.893131 20451 net.cpp:91] Creating Layer dt13
I0808 13:44:08.893136 20451 net.cpp:425] dt13 <- Dropout28
I0808 13:44:08.893147 20451 net.cpp:399] dt13 -> dt13
I0808 13:44:08.893281 20451 net.cpp:141] Setting up dt13
I0808 13:44:08.893291 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.893297 20451 net.cpp:156] Memory required for data: 1473588224
I0808 13:44:08.893303 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.893311 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.893316 20451 layer_factory.hpp:77] Creating layer Convolution85
I0808 13:44:08.893328 20451 net.cpp:91] Creating Layer Convolution85
I0808 13:44:08.893335 20451 net.cpp:425] Convolution85 <- p2_p2_0_split_5
I0808 13:44:08.893348 20451 net.cpp:399] Convolution85 -> Convolution85
I0808 13:44:08.893692 20451 net.cpp:141] Setting up Convolution85
I0808 13:44:08.893699 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.893705 20451 net.cpp:156] Memory required for data: 1492020224
I0808 13:44:08.893712 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.893718 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.893724 20451 layer_factory.hpp:77] Creating layer Pooling85
I0808 13:44:08.893733 20451 net.cpp:91] Creating Layer Pooling85
I0808 13:44:08.893738 20451 net.cpp:425] Pooling85 <- Convolution85
I0808 13:44:08.893754 20451 net.cpp:399] Pooling85 -> Pooling85
I0808 13:44:08.893803 20451 net.cpp:141] Setting up Pooling85
I0808 13:44:08.893810 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.893816 20451 net.cpp:156] Memory required for data: 1496628224
I0808 13:44:08.893821 20451 layer_factory.hpp:77] Creating layer Convolution86
I0808 13:44:08.893836 20451 net.cpp:91] Creating Layer Convolution86
I0808 13:44:08.893842 20451 net.cpp:425] Convolution86 <- Pooling85
I0808 13:44:08.893852 20451 net.cpp:399] Convolution86 -> Convolution86
I0808 13:44:08.894384 20451 net.cpp:141] Setting up Convolution86
I0808 13:44:08.894393 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.894398 20451 net.cpp:156] Memory required for data: 1505281024
I0808 13:44:08.894404 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.894412 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.894419 20451 layer_factory.hpp:77] Creating layer Pooling86
I0808 13:44:08.894428 20451 net.cpp:91] Creating Layer Pooling86
I0808 13:44:08.894433 20451 net.cpp:425] Pooling86 <- Convolution86
I0808 13:44:08.894443 20451 net.cpp:399] Pooling86 -> Pooling86
I0808 13:44:08.894491 20451 net.cpp:141] Setting up Pooling86
I0808 13:44:08.894500 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.894513 20451 net.cpp:156] Memory required for data: 1507444224
I0808 13:44:08.894520 20451 layer_factory.hpp:77] Creating layer Convolution87
I0808 13:44:08.894532 20451 net.cpp:91] Creating Layer Convolution87
I0808 13:44:08.894538 20451 net.cpp:425] Convolution87 <- Pooling86
I0808 13:44:08.894551 20451 net.cpp:399] Convolution87 -> Convolution87
I0808 13:44:08.895426 20451 net.cpp:141] Setting up Convolution87
I0808 13:44:08.895439 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.895447 20451 net.cpp:156] Memory required for data: 1508481024
I0808 13:44:08.895457 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.895467 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.895475 20451 layer_factory.hpp:77] Creating layer Pooling87
I0808 13:44:08.895490 20451 net.cpp:91] Creating Layer Pooling87
I0808 13:44:08.895499 20451 net.cpp:425] Pooling87 <- Convolution87
I0808 13:44:08.895512 20451 net.cpp:399] Pooling87 -> Pooling87
I0808 13:44:08.895588 20451 net.cpp:141] Setting up Pooling87
I0808 13:44:08.895599 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.895607 20451 net.cpp:156] Memory required for data: 1508801024
I0808 13:44:08.895615 20451 layer_factory.hpp:77] Creating layer InnerProduct85
I0808 13:44:08.895628 20451 net.cpp:91] Creating Layer InnerProduct85
I0808 13:44:08.895637 20451 net.cpp:425] InnerProduct85 <- Pooling87
I0808 13:44:08.895654 20451 net.cpp:399] InnerProduct85 -> InnerProduct85
I0808 13:44:08.897276 20451 net.cpp:141] Setting up InnerProduct85
I0808 13:44:08.897289 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.897297 20451 net.cpp:156] Memory required for data: 1508826624
I0808 13:44:08.897306 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.897316 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.897325 20451 layer_factory.hpp:77] Creating layer ReLU57
I0808 13:44:08.897336 20451 net.cpp:91] Creating Layer ReLU57
I0808 13:44:08.897346 20451 net.cpp:425] ReLU57 <- InnerProduct85
I0808 13:44:08.897361 20451 net.cpp:386] ReLU57 -> InnerProduct85 (in-place)
I0808 13:44:08.897374 20451 net.cpp:141] Setting up ReLU57
I0808 13:44:08.897385 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.897393 20451 net.cpp:156] Memory required for data: 1508852224
I0808 13:44:08.897402 20451 layer_factory.hpp:77] Creating layer InnerProduct86
I0808 13:44:08.897414 20451 net.cpp:91] Creating Layer InnerProduct86
I0808 13:44:08.897423 20451 net.cpp:425] InnerProduct86 <- InnerProduct85
I0808 13:44:08.897440 20451 net.cpp:399] InnerProduct86 -> InnerProduct86
I0808 13:44:08.897724 20451 net.cpp:141] Setting up InnerProduct86
I0808 13:44:08.897740 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.897749 20451 net.cpp:156] Memory required for data: 1508865024
I0808 13:44:08.897760 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.897771 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.897781 20451 layer_factory.hpp:77] Creating layer Convolution88
I0808 13:44:08.897802 20451 net.cpp:91] Creating Layer Convolution88
I0808 13:44:08.897814 20451 net.cpp:425] Convolution88 <- c15
I0808 13:44:08.897831 20451 net.cpp:399] Convolution88 -> Convolution88
I0808 13:44:08.898382 20451 net.cpp:141] Setting up Convolution88
I0808 13:44:08.899137 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.899147 20451 net.cpp:156] Memory required for data: 1527297024
I0808 13:44:08.899157 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.899168 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.899176 20451 layer_factory.hpp:77] Creating layer Pooling88
I0808 13:44:08.899194 20451 net.cpp:91] Creating Layer Pooling88
I0808 13:44:08.899221 20451 net.cpp:425] Pooling88 <- Convolution88
I0808 13:44:08.899235 20451 net.cpp:399] Pooling88 -> Pooling88
I0808 13:44:08.899338 20451 net.cpp:141] Setting up Pooling88
I0808 13:44:08.899350 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.899363 20451 net.cpp:156] Memory required for data: 1531905024
I0808 13:44:08.899370 20451 layer_factory.hpp:77] Creating layer Convolution89
I0808 13:44:08.899385 20451 net.cpp:91] Creating Layer Convolution89
I0808 13:44:08.899392 20451 net.cpp:425] Convolution89 <- Pooling88
I0808 13:44:08.899404 20451 net.cpp:399] Convolution89 -> Convolution89
I0808 13:44:08.900032 20451 net.cpp:141] Setting up Convolution89
I0808 13:44:08.900044 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.900053 20451 net.cpp:156] Memory required for data: 1540557824
I0808 13:44:08.900063 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.900071 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.900079 20451 layer_factory.hpp:77] Creating layer Pooling89
I0808 13:44:08.900090 20451 net.cpp:91] Creating Layer Pooling89
I0808 13:44:08.900101 20451 net.cpp:425] Pooling89 <- Convolution89
I0808 13:44:08.900118 20451 net.cpp:399] Pooling89 -> Pooling89
I0808 13:44:08.900183 20451 net.cpp:141] Setting up Pooling89
I0808 13:44:08.900193 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.900200 20451 net.cpp:156] Memory required for data: 1542721024
I0808 13:44:08.900207 20451 layer_factory.hpp:77] Creating layer Convolution90
I0808 13:44:08.900224 20451 net.cpp:91] Creating Layer Convolution90
I0808 13:44:08.900233 20451 net.cpp:425] Convolution90 <- Pooling89
I0808 13:44:08.900249 20451 net.cpp:399] Convolution90 -> Convolution90
I0808 13:44:08.901315 20451 net.cpp:141] Setting up Convolution90
I0808 13:44:08.901335 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.901342 20451 net.cpp:156] Memory required for data: 1543757824
I0808 13:44:08.901352 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.901362 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.901373 20451 layer_factory.hpp:77] Creating layer Pooling90
I0808 13:44:08.901387 20451 net.cpp:91] Creating Layer Pooling90
I0808 13:44:08.901397 20451 net.cpp:425] Pooling90 <- Convolution90
I0808 13:44:08.901418 20451 net.cpp:399] Pooling90 -> Pooling90
I0808 13:44:08.901492 20451 net.cpp:141] Setting up Pooling90
I0808 13:44:08.901504 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.901513 20451 net.cpp:156] Memory required for data: 1544077824
I0808 13:44:08.901521 20451 layer_factory.hpp:77] Creating layer InnerProduct87
I0808 13:44:08.901540 20451 net.cpp:91] Creating Layer InnerProduct87
I0808 13:44:08.901549 20451 net.cpp:425] InnerProduct87 <- Pooling90
I0808 13:44:08.901566 20451 net.cpp:399] InnerProduct87 -> InnerProduct87
I0808 13:44:08.903538 20451 net.cpp:141] Setting up InnerProduct87
I0808 13:44:08.903554 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.903561 20451 net.cpp:156] Memory required for data: 1544103424
I0808 13:44:08.903569 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.903578 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.903585 20451 layer_factory.hpp:77] Creating layer ReLU58
I0808 13:44:08.903599 20451 net.cpp:91] Creating Layer ReLU58
I0808 13:44:08.903606 20451 net.cpp:425] ReLU58 <- InnerProduct87
I0808 13:44:08.903615 20451 net.cpp:386] ReLU58 -> InnerProduct87 (in-place)
I0808 13:44:08.903627 20451 net.cpp:141] Setting up ReLU58
I0808 13:44:08.903636 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.903642 20451 net.cpp:156] Memory required for data: 1544129024
I0808 13:44:08.903648 20451 layer_factory.hpp:77] Creating layer InnerProduct88
I0808 13:44:08.903662 20451 net.cpp:91] Creating Layer InnerProduct88
I0808 13:44:08.903684 20451 net.cpp:425] InnerProduct88 <- InnerProduct87
I0808 13:44:08.903695 20451 net.cpp:399] InnerProduct88 -> InnerProduct88
I0808 13:44:08.903904 20451 net.cpp:141] Setting up InnerProduct88
I0808 13:44:08.903913 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.903919 20451 net.cpp:156] Memory required for data: 1544141824
I0808 13:44:08.903926 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.903934 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.903940 20451 layer_factory.hpp:77] Creating layer Concat15
I0808 13:44:08.903950 20451 net.cpp:91] Creating Layer Concat15
I0808 13:44:08.903957 20451 net.cpp:425] Concat15 <- InnerProduct86
I0808 13:44:08.903966 20451 net.cpp:425] Concat15 <- InnerProduct88
I0808 13:44:08.903980 20451 net.cpp:399] Concat15 -> Concat15
I0808 13:44:08.904016 20451 net.cpp:141] Setting up Concat15
I0808 13:44:08.904026 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.904031 20451 net.cpp:156] Memory required for data: 1544167424
I0808 13:44:08.904037 20451 layer_factory.hpp:77] Creating layer InnerProduct89
I0808 13:44:08.904047 20451 net.cpp:91] Creating Layer InnerProduct89
I0808 13:44:08.904053 20451 net.cpp:425] InnerProduct89 <- Concat15
I0808 13:44:08.904068 20451 net.cpp:399] InnerProduct89 -> InnerProduct89
I0808 13:44:08.904283 20451 net.cpp:141] Setting up InnerProduct89
I0808 13:44:08.904290 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.904296 20451 net.cpp:156] Memory required for data: 1544183808
I0808 13:44:08.904304 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.904311 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.904319 20451 layer_factory.hpp:77] Creating layer ReLU59
I0808 13:44:08.904326 20451 net.cpp:91] Creating Layer ReLU59
I0808 13:44:08.904333 20451 net.cpp:425] ReLU59 <- InnerProduct89
I0808 13:44:08.904347 20451 net.cpp:386] ReLU59 -> InnerProduct89 (in-place)
I0808 13:44:08.904358 20451 net.cpp:141] Setting up ReLU59
I0808 13:44:08.904366 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.904373 20451 net.cpp:156] Memory required for data: 1544200192
I0808 13:44:08.904379 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.904388 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.904395 20451 net.cpp:425] drop1 <- InnerProduct89
I0808 13:44:08.904405 20451 net.cpp:399] drop1 -> Dropout29
I0808 13:44:08.904462 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.904471 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.904477 20451 net.cpp:156] Memory required for data: 1544216576
I0808 13:44:08.904484 20451 layer_factory.hpp:77] Creating layer InnerProduct90
I0808 13:44:08.904495 20451 net.cpp:91] Creating Layer InnerProduct90
I0808 13:44:08.904502 20451 net.cpp:425] InnerProduct90 <- Dropout29
I0808 13:44:08.904515 20451 net.cpp:399] InnerProduct90 -> InnerProduct90
I0808 13:44:08.904687 20451 net.cpp:141] Setting up InnerProduct90
I0808 13:44:08.904696 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.904702 20451 net.cpp:156] Memory required for data: 1544224768
I0808 13:44:08.904709 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.928421 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.928437 20451 layer_factory.hpp:77] Creating layer ReLU60
I0808 13:44:08.928463 20451 net.cpp:91] Creating Layer ReLU60
I0808 13:44:08.928472 20451 net.cpp:425] ReLU60 <- InnerProduct90
I0808 13:44:08.928483 20451 net.cpp:386] ReLU60 -> InnerProduct90 (in-place)
I0808 13:44:08.928496 20451 net.cpp:141] Setting up ReLU60
I0808 13:44:08.928506 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.928513 20451 net.cpp:156] Memory required for data: 1544232960
I0808 13:44:08.928519 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.928545 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.928552 20451 net.cpp:425] drop2 <- InnerProduct90
I0808 13:44:08.928566 20451 net.cpp:399] drop2 -> Dropout30
I0808 13:44:08.928642 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.928652 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.928658 20451 net.cpp:156] Memory required for data: 1544241152
I0808 13:44:08.928663 20451 layer_factory.hpp:77] Creating layer dt14
I0808 13:44:08.928676 20451 net.cpp:91] Creating Layer dt14
I0808 13:44:08.928683 20451 net.cpp:425] dt14 <- Dropout30
I0808 13:44:08.928695 20451 net.cpp:399] dt14 -> dt14
I0808 13:44:08.928863 20451 net.cpp:141] Setting up dt14
I0808 13:44:08.928871 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.928877 20451 net.cpp:156] Memory required for data: 1544241408
I0808 13:44:08.928884 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.928892 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.928900 20451 layer_factory.hpp:77] Creating layer Convolution91
I0808 13:44:08.928916 20451 net.cpp:91] Creating Layer Convolution91
I0808 13:44:08.928925 20451 net.cpp:425] Convolution91 <- p2_p2_0_split_6
I0808 13:44:08.928937 20451 net.cpp:399] Convolution91 -> Convolution91
I0808 13:44:08.929343 20451 net.cpp:141] Setting up Convolution91
I0808 13:44:08.929352 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.929358 20451 net.cpp:156] Memory required for data: 1562673408
I0808 13:44:08.929365 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.929373 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.929380 20451 layer_factory.hpp:77] Creating layer Pooling91
I0808 13:44:08.929395 20451 net.cpp:91] Creating Layer Pooling91
I0808 13:44:08.929404 20451 net.cpp:425] Pooling91 <- Convolution91
I0808 13:44:08.929417 20451 net.cpp:399] Pooling91 -> Pooling91
I0808 13:44:08.929499 20451 net.cpp:141] Setting up Pooling91
I0808 13:44:08.929512 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.929522 20451 net.cpp:156] Memory required for data: 1567281408
I0808 13:44:08.929527 20451 layer_factory.hpp:77] Creating layer Convolution92
I0808 13:44:08.929543 20451 net.cpp:91] Creating Layer Convolution92
I0808 13:44:08.929550 20451 net.cpp:425] Convolution92 <- Pooling91
I0808 13:44:08.929561 20451 net.cpp:399] Convolution92 -> Convolution92
I0808 13:44:08.930184 20451 net.cpp:141] Setting up Convolution92
I0808 13:44:08.930196 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.930202 20451 net.cpp:156] Memory required for data: 1575934208
I0808 13:44:08.930208 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.930217 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.930223 20451 layer_factory.hpp:77] Creating layer Pooling92
I0808 13:44:08.930233 20451 net.cpp:91] Creating Layer Pooling92
I0808 13:44:08.930239 20451 net.cpp:425] Pooling92 <- Convolution92
I0808 13:44:08.930250 20451 net.cpp:399] Pooling92 -> Pooling92
I0808 13:44:08.930306 20451 net.cpp:141] Setting up Pooling92
I0808 13:44:08.930315 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.930321 20451 net.cpp:156] Memory required for data: 1578097408
I0808 13:44:08.930328 20451 layer_factory.hpp:77] Creating layer Convolution93
I0808 13:44:08.930343 20451 net.cpp:91] Creating Layer Convolution93
I0808 13:44:08.930349 20451 net.cpp:425] Convolution93 <- Pooling92
I0808 13:44:08.930363 20451 net.cpp:399] Convolution93 -> Convolution93
I0808 13:44:08.932020 20451 net.cpp:141] Setting up Convolution93
I0808 13:44:08.932036 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.932044 20451 net.cpp:156] Memory required for data: 1579134208
I0808 13:44:08.932051 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.932075 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.932082 20451 layer_factory.hpp:77] Creating layer Pooling93
I0808 13:44:08.932093 20451 net.cpp:91] Creating Layer Pooling93
I0808 13:44:08.932102 20451 net.cpp:425] Pooling93 <- Convolution93
I0808 13:44:08.932116 20451 net.cpp:399] Pooling93 -> Pooling93
I0808 13:44:08.932175 20451 net.cpp:141] Setting up Pooling93
I0808 13:44:08.932183 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.932189 20451 net.cpp:156] Memory required for data: 1579454208
I0808 13:44:08.932196 20451 layer_factory.hpp:77] Creating layer InnerProduct91
I0808 13:44:08.932209 20451 net.cpp:91] Creating Layer InnerProduct91
I0808 13:44:08.932216 20451 net.cpp:425] InnerProduct91 <- Pooling93
I0808 13:44:08.932230 20451 net.cpp:399] InnerProduct91 -> InnerProduct91
I0808 13:44:08.933497 20451 net.cpp:141] Setting up InnerProduct91
I0808 13:44:08.933506 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.933513 20451 net.cpp:156] Memory required for data: 1579479808
I0808 13:44:08.933521 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.933528 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.933535 20451 layer_factory.hpp:77] Creating layer ReLU61
I0808 13:44:08.933544 20451 net.cpp:91] Creating Layer ReLU61
I0808 13:44:08.933552 20451 net.cpp:425] ReLU61 <- InnerProduct91
I0808 13:44:08.933560 20451 net.cpp:386] ReLU61 -> InnerProduct91 (in-place)
I0808 13:44:08.933571 20451 net.cpp:141] Setting up ReLU61
I0808 13:44:08.933579 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.933585 20451 net.cpp:156] Memory required for data: 1579505408
I0808 13:44:08.933591 20451 layer_factory.hpp:77] Creating layer InnerProduct92
I0808 13:44:08.933604 20451 net.cpp:91] Creating Layer InnerProduct92
I0808 13:44:08.933610 20451 net.cpp:425] InnerProduct92 <- InnerProduct91
I0808 13:44:08.933621 20451 net.cpp:399] InnerProduct92 -> InnerProduct92
I0808 13:44:08.933820 20451 net.cpp:141] Setting up InnerProduct92
I0808 13:44:08.933828 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.933833 20451 net.cpp:156] Memory required for data: 1579518208
I0808 13:44:08.933840 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.933848 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.933856 20451 layer_factory.hpp:77] Creating layer Convolution94
I0808 13:44:08.933868 20451 net.cpp:91] Creating Layer Convolution94
I0808 13:44:08.933876 20451 net.cpp:425] Convolution94 <- c16
I0808 13:44:08.933889 20451 net.cpp:399] Convolution94 -> Convolution94
I0808 13:44:08.934283 20451 net.cpp:141] Setting up Convolution94
I0808 13:44:08.934293 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.934299 20451 net.cpp:156] Memory required for data: 1597950208
I0808 13:44:08.934306 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.934314 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.953703 20451 layer_factory.hpp:77] Creating layer Pooling94
I0808 13:44:08.953727 20451 net.cpp:91] Creating Layer Pooling94
I0808 13:44:08.953739 20451 net.cpp:425] Pooling94 <- Convolution94
I0808 13:44:08.953764 20451 net.cpp:399] Pooling94 -> Pooling94
I0808 13:44:08.953840 20451 net.cpp:141] Setting up Pooling94
I0808 13:44:08.953850 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.953856 20451 net.cpp:156] Memory required for data: 1602558208
I0808 13:44:08.953863 20451 layer_factory.hpp:77] Creating layer Convolution95
I0808 13:44:08.953883 20451 net.cpp:91] Creating Layer Convolution95
I0808 13:44:08.953891 20451 net.cpp:425] Convolution95 <- Pooling94
I0808 13:44:08.953902 20451 net.cpp:399] Convolution95 -> Convolution95
I0808 13:44:08.954519 20451 net.cpp:141] Setting up Convolution95
I0808 13:44:08.954530 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.954536 20451 net.cpp:156] Memory required for data: 1611211008
I0808 13:44:08.954543 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.954551 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.954558 20451 layer_factory.hpp:77] Creating layer Pooling95
I0808 13:44:08.954567 20451 net.cpp:91] Creating Layer Pooling95
I0808 13:44:08.954574 20451 net.cpp:425] Pooling95 <- Convolution95
I0808 13:44:08.954584 20451 net.cpp:399] Pooling95 -> Pooling95
I0808 13:44:08.954640 20451 net.cpp:141] Setting up Pooling95
I0808 13:44:08.954649 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.954654 20451 net.cpp:156] Memory required for data: 1613374208
I0808 13:44:08.954661 20451 layer_factory.hpp:77] Creating layer Convolution96
I0808 13:44:08.954675 20451 net.cpp:91] Creating Layer Convolution96
I0808 13:44:08.954682 20451 net.cpp:425] Convolution96 <- Pooling95
I0808 13:44:08.954695 20451 net.cpp:399] Convolution96 -> Convolution96
I0808 13:44:08.955744 20451 net.cpp:141] Setting up Convolution96
I0808 13:44:08.955755 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.955765 20451 net.cpp:156] Memory required for data: 1614411008
I0808 13:44:08.955773 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.955783 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.955792 20451 layer_factory.hpp:77] Creating layer Pooling96
I0808 13:44:08.955804 20451 net.cpp:91] Creating Layer Pooling96
I0808 13:44:08.955813 20451 net.cpp:425] Pooling96 <- Convolution96
I0808 13:44:08.955831 20451 net.cpp:399] Pooling96 -> Pooling96
I0808 13:44:08.955902 20451 net.cpp:141] Setting up Pooling96
I0808 13:44:08.955917 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.955925 20451 net.cpp:156] Memory required for data: 1614731008
I0808 13:44:08.955934 20451 layer_factory.hpp:77] Creating layer InnerProduct93
I0808 13:44:08.955947 20451 net.cpp:91] Creating Layer InnerProduct93
I0808 13:44:08.955955 20451 net.cpp:425] InnerProduct93 <- Pooling96
I0808 13:44:08.955973 20451 net.cpp:399] InnerProduct93 -> InnerProduct93
I0808 13:44:08.958580 20451 net.cpp:141] Setting up InnerProduct93
I0808 13:44:08.958606 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.958618 20451 net.cpp:156] Memory required for data: 1614756608
I0808 13:44:08.958631 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.958644 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.958657 20451 layer_factory.hpp:77] Creating layer ReLU62
I0808 13:44:08.958676 20451 net.cpp:91] Creating Layer ReLU62
I0808 13:44:08.958690 20451 net.cpp:425] ReLU62 <- InnerProduct93
I0808 13:44:08.958708 20451 net.cpp:386] ReLU62 -> InnerProduct93 (in-place)
I0808 13:44:08.958726 20451 net.cpp:141] Setting up ReLU62
I0808 13:44:08.958741 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.958757 20451 net.cpp:156] Memory required for data: 1614782208
I0808 13:44:08.958768 20451 layer_factory.hpp:77] Creating layer InnerProduct94
I0808 13:44:08.958794 20451 net.cpp:91] Creating Layer InnerProduct94
I0808 13:44:08.958806 20451 net.cpp:425] InnerProduct94 <- InnerProduct93
I0808 13:44:08.958828 20451 net.cpp:399] InnerProduct94 -> InnerProduct94
I0808 13:44:08.959136 20451 net.cpp:141] Setting up InnerProduct94
I0808 13:44:08.959148 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.959156 20451 net.cpp:156] Memory required for data: 1614795008
I0808 13:44:08.959167 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.959182 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.959209 20451 layer_factory.hpp:77] Creating layer Concat16
I0808 13:44:08.959223 20451 net.cpp:91] Creating Layer Concat16
I0808 13:44:08.959231 20451 net.cpp:425] Concat16 <- InnerProduct92
I0808 13:44:08.959244 20451 net.cpp:425] Concat16 <- InnerProduct94
I0808 13:44:08.959259 20451 net.cpp:399] Concat16 -> Concat16
I0808 13:44:08.959328 20451 net.cpp:141] Setting up Concat16
I0808 13:44:08.959341 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.959348 20451 net.cpp:156] Memory required for data: 1614820608
I0808 13:44:08.959357 20451 layer_factory.hpp:77] Creating layer InnerProduct95
I0808 13:44:08.959374 20451 net.cpp:91] Creating Layer InnerProduct95
I0808 13:44:08.959383 20451 net.cpp:425] InnerProduct95 <- Concat16
I0808 13:44:08.959403 20451 net.cpp:399] InnerProduct95 -> InnerProduct95
I0808 13:44:08.960291 20451 net.cpp:141] Setting up InnerProduct95
I0808 13:44:08.960305 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.960311 20451 net.cpp:156] Memory required for data: 1614836992
I0808 13:44:08.960319 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.960330 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.960336 20451 layer_factory.hpp:77] Creating layer ReLU63
I0808 13:44:08.960351 20451 net.cpp:91] Creating Layer ReLU63
I0808 13:44:08.960361 20451 net.cpp:425] ReLU63 <- InnerProduct95
I0808 13:44:08.960372 20451 net.cpp:386] ReLU63 -> InnerProduct95 (in-place)
I0808 13:44:08.960384 20451 net.cpp:141] Setting up ReLU63
I0808 13:44:08.960392 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.960397 20451 net.cpp:156] Memory required for data: 1614853376
I0808 13:44:08.960403 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.960414 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.960422 20451 net.cpp:425] drop1 <- InnerProduct95
I0808 13:44:08.960432 20451 net.cpp:399] drop1 -> Dropout31
I0808 13:44:08.960482 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.960492 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.960499 20451 net.cpp:156] Memory required for data: 1614869760
I0808 13:44:08.960503 20451 layer_factory.hpp:77] Creating layer InnerProduct96
I0808 13:44:08.960513 20451 net.cpp:91] Creating Layer InnerProduct96
I0808 13:44:08.960520 20451 net.cpp:425] InnerProduct96 <- Dropout31
I0808 13:44:08.960531 20451 net.cpp:399] InnerProduct96 -> InnerProduct96
I0808 13:44:08.960702 20451 net.cpp:141] Setting up InnerProduct96
I0808 13:44:08.960711 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.960716 20451 net.cpp:156] Memory required for data: 1614877952
I0808 13:44:08.960722 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.960729 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.960736 20451 layer_factory.hpp:77] Creating layer ReLU64
I0808 13:44:08.960743 20451 net.cpp:91] Creating Layer ReLU64
I0808 13:44:08.960749 20451 net.cpp:425] ReLU64 <- InnerProduct96
I0808 13:44:08.960757 20451 net.cpp:386] ReLU64 -> InnerProduct96 (in-place)
I0808 13:44:08.960770 20451 net.cpp:141] Setting up ReLU64
I0808 13:44:08.960777 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.960783 20451 net.cpp:156] Memory required for data: 1614886144
I0808 13:44:08.960788 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.960796 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.960803 20451 net.cpp:425] drop2 <- InnerProduct96
I0808 13:44:08.960811 20451 net.cpp:399] drop2 -> Dropout32
I0808 13:44:08.960858 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.960866 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.960871 20451 net.cpp:156] Memory required for data: 1614894336
I0808 13:44:08.960877 20451 layer_factory.hpp:77] Creating layer dt15
I0808 13:44:08.960886 20451 net.cpp:91] Creating Layer dt15
I0808 13:44:08.960891 20451 net.cpp:425] dt15 <- Dropout32
I0808 13:44:08.960904 20451 net.cpp:399] dt15 -> dt15
I0808 13:44:08.961055 20451 net.cpp:141] Setting up dt15
I0808 13:44:08.961062 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.961067 20451 net.cpp:156] Memory required for data: 1614894592
I0808 13:44:08.961073 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.961081 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.961087 20451 layer_factory.hpp:77] Creating layer Convolution97
I0808 13:44:08.961102 20451 net.cpp:91] Creating Layer Convolution97
I0808 13:44:08.961109 20451 net.cpp:425] Convolution97 <- p2_p2_0_split_7
I0808 13:44:08.961122 20451 net.cpp:399] Convolution97 -> Convolution97
I0808 13:44:08.961503 20451 net.cpp:141] Setting up Convolution97
I0808 13:44:08.961513 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.961519 20451 net.cpp:156] Memory required for data: 1633326592
I0808 13:44:08.961524 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.961531 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.961537 20451 layer_factory.hpp:77] Creating layer Pooling97
I0808 13:44:08.961546 20451 net.cpp:91] Creating Layer Pooling97
I0808 13:44:08.961554 20451 net.cpp:425] Pooling97 <- Convolution97
I0808 13:44:08.961562 20451 net.cpp:399] Pooling97 -> Pooling97
I0808 13:44:08.961619 20451 net.cpp:141] Setting up Pooling97
I0808 13:44:08.961627 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.961633 20451 net.cpp:156] Memory required for data: 1637934592
I0808 13:44:08.961638 20451 layer_factory.hpp:77] Creating layer Convolution98
I0808 13:44:08.961652 20451 net.cpp:91] Creating Layer Convolution98
I0808 13:44:08.961658 20451 net.cpp:425] Convolution98 <- Pooling97
I0808 13:44:08.961670 20451 net.cpp:399] Convolution98 -> Convolution98
I0808 13:44:08.962226 20451 net.cpp:141] Setting up Convolution98
I0808 13:44:08.962236 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.962241 20451 net.cpp:156] Memory required for data: 1646587392
I0808 13:44:08.962249 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.962255 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.962260 20451 layer_factory.hpp:77] Creating layer Pooling98
I0808 13:44:08.962275 20451 net.cpp:91] Creating Layer Pooling98
I0808 13:44:08.962280 20451 net.cpp:425] Pooling98 <- Convolution98
I0808 13:44:08.962290 20451 net.cpp:399] Pooling98 -> Pooling98
I0808 13:44:08.962340 20451 net.cpp:141] Setting up Pooling98
I0808 13:44:08.962347 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.962353 20451 net.cpp:156] Memory required for data: 1648750592
I0808 13:44:08.962358 20451 layer_factory.hpp:77] Creating layer Convolution99
I0808 13:44:08.962373 20451 net.cpp:91] Creating Layer Convolution99
I0808 13:44:08.962378 20451 net.cpp:425] Convolution99 <- Pooling98
I0808 13:44:08.962388 20451 net.cpp:399] Convolution99 -> Convolution99
I0808 13:44:08.963212 20451 net.cpp:141] Setting up Convolution99
I0808 13:44:08.963219 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.963225 20451 net.cpp:156] Memory required for data: 1649787392
I0808 13:44:08.963232 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.963238 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.963244 20451 layer_factory.hpp:77] Creating layer Pooling99
I0808 13:44:08.963254 20451 net.cpp:91] Creating Layer Pooling99
I0808 13:44:08.963260 20451 net.cpp:425] Pooling99 <- Convolution99
I0808 13:44:08.963269 20451 net.cpp:399] Pooling99 -> Pooling99
I0808 13:44:08.963336 20451 net.cpp:141] Setting up Pooling99
I0808 13:44:08.963345 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.963349 20451 net.cpp:156] Memory required for data: 1650107392
I0808 13:44:08.963366 20451 layer_factory.hpp:77] Creating layer InnerProduct97
I0808 13:44:08.963378 20451 net.cpp:91] Creating Layer InnerProduct97
I0808 13:44:08.963384 20451 net.cpp:425] InnerProduct97 <- Pooling99
I0808 13:44:08.963393 20451 net.cpp:399] InnerProduct97 -> InnerProduct97
I0808 13:44:08.964514 20451 net.cpp:141] Setting up InnerProduct97
I0808 13:44:08.964524 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.964529 20451 net.cpp:156] Memory required for data: 1650132992
I0808 13:44:08.964536 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.964545 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.964550 20451 layer_factory.hpp:77] Creating layer ReLU65
I0808 13:44:08.964561 20451 net.cpp:91] Creating Layer ReLU65
I0808 13:44:08.964567 20451 net.cpp:425] ReLU65 <- InnerProduct97
I0808 13:44:08.964576 20451 net.cpp:386] ReLU65 -> InnerProduct97 (in-place)
I0808 13:44:08.964586 20451 net.cpp:141] Setting up ReLU65
I0808 13:44:08.964592 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.964598 20451 net.cpp:156] Memory required for data: 1650158592
I0808 13:44:08.964603 20451 layer_factory.hpp:77] Creating layer InnerProduct98
I0808 13:44:08.964615 20451 net.cpp:91] Creating Layer InnerProduct98
I0808 13:44:08.964622 20451 net.cpp:425] InnerProduct98 <- InnerProduct97
I0808 13:44:08.964632 20451 net.cpp:399] InnerProduct98 -> InnerProduct98
I0808 13:44:08.964802 20451 net.cpp:141] Setting up InnerProduct98
I0808 13:44:08.964810 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.964817 20451 net.cpp:156] Memory required for data: 1650171392
I0808 13:44:08.964823 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.964829 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.964835 20451 layer_factory.hpp:77] Creating layer Convolution100
I0808 13:44:08.964848 20451 net.cpp:91] Creating Layer Convolution100
I0808 13:44:08.964855 20451 net.cpp:425] Convolution100 <- c17
I0808 13:44:08.964869 20451 net.cpp:399] Convolution100 -> Convolution100
I0808 13:44:08.965225 20451 net.cpp:141] Setting up Convolution100
I0808 13:44:08.965234 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.965240 20451 net.cpp:156] Memory required for data: 1668603392
I0808 13:44:08.965245 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.965252 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.965258 20451 layer_factory.hpp:77] Creating layer Pooling100
I0808 13:44:08.965266 20451 net.cpp:91] Creating Layer Pooling100
I0808 13:44:08.965272 20451 net.cpp:425] Pooling100 <- Convolution100
I0808 13:44:08.965283 20451 net.cpp:399] Pooling100 -> Pooling100
I0808 13:44:08.965332 20451 net.cpp:141] Setting up Pooling100
I0808 13:44:08.965340 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.984473 20451 net.cpp:156] Memory required for data: 1673211392
I0808 13:44:08.984490 20451 layer_factory.hpp:77] Creating layer Convolution101
I0808 13:44:08.984520 20451 net.cpp:91] Creating Layer Convolution101
I0808 13:44:08.984531 20451 net.cpp:425] Convolution101 <- Pooling100
I0808 13:44:08.984555 20451 net.cpp:399] Convolution101 -> Convolution101
I0808 13:44:08.985868 20451 net.cpp:141] Setting up Convolution101
I0808 13:44:08.985885 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.985893 20451 net.cpp:156] Memory required for data: 1681864192
I0808 13:44:08.985903 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.985913 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.985919 20451 layer_factory.hpp:77] Creating layer Pooling101
I0808 13:44:08.985931 20451 net.cpp:91] Creating Layer Pooling101
I0808 13:44:08.985940 20451 net.cpp:425] Pooling101 <- Convolution101
I0808 13:44:08.985973 20451 net.cpp:399] Pooling101 -> Pooling101
I0808 13:44:08.986040 20451 net.cpp:141] Setting up Pooling101
I0808 13:44:08.986052 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.986058 20451 net.cpp:156] Memory required for data: 1684027392
I0808 13:44:08.986065 20451 layer_factory.hpp:77] Creating layer Convolution102
I0808 13:44:08.986083 20451 net.cpp:91] Creating Layer Convolution102
I0808 13:44:08.986091 20451 net.cpp:425] Convolution102 <- Pooling101
I0808 13:44:08.986104 20451 net.cpp:399] Convolution102 -> Convolution102
I0808 13:44:08.986912 20451 net.cpp:141] Setting up Convolution102
I0808 13:44:08.986920 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.986925 20451 net.cpp:156] Memory required for data: 1685064192
I0808 13:44:08.986932 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.986939 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.986945 20451 layer_factory.hpp:77] Creating layer Pooling102
I0808 13:44:08.986955 20451 net.cpp:91] Creating Layer Pooling102
I0808 13:44:08.986963 20451 net.cpp:425] Pooling102 <- Convolution102
I0808 13:44:08.986971 20451 net.cpp:399] Pooling102 -> Pooling102
I0808 13:44:08.987025 20451 net.cpp:141] Setting up Pooling102
I0808 13:44:08.987033 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.987038 20451 net.cpp:156] Memory required for data: 1685384192
I0808 13:44:08.987045 20451 layer_factory.hpp:77] Creating layer InnerProduct99
I0808 13:44:08.987056 20451 net.cpp:91] Creating Layer InnerProduct99
I0808 13:44:08.987062 20451 net.cpp:425] InnerProduct99 <- Pooling102
I0808 13:44:08.987072 20451 net.cpp:399] InnerProduct99 -> InnerProduct99
I0808 13:44:08.988884 20451 net.cpp:141] Setting up InnerProduct99
I0808 13:44:08.988901 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.988909 20451 net.cpp:156] Memory required for data: 1685409792
I0808 13:44:08.988919 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.988929 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.988937 20451 layer_factory.hpp:77] Creating layer ReLU66
I0808 13:44:08.988948 20451 net.cpp:91] Creating Layer ReLU66
I0808 13:44:08.988956 20451 net.cpp:425] ReLU66 <- InnerProduct99
I0808 13:44:08.988968 20451 net.cpp:386] ReLU66 -> InnerProduct99 (in-place)
I0808 13:44:08.988986 20451 net.cpp:141] Setting up ReLU66
I0808 13:44:08.988996 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.989001 20451 net.cpp:156] Memory required for data: 1685435392
I0808 13:44:08.989009 20451 layer_factory.hpp:77] Creating layer InnerProduct100
I0808 13:44:08.989022 20451 net.cpp:91] Creating Layer InnerProduct100
I0808 13:44:08.989030 20451 net.cpp:425] InnerProduct100 <- InnerProduct99
I0808 13:44:08.989042 20451 net.cpp:399] InnerProduct100 -> InnerProduct100
I0808 13:44:08.989272 20451 net.cpp:141] Setting up InnerProduct100
I0808 13:44:08.989284 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.989291 20451 net.cpp:156] Memory required for data: 1685448192
I0808 13:44:08.989300 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.989308 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.989315 20451 layer_factory.hpp:77] Creating layer Concat17
I0808 13:44:08.989331 20451 net.cpp:91] Creating Layer Concat17
I0808 13:44:08.989338 20451 net.cpp:425] Concat17 <- InnerProduct98
I0808 13:44:08.989347 20451 net.cpp:425] Concat17 <- InnerProduct100
I0808 13:44:08.989358 20451 net.cpp:399] Concat17 -> Concat17
I0808 13:44:08.989400 20451 net.cpp:141] Setting up Concat17
I0808 13:44:08.989410 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.989416 20451 net.cpp:156] Memory required for data: 1685473792
I0808 13:44:08.989423 20451 layer_factory.hpp:77] Creating layer InnerProduct101
I0808 13:44:08.989455 20451 net.cpp:91] Creating Layer InnerProduct101
I0808 13:44:08.989464 20451 net.cpp:425] InnerProduct101 <- Concat17
I0808 13:44:08.989475 20451 net.cpp:399] InnerProduct101 -> InnerProduct101
I0808 13:44:08.989698 20451 net.cpp:141] Setting up InnerProduct101
I0808 13:44:08.989711 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.989719 20451 net.cpp:156] Memory required for data: 1685490176
I0808 13:44:08.989727 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:08.989737 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:08.989744 20451 layer_factory.hpp:77] Creating layer ReLU67
I0808 13:44:08.989758 20451 net.cpp:91] Creating Layer ReLU67
I0808 13:44:08.989765 20451 net.cpp:425] ReLU67 <- InnerProduct101
I0808 13:44:08.989776 20451 net.cpp:386] ReLU67 -> InnerProduct101 (in-place)
I0808 13:44:08.989792 20451 net.cpp:141] Setting up ReLU67
I0808 13:44:08.989807 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.989819 20451 net.cpp:156] Memory required for data: 1685506560
I0808 13:44:08.989828 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:08.989841 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:08.989853 20451 net.cpp:425] drop1 <- InnerProduct101
I0808 13:44:08.989871 20451 net.cpp:399] drop1 -> Dropout33
I0808 13:44:08.989936 20451 net.cpp:141] Setting up drop1
I0808 13:44:08.989946 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:08.989954 20451 net.cpp:156] Memory required for data: 1685522944
I0808 13:44:08.989961 20451 layer_factory.hpp:77] Creating layer InnerProduct102
I0808 13:44:08.989976 20451 net.cpp:91] Creating Layer InnerProduct102
I0808 13:44:08.989984 20451 net.cpp:425] InnerProduct102 <- Dropout33
I0808 13:44:08.989997 20451 net.cpp:399] InnerProduct102 -> InnerProduct102
I0808 13:44:08.990200 20451 net.cpp:141] Setting up InnerProduct102
I0808 13:44:08.990212 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.990218 20451 net.cpp:156] Memory required for data: 1685531136
I0808 13:44:08.990224 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:08.990232 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:08.990238 20451 layer_factory.hpp:77] Creating layer ReLU68
I0808 13:44:08.990247 20451 net.cpp:91] Creating Layer ReLU68
I0808 13:44:08.990252 20451 net.cpp:425] ReLU68 <- InnerProduct102
I0808 13:44:08.990262 20451 net.cpp:386] ReLU68 -> InnerProduct102 (in-place)
I0808 13:44:08.990270 20451 net.cpp:141] Setting up ReLU68
I0808 13:44:08.990278 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.990283 20451 net.cpp:156] Memory required for data: 1685539328
I0808 13:44:08.990289 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:08.990298 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:08.990303 20451 net.cpp:425] drop2 <- InnerProduct102
I0808 13:44:08.992241 20451 net.cpp:399] drop2 -> Dropout34
I0808 13:44:08.992316 20451 net.cpp:141] Setting up drop2
I0808 13:44:08.992326 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:08.992331 20451 net.cpp:156] Memory required for data: 1685547520
I0808 13:44:08.992337 20451 layer_factory.hpp:77] Creating layer dt16
I0808 13:44:08.992350 20451 net.cpp:91] Creating Layer dt16
I0808 13:44:08.992357 20451 net.cpp:425] dt16 <- Dropout34
I0808 13:44:08.992368 20451 net.cpp:399] dt16 -> dt16
I0808 13:44:08.992518 20451 net.cpp:141] Setting up dt16
I0808 13:44:08.992527 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:08.992532 20451 net.cpp:156] Memory required for data: 1685547776
I0808 13:44:08.992538 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:08.992547 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:08.992552 20451 layer_factory.hpp:77] Creating layer Convolution103
I0808 13:44:08.992566 20451 net.cpp:91] Creating Layer Convolution103
I0808 13:44:08.992588 20451 net.cpp:425] Convolution103 <- p2_p2_0_split_8
I0808 13:44:08.992601 20451 net.cpp:399] Convolution103 -> Convolution103
I0808 13:44:08.992964 20451 net.cpp:141] Setting up Convolution103
I0808 13:44:08.992971 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.992976 20451 net.cpp:156] Memory required for data: 1703979776
I0808 13:44:08.992983 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.992990 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.992996 20451 layer_factory.hpp:77] Creating layer Pooling103
I0808 13:44:08.993007 20451 net.cpp:91] Creating Layer Pooling103
I0808 13:44:08.993013 20451 net.cpp:425] Pooling103 <- Convolution103
I0808 13:44:08.993023 20451 net.cpp:399] Pooling103 -> Pooling103
I0808 13:44:08.993075 20451 net.cpp:141] Setting up Pooling103
I0808 13:44:08.993083 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.993088 20451 net.cpp:156] Memory required for data: 1708587776
I0808 13:44:08.993093 20451 layer_factory.hpp:77] Creating layer Convolution104
I0808 13:44:08.993106 20451 net.cpp:91] Creating Layer Convolution104
I0808 13:44:08.993113 20451 net.cpp:425] Convolution104 <- Pooling103
I0808 13:44:08.993124 20451 net.cpp:399] Convolution104 -> Convolution104
I0808 13:44:08.993682 20451 net.cpp:141] Setting up Convolution104
I0808 13:44:08.993691 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:08.993703 20451 net.cpp:156] Memory required for data: 1717240576
I0808 13:44:08.993711 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:08.993721 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:08.993727 20451 layer_factory.hpp:77] Creating layer Pooling104
I0808 13:44:08.993738 20451 net.cpp:91] Creating Layer Pooling104
I0808 13:44:08.993746 20451 net.cpp:425] Pooling104 <- Convolution104
I0808 13:44:08.993759 20451 net.cpp:399] Pooling104 -> Pooling104
I0808 13:44:08.993818 20451 net.cpp:141] Setting up Pooling104
I0808 13:44:08.993827 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:08.993834 20451 net.cpp:156] Memory required for data: 1719403776
I0808 13:44:08.993841 20451 layer_factory.hpp:77] Creating layer Convolution105
I0808 13:44:08.993860 20451 net.cpp:91] Creating Layer Convolution105
I0808 13:44:08.993867 20451 net.cpp:425] Convolution105 <- Pooling104
I0808 13:44:08.993880 20451 net.cpp:399] Convolution105 -> Convolution105
I0808 13:44:08.994743 20451 net.cpp:141] Setting up Convolution105
I0808 13:44:08.994755 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:08.994761 20451 net.cpp:156] Memory required for data: 1720440576
I0808 13:44:08.994767 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:08.994774 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:08.994781 20451 layer_factory.hpp:77] Creating layer Pooling105
I0808 13:44:08.994791 20451 net.cpp:91] Creating Layer Pooling105
I0808 13:44:08.994796 20451 net.cpp:425] Pooling105 <- Convolution105
I0808 13:44:08.994806 20451 net.cpp:399] Pooling105 -> Pooling105
I0808 13:44:08.994860 20451 net.cpp:141] Setting up Pooling105
I0808 13:44:08.994868 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:08.994874 20451 net.cpp:156] Memory required for data: 1720760576
I0808 13:44:08.994879 20451 layer_factory.hpp:77] Creating layer InnerProduct103
I0808 13:44:08.994889 20451 net.cpp:91] Creating Layer InnerProduct103
I0808 13:44:08.994894 20451 net.cpp:425] InnerProduct103 <- Pooling105
I0808 13:44:08.994906 20451 net.cpp:399] InnerProduct103 -> InnerProduct103
I0808 13:44:08.996158 20451 net.cpp:141] Setting up InnerProduct103
I0808 13:44:08.996168 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.996175 20451 net.cpp:156] Memory required for data: 1720786176
I0808 13:44:08.996182 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:08.996204 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:08.996212 20451 layer_factory.hpp:77] Creating layer ReLU69
I0808 13:44:08.996220 20451 net.cpp:91] Creating Layer ReLU69
I0808 13:44:08.996227 20451 net.cpp:425] ReLU69 <- InnerProduct103
I0808 13:44:08.996239 20451 net.cpp:386] ReLU69 -> InnerProduct103 (in-place)
I0808 13:44:08.996250 20451 net.cpp:141] Setting up ReLU69
I0808 13:44:08.996258 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:08.996264 20451 net.cpp:156] Memory required for data: 1720811776
I0808 13:44:08.996270 20451 layer_factory.hpp:77] Creating layer InnerProduct104
I0808 13:44:08.996280 20451 net.cpp:91] Creating Layer InnerProduct104
I0808 13:44:08.996287 20451 net.cpp:425] InnerProduct104 <- InnerProduct103
I0808 13:44:08.996300 20451 net.cpp:399] InnerProduct104 -> InnerProduct104
I0808 13:44:08.996495 20451 net.cpp:141] Setting up InnerProduct104
I0808 13:44:08.996505 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:08.996510 20451 net.cpp:156] Memory required for data: 1720824576
I0808 13:44:08.996517 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:08.996526 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:08.996531 20451 layer_factory.hpp:77] Creating layer Convolution106
I0808 13:44:08.996546 20451 net.cpp:91] Creating Layer Convolution106
I0808 13:44:08.996553 20451 net.cpp:425] Convolution106 <- c18
I0808 13:44:08.996565 20451 net.cpp:399] Convolution106 -> Convolution106
I0808 13:44:08.996966 20451 net.cpp:141] Setting up Convolution106
I0808 13:44:08.996978 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:08.996984 20451 net.cpp:156] Memory required for data: 1739256576
I0808 13:44:08.996991 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:08.996999 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:08.997005 20451 layer_factory.hpp:77] Creating layer Pooling106
I0808 13:44:08.997014 20451 net.cpp:91] Creating Layer Pooling106
I0808 13:44:08.997021 20451 net.cpp:425] Pooling106 <- Convolution106
I0808 13:44:08.997031 20451 net.cpp:399] Pooling106 -> Pooling106
I0808 13:44:08.997087 20451 net.cpp:141] Setting up Pooling106
I0808 13:44:08.997097 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:08.997102 20451 net.cpp:156] Memory required for data: 1743864576
I0808 13:44:08.997108 20451 layer_factory.hpp:77] Creating layer Convolution107
I0808 13:44:08.997123 20451 net.cpp:91] Creating Layer Convolution107
I0808 13:44:08.997130 20451 net.cpp:425] Convolution107 <- Pooling106
I0808 13:44:08.997143 20451 net.cpp:399] Convolution107 -> Convolution107
I0808 13:44:08.997758 20451 net.cpp:141] Setting up Convolution107
I0808 13:44:09.021653 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.021666 20451 net.cpp:156] Memory required for data: 1752517376
I0808 13:44:09.021677 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.021688 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.021695 20451 layer_factory.hpp:77] Creating layer Pooling107
I0808 13:44:09.021708 20451 net.cpp:91] Creating Layer Pooling107
I0808 13:44:09.021715 20451 net.cpp:425] Pooling107 <- Convolution107
I0808 13:44:09.021731 20451 net.cpp:399] Pooling107 -> Pooling107
I0808 13:44:09.021812 20451 net.cpp:141] Setting up Pooling107
I0808 13:44:09.021823 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.021831 20451 net.cpp:156] Memory required for data: 1754680576
I0808 13:44:09.021836 20451 layer_factory.hpp:77] Creating layer Convolution108
I0808 13:44:09.021850 20451 net.cpp:91] Creating Layer Convolution108
I0808 13:44:09.021857 20451 net.cpp:425] Convolution108 <- Pooling107
I0808 13:44:09.021888 20451 net.cpp:399] Convolution108 -> Convolution108
I0808 13:44:09.023627 20451 net.cpp:141] Setting up Convolution108
I0808 13:44:09.023643 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.023650 20451 net.cpp:156] Memory required for data: 1755717376
I0808 13:44:09.023658 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.023668 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.023674 20451 layer_factory.hpp:77] Creating layer Pooling108
I0808 13:44:09.023687 20451 net.cpp:91] Creating Layer Pooling108
I0808 13:44:09.023695 20451 net.cpp:425] Pooling108 <- Convolution108
I0808 13:44:09.023706 20451 net.cpp:399] Pooling108 -> Pooling108
I0808 13:44:09.023772 20451 net.cpp:141] Setting up Pooling108
I0808 13:44:09.023779 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.023787 20451 net.cpp:156] Memory required for data: 1756037376
I0808 13:44:09.023792 20451 layer_factory.hpp:77] Creating layer InnerProduct105
I0808 13:44:09.023803 20451 net.cpp:91] Creating Layer InnerProduct105
I0808 13:44:09.023813 20451 net.cpp:425] InnerProduct105 <- Pooling108
I0808 13:44:09.023830 20451 net.cpp:399] InnerProduct105 -> InnerProduct105
I0808 13:44:09.025745 20451 net.cpp:141] Setting up InnerProduct105
I0808 13:44:09.025763 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.025769 20451 net.cpp:156] Memory required for data: 1756062976
I0808 13:44:09.025779 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.025787 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.025794 20451 layer_factory.hpp:77] Creating layer ReLU70
I0808 13:44:09.025804 20451 net.cpp:91] Creating Layer ReLU70
I0808 13:44:09.025812 20451 net.cpp:425] ReLU70 <- InnerProduct105
I0808 13:44:09.025822 20451 net.cpp:386] ReLU70 -> InnerProduct105 (in-place)
I0808 13:44:09.025835 20451 net.cpp:141] Setting up ReLU70
I0808 13:44:09.025842 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.025848 20451 net.cpp:156] Memory required for data: 1756088576
I0808 13:44:09.025854 20451 layer_factory.hpp:77] Creating layer InnerProduct106
I0808 13:44:09.025868 20451 net.cpp:91] Creating Layer InnerProduct106
I0808 13:44:09.025876 20451 net.cpp:425] InnerProduct106 <- InnerProduct105
I0808 13:44:09.025887 20451 net.cpp:399] InnerProduct106 -> InnerProduct106
I0808 13:44:09.026108 20451 net.cpp:141] Setting up InnerProduct106
I0808 13:44:09.026118 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.026124 20451 net.cpp:156] Memory required for data: 1756101376
I0808 13:44:09.026131 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.026139 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.026146 20451 layer_factory.hpp:77] Creating layer Concat18
I0808 13:44:09.026157 20451 net.cpp:91] Creating Layer Concat18
I0808 13:44:09.026165 20451 net.cpp:425] Concat18 <- InnerProduct104
I0808 13:44:09.026172 20451 net.cpp:425] Concat18 <- InnerProduct106
I0808 13:44:09.026185 20451 net.cpp:399] Concat18 -> Concat18
I0808 13:44:09.026217 20451 net.cpp:141] Setting up Concat18
I0808 13:44:09.026229 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.026235 20451 net.cpp:156] Memory required for data: 1756126976
I0808 13:44:09.026242 20451 layer_factory.hpp:77] Creating layer InnerProduct107
I0808 13:44:09.026252 20451 net.cpp:91] Creating Layer InnerProduct107
I0808 13:44:09.026258 20451 net.cpp:425] InnerProduct107 <- Concat18
I0808 13:44:09.026271 20451 net.cpp:399] InnerProduct107 -> InnerProduct107
I0808 13:44:09.026489 20451 net.cpp:141] Setting up InnerProduct107
I0808 13:44:09.026497 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.026504 20451 net.cpp:156] Memory required for data: 1756143360
I0808 13:44:09.026510 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.026535 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.026540 20451 layer_factory.hpp:77] Creating layer ReLU71
I0808 13:44:09.026549 20451 net.cpp:91] Creating Layer ReLU71
I0808 13:44:09.026556 20451 net.cpp:425] ReLU71 <- InnerProduct107
I0808 13:44:09.026568 20451 net.cpp:386] ReLU71 -> InnerProduct107 (in-place)
I0808 13:44:09.026578 20451 net.cpp:141] Setting up ReLU71
I0808 13:44:09.026587 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.026593 20451 net.cpp:156] Memory required for data: 1756159744
I0808 13:44:09.026599 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.026608 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.026615 20451 net.cpp:425] drop1 <- InnerProduct107
I0808 13:44:09.026626 20451 net.cpp:399] drop1 -> Dropout35
I0808 13:44:09.026684 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.026693 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.026700 20451 net.cpp:156] Memory required for data: 1756176128
I0808 13:44:09.026705 20451 layer_factory.hpp:77] Creating layer InnerProduct108
I0808 13:44:09.026717 20451 net.cpp:91] Creating Layer InnerProduct108
I0808 13:44:09.026724 20451 net.cpp:425] InnerProduct108 <- Dropout35
I0808 13:44:09.026734 20451 net.cpp:399] InnerProduct108 -> InnerProduct108
I0808 13:44:09.026921 20451 net.cpp:141] Setting up InnerProduct108
I0808 13:44:09.026931 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.026937 20451 net.cpp:156] Memory required for data: 1756184320
I0808 13:44:09.026943 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.026952 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.026958 20451 layer_factory.hpp:77] Creating layer ReLU72
I0808 13:44:09.027112 20451 net.cpp:91] Creating Layer ReLU72
I0808 13:44:09.027120 20451 net.cpp:425] ReLU72 <- InnerProduct108
I0808 13:44:09.027129 20451 net.cpp:386] ReLU72 -> InnerProduct108 (in-place)
I0808 13:44:09.027140 20451 net.cpp:141] Setting up ReLU72
I0808 13:44:09.027148 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.027154 20451 net.cpp:156] Memory required for data: 1756192512
I0808 13:44:09.027161 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.027170 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.027178 20451 net.cpp:425] drop2 <- InnerProduct108
I0808 13:44:09.027187 20451 net.cpp:399] drop2 -> Dropout36
I0808 13:44:09.027245 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.027254 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.027261 20451 net.cpp:156] Memory required for data: 1756200704
I0808 13:44:09.027266 20451 layer_factory.hpp:77] Creating layer dt17
I0808 13:44:09.027285 20451 net.cpp:91] Creating Layer dt17
I0808 13:44:09.046077 20451 net.cpp:425] dt17 <- Dropout36
I0808 13:44:09.046124 20451 net.cpp:399] dt17 -> dt17
I0808 13:44:09.046316 20451 net.cpp:141] Setting up dt17
I0808 13:44:09.046329 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.046335 20451 net.cpp:156] Memory required for data: 1756200960
I0808 13:44:09.046344 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.046353 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.046360 20451 layer_factory.hpp:77] Creating layer Convolution109
I0808 13:44:09.046380 20451 net.cpp:91] Creating Layer Convolution109
I0808 13:44:09.046387 20451 net.cpp:425] Convolution109 <- p2_p2_0_split_9
I0808 13:44:09.046399 20451 net.cpp:399] Convolution109 -> Convolution109
I0808 13:44:09.046805 20451 net.cpp:141] Setting up Convolution109
I0808 13:44:09.046815 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.046821 20451 net.cpp:156] Memory required for data: 1774632960
I0808 13:44:09.046828 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.046836 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.046856 20451 layer_factory.hpp:77] Creating layer Pooling109
I0808 13:44:09.046869 20451 net.cpp:91] Creating Layer Pooling109
I0808 13:44:09.046876 20451 net.cpp:425] Pooling109 <- Convolution109
I0808 13:44:09.046886 20451 net.cpp:399] Pooling109 -> Pooling109
I0808 13:44:09.046946 20451 net.cpp:141] Setting up Pooling109
I0808 13:44:09.046954 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.046960 20451 net.cpp:156] Memory required for data: 1779240960
I0808 13:44:09.046967 20451 layer_factory.hpp:77] Creating layer Convolution110
I0808 13:44:09.046980 20451 net.cpp:91] Creating Layer Convolution110
I0808 13:44:09.046988 20451 net.cpp:425] Convolution110 <- Pooling109
I0808 13:44:09.047001 20451 net.cpp:399] Convolution110 -> Convolution110
I0808 13:44:09.048022 20451 net.cpp:141] Setting up Convolution110
I0808 13:44:09.048044 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.048058 20451 net.cpp:156] Memory required for data: 1787893760
I0808 13:44:09.048071 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.048086 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.048100 20451 layer_factory.hpp:77] Creating layer Pooling110
I0808 13:44:09.048123 20451 net.cpp:91] Creating Layer Pooling110
I0808 13:44:09.048137 20451 net.cpp:425] Pooling110 <- Convolution110
I0808 13:44:09.048161 20451 net.cpp:399] Pooling110 -> Pooling110
I0808 13:44:09.048275 20451 net.cpp:141] Setting up Pooling110
I0808 13:44:09.048298 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.048313 20451 net.cpp:156] Memory required for data: 1790056960
I0808 13:44:09.048327 20451 layer_factory.hpp:77] Creating layer Convolution111
I0808 13:44:09.048362 20451 net.cpp:91] Creating Layer Convolution111
I0808 13:44:09.048380 20451 net.cpp:425] Convolution111 <- Pooling110
I0808 13:44:09.048413 20451 net.cpp:399] Convolution111 -> Convolution111
I0808 13:44:09.050305 20451 net.cpp:141] Setting up Convolution111
I0808 13:44:09.050329 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.050343 20451 net.cpp:156] Memory required for data: 1791093760
I0808 13:44:09.050357 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.050374 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.050386 20451 layer_factory.hpp:77] Creating layer Pooling111
I0808 13:44:09.050405 20451 net.cpp:91] Creating Layer Pooling111
I0808 13:44:09.050420 20451 net.cpp:425] Pooling111 <- Convolution111
I0808 13:44:09.050444 20451 net.cpp:399] Pooling111 -> Pooling111
I0808 13:44:09.050554 20451 net.cpp:141] Setting up Pooling111
I0808 13:44:09.050572 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.050585 20451 net.cpp:156] Memory required for data: 1791413760
I0808 13:44:09.050596 20451 layer_factory.hpp:77] Creating layer InnerProduct109
I0808 13:44:09.050621 20451 net.cpp:91] Creating Layer InnerProduct109
I0808 13:44:09.050634 20451 net.cpp:425] InnerProduct109 <- Pooling111
I0808 13:44:09.050659 20451 net.cpp:399] InnerProduct109 -> InnerProduct109
I0808 13:44:09.053136 20451 net.cpp:141] Setting up InnerProduct109
I0808 13:44:09.053160 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.053172 20451 net.cpp:156] Memory required for data: 1791439360
I0808 13:44:09.053187 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.053203 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.053216 20451 layer_factory.hpp:77] Creating layer ReLU73
I0808 13:44:09.053234 20451 net.cpp:91] Creating Layer ReLU73
I0808 13:44:09.053248 20451 net.cpp:425] ReLU73 <- InnerProduct109
I0808 13:44:09.053267 20451 net.cpp:386] ReLU73 -> InnerProduct109 (in-place)
I0808 13:44:09.053287 20451 net.cpp:141] Setting up ReLU73
I0808 13:44:09.053331 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.053344 20451 net.cpp:156] Memory required for data: 1791464960
I0808 13:44:09.053356 20451 layer_factory.hpp:77] Creating layer InnerProduct110
I0808 13:44:09.053380 20451 net.cpp:91] Creating Layer InnerProduct110
I0808 13:44:09.053395 20451 net.cpp:425] InnerProduct110 <- InnerProduct109
I0808 13:44:09.053419 20451 net.cpp:399] InnerProduct110 -> InnerProduct110
I0808 13:44:09.053800 20451 net.cpp:141] Setting up InnerProduct110
I0808 13:44:09.053818 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.053830 20451 net.cpp:156] Memory required for data: 1791477760
I0808 13:44:09.053843 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.053858 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.053871 20451 layer_factory.hpp:77] Creating layer Convolution112
I0808 13:44:09.053895 20451 net.cpp:91] Creating Layer Convolution112
I0808 13:44:09.053910 20451 net.cpp:425] Convolution112 <- c19
I0808 13:44:09.053936 20451 net.cpp:399] Convolution112 -> Convolution112
I0808 13:44:09.054743 20451 net.cpp:141] Setting up Convolution112
I0808 13:44:09.054760 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.054772 20451 net.cpp:156] Memory required for data: 1809909760
I0808 13:44:09.054785 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.054800 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.054813 20451 layer_factory.hpp:77] Creating layer Pooling112
I0808 13:44:09.054836 20451 net.cpp:91] Creating Layer Pooling112
I0808 13:44:09.054849 20451 net.cpp:425] Pooling112 <- Convolution112
I0808 13:44:09.054869 20451 net.cpp:399] Pooling112 -> Pooling112
I0808 13:44:09.054980 20451 net.cpp:141] Setting up Pooling112
I0808 13:44:09.054997 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.055009 20451 net.cpp:156] Memory required for data: 1814517760
I0808 13:44:09.055022 20451 layer_factory.hpp:77] Creating layer Convolution113
I0808 13:44:09.055048 20451 net.cpp:91] Creating Layer Convolution113
I0808 13:44:09.055063 20451 net.cpp:425] Convolution113 <- Pooling112
I0808 13:44:09.055083 20451 net.cpp:399] Convolution113 -> Convolution113
I0808 13:44:09.055816 20451 net.cpp:141] Setting up Convolution113
I0808 13:44:09.055825 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.055830 20451 net.cpp:156] Memory required for data: 1823170560
I0808 13:44:09.055837 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.055843 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.077016 20451 layer_factory.hpp:77] Creating layer Pooling113
I0808 13:44:09.077051 20451 net.cpp:91] Creating Layer Pooling113
I0808 13:44:09.077070 20451 net.cpp:425] Pooling113 <- Convolution113
I0808 13:44:09.077090 20451 net.cpp:399] Pooling113 -> Pooling113
I0808 13:44:09.077169 20451 net.cpp:141] Setting up Pooling113
I0808 13:44:09.077178 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.077184 20451 net.cpp:156] Memory required for data: 1825333760
I0808 13:44:09.077190 20451 layer_factory.hpp:77] Creating layer Convolution114
I0808 13:44:09.077204 20451 net.cpp:91] Creating Layer Convolution114
I0808 13:44:09.077211 20451 net.cpp:425] Convolution114 <- Pooling113
I0808 13:44:09.077224 20451 net.cpp:399] Convolution114 -> Convolution114
I0808 13:44:09.078059 20451 net.cpp:141] Setting up Convolution114
I0808 13:44:09.078068 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.078073 20451 net.cpp:156] Memory required for data: 1826370560
I0808 13:44:09.078080 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.078088 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.078105 20451 layer_factory.hpp:77] Creating layer Pooling114
I0808 13:44:09.078116 20451 net.cpp:91] Creating Layer Pooling114
I0808 13:44:09.078122 20451 net.cpp:425] Pooling114 <- Convolution114
I0808 13:44:09.078132 20451 net.cpp:399] Pooling114 -> Pooling114
I0808 13:44:09.078186 20451 net.cpp:141] Setting up Pooling114
I0808 13:44:09.078193 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.078198 20451 net.cpp:156] Memory required for data: 1826690560
I0808 13:44:09.078204 20451 layer_factory.hpp:77] Creating layer InnerProduct111
I0808 13:44:09.078213 20451 net.cpp:91] Creating Layer InnerProduct111
I0808 13:44:09.078219 20451 net.cpp:425] InnerProduct111 <- Pooling114
I0808 13:44:09.078233 20451 net.cpp:399] InnerProduct111 -> InnerProduct111
I0808 13:44:09.080027 20451 net.cpp:141] Setting up InnerProduct111
I0808 13:44:09.080042 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.080049 20451 net.cpp:156] Memory required for data: 1826716160
I0808 13:44:09.080056 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.080065 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.080070 20451 layer_factory.hpp:77] Creating layer ReLU74
I0808 13:44:09.080080 20451 net.cpp:91] Creating Layer ReLU74
I0808 13:44:09.080087 20451 net.cpp:425] ReLU74 <- InnerProduct111
I0808 13:44:09.080096 20451 net.cpp:386] ReLU74 -> InnerProduct111 (in-place)
I0808 13:44:09.080107 20451 net.cpp:141] Setting up ReLU74
I0808 13:44:09.080114 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.080121 20451 net.cpp:156] Memory required for data: 1826741760
I0808 13:44:09.080126 20451 layer_factory.hpp:77] Creating layer InnerProduct112
I0808 13:44:09.080138 20451 net.cpp:91] Creating Layer InnerProduct112
I0808 13:44:09.080144 20451 net.cpp:425] InnerProduct112 <- InnerProduct111
I0808 13:44:09.080157 20451 net.cpp:399] InnerProduct112 -> InnerProduct112
I0808 13:44:09.080343 20451 net.cpp:141] Setting up InnerProduct112
I0808 13:44:09.080351 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.080356 20451 net.cpp:156] Memory required for data: 1826754560
I0808 13:44:09.080363 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.080369 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.080375 20451 layer_factory.hpp:77] Creating layer Concat19
I0808 13:44:09.080384 20451 net.cpp:91] Creating Layer Concat19
I0808 13:44:09.080390 20451 net.cpp:425] Concat19 <- InnerProduct110
I0808 13:44:09.080399 20451 net.cpp:425] Concat19 <- InnerProduct112
I0808 13:44:09.080407 20451 net.cpp:399] Concat19 -> Concat19
I0808 13:44:09.080440 20451 net.cpp:141] Setting up Concat19
I0808 13:44:09.080447 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.080453 20451 net.cpp:156] Memory required for data: 1826780160
I0808 13:44:09.080458 20451 layer_factory.hpp:77] Creating layer InnerProduct113
I0808 13:44:09.080471 20451 net.cpp:91] Creating Layer InnerProduct113
I0808 13:44:09.080476 20451 net.cpp:425] InnerProduct113 <- Concat19
I0808 13:44:09.080485 20451 net.cpp:399] InnerProduct113 -> InnerProduct113
I0808 13:44:09.080682 20451 net.cpp:141] Setting up InnerProduct113
I0808 13:44:09.080689 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.080694 20451 net.cpp:156] Memory required for data: 1826796544
I0808 13:44:09.080700 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.080708 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.080713 20451 layer_factory.hpp:77] Creating layer ReLU75
I0808 13:44:09.080721 20451 net.cpp:91] Creating Layer ReLU75
I0808 13:44:09.080727 20451 net.cpp:425] ReLU75 <- InnerProduct113
I0808 13:44:09.080739 20451 net.cpp:386] ReLU75 -> InnerProduct113 (in-place)
I0808 13:44:09.080747 20451 net.cpp:141] Setting up ReLU75
I0808 13:44:09.080754 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.080775 20451 net.cpp:156] Memory required for data: 1826812928
I0808 13:44:09.080780 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.080790 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.080796 20451 net.cpp:425] drop1 <- InnerProduct113
I0808 13:44:09.080807 20451 net.cpp:399] drop1 -> Dropout37
I0808 13:44:09.080870 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.080881 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.080888 20451 net.cpp:156] Memory required for data: 1826829312
I0808 13:44:09.080896 20451 layer_factory.hpp:77] Creating layer InnerProduct114
I0808 13:44:09.080909 20451 net.cpp:91] Creating Layer InnerProduct114
I0808 13:44:09.080915 20451 net.cpp:425] InnerProduct114 <- Dropout37
I0808 13:44:09.080925 20451 net.cpp:399] InnerProduct114 -> InnerProduct114
I0808 13:44:09.081095 20451 net.cpp:141] Setting up InnerProduct114
I0808 13:44:09.081104 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.081110 20451 net.cpp:156] Memory required for data: 1826837504
I0808 13:44:09.081115 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.081123 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.081128 20451 layer_factory.hpp:77] Creating layer ReLU76
I0808 13:44:09.081138 20451 net.cpp:91] Creating Layer ReLU76
I0808 13:44:09.081146 20451 net.cpp:425] ReLU76 <- InnerProduct114
I0808 13:44:09.081153 20451 net.cpp:386] ReLU76 -> InnerProduct114 (in-place)
I0808 13:44:09.081162 20451 net.cpp:141] Setting up ReLU76
I0808 13:44:09.081171 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.081176 20451 net.cpp:156] Memory required for data: 1826845696
I0808 13:44:09.081182 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.081190 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.081197 20451 net.cpp:425] drop2 <- InnerProduct114
I0808 13:44:09.081207 20451 net.cpp:399] drop2 -> Dropout38
I0808 13:44:09.081254 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.081262 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.081267 20451 net.cpp:156] Memory required for data: 1826853888
I0808 13:44:09.081274 20451 layer_factory.hpp:77] Creating layer dt18
I0808 13:44:09.081282 20451 net.cpp:91] Creating Layer dt18
I0808 13:44:09.081288 20451 net.cpp:425] dt18 <- Dropout38
I0808 13:44:09.081301 20451 net.cpp:399] dt18 -> dt18
I0808 13:44:09.081444 20451 net.cpp:141] Setting up dt18
I0808 13:44:09.081452 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.081457 20451 net.cpp:156] Memory required for data: 1826854144
I0808 13:44:09.081465 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.082108 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.082116 20451 layer_factory.hpp:77] Creating layer con
I0808 13:44:09.082129 20451 net.cpp:91] Creating Layer con
I0808 13:44:09.082137 20451 net.cpp:425] con <- dt0
I0808 13:44:09.082146 20451 net.cpp:425] con <- dt1
I0808 13:44:09.082155 20451 net.cpp:425] con <- dt2
I0808 13:44:09.082162 20451 net.cpp:425] con <- dt3
I0808 13:44:09.082170 20451 net.cpp:425] con <- dt4
I0808 13:44:09.082176 20451 net.cpp:425] con <- dt5
I0808 13:44:09.082185 20451 net.cpp:425] con <- dt6
I0808 13:44:09.082190 20451 net.cpp:425] con <- dt7
I0808 13:44:09.082197 20451 net.cpp:425] con <- dt8
I0808 13:44:09.082207 20451 net.cpp:425] con <- dt9
I0808 13:44:09.082214 20451 net.cpp:425] con <- dt10
I0808 13:44:09.082221 20451 net.cpp:425] con <- dt11
I0808 13:44:09.082228 20451 net.cpp:425] con <- dt12
I0808 13:44:09.082236 20451 net.cpp:425] con <- dt13
I0808 13:44:09.082242 20451 net.cpp:425] con <- dt14
I0808 13:44:09.082248 20451 net.cpp:425] con <- dt15
I0808 13:44:09.082254 20451 net.cpp:425] con <- dt16
I0808 13:44:09.082262 20451 net.cpp:425] con <- dt17
I0808 13:44:09.082267 20451 net.cpp:425] con <- dt18
I0808 13:44:09.082279 20451 net.cpp:399] con -> con
I0808 13:44:09.082325 20451 net.cpp:141] Setting up con
I0808 13:44:09.082332 20451 net.cpp:148] Top shape: 64 19 (1216)
I0808 13:44:09.082339 20451 net.cpp:156] Memory required for data: 1826859008
I0808 13:44:09.082345 20451 layer_factory.hpp:77] Creating layer r1
I0808 13:44:09.082357 20451 net.cpp:91] Creating Layer r1
I0808 13:44:09.082363 20451 net.cpp:425] r1 <- con
I0808 13:44:09.082372 20451 net.cpp:399] r1 -> r1
I0808 13:44:09.082411 20451 net.cpp:141] Setting up r1
I0808 13:44:09.082417 20451 net.cpp:148] Top shape: 64 1 1 19 (1216)
I0808 13:44:09.082423 20451 net.cpp:156] Memory required for data: 1826863872
I0808 13:44:09.082428 20451 layer_factory.hpp:77] Creating layer p
I0808 13:44:09.082437 20451 net.cpp:91] Creating Layer p
I0808 13:44:09.082443 20451 net.cpp:425] p <- r1
I0808 13:44:09.082454 20451 net.cpp:399] p -> p
I0808 13:44:09.082504 20451 net.cpp:141] Setting up p
I0808 13:44:09.082511 20451 net.cpp:148] Top shape: 64 1 1 1 (64)
I0808 13:44:09.082516 20451 net.cpp:156] Memory required for data: 1826864128
I0808 13:44:09.082522 20451 layer_factory.hpp:77] Creating layer r2
I0808 13:44:09.082532 20451 net.cpp:91] Creating Layer r2
I0808 13:44:09.082538 20451 net.cpp:425] r2 <- p
I0808 13:44:09.082546 20451 net.cpp:399] r2 -> r2
I0808 13:44:09.082576 20451 net.cpp:141] Setting up r2
I0808 13:44:09.082583 20451 net.cpp:148] Top shape: 64 1 1 1 (64)
I0808 13:44:09.082588 20451 net.cpp:156] Memory required for data: 1826864384
I0808 13:44:09.082594 20451 layer_factory.hpp:77] Creating layer padL
I0808 13:44:09.082604 20451 net.cpp:91] Creating Layer padL
I0808 13:44:09.082610 20451 net.cpp:425] padL <- label_data_1_split_1
I0808 13:44:09.082619 20451 net.cpp:399] padL -> padL
I0808 13:44:09.082648 20451 net.cpp:141] Setting up padL
I0808 13:44:09.082656 20451 net.cpp:148] Top shape: 64 1 1 1 (64)
I0808 13:44:09.082661 20451 net.cpp:156] Memory required for data: 1826864640
I0808 13:44:09.082667 20451 layer_factory.hpp:77] Creating layer pad
I0808 13:44:09.082674 20451 net.cpp:91] Creating Layer pad
I0808 13:44:09.082680 20451 net.cpp:425] pad <- r2
I0808 13:44:09.082687 20451 net.cpp:425] pad <- padL
I0808 13:44:09.082698 20451 net.cpp:399] pad -> pad
I0808 13:44:09.082726 20451 net.cpp:141] Setting up pad
I0808 13:44:09.082737 20451 net.cpp:148] Top shape: 64 2 1 1 (128)
I0808 13:44:09.082742 20451 net.cpp:156] Memory required for data: 1826865152
I0808 13:44:09.082747 20451 layer_factory.hpp:77] Creating layer pad_pad_0_split
I0808 13:44:09.082756 20451 net.cpp:91] Creating Layer pad_pad_0_split
I0808 13:44:09.082762 20451 net.cpp:425] pad_pad_0_split <- pad
I0808 13:44:09.082769 20451 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_0
I0808 13:44:09.082779 20451 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_1
I0808 13:44:09.082981 20451 net.cpp:141] Setting up pad_pad_0_split
I0808 13:44:09.082993 20451 net.cpp:148] Top shape: 64 2 1 1 (128)
I0808 13:44:09.083009 20451 net.cpp:148] Top shape: 64 2 1 1 (128)
I0808 13:44:09.083015 20451 net.cpp:156] Memory required for data: 1826866176
I0808 13:44:09.083032 20451 layer_factory.hpp:77] Creating layer loss
I0808 13:44:09.083042 20451 net.cpp:91] Creating Layer loss
I0808 13:44:09.083050 20451 net.cpp:425] loss <- pad_pad_0_split_0
I0808 13:44:09.083058 20451 net.cpp:425] loss <- th_th_0_split_0
I0808 13:44:09.083070 20451 net.cpp:399] loss -> loss
I0808 13:44:09.083120 20451 net.cpp:141] Setting up loss
I0808 13:44:09.083132 20451 net.cpp:148] Top shape: (1)
I0808 13:44:09.083140 20451 net.cpp:151]     with loss weight 1
I0808 13:44:09.083163 20451 net.cpp:156] Memory required for data: 1826866180
I0808 13:44:09.083171 20451 layer_factory.hpp:77] Creating layer accuracy
I0808 13:44:09.083183 20451 net.cpp:91] Creating Layer accuracy
I0808 13:44:09.083189 20451 net.cpp:425] accuracy <- pad_pad_0_split_1
I0808 13:44:09.083199 20451 net.cpp:425] accuracy <- th_th_0_split_1
I0808 13:44:09.083209 20451 net.cpp:399] accuracy -> accuracy
I0808 13:44:09.083223 20451 net.cpp:141] Setting up accuracy
I0808 13:44:09.083231 20451 net.cpp:148] Top shape: (1)
I0808 13:44:09.083237 20451 net.cpp:156] Memory required for data: 1826866184
I0808 13:44:09.083256 20451 net.cpp:219] accuracy does not need backward computation.
I0808 13:44:09.083263 20451 net.cpp:217] loss needs backward computation.
I0808 13:44:09.083279 20451 net.cpp:217] pad_pad_0_split needs backward computation.
I0808 13:44:09.083288 20451 net.cpp:217] pad needs backward computation.
I0808 13:44:09.083297 20451 net.cpp:219] padL does not need backward computation.
I0808 13:44:09.083304 20451 net.cpp:217] r2 needs backward computation.
I0808 13:44:09.083312 20451 net.cpp:217] p needs backward computation.
I0808 13:44:09.083318 20451 net.cpp:217] r1 needs backward computation.
I0808 13:44:09.083326 20451 net.cpp:217] con needs backward computation.
I0808 13:44:09.083339 20451 net.cpp:217] dt18 needs backward computation.
I0808 13:44:09.083348 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.083355 20451 net.cpp:217] ReLU76 needs backward computation.
I0808 13:44:09.083362 20451 net.cpp:217] InnerProduct114 needs backward computation.
I0808 13:44:09.083369 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.083376 20451 net.cpp:217] ReLU75 needs backward computation.
I0808 13:44:09.083384 20451 net.cpp:217] InnerProduct113 needs backward computation.
I0808 13:44:09.083390 20451 net.cpp:217] Concat19 needs backward computation.
I0808 13:44:09.083397 20451 net.cpp:217] InnerProduct112 needs backward computation.
I0808 13:44:09.083405 20451 net.cpp:217] ReLU74 needs backward computation.
I0808 13:44:09.083411 20451 net.cpp:217] InnerProduct111 needs backward computation.
I0808 13:44:09.083420 20451 net.cpp:217] Pooling114 needs backward computation.
I0808 13:44:09.083427 20451 net.cpp:217] Convolution114 needs backward computation.
I0808 13:44:09.083434 20451 net.cpp:217] Pooling113 needs backward computation.
I0808 13:44:09.083442 20451 net.cpp:217] Convolution113 needs backward computation.
I0808 13:44:09.083454 20451 net.cpp:217] Pooling112 needs backward computation.
I0808 13:44:09.083462 20451 net.cpp:217] Convolution112 needs backward computation.
I0808 13:44:09.083472 20451 net.cpp:217] InnerProduct110 needs backward computation.
I0808 13:44:09.083479 20451 net.cpp:217] ReLU73 needs backward computation.
I0808 13:44:09.083487 20451 net.cpp:217] InnerProduct109 needs backward computation.
I0808 13:44:09.083495 20451 net.cpp:217] Pooling111 needs backward computation.
I0808 13:44:09.083503 20451 net.cpp:217] Convolution111 needs backward computation.
I0808 13:44:09.083513 20451 net.cpp:217] Pooling110 needs backward computation.
I0808 13:44:09.083520 20451 net.cpp:217] Convolution110 needs backward computation.
I0808 13:44:09.083528 20451 net.cpp:217] Pooling109 needs backward computation.
I0808 13:44:09.107765 20451 net.cpp:217] Convolution109 needs backward computation.
I0808 13:44:09.107795 20451 net.cpp:217] dt17 needs backward computation.
I0808 13:44:09.107815 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.107831 20451 net.cpp:217] ReLU72 needs backward computation.
I0808 13:44:09.107844 20451 net.cpp:217] InnerProduct108 needs backward computation.
I0808 13:44:09.107858 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.107872 20451 net.cpp:217] ReLU71 needs backward computation.
I0808 13:44:09.107887 20451 net.cpp:217] InnerProduct107 needs backward computation.
I0808 13:44:09.107893 20451 net.cpp:217] Concat18 needs backward computation.
I0808 13:44:09.107900 20451 net.cpp:217] InnerProduct106 needs backward computation.
I0808 13:44:09.107906 20451 net.cpp:217] ReLU70 needs backward computation.
I0808 13:44:09.107913 20451 net.cpp:217] InnerProduct105 needs backward computation.
I0808 13:44:09.107919 20451 net.cpp:217] Pooling108 needs backward computation.
I0808 13:44:09.107926 20451 net.cpp:217] Convolution108 needs backward computation.
I0808 13:44:09.107933 20451 net.cpp:217] Pooling107 needs backward computation.
I0808 13:44:09.107939 20451 net.cpp:217] Convolution107 needs backward computation.
I0808 13:44:09.107945 20451 net.cpp:217] Pooling106 needs backward computation.
I0808 13:44:09.107966 20451 net.cpp:217] Convolution106 needs backward computation.
I0808 13:44:09.107974 20451 net.cpp:217] InnerProduct104 needs backward computation.
I0808 13:44:09.107980 20451 net.cpp:217] ReLU69 needs backward computation.
I0808 13:44:09.107985 20451 net.cpp:217] InnerProduct103 needs backward computation.
I0808 13:44:09.107992 20451 net.cpp:217] Pooling105 needs backward computation.
I0808 13:44:09.107998 20451 net.cpp:217] Convolution105 needs backward computation.
I0808 13:44:09.108006 20451 net.cpp:217] Pooling104 needs backward computation.
I0808 13:44:09.108011 20451 net.cpp:217] Convolution104 needs backward computation.
I0808 13:44:09.108017 20451 net.cpp:217] Pooling103 needs backward computation.
I0808 13:44:09.108024 20451 net.cpp:217] Convolution103 needs backward computation.
I0808 13:44:09.108031 20451 net.cpp:217] dt16 needs backward computation.
I0808 13:44:09.108037 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.108044 20451 net.cpp:217] ReLU68 needs backward computation.
I0808 13:44:09.108050 20451 net.cpp:217] InnerProduct102 needs backward computation.
I0808 13:44:09.108057 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.108063 20451 net.cpp:217] ReLU67 needs backward computation.
I0808 13:44:09.108068 20451 net.cpp:217] InnerProduct101 needs backward computation.
I0808 13:44:09.108074 20451 net.cpp:217] Concat17 needs backward computation.
I0808 13:44:09.108083 20451 net.cpp:217] InnerProduct100 needs backward computation.
I0808 13:44:09.108088 20451 net.cpp:217] ReLU66 needs backward computation.
I0808 13:44:09.108094 20451 net.cpp:217] InnerProduct99 needs backward computation.
I0808 13:44:09.108101 20451 net.cpp:217] Pooling102 needs backward computation.
I0808 13:44:09.108108 20451 net.cpp:217] Convolution102 needs backward computation.
I0808 13:44:09.108114 20451 net.cpp:217] Pooling101 needs backward computation.
I0808 13:44:09.108120 20451 net.cpp:217] Convolution101 needs backward computation.
I0808 13:44:09.108127 20451 net.cpp:217] Pooling100 needs backward computation.
I0808 13:44:09.108134 20451 net.cpp:217] Convolution100 needs backward computation.
I0808 13:44:09.108140 20451 net.cpp:217] InnerProduct98 needs backward computation.
I0808 13:44:09.108147 20451 net.cpp:217] ReLU65 needs backward computation.
I0808 13:44:09.108153 20451 net.cpp:217] InnerProduct97 needs backward computation.
I0808 13:44:09.108160 20451 net.cpp:217] Pooling99 needs backward computation.
I0808 13:44:09.108166 20451 net.cpp:217] Convolution99 needs backward computation.
I0808 13:44:09.108172 20451 net.cpp:217] Pooling98 needs backward computation.
I0808 13:44:09.108180 20451 net.cpp:217] Convolution98 needs backward computation.
I0808 13:44:09.108186 20451 net.cpp:217] Pooling97 needs backward computation.
I0808 13:44:09.108192 20451 net.cpp:217] Convolution97 needs backward computation.
I0808 13:44:09.108201 20451 net.cpp:217] dt15 needs backward computation.
I0808 13:44:09.108206 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.108213 20451 net.cpp:217] ReLU64 needs backward computation.
I0808 13:44:09.108219 20451 net.cpp:217] InnerProduct96 needs backward computation.
I0808 13:44:09.108225 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.108232 20451 net.cpp:217] ReLU63 needs backward computation.
I0808 13:44:09.108238 20451 net.cpp:217] InnerProduct95 needs backward computation.
I0808 13:44:09.108244 20451 net.cpp:217] Concat16 needs backward computation.
I0808 13:44:09.108252 20451 net.cpp:217] InnerProduct94 needs backward computation.
I0808 13:44:09.108258 20451 net.cpp:217] ReLU62 needs backward computation.
I0808 13:44:09.108264 20451 net.cpp:217] InnerProduct93 needs backward computation.
I0808 13:44:09.108271 20451 net.cpp:217] Pooling96 needs backward computation.
I0808 13:44:09.108278 20451 net.cpp:217] Convolution96 needs backward computation.
I0808 13:44:09.108284 20451 net.cpp:217] Pooling95 needs backward computation.
I0808 13:44:09.108290 20451 net.cpp:217] Convolution95 needs backward computation.
I0808 13:44:09.108305 20451 net.cpp:217] Pooling94 needs backward computation.
I0808 13:44:09.108311 20451 net.cpp:217] Convolution94 needs backward computation.
I0808 13:44:09.108319 20451 net.cpp:217] InnerProduct92 needs backward computation.
I0808 13:44:09.108325 20451 net.cpp:217] ReLU61 needs backward computation.
I0808 13:44:09.108331 20451 net.cpp:217] InnerProduct91 needs backward computation.
I0808 13:44:09.108338 20451 net.cpp:217] Pooling93 needs backward computation.
I0808 13:44:09.108345 20451 net.cpp:217] Convolution93 needs backward computation.
I0808 13:44:09.108351 20451 net.cpp:217] Pooling92 needs backward computation.
I0808 13:44:09.108358 20451 net.cpp:217] Convolution92 needs backward computation.
I0808 13:44:09.108364 20451 net.cpp:217] Pooling91 needs backward computation.
I0808 13:44:09.108374 20451 net.cpp:217] Convolution91 needs backward computation.
I0808 13:44:09.108383 20451 net.cpp:217] dt14 needs backward computation.
I0808 13:44:09.108389 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.108397 20451 net.cpp:217] ReLU60 needs backward computation.
I0808 13:44:09.108402 20451 net.cpp:217] InnerProduct90 needs backward computation.
I0808 13:44:09.108409 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.108415 20451 net.cpp:217] ReLU59 needs backward computation.
I0808 13:44:09.108422 20451 net.cpp:217] InnerProduct89 needs backward computation.
I0808 13:44:09.108428 20451 net.cpp:217] Concat15 needs backward computation.
I0808 13:44:09.108435 20451 net.cpp:217] InnerProduct88 needs backward computation.
I0808 13:44:09.108443 20451 net.cpp:217] ReLU58 needs backward computation.
I0808 13:44:09.108448 20451 net.cpp:217] InnerProduct87 needs backward computation.
I0808 13:44:09.108454 20451 net.cpp:217] Pooling90 needs backward computation.
I0808 13:44:09.108461 20451 net.cpp:217] Convolution90 needs backward computation.
I0808 13:44:09.108467 20451 net.cpp:217] Pooling89 needs backward computation.
I0808 13:44:09.108474 20451 net.cpp:217] Convolution89 needs backward computation.
I0808 13:44:09.108480 20451 net.cpp:217] Pooling88 needs backward computation.
I0808 13:44:09.108487 20451 net.cpp:217] Convolution88 needs backward computation.
I0808 13:44:09.108494 20451 net.cpp:217] InnerProduct86 needs backward computation.
I0808 13:44:09.108501 20451 net.cpp:217] ReLU57 needs backward computation.
I0808 13:44:09.108507 20451 net.cpp:217] InnerProduct85 needs backward computation.
I0808 13:44:09.108513 20451 net.cpp:217] Pooling87 needs backward computation.
I0808 13:44:09.108520 20451 net.cpp:217] Convolution87 needs backward computation.
I0808 13:44:09.138419 20451 net.cpp:217] Pooling86 needs backward computation.
I0808 13:44:09.138448 20451 net.cpp:217] Convolution86 needs backward computation.
I0808 13:44:09.138465 20451 net.cpp:217] Pooling85 needs backward computation.
I0808 13:44:09.138483 20451 net.cpp:217] Convolution85 needs backward computation.
I0808 13:44:09.138502 20451 net.cpp:217] dt13 needs backward computation.
I0808 13:44:09.138520 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.138536 20451 net.cpp:217] ReLU56 needs backward computation.
I0808 13:44:09.138550 20451 net.cpp:217] InnerProduct84 needs backward computation.
I0808 13:44:09.138564 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.138577 20451 net.cpp:217] ReLU55 needs backward computation.
I0808 13:44:09.138591 20451 net.cpp:217] InnerProduct83 needs backward computation.
I0808 13:44:09.138604 20451 net.cpp:217] Concat14 needs backward computation.
I0808 13:44:09.138620 20451 net.cpp:217] InnerProduct82 needs backward computation.
I0808 13:44:09.138643 20451 net.cpp:217] ReLU54 needs backward computation.
I0808 13:44:09.138655 20451 net.cpp:217] InnerProduct81 needs backward computation.
I0808 13:44:09.138669 20451 net.cpp:217] Pooling84 needs backward computation.
I0808 13:44:09.138684 20451 net.cpp:217] Convolution84 needs backward computation.
I0808 13:44:09.138697 20451 net.cpp:217] Pooling83 needs backward computation.
I0808 13:44:09.138736 20451 net.cpp:217] Convolution83 needs backward computation.
I0808 13:44:09.138751 20451 net.cpp:217] Pooling82 needs backward computation.
I0808 13:44:09.138766 20451 net.cpp:217] Convolution82 needs backward computation.
I0808 13:44:09.138780 20451 net.cpp:217] InnerProduct80 needs backward computation.
I0808 13:44:09.138794 20451 net.cpp:217] ReLU53 needs backward computation.
I0808 13:44:09.138808 20451 net.cpp:217] InnerProduct79 needs backward computation.
I0808 13:44:09.138821 20451 net.cpp:217] Pooling81 needs backward computation.
I0808 13:44:09.138835 20451 net.cpp:217] Convolution81 needs backward computation.
I0808 13:44:09.138849 20451 net.cpp:217] Pooling80 needs backward computation.
I0808 13:44:09.138864 20451 net.cpp:217] Convolution80 needs backward computation.
I0808 13:44:09.138877 20451 net.cpp:217] Pooling79 needs backward computation.
I0808 13:44:09.138890 20451 net.cpp:217] Convolution79 needs backward computation.
I0808 13:44:09.138906 20451 net.cpp:217] dt12 needs backward computation.
I0808 13:44:09.138921 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.138933 20451 net.cpp:217] ReLU52 needs backward computation.
I0808 13:44:09.138947 20451 net.cpp:217] InnerProduct78 needs backward computation.
I0808 13:44:09.138960 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.138973 20451 net.cpp:217] ReLU51 needs backward computation.
I0808 13:44:09.138988 20451 net.cpp:217] InnerProduct77 needs backward computation.
I0808 13:44:09.139001 20451 net.cpp:217] Concat13 needs backward computation.
I0808 13:44:09.139016 20451 net.cpp:217] InnerProduct76 needs backward computation.
I0808 13:44:09.139030 20451 net.cpp:217] ReLU50 needs backward computation.
I0808 13:44:09.139044 20451 net.cpp:217] InnerProduct75 needs backward computation.
I0808 13:44:09.139057 20451 net.cpp:217] Pooling78 needs backward computation.
I0808 13:44:09.139071 20451 net.cpp:217] Convolution78 needs backward computation.
I0808 13:44:09.139086 20451 net.cpp:217] Pooling77 needs backward computation.
I0808 13:44:09.139099 20451 net.cpp:217] Convolution77 needs backward computation.
I0808 13:44:09.139113 20451 net.cpp:217] Pooling76 needs backward computation.
I0808 13:44:09.139127 20451 net.cpp:217] Convolution76 needs backward computation.
I0808 13:44:09.139142 20451 net.cpp:217] InnerProduct74 needs backward computation.
I0808 13:44:09.139155 20451 net.cpp:217] ReLU49 needs backward computation.
I0808 13:44:09.139168 20451 net.cpp:217] InnerProduct73 needs backward computation.
I0808 13:44:09.139183 20451 net.cpp:217] Pooling75 needs backward computation.
I0808 13:44:09.139196 20451 net.cpp:217] Convolution75 needs backward computation.
I0808 13:44:09.139210 20451 net.cpp:217] Pooling74 needs backward computation.
I0808 13:44:09.139225 20451 net.cpp:217] Convolution74 needs backward computation.
I0808 13:44:09.139237 20451 net.cpp:217] Pooling73 needs backward computation.
I0808 13:44:09.139251 20451 net.cpp:217] Convolution73 needs backward computation.
I0808 13:44:09.139266 20451 net.cpp:217] dt11 needs backward computation.
I0808 13:44:09.139313 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.139328 20451 net.cpp:217] ReLU48 needs backward computation.
I0808 13:44:09.139341 20451 net.cpp:217] InnerProduct72 needs backward computation.
I0808 13:44:09.139354 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.139369 20451 net.cpp:217] ReLU47 needs backward computation.
I0808 13:44:09.139381 20451 net.cpp:217] InnerProduct71 needs backward computation.
I0808 13:44:09.139395 20451 net.cpp:217] Concat12 needs backward computation.
I0808 13:44:09.139410 20451 net.cpp:217] InnerProduct70 needs backward computation.
I0808 13:44:09.139425 20451 net.cpp:217] ReLU46 needs backward computation.
I0808 13:44:09.139437 20451 net.cpp:217] InnerProduct69 needs backward computation.
I0808 13:44:09.139457 20451 net.cpp:217] Pooling72 needs backward computation.
I0808 13:44:09.139472 20451 net.cpp:217] Convolution72 needs backward computation.
I0808 13:44:09.139506 20451 net.cpp:217] Pooling71 needs backward computation.
I0808 13:44:09.139521 20451 net.cpp:217] Convolution71 needs backward computation.
I0808 13:44:09.139535 20451 net.cpp:217] Pooling70 needs backward computation.
I0808 13:44:09.139549 20451 net.cpp:217] Convolution70 needs backward computation.
I0808 13:44:09.139564 20451 net.cpp:217] InnerProduct68 needs backward computation.
I0808 13:44:09.139577 20451 net.cpp:217] ReLU45 needs backward computation.
I0808 13:44:09.139590 20451 net.cpp:217] InnerProduct67 needs backward computation.
I0808 13:44:09.139605 20451 net.cpp:217] Pooling69 needs backward computation.
I0808 13:44:09.139618 20451 net.cpp:217] Convolution69 needs backward computation.
I0808 13:44:09.139632 20451 net.cpp:217] Pooling68 needs backward computation.
I0808 13:44:09.139647 20451 net.cpp:217] Convolution68 needs backward computation.
I0808 13:44:09.139660 20451 net.cpp:217] Pooling67 needs backward computation.
I0808 13:44:09.139674 20451 net.cpp:217] Convolution67 needs backward computation.
I0808 13:44:09.139690 20451 net.cpp:217] dt10 needs backward computation.
I0808 13:44:09.139703 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.139717 20451 net.cpp:217] ReLU44 needs backward computation.
I0808 13:44:09.139730 20451 net.cpp:217] InnerProduct66 needs backward computation.
I0808 13:44:09.139744 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.139757 20451 net.cpp:217] ReLU43 needs backward computation.
I0808 13:44:09.139770 20451 net.cpp:217] InnerProduct65 needs backward computation.
I0808 13:44:09.139785 20451 net.cpp:217] Concat11 needs backward computation.
I0808 13:44:09.139798 20451 net.cpp:217] InnerProduct64 needs backward computation.
I0808 13:44:09.139812 20451 net.cpp:217] ReLU42 needs backward computation.
I0808 13:44:09.139827 20451 net.cpp:217] InnerProduct63 needs backward computation.
I0808 13:44:09.139839 20451 net.cpp:217] Pooling66 needs backward computation.
I0808 13:44:09.139854 20451 net.cpp:217] Convolution66 needs backward computation.
I0808 13:44:09.139868 20451 net.cpp:217] Pooling65 needs backward computation.
I0808 13:44:09.139883 20451 net.cpp:217] Convolution65 needs backward computation.
I0808 13:44:09.139896 20451 net.cpp:217] Pooling64 needs backward computation.
I0808 13:44:09.139910 20451 net.cpp:217] Convolution64 needs backward computation.
I0808 13:44:09.139925 20451 net.cpp:217] InnerProduct62 needs backward computation.
I0808 13:44:09.139940 20451 net.cpp:217] ReLU41 needs backward computation.
I0808 13:44:09.139952 20451 net.cpp:217] InnerProduct61 needs backward computation.
I0808 13:44:09.144731 20451 net.cpp:217] Pooling63 needs backward computation.
I0808 13:44:09.144762 20451 net.cpp:217] Convolution63 needs backward computation.
I0808 13:44:09.144780 20451 net.cpp:217] Pooling62 needs backward computation.
I0808 13:44:09.144796 20451 net.cpp:217] Convolution62 needs backward computation.
I0808 13:44:09.144810 20451 net.cpp:217] Pooling61 needs backward computation.
I0808 13:44:09.144825 20451 net.cpp:217] Convolution61 needs backward computation.
I0808 13:44:09.144842 20451 net.cpp:217] dt9 needs backward computation.
I0808 13:44:09.144857 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.144872 20451 net.cpp:217] ReLU40 needs backward computation.
I0808 13:44:09.144886 20451 net.cpp:217] InnerProduct60 needs backward computation.
I0808 13:44:09.144899 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.144913 20451 net.cpp:217] ReLU39 needs backward computation.
I0808 13:44:09.144927 20451 net.cpp:217] InnerProduct59 needs backward computation.
I0808 13:44:09.144940 20451 net.cpp:217] Concat10 needs backward computation.
I0808 13:44:09.144956 20451 net.cpp:217] InnerProduct58 needs backward computation.
I0808 13:44:09.144970 20451 net.cpp:217] ReLU38 needs backward computation.
I0808 13:44:09.144984 20451 net.cpp:217] InnerProduct57 needs backward computation.
I0808 13:44:09.144999 20451 net.cpp:217] Pooling60 needs backward computation.
I0808 13:44:09.145040 20451 net.cpp:217] Convolution60 needs backward computation.
I0808 13:44:09.145054 20451 net.cpp:217] Pooling59 needs backward computation.
I0808 13:44:09.145068 20451 net.cpp:217] Convolution59 needs backward computation.
I0808 13:44:09.145082 20451 net.cpp:217] Pooling58 needs backward computation.
I0808 13:44:09.145097 20451 net.cpp:217] Convolution58 needs backward computation.
I0808 13:44:09.145112 20451 net.cpp:217] InnerProduct56 needs backward computation.
I0808 13:44:09.145125 20451 net.cpp:217] ReLU37 needs backward computation.
I0808 13:44:09.145138 20451 net.cpp:217] InnerProduct55 needs backward computation.
I0808 13:44:09.145153 20451 net.cpp:217] Pooling57 needs backward computation.
I0808 13:44:09.145166 20451 net.cpp:217] Convolution57 needs backward computation.
I0808 13:44:09.145180 20451 net.cpp:217] Pooling56 needs backward computation.
I0808 13:44:09.145195 20451 net.cpp:217] Convolution56 needs backward computation.
I0808 13:44:09.145210 20451 net.cpp:217] Pooling55 needs backward computation.
I0808 13:44:09.145223 20451 net.cpp:217] Convolution55 needs backward computation.
I0808 13:44:09.145238 20451 net.cpp:217] dt8 needs backward computation.
I0808 13:44:09.145253 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.145267 20451 net.cpp:217] ReLU36 needs backward computation.
I0808 13:44:09.145280 20451 net.cpp:217] InnerProduct54 needs backward computation.
I0808 13:44:09.145293 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.145308 20451 net.cpp:217] ReLU35 needs backward computation.
I0808 13:44:09.145320 20451 net.cpp:217] InnerProduct53 needs backward computation.
I0808 13:44:09.145334 20451 net.cpp:217] Concat9 needs backward computation.
I0808 13:44:09.145349 20451 net.cpp:217] InnerProduct52 needs backward computation.
I0808 13:44:09.145364 20451 net.cpp:217] ReLU34 needs backward computation.
I0808 13:44:09.145376 20451 net.cpp:217] InnerProduct51 needs backward computation.
I0808 13:44:09.145390 20451 net.cpp:217] Pooling54 needs backward computation.
I0808 13:44:09.145406 20451 net.cpp:217] Convolution54 needs backward computation.
I0808 13:44:09.145419 20451 net.cpp:217] Pooling53 needs backward computation.
I0808 13:44:09.145433 20451 net.cpp:217] Convolution53 needs backward computation.
I0808 13:44:09.145447 20451 net.cpp:217] Pooling52 needs backward computation.
I0808 13:44:09.145462 20451 net.cpp:217] Convolution52 needs backward computation.
I0808 13:44:09.145478 20451 net.cpp:217] InnerProduct50 needs backward computation.
I0808 13:44:09.145491 20451 net.cpp:217] ReLU33 needs backward computation.
I0808 13:44:09.145505 20451 net.cpp:217] InnerProduct49 needs backward computation.
I0808 13:44:09.145519 20451 net.cpp:217] Pooling51 needs backward computation.
I0808 13:44:09.145541 20451 net.cpp:217] Convolution51 needs backward computation.
I0808 13:44:09.145555 20451 net.cpp:217] Pooling50 needs backward computation.
I0808 13:44:09.145570 20451 net.cpp:217] Convolution50 needs backward computation.
I0808 13:44:09.145583 20451 net.cpp:217] Pooling49 needs backward computation.
I0808 13:44:09.145601 20451 net.cpp:217] Convolution49 needs backward computation.
I0808 13:44:09.145620 20451 net.cpp:217] dt7 needs backward computation.
I0808 13:44:09.145638 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.145668 20451 net.cpp:217] ReLU32 needs backward computation.
I0808 13:44:09.145683 20451 net.cpp:217] InnerProduct48 needs backward computation.
I0808 13:44:09.145699 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.145715 20451 net.cpp:217] ReLU31 needs backward computation.
I0808 13:44:09.145731 20451 net.cpp:217] InnerProduct47 needs backward computation.
I0808 13:44:09.145747 20451 net.cpp:217] Concat8 needs backward computation.
I0808 13:44:09.145766 20451 net.cpp:217] InnerProduct46 needs backward computation.
I0808 13:44:09.145782 20451 net.cpp:217] ReLU30 needs backward computation.
I0808 13:44:09.145800 20451 net.cpp:217] InnerProduct45 needs backward computation.
I0808 13:44:09.145818 20451 net.cpp:217] Pooling48 needs backward computation.
I0808 13:44:09.145859 20451 net.cpp:217] Convolution48 needs backward computation.
I0808 13:44:09.145874 20451 net.cpp:217] Pooling47 needs backward computation.
I0808 13:44:09.145889 20451 net.cpp:217] Convolution47 needs backward computation.
I0808 13:44:09.145905 20451 net.cpp:217] Pooling46 needs backward computation.
I0808 13:44:09.145923 20451 net.cpp:217] Convolution46 needs backward computation.
I0808 13:44:09.145942 20451 net.cpp:217] InnerProduct44 needs backward computation.
I0808 13:44:09.145959 20451 net.cpp:217] ReLU29 needs backward computation.
I0808 13:44:09.145974 20451 net.cpp:217] InnerProduct43 needs backward computation.
I0808 13:44:09.145990 20451 net.cpp:217] Pooling45 needs backward computation.
I0808 13:44:09.146005 20451 net.cpp:217] Convolution45 needs backward computation.
I0808 13:44:09.146021 20451 net.cpp:217] Pooling44 needs backward computation.
I0808 13:44:09.146036 20451 net.cpp:217] Convolution44 needs backward computation.
I0808 13:44:09.146052 20451 net.cpp:217] Pooling43 needs backward computation.
I0808 13:44:09.146067 20451 net.cpp:217] Convolution43 needs backward computation.
I0808 13:44:09.146085 20451 net.cpp:217] dt6 needs backward computation.
I0808 13:44:09.146100 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.146117 20451 net.cpp:217] ReLU28 needs backward computation.
I0808 13:44:09.146132 20451 net.cpp:217] InnerProduct42 needs backward computation.
I0808 13:44:09.146149 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.146173 20451 net.cpp:217] ReLU27 needs backward computation.
I0808 13:44:09.146189 20451 net.cpp:217] InnerProduct41 needs backward computation.
I0808 13:44:09.146206 20451 net.cpp:217] Concat7 needs backward computation.
I0808 13:44:09.146225 20451 net.cpp:217] InnerProduct40 needs backward computation.
I0808 13:44:09.146242 20451 net.cpp:217] ReLU26 needs backward computation.
I0808 13:44:09.146260 20451 net.cpp:217] InnerProduct39 needs backward computation.
I0808 13:44:09.146277 20451 net.cpp:217] Pooling42 needs backward computation.
I0808 13:44:09.146294 20451 net.cpp:217] Convolution42 needs backward computation.
I0808 13:44:09.146312 20451 net.cpp:217] Pooling41 needs backward computation.
I0808 13:44:09.146329 20451 net.cpp:217] Convolution41 needs backward computation.
I0808 13:44:09.146348 20451 net.cpp:217] Pooling40 needs backward computation.
I0808 13:44:09.146368 20451 net.cpp:217] Convolution40 needs backward computation.
I0808 13:44:09.146389 20451 net.cpp:217] InnerProduct38 needs backward computation.
I0808 13:44:09.169122 20451 net.cpp:217] ReLU25 needs backward computation.
I0808 13:44:09.169152 20451 net.cpp:217] InnerProduct37 needs backward computation.
I0808 13:44:09.169169 20451 net.cpp:217] Pooling39 needs backward computation.
I0808 13:44:09.169185 20451 net.cpp:217] Convolution39 needs backward computation.
I0808 13:44:09.169201 20451 net.cpp:217] Pooling38 needs backward computation.
I0808 13:44:09.169216 20451 net.cpp:217] Convolution38 needs backward computation.
I0808 13:44:09.169230 20451 net.cpp:217] Pooling37 needs backward computation.
I0808 13:44:09.169245 20451 net.cpp:217] Convolution37 needs backward computation.
I0808 13:44:09.169262 20451 net.cpp:217] dt5 needs backward computation.
I0808 13:44:09.169277 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.169292 20451 net.cpp:217] ReLU24 needs backward computation.
I0808 13:44:09.169306 20451 net.cpp:217] InnerProduct36 needs backward computation.
I0808 13:44:09.169320 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.169333 20451 net.cpp:217] ReLU23 needs backward computation.
I0808 13:44:09.169348 20451 net.cpp:217] InnerProduct35 needs backward computation.
I0808 13:44:09.169361 20451 net.cpp:217] Concat6 needs backward computation.
I0808 13:44:09.169376 20451 net.cpp:217] InnerProduct34 needs backward computation.
I0808 13:44:09.169390 20451 net.cpp:217] ReLU22 needs backward computation.
I0808 13:44:09.169404 20451 net.cpp:217] InnerProduct33 needs backward computation.
I0808 13:44:09.169445 20451 net.cpp:217] Pooling36 needs backward computation.
I0808 13:44:09.169459 20451 net.cpp:217] Convolution36 needs backward computation.
I0808 13:44:09.169473 20451 net.cpp:217] Pooling35 needs backward computation.
I0808 13:44:09.169487 20451 net.cpp:217] Convolution35 needs backward computation.
I0808 13:44:09.169502 20451 net.cpp:217] Pooling34 needs backward computation.
I0808 13:44:09.169515 20451 net.cpp:217] Convolution34 needs backward computation.
I0808 13:44:09.169531 20451 net.cpp:217] InnerProduct32 needs backward computation.
I0808 13:44:09.169545 20451 net.cpp:217] ReLU21 needs backward computation.
I0808 13:44:09.169559 20451 net.cpp:217] InnerProduct31 needs backward computation.
I0808 13:44:09.169572 20451 net.cpp:217] Pooling33 needs backward computation.
I0808 13:44:09.169586 20451 net.cpp:217] Convolution33 needs backward computation.
I0808 13:44:09.169600 20451 net.cpp:217] Pooling32 needs backward computation.
I0808 13:44:09.169615 20451 net.cpp:217] Convolution32 needs backward computation.
I0808 13:44:09.169627 20451 net.cpp:217] Pooling31 needs backward computation.
I0808 13:44:09.169641 20451 net.cpp:217] Convolution31 needs backward computation.
I0808 13:44:09.169657 20451 net.cpp:217] dt4 needs backward computation.
I0808 13:44:09.169672 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.169687 20451 net.cpp:217] ReLU20 needs backward computation.
I0808 13:44:09.169699 20451 net.cpp:217] InnerProduct30 needs backward computation.
I0808 13:44:09.169713 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.169734 20451 net.cpp:217] ReLU19 needs backward computation.
I0808 13:44:09.169747 20451 net.cpp:217] InnerProduct29 needs backward computation.
I0808 13:44:09.169762 20451 net.cpp:217] Concat5 needs backward computation.
I0808 13:44:09.169778 20451 net.cpp:217] InnerProduct28 needs backward computation.
I0808 13:44:09.169792 20451 net.cpp:217] ReLU18 needs backward computation.
I0808 13:44:09.169806 20451 net.cpp:217] InnerProduct27 needs backward computation.
I0808 13:44:09.169821 20451 net.cpp:217] Pooling30 needs backward computation.
I0808 13:44:09.169834 20451 net.cpp:217] Convolution30 needs backward computation.
I0808 13:44:09.169848 20451 net.cpp:217] Pooling29 needs backward computation.
I0808 13:44:09.169862 20451 net.cpp:217] Convolution29 needs backward computation.
I0808 13:44:09.169877 20451 net.cpp:217] Pooling28 needs backward computation.
I0808 13:44:09.169891 20451 net.cpp:217] Convolution28 needs backward computation.
I0808 13:44:09.169910 20451 net.cpp:217] InnerProduct26 needs backward computation.
I0808 13:44:09.169924 20451 net.cpp:217] ReLU17 needs backward computation.
I0808 13:44:09.169937 20451 net.cpp:217] InnerProduct25 needs backward computation.
I0808 13:44:09.169951 20451 net.cpp:217] Pooling27 needs backward computation.
I0808 13:44:09.169966 20451 net.cpp:217] Convolution27 needs backward computation.
I0808 13:44:09.169981 20451 net.cpp:217] Pooling26 needs backward computation.
I0808 13:44:09.169994 20451 net.cpp:217] Convolution26 needs backward computation.
I0808 13:44:09.170008 20451 net.cpp:217] Pooling25 needs backward computation.
I0808 13:44:09.170022 20451 net.cpp:217] Convolution25 needs backward computation.
I0808 13:44:09.170038 20451 net.cpp:217] dt3 needs backward computation.
I0808 13:44:09.170053 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.170066 20451 net.cpp:217] ReLU16 needs backward computation.
I0808 13:44:09.170080 20451 net.cpp:217] InnerProduct24 needs backward computation.
I0808 13:44:09.170094 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.170107 20451 net.cpp:217] ReLU15 needs backward computation.
I0808 13:44:09.170121 20451 net.cpp:217] InnerProduct23 needs backward computation.
I0808 13:44:09.170135 20451 net.cpp:217] Concat4 needs backward computation.
I0808 13:44:09.170150 20451 net.cpp:217] InnerProduct22 needs backward computation.
I0808 13:44:09.170164 20451 net.cpp:217] ReLU14 needs backward computation.
I0808 13:44:09.170197 20451 net.cpp:217] InnerProduct21 needs backward computation.
I0808 13:44:09.170212 20451 net.cpp:217] Pooling24 needs backward computation.
I0808 13:44:09.170228 20451 net.cpp:217] Convolution24 needs backward computation.
I0808 13:44:09.170241 20451 net.cpp:217] Pooling23 needs backward computation.
I0808 13:44:09.170256 20451 net.cpp:217] Convolution23 needs backward computation.
I0808 13:44:09.170269 20451 net.cpp:217] Pooling22 needs backward computation.
I0808 13:44:09.170284 20451 net.cpp:217] Convolution22 needs backward computation.
I0808 13:44:09.170300 20451 net.cpp:217] InnerProduct20 needs backward computation.
I0808 13:44:09.170313 20451 net.cpp:217] ReLU13 needs backward computation.
I0808 13:44:09.170326 20451 net.cpp:217] InnerProduct19 needs backward computation.
I0808 13:44:09.170341 20451 net.cpp:217] Pooling21 needs backward computation.
I0808 13:44:09.170356 20451 net.cpp:217] Convolution21 needs backward computation.
I0808 13:44:09.170369 20451 net.cpp:217] Pooling20 needs backward computation.
I0808 13:44:09.170383 20451 net.cpp:217] Convolution20 needs backward computation.
I0808 13:44:09.170397 20451 net.cpp:217] Pooling19 needs backward computation.
I0808 13:44:09.170411 20451 net.cpp:217] Convolution19 needs backward computation.
I0808 13:44:09.170428 20451 net.cpp:217] dt2 needs backward computation.
I0808 13:44:09.170441 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.170455 20451 net.cpp:217] ReLU12 needs backward computation.
I0808 13:44:09.170469 20451 net.cpp:217] InnerProduct18 needs backward computation.
I0808 13:44:09.170482 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.170496 20451 net.cpp:217] ReLU11 needs backward computation.
I0808 13:44:09.170509 20451 net.cpp:217] InnerProduct17 needs backward computation.
I0808 13:44:09.170523 20451 net.cpp:217] Concat3 needs backward computation.
I0808 13:44:09.170538 20451 net.cpp:217] InnerProduct16 needs backward computation.
I0808 13:44:09.170552 20451 net.cpp:217] ReLU10 needs backward computation.
I0808 13:44:09.170565 20451 net.cpp:217] InnerProduct15 needs backward computation.
I0808 13:44:09.170579 20451 net.cpp:217] Pooling18 needs backward computation.
I0808 13:44:09.170594 20451 net.cpp:217] Convolution18 needs backward computation.
I0808 13:44:09.170608 20451 net.cpp:217] Pooling17 needs backward computation.
I0808 13:44:09.170622 20451 net.cpp:217] Convolution17 needs backward computation.
I0808 13:44:09.170636 20451 net.cpp:217] Pooling16 needs backward computation.
I0808 13:44:09.199812 20451 net.cpp:217] Convolution16 needs backward computation.
I0808 13:44:09.199843 20451 net.cpp:217] InnerProduct14 needs backward computation.
I0808 13:44:09.199862 20451 net.cpp:217] ReLU9 needs backward computation.
I0808 13:44:09.199877 20451 net.cpp:217] InnerProduct13 needs backward computation.
I0808 13:44:09.199898 20451 net.cpp:217] Pooling15 needs backward computation.
I0808 13:44:09.199915 20451 net.cpp:217] Convolution15 needs backward computation.
I0808 13:44:09.199930 20451 net.cpp:217] Pooling14 needs backward computation.
I0808 13:44:09.199945 20451 net.cpp:217] Convolution14 needs backward computation.
I0808 13:44:09.199959 20451 net.cpp:217] Pooling13 needs backward computation.
I0808 13:44:09.199975 20451 net.cpp:217] Convolution13 needs backward computation.
I0808 13:44:09.199991 20451 net.cpp:217] dt1 needs backward computation.
I0808 13:44:09.200006 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.200021 20451 net.cpp:217] ReLU8 needs backward computation.
I0808 13:44:09.200036 20451 net.cpp:217] InnerProduct12 needs backward computation.
I0808 13:44:09.200049 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.200064 20451 net.cpp:217] ReLU7 needs backward computation.
I0808 13:44:09.200078 20451 net.cpp:217] InnerProduct11 needs backward computation.
I0808 13:44:09.200093 20451 net.cpp:217] Concat2 needs backward computation.
I0808 13:44:09.200109 20451 net.cpp:217] InnerProduct10 needs backward computation.
I0808 13:44:09.200150 20451 net.cpp:217] ReLU6 needs backward computation.
I0808 13:44:09.200163 20451 net.cpp:217] InnerProduct9 needs backward computation.
I0808 13:44:09.200177 20451 net.cpp:217] Pooling12 needs backward computation.
I0808 13:44:09.200192 20451 net.cpp:217] Convolution12 needs backward computation.
I0808 13:44:09.200206 20451 net.cpp:217] Pooling11 needs backward computation.
I0808 13:44:09.200222 20451 net.cpp:217] Convolution11 needs backward computation.
I0808 13:44:09.200235 20451 net.cpp:217] Pooling10 needs backward computation.
I0808 13:44:09.200250 20451 net.cpp:217] Convolution10 needs backward computation.
I0808 13:44:09.200273 20451 net.cpp:217] InnerProduct8 needs backward computation.
I0808 13:44:09.200289 20451 net.cpp:217] ReLU5 needs backward computation.
I0808 13:44:09.200301 20451 net.cpp:217] InnerProduct7 needs backward computation.
I0808 13:44:09.200315 20451 net.cpp:217] Pooling9 needs backward computation.
I0808 13:44:09.200330 20451 net.cpp:217] Convolution9 needs backward computation.
I0808 13:44:09.200345 20451 net.cpp:217] Pooling8 needs backward computation.
I0808 13:44:09.200358 20451 net.cpp:217] Convolution8 needs backward computation.
I0808 13:44:09.200373 20451 net.cpp:217] Pooling7 needs backward computation.
I0808 13:44:09.200387 20451 net.cpp:217] Convolution7 needs backward computation.
I0808 13:44:09.200403 20451 net.cpp:217] dt0 needs backward computation.
I0808 13:44:09.200417 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:09.200433 20451 net.cpp:217] ReLU4 needs backward computation.
I0808 13:44:09.200445 20451 net.cpp:217] InnerProduct6 needs backward computation.
I0808 13:44:09.200459 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:09.200472 20451 net.cpp:217] ReLU3 needs backward computation.
I0808 13:44:09.200485 20451 net.cpp:217] InnerProduct5 needs backward computation.
I0808 13:44:09.200500 20451 net.cpp:217] Concat1 needs backward computation.
I0808 13:44:09.200515 20451 net.cpp:217] InnerProduct4 needs backward computation.
I0808 13:44:09.200530 20451 net.cpp:217] ReLU2 needs backward computation.
I0808 13:44:09.200542 20451 net.cpp:217] InnerProduct3 needs backward computation.
I0808 13:44:09.200556 20451 net.cpp:217] Pooling6 needs backward computation.
I0808 13:44:09.200570 20451 net.cpp:217] Convolution6 needs backward computation.
I0808 13:44:09.200584 20451 net.cpp:217] Pooling5 needs backward computation.
I0808 13:44:09.200598 20451 net.cpp:217] Convolution5 needs backward computation.
I0808 13:44:09.200613 20451 net.cpp:217] Pooling4 needs backward computation.
I0808 13:44:09.200628 20451 net.cpp:217] Convolution4 needs backward computation.
I0808 13:44:09.200644 20451 net.cpp:217] InnerProduct2 needs backward computation.
I0808 13:44:09.200657 20451 net.cpp:217] ReLU1 needs backward computation.
I0808 13:44:09.200670 20451 net.cpp:217] InnerProduct1 needs backward computation.
I0808 13:44:09.200685 20451 net.cpp:217] Pooling3 needs backward computation.
I0808 13:44:09.200698 20451 net.cpp:217] Convolution3 needs backward computation.
I0808 13:44:09.200712 20451 net.cpp:217] Pooling2 needs backward computation.
I0808 13:44:09.200726 20451 net.cpp:217] Convolution2 needs backward computation.
I0808 13:44:09.200741 20451 net.cpp:217] Pooling1 needs backward computation.
I0808 13:44:09.200755 20451 net.cpp:217] Convolution1 needs backward computation.
I0808 13:44:09.200772 20451 net.cpp:219] c29 does not need backward computation.
I0808 13:44:09.200788 20451 net.cpp:219] Input18 does not need backward computation.
I0808 13:44:09.200800 20451 net.cpp:219] c28 does not need backward computation.
I0808 13:44:09.200819 20451 net.cpp:219] Input17 does not need backward computation.
I0808 13:44:09.200830 20451 net.cpp:219] c27 does not need backward computation.
I0808 13:44:09.200847 20451 net.cpp:219] Input16 does not need backward computation.
I0808 13:44:09.200860 20451 net.cpp:219] c26 does not need backward computation.
I0808 13:44:09.200877 20451 net.cpp:219] Input15 does not need backward computation.
I0808 13:44:09.200906 20451 net.cpp:219] c25 does not need backward computation.
I0808 13:44:09.200924 20451 net.cpp:219] Input14 does not need backward computation.
I0808 13:44:09.200937 20451 net.cpp:219] c24 does not need backward computation.
I0808 13:44:09.200953 20451 net.cpp:219] Input13 does not need backward computation.
I0808 13:44:09.200966 20451 net.cpp:219] c23 does not need backward computation.
I0808 13:44:09.200983 20451 net.cpp:219] Input12 does not need backward computation.
I0808 13:44:09.200995 20451 net.cpp:219] c22 does not need backward computation.
I0808 13:44:09.201011 20451 net.cpp:219] Input11 does not need backward computation.
I0808 13:44:09.201025 20451 net.cpp:219] c21 does not need backward computation.
I0808 13:44:09.201040 20451 net.cpp:219] Input10 does not need backward computation.
I0808 13:44:09.201053 20451 net.cpp:219] c19 does not need backward computation.
I0808 13:44:09.201071 20451 net.cpp:219] Input9 does not need backward computation.
I0808 13:44:09.201083 20451 net.cpp:219] c18 does not need backward computation.
I0808 13:44:09.201100 20451 net.cpp:219] Input8 does not need backward computation.
I0808 13:44:09.201113 20451 net.cpp:219] c17 does not need backward computation.
I0808 13:44:09.201130 20451 net.cpp:219] Input7 does not need backward computation.
I0808 13:44:09.201143 20451 net.cpp:219] c16 does not need backward computation.
I0808 13:44:09.201164 20451 net.cpp:219] Input6 does not need backward computation.
I0808 13:44:09.201176 20451 net.cpp:219] c15 does not need backward computation.
I0808 13:44:09.201194 20451 net.cpp:219] Input5 does not need backward computation.
I0808 13:44:09.201205 20451 net.cpp:219] c14 does not need backward computation.
I0808 13:44:09.201222 20451 net.cpp:219] Input4 does not need backward computation.
I0808 13:44:09.201234 20451 net.cpp:219] c13 does not need backward computation.
I0808 13:44:09.201251 20451 net.cpp:219] Input3 does not need backward computation.
I0808 13:44:09.201264 20451 net.cpp:219] c12 does not need backward computation.
I0808 13:44:09.201280 20451 net.cpp:219] Input2 does not need backward computation.
I0808 13:44:09.201293 20451 net.cpp:219] c11 does not need backward computation.
I0808 13:44:09.201310 20451 net.cpp:219] Input1 does not need backward computation.
I0808 13:44:09.201328 20451 net.cpp:219] p2_p2_0_split does not need backward computation.
I0808 13:44:09.201344 20451 net.cpp:219] p2 does not need backward computation.
I0808 13:44:09.204442 20451 net.cpp:219] p1_p1_0_split does not need backward computation.
I0808 13:44:09.204460 20451 net.cpp:219] p1 does not need backward computation.
I0808 13:44:09.204478 20451 net.cpp:219] i2_i1_1_split does not need backward computation.
I0808 13:44:09.204493 20451 net.cpp:219] i1_i1_0_split does not need backward computation.
I0808 13:44:09.204504 20451 net.cpp:219] i1 does not need backward computation.
I0808 13:44:09.204516 20451 net.cpp:219] th_th_0_split does not need backward computation.
I0808 13:44:09.204527 20451 net.cpp:219] th does not need backward computation.
I0808 13:44:09.204537 20451 net.cpp:219] label_data_1_split does not need backward computation.
I0808 13:44:09.204550 20451 net.cpp:219] data does not need backward computation.
I0808 13:44:09.204557 20451 net.cpp:261] This network produces output accuracy
I0808 13:44:09.204569 20451 net.cpp:261] This network produces output loss
I0808 13:44:09.225782 20451 net.cpp:274] Network initialization done.
I0808 13:44:09.250818 20451 solver.cpp:181] Creating test net (#0) specified by test_net file: examples/scene/matchNetTestHingeMini.prototxt
I0808 13:44:09.257683 20451 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0039215689
    mirror: true
    mean_file: "examples/scene/scene_mean.binaryproto"
  }
  data_param {
    source: "examples/scene/scene_test_pairs.lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "th"
  type: "Threshold"
  bottom: "label"
  top: "th"
  threshold_param {
    threshold: 0
  }
}
layer {
  name: "i1"
  type: "Slice"
  bottom: "data"
  top: "i1"
  top: "i2"
  slice_param {
    slice_dim: 1
    slice_point: 3
  }
}
layer {
  name: "p1"
  type: "Pooling"
  bottom: "i1"
  top: "p1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "p2"
  type: "Pooling"
  bottom: "i2"
  top: "p2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input1"
  type: "Input"
  top: "Input1"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c11"
  type: "Crop"
  bottom: "i1"
  bottom: "Input1"
  top: "c11"
  crop_param {
    axis: 2
    offset: 0
    offset: 0
  }
}
layer {
  name: "Input2"
  type: "Input"
  top: "Input2"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c12"
  type: "Crop"
  bottom: "i1"
  bottom: "Input2"
  top: "c12"
  crop_param {
    axis: 2
    offset: 0
    offset: 32
  }
}
layer {
  name: "Input3"
  type: "Input"
  top: "Input3"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c13"
  type: "Crop"
  bottom: "i1"
  bottom: "Input3"
  top: "c13"
  crop_param {
    axis: 2
    offset: 0
    offset: 64
  }
}
layer {
  name: "Input4"
  type: "Input"
  top: "Input4"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c14"
  type: "Crop"
  bottom: "i1"
  bottom: "Input4"
  top: "c14"
  crop_param {
    axis: 2
    offset: 32
    offset: 0
  }
}
layer {
  name: "Input5"
  type: "Input"
  top: "Input5"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c15"
  type: "Crop"
  bottom: "i1"
  bottom: "Input5"
  top: "c15"
  crop_param {
    axis: 2
    offset: 32
    offset: 32
  }
}
layer {
  name: "Input6"
  type: "Input"
  top: "Input6"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c16"
  type: "Crop"
  bottom: "i1"
  bottom: "Input6"
  top: "c16"
  crop_param {
    axis: 2
    offset: 32
    offset: 64
  }
}
layer {
  name: "Input7"
  type: "Input"
  top: "Input7"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c17"
  type: "Crop"
  bottom: "i1"
  bottom: "Input7"
  top: "c17"
  crop_param {
    axis: 2
    offset: 64
    offset: 0
  }
}
layer {
  name: "Input8"
  type: "Input"
  top: "Input8"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c18"
  type: "Crop"
  bottom: "i1"
  bottom: "Input8"
  top: "c18"
  crop_param {
    axis: 2
    offset: 64
    offset: 32
  }
}
layer {
  name: "Input9"
  type: "Input"
  top: "Input9"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c19"
  type: "Crop"
  bottom: "i1"
  bottom: "Input9"
  top: "c19"
  crop_param {
    axis: 2
    offset: 64
    offset: 64
  }
}
layer {
  name: "Input10"
  type: "Input"
  top: "Input10"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c21"
  type: "Crop"
  bottom: "i2"
  bottom: "Input10"
  top: "c21"
  crop_param {
    axis: 2
    offset: 0
    offset: 0
  }
}
layer {
  name: "Input11"
  type: "Input"
  top: "Input11"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c22"
  type: "Crop"
  bottom: "i2"
  bottom: "Input11"
  top: "c22"
  crop_param {
    axis: 2
    offset: 0
    offset: 32
  }
}
layer {
  name: "Input12"
  type: "Input"
  top: "Input12"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c23"
  type: "Crop"
  bottom: "i2"
  bottom: "Input12"
  top: "c23"
  crop_param {
    axis: 2
    offset: 0
    offset: 64
  }
}
layer {
  name: "Input13"
  type: "Input"
  top: "Input13"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c24"
  type: "Crop"
  bottom: "i2"
  bottom: "Input13"
  top: "c24"
  crop_param {
    axis: 2
    offset: 32
    offset: 0
  }
}
layer {
  name: "Input14"
  type: "Input"
  top: "Input14"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c25"
  type: "Crop"
  bottom: "i2"
  bottom: "Input14"
  top: "c25"
  crop_param {
    axis: 2
    offset: 32
    offset: 32
  }
}
layer {
  name: "Input15"
  type: "Input"
  top: "Input15"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c26"
  type: "Crop"
  bottom: "i2"
  bottom: "Input15"
  top: "c26"
  crop_param {
    axis: 2
    offset: 32
    offset: 64
  }
}
layer {
  name: "Input16"
  type: "Input"
  top: "Input16"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c27"
  type: "Crop"
  bottom: "i2"
  bottom: "Input16"
  top: "c27"
  crop_param {
    axis: 2
    offset: 64
    offset: 0
  }
}
layer {
  name: "Input17"
  type: "Input"
  top: "Input17"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c28"
  type: "Crop"
  bottom: "i2"
  bottom: "Input17"
  top: "c28"
  crop_param {
    axis: 2
    offset: 64
    offset: 32
  }
}
layer {
  name: "Input18"
  type: "Input"
  top: "Input18"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c29"
  type: "Crop"
  bottom: "i2"
  bottom: "Input18"
  top: "c29"
  crop_param {
    axis: 2
    offset: 64
    offset: 64
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution1"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Convolution1"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Pooling1"
  top: "Convolution2"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Convolution2"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Pooling2"
  top: "Convolution3"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Convolution3"
  top: "Pooling3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling3"
  top: "InnerProduct1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "InnerProduct1"
  top: "InnerProduct2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "p2"
  top: "Convolution4"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling4"
  type: "Pooling"
  bottom: "Convolution4"
  top: "Pooling4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Pooling4"
  top: "Convolution5"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling5"
  type: "Pooling"
  bottom: "Convolution5"
  top: "Pooling5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Pooling5"
  top: "Convolution6"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling6"
  type: "Pooling"
  bottom: "Convolution6"
  top: "Pooling6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "Pooling6"
  top: "InnerProduct3"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "InnerProduct3"
  top: "InnerProduct3"
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "InnerProduct3"
  top: "InnerProduct4"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "InnerProduct2"
  bottom: "InnerProduct4"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct5"
  type: "InnerProduct"
  bottom: "Concat1"
  top: "InnerProduct5"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "InnerProduct5"
  top: "InnerProduct5"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct5"
  top: "Dropout1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct6"
  type: "InnerProduct"
  bottom: "Dropout1"
  top: "InnerProduct6"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "InnerProduct6"
  top: "InnerProduct6"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct6"
  top: "Dropout2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "dt0"
  type: "InnerProduct"
  bottom: "Dropout2"
  top: "dt0"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution7"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling7"
  type: "Pooling"
  bottom: "Convolution7"
  top: "Pooling7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Pooling7"
  top: "Convolution8"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling8"
  type: "Pooling"
  bottom: "Convolution8"
  top: "Pooling8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Pooling8"
  top: "Convolution9"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling9"
  type: "Pooling"
  bottom: "Convolution9"
  top: "Pooling9"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct7"
  type: "InnerProduct"
  bottom: "Pooling9"
  top: "InnerProduct7"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "InnerProduct7"
  top: "InnerProduct7"
}
layer {
  name: "InnerProduct8"
  type: "InnerProduct"
  bottom: "InnerProduct7"
  top: "InnerProduct8"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "c21"
  top: "Convolution10"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling10"
  type: "Pooling"
  bottom: "Convolution10"
  top: "Pooling10"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Pooling10"
  top: "Convolution11"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling11"
  type: "Pooling"
  bottom: "Convolution11"
  top: "Pooling11"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Pooling11"
  top: "Convolution12"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling12"
  type: "Pooling"
  bottom: "Convolution12"
  top: "Pooling12"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct9"
  type: "InnerProduct"
  bottom: "Pooling12"
  top: "InnerProduct9"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "InnerProduct9"
  top: "InnerProduct9"
}
layer {
  name: "InnerProduct10"
  type: "InnerProduct"
  bottom: "InnerProduct9"
  top: "InnerProduct10"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "InnerProduct8"
  bottom: "InnerProduct10"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct11"
  type: "InnerProduct"
  bottom: "Concat2"
  top: "InnerProduct11"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "InnerProduct11"
  top: "InnerProduct11"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct11"
  top: "Dropout3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct12"
  type: "InnerProduct"
  bottom: "Dropout3"
  top: "InnerProduct12"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "InnerProduct12"
  top: "InnerProduct12"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct12"
  top: "Dropout4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "dt1"
  type: "InnerProduct"
  bottom: "Dropout4"
  top: "dt1"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution13"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling13"
  type: "Pooling"
  bottom: "Convolution13"
  top: "Pooling13"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Pooling13"
  top: "Convolution14"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling14"
  type: "Pooling"
  bottom: "Convolution14"
  top: "Pooling14"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Pooling14"
  top: "Convolution15"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling15"
  type: "Pooling"
  bottom: "Convolution15"
  top: "Pooling15"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct13"
  type: "InnerProduct"
  bottom: "Pooling15"
  top: "InnerProduct13"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "InnerProduct13"
  top: "InnerProduct13"
}
layer {
  name: "InnerProduct14"
  type: "InnerProduct"
  bottom: "InnerProduct13"
  top: "InnerProduct14"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "c22"
  top: "Convolution16"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling16"
  type: "Pooling"
  bottom: "Convolution16"
  top: "Pooling16"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Pooling16"
  top: "Convolution17"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling17"
  type: "Pooling"
  bottom: "Convolution17"
  top: "Pooling17"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Pooling17"
  top: "Convolution18"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling18"
  type: "Pooling"
  bottom: "Convolution18"
  top: "Pooling18"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct15"
  type: "InnerProduct"
  bottom: "Pooling18"
  top: "InnerProduct15"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "InnerProduct15"
  top: "InnerProduct15"
}
layer {
  name: "InnerProduct16"
  type: "InnerProduct"
  bottom: "InnerProduct15"
  top: "InnerProduct16"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "InnerProduct14"
  bottom: "InnerProduct16"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct17"
  type: "InnerProduct"
  bottom: "Concat3"
  top: "InnerProduct17"
  param {
    name: "fc1_w"
    lr_mult: 1
  }
  param {
    name: "fc1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "InnerProduct17"
  top: "InnerProduct17"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "InnerProduct17"
  top: "Dropout5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "InnerProduct18"
  type: "InnerProduct"
  bottom: "Dropout5"
  top: "InnerProduct18"
  param {
    name: "fc2_w"
    lr_mult: 1
  }
  param {
    name: "fc2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "InnerProduct18"
  top: "InnerProduct18"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "InnerProduct18"
  top: "Dropout6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "dt2"
  type: "InnerProduct"
  bottom: "Dropout6"
  top: "dt2"
  param {
    name: "fc3_w"
    lr_mult: 1
  }
  param {
    name: "fc3_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution19"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling19"
  type: "Pooling"
  bottom: "Convolution19"
  top: "Pooling19"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Pooling19"
  top: "Convolution20"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling20"
  type: "Pooling"
  bottom: "Convolution20"
  top: "Pooling20"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Pooling20"
  top: "Convolution21"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling21"
  type: "Pooling"
  bottom: "Convolution21"
  top: "Pooling21"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct19"
  type: "InnerProduct"
  bottom: "Pooling21"
  top: "InnerProduct19"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "InnerProduct19"
  top: "InnerProduct19"
}
layer {
  name: "InnerProduct20"
  type: "InnerProduct"
  bottom: "InnerProduct19"
  top: "InnerProduct20"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "c23"
  top: "Convolution22"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling22"
  type: "Pooling"
  bottom: "Convolution22"
  top: "Pooling22"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Pooling22"
  top: "Convolution23"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling23"
  type: "Pooling"
  bottom: "Convolution23"
  top: "Pooling23"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Pooling23"
  top: "Convolution24"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling24"
  type: "Pooling"
  bottom: "Convolution24"
  top: "Pooling24"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "InnerProduct21"
  type: "InnerProduct"
  bottom: "Pooling24"
  top: "InnerProduct21"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
I0808 13:44:09.272492 20451 layer_factory.hpp:77] Creating layer data
I0808 13:44:09.272641 20451 net.cpp:91] Creating Layer data
I0808 13:44:09.272651 20451 net.cpp:399] data -> data
I0808 13:44:09.272670 20451 net.cpp:399] data -> label
I0808 13:44:09.272683 20451 data_transformer.cpp:25] Loading mean file from: examples/scene/scene_mean.binaryproto
I0808 13:44:09.274413 20459 db_lmdb.cpp:35] Opened lmdb examples/scene/scene_test_pairs.lmdb
I0808 13:44:09.274868 20451 data_layer.cpp:41] output data size: 64,6,128,128
I0808 13:44:09.340368 20451 net.cpp:141] Setting up data
I0808 13:44:09.340399 20451 net.cpp:148] Top shape: 64 6 128 128 (6291456)
I0808 13:44:09.340410 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:09.340417 20451 net.cpp:156] Memory required for data: 25166080
I0808 13:44:09.340428 20451 layer_factory.hpp:77] Creating layer label_data_1_split
I0808 13:44:09.340447 20451 net.cpp:91] Creating Layer label_data_1_split
I0808 13:44:09.340456 20451 net.cpp:425] label_data_1_split <- label
I0808 13:44:09.340468 20451 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0808 13:44:09.340486 20451 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0808 13:44:09.340668 20451 net.cpp:141] Setting up label_data_1_split
I0808 13:44:09.340679 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:09.340688 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:09.340694 20451 net.cpp:156] Memory required for data: 25166592
I0808 13:44:09.340701 20451 layer_factory.hpp:77] Creating layer th
I0808 13:44:09.340714 20451 net.cpp:91] Creating Layer th
I0808 13:44:09.340720 20451 net.cpp:425] th <- label_data_1_split_0
I0808 13:44:09.340730 20451 net.cpp:399] th -> th
I0808 13:44:09.340769 20451 net.cpp:141] Setting up th
I0808 13:44:09.340777 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:09.340783 20451 net.cpp:156] Memory required for data: 25166848
I0808 13:44:09.340790 20451 layer_factory.hpp:77] Creating layer th_th_0_split
I0808 13:44:09.340800 20451 net.cpp:91] Creating Layer th_th_0_split
I0808 13:44:09.340806 20451 net.cpp:425] th_th_0_split <- th
I0808 13:44:09.340814 20451 net.cpp:399] th_th_0_split -> th_th_0_split_0
I0808 13:44:09.340826 20451 net.cpp:399] th_th_0_split -> th_th_0_split_1
I0808 13:44:09.340891 20451 net.cpp:141] Setting up th_th_0_split
I0808 13:44:09.340903 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:09.340914 20451 net.cpp:148] Top shape: 64 (64)
I0808 13:44:09.340920 20451 net.cpp:156] Memory required for data: 25167360
I0808 13:44:09.340926 20451 layer_factory.hpp:77] Creating layer i1
I0808 13:44:09.340939 20451 net.cpp:91] Creating Layer i1
I0808 13:44:09.340945 20451 net.cpp:425] i1 <- data
I0808 13:44:09.340955 20451 net.cpp:399] i1 -> i1
I0808 13:44:09.340966 20451 net.cpp:399] i1 -> i2
I0808 13:44:09.341034 20451 net.cpp:141] Setting up i1
I0808 13:44:09.341042 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341051 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341058 20451 net.cpp:156] Memory required for data: 50333184
I0808 13:44:09.341063 20451 layer_factory.hpp:77] Creating layer i1_i1_0_split
I0808 13:44:09.341073 20451 net.cpp:91] Creating Layer i1_i1_0_split
I0808 13:44:09.341104 20451 net.cpp:425] i1_i1_0_split <- i1
I0808 13:44:09.341115 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_0
I0808 13:44:09.341127 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_1
I0808 13:44:09.341140 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_2
I0808 13:44:09.341152 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_3
I0808 13:44:09.341166 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_4
I0808 13:44:09.341179 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_5
I0808 13:44:09.341192 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_6
I0808 13:44:09.341202 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_7
I0808 13:44:09.341217 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_8
I0808 13:44:09.341229 20451 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_9
I0808 13:44:09.341478 20451 net.cpp:141] Setting up i1_i1_0_split
I0808 13:44:09.341488 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341496 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341505 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341512 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341521 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341528 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341536 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341544 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341552 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341560 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.341567 20451 net.cpp:156] Memory required for data: 176162304
I0808 13:44:09.341572 20451 layer_factory.hpp:77] Creating layer i2_i1_1_split
I0808 13:44:09.341583 20451 net.cpp:91] Creating Layer i2_i1_1_split
I0808 13:44:09.341588 20451 net.cpp:425] i2_i1_1_split <- i2
I0808 13:44:09.341598 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_0
I0808 13:44:09.341611 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_1
I0808 13:44:09.341624 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_2
I0808 13:44:09.341637 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_3
I0808 13:44:09.341650 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_4
I0808 13:44:09.341662 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_5
I0808 13:44:09.341675 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_6
I0808 13:44:09.341686 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_7
I0808 13:44:09.341698 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_8
I0808 13:44:09.341711 20451 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_9
I0808 13:44:09.345757 20451 net.cpp:141] Setting up i2_i1_1_split
I0808 13:44:09.345785 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.345795 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.345805 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.345814 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.345824 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.345832 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.345841 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.345850 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.345860 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.345868 20451 net.cpp:148] Top shape: 64 3 128 128 (3145728)
I0808 13:44:09.345875 20451 net.cpp:156] Memory required for data: 301991424
I0808 13:44:09.345885 20451 layer_factory.hpp:77] Creating layer p1
I0808 13:44:09.345901 20451 net.cpp:91] Creating Layer p1
I0808 13:44:09.345909 20451 net.cpp:425] p1 <- i1_i1_0_split_0
I0808 13:44:09.345923 20451 net.cpp:399] p1 -> p1
I0808 13:44:09.345973 20451 net.cpp:141] Setting up p1
I0808 13:44:09.345981 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.345988 20451 net.cpp:156] Memory required for data: 305137152
I0808 13:44:09.345995 20451 layer_factory.hpp:77] Creating layer p1_p1_0_split
I0808 13:44:09.346010 20451 net.cpp:91] Creating Layer p1_p1_0_split
I0808 13:44:09.346040 20451 net.cpp:425] p1_p1_0_split <- p1
I0808 13:44:09.346051 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_0
I0808 13:44:09.346067 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_1
I0808 13:44:09.346082 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_2
I0808 13:44:09.346106 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_3
I0808 13:44:09.346119 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_4
I0808 13:44:09.346134 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_5
I0808 13:44:09.346148 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_6
I0808 13:44:09.346163 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_7
I0808 13:44:09.346175 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_8
I0808 13:44:09.346190 20451 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_9
I0808 13:44:09.346458 20451 net.cpp:141] Setting up p1_p1_0_split
I0808 13:44:09.346468 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346479 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346490 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346499 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346508 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346525 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346534 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346541 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346549 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346557 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346563 20451 net.cpp:156] Memory required for data: 336594432
I0808 13:44:09.346570 20451 layer_factory.hpp:77] Creating layer p2
I0808 13:44:09.346580 20451 net.cpp:91] Creating Layer p2
I0808 13:44:09.346585 20451 net.cpp:425] p2 <- i2_i1_1_split_0
I0808 13:44:09.346596 20451 net.cpp:399] p2 -> p2
I0808 13:44:09.346633 20451 net.cpp:141] Setting up p2
I0808 13:44:09.346642 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.346648 20451 net.cpp:156] Memory required for data: 339740160
I0808 13:44:09.346654 20451 layer_factory.hpp:77] Creating layer p2_p2_0_split
I0808 13:44:09.346663 20451 net.cpp:91] Creating Layer p2_p2_0_split
I0808 13:44:09.346670 20451 net.cpp:425] p2_p2_0_split <- p2
I0808 13:44:09.346680 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_0
I0808 13:44:09.346694 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_1
I0808 13:44:09.346709 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_2
I0808 13:44:09.346721 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_3
I0808 13:44:09.346735 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_4
I0808 13:44:09.346748 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_5
I0808 13:44:09.346761 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_6
I0808 13:44:09.346774 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_7
I0808 13:44:09.346787 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_8
I0808 13:44:09.346801 20451 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_9
I0808 13:44:09.347043 20451 net.cpp:141] Setting up p2_p2_0_split
I0808 13:44:09.347053 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347060 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347067 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347075 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347084 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347091 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347098 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347106 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347115 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347123 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347129 20451 net.cpp:156] Memory required for data: 371197440
I0808 13:44:09.347136 20451 layer_factory.hpp:77] Creating layer Input1
I0808 13:44:09.347147 20451 net.cpp:91] Creating Layer Input1
I0808 13:44:09.347156 20451 net.cpp:399] Input1 -> Input1
I0808 13:44:09.347203 20451 net.cpp:141] Setting up Input1
I0808 13:44:09.347213 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347220 20451 net.cpp:156] Memory required for data: 374343168
I0808 13:44:09.347229 20451 layer_factory.hpp:77] Creating layer c11
I0808 13:44:09.347241 20451 net.cpp:91] Creating Layer c11
I0808 13:44:09.347249 20451 net.cpp:425] c11 <- i1_i1_0_split_1
I0808 13:44:09.347259 20451 net.cpp:425] c11 <- Input1
I0808 13:44:09.347301 20451 net.cpp:399] c11 -> c11
I0808 13:44:09.347352 20451 net.cpp:141] Setting up c11
I0808 13:44:09.347362 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347368 20451 net.cpp:156] Memory required for data: 377488896
I0808 13:44:09.347375 20451 layer_factory.hpp:77] Creating layer Input2
I0808 13:44:09.347385 20451 net.cpp:91] Creating Layer Input2
I0808 13:44:09.347395 20451 net.cpp:399] Input2 -> Input2
I0808 13:44:09.347432 20451 net.cpp:141] Setting up Input2
I0808 13:44:09.347441 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347447 20451 net.cpp:156] Memory required for data: 380634624
I0808 13:44:09.347455 20451 layer_factory.hpp:77] Creating layer c12
I0808 13:44:09.347465 20451 net.cpp:91] Creating Layer c12
I0808 13:44:09.347471 20451 net.cpp:425] c12 <- i1_i1_0_split_2
I0808 13:44:09.347481 20451 net.cpp:425] c12 <- Input2
I0808 13:44:09.347491 20451 net.cpp:399] c12 -> c12
I0808 13:44:09.347529 20451 net.cpp:141] Setting up c12
I0808 13:44:09.347538 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347545 20451 net.cpp:156] Memory required for data: 383780352
I0808 13:44:09.347551 20451 layer_factory.hpp:77] Creating layer Input3
I0808 13:44:09.347561 20451 net.cpp:91] Creating Layer Input3
I0808 13:44:09.347570 20451 net.cpp:399] Input3 -> Input3
I0808 13:44:09.347606 20451 net.cpp:141] Setting up Input3
I0808 13:44:09.347615 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347622 20451 net.cpp:156] Memory required for data: 386926080
I0808 13:44:09.347630 20451 layer_factory.hpp:77] Creating layer c13
I0808 13:44:09.347642 20451 net.cpp:91] Creating Layer c13
I0808 13:44:09.347650 20451 net.cpp:425] c13 <- i1_i1_0_split_3
I0808 13:44:09.347658 20451 net.cpp:425] c13 <- Input3
I0808 13:44:09.347671 20451 net.cpp:399] c13 -> c13
I0808 13:44:09.347710 20451 net.cpp:141] Setting up c13
I0808 13:44:09.347719 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347726 20451 net.cpp:156] Memory required for data: 390071808
I0808 13:44:09.347733 20451 layer_factory.hpp:77] Creating layer Input4
I0808 13:44:09.347743 20451 net.cpp:91] Creating Layer Input4
I0808 13:44:09.347751 20451 net.cpp:399] Input4 -> Input4
I0808 13:44:09.347795 20451 net.cpp:141] Setting up Input4
I0808 13:44:09.347803 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347810 20451 net.cpp:156] Memory required for data: 393217536
I0808 13:44:09.347816 20451 layer_factory.hpp:77] Creating layer c14
I0808 13:44:09.347826 20451 net.cpp:91] Creating Layer c14
I0808 13:44:09.347832 20451 net.cpp:425] c14 <- i1_i1_0_split_4
I0808 13:44:09.347841 20451 net.cpp:425] c14 <- Input4
I0808 13:44:09.347851 20451 net.cpp:399] c14 -> c14
I0808 13:44:09.347892 20451 net.cpp:141] Setting up c14
I0808 13:44:09.347900 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347906 20451 net.cpp:156] Memory required for data: 396363264
I0808 13:44:09.347913 20451 layer_factory.hpp:77] Creating layer Input5
I0808 13:44:09.347923 20451 net.cpp:91] Creating Layer Input5
I0808 13:44:09.347931 20451 net.cpp:399] Input5 -> Input5
I0808 13:44:09.347970 20451 net.cpp:141] Setting up Input5
I0808 13:44:09.347978 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.347985 20451 net.cpp:156] Memory required for data: 399508992
I0808 13:44:09.347992 20451 layer_factory.hpp:77] Creating layer c15
I0808 13:44:09.348002 20451 net.cpp:91] Creating Layer c15
I0808 13:44:09.348009 20451 net.cpp:425] c15 <- i1_i1_0_split_5
I0808 13:44:09.348018 20451 net.cpp:425] c15 <- Input5
I0808 13:44:09.348042 20451 net.cpp:399] c15 -> c15
I0808 13:44:09.348079 20451 net.cpp:141] Setting up c15
I0808 13:44:09.348089 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348095 20451 net.cpp:156] Memory required for data: 402654720
I0808 13:44:09.348103 20451 layer_factory.hpp:77] Creating layer Input6
I0808 13:44:09.348112 20451 net.cpp:91] Creating Layer Input6
I0808 13:44:09.348121 20451 net.cpp:399] Input6 -> Input6
I0808 13:44:09.348160 20451 net.cpp:141] Setting up Input6
I0808 13:44:09.348170 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348177 20451 net.cpp:156] Memory required for data: 405800448
I0808 13:44:09.348184 20451 layer_factory.hpp:77] Creating layer c16
I0808 13:44:09.348193 20451 net.cpp:91] Creating Layer c16
I0808 13:44:09.348201 20451 net.cpp:425] c16 <- i1_i1_0_split_6
I0808 13:44:09.348211 20451 net.cpp:425] c16 <- Input6
I0808 13:44:09.348222 20451 net.cpp:399] c16 -> c16
I0808 13:44:09.348260 20451 net.cpp:141] Setting up c16
I0808 13:44:09.348269 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348276 20451 net.cpp:156] Memory required for data: 408946176
I0808 13:44:09.348283 20451 layer_factory.hpp:77] Creating layer Input7
I0808 13:44:09.348292 20451 net.cpp:91] Creating Layer Input7
I0808 13:44:09.348300 20451 net.cpp:399] Input7 -> Input7
I0808 13:44:09.348340 20451 net.cpp:141] Setting up Input7
I0808 13:44:09.348348 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348356 20451 net.cpp:156] Memory required for data: 412091904
I0808 13:44:09.348362 20451 layer_factory.hpp:77] Creating layer c17
I0808 13:44:09.348371 20451 net.cpp:91] Creating Layer c17
I0808 13:44:09.348378 20451 net.cpp:425] c17 <- i1_i1_0_split_7
I0808 13:44:09.348387 20451 net.cpp:425] c17 <- Input7
I0808 13:44:09.348397 20451 net.cpp:399] c17 -> c17
I0808 13:44:09.348445 20451 net.cpp:141] Setting up c17
I0808 13:44:09.348455 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348461 20451 net.cpp:156] Memory required for data: 415237632
I0808 13:44:09.348469 20451 layer_factory.hpp:77] Creating layer Input8
I0808 13:44:09.348477 20451 net.cpp:91] Creating Layer Input8
I0808 13:44:09.348486 20451 net.cpp:399] Input8 -> Input8
I0808 13:44:09.348522 20451 net.cpp:141] Setting up Input8
I0808 13:44:09.348531 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348538 20451 net.cpp:156] Memory required for data: 418383360
I0808 13:44:09.348546 20451 layer_factory.hpp:77] Creating layer c18
I0808 13:44:09.348554 20451 net.cpp:91] Creating Layer c18
I0808 13:44:09.348562 20451 net.cpp:425] c18 <- i1_i1_0_split_8
I0808 13:44:09.348570 20451 net.cpp:425] c18 <- Input8
I0808 13:44:09.348580 20451 net.cpp:399] c18 -> c18
I0808 13:44:09.348618 20451 net.cpp:141] Setting up c18
I0808 13:44:09.348626 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348633 20451 net.cpp:156] Memory required for data: 421529088
I0808 13:44:09.348639 20451 layer_factory.hpp:77] Creating layer Input9
I0808 13:44:09.348649 20451 net.cpp:91] Creating Layer Input9
I0808 13:44:09.348657 20451 net.cpp:399] Input9 -> Input9
I0808 13:44:09.348692 20451 net.cpp:141] Setting up Input9
I0808 13:44:09.348701 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348708 20451 net.cpp:156] Memory required for data: 424674816
I0808 13:44:09.348714 20451 layer_factory.hpp:77] Creating layer c19
I0808 13:44:09.348723 20451 net.cpp:91] Creating Layer c19
I0808 13:44:09.348731 20451 net.cpp:425] c19 <- i1_i1_0_split_9
I0808 13:44:09.348740 20451 net.cpp:425] c19 <- Input9
I0808 13:44:09.348750 20451 net.cpp:399] c19 -> c19
I0808 13:44:09.348788 20451 net.cpp:141] Setting up c19
I0808 13:44:09.348798 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348803 20451 net.cpp:156] Memory required for data: 427820544
I0808 13:44:09.348810 20451 layer_factory.hpp:77] Creating layer Input10
I0808 13:44:09.348820 20451 net.cpp:91] Creating Layer Input10
I0808 13:44:09.348829 20451 net.cpp:399] Input10 -> Input10
I0808 13:44:09.348863 20451 net.cpp:141] Setting up Input10
I0808 13:44:09.348882 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348889 20451 net.cpp:156] Memory required for data: 430966272
I0808 13:44:09.348896 20451 layer_factory.hpp:77] Creating layer c21
I0808 13:44:09.348906 20451 net.cpp:91] Creating Layer c21
I0808 13:44:09.348912 20451 net.cpp:425] c21 <- i2_i1_1_split_1
I0808 13:44:09.348922 20451 net.cpp:425] c21 <- Input10
I0808 13:44:09.348932 20451 net.cpp:399] c21 -> c21
I0808 13:44:09.348970 20451 net.cpp:141] Setting up c21
I0808 13:44:09.348979 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.348986 20451 net.cpp:156] Memory required for data: 434112000
I0808 13:44:09.348992 20451 layer_factory.hpp:77] Creating layer Input11
I0808 13:44:09.349001 20451 net.cpp:91] Creating Layer Input11
I0808 13:44:09.349011 20451 net.cpp:399] Input11 -> Input11
I0808 13:44:09.349048 20451 net.cpp:141] Setting up Input11
I0808 13:44:09.349057 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349063 20451 net.cpp:156] Memory required for data: 437257728
I0808 13:44:09.349071 20451 layer_factory.hpp:77] Creating layer c22
I0808 13:44:09.349086 20451 net.cpp:91] Creating Layer c22
I0808 13:44:09.349092 20451 net.cpp:425] c22 <- i2_i1_1_split_2
I0808 13:44:09.349102 20451 net.cpp:425] c22 <- Input11
I0808 13:44:09.349112 20451 net.cpp:399] c22 -> c22
I0808 13:44:09.349151 20451 net.cpp:141] Setting up c22
I0808 13:44:09.349160 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349166 20451 net.cpp:156] Memory required for data: 440403456
I0808 13:44:09.349174 20451 layer_factory.hpp:77] Creating layer Input12
I0808 13:44:09.349184 20451 net.cpp:91] Creating Layer Input12
I0808 13:44:09.349192 20451 net.cpp:399] Input12 -> Input12
I0808 13:44:09.349230 20451 net.cpp:141] Setting up Input12
I0808 13:44:09.349238 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349244 20451 net.cpp:156] Memory required for data: 443549184
I0808 13:44:09.349251 20451 layer_factory.hpp:77] Creating layer c23
I0808 13:44:09.349261 20451 net.cpp:91] Creating Layer c23
I0808 13:44:09.349267 20451 net.cpp:425] c23 <- i2_i1_1_split_3
I0808 13:44:09.349277 20451 net.cpp:425] c23 <- Input12
I0808 13:44:09.349287 20451 net.cpp:399] c23 -> c23
I0808 13:44:09.349323 20451 net.cpp:141] Setting up c23
I0808 13:44:09.349333 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349339 20451 net.cpp:156] Memory required for data: 446694912
I0808 13:44:09.349346 20451 layer_factory.hpp:77] Creating layer Input13
I0808 13:44:09.349355 20451 net.cpp:91] Creating Layer Input13
I0808 13:44:09.349364 20451 net.cpp:399] Input13 -> Input13
I0808 13:44:09.349401 20451 net.cpp:141] Setting up Input13
I0808 13:44:09.349411 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349417 20451 net.cpp:156] Memory required for data: 449840640
I0808 13:44:09.349423 20451 layer_factory.hpp:77] Creating layer c24
I0808 13:44:09.349433 20451 net.cpp:91] Creating Layer c24
I0808 13:44:09.349439 20451 net.cpp:425] c24 <- i2_i1_1_split_4
I0808 13:44:09.349449 20451 net.cpp:425] c24 <- Input13
I0808 13:44:09.349459 20451 net.cpp:399] c24 -> c24
I0808 13:44:09.349498 20451 net.cpp:141] Setting up c24
I0808 13:44:09.349508 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349514 20451 net.cpp:156] Memory required for data: 452986368
I0808 13:44:09.349520 20451 layer_factory.hpp:77] Creating layer Input14
I0808 13:44:09.349529 20451 net.cpp:91] Creating Layer Input14
I0808 13:44:09.349537 20451 net.cpp:399] Input14 -> Input14
I0808 13:44:09.349576 20451 net.cpp:141] Setting up Input14
I0808 13:44:09.349586 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349592 20451 net.cpp:156] Memory required for data: 456132096
I0808 13:44:09.349599 20451 layer_factory.hpp:77] Creating layer c25
I0808 13:44:09.349608 20451 net.cpp:91] Creating Layer c25
I0808 13:44:09.349616 20451 net.cpp:425] c25 <- i2_i1_1_split_5
I0808 13:44:09.349624 20451 net.cpp:425] c25 <- Input14
I0808 13:44:09.349635 20451 net.cpp:399] c25 -> c25
I0808 13:44:09.349683 20451 net.cpp:141] Setting up c25
I0808 13:44:09.349691 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349699 20451 net.cpp:156] Memory required for data: 459277824
I0808 13:44:09.349704 20451 layer_factory.hpp:77] Creating layer Input15
I0808 13:44:09.349714 20451 net.cpp:91] Creating Layer Input15
I0808 13:44:09.349725 20451 net.cpp:399] Input15 -> Input15
I0808 13:44:09.349759 20451 net.cpp:141] Setting up Input15
I0808 13:44:09.349768 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349774 20451 net.cpp:156] Memory required for data: 462423552
I0808 13:44:09.349781 20451 layer_factory.hpp:77] Creating layer c26
I0808 13:44:09.349791 20451 net.cpp:91] Creating Layer c26
I0808 13:44:09.349800 20451 net.cpp:425] c26 <- i2_i1_1_split_6
I0808 13:44:09.349809 20451 net.cpp:425] c26 <- Input15
I0808 13:44:09.349819 20451 net.cpp:399] c26 -> c26
I0808 13:44:09.349855 20451 net.cpp:141] Setting up c26
I0808 13:44:09.349864 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349871 20451 net.cpp:156] Memory required for data: 465569280
I0808 13:44:09.349879 20451 layer_factory.hpp:77] Creating layer Input16
I0808 13:44:09.349887 20451 net.cpp:91] Creating Layer Input16
I0808 13:44:09.349896 20451 net.cpp:399] Input16 -> Input16
I0808 13:44:09.349932 20451 net.cpp:141] Setting up Input16
I0808 13:44:09.349941 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.349947 20451 net.cpp:156] Memory required for data: 468715008
I0808 13:44:09.349954 20451 layer_factory.hpp:77] Creating layer c27
I0808 13:44:09.349963 20451 net.cpp:91] Creating Layer c27
I0808 13:44:09.349972 20451 net.cpp:425] c27 <- i2_i1_1_split_7
I0808 13:44:09.349980 20451 net.cpp:425] c27 <- Input16
I0808 13:44:09.349990 20451 net.cpp:399] c27 -> c27
I0808 13:44:09.350028 20451 net.cpp:141] Setting up c27
I0808 13:44:09.350036 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.350044 20451 net.cpp:156] Memory required for data: 471860736
I0808 13:44:09.350050 20451 layer_factory.hpp:77] Creating layer Input17
I0808 13:44:09.350060 20451 net.cpp:91] Creating Layer Input17
I0808 13:44:09.350069 20451 net.cpp:399] Input17 -> Input17
I0808 13:44:09.350105 20451 net.cpp:141] Setting up Input17
I0808 13:44:09.350113 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.350119 20451 net.cpp:156] Memory required for data: 475006464
I0808 13:44:09.350126 20451 layer_factory.hpp:77] Creating layer c28
I0808 13:44:09.350136 20451 net.cpp:91] Creating Layer c28
I0808 13:44:09.350142 20451 net.cpp:425] c28 <- i2_i1_1_split_8
I0808 13:44:09.350152 20451 net.cpp:425] c28 <- Input17
I0808 13:44:09.350162 20451 net.cpp:399] c28 -> c28
I0808 13:44:09.350201 20451 net.cpp:141] Setting up c28
I0808 13:44:09.350211 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.350217 20451 net.cpp:156] Memory required for data: 478152192
I0808 13:44:09.350224 20451 layer_factory.hpp:77] Creating layer Input18
I0808 13:44:09.350234 20451 net.cpp:91] Creating Layer Input18
I0808 13:44:09.350242 20451 net.cpp:399] Input18 -> Input18
I0808 13:44:09.350276 20451 net.cpp:141] Setting up Input18
I0808 13:44:09.350286 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.350292 20451 net.cpp:156] Memory required for data: 481297920
I0808 13:44:09.350298 20451 layer_factory.hpp:77] Creating layer c29
I0808 13:44:09.350308 20451 net.cpp:91] Creating Layer c29
I0808 13:44:09.350316 20451 net.cpp:425] c29 <- i2_i1_1_split_9
I0808 13:44:09.350324 20451 net.cpp:425] c29 <- Input18
I0808 13:44:09.350334 20451 net.cpp:399] c29 -> c29
I0808 13:44:09.350368 20451 net.cpp:141] Setting up c29
I0808 13:44:09.350376 20451 net.cpp:148] Top shape: 64 3 64 64 (786432)
I0808 13:44:09.350383 20451 net.cpp:156] Memory required for data: 484443648
I0808 13:44:09.350390 20451 layer_factory.hpp:77] Creating layer Convolution1
I0808 13:44:09.350407 20451 net.cpp:91] Creating Layer Convolution1
I0808 13:44:09.350414 20451 net.cpp:425] Convolution1 <- p1_p1_0_split_0
I0808 13:44:09.350436 20451 net.cpp:399] Convolution1 -> Convolution1
I0808 13:44:09.350864 20451 net.cpp:141] Setting up Convolution1
I0808 13:44:09.350873 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.350880 20451 net.cpp:156] Memory required for data: 502875648
I0808 13:44:09.350894 20451 layer_factory.hpp:77] Creating layer Pooling1
I0808 13:44:09.350904 20451 net.cpp:91] Creating Layer Pooling1
I0808 13:44:09.350911 20451 net.cpp:425] Pooling1 <- Convolution1
I0808 13:44:09.350921 20451 net.cpp:399] Pooling1 -> Pooling1
I0808 13:44:09.350976 20451 net.cpp:141] Setting up Pooling1
I0808 13:44:09.350986 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.350992 20451 net.cpp:156] Memory required for data: 507483648
I0808 13:44:09.350999 20451 layer_factory.hpp:77] Creating layer Convolution2
I0808 13:44:09.351013 20451 net.cpp:91] Creating Layer Convolution2
I0808 13:44:09.351021 20451 net.cpp:425] Convolution2 <- Pooling1
I0808 13:44:09.351032 20451 net.cpp:399] Convolution2 -> Convolution2
I0808 13:44:09.351649 20451 net.cpp:141] Setting up Convolution2
I0808 13:44:09.351657 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.351665 20451 net.cpp:156] Memory required for data: 516136448
I0808 13:44:09.351676 20451 layer_factory.hpp:77] Creating layer Pooling2
I0808 13:44:09.351686 20451 net.cpp:91] Creating Layer Pooling2
I0808 13:44:09.351693 20451 net.cpp:425] Pooling2 <- Convolution2
I0808 13:44:09.351703 20451 net.cpp:399] Pooling2 -> Pooling2
I0808 13:44:09.351758 20451 net.cpp:141] Setting up Pooling2
I0808 13:44:09.351768 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.351773 20451 net.cpp:156] Memory required for data: 518299648
I0808 13:44:09.351780 20451 layer_factory.hpp:77] Creating layer Convolution3
I0808 13:44:09.351794 20451 net.cpp:91] Creating Layer Convolution3
I0808 13:44:09.351800 20451 net.cpp:425] Convolution3 <- Pooling2
I0808 13:44:09.351811 20451 net.cpp:399] Convolution3 -> Convolution3
I0808 13:44:09.352735 20451 net.cpp:141] Setting up Convolution3
I0808 13:44:09.352746 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.352751 20451 net.cpp:156] Memory required for data: 519336448
I0808 13:44:09.352763 20451 layer_factory.hpp:77] Creating layer Pooling3
I0808 13:44:09.352773 20451 net.cpp:91] Creating Layer Pooling3
I0808 13:44:09.352780 20451 net.cpp:425] Pooling3 <- Convolution3
I0808 13:44:09.352792 20451 net.cpp:399] Pooling3 -> Pooling3
I0808 13:44:09.352847 20451 net.cpp:141] Setting up Pooling3
I0808 13:44:09.352856 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.352864 20451 net.cpp:156] Memory required for data: 519656448
I0808 13:44:09.352869 20451 layer_factory.hpp:77] Creating layer InnerProduct1
I0808 13:44:09.352881 20451 net.cpp:91] Creating Layer InnerProduct1
I0808 13:44:09.352888 20451 net.cpp:425] InnerProduct1 <- Pooling3
I0808 13:44:09.352900 20451 net.cpp:399] InnerProduct1 -> InnerProduct1
I0808 13:44:09.354204 20451 net.cpp:141] Setting up InnerProduct1
I0808 13:44:09.354218 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.354225 20451 net.cpp:156] Memory required for data: 519682048
I0808 13:44:09.354236 20451 layer_factory.hpp:77] Creating layer ReLU1
I0808 13:44:09.354249 20451 net.cpp:91] Creating Layer ReLU1
I0808 13:44:09.354257 20451 net.cpp:425] ReLU1 <- InnerProduct1
I0808 13:44:09.354269 20451 net.cpp:386] ReLU1 -> InnerProduct1 (in-place)
I0808 13:44:09.354281 20451 net.cpp:141] Setting up ReLU1
I0808 13:44:09.354291 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.354300 20451 net.cpp:156] Memory required for data: 519707648
I0808 13:44:09.354306 20451 layer_factory.hpp:77] Creating layer InnerProduct2
I0808 13:44:09.354320 20451 net.cpp:91] Creating Layer InnerProduct2
I0808 13:44:09.354327 20451 net.cpp:425] InnerProduct2 <- InnerProduct1
I0808 13:44:09.354341 20451 net.cpp:399] InnerProduct2 -> InnerProduct2
I0808 13:44:09.354568 20451 net.cpp:141] Setting up InnerProduct2
I0808 13:44:09.354578 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.354601 20451 net.cpp:156] Memory required for data: 519720448
I0808 13:44:09.354617 20451 layer_factory.hpp:77] Creating layer Convolution4
I0808 13:44:09.354635 20451 net.cpp:91] Creating Layer Convolution4
I0808 13:44:09.354642 20451 net.cpp:425] Convolution4 <- p2_p2_0_split_0
I0808 13:44:09.354656 20451 net.cpp:399] Convolution4 -> Convolution4
I0808 13:44:09.355099 20451 net.cpp:141] Setting up Convolution4
I0808 13:44:09.355111 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.355118 20451 net.cpp:156] Memory required for data: 538152448
I0808 13:44:09.355128 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.355137 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.355146 20451 layer_factory.hpp:77] Creating layer Pooling4
I0808 13:44:09.355159 20451 net.cpp:91] Creating Layer Pooling4
I0808 13:44:09.355168 20451 net.cpp:425] Pooling4 <- Convolution4
I0808 13:44:09.355181 20451 net.cpp:399] Pooling4 -> Pooling4
I0808 13:44:09.355250 20451 net.cpp:141] Setting up Pooling4
I0808 13:44:09.355262 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.355269 20451 net.cpp:156] Memory required for data: 542760448
I0808 13:44:09.355306 20451 layer_factory.hpp:77] Creating layer Convolution5
I0808 13:44:09.355321 20451 net.cpp:91] Creating Layer Convolution5
I0808 13:44:09.355329 20451 net.cpp:425] Convolution5 <- Pooling4
I0808 13:44:09.355340 20451 net.cpp:399] Convolution5 -> Convolution5
I0808 13:44:09.356010 20451 net.cpp:141] Setting up Convolution5
I0808 13:44:09.356027 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.356034 20451 net.cpp:156] Memory required for data: 551413248
I0808 13:44:09.356042 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.356051 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.356058 20451 layer_factory.hpp:77] Creating layer Pooling5
I0808 13:44:09.356071 20451 net.cpp:91] Creating Layer Pooling5
I0808 13:44:09.356081 20451 net.cpp:425] Pooling5 <- Convolution5
I0808 13:44:09.356096 20451 net.cpp:399] Pooling5 -> Pooling5
I0808 13:44:09.356165 20451 net.cpp:141] Setting up Pooling5
I0808 13:44:09.356178 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.356184 20451 net.cpp:156] Memory required for data: 553576448
I0808 13:44:09.356190 20451 layer_factory.hpp:77] Creating layer Convolution6
I0808 13:44:09.356206 20451 net.cpp:91] Creating Layer Convolution6
I0808 13:44:09.356214 20451 net.cpp:425] Convolution6 <- Pooling5
I0808 13:44:09.356226 20451 net.cpp:399] Convolution6 -> Convolution6
I0808 13:44:09.358065 20451 net.cpp:141] Setting up Convolution6
I0808 13:44:09.358093 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.358101 20451 net.cpp:156] Memory required for data: 554613248
I0808 13:44:09.358114 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.358125 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.358134 20451 layer_factory.hpp:77] Creating layer Pooling6
I0808 13:44:09.358150 20451 net.cpp:91] Creating Layer Pooling6
I0808 13:44:09.358161 20451 net.cpp:425] Pooling6 <- Convolution6
I0808 13:44:09.358175 20451 net.cpp:399] Pooling6 -> Pooling6
I0808 13:44:09.358252 20451 net.cpp:141] Setting up Pooling6
I0808 13:44:09.358263 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.358270 20451 net.cpp:156] Memory required for data: 554933248
I0808 13:44:09.358279 20451 layer_factory.hpp:77] Creating layer InnerProduct3
I0808 13:44:09.358294 20451 net.cpp:91] Creating Layer InnerProduct3
I0808 13:44:09.358302 20451 net.cpp:425] InnerProduct3 <- Pooling6
I0808 13:44:09.358317 20451 net.cpp:399] InnerProduct3 -> InnerProduct3
I0808 13:44:09.360435 20451 net.cpp:141] Setting up InnerProduct3
I0808 13:44:09.360457 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.360491 20451 net.cpp:156] Memory required for data: 554958848
I0808 13:44:09.360509 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.360518 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.360525 20451 layer_factory.hpp:77] Creating layer ReLU2
I0808 13:44:09.360538 20451 net.cpp:91] Creating Layer ReLU2
I0808 13:44:09.360545 20451 net.cpp:425] ReLU2 <- InnerProduct3
I0808 13:44:09.360556 20451 net.cpp:386] ReLU2 -> InnerProduct3 (in-place)
I0808 13:44:09.364387 20451 net.cpp:141] Setting up ReLU2
I0808 13:44:09.364409 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.364416 20451 net.cpp:156] Memory required for data: 554984448
I0808 13:44:09.364424 20451 layer_factory.hpp:77] Creating layer InnerProduct4
I0808 13:44:09.364469 20451 net.cpp:91] Creating Layer InnerProduct4
I0808 13:44:09.364477 20451 net.cpp:425] InnerProduct4 <- InnerProduct3
I0808 13:44:09.364491 20451 net.cpp:399] InnerProduct4 -> InnerProduct4
I0808 13:44:09.364898 20451 net.cpp:141] Setting up InnerProduct4
I0808 13:44:09.364919 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.364928 20451 net.cpp:156] Memory required for data: 554997248
I0808 13:44:09.364938 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.364946 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.364954 20451 layer_factory.hpp:77] Creating layer Concat1
I0808 13:44:09.364967 20451 net.cpp:91] Creating Layer Concat1
I0808 13:44:09.364974 20451 net.cpp:425] Concat1 <- InnerProduct2
I0808 13:44:09.364984 20451 net.cpp:425] Concat1 <- InnerProduct4
I0808 13:44:09.364994 20451 net.cpp:399] Concat1 -> Concat1
I0808 13:44:09.365031 20451 net.cpp:141] Setting up Concat1
I0808 13:44:09.365041 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.365049 20451 net.cpp:156] Memory required for data: 555022848
I0808 13:44:09.365057 20451 layer_factory.hpp:77] Creating layer InnerProduct5
I0808 13:44:09.365069 20451 net.cpp:91] Creating Layer InnerProduct5
I0808 13:44:09.365077 20451 net.cpp:425] InnerProduct5 <- Concat1
I0808 13:44:09.365090 20451 net.cpp:399] InnerProduct5 -> InnerProduct5
I0808 13:44:09.365314 20451 net.cpp:141] Setting up InnerProduct5
I0808 13:44:09.365324 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.365332 20451 net.cpp:156] Memory required for data: 555039232
I0808 13:44:09.365344 20451 layer_factory.hpp:77] Creating layer ReLU3
I0808 13:44:09.365356 20451 net.cpp:91] Creating Layer ReLU3
I0808 13:44:09.365365 20451 net.cpp:425] ReLU3 <- InnerProduct5
I0808 13:44:09.365375 20451 net.cpp:386] ReLU3 -> InnerProduct5 (in-place)
I0808 13:44:09.365386 20451 net.cpp:141] Setting up ReLU3
I0808 13:44:09.365394 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.365401 20451 net.cpp:156] Memory required for data: 555055616
I0808 13:44:09.365408 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.365419 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.365427 20451 net.cpp:425] drop1 <- InnerProduct5
I0808 13:44:09.365437 20451 net.cpp:399] drop1 -> Dropout1
I0808 13:44:09.365491 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.365501 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.365507 20451 net.cpp:156] Memory required for data: 555072000
I0808 13:44:09.365514 20451 layer_factory.hpp:77] Creating layer InnerProduct6
I0808 13:44:09.365525 20451 net.cpp:91] Creating Layer InnerProduct6
I0808 13:44:09.365532 20451 net.cpp:425] InnerProduct6 <- Dropout1
I0808 13:44:09.365545 20451 net.cpp:399] InnerProduct6 -> InnerProduct6
I0808 13:44:09.365839 20451 net.cpp:141] Setting up InnerProduct6
I0808 13:44:09.365850 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.365856 20451 net.cpp:156] Memory required for data: 555080192
I0808 13:44:09.365867 20451 layer_factory.hpp:77] Creating layer ReLU4
I0808 13:44:09.365877 20451 net.cpp:91] Creating Layer ReLU4
I0808 13:44:09.365908 20451 net.cpp:425] ReLU4 <- InnerProduct6
I0808 13:44:09.365918 20451 net.cpp:386] ReLU4 -> InnerProduct6 (in-place)
I0808 13:44:09.365931 20451 net.cpp:141] Setting up ReLU4
I0808 13:44:09.365938 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.365945 20451 net.cpp:156] Memory required for data: 555088384
I0808 13:44:09.365952 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.365962 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.365969 20451 net.cpp:425] drop2 <- InnerProduct6
I0808 13:44:09.365980 20451 net.cpp:399] drop2 -> Dropout2
I0808 13:44:09.366035 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.366045 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.366051 20451 net.cpp:156] Memory required for data: 555096576
I0808 13:44:09.366058 20451 layer_factory.hpp:77] Creating layer dt0
I0808 13:44:09.366070 20451 net.cpp:91] Creating Layer dt0
I0808 13:44:09.366076 20451 net.cpp:425] dt0 <- Dropout2
I0808 13:44:09.366088 20451 net.cpp:399] dt0 -> dt0
I0808 13:44:09.366253 20451 net.cpp:141] Setting up dt0
I0808 13:44:09.366262 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.366269 20451 net.cpp:156] Memory required for data: 555096832
I0808 13:44:09.366279 20451 layer_factory.hpp:77] Creating layer Convolution7
I0808 13:44:09.366295 20451 net.cpp:91] Creating Layer Convolution7
I0808 13:44:09.366303 20451 net.cpp:425] Convolution7 <- p1_p1_0_split_1
I0808 13:44:09.366315 20451 net.cpp:399] Convolution7 -> Convolution7
I0808 13:44:09.366751 20451 net.cpp:141] Setting up Convolution7
I0808 13:44:09.366760 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.366767 20451 net.cpp:156] Memory required for data: 573528832
I0808 13:44:09.366775 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.366783 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.366791 20451 layer_factory.hpp:77] Creating layer Pooling7
I0808 13:44:09.366802 20451 net.cpp:91] Creating Layer Pooling7
I0808 13:44:09.366809 20451 net.cpp:425] Pooling7 <- Convolution7
I0808 13:44:09.366821 20451 net.cpp:399] Pooling7 -> Pooling7
I0808 13:44:09.366878 20451 net.cpp:141] Setting up Pooling7
I0808 13:44:09.366888 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.366894 20451 net.cpp:156] Memory required for data: 578136832
I0808 13:44:09.366899 20451 layer_factory.hpp:77] Creating layer Convolution8
I0808 13:44:09.366914 20451 net.cpp:91] Creating Layer Convolution8
I0808 13:44:09.366921 20451 net.cpp:425] Convolution8 <- Pooling7
I0808 13:44:09.366933 20451 net.cpp:399] Convolution8 -> Convolution8
I0808 13:44:09.367565 20451 net.cpp:141] Setting up Convolution8
I0808 13:44:09.367578 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.367584 20451 net.cpp:156] Memory required for data: 586789632
I0808 13:44:09.367593 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.367600 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.367609 20451 layer_factory.hpp:77] Creating layer Pooling8
I0808 13:44:09.367619 20451 net.cpp:91] Creating Layer Pooling8
I0808 13:44:09.367627 20451 net.cpp:425] Pooling8 <- Convolution8
I0808 13:44:09.367637 20451 net.cpp:399] Pooling8 -> Pooling8
I0808 13:44:09.367697 20451 net.cpp:141] Setting up Pooling8
I0808 13:44:09.367707 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.367713 20451 net.cpp:156] Memory required for data: 588952832
I0808 13:44:09.367722 20451 layer_factory.hpp:77] Creating layer Convolution9
I0808 13:44:09.367735 20451 net.cpp:91] Creating Layer Convolution9
I0808 13:44:09.367743 20451 net.cpp:425] Convolution9 <- Pooling8
I0808 13:44:09.367755 20451 net.cpp:399] Convolution9 -> Convolution9
I0808 13:44:09.368671 20451 net.cpp:141] Setting up Convolution9
I0808 13:44:09.368682 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.368690 20451 net.cpp:156] Memory required for data: 589989632
I0808 13:44:09.368713 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.368722 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.368729 20451 layer_factory.hpp:77] Creating layer Pooling9
I0808 13:44:09.368739 20451 net.cpp:91] Creating Layer Pooling9
I0808 13:44:09.368747 20451 net.cpp:425] Pooling9 <- Convolution9
I0808 13:44:09.384975 20451 net.cpp:399] Pooling9 -> Pooling9
I0808 13:44:09.386239 20451 net.cpp:141] Setting up Pooling9
I0808 13:44:09.386255 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.386261 20451 net.cpp:156] Memory required for data: 590309632
I0808 13:44:09.386270 20451 layer_factory.hpp:77] Creating layer InnerProduct7
I0808 13:44:09.386286 20451 net.cpp:91] Creating Layer InnerProduct7
I0808 13:44:09.386294 20451 net.cpp:425] InnerProduct7 <- Pooling9
I0808 13:44:09.386307 20451 net.cpp:399] InnerProduct7 -> InnerProduct7
I0808 13:44:09.387572 20451 net.cpp:141] Setting up InnerProduct7
I0808 13:44:09.387586 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.387593 20451 net.cpp:156] Memory required for data: 590335232
I0808 13:44:09.387619 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.387629 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.387636 20451 layer_factory.hpp:77] Creating layer ReLU5
I0808 13:44:09.387648 20451 net.cpp:91] Creating Layer ReLU5
I0808 13:44:09.387657 20451 net.cpp:425] ReLU5 <- InnerProduct7
I0808 13:44:09.387668 20451 net.cpp:386] ReLU5 -> InnerProduct7 (in-place)
I0808 13:44:09.387681 20451 net.cpp:141] Setting up ReLU5
I0808 13:44:09.387691 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.387696 20451 net.cpp:156] Memory required for data: 590360832
I0808 13:44:09.387703 20451 layer_factory.hpp:77] Creating layer InnerProduct8
I0808 13:44:09.387717 20451 net.cpp:91] Creating Layer InnerProduct8
I0808 13:44:09.387723 20451 net.cpp:425] InnerProduct8 <- InnerProduct7
I0808 13:44:09.387734 20451 net.cpp:399] InnerProduct8 -> InnerProduct8
I0808 13:44:09.387946 20451 net.cpp:141] Setting up InnerProduct8
I0808 13:44:09.387956 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.387962 20451 net.cpp:156] Memory required for data: 590373632
I0808 13:44:09.387970 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.387979 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.387986 20451 layer_factory.hpp:77] Creating layer Convolution10
I0808 13:44:09.388005 20451 net.cpp:91] Creating Layer Convolution10
I0808 13:44:09.388013 20451 net.cpp:425] Convolution10 <- c21
I0808 13:44:09.388026 20451 net.cpp:399] Convolution10 -> Convolution10
I0808 13:44:09.388576 20451 net.cpp:141] Setting up Convolution10
I0808 13:44:09.388586 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.388593 20451 net.cpp:156] Memory required for data: 608805632
I0808 13:44:09.388600 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.388609 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.388617 20451 layer_factory.hpp:77] Creating layer Pooling10
I0808 13:44:09.388628 20451 net.cpp:91] Creating Layer Pooling10
I0808 13:44:09.388635 20451 net.cpp:425] Pooling10 <- Convolution10
I0808 13:44:09.389585 20451 net.cpp:399] Pooling10 -> Pooling10
I0808 13:44:09.389719 20451 net.cpp:141] Setting up Pooling10
I0808 13:44:09.389731 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.389739 20451 net.cpp:156] Memory required for data: 613413632
I0808 13:44:09.389745 20451 layer_factory.hpp:77] Creating layer Convolution11
I0808 13:44:09.389766 20451 net.cpp:91] Creating Layer Convolution11
I0808 13:44:09.389775 20451 net.cpp:425] Convolution11 <- Pooling10
I0808 13:44:09.389812 20451 net.cpp:399] Convolution11 -> Convolution11
I0808 13:44:09.390442 20451 net.cpp:141] Setting up Convolution11
I0808 13:44:09.390453 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.390460 20451 net.cpp:156] Memory required for data: 622066432
I0808 13:44:09.390467 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.390476 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.390486 20451 layer_factory.hpp:77] Creating layer Pooling11
I0808 13:44:09.390496 20451 net.cpp:91] Creating Layer Pooling11
I0808 13:44:09.390504 20451 net.cpp:425] Pooling11 <- Convolution11
I0808 13:44:09.390516 20451 net.cpp:399] Pooling11 -> Pooling11
I0808 13:44:09.390573 20451 net.cpp:141] Setting up Pooling11
I0808 13:44:09.390581 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.390588 20451 net.cpp:156] Memory required for data: 624229632
I0808 13:44:09.390594 20451 layer_factory.hpp:77] Creating layer Convolution12
I0808 13:44:09.390609 20451 net.cpp:91] Creating Layer Convolution12
I0808 13:44:09.390616 20451 net.cpp:425] Convolution12 <- Pooling11
I0808 13:44:09.390628 20451 net.cpp:399] Convolution12 -> Convolution12
I0808 13:44:09.391801 20451 net.cpp:141] Setting up Convolution12
I0808 13:44:09.391819 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.391825 20451 net.cpp:156] Memory required for data: 625266432
I0808 13:44:09.391834 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.391844 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.391850 20451 layer_factory.hpp:77] Creating layer Pooling12
I0808 13:44:09.391862 20451 net.cpp:91] Creating Layer Pooling12
I0808 13:44:09.391870 20451 net.cpp:425] Pooling12 <- Convolution12
I0808 13:44:09.391882 20451 net.cpp:399] Pooling12 -> Pooling12
I0808 13:44:09.391943 20451 net.cpp:141] Setting up Pooling12
I0808 13:44:09.391952 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.391959 20451 net.cpp:156] Memory required for data: 625586432
I0808 13:44:09.391965 20451 layer_factory.hpp:77] Creating layer InnerProduct9
I0808 13:44:09.391978 20451 net.cpp:91] Creating Layer InnerProduct9
I0808 13:44:09.391985 20451 net.cpp:425] InnerProduct9 <- Pooling12
I0808 13:44:09.391998 20451 net.cpp:399] InnerProduct9 -> InnerProduct9
I0808 13:44:09.394227 20451 net.cpp:141] Setting up InnerProduct9
I0808 13:44:09.394244 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.394251 20451 net.cpp:156] Memory required for data: 625612032
I0808 13:44:09.394261 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.394270 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.394278 20451 layer_factory.hpp:77] Creating layer ReLU6
I0808 13:44:09.394289 20451 net.cpp:91] Creating Layer ReLU6
I0808 13:44:09.394297 20451 net.cpp:425] ReLU6 <- InnerProduct9
I0808 13:44:09.394307 20451 net.cpp:386] ReLU6 -> InnerProduct9 (in-place)
I0808 13:44:09.394320 20451 net.cpp:141] Setting up ReLU6
I0808 13:44:09.394330 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.394335 20451 net.cpp:156] Memory required for data: 625637632
I0808 13:44:09.394342 20451 layer_factory.hpp:77] Creating layer InnerProduct10
I0808 13:44:09.394354 20451 net.cpp:91] Creating Layer InnerProduct10
I0808 13:44:09.394361 20451 net.cpp:425] InnerProduct10 <- InnerProduct9
I0808 13:44:09.394372 20451 net.cpp:399] InnerProduct10 -> InnerProduct10
I0808 13:44:09.394670 20451 net.cpp:141] Setting up InnerProduct10
I0808 13:44:09.394680 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.394686 20451 net.cpp:156] Memory required for data: 625650432
I0808 13:44:09.394695 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.394703 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.394733 20451 layer_factory.hpp:77] Creating layer Concat2
I0808 13:44:09.394744 20451 net.cpp:91] Creating Layer Concat2
I0808 13:44:09.394752 20451 net.cpp:425] Concat2 <- InnerProduct8
I0808 13:44:09.394760 20451 net.cpp:425] Concat2 <- InnerProduct10
I0808 13:44:09.394771 20451 net.cpp:399] Concat2 -> Concat2
I0808 13:44:09.394807 20451 net.cpp:141] Setting up Concat2
I0808 13:44:09.394816 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.394822 20451 net.cpp:156] Memory required for data: 625676032
I0808 13:44:09.394829 20451 layer_factory.hpp:77] Creating layer InnerProduct11
I0808 13:44:09.394840 20451 net.cpp:91] Creating Layer InnerProduct11
I0808 13:44:09.394846 20451 net.cpp:425] InnerProduct11 <- Concat2
I0808 13:44:09.394857 20451 net.cpp:399] InnerProduct11 -> InnerProduct11
I0808 13:44:09.395072 20451 net.cpp:141] Setting up InnerProduct11
I0808 13:44:09.395081 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.395087 20451 net.cpp:156] Memory required for data: 625692416
I0808 13:44:09.395094 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.395103 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.395109 20451 layer_factory.hpp:77] Creating layer ReLU7
I0808 13:44:09.395119 20451 net.cpp:91] Creating Layer ReLU7
I0808 13:44:09.395125 20451 net.cpp:425] ReLU7 <- InnerProduct11
I0808 13:44:09.395135 20451 net.cpp:386] ReLU7 -> InnerProduct11 (in-place)
I0808 13:44:09.395145 20451 net.cpp:141] Setting up ReLU7
I0808 13:44:09.395154 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.395160 20451 net.cpp:156] Memory required for data: 625708800
I0808 13:44:09.395166 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.395176 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.395184 20451 net.cpp:425] drop1 <- InnerProduct11
I0808 13:44:09.395193 20451 net.cpp:399] drop1 -> Dropout3
I0808 13:44:09.395247 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.395256 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.395262 20451 net.cpp:156] Memory required for data: 625725184
I0808 13:44:09.395269 20451 layer_factory.hpp:77] Creating layer InnerProduct12
I0808 13:44:09.395287 20451 net.cpp:91] Creating Layer InnerProduct12
I0808 13:44:09.395294 20451 net.cpp:425] InnerProduct12 <- Dropout3
I0808 13:44:09.395305 20451 net.cpp:399] InnerProduct12 -> InnerProduct12
I0808 13:44:09.395535 20451 net.cpp:141] Setting up InnerProduct12
I0808 13:44:09.395546 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.395553 20451 net.cpp:156] Memory required for data: 625733376
I0808 13:44:09.395560 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.395570 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.395576 20451 layer_factory.hpp:77] Creating layer ReLU8
I0808 13:44:09.395586 20451 net.cpp:91] Creating Layer ReLU8
I0808 13:44:09.395592 20451 net.cpp:425] ReLU8 <- InnerProduct12
I0808 13:44:09.395602 20451 net.cpp:386] ReLU8 -> InnerProduct12 (in-place)
I0808 13:44:09.395614 20451 net.cpp:141] Setting up ReLU8
I0808 13:44:09.395622 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.395628 20451 net.cpp:156] Memory required for data: 625741568
I0808 13:44:09.395634 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.395644 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.395650 20451 net.cpp:425] drop2 <- InnerProduct12
I0808 13:44:09.395661 20451 net.cpp:399] drop2 -> Dropout4
I0808 13:44:09.395714 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.395723 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.395730 20451 net.cpp:156] Memory required for data: 625749760
I0808 13:44:09.395736 20451 layer_factory.hpp:77] Creating layer dt1
I0808 13:44:09.395746 20451 net.cpp:91] Creating Layer dt1
I0808 13:44:09.395753 20451 net.cpp:425] dt1 <- Dropout4
I0808 13:44:09.395779 20451 net.cpp:399] dt1 -> dt1
I0808 13:44:09.395941 20451 net.cpp:141] Setting up dt1
I0808 13:44:09.395951 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.395956 20451 net.cpp:156] Memory required for data: 625750016
I0808 13:44:09.395963 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.395972 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.395979 20451 layer_factory.hpp:77] Creating layer Convolution13
I0808 13:44:09.395993 20451 net.cpp:91] Creating Layer Convolution13
I0808 13:44:09.396000 20451 net.cpp:425] Convolution13 <- p1_p1_0_split_2
I0808 13:44:09.396013 20451 net.cpp:399] Convolution13 -> Convolution13
I0808 13:44:09.396432 20451 net.cpp:141] Setting up Convolution13
I0808 13:44:09.396442 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.396448 20451 net.cpp:156] Memory required for data: 644182016
I0808 13:44:09.396456 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.396464 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.396471 20451 layer_factory.hpp:77] Creating layer Pooling13
I0808 13:44:09.396481 20451 net.cpp:91] Creating Layer Pooling13
I0808 13:44:09.396487 20451 net.cpp:425] Pooling13 <- Convolution13
I0808 13:44:09.396498 20451 net.cpp:399] Pooling13 -> Pooling13
I0808 13:44:09.396553 20451 net.cpp:141] Setting up Pooling13
I0808 13:44:09.396562 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.396569 20451 net.cpp:156] Memory required for data: 648790016
I0808 13:44:09.396575 20451 layer_factory.hpp:77] Creating layer Convolution14
I0808 13:44:09.396589 20451 net.cpp:91] Creating Layer Convolution14
I0808 13:44:09.396595 20451 net.cpp:425] Convolution14 <- Pooling13
I0808 13:44:09.396606 20451 net.cpp:399] Convolution14 -> Convolution14
I0808 13:44:09.397207 20451 net.cpp:141] Setting up Convolution14
I0808 13:44:09.397217 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.397223 20451 net.cpp:156] Memory required for data: 657442816
I0808 13:44:09.397231 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.397239 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.397246 20451 layer_factory.hpp:77] Creating layer Pooling14
I0808 13:44:09.397258 20451 net.cpp:91] Creating Layer Pooling14
I0808 13:44:09.397264 20451 net.cpp:425] Pooling14 <- Convolution14
I0808 13:44:09.397274 20451 net.cpp:399] Pooling14 -> Pooling14
I0808 13:44:09.397331 20451 net.cpp:141] Setting up Pooling14
I0808 13:44:09.397341 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.397347 20451 net.cpp:156] Memory required for data: 659606016
I0808 13:44:09.397353 20451 layer_factory.hpp:77] Creating layer Convolution15
I0808 13:44:09.397367 20451 net.cpp:91] Creating Layer Convolution15
I0808 13:44:09.397373 20451 net.cpp:425] Convolution15 <- Pooling14
I0808 13:44:09.397385 20451 net.cpp:399] Convolution15 -> Convolution15
I0808 13:44:09.399047 20451 net.cpp:141] Setting up Convolution15
I0808 13:44:09.399065 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.399071 20451 net.cpp:156] Memory required for data: 660642816
I0808 13:44:09.399080 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.399088 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.399096 20451 layer_factory.hpp:77] Creating layer Pooling15
I0808 13:44:09.399107 20451 net.cpp:91] Creating Layer Pooling15
I0808 13:44:09.399116 20451 net.cpp:425] Pooling15 <- Convolution15
I0808 13:44:09.399127 20451 net.cpp:399] Pooling15 -> Pooling15
I0808 13:44:09.399188 20451 net.cpp:141] Setting up Pooling15
I0808 13:44:09.399197 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.399204 20451 net.cpp:156] Memory required for data: 660962816
I0808 13:44:09.399226 20451 layer_factory.hpp:77] Creating layer InnerProduct13
I0808 13:44:09.399240 20451 net.cpp:91] Creating Layer InnerProduct13
I0808 13:44:09.399245 20451 net.cpp:425] InnerProduct13 <- Pooling15
I0808 13:44:09.399258 20451 net.cpp:399] InnerProduct13 -> InnerProduct13
I0808 13:44:09.400501 20451 net.cpp:141] Setting up InnerProduct13
I0808 13:44:09.421360 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.421378 20451 net.cpp:156] Memory required for data: 660988416
I0808 13:44:09.421396 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.421408 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.421417 20451 layer_factory.hpp:77] Creating layer ReLU9
I0808 13:44:09.421434 20451 net.cpp:91] Creating Layer ReLU9
I0808 13:44:09.421468 20451 net.cpp:425] ReLU9 <- InnerProduct13
I0808 13:44:09.421483 20451 net.cpp:386] ReLU9 -> InnerProduct13 (in-place)
I0808 13:44:09.421504 20451 net.cpp:141] Setting up ReLU9
I0808 13:44:09.421514 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.421520 20451 net.cpp:156] Memory required for data: 661014016
I0808 13:44:09.421528 20451 layer_factory.hpp:77] Creating layer InnerProduct14
I0808 13:44:09.421545 20451 net.cpp:91] Creating Layer InnerProduct14
I0808 13:44:09.421553 20451 net.cpp:425] InnerProduct14 <- InnerProduct13
I0808 13:44:09.421567 20451 net.cpp:399] InnerProduct14 -> InnerProduct14
I0808 13:44:09.424439 20451 net.cpp:141] Setting up InnerProduct14
I0808 13:44:09.424456 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.424463 20451 net.cpp:156] Memory required for data: 661026816
I0808 13:44:09.424471 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.424479 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.424486 20451 layer_factory.hpp:77] Creating layer Convolution16
I0808 13:44:09.424502 20451 net.cpp:91] Creating Layer Convolution16
I0808 13:44:09.424510 20451 net.cpp:425] Convolution16 <- c22
I0808 13:44:09.424523 20451 net.cpp:399] Convolution16 -> Convolution16
I0808 13:44:09.424938 20451 net.cpp:141] Setting up Convolution16
I0808 13:44:09.424948 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.424953 20451 net.cpp:156] Memory required for data: 679458816
I0808 13:44:09.424960 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.424968 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.424974 20451 layer_factory.hpp:77] Creating layer Pooling16
I0808 13:44:09.424983 20451 net.cpp:91] Creating Layer Pooling16
I0808 13:44:09.424990 20451 net.cpp:425] Pooling16 <- Convolution16
I0808 13:44:09.425000 20451 net.cpp:399] Pooling16 -> Pooling16
I0808 13:44:09.425074 20451 net.cpp:141] Setting up Pooling16
I0808 13:44:09.425083 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.425088 20451 net.cpp:156] Memory required for data: 684066816
I0808 13:44:09.425094 20451 layer_factory.hpp:77] Creating layer Convolution17
I0808 13:44:09.425108 20451 net.cpp:91] Creating Layer Convolution17
I0808 13:44:09.425115 20451 net.cpp:425] Convolution17 <- Pooling16
I0808 13:44:09.425127 20451 net.cpp:399] Convolution17 -> Convolution17
I0808 13:44:09.425680 20451 net.cpp:141] Setting up Convolution17
I0808 13:44:09.425689 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.425695 20451 net.cpp:156] Memory required for data: 692719616
I0808 13:44:09.425724 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.425732 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.425739 20451 layer_factory.hpp:77] Creating layer Pooling17
I0808 13:44:09.425746 20451 net.cpp:91] Creating Layer Pooling17
I0808 13:44:09.425753 20451 net.cpp:425] Pooling17 <- Convolution17
I0808 13:44:09.425782 20451 net.cpp:399] Pooling17 -> Pooling17
I0808 13:44:09.425835 20451 net.cpp:141] Setting up Pooling17
I0808 13:44:09.425843 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.425849 20451 net.cpp:156] Memory required for data: 694882816
I0808 13:44:09.425854 20451 layer_factory.hpp:77] Creating layer Convolution18
I0808 13:44:09.425871 20451 net.cpp:91] Creating Layer Convolution18
I0808 13:44:09.425878 20451 net.cpp:425] Convolution18 <- Pooling17
I0808 13:44:09.425887 20451 net.cpp:399] Convolution18 -> Convolution18
I0808 13:44:09.426761 20451 net.cpp:141] Setting up Convolution18
I0808 13:44:09.426779 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.426787 20451 net.cpp:156] Memory required for data: 695919616
I0808 13:44:09.426798 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.426813 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.426821 20451 layer_factory.hpp:77] Creating layer Pooling18
I0808 13:44:09.426832 20451 net.cpp:91] Creating Layer Pooling18
I0808 13:44:09.426839 20451 net.cpp:425] Pooling18 <- Convolution18
I0808 13:44:09.426848 20451 net.cpp:399] Pooling18 -> Pooling18
I0808 13:44:09.426908 20451 net.cpp:141] Setting up Pooling18
I0808 13:44:09.426916 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.426921 20451 net.cpp:156] Memory required for data: 696239616
I0808 13:44:09.426928 20451 layer_factory.hpp:77] Creating layer InnerProduct15
I0808 13:44:09.426939 20451 net.cpp:91] Creating Layer InnerProduct15
I0808 13:44:09.426946 20451 net.cpp:425] InnerProduct15 <- Pooling18
I0808 13:44:09.426955 20451 net.cpp:399] InnerProduct15 -> InnerProduct15
I0808 13:44:09.428848 20451 net.cpp:141] Setting up InnerProduct15
I0808 13:44:09.428864 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.428869 20451 net.cpp:156] Memory required for data: 696265216
I0808 13:44:09.428877 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.428885 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.428892 20451 layer_factory.hpp:77] Creating layer ReLU10
I0808 13:44:09.428901 20451 net.cpp:91] Creating Layer ReLU10
I0808 13:44:09.428908 20451 net.cpp:425] ReLU10 <- InnerProduct15
I0808 13:44:09.428917 20451 net.cpp:386] ReLU10 -> InnerProduct15 (in-place)
I0808 13:44:09.428928 20451 net.cpp:141] Setting up ReLU10
I0808 13:44:09.428936 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.428941 20451 net.cpp:156] Memory required for data: 696290816
I0808 13:44:09.428947 20451 layer_factory.hpp:77] Creating layer InnerProduct16
I0808 13:44:09.428959 20451 net.cpp:91] Creating Layer InnerProduct16
I0808 13:44:09.428966 20451 net.cpp:425] InnerProduct16 <- InnerProduct15
I0808 13:44:09.428982 20451 net.cpp:399] InnerProduct16 -> InnerProduct16
I0808 13:44:09.429193 20451 net.cpp:141] Setting up InnerProduct16
I0808 13:44:09.429200 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.429206 20451 net.cpp:156] Memory required for data: 696303616
I0808 13:44:09.429213 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.429220 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.429226 20451 layer_factory.hpp:77] Creating layer Concat3
I0808 13:44:09.429235 20451 net.cpp:91] Creating Layer Concat3
I0808 13:44:09.429241 20451 net.cpp:425] Concat3 <- InnerProduct14
I0808 13:44:09.429250 20451 net.cpp:425] Concat3 <- InnerProduct16
I0808 13:44:09.429258 20451 net.cpp:399] Concat3 -> Concat3
I0808 13:44:09.429293 20451 net.cpp:141] Setting up Concat3
I0808 13:44:09.429301 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.429307 20451 net.cpp:156] Memory required for data: 696329216
I0808 13:44:09.429312 20451 layer_factory.hpp:77] Creating layer InnerProduct17
I0808 13:44:09.429323 20451 net.cpp:91] Creating Layer InnerProduct17
I0808 13:44:09.429345 20451 net.cpp:425] InnerProduct17 <- Concat3
I0808 13:44:09.429355 20451 net.cpp:399] InnerProduct17 -> InnerProduct17
I0808 13:44:09.429581 20451 net.cpp:141] Setting up InnerProduct17
I0808 13:44:09.429592 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.446019 20451 net.cpp:156] Memory required for data: 696345600
I0808 13:44:09.446045 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.446056 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.446063 20451 layer_factory.hpp:77] Creating layer ReLU11
I0808 13:44:09.446085 20451 net.cpp:91] Creating Layer ReLU11
I0808 13:44:09.446095 20451 net.cpp:425] ReLU11 <- InnerProduct17
I0808 13:44:09.446107 20451 net.cpp:386] ReLU11 -> InnerProduct17 (in-place)
I0808 13:44:09.446122 20451 net.cpp:141] Setting up ReLU11
I0808 13:44:09.446133 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.446140 20451 net.cpp:156] Memory required for data: 696361984
I0808 13:44:09.446146 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.446156 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.446166 20451 net.cpp:425] drop1 <- InnerProduct17
I0808 13:44:09.446176 20451 net.cpp:399] drop1 -> Dropout5
I0808 13:44:09.446307 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.446321 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.446327 20451 net.cpp:156] Memory required for data: 696378368
I0808 13:44:09.446333 20451 layer_factory.hpp:77] Creating layer InnerProduct18
I0808 13:44:09.446346 20451 net.cpp:91] Creating Layer InnerProduct18
I0808 13:44:09.446352 20451 net.cpp:425] InnerProduct18 <- Dropout5
I0808 13:44:09.446364 20451 net.cpp:399] InnerProduct18 -> InnerProduct18
I0808 13:44:09.446568 20451 net.cpp:141] Setting up InnerProduct18
I0808 13:44:09.446576 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.446583 20451 net.cpp:156] Memory required for data: 696386560
I0808 13:44:09.446589 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.446596 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.446602 20451 layer_factory.hpp:77] Creating layer ReLU12
I0808 13:44:09.446612 20451 net.cpp:91] Creating Layer ReLU12
I0808 13:44:09.446619 20451 net.cpp:425] ReLU12 <- InnerProduct18
I0808 13:44:09.446626 20451 net.cpp:386] ReLU12 -> InnerProduct18 (in-place)
I0808 13:44:09.446636 20451 net.cpp:141] Setting up ReLU12
I0808 13:44:09.446643 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.446650 20451 net.cpp:156] Memory required for data: 696394752
I0808 13:44:09.446655 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.446666 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.446671 20451 net.cpp:425] drop2 <- InnerProduct18
I0808 13:44:09.446681 20451 net.cpp:399] drop2 -> Dropout6
I0808 13:44:09.446755 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.446766 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.446773 20451 net.cpp:156] Memory required for data: 696402944
I0808 13:44:09.446779 20451 layer_factory.hpp:77] Creating layer dt2
I0808 13:44:09.446789 20451 net.cpp:91] Creating Layer dt2
I0808 13:44:09.446794 20451 net.cpp:425] dt2 <- Dropout6
I0808 13:44:09.446807 20451 net.cpp:399] dt2 -> dt2
I0808 13:44:09.446951 20451 net.cpp:141] Setting up dt2
I0808 13:44:09.446959 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.446965 20451 net.cpp:156] Memory required for data: 696403200
I0808 13:44:09.446971 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.446979 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.446985 20451 layer_factory.hpp:77] Creating layer Convolution19
I0808 13:44:09.447000 20451 net.cpp:91] Creating Layer Convolution19
I0808 13:44:09.447007 20451 net.cpp:425] Convolution19 <- p1_p1_0_split_3
I0808 13:44:09.447022 20451 net.cpp:399] Convolution19 -> Convolution19
I0808 13:44:09.448331 20451 net.cpp:141] Setting up Convolution19
I0808 13:44:09.448350 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.448357 20451 net.cpp:156] Memory required for data: 714835200
I0808 13:44:09.448369 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.448381 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.448388 20451 layer_factory.hpp:77] Creating layer Pooling19
I0808 13:44:09.448405 20451 net.cpp:91] Creating Layer Pooling19
I0808 13:44:09.448415 20451 net.cpp:425] Pooling19 <- Convolution19
I0808 13:44:09.448429 20451 net.cpp:399] Pooling19 -> Pooling19
I0808 13:44:09.448511 20451 net.cpp:141] Setting up Pooling19
I0808 13:44:09.448523 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.448530 20451 net.cpp:156] Memory required for data: 719443200
I0808 13:44:09.448537 20451 layer_factory.hpp:77] Creating layer Convolution20
I0808 13:44:09.448556 20451 net.cpp:91] Creating Layer Convolution20
I0808 13:44:09.448565 20451 net.cpp:425] Convolution20 <- Pooling19
I0808 13:44:09.448581 20451 net.cpp:399] Convolution20 -> Convolution20
I0808 13:44:09.449362 20451 net.cpp:141] Setting up Convolution20
I0808 13:44:09.449378 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.449385 20451 net.cpp:156] Memory required for data: 728096000
I0808 13:44:09.449394 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.449404 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.449412 20451 layer_factory.hpp:77] Creating layer Pooling20
I0808 13:44:09.449471 20451 net.cpp:91] Creating Layer Pooling20
I0808 13:44:09.449481 20451 net.cpp:425] Pooling20 <- Convolution20
I0808 13:44:09.449492 20451 net.cpp:399] Pooling20 -> Pooling20
I0808 13:44:09.449563 20451 net.cpp:141] Setting up Pooling20
I0808 13:44:09.449573 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.449580 20451 net.cpp:156] Memory required for data: 730259200
I0808 13:44:09.449589 20451 layer_factory.hpp:77] Creating layer Convolution21
I0808 13:44:09.449607 20451 net.cpp:91] Creating Layer Convolution21
I0808 13:44:09.449615 20451 net.cpp:425] Convolution21 <- Pooling20
I0808 13:44:09.449630 20451 net.cpp:399] Convolution21 -> Convolution21
I0808 13:44:09.450551 20451 net.cpp:141] Setting up Convolution21
I0808 13:44:09.450562 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.450567 20451 net.cpp:156] Memory required for data: 731296000
I0808 13:44:09.450574 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.450582 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.450588 20451 layer_factory.hpp:77] Creating layer Pooling21
I0808 13:44:09.450598 20451 net.cpp:91] Creating Layer Pooling21
I0808 13:44:09.450604 20451 net.cpp:425] Pooling21 <- Convolution21
I0808 13:44:09.450616 20451 net.cpp:399] Pooling21 -> Pooling21
I0808 13:44:09.450670 20451 net.cpp:141] Setting up Pooling21
I0808 13:44:09.450680 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.450685 20451 net.cpp:156] Memory required for data: 731616000
I0808 13:44:09.450691 20451 layer_factory.hpp:77] Creating layer InnerProduct19
I0808 13:44:09.450702 20451 net.cpp:91] Creating Layer InnerProduct19
I0808 13:44:09.450707 20451 net.cpp:425] InnerProduct19 <- Pooling21
I0808 13:44:09.450721 20451 net.cpp:399] InnerProduct19 -> InnerProduct19
I0808 13:44:09.451959 20451 net.cpp:141] Setting up InnerProduct19
I0808 13:44:09.451972 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.451978 20451 net.cpp:156] Memory required for data: 731641600
I0808 13:44:09.451985 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.451993 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.452018 20451 layer_factory.hpp:77] Creating layer ReLU13
I0808 13:44:09.452030 20451 net.cpp:91] Creating Layer ReLU13
I0808 13:44:09.452038 20451 net.cpp:425] ReLU13 <- InnerProduct19
I0808 13:44:09.479796 20451 net.cpp:386] ReLU13 -> InnerProduct19 (in-place)
I0808 13:44:09.479817 20451 net.cpp:141] Setting up ReLU13
I0808 13:44:09.479826 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.479832 20451 net.cpp:156] Memory required for data: 731667200
I0808 13:44:09.479838 20451 layer_factory.hpp:77] Creating layer InnerProduct20
I0808 13:44:09.479856 20451 net.cpp:91] Creating Layer InnerProduct20
I0808 13:44:09.479863 20451 net.cpp:425] InnerProduct20 <- InnerProduct19
I0808 13:44:09.479873 20451 net.cpp:399] InnerProduct20 -> InnerProduct20
I0808 13:44:09.480092 20451 net.cpp:141] Setting up InnerProduct20
I0808 13:44:09.480099 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.480105 20451 net.cpp:156] Memory required for data: 731680000
I0808 13:44:09.480113 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.480120 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.480126 20451 layer_factory.hpp:77] Creating layer Convolution22
I0808 13:44:09.480142 20451 net.cpp:91] Creating Layer Convolution22
I0808 13:44:09.480149 20451 net.cpp:425] Convolution22 <- c23
I0808 13:44:09.480161 20451 net.cpp:399] Convolution22 -> Convolution22
I0808 13:44:09.480540 20451 net.cpp:141] Setting up Convolution22
I0808 13:44:09.480548 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.480553 20451 net.cpp:156] Memory required for data: 750112000
I0808 13:44:09.480559 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.480567 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.480573 20451 layer_factory.hpp:77] Creating layer Pooling22
I0808 13:44:09.480581 20451 net.cpp:91] Creating Layer Pooling22
I0808 13:44:09.480587 20451 net.cpp:425] Pooling22 <- Convolution22
I0808 13:44:09.480600 20451 net.cpp:399] Pooling22 -> Pooling22
I0808 13:44:09.480651 20451 net.cpp:141] Setting up Pooling22
I0808 13:44:09.480661 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.480667 20451 net.cpp:156] Memory required for data: 754720000
I0808 13:44:09.480672 20451 layer_factory.hpp:77] Creating layer Convolution23
I0808 13:44:09.480684 20451 net.cpp:91] Creating Layer Convolution23
I0808 13:44:09.480690 20451 net.cpp:425] Convolution23 <- Pooling22
I0808 13:44:09.480702 20451 net.cpp:399] Convolution23 -> Convolution23
I0808 13:44:09.481317 20451 net.cpp:141] Setting up Convolution23
I0808 13:44:09.481328 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.481334 20451 net.cpp:156] Memory required for data: 763372800
I0808 13:44:09.481341 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.481348 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.481354 20451 layer_factory.hpp:77] Creating layer Pooling23
I0808 13:44:09.481366 20451 net.cpp:91] Creating Layer Pooling23
I0808 13:44:09.481372 20451 net.cpp:425] Pooling23 <- Convolution23
I0808 13:44:09.481382 20451 net.cpp:399] Pooling23 -> Pooling23
I0808 13:44:09.481449 20451 net.cpp:141] Setting up Pooling23
I0808 13:44:09.481462 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.481469 20451 net.cpp:156] Memory required for data: 765536000
I0808 13:44:09.481477 20451 layer_factory.hpp:77] Creating layer Convolution24
I0808 13:44:09.481497 20451 net.cpp:91] Creating Layer Convolution24
I0808 13:44:09.481504 20451 net.cpp:425] Convolution24 <- Pooling23
I0808 13:44:09.481518 20451 net.cpp:399] Convolution24 -> Convolution24
I0808 13:44:09.483038 20451 net.cpp:141] Setting up Convolution24
I0808 13:44:09.483052 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.483073 20451 net.cpp:156] Memory required for data: 766572800
I0808 13:44:09.483080 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.483088 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.483094 20451 layer_factory.hpp:77] Creating layer Pooling24
I0808 13:44:09.483106 20451 net.cpp:91] Creating Layer Pooling24
I0808 13:44:09.483114 20451 net.cpp:425] Pooling24 <- Convolution24
I0808 13:44:09.483122 20451 net.cpp:399] Pooling24 -> Pooling24
I0808 13:44:09.483178 20451 net.cpp:141] Setting up Pooling24
I0808 13:44:09.483186 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.483191 20451 net.cpp:156] Memory required for data: 766892800
I0808 13:44:09.483197 20451 layer_factory.hpp:77] Creating layer InnerProduct21
I0808 13:44:09.483209 20451 net.cpp:91] Creating Layer InnerProduct21
I0808 13:44:09.483216 20451 net.cpp:425] InnerProduct21 <- Pooling24
I0808 13:44:09.483225 20451 net.cpp:399] InnerProduct21 -> InnerProduct21
I0808 13:44:09.484881 20451 net.cpp:141] Setting up InnerProduct21
I0808 13:44:09.484894 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.484899 20451 net.cpp:156] Memory required for data: 766918400
I0808 13:44:09.484906 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.484915 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.484920 20451 layer_factory.hpp:77] Creating layer ReLU14
I0808 13:44:09.484928 20451 net.cpp:91] Creating Layer ReLU14
I0808 13:44:09.484935 20451 net.cpp:425] ReLU14 <- InnerProduct21
I0808 13:44:09.484946 20451 net.cpp:386] ReLU14 -> InnerProduct21 (in-place)
I0808 13:44:09.484956 20451 net.cpp:141] Setting up ReLU14
I0808 13:44:09.484964 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.484969 20451 net.cpp:156] Memory required for data: 766944000
I0808 13:44:09.484975 20451 layer_factory.hpp:77] Creating layer InnerProduct22
I0808 13:44:09.484985 20451 net.cpp:91] Creating Layer InnerProduct22
I0808 13:44:09.484992 20451 net.cpp:425] InnerProduct22 <- InnerProduct21
I0808 13:44:09.485003 20451 net.cpp:399] InnerProduct22 -> InnerProduct22
I0808 13:44:09.485193 20451 net.cpp:141] Setting up InnerProduct22
I0808 13:44:09.485200 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.485206 20451 net.cpp:156] Memory required for data: 766956800
I0808 13:44:09.485213 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.485219 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.485225 20451 layer_factory.hpp:77] Creating layer Concat4
I0808 13:44:09.485234 20451 net.cpp:91] Creating Layer Concat4
I0808 13:44:09.485239 20451 net.cpp:425] Concat4 <- InnerProduct20
I0808 13:44:09.485247 20451 net.cpp:425] Concat4 <- InnerProduct22
I0808 13:44:09.485258 20451 net.cpp:399] Concat4 -> Concat4
I0808 13:44:09.485288 20451 net.cpp:141] Setting up Concat4
I0808 13:44:09.485296 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.485301 20451 net.cpp:156] Memory required for data: 766982400
I0808 13:44:09.485306 20451 layer_factory.hpp:77] Creating layer InnerProduct23
I0808 13:44:09.485317 20451 net.cpp:91] Creating Layer InnerProduct23
I0808 13:44:09.485323 20451 net.cpp:425] InnerProduct23 <- Concat4
I0808 13:44:09.485335 20451 net.cpp:399] InnerProduct23 -> InnerProduct23
I0808 13:44:09.485538 20451 net.cpp:141] Setting up InnerProduct23
I0808 13:44:09.485546 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.485551 20451 net.cpp:156] Memory required for data: 766998784
I0808 13:44:09.485558 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.485564 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.485570 20451 layer_factory.hpp:77] Creating layer ReLU15
I0808 13:44:09.485590 20451 net.cpp:91] Creating Layer ReLU15
I0808 13:44:09.485596 20451 net.cpp:425] ReLU15 <- InnerProduct23
I0808 13:44:09.485605 20451 net.cpp:386] ReLU15 -> InnerProduct23 (in-place)
I0808 13:44:09.485615 20451 net.cpp:141] Setting up ReLU15
I0808 13:44:09.485621 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.485626 20451 net.cpp:156] Memory required for data: 767015168
I0808 13:44:09.485632 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.485641 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.485646 20451 net.cpp:425] drop1 <- InnerProduct23
I0808 13:44:09.485658 20451 net.cpp:399] drop1 -> Dropout7
I0808 13:44:09.485708 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.485716 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.485721 20451 net.cpp:156] Memory required for data: 767031552
I0808 13:44:09.485728 20451 layer_factory.hpp:77] Creating layer InnerProduct24
I0808 13:44:09.485738 20451 net.cpp:91] Creating Layer InnerProduct24
I0808 13:44:09.485744 20451 net.cpp:425] InnerProduct24 <- Dropout7
I0808 13:44:09.485754 20451 net.cpp:399] InnerProduct24 -> InnerProduct24
I0808 13:44:09.485911 20451 net.cpp:141] Setting up InnerProduct24
I0808 13:44:09.485918 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.485924 20451 net.cpp:156] Memory required for data: 767039744
I0808 13:44:09.485930 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.485936 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.485942 20451 layer_factory.hpp:77] Creating layer ReLU16
I0808 13:44:09.485950 20451 net.cpp:91] Creating Layer ReLU16
I0808 13:44:09.485955 20451 net.cpp:425] ReLU16 <- InnerProduct24
I0808 13:44:09.485963 20451 net.cpp:386] ReLU16 -> InnerProduct24 (in-place)
I0808 13:44:09.485972 20451 net.cpp:141] Setting up ReLU16
I0808 13:44:09.485980 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.485985 20451 net.cpp:156] Memory required for data: 767047936
I0808 13:44:09.485991 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.486001 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.486006 20451 net.cpp:425] drop2 <- InnerProduct24
I0808 13:44:09.486014 20451 net.cpp:399] drop2 -> Dropout8
I0808 13:44:09.486064 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.486071 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.486078 20451 net.cpp:156] Memory required for data: 767056128
I0808 13:44:09.486083 20451 layer_factory.hpp:77] Creating layer dt3
I0808 13:44:09.486091 20451 net.cpp:91] Creating Layer dt3
I0808 13:44:09.486098 20451 net.cpp:425] dt3 <- Dropout8
I0808 13:44:09.486107 20451 net.cpp:399] dt3 -> dt3
I0808 13:44:09.486250 20451 net.cpp:141] Setting up dt3
I0808 13:44:09.486258 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.486263 20451 net.cpp:156] Memory required for data: 767056384
I0808 13:44:09.486270 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.486277 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.486284 20451 layer_factory.hpp:77] Creating layer Convolution25
I0808 13:44:09.486296 20451 net.cpp:91] Creating Layer Convolution25
I0808 13:44:09.486304 20451 net.cpp:425] Convolution25 <- p1_p1_0_split_4
I0808 13:44:09.486315 20451 net.cpp:399] Convolution25 -> Convolution25
I0808 13:44:09.486676 20451 net.cpp:141] Setting up Convolution25
I0808 13:44:09.486685 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.486690 20451 net.cpp:156] Memory required for data: 785488384
I0808 13:44:09.486696 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.486703 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.486708 20451 layer_factory.hpp:77] Creating layer Pooling25
I0808 13:44:09.486719 20451 net.cpp:91] Creating Layer Pooling25
I0808 13:44:09.486726 20451 net.cpp:425] Pooling25 <- Convolution25
I0808 13:44:09.486743 20451 net.cpp:399] Pooling25 -> Pooling25
I0808 13:44:09.486796 20451 net.cpp:141] Setting up Pooling25
I0808 13:44:09.486804 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.486809 20451 net.cpp:156] Memory required for data: 790096384
I0808 13:44:09.486814 20451 layer_factory.hpp:77] Creating layer Convolution26
I0808 13:44:09.486827 20451 net.cpp:91] Creating Layer Convolution26
I0808 13:44:09.486834 20451 net.cpp:425] Convolution26 <- Pooling25
I0808 13:44:09.486845 20451 net.cpp:399] Convolution26 -> Convolution26
I0808 13:44:09.487390 20451 net.cpp:141] Setting up Convolution26
I0808 13:44:09.487398 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.487403 20451 net.cpp:156] Memory required for data: 798749184
I0808 13:44:09.487409 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.487416 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.487422 20451 layer_factory.hpp:77] Creating layer Pooling26
I0808 13:44:09.487431 20451 net.cpp:91] Creating Layer Pooling26
I0808 13:44:09.487437 20451 net.cpp:425] Pooling26 <- Convolution26
I0808 13:44:09.487447 20451 net.cpp:399] Pooling26 -> Pooling26
I0808 13:44:09.487498 20451 net.cpp:141] Setting up Pooling26
I0808 13:44:09.487504 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.487510 20451 net.cpp:156] Memory required for data: 800912384
I0808 13:44:09.487515 20451 layer_factory.hpp:77] Creating layer Convolution27
I0808 13:44:09.487530 20451 net.cpp:91] Creating Layer Convolution27
I0808 13:44:09.487536 20451 net.cpp:425] Convolution27 <- Pooling26
I0808 13:44:09.487545 20451 net.cpp:399] Convolution27 -> Convolution27
I0808 13:44:09.488354 20451 net.cpp:141] Setting up Convolution27
I0808 13:44:09.488363 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.488368 20451 net.cpp:156] Memory required for data: 801949184
I0808 13:44:09.488373 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.488380 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.488386 20451 layer_factory.hpp:77] Creating layer Pooling27
I0808 13:44:09.488394 20451 net.cpp:91] Creating Layer Pooling27
I0808 13:44:09.488400 20451 net.cpp:425] Pooling27 <- Convolution27
I0808 13:44:09.488409 20451 net.cpp:399] Pooling27 -> Pooling27
I0808 13:44:09.488461 20451 net.cpp:141] Setting up Pooling27
I0808 13:44:09.488469 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.488474 20451 net.cpp:156] Memory required for data: 802269184
I0808 13:44:09.488479 20451 layer_factory.hpp:77] Creating layer InnerProduct25
I0808 13:44:09.488490 20451 net.cpp:91] Creating Layer InnerProduct25
I0808 13:44:09.488497 20451 net.cpp:425] InnerProduct25 <- Pooling27
I0808 13:44:09.488508 20451 net.cpp:399] InnerProduct25 -> InnerProduct25
I0808 13:44:09.489588 20451 net.cpp:141] Setting up InnerProduct25
I0808 13:44:09.489598 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.489603 20451 net.cpp:156] Memory required for data: 802294784
I0808 13:44:09.489610 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.489617 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.489622 20451 layer_factory.hpp:77] Creating layer ReLU17
I0808 13:44:09.489630 20451 net.cpp:91] Creating Layer ReLU17
I0808 13:44:09.489636 20451 net.cpp:425] ReLU17 <- InnerProduct25
I0808 13:44:09.489645 20451 net.cpp:386] ReLU17 -> InnerProduct25 (in-place)
I0808 13:44:09.489653 20451 net.cpp:141] Setting up ReLU17
I0808 13:44:09.489660 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.489665 20451 net.cpp:156] Memory required for data: 802320384
I0808 13:44:09.489671 20451 layer_factory.hpp:77] Creating layer InnerProduct26
I0808 13:44:09.489681 20451 net.cpp:91] Creating Layer InnerProduct26
I0808 13:44:09.489697 20451 net.cpp:425] InnerProduct26 <- InnerProduct25
I0808 13:44:09.510792 20451 net.cpp:399] InnerProduct26 -> InnerProduct26
I0808 13:44:09.511013 20451 net.cpp:141] Setting up InnerProduct26
I0808 13:44:09.511023 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.511029 20451 net.cpp:156] Memory required for data: 802333184
I0808 13:44:09.511036 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.511044 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.511050 20451 layer_factory.hpp:77] Creating layer Convolution28
I0808 13:44:09.511064 20451 net.cpp:91] Creating Layer Convolution28
I0808 13:44:09.511071 20451 net.cpp:425] Convolution28 <- c24
I0808 13:44:09.511082 20451 net.cpp:399] Convolution28 -> Convolution28
I0808 13:44:09.511476 20451 net.cpp:141] Setting up Convolution28
I0808 13:44:09.511483 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.511489 20451 net.cpp:156] Memory required for data: 820765184
I0808 13:44:09.511495 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.511502 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.511508 20451 layer_factory.hpp:77] Creating layer Pooling28
I0808 13:44:09.511518 20451 net.cpp:91] Creating Layer Pooling28
I0808 13:44:09.511523 20451 net.cpp:425] Pooling28 <- Convolution28
I0808 13:44:09.511533 20451 net.cpp:399] Pooling28 -> Pooling28
I0808 13:44:09.511586 20451 net.cpp:141] Setting up Pooling28
I0808 13:44:09.511595 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.511600 20451 net.cpp:156] Memory required for data: 825373184
I0808 13:44:09.511605 20451 layer_factory.hpp:77] Creating layer Convolution29
I0808 13:44:09.511618 20451 net.cpp:91] Creating Layer Convolution29
I0808 13:44:09.511625 20451 net.cpp:425] Convolution29 <- Pooling28
I0808 13:44:09.511636 20451 net.cpp:399] Convolution29 -> Convolution29
I0808 13:44:09.512244 20451 net.cpp:141] Setting up Convolution29
I0808 13:44:09.512259 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.512265 20451 net.cpp:156] Memory required for data: 834025984
I0808 13:44:09.512274 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.512281 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.512287 20451 layer_factory.hpp:77] Creating layer Pooling29
I0808 13:44:09.512300 20451 net.cpp:91] Creating Layer Pooling29
I0808 13:44:09.512308 20451 net.cpp:425] Pooling29 <- Convolution29
I0808 13:44:09.512320 20451 net.cpp:399] Pooling29 -> Pooling29
I0808 13:44:09.512388 20451 net.cpp:141] Setting up Pooling29
I0808 13:44:09.512399 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.512406 20451 net.cpp:156] Memory required for data: 836189184
I0808 13:44:09.512413 20451 layer_factory.hpp:77] Creating layer Convolution30
I0808 13:44:09.512431 20451 net.cpp:91] Creating Layer Convolution30
I0808 13:44:09.512439 20451 net.cpp:425] Convolution30 <- Pooling29
I0808 13:44:09.512456 20451 net.cpp:399] Convolution30 -> Convolution30
I0808 13:44:09.513480 20451 net.cpp:141] Setting up Convolution30
I0808 13:44:09.513496 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.513502 20451 net.cpp:156] Memory required for data: 837225984
I0808 13:44:09.513510 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.513517 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.513523 20451 layer_factory.hpp:77] Creating layer Pooling30
I0808 13:44:09.513536 20451 net.cpp:91] Creating Layer Pooling30
I0808 13:44:09.513543 20451 net.cpp:425] Pooling30 <- Convolution30
I0808 13:44:09.513556 20451 net.cpp:399] Pooling30 -> Pooling30
I0808 13:44:09.513615 20451 net.cpp:141] Setting up Pooling30
I0808 13:44:09.513623 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.513648 20451 net.cpp:156] Memory required for data: 837545984
I0808 13:44:09.513653 20451 layer_factory.hpp:77] Creating layer InnerProduct27
I0808 13:44:09.513665 20451 net.cpp:91] Creating Layer InnerProduct27
I0808 13:44:09.513671 20451 net.cpp:425] InnerProduct27 <- Pooling30
I0808 13:44:09.513681 20451 net.cpp:399] InnerProduct27 -> InnerProduct27
I0808 13:44:09.515452 20451 net.cpp:141] Setting up InnerProduct27
I0808 13:44:09.515465 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.515471 20451 net.cpp:156] Memory required for data: 837571584
I0808 13:44:09.515480 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.515487 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.515493 20451 layer_factory.hpp:77] Creating layer ReLU18
I0808 13:44:09.515502 20451 net.cpp:91] Creating Layer ReLU18
I0808 13:44:09.515509 20451 net.cpp:425] ReLU18 <- InnerProduct27
I0808 13:44:09.515521 20451 net.cpp:386] ReLU18 -> InnerProduct27 (in-place)
I0808 13:44:09.515532 20451 net.cpp:141] Setting up ReLU18
I0808 13:44:09.515539 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.515544 20451 net.cpp:156] Memory required for data: 837597184
I0808 13:44:09.515550 20451 layer_factory.hpp:77] Creating layer InnerProduct28
I0808 13:44:09.515563 20451 net.cpp:91] Creating Layer InnerProduct28
I0808 13:44:09.515569 20451 net.cpp:425] InnerProduct28 <- InnerProduct27
I0808 13:44:09.515580 20451 net.cpp:399] InnerProduct28 -> InnerProduct28
I0808 13:44:09.515775 20451 net.cpp:141] Setting up InnerProduct28
I0808 13:44:09.515784 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.515789 20451 net.cpp:156] Memory required for data: 837609984
I0808 13:44:09.515795 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.515805 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.515811 20451 layer_factory.hpp:77] Creating layer Concat5
I0808 13:44:09.515820 20451 net.cpp:91] Creating Layer Concat5
I0808 13:44:09.515826 20451 net.cpp:425] Concat5 <- InnerProduct26
I0808 13:44:09.515833 20451 net.cpp:425] Concat5 <- InnerProduct28
I0808 13:44:09.515846 20451 net.cpp:399] Concat5 -> Concat5
I0808 13:44:09.515877 20451 net.cpp:141] Setting up Concat5
I0808 13:44:09.515884 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.515889 20451 net.cpp:156] Memory required for data: 837635584
I0808 13:44:09.515895 20451 layer_factory.hpp:77] Creating layer InnerProduct29
I0808 13:44:09.515908 20451 net.cpp:91] Creating Layer InnerProduct29
I0808 13:44:09.515913 20451 net.cpp:425] InnerProduct29 <- Concat5
I0808 13:44:09.515924 20451 net.cpp:399] InnerProduct29 -> InnerProduct29
I0808 13:44:09.516124 20451 net.cpp:141] Setting up InnerProduct29
I0808 13:44:09.516132 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.516137 20451 net.cpp:156] Memory required for data: 837651968
I0808 13:44:09.516144 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.516151 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.516157 20451 layer_factory.hpp:77] Creating layer ReLU19
I0808 13:44:09.516165 20451 net.cpp:91] Creating Layer ReLU19
I0808 13:44:09.516170 20451 net.cpp:425] ReLU19 <- InnerProduct29
I0808 13:44:09.516178 20451 net.cpp:386] ReLU19 -> InnerProduct29 (in-place)
I0808 13:44:09.516188 20451 net.cpp:141] Setting up ReLU19
I0808 13:44:09.516196 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.516201 20451 net.cpp:156] Memory required for data: 837668352
I0808 13:44:09.516206 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.516214 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.516221 20451 net.cpp:425] drop1 <- InnerProduct29
I0808 13:44:09.516232 20451 net.cpp:399] drop1 -> Dropout9
I0808 13:44:09.516284 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.541729 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.541744 20451 net.cpp:156] Memory required for data: 837684736
I0808 13:44:09.541755 20451 layer_factory.hpp:77] Creating layer InnerProduct30
I0808 13:44:09.541775 20451 net.cpp:91] Creating Layer InnerProduct30
I0808 13:44:09.541785 20451 net.cpp:425] InnerProduct30 <- Dropout9
I0808 13:44:09.541801 20451 net.cpp:399] InnerProduct30 -> InnerProduct30
I0808 13:44:09.542026 20451 net.cpp:141] Setting up InnerProduct30
I0808 13:44:09.542035 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.542042 20451 net.cpp:156] Memory required for data: 837692928
I0808 13:44:09.542049 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.542058 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.542064 20451 layer_factory.hpp:77] Creating layer ReLU20
I0808 13:44:09.542078 20451 net.cpp:91] Creating Layer ReLU20
I0808 13:44:09.542084 20451 net.cpp:425] ReLU20 <- InnerProduct30
I0808 13:44:09.542094 20451 net.cpp:386] ReLU20 -> InnerProduct30 (in-place)
I0808 13:44:09.542104 20451 net.cpp:141] Setting up ReLU20
I0808 13:44:09.542112 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.542119 20451 net.cpp:156] Memory required for data: 837701120
I0808 13:44:09.542125 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.542136 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.542145 20451 net.cpp:425] drop2 <- InnerProduct30
I0808 13:44:09.542155 20451 net.cpp:399] drop2 -> Dropout10
I0808 13:44:09.542214 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.542223 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.542229 20451 net.cpp:156] Memory required for data: 837709312
I0808 13:44:09.542235 20451 layer_factory.hpp:77] Creating layer dt4
I0808 13:44:09.542245 20451 net.cpp:91] Creating Layer dt4
I0808 13:44:09.542253 20451 net.cpp:425] dt4 <- Dropout10
I0808 13:44:09.542264 20451 net.cpp:399] dt4 -> dt4
I0808 13:44:09.542428 20451 net.cpp:141] Setting up dt4
I0808 13:44:09.542438 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.542443 20451 net.cpp:156] Memory required for data: 837709568
I0808 13:44:09.542495 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.542505 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.542512 20451 layer_factory.hpp:77] Creating layer Convolution31
I0808 13:44:09.542526 20451 net.cpp:91] Creating Layer Convolution31
I0808 13:44:09.542533 20451 net.cpp:425] Convolution31 <- p1_p1_0_split_5
I0808 13:44:09.542546 20451 net.cpp:399] Convolution31 -> Convolution31
I0808 13:44:09.543006 20451 net.cpp:141] Setting up Convolution31
I0808 13:44:09.543018 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.543025 20451 net.cpp:156] Memory required for data: 856141568
I0808 13:44:09.543031 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.543040 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.543046 20451 layer_factory.hpp:77] Creating layer Pooling31
I0808 13:44:09.543062 20451 net.cpp:91] Creating Layer Pooling31
I0808 13:44:09.543071 20451 net.cpp:425] Pooling31 <- Convolution31
I0808 13:44:09.543083 20451 net.cpp:399] Pooling31 -> Pooling31
I0808 13:44:09.543159 20451 net.cpp:141] Setting up Pooling31
I0808 13:44:09.543167 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.543174 20451 net.cpp:156] Memory required for data: 860749568
I0808 13:44:09.543180 20451 layer_factory.hpp:77] Creating layer Convolution32
I0808 13:44:09.543195 20451 net.cpp:91] Creating Layer Convolution32
I0808 13:44:09.543202 20451 net.cpp:425] Convolution32 <- Pooling31
I0808 13:44:09.543217 20451 net.cpp:399] Convolution32 -> Convolution32
I0808 13:44:09.544507 20451 net.cpp:141] Setting up Convolution32
I0808 13:44:09.544524 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.544548 20451 net.cpp:156] Memory required for data: 869402368
I0808 13:44:09.544556 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.544565 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.544572 20451 layer_factory.hpp:77] Creating layer Pooling32
I0808 13:44:09.544582 20451 net.cpp:91] Creating Layer Pooling32
I0808 13:44:09.544590 20451 net.cpp:425] Pooling32 <- Convolution32
I0808 13:44:09.544601 20451 net.cpp:399] Pooling32 -> Pooling32
I0808 13:44:09.544664 20451 net.cpp:141] Setting up Pooling32
I0808 13:44:09.544673 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.544679 20451 net.cpp:156] Memory required for data: 871565568
I0808 13:44:09.544685 20451 layer_factory.hpp:77] Creating layer Convolution33
I0808 13:44:09.544701 20451 net.cpp:91] Creating Layer Convolution33
I0808 13:44:09.544708 20451 net.cpp:425] Convolution33 <- Pooling32
I0808 13:44:09.544723 20451 net.cpp:399] Convolution33 -> Convolution33
I0808 13:44:09.545693 20451 net.cpp:141] Setting up Convolution33
I0808 13:44:09.545704 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.545711 20451 net.cpp:156] Memory required for data: 872602368
I0808 13:44:09.545718 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.545727 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.545733 20451 layer_factory.hpp:77] Creating layer Pooling33
I0808 13:44:09.545743 20451 net.cpp:91] Creating Layer Pooling33
I0808 13:44:09.545750 20451 net.cpp:425] Pooling33 <- Convolution33
I0808 13:44:09.545763 20451 net.cpp:399] Pooling33 -> Pooling33
I0808 13:44:09.545822 20451 net.cpp:141] Setting up Pooling33
I0808 13:44:09.545833 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.545840 20451 net.cpp:156] Memory required for data: 872922368
I0808 13:44:09.545846 20451 layer_factory.hpp:77] Creating layer InnerProduct31
I0808 13:44:09.545857 20451 net.cpp:91] Creating Layer InnerProduct31
I0808 13:44:09.545863 20451 net.cpp:425] InnerProduct31 <- Pooling33
I0808 13:44:09.545877 20451 net.cpp:399] InnerProduct31 -> InnerProduct31
I0808 13:44:09.547140 20451 net.cpp:141] Setting up InnerProduct31
I0808 13:44:09.547149 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.547155 20451 net.cpp:156] Memory required for data: 872947968
I0808 13:44:09.547163 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.547171 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.547178 20451 layer_factory.hpp:77] Creating layer ReLU21
I0808 13:44:09.547189 20451 net.cpp:91] Creating Layer ReLU21
I0808 13:44:09.547196 20451 net.cpp:425] ReLU21 <- InnerProduct31
I0808 13:44:09.547205 20451 net.cpp:386] ReLU21 -> InnerProduct31 (in-place)
I0808 13:44:09.547215 20451 net.cpp:141] Setting up ReLU21
I0808 13:44:09.547224 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.547230 20451 net.cpp:156] Memory required for data: 872973568
I0808 13:44:09.547236 20451 layer_factory.hpp:77] Creating layer InnerProduct32
I0808 13:44:09.547250 20451 net.cpp:91] Creating Layer InnerProduct32
I0808 13:44:09.547256 20451 net.cpp:425] InnerProduct32 <- InnerProduct31
I0808 13:44:09.547266 20451 net.cpp:399] InnerProduct32 -> InnerProduct32
I0808 13:44:09.547509 20451 net.cpp:141] Setting up InnerProduct32
I0808 13:44:09.547518 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.547524 20451 net.cpp:156] Memory required for data: 872986368
I0808 13:44:09.547533 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.547540 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.547546 20451 layer_factory.hpp:77] Creating layer Convolution34
I0808 13:44:09.547566 20451 net.cpp:91] Creating Layer Convolution34
I0808 13:44:09.547593 20451 net.cpp:425] Convolution34 <- c25
I0808 13:44:09.547610 20451 net.cpp:399] Convolution34 -> Convolution34
I0808 13:44:09.548050 20451 net.cpp:141] Setting up Convolution34
I0808 13:44:09.548061 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.548068 20451 net.cpp:156] Memory required for data: 891418368
I0808 13:44:09.548075 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.548082 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.548089 20451 layer_factory.hpp:77] Creating layer Pooling34
I0808 13:44:09.548099 20451 net.cpp:91] Creating Layer Pooling34
I0808 13:44:09.548106 20451 net.cpp:425] Pooling34 <- Convolution34
I0808 13:44:09.548120 20451 net.cpp:399] Pooling34 -> Pooling34
I0808 13:44:09.548177 20451 net.cpp:141] Setting up Pooling34
I0808 13:44:09.548189 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.548195 20451 net.cpp:156] Memory required for data: 896026368
I0808 13:44:09.548202 20451 layer_factory.hpp:77] Creating layer Convolution35
I0808 13:44:09.548213 20451 net.cpp:91] Creating Layer Convolution35
I0808 13:44:09.548220 20451 net.cpp:425] Convolution35 <- Pooling34
I0808 13:44:09.548234 20451 net.cpp:399] Convolution35 -> Convolution35
I0808 13:44:09.548848 20451 net.cpp:141] Setting up Convolution35
I0808 13:44:09.548858 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.548864 20451 net.cpp:156] Memory required for data: 904679168
I0808 13:44:09.548871 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.548879 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.548885 20451 layer_factory.hpp:77] Creating layer Pooling35
I0808 13:44:09.548898 20451 net.cpp:91] Creating Layer Pooling35
I0808 13:44:09.548907 20451 net.cpp:425] Pooling35 <- Convolution35
I0808 13:44:09.548916 20451 net.cpp:399] Pooling35 -> Pooling35
I0808 13:44:09.548975 20451 net.cpp:141] Setting up Pooling35
I0808 13:44:09.548985 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.548990 20451 net.cpp:156] Memory required for data: 906842368
I0808 13:44:09.548996 20451 layer_factory.hpp:77] Creating layer Convolution36
I0808 13:44:09.549010 20451 net.cpp:91] Creating Layer Convolution36
I0808 13:44:09.549017 20451 net.cpp:425] Convolution36 <- Pooling35
I0808 13:44:09.549032 20451 net.cpp:399] Convolution36 -> Convolution36
I0808 13:44:09.549980 20451 net.cpp:141] Setting up Convolution36
I0808 13:44:09.549990 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.549996 20451 net.cpp:156] Memory required for data: 907879168
I0808 13:44:09.550004 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.550011 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.550017 20451 layer_factory.hpp:77] Creating layer Pooling36
I0808 13:44:09.550026 20451 net.cpp:91] Creating Layer Pooling36
I0808 13:44:09.550034 20451 net.cpp:425] Pooling36 <- Convolution36
I0808 13:44:09.550047 20451 net.cpp:399] Pooling36 -> Pooling36
I0808 13:44:09.550106 20451 net.cpp:141] Setting up Pooling36
I0808 13:44:09.550114 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.550120 20451 net.cpp:156] Memory required for data: 908199168
I0808 13:44:09.550127 20451 layer_factory.hpp:77] Creating layer InnerProduct33
I0808 13:44:09.550139 20451 net.cpp:91] Creating Layer InnerProduct33
I0808 13:44:09.550146 20451 net.cpp:425] InnerProduct33 <- Pooling36
I0808 13:44:09.550159 20451 net.cpp:399] InnerProduct33 -> InnerProduct33
I0808 13:44:09.552057 20451 net.cpp:141] Setting up InnerProduct33
I0808 13:44:09.552073 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.552078 20451 net.cpp:156] Memory required for data: 908224768
I0808 13:44:09.552088 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.552110 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.552117 20451 layer_factory.hpp:77] Creating layer ReLU22
I0808 13:44:09.552130 20451 net.cpp:91] Creating Layer ReLU22
I0808 13:44:09.552137 20451 net.cpp:425] ReLU22 <- InnerProduct33
I0808 13:44:09.552147 20451 net.cpp:386] ReLU22 -> InnerProduct33 (in-place)
I0808 13:44:09.552160 20451 net.cpp:141] Setting up ReLU22
I0808 13:44:09.552168 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.552175 20451 net.cpp:156] Memory required for data: 908250368
I0808 13:44:09.552181 20451 layer_factory.hpp:77] Creating layer InnerProduct34
I0808 13:44:09.552196 20451 net.cpp:91] Creating Layer InnerProduct34
I0808 13:44:09.552202 20451 net.cpp:425] InnerProduct34 <- InnerProduct33
I0808 13:44:09.552213 20451 net.cpp:399] InnerProduct34 -> InnerProduct34
I0808 13:44:09.552431 20451 net.cpp:141] Setting up InnerProduct34
I0808 13:44:09.552440 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.552446 20451 net.cpp:156] Memory required for data: 908263168
I0808 13:44:09.552453 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.552461 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.552469 20451 layer_factory.hpp:77] Creating layer Concat6
I0808 13:44:09.552479 20451 net.cpp:91] Creating Layer Concat6
I0808 13:44:09.552485 20451 net.cpp:425] Concat6 <- InnerProduct32
I0808 13:44:09.552494 20451 net.cpp:425] Concat6 <- InnerProduct34
I0808 13:44:09.552506 20451 net.cpp:399] Concat6 -> Concat6
I0808 13:44:09.552542 20451 net.cpp:141] Setting up Concat6
I0808 13:44:09.552553 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.552559 20451 net.cpp:156] Memory required for data: 908288768
I0808 13:44:09.552566 20451 layer_factory.hpp:77] Creating layer InnerProduct35
I0808 13:44:09.552575 20451 net.cpp:91] Creating Layer InnerProduct35
I0808 13:44:09.552582 20451 net.cpp:425] InnerProduct35 <- Concat6
I0808 13:44:09.552597 20451 net.cpp:399] InnerProduct35 -> InnerProduct35
I0808 13:44:09.552825 20451 net.cpp:141] Setting up InnerProduct35
I0808 13:44:09.552834 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.552840 20451 net.cpp:156] Memory required for data: 908305152
I0808 13:44:09.552847 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.552855 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.552862 20451 layer_factory.hpp:77] Creating layer ReLU23
I0808 13:44:09.552870 20451 net.cpp:91] Creating Layer ReLU23
I0808 13:44:09.552877 20451 net.cpp:425] ReLU23 <- InnerProduct35
I0808 13:44:09.552888 20451 net.cpp:386] ReLU23 -> InnerProduct35 (in-place)
I0808 13:44:09.552899 20451 net.cpp:141] Setting up ReLU23
I0808 13:44:09.552907 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.552913 20451 net.cpp:156] Memory required for data: 908321536
I0808 13:44:09.552919 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.552928 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.552935 20451 net.cpp:425] drop1 <- InnerProduct35
I0808 13:44:09.552947 20451 net.cpp:399] drop1 -> Dropout11
I0808 13:44:09.553005 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.553014 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.553022 20451 net.cpp:156] Memory required for data: 908337920
I0808 13:44:09.553028 20451 layer_factory.hpp:77] Creating layer InnerProduct36
I0808 13:44:09.553038 20451 net.cpp:91] Creating Layer InnerProduct36
I0808 13:44:09.553045 20451 net.cpp:425] InnerProduct36 <- Dropout11
I0808 13:44:09.553058 20451 net.cpp:399] InnerProduct36 -> InnerProduct36
I0808 13:44:09.553243 20451 net.cpp:141] Setting up InnerProduct36
I0808 13:44:09.553252 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.572880 20451 net.cpp:156] Memory required for data: 908346112
I0808 13:44:09.572896 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.572921 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.572928 20451 layer_factory.hpp:77] Creating layer ReLU24
I0808 13:44:09.572939 20451 net.cpp:91] Creating Layer ReLU24
I0808 13:44:09.572948 20451 net.cpp:425] ReLU24 <- InnerProduct36
I0808 13:44:09.572964 20451 net.cpp:386] ReLU24 -> InnerProduct36 (in-place)
I0808 13:44:09.572978 20451 net.cpp:141] Setting up ReLU24
I0808 13:44:09.572988 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.572994 20451 net.cpp:156] Memory required for data: 908354304
I0808 13:44:09.573000 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.573010 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.573017 20451 net.cpp:425] drop2 <- InnerProduct36
I0808 13:44:09.573027 20451 net.cpp:399] drop2 -> Dropout12
I0808 13:44:09.573110 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.573119 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.573125 20451 net.cpp:156] Memory required for data: 908362496
I0808 13:44:09.573132 20451 layer_factory.hpp:77] Creating layer dt5
I0808 13:44:09.573145 20451 net.cpp:91] Creating Layer dt5
I0808 13:44:09.573153 20451 net.cpp:425] dt5 <- Dropout12
I0808 13:44:09.573164 20451 net.cpp:399] dt5 -> dt5
I0808 13:44:09.573338 20451 net.cpp:141] Setting up dt5
I0808 13:44:09.573349 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.573355 20451 net.cpp:156] Memory required for data: 908362752
I0808 13:44:09.573362 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.573371 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.573377 20451 layer_factory.hpp:77] Creating layer Convolution37
I0808 13:44:09.573391 20451 net.cpp:91] Creating Layer Convolution37
I0808 13:44:09.573398 20451 net.cpp:425] Convolution37 <- p1_p1_0_split_6
I0808 13:44:09.573413 20451 net.cpp:399] Convolution37 -> Convolution37
I0808 13:44:09.573850 20451 net.cpp:141] Setting up Convolution37
I0808 13:44:09.573864 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.573871 20451 net.cpp:156] Memory required for data: 926794752
I0808 13:44:09.573880 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.573890 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.573962 20451 layer_factory.hpp:77] Creating layer Pooling37
I0808 13:44:09.573974 20451 net.cpp:91] Creating Layer Pooling37
I0808 13:44:09.573983 20451 net.cpp:425] Pooling37 <- Convolution37
I0808 13:44:09.574000 20451 net.cpp:399] Pooling37 -> Pooling37
I0808 13:44:09.574070 20451 net.cpp:141] Setting up Pooling37
I0808 13:44:09.574080 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.574086 20451 net.cpp:156] Memory required for data: 931402752
I0808 13:44:09.574093 20451 layer_factory.hpp:77] Creating layer Convolution38
I0808 13:44:09.574113 20451 net.cpp:91] Creating Layer Convolution38
I0808 13:44:09.574120 20451 net.cpp:425] Convolution38 <- Pooling37
I0808 13:44:09.574132 20451 net.cpp:399] Convolution38 -> Convolution38
I0808 13:44:09.574791 20451 net.cpp:141] Setting up Convolution38
I0808 13:44:09.574805 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.574811 20451 net.cpp:156] Memory required for data: 940055552
I0808 13:44:09.574818 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.574826 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.574833 20451 layer_factory.hpp:77] Creating layer Pooling38
I0808 13:44:09.574843 20451 net.cpp:91] Creating Layer Pooling38
I0808 13:44:09.574851 20451 net.cpp:425] Pooling38 <- Convolution38
I0808 13:44:09.574862 20451 net.cpp:399] Pooling38 -> Pooling38
I0808 13:44:09.574946 20451 net.cpp:141] Setting up Pooling38
I0808 13:44:09.574955 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.574973 20451 net.cpp:156] Memory required for data: 942218752
I0808 13:44:09.574980 20451 layer_factory.hpp:77] Creating layer Convolution39
I0808 13:44:09.574995 20451 net.cpp:91] Creating Layer Convolution39
I0808 13:44:09.575002 20451 net.cpp:425] Convolution39 <- Pooling38
I0808 13:44:09.575016 20451 net.cpp:399] Convolution39 -> Convolution39
I0808 13:44:09.576753 20451 net.cpp:141] Setting up Convolution39
I0808 13:44:09.576768 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.576776 20451 net.cpp:156] Memory required for data: 943255552
I0808 13:44:09.576783 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.576792 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.576799 20451 layer_factory.hpp:77] Creating layer Pooling39
I0808 13:44:09.576812 20451 net.cpp:91] Creating Layer Pooling39
I0808 13:44:09.576820 20451 net.cpp:425] Pooling39 <- Convolution39
I0808 13:44:09.576831 20451 net.cpp:399] Pooling39 -> Pooling39
I0808 13:44:09.576905 20451 net.cpp:141] Setting up Pooling39
I0808 13:44:09.576915 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.576920 20451 net.cpp:156] Memory required for data: 943575552
I0808 13:44:09.576926 20451 layer_factory.hpp:77] Creating layer InnerProduct37
I0808 13:44:09.576939 20451 net.cpp:91] Creating Layer InnerProduct37
I0808 13:44:09.576946 20451 net.cpp:425] InnerProduct37 <- Pooling39
I0808 13:44:09.576959 20451 net.cpp:399] InnerProduct37 -> InnerProduct37
I0808 13:44:09.578282 20451 net.cpp:141] Setting up InnerProduct37
I0808 13:44:09.578294 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.578300 20451 net.cpp:156] Memory required for data: 943601152
I0808 13:44:09.578308 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.578316 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.578322 20451 layer_factory.hpp:77] Creating layer ReLU25
I0808 13:44:09.578331 20451 net.cpp:91] Creating Layer ReLU25
I0808 13:44:09.578338 20451 net.cpp:425] ReLU25 <- InnerProduct37
I0808 13:44:09.578348 20451 net.cpp:386] ReLU25 -> InnerProduct37 (in-place)
I0808 13:44:09.578359 20451 net.cpp:141] Setting up ReLU25
I0808 13:44:09.578369 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.578375 20451 net.cpp:156] Memory required for data: 943626752
I0808 13:44:09.578382 20451 layer_factory.hpp:77] Creating layer InnerProduct38
I0808 13:44:09.578395 20451 net.cpp:91] Creating Layer InnerProduct38
I0808 13:44:09.578402 20451 net.cpp:425] InnerProduct38 <- InnerProduct37
I0808 13:44:09.578413 20451 net.cpp:399] InnerProduct38 -> InnerProduct38
I0808 13:44:09.578657 20451 net.cpp:141] Setting up InnerProduct38
I0808 13:44:09.578666 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.578672 20451 net.cpp:156] Memory required for data: 943639552
I0808 13:44:09.578680 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.578687 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.578694 20451 layer_factory.hpp:77] Creating layer Convolution40
I0808 13:44:09.578709 20451 net.cpp:91] Creating Layer Convolution40
I0808 13:44:09.578717 20451 net.cpp:425] Convolution40 <- c26
I0808 13:44:09.578729 20451 net.cpp:399] Convolution40 -> Convolution40
I0808 13:44:09.579226 20451 net.cpp:141] Setting up Convolution40
I0808 13:44:09.579236 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.579241 20451 net.cpp:156] Memory required for data: 962071552
I0808 13:44:09.579248 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.600095 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.600109 20451 layer_factory.hpp:77] Creating layer Pooling40
I0808 13:44:09.600144 20451 net.cpp:91] Creating Layer Pooling40
I0808 13:44:09.600154 20451 net.cpp:425] Pooling40 <- Convolution40
I0808 13:44:09.600168 20451 net.cpp:399] Pooling40 -> Pooling40
I0808 13:44:09.600270 20451 net.cpp:141] Setting up Pooling40
I0808 13:44:09.600278 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.600284 20451 net.cpp:156] Memory required for data: 966679552
I0808 13:44:09.600291 20451 layer_factory.hpp:77] Creating layer Convolution41
I0808 13:44:09.600307 20451 net.cpp:91] Creating Layer Convolution41
I0808 13:44:09.600314 20451 net.cpp:425] Convolution41 <- Pooling40
I0808 13:44:09.600324 20451 net.cpp:399] Convolution41 -> Convolution41
I0808 13:44:09.600965 20451 net.cpp:141] Setting up Convolution41
I0808 13:44:09.600973 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.600978 20451 net.cpp:156] Memory required for data: 975332352
I0808 13:44:09.600986 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.600992 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.600998 20451 layer_factory.hpp:77] Creating layer Pooling41
I0808 13:44:09.601009 20451 net.cpp:91] Creating Layer Pooling41
I0808 13:44:09.601016 20451 net.cpp:425] Pooling41 <- Convolution41
I0808 13:44:09.601025 20451 net.cpp:399] Pooling41 -> Pooling41
I0808 13:44:09.601090 20451 net.cpp:141] Setting up Pooling41
I0808 13:44:09.601099 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.601104 20451 net.cpp:156] Memory required for data: 977495552
I0808 13:44:09.601110 20451 layer_factory.hpp:77] Creating layer Convolution42
I0808 13:44:09.601124 20451 net.cpp:91] Creating Layer Convolution42
I0808 13:44:09.601130 20451 net.cpp:425] Convolution42 <- Pooling41
I0808 13:44:09.601142 20451 net.cpp:399] Convolution42 -> Convolution42
I0808 13:44:09.602092 20451 net.cpp:141] Setting up Convolution42
I0808 13:44:09.602104 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.602111 20451 net.cpp:156] Memory required for data: 978532352
I0808 13:44:09.602119 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.602129 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.602136 20451 layer_factory.hpp:77] Creating layer Pooling42
I0808 13:44:09.602150 20451 net.cpp:91] Creating Layer Pooling42
I0808 13:44:09.602159 20451 net.cpp:425] Pooling42 <- Convolution42
I0808 13:44:09.602170 20451 net.cpp:399] Pooling42 -> Pooling42
I0808 13:44:09.602252 20451 net.cpp:141] Setting up Pooling42
I0808 13:44:09.602262 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.602268 20451 net.cpp:156] Memory required for data: 978852352
I0808 13:44:09.602273 20451 layer_factory.hpp:77] Creating layer InnerProduct39
I0808 13:44:09.602286 20451 net.cpp:91] Creating Layer InnerProduct39
I0808 13:44:09.602293 20451 net.cpp:425] InnerProduct39 <- Pooling42
I0808 13:44:09.602303 20451 net.cpp:399] InnerProduct39 -> InnerProduct39
I0808 13:44:09.604176 20451 net.cpp:141] Setting up InnerProduct39
I0808 13:44:09.604195 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.604204 20451 net.cpp:156] Memory required for data: 978877952
I0808 13:44:09.604215 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.604225 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.604233 20451 layer_factory.hpp:77] Creating layer ReLU26
I0808 13:44:09.604248 20451 net.cpp:91] Creating Layer ReLU26
I0808 13:44:09.604256 20451 net.cpp:425] ReLU26 <- InnerProduct39
I0808 13:44:09.604269 20451 net.cpp:386] ReLU26 -> InnerProduct39 (in-place)
I0808 13:44:09.604282 20451 net.cpp:141] Setting up ReLU26
I0808 13:44:09.604292 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.604300 20451 net.cpp:156] Memory required for data: 978903552
I0808 13:44:09.604307 20451 layer_factory.hpp:77] Creating layer InnerProduct40
I0808 13:44:09.604336 20451 net.cpp:91] Creating Layer InnerProduct40
I0808 13:44:09.604344 20451 net.cpp:425] InnerProduct40 <- InnerProduct39
I0808 13:44:09.604360 20451 net.cpp:399] InnerProduct40 -> InnerProduct40
I0808 13:44:09.604610 20451 net.cpp:141] Setting up InnerProduct40
I0808 13:44:09.604619 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.604625 20451 net.cpp:156] Memory required for data: 978916352
I0808 13:44:09.604631 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.604640 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.604645 20451 layer_factory.hpp:77] Creating layer Concat7
I0808 13:44:09.604655 20451 net.cpp:91] Creating Layer Concat7
I0808 13:44:09.604661 20451 net.cpp:425] Concat7 <- InnerProduct38
I0808 13:44:09.604670 20451 net.cpp:425] Concat7 <- InnerProduct40
I0808 13:44:09.604679 20451 net.cpp:399] Concat7 -> Concat7
I0808 13:44:09.604719 20451 net.cpp:141] Setting up Concat7
I0808 13:44:09.604727 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.604732 20451 net.cpp:156] Memory required for data: 978941952
I0808 13:44:09.604737 20451 layer_factory.hpp:77] Creating layer InnerProduct41
I0808 13:44:09.604750 20451 net.cpp:91] Creating Layer InnerProduct41
I0808 13:44:09.604756 20451 net.cpp:425] InnerProduct41 <- Concat7
I0808 13:44:09.604766 20451 net.cpp:399] InnerProduct41 -> InnerProduct41
I0808 13:44:09.605113 20451 net.cpp:141] Setting up InnerProduct41
I0808 13:44:09.605125 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.605132 20451 net.cpp:156] Memory required for data: 978958336
I0808 13:44:09.605139 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.605147 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.605154 20451 layer_factory.hpp:77] Creating layer ReLU27
I0808 13:44:09.605164 20451 net.cpp:91] Creating Layer ReLU27
I0808 13:44:09.605170 20451 net.cpp:425] ReLU27 <- InnerProduct41
I0808 13:44:09.605183 20451 net.cpp:386] ReLU27 -> InnerProduct41 (in-place)
I0808 13:44:09.605196 20451 net.cpp:141] Setting up ReLU27
I0808 13:44:09.605204 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.605211 20451 net.cpp:156] Memory required for data: 978974720
I0808 13:44:09.605218 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.605229 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.605237 20451 net.cpp:425] drop1 <- InnerProduct41
I0808 13:44:09.605252 20451 net.cpp:399] drop1 -> Dropout13
I0808 13:44:09.605324 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.605334 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.605340 20451 net.cpp:156] Memory required for data: 978991104
I0808 13:44:09.605346 20451 layer_factory.hpp:77] Creating layer InnerProduct42
I0808 13:44:09.605360 20451 net.cpp:91] Creating Layer InnerProduct42
I0808 13:44:09.605367 20451 net.cpp:425] InnerProduct42 <- Dropout13
I0808 13:44:09.605379 20451 net.cpp:399] InnerProduct42 -> InnerProduct42
I0808 13:44:09.605638 20451 net.cpp:141] Setting up InnerProduct42
I0808 13:44:09.605648 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.605656 20451 net.cpp:156] Memory required for data: 978999296
I0808 13:44:09.605665 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.605675 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.605684 20451 layer_factory.hpp:77] Creating layer ReLU28
I0808 13:44:09.605695 20451 net.cpp:91] Creating Layer ReLU28
I0808 13:44:09.605703 20451 net.cpp:425] ReLU28 <- InnerProduct42
I0808 13:44:09.605715 20451 net.cpp:386] ReLU28 -> InnerProduct42 (in-place)
I0808 13:44:09.605728 20451 net.cpp:141] Setting up ReLU28
I0808 13:44:09.605739 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.605747 20451 net.cpp:156] Memory required for data: 979007488
I0808 13:44:09.605772 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.605785 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.605795 20451 net.cpp:425] drop2 <- InnerProduct42
I0808 13:44:09.605808 20451 net.cpp:399] drop2 -> Dropout14
I0808 13:44:09.605890 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.605898 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.605904 20451 net.cpp:156] Memory required for data: 979015680
I0808 13:44:09.605911 20451 layer_factory.hpp:77] Creating layer dt6
I0808 13:44:09.605922 20451 net.cpp:91] Creating Layer dt6
I0808 13:44:09.605928 20451 net.cpp:425] dt6 <- Dropout14
I0808 13:44:09.605939 20451 net.cpp:399] dt6 -> dt6
I0808 13:44:09.606164 20451 net.cpp:141] Setting up dt6
I0808 13:44:09.606192 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.606204 20451 net.cpp:156] Memory required for data: 979015936
I0808 13:44:09.606220 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.606233 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.606246 20451 layer_factory.hpp:77] Creating layer Convolution43
I0808 13:44:09.606263 20451 net.cpp:91] Creating Layer Convolution43
I0808 13:44:09.606271 20451 net.cpp:425] Convolution43 <- p1_p1_0_split_7
I0808 13:44:09.606288 20451 net.cpp:399] Convolution43 -> Convolution43
I0808 13:44:09.606880 20451 net.cpp:141] Setting up Convolution43
I0808 13:44:09.606894 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.606899 20451 net.cpp:156] Memory required for data: 997447936
I0808 13:44:09.606907 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.606914 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.606920 20451 layer_factory.hpp:77] Creating layer Pooling43
I0808 13:44:09.606930 20451 net.cpp:91] Creating Layer Pooling43
I0808 13:44:09.606936 20451 net.cpp:425] Pooling43 <- Convolution43
I0808 13:44:09.606947 20451 net.cpp:399] Pooling43 -> Pooling43
I0808 13:44:09.607014 20451 net.cpp:141] Setting up Pooling43
I0808 13:44:09.607023 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.607028 20451 net.cpp:156] Memory required for data: 1002055936
I0808 13:44:09.607033 20451 layer_factory.hpp:77] Creating layer Convolution44
I0808 13:44:09.607049 20451 net.cpp:91] Creating Layer Convolution44
I0808 13:44:09.607056 20451 net.cpp:425] Convolution44 <- Pooling43
I0808 13:44:09.607072 20451 net.cpp:399] Convolution44 -> Convolution44
I0808 13:44:09.607723 20451 net.cpp:141] Setting up Convolution44
I0808 13:44:09.607733 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.607738 20451 net.cpp:156] Memory required for data: 1010708736
I0808 13:44:09.607745 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.607753 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.607758 20451 layer_factory.hpp:77] Creating layer Pooling44
I0808 13:44:09.607767 20451 net.cpp:91] Creating Layer Pooling44
I0808 13:44:09.607774 20451 net.cpp:425] Pooling44 <- Convolution44
I0808 13:44:09.607782 20451 net.cpp:399] Pooling44 -> Pooling44
I0808 13:44:09.607842 20451 net.cpp:141] Setting up Pooling44
I0808 13:44:09.607852 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.607858 20451 net.cpp:156] Memory required for data: 1012871936
I0808 13:44:09.607864 20451 layer_factory.hpp:77] Creating layer Convolution45
I0808 13:44:09.607875 20451 net.cpp:91] Creating Layer Convolution45
I0808 13:44:09.607882 20451 net.cpp:425] Convolution45 <- Pooling44
I0808 13:44:09.607894 20451 net.cpp:399] Convolution45 -> Convolution45
I0808 13:44:09.609313 20451 net.cpp:141] Setting up Convolution45
I0808 13:44:09.609324 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.609330 20451 net.cpp:156] Memory required for data: 1013908736
I0808 13:44:09.609338 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.609359 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.609365 20451 layer_factory.hpp:77] Creating layer Pooling45
I0808 13:44:09.609375 20451 net.cpp:91] Creating Layer Pooling45
I0808 13:44:09.609381 20451 net.cpp:425] Pooling45 <- Convolution45
I0808 13:44:09.609393 20451 net.cpp:399] Pooling45 -> Pooling45
I0808 13:44:09.609443 20451 net.cpp:141] Setting up Pooling45
I0808 13:44:09.609454 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.609459 20451 net.cpp:156] Memory required for data: 1014228736
I0808 13:44:09.609465 20451 layer_factory.hpp:77] Creating layer InnerProduct43
I0808 13:44:09.609474 20451 net.cpp:91] Creating Layer InnerProduct43
I0808 13:44:09.609480 20451 net.cpp:425] InnerProduct43 <- Pooling45
I0808 13:44:09.609493 20451 net.cpp:399] InnerProduct43 -> InnerProduct43
I0808 13:44:09.610617 20451 net.cpp:141] Setting up InnerProduct43
I0808 13:44:09.610625 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.610631 20451 net.cpp:156] Memory required for data: 1014254336
I0808 13:44:09.610637 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.610644 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.610651 20451 layer_factory.hpp:77] Creating layer ReLU29
I0808 13:44:09.610661 20451 net.cpp:91] Creating Layer ReLU29
I0808 13:44:09.610667 20451 net.cpp:425] ReLU29 <- InnerProduct43
I0808 13:44:09.610676 20451 net.cpp:386] ReLU29 -> InnerProduct43 (in-place)
I0808 13:44:09.610685 20451 net.cpp:141] Setting up ReLU29
I0808 13:44:09.610692 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.610697 20451 net.cpp:156] Memory required for data: 1014279936
I0808 13:44:09.610703 20451 layer_factory.hpp:77] Creating layer InnerProduct44
I0808 13:44:09.610715 20451 net.cpp:91] Creating Layer InnerProduct44
I0808 13:44:09.610721 20451 net.cpp:425] InnerProduct44 <- InnerProduct43
I0808 13:44:09.610730 20451 net.cpp:399] InnerProduct44 -> InnerProduct44
I0808 13:44:09.610909 20451 net.cpp:141] Setting up InnerProduct44
I0808 13:44:09.610918 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.610923 20451 net.cpp:156] Memory required for data: 1014292736
I0808 13:44:09.610929 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.610935 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.610941 20451 layer_factory.hpp:77] Creating layer Convolution46
I0808 13:44:09.610955 20451 net.cpp:91] Creating Layer Convolution46
I0808 13:44:09.610962 20451 net.cpp:425] Convolution46 <- c27
I0808 13:44:09.610972 20451 net.cpp:399] Convolution46 -> Convolution46
I0808 13:44:09.611331 20451 net.cpp:141] Setting up Convolution46
I0808 13:44:09.611341 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.611346 20451 net.cpp:156] Memory required for data: 1032724736
I0808 13:44:09.611352 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.611359 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.611366 20451 layer_factory.hpp:77] Creating layer Pooling46
I0808 13:44:09.611374 20451 net.cpp:91] Creating Layer Pooling46
I0808 13:44:09.611380 20451 net.cpp:425] Pooling46 <- Convolution46
I0808 13:44:09.611392 20451 net.cpp:399] Pooling46 -> Pooling46
I0808 13:44:09.611448 20451 net.cpp:141] Setting up Pooling46
I0808 13:44:09.611459 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.637879 20451 net.cpp:156] Memory required for data: 1037332736
I0808 13:44:09.637907 20451 layer_factory.hpp:77] Creating layer Convolution47
I0808 13:44:09.637946 20451 net.cpp:91] Creating Layer Convolution47
I0808 13:44:09.637966 20451 net.cpp:425] Convolution47 <- Pooling46
I0808 13:44:09.638005 20451 net.cpp:399] Convolution47 -> Convolution47
I0808 13:44:09.638674 20451 net.cpp:141] Setting up Convolution47
I0808 13:44:09.638685 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.638692 20451 net.cpp:156] Memory required for data: 1045985536
I0808 13:44:09.638700 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.638712 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.638720 20451 layer_factory.hpp:77] Creating layer Pooling47
I0808 13:44:09.638733 20451 net.cpp:91] Creating Layer Pooling47
I0808 13:44:09.638741 20451 net.cpp:425] Pooling47 <- Convolution47
I0808 13:44:09.638752 20451 net.cpp:399] Pooling47 -> Pooling47
I0808 13:44:09.638821 20451 net.cpp:141] Setting up Pooling47
I0808 13:44:09.638834 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.638844 20451 net.cpp:156] Memory required for data: 1048148736
I0808 13:44:09.638851 20451 layer_factory.hpp:77] Creating layer Convolution48
I0808 13:44:09.638867 20451 net.cpp:91] Creating Layer Convolution48
I0808 13:44:09.638873 20451 net.cpp:425] Convolution48 <- Pooling47
I0808 13:44:09.638886 20451 net.cpp:399] Convolution48 -> Convolution48
I0808 13:44:09.640533 20451 net.cpp:141] Setting up Convolution48
I0808 13:44:09.640552 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.640560 20451 net.cpp:156] Memory required for data: 1049185536
I0808 13:44:09.640570 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.640580 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.640588 20451 layer_factory.hpp:77] Creating layer Pooling48
I0808 13:44:09.640600 20451 net.cpp:91] Creating Layer Pooling48
I0808 13:44:09.640609 20451 net.cpp:425] Pooling48 <- Convolution48
I0808 13:44:09.640619 20451 net.cpp:399] Pooling48 -> Pooling48
I0808 13:44:09.640677 20451 net.cpp:141] Setting up Pooling48
I0808 13:44:09.640686 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.640691 20451 net.cpp:156] Memory required for data: 1049505536
I0808 13:44:09.640697 20451 layer_factory.hpp:77] Creating layer InnerProduct45
I0808 13:44:09.640708 20451 net.cpp:91] Creating Layer InnerProduct45
I0808 13:44:09.640715 20451 net.cpp:425] InnerProduct45 <- Pooling48
I0808 13:44:09.640725 20451 net.cpp:399] InnerProduct45 -> InnerProduct45
I0808 13:44:09.642388 20451 net.cpp:141] Setting up InnerProduct45
I0808 13:44:09.642400 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.642406 20451 net.cpp:156] Memory required for data: 1049531136
I0808 13:44:09.642415 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.642421 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.642427 20451 layer_factory.hpp:77] Creating layer ReLU30
I0808 13:44:09.642436 20451 net.cpp:91] Creating Layer ReLU30
I0808 13:44:09.642442 20451 net.cpp:425] ReLU30 <- InnerProduct45
I0808 13:44:09.642453 20451 net.cpp:386] ReLU30 -> InnerProduct45 (in-place)
I0808 13:44:09.642464 20451 net.cpp:141] Setting up ReLU30
I0808 13:44:09.642472 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.642477 20451 net.cpp:156] Memory required for data: 1049556736
I0808 13:44:09.642482 20451 layer_factory.hpp:77] Creating layer InnerProduct46
I0808 13:44:09.642493 20451 net.cpp:91] Creating Layer InnerProduct46
I0808 13:44:09.642498 20451 net.cpp:425] InnerProduct46 <- InnerProduct45
I0808 13:44:09.642510 20451 net.cpp:399] InnerProduct46 -> InnerProduct46
I0808 13:44:09.642772 20451 net.cpp:141] Setting up InnerProduct46
I0808 13:44:09.642781 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.642786 20451 net.cpp:156] Memory required for data: 1049569536
I0808 13:44:09.642793 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.642801 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.642822 20451 layer_factory.hpp:77] Creating layer Concat8
I0808 13:44:09.642834 20451 net.cpp:91] Creating Layer Concat8
I0808 13:44:09.642840 20451 net.cpp:425] Concat8 <- InnerProduct44
I0808 13:44:09.642848 20451 net.cpp:425] Concat8 <- InnerProduct46
I0808 13:44:09.642858 20451 net.cpp:399] Concat8 -> Concat8
I0808 13:44:09.642889 20451 net.cpp:141] Setting up Concat8
I0808 13:44:09.642897 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.642902 20451 net.cpp:156] Memory required for data: 1049595136
I0808 13:44:09.642909 20451 layer_factory.hpp:77] Creating layer InnerProduct47
I0808 13:44:09.642916 20451 net.cpp:91] Creating Layer InnerProduct47
I0808 13:44:09.642922 20451 net.cpp:425] InnerProduct47 <- Concat8
I0808 13:44:09.642935 20451 net.cpp:399] InnerProduct47 -> InnerProduct47
I0808 13:44:09.643127 20451 net.cpp:141] Setting up InnerProduct47
I0808 13:44:09.643136 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.643141 20451 net.cpp:156] Memory required for data: 1049611520
I0808 13:44:09.643146 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.643153 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.643159 20451 layer_factory.hpp:77] Creating layer ReLU31
I0808 13:44:09.643167 20451 net.cpp:91] Creating Layer ReLU31
I0808 13:44:09.643172 20451 net.cpp:425] ReLU31 <- InnerProduct47
I0808 13:44:09.643182 20451 net.cpp:386] ReLU31 -> InnerProduct47 (in-place)
I0808 13:44:09.643191 20451 net.cpp:141] Setting up ReLU31
I0808 13:44:09.643199 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.643204 20451 net.cpp:156] Memory required for data: 1049627904
I0808 13:44:09.643209 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.643218 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.643224 20451 net.cpp:425] drop1 <- InnerProduct47
I0808 13:44:09.643232 20451 net.cpp:399] drop1 -> Dropout15
I0808 13:44:09.643311 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.643321 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.643326 20451 net.cpp:156] Memory required for data: 1049644288
I0808 13:44:09.643332 20451 layer_factory.hpp:77] Creating layer InnerProduct48
I0808 13:44:09.643345 20451 net.cpp:91] Creating Layer InnerProduct48
I0808 13:44:09.643352 20451 net.cpp:425] InnerProduct48 <- Dropout15
I0808 13:44:09.643363 20451 net.cpp:399] InnerProduct48 -> InnerProduct48
I0808 13:44:09.643548 20451 net.cpp:141] Setting up InnerProduct48
I0808 13:44:09.643556 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.643563 20451 net.cpp:156] Memory required for data: 1049652480
I0808 13:44:09.643569 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.643578 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.643584 20451 layer_factory.hpp:77] Creating layer ReLU32
I0808 13:44:09.643595 20451 net.cpp:91] Creating Layer ReLU32
I0808 13:44:09.643602 20451 net.cpp:425] ReLU32 <- InnerProduct48
I0808 13:44:09.643611 20451 net.cpp:386] ReLU32 -> InnerProduct48 (in-place)
I0808 13:44:09.643622 20451 net.cpp:141] Setting up ReLU32
I0808 13:44:09.643630 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.643636 20451 net.cpp:156] Memory required for data: 1049660672
I0808 13:44:09.643642 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.643651 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.643658 20451 net.cpp:425] drop2 <- InnerProduct48
I0808 13:44:09.662214 20451 net.cpp:399] drop2 -> Dropout16
I0808 13:44:09.662407 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.662431 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.662446 20451 net.cpp:156] Memory required for data: 1049668864
I0808 13:44:09.662461 20451 layer_factory.hpp:77] Creating layer dt7
I0808 13:44:09.662494 20451 net.cpp:91] Creating Layer dt7
I0808 13:44:09.662511 20451 net.cpp:425] dt7 <- Dropout16
I0808 13:44:09.662539 20451 net.cpp:399] dt7 -> dt7
I0808 13:44:09.662963 20451 net.cpp:141] Setting up dt7
I0808 13:44:09.662984 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.662998 20451 net.cpp:156] Memory required for data: 1049669120
I0808 13:44:09.663017 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.663036 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.663053 20451 layer_factory.hpp:77] Creating layer Convolution49
I0808 13:44:09.663087 20451 net.cpp:91] Creating Layer Convolution49
I0808 13:44:09.663106 20451 net.cpp:425] Convolution49 <- p1_p1_0_split_8
I0808 13:44:09.663141 20451 net.cpp:399] Convolution49 -> Convolution49
I0808 13:44:09.664099 20451 net.cpp:141] Setting up Convolution49
I0808 13:44:09.664127 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.664141 20451 net.cpp:156] Memory required for data: 1068101120
I0808 13:44:09.664158 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.664177 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.664192 20451 layer_factory.hpp:77] Creating layer Pooling49
I0808 13:44:09.664378 20451 net.cpp:91] Creating Layer Pooling49
I0808 13:44:09.664397 20451 net.cpp:425] Pooling49 <- Convolution49
I0808 13:44:09.664422 20451 net.cpp:399] Pooling49 -> Pooling49
I0808 13:44:09.664566 20451 net.cpp:141] Setting up Pooling49
I0808 13:44:09.664587 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.664602 20451 net.cpp:156] Memory required for data: 1072709120
I0808 13:44:09.664618 20451 layer_factory.hpp:77] Creating layer Convolution50
I0808 13:44:09.664654 20451 net.cpp:91] Creating Layer Convolution50
I0808 13:44:09.664670 20451 net.cpp:425] Convolution50 <- Pooling49
I0808 13:44:09.664697 20451 net.cpp:399] Convolution50 -> Convolution50
I0808 13:44:09.666095 20451 net.cpp:141] Setting up Convolution50
I0808 13:44:09.666122 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.666137 20451 net.cpp:156] Memory required for data: 1081361920
I0808 13:44:09.666154 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.666173 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.666190 20451 layer_factory.hpp:77] Creating layer Pooling50
I0808 13:44:09.666218 20451 net.cpp:91] Creating Layer Pooling50
I0808 13:44:09.666234 20451 net.cpp:425] Pooling50 <- Convolution50
I0808 13:44:09.666263 20451 net.cpp:399] Pooling50 -> Pooling50
I0808 13:44:09.666421 20451 net.cpp:141] Setting up Pooling50
I0808 13:44:09.666445 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.666458 20451 net.cpp:156] Memory required for data: 1083525120
I0808 13:44:09.666473 20451 layer_factory.hpp:77] Creating layer Convolution51
I0808 13:44:09.666510 20451 net.cpp:91] Creating Layer Convolution51
I0808 13:44:09.666528 20451 net.cpp:425] Convolution51 <- Pooling50
I0808 13:44:09.666563 20451 net.cpp:399] Convolution51 -> Convolution51
I0808 13:44:09.668275 20451 net.cpp:141] Setting up Convolution51
I0808 13:44:09.668299 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.668309 20451 net.cpp:156] Memory required for data: 1084561920
I0808 13:44:09.668321 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.668334 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.668344 20451 layer_factory.hpp:77] Creating layer Pooling51
I0808 13:44:09.668357 20451 net.cpp:91] Creating Layer Pooling51
I0808 13:44:09.668368 20451 net.cpp:425] Pooling51 <- Convolution51
I0808 13:44:09.668386 20451 net.cpp:399] Pooling51 -> Pooling51
I0808 13:44:09.668467 20451 net.cpp:141] Setting up Pooling51
I0808 13:44:09.668478 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.668486 20451 net.cpp:156] Memory required for data: 1084881920
I0808 13:44:09.668525 20451 layer_factory.hpp:77] Creating layer InnerProduct49
I0808 13:44:09.668543 20451 net.cpp:91] Creating Layer InnerProduct49
I0808 13:44:09.668552 20451 net.cpp:425] InnerProduct49 <- Pooling51
I0808 13:44:09.668570 20451 net.cpp:399] InnerProduct49 -> InnerProduct49
I0808 13:44:09.669797 20451 net.cpp:141] Setting up InnerProduct49
I0808 13:44:09.669809 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.669816 20451 net.cpp:156] Memory required for data: 1084907520
I0808 13:44:09.669824 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.669831 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.669838 20451 layer_factory.hpp:77] Creating layer ReLU33
I0808 13:44:09.669847 20451 net.cpp:91] Creating Layer ReLU33
I0808 13:44:09.669854 20451 net.cpp:425] ReLU33 <- InnerProduct49
I0808 13:44:09.669863 20451 net.cpp:386] ReLU33 -> InnerProduct49 (in-place)
I0808 13:44:09.669874 20451 net.cpp:141] Setting up ReLU33
I0808 13:44:09.669883 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.669888 20451 net.cpp:156] Memory required for data: 1084933120
I0808 13:44:09.669894 20451 layer_factory.hpp:77] Creating layer InnerProduct50
I0808 13:44:09.669908 20451 net.cpp:91] Creating Layer InnerProduct50
I0808 13:44:09.669914 20451 net.cpp:425] InnerProduct50 <- InnerProduct49
I0808 13:44:09.669927 20451 net.cpp:399] InnerProduct50 -> InnerProduct50
I0808 13:44:09.670233 20451 net.cpp:141] Setting up InnerProduct50
I0808 13:44:09.670243 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.670249 20451 net.cpp:156] Memory required for data: 1084945920
I0808 13:44:09.670256 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.670264 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.670274 20451 layer_factory.hpp:77] Creating layer Convolution52
I0808 13:44:09.670291 20451 net.cpp:91] Creating Layer Convolution52
I0808 13:44:09.670301 20451 net.cpp:425] Convolution52 <- c28
I0808 13:44:09.670320 20451 net.cpp:399] Convolution52 -> Convolution52
I0808 13:44:09.670727 20451 net.cpp:141] Setting up Convolution52
I0808 13:44:09.670735 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.670740 20451 net.cpp:156] Memory required for data: 1103377920
I0808 13:44:09.670747 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.670755 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.670761 20451 layer_factory.hpp:77] Creating layer Pooling52
I0808 13:44:09.670775 20451 net.cpp:91] Creating Layer Pooling52
I0808 13:44:09.670783 20451 net.cpp:425] Pooling52 <- Convolution52
I0808 13:44:09.670792 20451 net.cpp:399] Pooling52 -> Pooling52
I0808 13:44:09.670847 20451 net.cpp:141] Setting up Pooling52
I0808 13:44:09.670855 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.670861 20451 net.cpp:156] Memory required for data: 1107985920
I0808 13:44:09.670867 20451 layer_factory.hpp:77] Creating layer Convolution53
I0808 13:44:09.670881 20451 net.cpp:91] Creating Layer Convolution53
I0808 13:44:09.670887 20451 net.cpp:425] Convolution53 <- Pooling52
I0808 13:44:09.670898 20451 net.cpp:399] Convolution53 -> Convolution53
I0808 13:44:09.671481 20451 net.cpp:141] Setting up Convolution53
I0808 13:44:09.671494 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.671501 20451 net.cpp:156] Memory required for data: 1116638720
I0808 13:44:09.671510 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.671520 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.671528 20451 layer_factory.hpp:77] Creating layer Pooling53
I0808 13:44:09.671540 20451 net.cpp:91] Creating Layer Pooling53
I0808 13:44:09.671545 20451 net.cpp:425] Pooling53 <- Convolution53
I0808 13:44:09.671572 20451 net.cpp:399] Pooling53 -> Pooling53
I0808 13:44:09.671629 20451 net.cpp:141] Setting up Pooling53
I0808 13:44:09.671638 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.671643 20451 net.cpp:156] Memory required for data: 1118801920
I0808 13:44:09.671649 20451 layer_factory.hpp:77] Creating layer Convolution54
I0808 13:44:09.671663 20451 net.cpp:91] Creating Layer Convolution54
I0808 13:44:09.671669 20451 net.cpp:425] Convolution54 <- Pooling53
I0808 13:44:09.671682 20451 net.cpp:399] Convolution54 -> Convolution54
I0808 13:44:09.672597 20451 net.cpp:141] Setting up Convolution54
I0808 13:44:09.672607 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.672613 20451 net.cpp:156] Memory required for data: 1119838720
I0808 13:44:09.672621 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.672628 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.672634 20451 layer_factory.hpp:77] Creating layer Pooling54
I0808 13:44:09.672646 20451 net.cpp:91] Creating Layer Pooling54
I0808 13:44:09.672652 20451 net.cpp:425] Pooling54 <- Convolution54
I0808 13:44:09.672662 20451 net.cpp:399] Pooling54 -> Pooling54
I0808 13:44:09.672716 20451 net.cpp:141] Setting up Pooling54
I0808 13:44:09.672724 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.672730 20451 net.cpp:156] Memory required for data: 1120158720
I0808 13:44:09.672735 20451 layer_factory.hpp:77] Creating layer InnerProduct51
I0808 13:44:09.672746 20451 net.cpp:91] Creating Layer InnerProduct51
I0808 13:44:09.672752 20451 net.cpp:425] InnerProduct51 <- Pooling54
I0808 13:44:09.672765 20451 net.cpp:399] InnerProduct51 -> InnerProduct51
I0808 13:44:09.674540 20451 net.cpp:141] Setting up InnerProduct51
I0808 13:44:09.674554 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.674561 20451 net.cpp:156] Memory required for data: 1120184320
I0808 13:44:09.674568 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.674576 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.674582 20451 layer_factory.hpp:77] Creating layer ReLU34
I0808 13:44:09.674592 20451 net.cpp:91] Creating Layer ReLU34
I0808 13:44:09.674598 20451 net.cpp:425] ReLU34 <- InnerProduct51
I0808 13:44:09.674607 20451 net.cpp:386] ReLU34 -> InnerProduct51 (in-place)
I0808 13:44:09.674618 20451 net.cpp:141] Setting up ReLU34
I0808 13:44:09.674625 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.674630 20451 net.cpp:156] Memory required for data: 1120209920
I0808 13:44:09.674636 20451 layer_factory.hpp:77] Creating layer InnerProduct52
I0808 13:44:09.674649 20451 net.cpp:91] Creating Layer InnerProduct52
I0808 13:44:09.674655 20451 net.cpp:425] InnerProduct52 <- InnerProduct51
I0808 13:44:09.674664 20451 net.cpp:399] InnerProduct52 -> InnerProduct52
I0808 13:44:09.674863 20451 net.cpp:141] Setting up InnerProduct52
I0808 13:44:09.674871 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.674877 20451 net.cpp:156] Memory required for data: 1120222720
I0808 13:44:09.674883 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.674891 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.674897 20451 layer_factory.hpp:77] Creating layer Concat9
I0808 13:44:09.674907 20451 net.cpp:91] Creating Layer Concat9
I0808 13:44:09.674913 20451 net.cpp:425] Concat9 <- InnerProduct50
I0808 13:44:09.674921 20451 net.cpp:425] Concat9 <- InnerProduct52
I0808 13:44:09.674932 20451 net.cpp:399] Concat9 -> Concat9
I0808 13:44:09.674965 20451 net.cpp:141] Setting up Concat9
I0808 13:44:09.674973 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.674978 20451 net.cpp:156] Memory required for data: 1120248320
I0808 13:44:09.674984 20451 layer_factory.hpp:77] Creating layer InnerProduct53
I0808 13:44:09.674996 20451 net.cpp:91] Creating Layer InnerProduct53
I0808 13:44:09.675019 20451 net.cpp:425] InnerProduct53 <- Concat9
I0808 13:44:09.675029 20451 net.cpp:399] InnerProduct53 -> InnerProduct53
I0808 13:44:09.675232 20451 net.cpp:141] Setting up InnerProduct53
I0808 13:44:09.675240 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.675246 20451 net.cpp:156] Memory required for data: 1120264704
I0808 13:44:09.675251 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.675259 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.675266 20451 layer_factory.hpp:77] Creating layer ReLU35
I0808 13:44:09.675281 20451 net.cpp:91] Creating Layer ReLU35
I0808 13:44:09.675287 20451 net.cpp:425] ReLU35 <- InnerProduct53
I0808 13:44:09.675297 20451 net.cpp:386] ReLU35 -> InnerProduct53 (in-place)
I0808 13:44:09.675307 20451 net.cpp:141] Setting up ReLU35
I0808 13:44:09.675314 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.675320 20451 net.cpp:156] Memory required for data: 1120281088
I0808 13:44:09.675325 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.675334 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.675340 20451 net.cpp:425] drop1 <- InnerProduct53
I0808 13:44:09.675353 20451 net.cpp:399] drop1 -> Dropout17
I0808 13:44:09.675402 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.675410 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.675416 20451 net.cpp:156] Memory required for data: 1120297472
I0808 13:44:09.675421 20451 layer_factory.hpp:77] Creating layer InnerProduct54
I0808 13:44:09.675433 20451 net.cpp:91] Creating Layer InnerProduct54
I0808 13:44:09.675439 20451 net.cpp:425] InnerProduct54 <- Dropout17
I0808 13:44:09.675448 20451 net.cpp:399] InnerProduct54 -> InnerProduct54
I0808 13:44:09.675621 20451 net.cpp:141] Setting up InnerProduct54
I0808 13:44:09.675628 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.675634 20451 net.cpp:156] Memory required for data: 1120305664
I0808 13:44:09.675640 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.675648 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.675654 20451 layer_factory.hpp:77] Creating layer ReLU36
I0808 13:44:09.675664 20451 net.cpp:91] Creating Layer ReLU36
I0808 13:44:09.675670 20451 net.cpp:425] ReLU36 <- InnerProduct54
I0808 13:44:09.675679 20451 net.cpp:386] ReLU36 -> InnerProduct54 (in-place)
I0808 13:44:09.675688 20451 net.cpp:141] Setting up ReLU36
I0808 13:44:09.675696 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.675701 20451 net.cpp:156] Memory required for data: 1120313856
I0808 13:44:09.675707 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.675715 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.675724 20451 net.cpp:425] drop2 <- InnerProduct54
I0808 13:44:09.675734 20451 net.cpp:399] drop2 -> Dropout18
I0808 13:44:09.675782 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.675791 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.675796 20451 net.cpp:156] Memory required for data: 1120322048
I0808 13:44:09.675802 20451 layer_factory.hpp:77] Creating layer dt8
I0808 13:44:09.675812 20451 net.cpp:91] Creating Layer dt8
I0808 13:44:09.675817 20451 net.cpp:425] dt8 <- Dropout18
I0808 13:44:09.675830 20451 net.cpp:399] dt8 -> dt8
I0808 13:44:09.696777 20451 net.cpp:141] Setting up dt8
I0808 13:44:09.696801 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.696807 20451 net.cpp:156] Memory required for data: 1120322304
I0808 13:44:09.696817 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.696826 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.696832 20451 layer_factory.hpp:77] Creating layer Convolution55
I0808 13:44:09.696857 20451 net.cpp:91] Creating Layer Convolution55
I0808 13:44:09.696866 20451 net.cpp:425] Convolution55 <- p1_p1_0_split_9
I0808 13:44:09.696897 20451 net.cpp:399] Convolution55 -> Convolution55
I0808 13:44:09.697283 20451 net.cpp:141] Setting up Convolution55
I0808 13:44:09.697291 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.697296 20451 net.cpp:156] Memory required for data: 1138754304
I0808 13:44:09.697304 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.697310 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.697316 20451 layer_factory.hpp:77] Creating layer Pooling55
I0808 13:44:09.697329 20451 net.cpp:91] Creating Layer Pooling55
I0808 13:44:09.697335 20451 net.cpp:425] Pooling55 <- Convolution55
I0808 13:44:09.697345 20451 net.cpp:399] Pooling55 -> Pooling55
I0808 13:44:09.697407 20451 net.cpp:141] Setting up Pooling55
I0808 13:44:09.697414 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.697419 20451 net.cpp:156] Memory required for data: 1143362304
I0808 13:44:09.697425 20451 layer_factory.hpp:77] Creating layer Convolution56
I0808 13:44:09.697439 20451 net.cpp:91] Creating Layer Convolution56
I0808 13:44:09.697445 20451 net.cpp:425] Convolution56 <- Pooling55
I0808 13:44:09.697458 20451 net.cpp:399] Convolution56 -> Convolution56
I0808 13:44:09.698035 20451 net.cpp:141] Setting up Convolution56
I0808 13:44:09.698045 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.698050 20451 net.cpp:156] Memory required for data: 1152015104
I0808 13:44:09.698056 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.698063 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.698070 20451 layer_factory.hpp:77] Creating layer Pooling56
I0808 13:44:09.698078 20451 net.cpp:91] Creating Layer Pooling56
I0808 13:44:09.698084 20451 net.cpp:425] Pooling56 <- Convolution56
I0808 13:44:09.698096 20451 net.cpp:399] Pooling56 -> Pooling56
I0808 13:44:09.698146 20451 net.cpp:141] Setting up Pooling56
I0808 13:44:09.698154 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.698160 20451 net.cpp:156] Memory required for data: 1154178304
I0808 13:44:09.698166 20451 layer_factory.hpp:77] Creating layer Convolution57
I0808 13:44:09.698179 20451 net.cpp:91] Creating Layer Convolution57
I0808 13:44:09.698185 20451 net.cpp:425] Convolution57 <- Pooling56
I0808 13:44:09.698199 20451 net.cpp:399] Convolution57 -> Convolution57
I0808 13:44:09.699735 20451 net.cpp:141] Setting up Convolution57
I0808 13:44:09.699748 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.699754 20451 net.cpp:156] Memory required for data: 1155215104
I0808 13:44:09.699762 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.699770 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.699776 20451 layer_factory.hpp:77] Creating layer Pooling57
I0808 13:44:09.699786 20451 net.cpp:91] Creating Layer Pooling57
I0808 13:44:09.699793 20451 net.cpp:425] Pooling57 <- Convolution57
I0808 13:44:09.699805 20451 net.cpp:399] Pooling57 -> Pooling57
I0808 13:44:09.699861 20451 net.cpp:141] Setting up Pooling57
I0808 13:44:09.699870 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.699877 20451 net.cpp:156] Memory required for data: 1155535104
I0808 13:44:09.699882 20451 layer_factory.hpp:77] Creating layer InnerProduct55
I0808 13:44:09.699893 20451 net.cpp:91] Creating Layer InnerProduct55
I0808 13:44:09.699899 20451 net.cpp:425] InnerProduct55 <- Pooling57
I0808 13:44:09.699913 20451 net.cpp:399] InnerProduct55 -> InnerProduct55
I0808 13:44:09.701059 20451 net.cpp:141] Setting up InnerProduct55
I0808 13:44:09.701067 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.701072 20451 net.cpp:156] Memory required for data: 1155560704
I0808 13:44:09.701079 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.701086 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.701107 20451 layer_factory.hpp:77] Creating layer ReLU37
I0808 13:44:09.701119 20451 net.cpp:91] Creating Layer ReLU37
I0808 13:44:09.701125 20451 net.cpp:425] ReLU37 <- InnerProduct55
I0808 13:44:09.701134 20451 net.cpp:386] ReLU37 -> InnerProduct55 (in-place)
I0808 13:44:09.701144 20451 net.cpp:141] Setting up ReLU37
I0808 13:44:09.701151 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.701156 20451 net.cpp:156] Memory required for data: 1155586304
I0808 13:44:09.701162 20451 layer_factory.hpp:77] Creating layer InnerProduct56
I0808 13:44:09.701174 20451 net.cpp:91] Creating Layer InnerProduct56
I0808 13:44:09.701180 20451 net.cpp:425] InnerProduct56 <- InnerProduct55
I0808 13:44:09.701189 20451 net.cpp:399] InnerProduct56 -> InnerProduct56
I0808 13:44:09.701377 20451 net.cpp:141] Setting up InnerProduct56
I0808 13:44:09.701385 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.701390 20451 net.cpp:156] Memory required for data: 1155599104
I0808 13:44:09.701396 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.701403 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.701409 20451 layer_factory.hpp:77] Creating layer Convolution58
I0808 13:44:09.701423 20451 net.cpp:91] Creating Layer Convolution58
I0808 13:44:09.701431 20451 net.cpp:425] Convolution58 <- c29
I0808 13:44:09.701442 20451 net.cpp:399] Convolution58 -> Convolution58
I0808 13:44:09.701817 20451 net.cpp:141] Setting up Convolution58
I0808 13:44:09.701825 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.701831 20451 net.cpp:156] Memory required for data: 1174031104
I0808 13:44:09.701838 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.701843 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.701849 20451 layer_factory.hpp:77] Creating layer Pooling58
I0808 13:44:09.701858 20451 net.cpp:91] Creating Layer Pooling58
I0808 13:44:09.701864 20451 net.cpp:425] Pooling58 <- Convolution58
I0808 13:44:09.701874 20451 net.cpp:399] Pooling58 -> Pooling58
I0808 13:44:09.701925 20451 net.cpp:141] Setting up Pooling58
I0808 13:44:09.701934 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.701941 20451 net.cpp:156] Memory required for data: 1178639104
I0808 13:44:09.701946 20451 layer_factory.hpp:77] Creating layer Convolution59
I0808 13:44:09.701957 20451 net.cpp:91] Creating Layer Convolution59
I0808 13:44:09.701963 20451 net.cpp:425] Convolution59 <- Pooling58
I0808 13:44:09.701975 20451 net.cpp:399] Convolution59 -> Convolution59
I0808 13:44:09.702510 20451 net.cpp:141] Setting up Convolution59
I0808 13:44:09.702519 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.702524 20451 net.cpp:156] Memory required for data: 1187291904
I0808 13:44:09.702530 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.702538 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.702543 20451 layer_factory.hpp:77] Creating layer Pooling59
I0808 13:44:09.702553 20451 net.cpp:91] Creating Layer Pooling59
I0808 13:44:09.723079 20451 net.cpp:425] Pooling59 <- Convolution59
I0808 13:44:09.723124 20451 net.cpp:399] Pooling59 -> Pooling59
I0808 13:44:09.723343 20451 net.cpp:141] Setting up Pooling59
I0808 13:44:09.723371 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.723387 20451 net.cpp:156] Memory required for data: 1189455104
I0808 13:44:09.723404 20451 layer_factory.hpp:77] Creating layer Convolution60
I0808 13:44:09.723441 20451 net.cpp:91] Creating Layer Convolution60
I0808 13:44:09.723456 20451 net.cpp:425] Convolution60 <- Pooling59
I0808 13:44:09.723484 20451 net.cpp:399] Convolution60 -> Convolution60
I0808 13:44:09.725425 20451 net.cpp:141] Setting up Convolution60
I0808 13:44:09.725450 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.725491 20451 net.cpp:156] Memory required for data: 1190491904
I0808 13:44:09.725507 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.725523 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.725538 20451 layer_factory.hpp:77] Creating layer Pooling60
I0808 13:44:09.725556 20451 net.cpp:91] Creating Layer Pooling60
I0808 13:44:09.725571 20451 net.cpp:425] Pooling60 <- Convolution60
I0808 13:44:09.725597 20451 net.cpp:399] Pooling60 -> Pooling60
I0808 13:44:09.725713 20451 net.cpp:141] Setting up Pooling60
I0808 13:44:09.725731 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.725744 20451 net.cpp:156] Memory required for data: 1190811904
I0808 13:44:09.725756 20451 layer_factory.hpp:77] Creating layer InnerProduct57
I0808 13:44:09.725782 20451 net.cpp:91] Creating Layer InnerProduct57
I0808 13:44:09.725796 20451 net.cpp:425] InnerProduct57 <- Pooling60
I0808 13:44:09.725821 20451 net.cpp:399] InnerProduct57 -> InnerProduct57
I0808 13:44:09.728853 20451 net.cpp:141] Setting up InnerProduct57
I0808 13:44:09.728874 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.728883 20451 net.cpp:156] Memory required for data: 1190837504
I0808 13:44:09.728894 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.728906 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.728915 20451 layer_factory.hpp:77] Creating layer ReLU38
I0808 13:44:09.728931 20451 net.cpp:91] Creating Layer ReLU38
I0808 13:44:09.728941 20451 net.cpp:425] ReLU38 <- InnerProduct57
I0808 13:44:09.728955 20451 net.cpp:386] ReLU38 -> InnerProduct57 (in-place)
I0808 13:44:09.728971 20451 net.cpp:141] Setting up ReLU38
I0808 13:44:09.728982 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.728991 20451 net.cpp:156] Memory required for data: 1190863104
I0808 13:44:09.728998 20451 layer_factory.hpp:77] Creating layer InnerProduct58
I0808 13:44:09.729017 20451 net.cpp:91] Creating Layer InnerProduct58
I0808 13:44:09.729025 20451 net.cpp:425] InnerProduct58 <- InnerProduct57
I0808 13:44:09.729039 20451 net.cpp:399] InnerProduct58 -> InnerProduct58
I0808 13:44:09.729326 20451 net.cpp:141] Setting up InnerProduct58
I0808 13:44:09.729338 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.729346 20451 net.cpp:156] Memory required for data: 1190875904
I0808 13:44:09.729356 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.729367 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.729375 20451 layer_factory.hpp:77] Creating layer Concat10
I0808 13:44:09.729389 20451 net.cpp:91] Creating Layer Concat10
I0808 13:44:09.729398 20451 net.cpp:425] Concat10 <- InnerProduct56
I0808 13:44:09.729409 20451 net.cpp:425] Concat10 <- InnerProduct58
I0808 13:44:09.729426 20451 net.cpp:399] Concat10 -> Concat10
I0808 13:44:09.729471 20451 net.cpp:141] Setting up Concat10
I0808 13:44:09.729486 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.729495 20451 net.cpp:156] Memory required for data: 1190901504
I0808 13:44:09.729502 20451 layer_factory.hpp:77] Creating layer InnerProduct59
I0808 13:44:09.729516 20451 net.cpp:91] Creating Layer InnerProduct59
I0808 13:44:09.729524 20451 net.cpp:425] InnerProduct59 <- Concat10
I0808 13:44:09.729542 20451 net.cpp:399] InnerProduct59 -> InnerProduct59
I0808 13:44:09.729845 20451 net.cpp:141] Setting up InnerProduct59
I0808 13:44:09.729856 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.729864 20451 net.cpp:156] Memory required for data: 1190917888
I0808 13:44:09.729874 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.729884 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.729893 20451 layer_factory.hpp:77] Creating layer ReLU39
I0808 13:44:09.729923 20451 net.cpp:91] Creating Layer ReLU39
I0808 13:44:09.729933 20451 net.cpp:425] ReLU39 <- InnerProduct59
I0808 13:44:09.729948 20451 net.cpp:386] ReLU39 -> InnerProduct59 (in-place)
I0808 13:44:09.729961 20451 net.cpp:141] Setting up ReLU39
I0808 13:44:09.729972 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.729981 20451 net.cpp:156] Memory required for data: 1190934272
I0808 13:44:09.729990 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.730001 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.730011 20451 net.cpp:425] drop1 <- InnerProduct59
I0808 13:44:09.730026 20451 net.cpp:399] drop1 -> Dropout19
I0808 13:44:09.730103 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.730114 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.730123 20451 net.cpp:156] Memory required for data: 1190950656
I0808 13:44:09.730131 20451 layer_factory.hpp:77] Creating layer InnerProduct60
I0808 13:44:09.730144 20451 net.cpp:91] Creating Layer InnerProduct60
I0808 13:44:09.730154 20451 net.cpp:425] InnerProduct60 <- Dropout19
I0808 13:44:09.730170 20451 net.cpp:399] InnerProduct60 -> InnerProduct60
I0808 13:44:09.730415 20451 net.cpp:141] Setting up InnerProduct60
I0808 13:44:09.730427 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.730434 20451 net.cpp:156] Memory required for data: 1190958848
I0808 13:44:09.730547 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.730559 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.730568 20451 layer_factory.hpp:77] Creating layer ReLU40
I0808 13:44:09.730581 20451 net.cpp:91] Creating Layer ReLU40
I0808 13:44:09.730589 20451 net.cpp:425] ReLU40 <- InnerProduct60
I0808 13:44:09.730602 20451 net.cpp:386] ReLU40 -> InnerProduct60 (in-place)
I0808 13:44:09.730617 20451 net.cpp:141] Setting up ReLU40
I0808 13:44:09.730628 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.730635 20451 net.cpp:156] Memory required for data: 1190967040
I0808 13:44:09.730643 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.730655 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.730664 20451 net.cpp:425] drop2 <- InnerProduct60
I0808 13:44:09.730677 20451 net.cpp:399] drop2 -> Dropout20
I0808 13:44:09.730752 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.730763 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.730772 20451 net.cpp:156] Memory required for data: 1190975232
I0808 13:44:09.730780 20451 layer_factory.hpp:77] Creating layer dt9
I0808 13:44:09.730793 20451 net.cpp:91] Creating Layer dt9
I0808 13:44:09.730803 20451 net.cpp:425] dt9 <- Dropout20
I0808 13:44:09.730818 20451 net.cpp:399] dt9 -> dt9
I0808 13:44:09.731037 20451 net.cpp:141] Setting up dt9
I0808 13:44:09.731055 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.731065 20451 net.cpp:156] Memory required for data: 1190975488
I0808 13:44:09.731076 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.731086 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.731094 20451 layer_factory.hpp:77] Creating layer Convolution61
I0808 13:44:09.731115 20451 net.cpp:91] Creating Layer Convolution61
I0808 13:44:09.731125 20451 net.cpp:425] Convolution61 <- p2_p2_0_split_1
I0808 13:44:09.731144 20451 net.cpp:399] Convolution61 -> Convolution61
I0808 13:44:09.731694 20451 net.cpp:141] Setting up Convolution61
I0808 13:44:09.731708 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.731715 20451 net.cpp:156] Memory required for data: 1209407488
I0808 13:44:09.731724 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.731735 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.731745 20451 layer_factory.hpp:77] Creating layer Pooling61
I0808 13:44:09.731756 20451 net.cpp:91] Creating Layer Pooling61
I0808 13:44:09.731781 20451 net.cpp:425] Pooling61 <- Convolution61
I0808 13:44:09.731798 20451 net.cpp:399] Pooling61 -> Pooling61
I0808 13:44:09.731875 20451 net.cpp:141] Setting up Pooling61
I0808 13:44:09.731890 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.731899 20451 net.cpp:156] Memory required for data: 1214015488
I0808 13:44:09.731906 20451 layer_factory.hpp:77] Creating layer Convolution62
I0808 13:44:09.731923 20451 net.cpp:91] Creating Layer Convolution62
I0808 13:44:09.731931 20451 net.cpp:425] Convolution62 <- Pooling61
I0808 13:44:09.731950 20451 net.cpp:399] Convolution62 -> Convolution62
I0808 13:44:09.732769 20451 net.cpp:141] Setting up Convolution62
I0808 13:44:09.732781 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.732789 20451 net.cpp:156] Memory required for data: 1222668288
I0808 13:44:09.732800 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.732810 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.732818 20451 layer_factory.hpp:77] Creating layer Pooling62
I0808 13:44:09.732833 20451 net.cpp:91] Creating Layer Pooling62
I0808 13:44:09.732842 20451 net.cpp:425] Pooling62 <- Convolution62
I0808 13:44:09.732856 20451 net.cpp:399] Pooling62 -> Pooling62
I0808 13:44:09.732933 20451 net.cpp:141] Setting up Pooling62
I0808 13:44:09.732944 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.732952 20451 net.cpp:156] Memory required for data: 1224831488
I0808 13:44:09.732961 20451 layer_factory.hpp:77] Creating layer Convolution63
I0808 13:44:09.732980 20451 net.cpp:91] Creating Layer Convolution63
I0808 13:44:09.732990 20451 net.cpp:425] Convolution63 <- Pooling62
I0808 13:44:09.733011 20451 net.cpp:399] Convolution63 -> Convolution63
I0808 13:44:09.734236 20451 net.cpp:141] Setting up Convolution63
I0808 13:44:09.734247 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.734256 20451 net.cpp:156] Memory required for data: 1225868288
I0808 13:44:09.734264 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.734275 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.734284 20451 layer_factory.hpp:77] Creating layer Pooling63
I0808 13:44:09.734295 20451 net.cpp:91] Creating Layer Pooling63
I0808 13:44:09.734304 20451 net.cpp:425] Pooling63 <- Convolution63
I0808 13:44:09.734323 20451 net.cpp:399] Pooling63 -> Pooling63
I0808 13:44:09.734400 20451 net.cpp:141] Setting up Pooling63
I0808 13:44:09.734412 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.734421 20451 net.cpp:156] Memory required for data: 1226188288
I0808 13:44:09.734428 20451 layer_factory.hpp:77] Creating layer InnerProduct61
I0808 13:44:09.734444 20451 net.cpp:91] Creating Layer InnerProduct61
I0808 13:44:09.734453 20451 net.cpp:425] InnerProduct61 <- Pooling63
I0808 13:44:09.734470 20451 net.cpp:399] InnerProduct61 -> InnerProduct61
I0808 13:44:09.736146 20451 net.cpp:141] Setting up InnerProduct61
I0808 13:44:09.736158 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.736166 20451 net.cpp:156] Memory required for data: 1226213888
I0808 13:44:09.736176 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.736187 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.736196 20451 layer_factory.hpp:77] Creating layer ReLU41
I0808 13:44:09.736207 20451 net.cpp:91] Creating Layer ReLU41
I0808 13:44:09.736217 20451 net.cpp:425] ReLU41 <- InnerProduct61
I0808 13:44:09.736229 20451 net.cpp:386] ReLU41 -> InnerProduct61 (in-place)
I0808 13:44:09.736243 20451 net.cpp:141] Setting up ReLU41
I0808 13:44:09.736253 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.736261 20451 net.cpp:156] Memory required for data: 1226239488
I0808 13:44:09.736270 20451 layer_factory.hpp:77] Creating layer InnerProduct62
I0808 13:44:09.736286 20451 net.cpp:91] Creating Layer InnerProduct62
I0808 13:44:09.736310 20451 net.cpp:425] InnerProduct62 <- InnerProduct61
I0808 13:44:09.736328 20451 net.cpp:399] InnerProduct62 -> InnerProduct62
I0808 13:44:09.736596 20451 net.cpp:141] Setting up InnerProduct62
I0808 13:44:09.736608 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.736615 20451 net.cpp:156] Memory required for data: 1226252288
I0808 13:44:09.736625 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.736635 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.736644 20451 layer_factory.hpp:77] Creating layer Convolution64
I0808 13:44:09.736661 20451 net.cpp:91] Creating Layer Convolution64
I0808 13:44:09.736670 20451 net.cpp:425] Convolution64 <- c11
I0808 13:44:09.736690 20451 net.cpp:399] Convolution64 -> Convolution64
I0808 13:44:09.737234 20451 net.cpp:141] Setting up Convolution64
I0808 13:44:09.737246 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.737254 20451 net.cpp:156] Memory required for data: 1244684288
I0808 13:44:09.737263 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.737273 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.737282 20451 layer_factory.hpp:77] Creating layer Pooling64
I0808 13:44:09.737294 20451 net.cpp:91] Creating Layer Pooling64
I0808 13:44:09.737303 20451 net.cpp:425] Pooling64 <- Convolution64
I0808 13:44:09.737320 20451 net.cpp:399] Pooling64 -> Pooling64
I0808 13:44:09.737396 20451 net.cpp:141] Setting up Pooling64
I0808 13:44:09.737408 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.737416 20451 net.cpp:156] Memory required for data: 1249292288
I0808 13:44:09.737424 20451 layer_factory.hpp:77] Creating layer Convolution65
I0808 13:44:09.737447 20451 net.cpp:91] Creating Layer Convolution65
I0808 13:44:09.737455 20451 net.cpp:425] Convolution65 <- Pooling64
I0808 13:44:09.737470 20451 net.cpp:399] Convolution65 -> Convolution65
I0808 13:44:09.739109 20451 net.cpp:141] Setting up Convolution65
I0808 13:44:09.739126 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.739135 20451 net.cpp:156] Memory required for data: 1257945088
I0808 13:44:09.739145 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.739156 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.739166 20451 layer_factory.hpp:77] Creating layer Pooling65
I0808 13:44:09.739178 20451 net.cpp:91] Creating Layer Pooling65
I0808 13:44:09.739188 20451 net.cpp:425] Pooling65 <- Convolution65
I0808 13:44:09.739207 20451 net.cpp:399] Pooling65 -> Pooling65
I0808 13:44:09.739310 20451 net.cpp:141] Setting up Pooling65
I0808 13:44:09.739323 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.739331 20451 net.cpp:156] Memory required for data: 1260108288
I0808 13:44:09.739341 20451 layer_factory.hpp:77] Creating layer Convolution66
I0808 13:44:09.739363 20451 net.cpp:91] Creating Layer Convolution66
I0808 13:44:09.760241 20451 net.cpp:425] Convolution66 <- Pooling65
I0808 13:44:09.760265 20451 net.cpp:399] Convolution66 -> Convolution66
I0808 13:44:09.761234 20451 net.cpp:141] Setting up Convolution66
I0808 13:44:09.761245 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.761250 20451 net.cpp:156] Memory required for data: 1261145088
I0808 13:44:09.761257 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.761265 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.761271 20451 layer_factory.hpp:77] Creating layer Pooling66
I0808 13:44:09.761281 20451 net.cpp:91] Creating Layer Pooling66
I0808 13:44:09.761287 20451 net.cpp:425] Pooling66 <- Convolution66
I0808 13:44:09.761297 20451 net.cpp:399] Pooling66 -> Pooling66
I0808 13:44:09.761353 20451 net.cpp:141] Setting up Pooling66
I0808 13:44:09.761374 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.761380 20451 net.cpp:156] Memory required for data: 1261465088
I0808 13:44:09.761386 20451 layer_factory.hpp:77] Creating layer InnerProduct63
I0808 13:44:09.761399 20451 net.cpp:91] Creating Layer InnerProduct63
I0808 13:44:09.761405 20451 net.cpp:425] InnerProduct63 <- Pooling66
I0808 13:44:09.761415 20451 net.cpp:399] InnerProduct63 -> InnerProduct63
I0808 13:44:09.763141 20451 net.cpp:141] Setting up InnerProduct63
I0808 13:44:09.763154 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.763159 20451 net.cpp:156] Memory required for data: 1261490688
I0808 13:44:09.763167 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.763175 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.763181 20451 layer_factory.hpp:77] Creating layer ReLU42
I0808 13:44:09.763190 20451 net.cpp:91] Creating Layer ReLU42
I0808 13:44:09.763197 20451 net.cpp:425] ReLU42 <- InnerProduct63
I0808 13:44:09.763206 20451 net.cpp:386] ReLU42 -> InnerProduct63 (in-place)
I0808 13:44:09.763216 20451 net.cpp:141] Setting up ReLU42
I0808 13:44:09.763224 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.763229 20451 net.cpp:156] Memory required for data: 1261516288
I0808 13:44:09.763236 20451 layer_factory.hpp:77] Creating layer InnerProduct64
I0808 13:44:09.763247 20451 net.cpp:91] Creating Layer InnerProduct64
I0808 13:44:09.763254 20451 net.cpp:425] InnerProduct64 <- InnerProduct63
I0808 13:44:09.763265 20451 net.cpp:399] InnerProduct64 -> InnerProduct64
I0808 13:44:09.763516 20451 net.cpp:141] Setting up InnerProduct64
I0808 13:44:09.763527 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.763533 20451 net.cpp:156] Memory required for data: 1261529088
I0808 13:44:09.763540 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.763548 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.763556 20451 layer_factory.hpp:77] Creating layer Concat11
I0808 13:44:09.763566 20451 net.cpp:91] Creating Layer Concat11
I0808 13:44:09.763572 20451 net.cpp:425] Concat11 <- InnerProduct62
I0808 13:44:09.763581 20451 net.cpp:425] Concat11 <- InnerProduct64
I0808 13:44:09.763592 20451 net.cpp:399] Concat11 -> Concat11
I0808 13:44:09.763628 20451 net.cpp:141] Setting up Concat11
I0808 13:44:09.763638 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.763643 20451 net.cpp:156] Memory required for data: 1261554688
I0808 13:44:09.763649 20451 layer_factory.hpp:77] Creating layer InnerProduct65
I0808 13:44:09.763662 20451 net.cpp:91] Creating Layer InnerProduct65
I0808 13:44:09.763669 20451 net.cpp:425] InnerProduct65 <- Concat11
I0808 13:44:09.763679 20451 net.cpp:399] InnerProduct65 -> InnerProduct65
I0808 13:44:09.763908 20451 net.cpp:141] Setting up InnerProduct65
I0808 13:44:09.763917 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.763923 20451 net.cpp:156] Memory required for data: 1261571072
I0808 13:44:09.763931 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.763939 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.763945 20451 layer_factory.hpp:77] Creating layer ReLU43
I0808 13:44:09.763954 20451 net.cpp:91] Creating Layer ReLU43
I0808 13:44:09.763962 20451 net.cpp:425] ReLU43 <- InnerProduct65
I0808 13:44:09.763972 20451 net.cpp:386] ReLU43 -> InnerProduct65 (in-place)
I0808 13:44:09.763983 20451 net.cpp:141] Setting up ReLU43
I0808 13:44:09.763991 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.763998 20451 net.cpp:156] Memory required for data: 1261587456
I0808 13:44:09.764004 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.764014 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.764020 20451 net.cpp:425] drop1 <- InnerProduct65
I0808 13:44:09.764048 20451 net.cpp:399] drop1 -> Dropout21
I0808 13:44:09.764107 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.764117 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.764122 20451 net.cpp:156] Memory required for data: 1261603840
I0808 13:44:09.764129 20451 layer_factory.hpp:77] Creating layer InnerProduct66
I0808 13:44:09.764142 20451 net.cpp:91] Creating Layer InnerProduct66
I0808 13:44:09.764149 20451 net.cpp:425] InnerProduct66 <- Dropout21
I0808 13:44:09.764159 20451 net.cpp:399] InnerProduct66 -> InnerProduct66
I0808 13:44:09.764353 20451 net.cpp:141] Setting up InnerProduct66
I0808 13:44:09.764361 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.764367 20451 net.cpp:156] Memory required for data: 1261612032
I0808 13:44:09.764374 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.764382 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.764389 20451 layer_factory.hpp:77] Creating layer ReLU44
I0808 13:44:09.764400 20451 net.cpp:91] Creating Layer ReLU44
I0808 13:44:09.764406 20451 net.cpp:425] ReLU44 <- InnerProduct66
I0808 13:44:09.764415 20451 net.cpp:386] ReLU44 -> InnerProduct66 (in-place)
I0808 13:44:09.764428 20451 net.cpp:141] Setting up ReLU44
I0808 13:44:09.764436 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.764442 20451 net.cpp:156] Memory required for data: 1261620224
I0808 13:44:09.764448 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.764459 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.764467 20451 net.cpp:425] drop2 <- InnerProduct66
I0808 13:44:09.764477 20451 net.cpp:399] drop2 -> Dropout22
I0808 13:44:09.764539 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.764550 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.764557 20451 net.cpp:156] Memory required for data: 1261628416
I0808 13:44:09.764564 20451 layer_factory.hpp:77] Creating layer dt10
I0808 13:44:09.764574 20451 net.cpp:91] Creating Layer dt10
I0808 13:44:09.764580 20451 net.cpp:425] dt10 <- Dropout22
I0808 13:44:09.764595 20451 net.cpp:399] dt10 -> dt10
I0808 13:44:09.764768 20451 net.cpp:141] Setting up dt10
I0808 13:44:09.764777 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.764785 20451 net.cpp:156] Memory required for data: 1261628672
I0808 13:44:09.764791 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.764801 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.764806 20451 layer_factory.hpp:77] Creating layer Convolution67
I0808 13:44:09.764822 20451 net.cpp:91] Creating Layer Convolution67
I0808 13:44:09.764830 20451 net.cpp:425] Convolution67 <- p2_p2_0_split_2
I0808 13:44:09.764842 20451 net.cpp:399] Convolution67 -> Convolution67
I0808 13:44:09.765252 20451 net.cpp:141] Setting up Convolution67
I0808 13:44:09.765264 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.765270 20451 net.cpp:156] Memory required for data: 1280060672
I0808 13:44:09.765277 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.784734 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.784761 20451 layer_factory.hpp:77] Creating layer Pooling67
I0808 13:44:09.784787 20451 net.cpp:91] Creating Layer Pooling67
I0808 13:44:09.784806 20451 net.cpp:425] Pooling67 <- Convolution67
I0808 13:44:09.784833 20451 net.cpp:399] Pooling67 -> Pooling67
I0808 13:44:09.785015 20451 net.cpp:141] Setting up Pooling67
I0808 13:44:09.785038 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.785053 20451 net.cpp:156] Memory required for data: 1284668672
I0808 13:44:09.785068 20451 layer_factory.hpp:77] Creating layer Convolution68
I0808 13:44:09.785105 20451 net.cpp:91] Creating Layer Convolution68
I0808 13:44:09.785122 20451 net.cpp:425] Convolution68 <- Pooling67
I0808 13:44:09.785153 20451 net.cpp:399] Convolution68 -> Convolution68
I0808 13:44:09.786547 20451 net.cpp:141] Setting up Convolution68
I0808 13:44:09.786609 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.786624 20451 net.cpp:156] Memory required for data: 1293321472
I0808 13:44:09.786643 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.786662 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.786679 20451 layer_factory.hpp:77] Creating layer Pooling68
I0808 13:44:09.786700 20451 net.cpp:91] Creating Layer Pooling68
I0808 13:44:09.786718 20451 net.cpp:425] Pooling68 <- Convolution68
I0808 13:44:09.786748 20451 net.cpp:399] Pooling68 -> Pooling68
I0808 13:44:09.787382 20451 net.cpp:141] Setting up Pooling68
I0808 13:44:09.787395 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.787402 20451 net.cpp:156] Memory required for data: 1295484672
I0808 13:44:09.787410 20451 layer_factory.hpp:77] Creating layer Convolution69
I0808 13:44:09.787427 20451 net.cpp:91] Creating Layer Convolution69
I0808 13:44:09.787436 20451 net.cpp:425] Convolution69 <- Pooling68
I0808 13:44:09.787451 20451 net.cpp:399] Convolution69 -> Convolution69
I0808 13:44:09.788398 20451 net.cpp:141] Setting up Convolution69
I0808 13:44:09.788413 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.788419 20451 net.cpp:156] Memory required for data: 1296521472
I0808 13:44:09.788440 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.788450 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.788457 20451 layer_factory.hpp:77] Creating layer Pooling69
I0808 13:44:09.788470 20451 net.cpp:91] Creating Layer Pooling69
I0808 13:44:09.788480 20451 net.cpp:425] Pooling69 <- Convolution69
I0808 13:44:09.788491 20451 net.cpp:399] Pooling69 -> Pooling69
I0808 13:44:09.788559 20451 net.cpp:141] Setting up Pooling69
I0808 13:44:09.788569 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.788576 20451 net.cpp:156] Memory required for data: 1296841472
I0808 13:44:09.788583 20451 layer_factory.hpp:77] Creating layer InnerProduct67
I0808 13:44:09.788596 20451 net.cpp:91] Creating Layer InnerProduct67
I0808 13:44:09.788604 20451 net.cpp:425] InnerProduct67 <- Pooling69
I0808 13:44:09.788616 20451 net.cpp:399] InnerProduct67 -> InnerProduct67
I0808 13:44:09.789851 20451 net.cpp:141] Setting up InnerProduct67
I0808 13:44:09.789866 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.789872 20451 net.cpp:156] Memory required for data: 1296867072
I0808 13:44:09.789881 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.789891 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.789897 20451 layer_factory.hpp:77] Creating layer ReLU45
I0808 13:44:09.789907 20451 net.cpp:91] Creating Layer ReLU45
I0808 13:44:09.789916 20451 net.cpp:425] ReLU45 <- InnerProduct67
I0808 13:44:09.789928 20451 net.cpp:386] ReLU45 -> InnerProduct67 (in-place)
I0808 13:44:09.789942 20451 net.cpp:141] Setting up ReLU45
I0808 13:44:09.789949 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.789957 20451 net.cpp:156] Memory required for data: 1296892672
I0808 13:44:09.789963 20451 layer_factory.hpp:77] Creating layer InnerProduct68
I0808 13:44:09.789973 20451 net.cpp:91] Creating Layer InnerProduct68
I0808 13:44:09.789981 20451 net.cpp:425] InnerProduct68 <- InnerProduct67
I0808 13:44:09.789994 20451 net.cpp:399] InnerProduct68 -> InnerProduct68
I0808 13:44:09.790212 20451 net.cpp:141] Setting up InnerProduct68
I0808 13:44:09.790222 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.790228 20451 net.cpp:156] Memory required for data: 1296905472
I0808 13:44:09.790236 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.790244 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.790251 20451 layer_factory.hpp:77] Creating layer Convolution70
I0808 13:44:09.790283 20451 net.cpp:91] Creating Layer Convolution70
I0808 13:44:09.790290 20451 net.cpp:425] Convolution70 <- c12
I0808 13:44:09.790307 20451 net.cpp:399] Convolution70 -> Convolution70
I0808 13:44:09.790760 20451 net.cpp:141] Setting up Convolution70
I0808 13:44:09.790771 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.790777 20451 net.cpp:156] Memory required for data: 1315337472
I0808 13:44:09.790784 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.790793 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.790801 20451 layer_factory.hpp:77] Creating layer Pooling70
I0808 13:44:09.790813 20451 net.cpp:91] Creating Layer Pooling70
I0808 13:44:09.790822 20451 net.cpp:425] Pooling70 <- Convolution70
I0808 13:44:09.790832 20451 net.cpp:399] Pooling70 -> Pooling70
I0808 13:44:09.790896 20451 net.cpp:141] Setting up Pooling70
I0808 13:44:09.790906 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.790913 20451 net.cpp:156] Memory required for data: 1319945472
I0808 13:44:09.790920 20451 layer_factory.hpp:77] Creating layer Convolution71
I0808 13:44:09.790935 20451 net.cpp:91] Creating Layer Convolution71
I0808 13:44:09.790942 20451 net.cpp:425] Convolution71 <- Pooling70
I0808 13:44:09.790957 20451 net.cpp:399] Convolution71 -> Convolution71
I0808 13:44:09.791609 20451 net.cpp:141] Setting up Convolution71
I0808 13:44:09.791622 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.791628 20451 net.cpp:156] Memory required for data: 1328598272
I0808 13:44:09.791636 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.791646 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.791652 20451 layer_factory.hpp:77] Creating layer Pooling71
I0808 13:44:09.791662 20451 net.cpp:91] Creating Layer Pooling71
I0808 13:44:09.791671 20451 net.cpp:425] Pooling71 <- Convolution71
I0808 13:44:09.791683 20451 net.cpp:399] Pooling71 -> Pooling71
I0808 13:44:09.791748 20451 net.cpp:141] Setting up Pooling71
I0808 13:44:09.791757 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.791764 20451 net.cpp:156] Memory required for data: 1330761472
I0808 13:44:09.791769 20451 layer_factory.hpp:77] Creating layer Convolution72
I0808 13:44:09.791790 20451 net.cpp:91] Creating Layer Convolution72
I0808 13:44:09.791797 20451 net.cpp:425] Convolution72 <- Pooling71
I0808 13:44:09.791810 20451 net.cpp:399] Convolution72 -> Convolution72
I0808 13:44:09.793457 20451 net.cpp:141] Setting up Convolution72
I0808 13:44:09.793475 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.793483 20451 net.cpp:156] Memory required for data: 1331798272
I0808 13:44:09.793491 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.793500 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.793509 20451 layer_factory.hpp:77] Creating layer Pooling72
I0808 13:44:09.793520 20451 net.cpp:91] Creating Layer Pooling72
I0808 13:44:09.793529 20451 net.cpp:425] Pooling72 <- Convolution72
I0808 13:44:09.793547 20451 net.cpp:399] Pooling72 -> Pooling72
I0808 13:44:09.793615 20451 net.cpp:141] Setting up Pooling72
I0808 13:44:09.793624 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.793632 20451 net.cpp:156] Memory required for data: 1332118272
I0808 13:44:09.793637 20451 layer_factory.hpp:77] Creating layer InnerProduct69
I0808 13:44:09.793653 20451 net.cpp:91] Creating Layer InnerProduct69
I0808 13:44:09.793659 20451 net.cpp:425] InnerProduct69 <- Pooling72
I0808 13:44:09.793673 20451 net.cpp:399] InnerProduct69 -> InnerProduct69
I0808 13:44:09.795552 20451 net.cpp:141] Setting up InnerProduct69
I0808 13:44:09.795572 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.795578 20451 net.cpp:156] Memory required for data: 1332143872
I0808 13:44:09.795608 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.795617 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.795625 20451 layer_factory.hpp:77] Creating layer ReLU46
I0808 13:44:09.795639 20451 net.cpp:91] Creating Layer ReLU46
I0808 13:44:09.795647 20451 net.cpp:425] ReLU46 <- InnerProduct69
I0808 13:44:09.795658 20451 net.cpp:386] ReLU46 -> InnerProduct69 (in-place)
I0808 13:44:09.795671 20451 net.cpp:141] Setting up ReLU46
I0808 13:44:09.795680 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.795686 20451 net.cpp:156] Memory required for data: 1332169472
I0808 13:44:09.795693 20451 layer_factory.hpp:77] Creating layer InnerProduct70
I0808 13:44:09.795706 20451 net.cpp:91] Creating Layer InnerProduct70
I0808 13:44:09.795713 20451 net.cpp:425] InnerProduct70 <- InnerProduct69
I0808 13:44:09.795725 20451 net.cpp:399] InnerProduct70 -> InnerProduct70
I0808 13:44:09.795960 20451 net.cpp:141] Setting up InnerProduct70
I0808 13:44:09.795970 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.795976 20451 net.cpp:156] Memory required for data: 1332182272
I0808 13:44:09.795984 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.795992 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.796000 20451 layer_factory.hpp:77] Creating layer Concat12
I0808 13:44:09.796010 20451 net.cpp:91] Creating Layer Concat12
I0808 13:44:09.796018 20451 net.cpp:425] Concat12 <- InnerProduct68
I0808 13:44:09.796027 20451 net.cpp:425] Concat12 <- InnerProduct70
I0808 13:44:09.796047 20451 net.cpp:399] Concat12 -> Concat12
I0808 13:44:09.796087 20451 net.cpp:141] Setting up Concat12
I0808 13:44:09.796095 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.796103 20451 net.cpp:156] Memory required for data: 1332207872
I0808 13:44:09.796108 20451 layer_factory.hpp:77] Creating layer InnerProduct71
I0808 13:44:09.796118 20451 net.cpp:91] Creating Layer InnerProduct71
I0808 13:44:09.796125 20451 net.cpp:425] InnerProduct71 <- Concat12
I0808 13:44:09.796139 20451 net.cpp:399] InnerProduct71 -> InnerProduct71
I0808 13:44:09.796367 20451 net.cpp:141] Setting up InnerProduct71
I0808 13:44:09.796376 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.796382 20451 net.cpp:156] Memory required for data: 1332224256
I0808 13:44:09.796389 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.796397 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.796404 20451 layer_factory.hpp:77] Creating layer ReLU47
I0808 13:44:09.796413 20451 net.cpp:91] Creating Layer ReLU47
I0808 13:44:09.796421 20451 net.cpp:425] ReLU47 <- InnerProduct71
I0808 13:44:09.796432 20451 net.cpp:386] ReLU47 -> InnerProduct71 (in-place)
I0808 13:44:09.796443 20451 net.cpp:141] Setting up ReLU47
I0808 13:44:09.796452 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.796458 20451 net.cpp:156] Memory required for data: 1332240640
I0808 13:44:09.796465 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.796474 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.796483 20451 net.cpp:425] drop1 <- InnerProduct71
I0808 13:44:09.796494 20451 net.cpp:399] drop1 -> Dropout23
I0808 13:44:09.796557 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.796566 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.796572 20451 net.cpp:156] Memory required for data: 1332257024
I0808 13:44:09.796579 20451 layer_factory.hpp:77] Creating layer InnerProduct72
I0808 13:44:09.796591 20451 net.cpp:91] Creating Layer InnerProduct72
I0808 13:44:09.796597 20451 net.cpp:425] InnerProduct72 <- Dropout23
I0808 13:44:09.796612 20451 net.cpp:399] InnerProduct72 -> InnerProduct72
I0808 13:44:09.796809 20451 net.cpp:141] Setting up InnerProduct72
I0808 13:44:09.796818 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.796838 20451 net.cpp:156] Memory required for data: 1332265216
I0808 13:44:09.796845 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.796854 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.796861 20451 layer_factory.hpp:77] Creating layer ReLU48
I0808 13:44:09.796875 20451 net.cpp:91] Creating Layer ReLU48
I0808 13:44:09.796881 20451 net.cpp:425] ReLU48 <- InnerProduct72
I0808 13:44:09.796890 20451 net.cpp:386] ReLU48 -> InnerProduct72 (in-place)
I0808 13:44:09.796901 20451 net.cpp:141] Setting up ReLU48
I0808 13:44:09.796911 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.796916 20451 net.cpp:156] Memory required for data: 1332273408
I0808 13:44:09.796922 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.796932 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.796939 20451 net.cpp:425] drop2 <- InnerProduct72
I0808 13:44:09.796949 20451 net.cpp:399] drop2 -> Dropout24
I0808 13:44:09.797011 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.797020 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.797027 20451 net.cpp:156] Memory required for data: 1332281600
I0808 13:44:09.797034 20451 layer_factory.hpp:77] Creating layer dt11
I0808 13:44:09.797063 20451 net.cpp:91] Creating Layer dt11
I0808 13:44:09.797070 20451 net.cpp:425] dt11 <- Dropout24
I0808 13:44:09.797082 20451 net.cpp:399] dt11 -> dt11
I0808 13:44:09.797281 20451 net.cpp:141] Setting up dt11
I0808 13:44:09.797297 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.797303 20451 net.cpp:156] Memory required for data: 1332281856
I0808 13:44:09.797312 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.797320 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.797327 20451 layer_factory.hpp:77] Creating layer Convolution73
I0808 13:44:09.797341 20451 net.cpp:91] Creating Layer Convolution73
I0808 13:44:09.797349 20451 net.cpp:425] Convolution73 <- p2_p2_0_split_3
I0808 13:44:09.797365 20451 net.cpp:399] Convolution73 -> Convolution73
I0808 13:44:09.797821 20451 net.cpp:141] Setting up Convolution73
I0808 13:44:09.797834 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.797842 20451 net.cpp:156] Memory required for data: 1350713856
I0808 13:44:09.797852 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.797860 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.797868 20451 layer_factory.hpp:77] Creating layer Pooling73
I0808 13:44:09.797881 20451 net.cpp:91] Creating Layer Pooling73
I0808 13:44:09.797891 20451 net.cpp:425] Pooling73 <- Convolution73
I0808 13:44:09.797906 20451 net.cpp:399] Pooling73 -> Pooling73
I0808 13:44:09.797977 20451 net.cpp:141] Setting up Pooling73
I0808 13:44:09.797987 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.819217 20451 net.cpp:156] Memory required for data: 1355321856
I0808 13:44:09.819241 20451 layer_factory.hpp:77] Creating layer Convolution74
I0808 13:44:09.819303 20451 net.cpp:91] Creating Layer Convolution74
I0808 13:44:09.819317 20451 net.cpp:425] Convolution74 <- Pooling73
I0808 13:44:09.819335 20451 net.cpp:399] Convolution74 -> Convolution74
I0808 13:44:09.820087 20451 net.cpp:141] Setting up Convolution74
I0808 13:44:09.820103 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.820109 20451 net.cpp:156] Memory required for data: 1363974656
I0808 13:44:09.820119 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.820128 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.820135 20451 layer_factory.hpp:77] Creating layer Pooling74
I0808 13:44:09.820148 20451 net.cpp:91] Creating Layer Pooling74
I0808 13:44:09.820157 20451 net.cpp:425] Pooling74 <- Convolution74
I0808 13:44:09.820194 20451 net.cpp:399] Pooling74 -> Pooling74
I0808 13:44:09.820263 20451 net.cpp:141] Setting up Pooling74
I0808 13:44:09.820273 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.820281 20451 net.cpp:156] Memory required for data: 1366137856
I0808 13:44:09.820286 20451 layer_factory.hpp:77] Creating layer Convolution75
I0808 13:44:09.820302 20451 net.cpp:91] Creating Layer Convolution75
I0808 13:44:09.820310 20451 net.cpp:425] Convolution75 <- Pooling74
I0808 13:44:09.820325 20451 net.cpp:399] Convolution75 -> Convolution75
I0808 13:44:09.821267 20451 net.cpp:141] Setting up Convolution75
I0808 13:44:09.821280 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.821287 20451 net.cpp:156] Memory required for data: 1367174656
I0808 13:44:09.821296 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.821305 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.821312 20451 layer_factory.hpp:77] Creating layer Pooling75
I0808 13:44:09.821323 20451 net.cpp:91] Creating Layer Pooling75
I0808 13:44:09.821333 20451 net.cpp:425] Pooling75 <- Convolution75
I0808 13:44:09.821344 20451 net.cpp:399] Pooling75 -> Pooling75
I0808 13:44:09.821418 20451 net.cpp:141] Setting up Pooling75
I0808 13:44:09.821430 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.821437 20451 net.cpp:156] Memory required for data: 1367494656
I0808 13:44:09.821444 20451 layer_factory.hpp:77] Creating layer InnerProduct73
I0808 13:44:09.821456 20451 net.cpp:91] Creating Layer InnerProduct73
I0808 13:44:09.821463 20451 net.cpp:425] InnerProduct73 <- Pooling75
I0808 13:44:09.821478 20451 net.cpp:399] InnerProduct73 -> InnerProduct73
I0808 13:44:09.822753 20451 net.cpp:141] Setting up InnerProduct73
I0808 13:44:09.822768 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.822777 20451 net.cpp:156] Memory required for data: 1367520256
I0808 13:44:09.822787 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.822796 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.822804 20451 layer_factory.hpp:77] Creating layer ReLU49
I0808 13:44:09.822815 20451 net.cpp:91] Creating Layer ReLU49
I0808 13:44:09.822824 20451 net.cpp:425] ReLU49 <- InnerProduct73
I0808 13:44:09.822839 20451 net.cpp:386] ReLU49 -> InnerProduct73 (in-place)
I0808 13:44:09.822852 20451 net.cpp:141] Setting up ReLU49
I0808 13:44:09.822862 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.822870 20451 net.cpp:156] Memory required for data: 1367545856
I0808 13:44:09.822877 20451 layer_factory.hpp:77] Creating layer InnerProduct74
I0808 13:44:09.822890 20451 net.cpp:91] Creating Layer InnerProduct74
I0808 13:44:09.822897 20451 net.cpp:425] InnerProduct74 <- InnerProduct73
I0808 13:44:09.822911 20451 net.cpp:399] InnerProduct74 -> InnerProduct74
I0808 13:44:09.823173 20451 net.cpp:141] Setting up InnerProduct74
I0808 13:44:09.823185 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.823194 20451 net.cpp:156] Memory required for data: 1367558656
I0808 13:44:09.823204 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.823215 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.823225 20451 layer_factory.hpp:77] Creating layer Convolution76
I0808 13:44:09.823245 20451 net.cpp:91] Creating Layer Convolution76
I0808 13:44:09.823253 20451 net.cpp:425] Convolution76 <- c13
I0808 13:44:09.823269 20451 net.cpp:399] Convolution76 -> Convolution76
I0808 13:44:09.823803 20451 net.cpp:141] Setting up Convolution76
I0808 13:44:09.823815 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.823822 20451 net.cpp:156] Memory required for data: 1385990656
I0808 13:44:09.823829 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.823838 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.823863 20451 layer_factory.hpp:77] Creating layer Pooling76
I0808 13:44:09.823875 20451 net.cpp:91] Creating Layer Pooling76
I0808 13:44:09.823884 20451 net.cpp:425] Pooling76 <- Convolution76
I0808 13:44:09.823894 20451 net.cpp:399] Pooling76 -> Pooling76
I0808 13:44:09.823961 20451 net.cpp:141] Setting up Pooling76
I0808 13:44:09.823969 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.823976 20451 net.cpp:156] Memory required for data: 1390598656
I0808 13:44:09.823982 20451 layer_factory.hpp:77] Creating layer Convolution77
I0808 13:44:09.824002 20451 net.cpp:91] Creating Layer Convolution77
I0808 13:44:09.824009 20451 net.cpp:425] Convolution77 <- Pooling76
I0808 13:44:09.824019 20451 net.cpp:399] Convolution77 -> Convolution77
I0808 13:44:09.824616 20451 net.cpp:141] Setting up Convolution77
I0808 13:44:09.824625 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.824631 20451 net.cpp:156] Memory required for data: 1399251456
I0808 13:44:09.824638 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.824645 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.824651 20451 layer_factory.hpp:77] Creating layer Pooling77
I0808 13:44:09.824662 20451 net.cpp:91] Creating Layer Pooling77
I0808 13:44:09.824669 20451 net.cpp:425] Pooling77 <- Convolution77
I0808 13:44:09.824678 20451 net.cpp:399] Pooling77 -> Pooling77
I0808 13:44:09.824736 20451 net.cpp:141] Setting up Pooling77
I0808 13:44:09.824744 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.824750 20451 net.cpp:156] Memory required for data: 1401414656
I0808 13:44:09.824756 20451 layer_factory.hpp:77] Creating layer Convolution78
I0808 13:44:09.824769 20451 net.cpp:91] Creating Layer Convolution78
I0808 13:44:09.824776 20451 net.cpp:425] Convolution78 <- Pooling77
I0808 13:44:09.824789 20451 net.cpp:399] Convolution78 -> Convolution78
I0808 13:44:09.825655 20451 net.cpp:141] Setting up Convolution78
I0808 13:44:09.825664 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.825669 20451 net.cpp:156] Memory required for data: 1402451456
I0808 13:44:09.825675 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.825682 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.825688 20451 layer_factory.hpp:77] Creating layer Pooling78
I0808 13:44:09.825696 20451 net.cpp:91] Creating Layer Pooling78
I0808 13:44:09.825702 20451 net.cpp:425] Pooling78 <- Convolution78
I0808 13:44:09.825713 20451 net.cpp:399] Pooling78 -> Pooling78
I0808 13:44:09.825767 20451 net.cpp:141] Setting up Pooling78
I0808 13:44:09.825774 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.825780 20451 net.cpp:156] Memory required for data: 1402771456
I0808 13:44:09.850134 20451 layer_factory.hpp:77] Creating layer InnerProduct75
I0808 13:44:09.850157 20451 net.cpp:91] Creating Layer InnerProduct75
I0808 13:44:09.850167 20451 net.cpp:425] InnerProduct75 <- Pooling78
I0808 13:44:09.850180 20451 net.cpp:399] InnerProduct75 -> InnerProduct75
I0808 13:44:09.852047 20451 net.cpp:141] Setting up InnerProduct75
I0808 13:44:09.852061 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.852067 20451 net.cpp:156] Memory required for data: 1402797056
I0808 13:44:09.852077 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.852084 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.852090 20451 layer_factory.hpp:77] Creating layer ReLU50
I0808 13:44:09.852102 20451 net.cpp:91] Creating Layer ReLU50
I0808 13:44:09.852109 20451 net.cpp:425] ReLU50 <- InnerProduct75
I0808 13:44:09.852118 20451 net.cpp:386] ReLU50 -> InnerProduct75 (in-place)
I0808 13:44:09.852129 20451 net.cpp:141] Setting up ReLU50
I0808 13:44:09.852138 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.852157 20451 net.cpp:156] Memory required for data: 1402822656
I0808 13:44:09.852164 20451 layer_factory.hpp:77] Creating layer InnerProduct76
I0808 13:44:09.852176 20451 net.cpp:91] Creating Layer InnerProduct76
I0808 13:44:09.852182 20451 net.cpp:425] InnerProduct76 <- InnerProduct75
I0808 13:44:09.852192 20451 net.cpp:399] InnerProduct76 -> InnerProduct76
I0808 13:44:09.852396 20451 net.cpp:141] Setting up InnerProduct76
I0808 13:44:09.852404 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.852409 20451 net.cpp:156] Memory required for data: 1402835456
I0808 13:44:09.852416 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.852423 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.852429 20451 layer_factory.hpp:77] Creating layer Concat13
I0808 13:44:09.852438 20451 net.cpp:91] Creating Layer Concat13
I0808 13:44:09.852445 20451 net.cpp:425] Concat13 <- InnerProduct74
I0808 13:44:09.852452 20451 net.cpp:425] Concat13 <- InnerProduct76
I0808 13:44:09.852466 20451 net.cpp:399] Concat13 -> Concat13
I0808 13:44:09.852501 20451 net.cpp:141] Setting up Concat13
I0808 13:44:09.852509 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.852514 20451 net.cpp:156] Memory required for data: 1402861056
I0808 13:44:09.852519 20451 layer_factory.hpp:77] Creating layer InnerProduct77
I0808 13:44:09.852529 20451 net.cpp:91] Creating Layer InnerProduct77
I0808 13:44:09.852535 20451 net.cpp:425] InnerProduct77 <- Concat13
I0808 13:44:09.852546 20451 net.cpp:399] InnerProduct77 -> InnerProduct77
I0808 13:44:09.852756 20451 net.cpp:141] Setting up InnerProduct77
I0808 13:44:09.852763 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.852769 20451 net.cpp:156] Memory required for data: 1402877440
I0808 13:44:09.852776 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.852782 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.852788 20451 layer_factory.hpp:77] Creating layer ReLU51
I0808 13:44:09.852797 20451 net.cpp:91] Creating Layer ReLU51
I0808 13:44:09.852802 20451 net.cpp:425] ReLU51 <- InnerProduct77
I0808 13:44:09.852813 20451 net.cpp:386] ReLU51 -> InnerProduct77 (in-place)
I0808 13:44:09.852823 20451 net.cpp:141] Setting up ReLU51
I0808 13:44:09.852829 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.852835 20451 net.cpp:156] Memory required for data: 1402893824
I0808 13:44:09.852840 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.852849 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.852855 20451 net.cpp:425] drop1 <- InnerProduct77
I0808 13:44:09.852865 20451 net.cpp:399] drop1 -> Dropout25
I0808 13:44:09.852919 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.852927 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.852933 20451 net.cpp:156] Memory required for data: 1402910208
I0808 13:44:09.852938 20451 layer_factory.hpp:77] Creating layer InnerProduct78
I0808 13:44:09.852951 20451 net.cpp:91] Creating Layer InnerProduct78
I0808 13:44:09.852957 20451 net.cpp:425] InnerProduct78 <- Dropout25
I0808 13:44:09.852967 20451 net.cpp:399] InnerProduct78 -> InnerProduct78
I0808 13:44:09.853139 20451 net.cpp:141] Setting up InnerProduct78
I0808 13:44:09.853147 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.853152 20451 net.cpp:156] Memory required for data: 1402918400
I0808 13:44:09.853158 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.853165 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.853171 20451 layer_factory.hpp:77] Creating layer ReLU52
I0808 13:44:09.853181 20451 net.cpp:91] Creating Layer ReLU52
I0808 13:44:09.853188 20451 net.cpp:425] ReLU52 <- InnerProduct78
I0808 13:44:09.853195 20451 net.cpp:386] ReLU52 -> InnerProduct78 (in-place)
I0808 13:44:09.853205 20451 net.cpp:141] Setting up ReLU52
I0808 13:44:09.853221 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.853227 20451 net.cpp:156] Memory required for data: 1402926592
I0808 13:44:09.853232 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.853240 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.853246 20451 net.cpp:425] drop2 <- InnerProduct78
I0808 13:44:09.853257 20451 net.cpp:399] drop2 -> Dropout26
I0808 13:44:09.853309 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.853317 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.853322 20451 net.cpp:156] Memory required for data: 1402934784
I0808 13:44:09.853328 20451 layer_factory.hpp:77] Creating layer dt12
I0808 13:44:09.853339 20451 net.cpp:91] Creating Layer dt12
I0808 13:44:09.853345 20451 net.cpp:425] dt12 <- Dropout26
I0808 13:44:09.853356 20451 net.cpp:399] dt12 -> dt12
I0808 13:44:09.853507 20451 net.cpp:141] Setting up dt12
I0808 13:44:09.853514 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.853519 20451 net.cpp:156] Memory required for data: 1402935040
I0808 13:44:09.853526 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.853533 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.853539 20451 layer_factory.hpp:77] Creating layer Convolution79
I0808 13:44:09.853551 20451 net.cpp:91] Creating Layer Convolution79
I0808 13:44:09.853559 20451 net.cpp:425] Convolution79 <- p2_p2_0_split_4
I0808 13:44:09.853571 20451 net.cpp:399] Convolution79 -> Convolution79
I0808 13:44:09.853991 20451 net.cpp:141] Setting up Convolution79
I0808 13:44:09.854001 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.854007 20451 net.cpp:156] Memory required for data: 1421367040
I0808 13:44:09.854012 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.854019 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.854024 20451 layer_factory.hpp:77] Creating layer Pooling79
I0808 13:44:09.854033 20451 net.cpp:91] Creating Layer Pooling79
I0808 13:44:09.854039 20451 net.cpp:425] Pooling79 <- Convolution79
I0808 13:44:09.854051 20451 net.cpp:399] Pooling79 -> Pooling79
I0808 13:44:09.854110 20451 net.cpp:141] Setting up Pooling79
I0808 13:44:09.854117 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.854122 20451 net.cpp:156] Memory required for data: 1425975040
I0808 13:44:09.854128 20451 layer_factory.hpp:77] Creating layer Convolution80
I0808 13:44:09.854145 20451 net.cpp:91] Creating Layer Convolution80
I0808 13:44:09.854151 20451 net.cpp:425] Convolution80 <- Pooling79
I0808 13:44:09.854161 20451 net.cpp:399] Convolution80 -> Convolution80
I0808 13:44:09.854729 20451 net.cpp:141] Setting up Convolution80
I0808 13:44:09.854737 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.854743 20451 net.cpp:156] Memory required for data: 1434627840
I0808 13:44:09.854749 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.854756 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.854761 20451 layer_factory.hpp:77] Creating layer Pooling80
I0808 13:44:09.854769 20451 net.cpp:91] Creating Layer Pooling80
I0808 13:44:09.854775 20451 net.cpp:425] Pooling80 <- Convolution80
I0808 13:44:09.854784 20451 net.cpp:399] Pooling80 -> Pooling80
I0808 13:44:09.854854 20451 net.cpp:141] Setting up Pooling80
I0808 13:44:09.854862 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.854867 20451 net.cpp:156] Memory required for data: 1436791040
I0808 13:44:09.854873 20451 layer_factory.hpp:77] Creating layer Convolution81
I0808 13:44:09.854887 20451 net.cpp:91] Creating Layer Convolution81
I0808 13:44:09.854892 20451 net.cpp:425] Convolution81 <- Pooling80
I0808 13:44:09.854912 20451 net.cpp:399] Convolution81 -> Convolution81
I0808 13:44:09.856380 20451 net.cpp:141] Setting up Convolution81
I0808 13:44:09.856394 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.856412 20451 net.cpp:156] Memory required for data: 1437827840
I0808 13:44:09.856420 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.856427 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.856433 20451 layer_factory.hpp:77] Creating layer Pooling81
I0808 13:44:09.856442 20451 net.cpp:91] Creating Layer Pooling81
I0808 13:44:09.856449 20451 net.cpp:425] Pooling81 <- Convolution81
I0808 13:44:09.856458 20451 net.cpp:399] Pooling81 -> Pooling81
I0808 13:44:09.856519 20451 net.cpp:141] Setting up Pooling81
I0808 13:44:09.856528 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.856533 20451 net.cpp:156] Memory required for data: 1438147840
I0808 13:44:09.856537 20451 layer_factory.hpp:77] Creating layer InnerProduct79
I0808 13:44:09.856549 20451 net.cpp:91] Creating Layer InnerProduct79
I0808 13:44:09.856555 20451 net.cpp:425] InnerProduct79 <- Pooling81
I0808 13:44:09.856567 20451 net.cpp:399] InnerProduct79 -> InnerProduct79
I0808 13:44:09.857672 20451 net.cpp:141] Setting up InnerProduct79
I0808 13:44:09.857683 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.857688 20451 net.cpp:156] Memory required for data: 1438173440
I0808 13:44:09.857695 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.857702 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.857707 20451 layer_factory.hpp:77] Creating layer ReLU53
I0808 13:44:09.857715 20451 net.cpp:91] Creating Layer ReLU53
I0808 13:44:09.857722 20451 net.cpp:425] ReLU53 <- InnerProduct79
I0808 13:44:09.857729 20451 net.cpp:386] ReLU53 -> InnerProduct79 (in-place)
I0808 13:44:09.857738 20451 net.cpp:141] Setting up ReLU53
I0808 13:44:09.857745 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.857750 20451 net.cpp:156] Memory required for data: 1438199040
I0808 13:44:09.857756 20451 layer_factory.hpp:77] Creating layer InnerProduct80
I0808 13:44:09.857767 20451 net.cpp:91] Creating Layer InnerProduct80
I0808 13:44:09.857774 20451 net.cpp:425] InnerProduct80 <- InnerProduct79
I0808 13:44:09.857784 20451 net.cpp:399] InnerProduct80 -> InnerProduct80
I0808 13:44:09.857969 20451 net.cpp:141] Setting up InnerProduct80
I0808 13:44:09.857977 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.857982 20451 net.cpp:156] Memory required for data: 1438211840
I0808 13:44:09.857988 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.857995 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.858001 20451 layer_factory.hpp:77] Creating layer Convolution82
I0808 13:44:09.858013 20451 net.cpp:91] Creating Layer Convolution82
I0808 13:44:09.858019 20451 net.cpp:425] Convolution82 <- c14
I0808 13:44:09.858031 20451 net.cpp:399] Convolution82 -> Convolution82
I0808 13:44:09.858409 20451 net.cpp:141] Setting up Convolution82
I0808 13:44:09.858417 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.858422 20451 net.cpp:156] Memory required for data: 1456643840
I0808 13:44:09.858429 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.858436 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.858441 20451 layer_factory.hpp:77] Creating layer Pooling82
I0808 13:44:09.858449 20451 net.cpp:91] Creating Layer Pooling82
I0808 13:44:09.858455 20451 net.cpp:425] Pooling82 <- Convolution82
I0808 13:44:09.858466 20451 net.cpp:399] Pooling82 -> Pooling82
I0808 13:44:09.858518 20451 net.cpp:141] Setting up Pooling82
I0808 13:44:09.858526 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.858531 20451 net.cpp:156] Memory required for data: 1461251840
I0808 13:44:09.858537 20451 layer_factory.hpp:77] Creating layer Convolution83
I0808 13:44:09.858551 20451 net.cpp:91] Creating Layer Convolution83
I0808 13:44:09.858567 20451 net.cpp:425] Convolution83 <- Pooling82
I0808 13:44:09.858578 20451 net.cpp:399] Convolution83 -> Convolution83
I0808 13:44:09.859124 20451 net.cpp:141] Setting up Convolution83
I0808 13:44:09.859133 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.859138 20451 net.cpp:156] Memory required for data: 1469904640
I0808 13:44:09.859144 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.859151 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.859158 20451 layer_factory.hpp:77] Creating layer Pooling83
I0808 13:44:09.859167 20451 net.cpp:91] Creating Layer Pooling83
I0808 13:44:09.859174 20451 net.cpp:425] Pooling83 <- Convolution83
I0808 13:44:09.859182 20451 net.cpp:399] Pooling83 -> Pooling83
I0808 13:44:09.859236 20451 net.cpp:141] Setting up Pooling83
I0808 13:44:09.859244 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.859249 20451 net.cpp:156] Memory required for data: 1472067840
I0808 13:44:09.859254 20451 layer_factory.hpp:77] Creating layer Convolution84
I0808 13:44:09.859267 20451 net.cpp:91] Creating Layer Convolution84
I0808 13:44:09.859298 20451 net.cpp:425] Convolution84 <- Pooling83
I0808 13:44:09.859315 20451 net.cpp:399] Convolution84 -> Convolution84
I0808 13:44:09.860282 20451 net.cpp:141] Setting up Convolution84
I0808 13:44:09.860291 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.860297 20451 net.cpp:156] Memory required for data: 1473104640
I0808 13:44:09.860304 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.860312 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.860319 20451 layer_factory.hpp:77] Creating layer Pooling84
I0808 13:44:09.860329 20451 net.cpp:91] Creating Layer Pooling84
I0808 13:44:09.860337 20451 net.cpp:425] Pooling84 <- Convolution84
I0808 13:44:09.860348 20451 net.cpp:399] Pooling84 -> Pooling84
I0808 13:44:09.860409 20451 net.cpp:141] Setting up Pooling84
I0808 13:44:09.860417 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.860424 20451 net.cpp:156] Memory required for data: 1473424640
I0808 13:44:09.860430 20451 layer_factory.hpp:77] Creating layer InnerProduct81
I0808 13:44:09.860442 20451 net.cpp:91] Creating Layer InnerProduct81
I0808 13:44:09.860450 20451 net.cpp:425] InnerProduct81 <- Pooling84
I0808 13:44:09.860462 20451 net.cpp:399] InnerProduct81 -> InnerProduct81
I0808 13:44:09.862336 20451 net.cpp:141] Setting up InnerProduct81
I0808 13:44:09.862350 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.862357 20451 net.cpp:156] Memory required for data: 1473450240
I0808 13:44:09.879952 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.879981 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.879994 20451 layer_factory.hpp:77] Creating layer ReLU54
I0808 13:44:09.880023 20451 net.cpp:91] Creating Layer ReLU54
I0808 13:44:09.880039 20451 net.cpp:425] ReLU54 <- InnerProduct81
I0808 13:44:09.880059 20451 net.cpp:386] ReLU54 -> InnerProduct81 (in-place)
I0808 13:44:09.880084 20451 net.cpp:141] Setting up ReLU54
I0808 13:44:09.880102 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.880115 20451 net.cpp:156] Memory required for data: 1473475840
I0808 13:44:09.880127 20451 layer_factory.hpp:77] Creating layer InnerProduct82
I0808 13:44:09.880148 20451 net.cpp:91] Creating Layer InnerProduct82
I0808 13:44:09.880162 20451 net.cpp:425] InnerProduct82 <- InnerProduct81
I0808 13:44:09.880188 20451 net.cpp:399] InnerProduct82 -> InnerProduct82
I0808 13:44:09.880664 20451 net.cpp:141] Setting up InnerProduct82
I0808 13:44:09.880682 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.880694 20451 net.cpp:156] Memory required for data: 1473488640
I0808 13:44:09.880708 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.880753 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.880767 20451 layer_factory.hpp:77] Creating layer Concat14
I0808 13:44:09.880786 20451 net.cpp:91] Creating Layer Concat14
I0808 13:44:09.880800 20451 net.cpp:425] Concat14 <- InnerProduct80
I0808 13:44:09.880816 20451 net.cpp:425] Concat14 <- InnerProduct82
I0808 13:44:09.880837 20451 net.cpp:399] Concat14 -> Concat14
I0808 13:44:09.880905 20451 net.cpp:141] Setting up Concat14
I0808 13:44:09.880923 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.880934 20451 net.cpp:156] Memory required for data: 1473514240
I0808 13:44:09.880946 20451 layer_factory.hpp:77] Creating layer InnerProduct83
I0808 13:44:09.880970 20451 net.cpp:91] Creating Layer InnerProduct83
I0808 13:44:09.880982 20451 net.cpp:425] InnerProduct83 <- Concat14
I0808 13:44:09.881008 20451 net.cpp:399] InnerProduct83 -> InnerProduct83
I0808 13:44:09.881453 20451 net.cpp:141] Setting up InnerProduct83
I0808 13:44:09.881469 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.881481 20451 net.cpp:156] Memory required for data: 1473530624
I0808 13:44:09.881494 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.881510 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.881523 20451 layer_factory.hpp:77] Creating layer ReLU55
I0808 13:44:09.881541 20451 net.cpp:91] Creating Layer ReLU55
I0808 13:44:09.881553 20451 net.cpp:425] ReLU55 <- InnerProduct83
I0808 13:44:09.881572 20451 net.cpp:386] ReLU55 -> InnerProduct83 (in-place)
I0808 13:44:09.881592 20451 net.cpp:141] Setting up ReLU55
I0808 13:44:09.881608 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.881620 20451 net.cpp:156] Memory required for data: 1473547008
I0808 13:44:09.881633 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.881654 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.881669 20451 net.cpp:425] drop1 <- InnerProduct83
I0808 13:44:09.881690 20451 net.cpp:399] drop1 -> Dropout27
I0808 13:44:09.881803 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.881819 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.881831 20451 net.cpp:156] Memory required for data: 1473563392
I0808 13:44:09.881844 20451 layer_factory.hpp:77] Creating layer InnerProduct84
I0808 13:44:09.881866 20451 net.cpp:91] Creating Layer InnerProduct84
I0808 13:44:09.881880 20451 net.cpp:425] InnerProduct84 <- Dropout27
I0808 13:44:09.881904 20451 net.cpp:399] InnerProduct84 -> InnerProduct84
I0808 13:44:09.882285 20451 net.cpp:141] Setting up InnerProduct84
I0808 13:44:09.882302 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.882314 20451 net.cpp:156] Memory required for data: 1473571584
I0808 13:44:09.882328 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.882344 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.882357 20451 layer_factory.hpp:77] Creating layer ReLU56
I0808 13:44:09.882374 20451 net.cpp:91] Creating Layer ReLU56
I0808 13:44:09.882386 20451 net.cpp:425] ReLU56 <- InnerProduct84
I0808 13:44:09.882408 20451 net.cpp:386] ReLU56 -> InnerProduct84 (in-place)
I0808 13:44:09.882429 20451 net.cpp:141] Setting up ReLU56
I0808 13:44:09.882446 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.882457 20451 net.cpp:156] Memory required for data: 1473579776
I0808 13:44:09.882468 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.882485 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.882498 20451 net.cpp:425] drop2 <- InnerProduct84
I0808 13:44:09.882517 20451 net.cpp:399] drop2 -> Dropout28
I0808 13:44:09.882634 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.882652 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.882663 20451 net.cpp:156] Memory required for data: 1473587968
I0808 13:44:09.882675 20451 layer_factory.hpp:77] Creating layer dt13
I0808 13:44:09.882711 20451 net.cpp:91] Creating Layer dt13
I0808 13:44:09.882725 20451 net.cpp:425] dt13 <- Dropout28
I0808 13:44:09.882746 20451 net.cpp:399] dt13 -> dt13
I0808 13:44:09.883090 20451 net.cpp:141] Setting up dt13
I0808 13:44:09.883107 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.883119 20451 net.cpp:156] Memory required for data: 1473588224
I0808 13:44:09.883133 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.883149 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.883162 20451 layer_factory.hpp:77] Creating layer Convolution85
I0808 13:44:09.883194 20451 net.cpp:91] Creating Layer Convolution85
I0808 13:44:09.883209 20451 net.cpp:425] Convolution85 <- p2_p2_0_split_5
I0808 13:44:09.883236 20451 net.cpp:399] Convolution85 -> Convolution85
I0808 13:44:09.883788 20451 net.cpp:141] Setting up Convolution85
I0808 13:44:09.883798 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.883805 20451 net.cpp:156] Memory required for data: 1492020224
I0808 13:44:09.883812 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.883821 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.883827 20451 layer_factory.hpp:77] Creating layer Pooling85
I0808 13:44:09.883837 20451 net.cpp:91] Creating Layer Pooling85
I0808 13:44:09.883844 20451 net.cpp:425] Pooling85 <- Convolution85
I0808 13:44:09.883858 20451 net.cpp:399] Pooling85 -> Pooling85
I0808 13:44:09.883919 20451 net.cpp:141] Setting up Pooling85
I0808 13:44:09.883929 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.883934 20451 net.cpp:156] Memory required for data: 1496628224
I0808 13:44:09.883940 20451 layer_factory.hpp:77] Creating layer Convolution86
I0808 13:44:09.883955 20451 net.cpp:91] Creating Layer Convolution86
I0808 13:44:09.883962 20451 net.cpp:425] Convolution86 <- Pooling85
I0808 13:44:09.883976 20451 net.cpp:399] Convolution86 -> Convolution86
I0808 13:44:09.884616 20451 net.cpp:141] Setting up Convolution86
I0808 13:44:09.884625 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.884631 20451 net.cpp:156] Memory required for data: 1505281024
I0808 13:44:09.884639 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.884646 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.884654 20451 layer_factory.hpp:77] Creating layer Pooling86
I0808 13:44:09.884665 20451 net.cpp:91] Creating Layer Pooling86
I0808 13:44:09.884671 20451 net.cpp:425] Pooling86 <- Convolution86
I0808 13:44:09.910126 20451 net.cpp:399] Pooling86 -> Pooling86
I0808 13:44:09.910223 20451 net.cpp:141] Setting up Pooling86
I0808 13:44:09.910233 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.910239 20451 net.cpp:156] Memory required for data: 1507444224
I0808 13:44:09.910246 20451 layer_factory.hpp:77] Creating layer Convolution87
I0808 13:44:09.910264 20451 net.cpp:91] Creating Layer Convolution87
I0808 13:44:09.910271 20451 net.cpp:425] Convolution87 <- Pooling86
I0808 13:44:09.910286 20451 net.cpp:399] Convolution87 -> Convolution87
I0808 13:44:09.911262 20451 net.cpp:141] Setting up Convolution87
I0808 13:44:09.911280 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.911286 20451 net.cpp:156] Memory required for data: 1508481024
I0808 13:44:09.911294 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.911303 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.911309 20451 layer_factory.hpp:77] Creating layer Pooling87
I0808 13:44:09.911319 20451 net.cpp:91] Creating Layer Pooling87
I0808 13:44:09.911326 20451 net.cpp:425] Pooling87 <- Convolution87
I0808 13:44:09.911339 20451 net.cpp:399] Pooling87 -> Pooling87
I0808 13:44:09.911401 20451 net.cpp:141] Setting up Pooling87
I0808 13:44:09.911427 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.911434 20451 net.cpp:156] Memory required for data: 1508801024
I0808 13:44:09.911440 20451 layer_factory.hpp:77] Creating layer InnerProduct85
I0808 13:44:09.911454 20451 net.cpp:91] Creating Layer InnerProduct85
I0808 13:44:09.911461 20451 net.cpp:425] InnerProduct85 <- Pooling87
I0808 13:44:09.911474 20451 net.cpp:399] InnerProduct85 -> InnerProduct85
I0808 13:44:09.912744 20451 net.cpp:141] Setting up InnerProduct85
I0808 13:44:09.912757 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.912762 20451 net.cpp:156] Memory required for data: 1508826624
I0808 13:44:09.912770 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.912778 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.912784 20451 layer_factory.hpp:77] Creating layer ReLU57
I0808 13:44:09.912793 20451 net.cpp:91] Creating Layer ReLU57
I0808 13:44:09.912801 20451 net.cpp:425] ReLU57 <- InnerProduct85
I0808 13:44:09.912808 20451 net.cpp:386] ReLU57 -> InnerProduct85 (in-place)
I0808 13:44:09.912819 20451 net.cpp:141] Setting up ReLU57
I0808 13:44:09.912827 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.912832 20451 net.cpp:156] Memory required for data: 1508852224
I0808 13:44:09.912838 20451 layer_factory.hpp:77] Creating layer InnerProduct86
I0808 13:44:09.912850 20451 net.cpp:91] Creating Layer InnerProduct86
I0808 13:44:09.912858 20451 net.cpp:425] InnerProduct86 <- InnerProduct85
I0808 13:44:09.912866 20451 net.cpp:399] InnerProduct86 -> InnerProduct86
I0808 13:44:09.913064 20451 net.cpp:141] Setting up InnerProduct86
I0808 13:44:09.913071 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.913076 20451 net.cpp:156] Memory required for data: 1508865024
I0808 13:44:09.913082 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.913089 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.913095 20451 layer_factory.hpp:77] Creating layer Convolution88
I0808 13:44:09.913107 20451 net.cpp:91] Creating Layer Convolution88
I0808 13:44:09.913115 20451 net.cpp:425] Convolution88 <- c15
I0808 13:44:09.913127 20451 net.cpp:399] Convolution88 -> Convolution88
I0808 13:44:09.913524 20451 net.cpp:141] Setting up Convolution88
I0808 13:44:09.913533 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.913538 20451 net.cpp:156] Memory required for data: 1527297024
I0808 13:44:09.913545 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.913552 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.913558 20451 layer_factory.hpp:77] Creating layer Pooling88
I0808 13:44:09.913568 20451 net.cpp:91] Creating Layer Pooling88
I0808 13:44:09.913573 20451 net.cpp:425] Pooling88 <- Convolution88
I0808 13:44:09.913584 20451 net.cpp:399] Pooling88 -> Pooling88
I0808 13:44:09.913638 20451 net.cpp:141] Setting up Pooling88
I0808 13:44:09.913646 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.913652 20451 net.cpp:156] Memory required for data: 1531905024
I0808 13:44:09.913657 20451 layer_factory.hpp:77] Creating layer Convolution89
I0808 13:44:09.913672 20451 net.cpp:91] Creating Layer Convolution89
I0808 13:44:09.913679 20451 net.cpp:425] Convolution89 <- Pooling88
I0808 13:44:09.913689 20451 net.cpp:399] Convolution89 -> Convolution89
I0808 13:44:09.914263 20451 net.cpp:141] Setting up Convolution89
I0808 13:44:09.914275 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.914281 20451 net.cpp:156] Memory required for data: 1540557824
I0808 13:44:09.914288 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.914294 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.914314 20451 layer_factory.hpp:77] Creating layer Pooling89
I0808 13:44:09.914322 20451 net.cpp:91] Creating Layer Pooling89
I0808 13:44:09.914329 20451 net.cpp:425] Pooling89 <- Convolution89
I0808 13:44:09.914338 20451 net.cpp:399] Pooling89 -> Pooling89
I0808 13:44:09.914394 20451 net.cpp:141] Setting up Pooling89
I0808 13:44:09.914402 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.914407 20451 net.cpp:156] Memory required for data: 1542721024
I0808 13:44:09.914412 20451 layer_factory.hpp:77] Creating layer Convolution90
I0808 13:44:09.914427 20451 net.cpp:91] Creating Layer Convolution90
I0808 13:44:09.914433 20451 net.cpp:425] Convolution90 <- Pooling89
I0808 13:44:09.914445 20451 net.cpp:399] Convolution90 -> Convolution90
I0808 13:44:09.915949 20451 net.cpp:141] Setting up Convolution90
I0808 13:44:09.915962 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.915968 20451 net.cpp:156] Memory required for data: 1543757824
I0808 13:44:09.915976 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.915983 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.915989 20451 layer_factory.hpp:77] Creating layer Pooling90
I0808 13:44:09.915998 20451 net.cpp:91] Creating Layer Pooling90
I0808 13:44:09.916005 20451 net.cpp:425] Pooling90 <- Convolution90
I0808 13:44:09.916016 20451 net.cpp:399] Pooling90 -> Pooling90
I0808 13:44:09.916074 20451 net.cpp:141] Setting up Pooling90
I0808 13:44:09.916081 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.916087 20451 net.cpp:156] Memory required for data: 1544077824
I0808 13:44:09.916092 20451 layer_factory.hpp:77] Creating layer InnerProduct87
I0808 13:44:09.916105 20451 net.cpp:91] Creating Layer InnerProduct87
I0808 13:44:09.916110 20451 net.cpp:425] InnerProduct87 <- Pooling90
I0808 13:44:09.916121 20451 net.cpp:399] InnerProduct87 -> InnerProduct87
I0808 13:44:09.917832 20451 net.cpp:141] Setting up InnerProduct87
I0808 13:44:09.917845 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.917850 20451 net.cpp:156] Memory required for data: 1544103424
I0808 13:44:09.917857 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.917865 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.917871 20451 layer_factory.hpp:77] Creating layer ReLU58
I0808 13:44:09.917879 20451 net.cpp:91] Creating Layer ReLU58
I0808 13:44:09.917886 20451 net.cpp:425] ReLU58 <- InnerProduct87
I0808 13:44:09.917896 20451 net.cpp:386] ReLU58 -> InnerProduct87 (in-place)
I0808 13:44:09.936425 20451 net.cpp:141] Setting up ReLU58
I0808 13:44:09.936450 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.936457 20451 net.cpp:156] Memory required for data: 1544129024
I0808 13:44:09.936466 20451 layer_factory.hpp:77] Creating layer InnerProduct88
I0808 13:44:09.936486 20451 net.cpp:91] Creating Layer InnerProduct88
I0808 13:44:09.936493 20451 net.cpp:425] InnerProduct88 <- InnerProduct87
I0808 13:44:09.936512 20451 net.cpp:399] InnerProduct88 -> InnerProduct88
I0808 13:44:09.936839 20451 net.cpp:141] Setting up InnerProduct88
I0808 13:44:09.936852 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.936859 20451 net.cpp:156] Memory required for data: 1544141824
I0808 13:44:09.936869 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.936879 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.936887 20451 layer_factory.hpp:77] Creating layer Concat15
I0808 13:44:09.936897 20451 net.cpp:91] Creating Layer Concat15
I0808 13:44:09.936904 20451 net.cpp:425] Concat15 <- InnerProduct86
I0808 13:44:09.936914 20451 net.cpp:425] Concat15 <- InnerProduct88
I0808 13:44:09.936926 20451 net.cpp:399] Concat15 -> Concat15
I0808 13:44:09.936969 20451 net.cpp:141] Setting up Concat15
I0808 13:44:09.936978 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.937005 20451 net.cpp:156] Memory required for data: 1544167424
I0808 13:44:09.937012 20451 layer_factory.hpp:77] Creating layer InnerProduct89
I0808 13:44:09.937026 20451 net.cpp:91] Creating Layer InnerProduct89
I0808 13:44:09.937033 20451 net.cpp:425] InnerProduct89 <- Concat15
I0808 13:44:09.937046 20451 net.cpp:399] InnerProduct89 -> InnerProduct89
I0808 13:44:09.937304 20451 net.cpp:141] Setting up InnerProduct89
I0808 13:44:09.937314 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.937320 20451 net.cpp:156] Memory required for data: 1544183808
I0808 13:44:09.937327 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.937336 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.937345 20451 layer_factory.hpp:77] Creating layer ReLU59
I0808 13:44:09.937357 20451 net.cpp:91] Creating Layer ReLU59
I0808 13:44:09.937366 20451 net.cpp:425] ReLU59 <- InnerProduct89
I0808 13:44:09.937374 20451 net.cpp:386] ReLU59 -> InnerProduct89 (in-place)
I0808 13:44:09.937386 20451 net.cpp:141] Setting up ReLU59
I0808 13:44:09.937394 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.937402 20451 net.cpp:156] Memory required for data: 1544200192
I0808 13:44:09.937407 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.937417 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.937427 20451 net.cpp:425] drop1 <- InnerProduct89
I0808 13:44:09.937439 20451 net.cpp:399] drop1 -> Dropout29
I0808 13:44:09.937501 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.937512 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.937520 20451 net.cpp:156] Memory required for data: 1544216576
I0808 13:44:09.937525 20451 layer_factory.hpp:77] Creating layer InnerProduct90
I0808 13:44:09.937536 20451 net.cpp:91] Creating Layer InnerProduct90
I0808 13:44:09.937542 20451 net.cpp:425] InnerProduct90 <- Dropout29
I0808 13:44:09.937556 20451 net.cpp:399] InnerProduct90 -> InnerProduct90
I0808 13:44:09.937769 20451 net.cpp:141] Setting up InnerProduct90
I0808 13:44:09.937778 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.937784 20451 net.cpp:156] Memory required for data: 1544224768
I0808 13:44:09.937793 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.937801 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.937808 20451 layer_factory.hpp:77] Creating layer ReLU60
I0808 13:44:09.937818 20451 net.cpp:91] Creating Layer ReLU60
I0808 13:44:09.937824 20451 net.cpp:425] ReLU60 <- InnerProduct90
I0808 13:44:09.937834 20451 net.cpp:386] ReLU60 -> InnerProduct90 (in-place)
I0808 13:44:09.937844 20451 net.cpp:141] Setting up ReLU60
I0808 13:44:09.937852 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.937860 20451 net.cpp:156] Memory required for data: 1544232960
I0808 13:44:09.937865 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.937878 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.937886 20451 net.cpp:425] drop2 <- InnerProduct90
I0808 13:44:09.937896 20451 net.cpp:399] drop2 -> Dropout30
I0808 13:44:09.937953 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.937961 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.937968 20451 net.cpp:156] Memory required for data: 1544241152
I0808 13:44:09.937974 20451 layer_factory.hpp:77] Creating layer dt14
I0808 13:44:09.937983 20451 net.cpp:91] Creating Layer dt14
I0808 13:44:09.937990 20451 net.cpp:425] dt14 <- Dropout30
I0808 13:44:09.938005 20451 net.cpp:399] dt14 -> dt14
I0808 13:44:09.938175 20451 net.cpp:141] Setting up dt14
I0808 13:44:09.938184 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.938190 20451 net.cpp:156] Memory required for data: 1544241408
I0808 13:44:09.938199 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.938206 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.938213 20451 layer_factory.hpp:77] Creating layer Convolution91
I0808 13:44:09.938243 20451 net.cpp:91] Creating Layer Convolution91
I0808 13:44:09.938252 20451 net.cpp:425] Convolution91 <- p2_p2_0_split_6
I0808 13:44:09.938267 20451 net.cpp:399] Convolution91 -> Convolution91
I0808 13:44:09.938705 20451 net.cpp:141] Setting up Convolution91
I0808 13:44:09.938714 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.938720 20451 net.cpp:156] Memory required for data: 1562673408
I0808 13:44:09.938727 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.938736 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.938743 20451 layer_factory.hpp:77] Creating layer Pooling91
I0808 13:44:09.938753 20451 net.cpp:91] Creating Layer Pooling91
I0808 13:44:09.938760 20451 net.cpp:425] Pooling91 <- Convolution91
I0808 13:44:09.938771 20451 net.cpp:399] Pooling91 -> Pooling91
I0808 13:44:09.938833 20451 net.cpp:141] Setting up Pooling91
I0808 13:44:09.938843 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.938848 20451 net.cpp:156] Memory required for data: 1567281408
I0808 13:44:09.938854 20451 layer_factory.hpp:77] Creating layer Convolution92
I0808 13:44:09.938869 20451 net.cpp:91] Creating Layer Convolution92
I0808 13:44:09.938876 20451 net.cpp:425] Convolution92 <- Pooling91
I0808 13:44:09.938890 20451 net.cpp:399] Convolution92 -> Convolution92
I0808 13:44:09.939620 20451 net.cpp:141] Setting up Convolution92
I0808 13:44:09.939633 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.939640 20451 net.cpp:156] Memory required for data: 1575934208
I0808 13:44:09.939648 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.939658 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.939666 20451 layer_factory.hpp:77] Creating layer Pooling92
I0808 13:44:09.939680 20451 net.cpp:91] Creating Layer Pooling92
I0808 13:44:09.939688 20451 net.cpp:425] Pooling92 <- Convolution92
I0808 13:44:09.939699 20451 net.cpp:399] Pooling92 -> Pooling92
I0808 13:44:09.939772 20451 net.cpp:141] Setting up Pooling92
I0808 13:44:09.939782 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.939790 20451 net.cpp:156] Memory required for data: 1578097408
I0808 13:44:09.939795 20451 layer_factory.hpp:77] Creating layer Convolution93
I0808 13:44:09.939812 20451 net.cpp:91] Creating Layer Convolution93
I0808 13:44:09.939821 20451 net.cpp:425] Convolution93 <- Pooling92
I0808 13:44:09.940320 20451 net.cpp:399] Convolution93 -> Convolution93
I0808 13:44:09.941879 20451 net.cpp:141] Setting up Convolution93
I0808 13:44:09.941903 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.941915 20451 net.cpp:156] Memory required for data: 1579134208
I0808 13:44:09.941928 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.941942 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.941954 20451 layer_factory.hpp:77] Creating layer Pooling93
I0808 13:44:09.941977 20451 net.cpp:91] Creating Layer Pooling93
I0808 13:44:09.941992 20451 net.cpp:425] Pooling93 <- Convolution93
I0808 13:44:09.942010 20451 net.cpp:399] Pooling93 -> Pooling93
I0808 13:44:09.942126 20451 net.cpp:141] Setting up Pooling93
I0808 13:44:09.942142 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.942152 20451 net.cpp:156] Memory required for data: 1579454208
I0808 13:44:09.942162 20451 layer_factory.hpp:77] Creating layer InnerProduct91
I0808 13:44:09.942185 20451 net.cpp:91] Creating Layer InnerProduct91
I0808 13:44:09.942198 20451 net.cpp:425] InnerProduct91 <- Pooling93
I0808 13:44:09.942217 20451 net.cpp:399] InnerProduct91 -> InnerProduct91
I0808 13:44:09.943929 20451 net.cpp:141] Setting up InnerProduct91
I0808 13:44:09.943948 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.943954 20451 net.cpp:156] Memory required for data: 1579479808
I0808 13:44:09.943984 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.943992 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.944000 20451 layer_factory.hpp:77] Creating layer ReLU61
I0808 13:44:09.944010 20451 net.cpp:91] Creating Layer ReLU61
I0808 13:44:09.944020 20451 net.cpp:425] ReLU61 <- InnerProduct91
I0808 13:44:09.944032 20451 net.cpp:386] ReLU61 -> InnerProduct91 (in-place)
I0808 13:44:09.944046 20451 net.cpp:141] Setting up ReLU61
I0808 13:44:09.944054 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.944061 20451 net.cpp:156] Memory required for data: 1579505408
I0808 13:44:09.944067 20451 layer_factory.hpp:77] Creating layer InnerProduct92
I0808 13:44:09.944079 20451 net.cpp:91] Creating Layer InnerProduct92
I0808 13:44:09.944090 20451 net.cpp:425] InnerProduct92 <- InnerProduct91
I0808 13:44:09.944102 20451 net.cpp:399] InnerProduct92 -> InnerProduct92
I0808 13:44:09.945029 20451 net.cpp:141] Setting up InnerProduct92
I0808 13:44:09.945042 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.945049 20451 net.cpp:156] Memory required for data: 1579518208
I0808 13:44:09.945057 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.945065 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.945072 20451 layer_factory.hpp:77] Creating layer Convolution94
I0808 13:44:09.945092 20451 net.cpp:91] Creating Layer Convolution94
I0808 13:44:09.945101 20451 net.cpp:425] Convolution94 <- c16
I0808 13:44:09.945113 20451 net.cpp:399] Convolution94 -> Convolution94
I0808 13:44:09.945595 20451 net.cpp:141] Setting up Convolution94
I0808 13:44:09.945605 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.945611 20451 net.cpp:156] Memory required for data: 1597950208
I0808 13:44:09.945617 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.945626 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.945633 20451 layer_factory.hpp:77] Creating layer Pooling94
I0808 13:44:09.945642 20451 net.cpp:91] Creating Layer Pooling94
I0808 13:44:09.945649 20451 net.cpp:425] Pooling94 <- Convolution94
I0808 13:44:09.945660 20451 net.cpp:399] Pooling94 -> Pooling94
I0808 13:44:09.945727 20451 net.cpp:141] Setting up Pooling94
I0808 13:44:09.945736 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.945742 20451 net.cpp:156] Memory required for data: 1602558208
I0808 13:44:09.945749 20451 layer_factory.hpp:77] Creating layer Convolution95
I0808 13:44:09.945765 20451 net.cpp:91] Creating Layer Convolution95
I0808 13:44:09.945771 20451 net.cpp:425] Convolution95 <- Pooling94
I0808 13:44:09.945785 20451 net.cpp:399] Convolution95 -> Convolution95
I0808 13:44:09.946439 20451 net.cpp:141] Setting up Convolution95
I0808 13:44:09.946449 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.946455 20451 net.cpp:156] Memory required for data: 1611211008
I0808 13:44:09.946462 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.946470 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.946477 20451 layer_factory.hpp:77] Creating layer Pooling95
I0808 13:44:09.946486 20451 net.cpp:91] Creating Layer Pooling95
I0808 13:44:09.946496 20451 net.cpp:425] Pooling95 <- Convolution95
I0808 13:44:09.946506 20451 net.cpp:399] Pooling95 -> Pooling95
I0808 13:44:09.946565 20451 net.cpp:141] Setting up Pooling95
I0808 13:44:09.946576 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.946583 20451 net.cpp:156] Memory required for data: 1613374208
I0808 13:44:09.946589 20451 layer_factory.hpp:77] Creating layer Convolution96
I0808 13:44:09.946604 20451 net.cpp:91] Creating Layer Convolution96
I0808 13:44:09.946611 20451 net.cpp:425] Convolution96 <- Pooling95
I0808 13:44:09.946637 20451 net.cpp:399] Convolution96 -> Convolution96
I0808 13:44:09.947616 20451 net.cpp:141] Setting up Convolution96
I0808 13:44:09.947626 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.947633 20451 net.cpp:156] Memory required for data: 1614411008
I0808 13:44:09.947639 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.947648 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.947654 20451 layer_factory.hpp:77] Creating layer Pooling96
I0808 13:44:09.947666 20451 net.cpp:91] Creating Layer Pooling96
I0808 13:44:09.947674 20451 net.cpp:425] Pooling96 <- Convolution96
I0808 13:44:09.947684 20451 net.cpp:399] Pooling96 -> Pooling96
I0808 13:44:09.947749 20451 net.cpp:141] Setting up Pooling96
I0808 13:44:09.947758 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.947764 20451 net.cpp:156] Memory required for data: 1614731008
I0808 13:44:09.947772 20451 layer_factory.hpp:77] Creating layer InnerProduct93
I0808 13:44:09.947784 20451 net.cpp:91] Creating Layer InnerProduct93
I0808 13:44:09.947791 20451 net.cpp:425] InnerProduct93 <- Pooling96
I0808 13:44:09.947803 20451 net.cpp:399] InnerProduct93 -> InnerProduct93
I0808 13:44:09.949718 20451 net.cpp:141] Setting up InnerProduct93
I0808 13:44:09.949731 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.949738 20451 net.cpp:156] Memory required for data: 1614756608
I0808 13:44:09.949746 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.949755 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.949762 20451 layer_factory.hpp:77] Creating layer ReLU62
I0808 13:44:09.949771 20451 net.cpp:91] Creating Layer ReLU62
I0808 13:44:09.949779 20451 net.cpp:425] ReLU62 <- InnerProduct93
I0808 13:44:09.949792 20451 net.cpp:386] ReLU62 -> InnerProduct93 (in-place)
I0808 13:44:09.949805 20451 net.cpp:141] Setting up ReLU62
I0808 13:44:09.949812 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.949818 20451 net.cpp:156] Memory required for data: 1614782208
I0808 13:44:09.949826 20451 layer_factory.hpp:77] Creating layer InnerProduct94
I0808 13:44:09.949836 20451 net.cpp:91] Creating Layer InnerProduct94
I0808 13:44:09.949843 20451 net.cpp:425] InnerProduct94 <- InnerProduct93
I0808 13:44:09.949857 20451 net.cpp:399] InnerProduct94 -> InnerProduct94
I0808 13:44:09.972090 20451 net.cpp:141] Setting up InnerProduct94
I0808 13:44:09.972116 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.972124 20451 net.cpp:156] Memory required for data: 1614795008
I0808 13:44:09.972141 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.972152 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.972162 20451 layer_factory.hpp:77] Creating layer Concat16
I0808 13:44:09.972180 20451 net.cpp:91] Creating Layer Concat16
I0808 13:44:09.972192 20451 net.cpp:425] Concat16 <- InnerProduct92
I0808 13:44:09.972204 20451 net.cpp:425] Concat16 <- InnerProduct94
I0808 13:44:09.972218 20451 net.cpp:399] Concat16 -> Concat16
I0808 13:44:09.972267 20451 net.cpp:141] Setting up Concat16
I0808 13:44:09.972278 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.972287 20451 net.cpp:156] Memory required for data: 1614820608
I0808 13:44:09.972295 20451 layer_factory.hpp:77] Creating layer InnerProduct95
I0808 13:44:09.972312 20451 net.cpp:91] Creating Layer InnerProduct95
I0808 13:44:09.972321 20451 net.cpp:425] InnerProduct95 <- Concat16
I0808 13:44:09.972337 20451 net.cpp:399] InnerProduct95 -> InnerProduct95
I0808 13:44:09.972612 20451 net.cpp:141] Setting up InnerProduct95
I0808 13:44:09.972623 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.972630 20451 net.cpp:156] Memory required for data: 1614836992
I0808 13:44:09.972637 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:09.972661 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:09.972668 20451 layer_factory.hpp:77] Creating layer ReLU63
I0808 13:44:09.972679 20451 net.cpp:91] Creating Layer ReLU63
I0808 13:44:09.972687 20451 net.cpp:425] ReLU63 <- InnerProduct95
I0808 13:44:09.972697 20451 net.cpp:386] ReLU63 -> InnerProduct95 (in-place)
I0808 13:44:09.972710 20451 net.cpp:141] Setting up ReLU63
I0808 13:44:09.972720 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.972728 20451 net.cpp:156] Memory required for data: 1614853376
I0808 13:44:09.972738 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:09.972749 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:09.972757 20451 net.cpp:425] drop1 <- InnerProduct95
I0808 13:44:09.972776 20451 net.cpp:399] drop1 -> Dropout31
I0808 13:44:09.972856 20451 net.cpp:141] Setting up drop1
I0808 13:44:09.972868 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:09.972879 20451 net.cpp:156] Memory required for data: 1614869760
I0808 13:44:09.972887 20451 layer_factory.hpp:77] Creating layer InnerProduct96
I0808 13:44:09.972903 20451 net.cpp:91] Creating Layer InnerProduct96
I0808 13:44:09.972911 20451 net.cpp:425] InnerProduct96 <- Dropout31
I0808 13:44:09.972925 20451 net.cpp:399] InnerProduct96 -> InnerProduct96
I0808 13:44:09.973142 20451 net.cpp:141] Setting up InnerProduct96
I0808 13:44:09.973151 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.973157 20451 net.cpp:156] Memory required for data: 1614877952
I0808 13:44:09.973165 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:09.973173 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:09.973179 20451 layer_factory.hpp:77] Creating layer ReLU64
I0808 13:44:09.973188 20451 net.cpp:91] Creating Layer ReLU64
I0808 13:44:09.973196 20451 net.cpp:425] ReLU64 <- InnerProduct96
I0808 13:44:09.973204 20451 net.cpp:386] ReLU64 -> InnerProduct96 (in-place)
I0808 13:44:09.973215 20451 net.cpp:141] Setting up ReLU64
I0808 13:44:09.973223 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.973229 20451 net.cpp:156] Memory required for data: 1614886144
I0808 13:44:09.973237 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:09.973249 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:09.973256 20451 net.cpp:425] drop2 <- InnerProduct96
I0808 13:44:09.973266 20451 net.cpp:399] drop2 -> Dropout32
I0808 13:44:09.973325 20451 net.cpp:141] Setting up drop2
I0808 13:44:09.973336 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:09.973342 20451 net.cpp:156] Memory required for data: 1614894336
I0808 13:44:09.973348 20451 layer_factory.hpp:77] Creating layer dt15
I0808 13:44:09.973358 20451 net.cpp:91] Creating Layer dt15
I0808 13:44:09.973366 20451 net.cpp:425] dt15 <- Dropout32
I0808 13:44:09.973377 20451 net.cpp:399] dt15 -> dt15
I0808 13:44:09.973551 20451 net.cpp:141] Setting up dt15
I0808 13:44:09.973559 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:09.973565 20451 net.cpp:156] Memory required for data: 1614894592
I0808 13:44:09.973572 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:09.973580 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:09.973587 20451 layer_factory.hpp:77] Creating layer Convolution97
I0808 13:44:09.973603 20451 net.cpp:91] Creating Layer Convolution97
I0808 13:44:09.973613 20451 net.cpp:425] Convolution97 <- p2_p2_0_split_7
I0808 13:44:09.973628 20451 net.cpp:399] Convolution97 -> Convolution97
I0808 13:44:09.974102 20451 net.cpp:141] Setting up Convolution97
I0808 13:44:09.974112 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.974118 20451 net.cpp:156] Memory required for data: 1633326592
I0808 13:44:09.974125 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.974133 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.974151 20451 layer_factory.hpp:77] Creating layer Pooling97
I0808 13:44:09.974171 20451 net.cpp:91] Creating Layer Pooling97
I0808 13:44:09.974179 20451 net.cpp:425] Pooling97 <- Convolution97
I0808 13:44:09.974190 20451 net.cpp:399] Pooling97 -> Pooling97
I0808 13:44:09.974256 20451 net.cpp:141] Setting up Pooling97
I0808 13:44:09.974264 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.974270 20451 net.cpp:156] Memory required for data: 1637934592
I0808 13:44:09.974277 20451 layer_factory.hpp:77] Creating layer Convolution98
I0808 13:44:09.974293 20451 net.cpp:91] Creating Layer Convolution98
I0808 13:44:09.974299 20451 net.cpp:425] Convolution98 <- Pooling97
I0808 13:44:09.974313 20451 net.cpp:399] Convolution98 -> Convolution98
I0808 13:44:09.975716 20451 net.cpp:141] Setting up Convolution98
I0808 13:44:09.975733 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.975739 20451 net.cpp:156] Memory required for data: 1646587392
I0808 13:44:09.975747 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.975755 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.975762 20451 layer_factory.hpp:77] Creating layer Pooling98
I0808 13:44:09.975774 20451 net.cpp:91] Creating Layer Pooling98
I0808 13:44:09.975780 20451 net.cpp:425] Pooling98 <- Convolution98
I0808 13:44:09.975795 20451 net.cpp:399] Pooling98 -> Pooling98
I0808 13:44:09.975857 20451 net.cpp:141] Setting up Pooling98
I0808 13:44:09.975865 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.975872 20451 net.cpp:156] Memory required for data: 1648750592
I0808 13:44:09.975878 20451 layer_factory.hpp:77] Creating layer Convolution99
I0808 13:44:09.975893 20451 net.cpp:91] Creating Layer Convolution99
I0808 13:44:09.975900 20451 net.cpp:425] Convolution99 <- Pooling98
I0808 13:44:09.975914 20451 net.cpp:399] Convolution99 -> Convolution99
I0808 13:44:09.976864 20451 net.cpp:141] Setting up Convolution99
I0808 13:44:09.976873 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.976881 20451 net.cpp:156] Memory required for data: 1649787392
I0808 13:44:09.976887 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.976896 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.976902 20451 layer_factory.hpp:77] Creating layer Pooling99
I0808 13:44:09.976913 20451 net.cpp:91] Creating Layer Pooling99
I0808 13:44:09.976922 20451 net.cpp:425] Pooling99 <- Convolution99
I0808 13:44:09.976932 20451 net.cpp:399] Pooling99 -> Pooling99
I0808 13:44:09.976996 20451 net.cpp:141] Setting up Pooling99
I0808 13:44:09.977005 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.977011 20451 net.cpp:156] Memory required for data: 1650107392
I0808 13:44:09.977017 20451 layer_factory.hpp:77] Creating layer InnerProduct97
I0808 13:44:09.977027 20451 net.cpp:91] Creating Layer InnerProduct97
I0808 13:44:09.977035 20451 net.cpp:425] InnerProduct97 <- Pooling99
I0808 13:44:09.977048 20451 net.cpp:399] InnerProduct97 -> InnerProduct97
I0808 13:44:09.978320 20451 net.cpp:141] Setting up InnerProduct97
I0808 13:44:09.978330 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.978335 20451 net.cpp:156] Memory required for data: 1650132992
I0808 13:44:09.978343 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.978351 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.978358 20451 layer_factory.hpp:77] Creating layer ReLU65
I0808 13:44:09.978368 20451 net.cpp:91] Creating Layer ReLU65
I0808 13:44:09.978374 20451 net.cpp:425] ReLU65 <- InnerProduct97
I0808 13:44:09.978385 20451 net.cpp:386] ReLU65 -> InnerProduct97 (in-place)
I0808 13:44:09.978396 20451 net.cpp:141] Setting up ReLU65
I0808 13:44:09.978404 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.978426 20451 net.cpp:156] Memory required for data: 1650158592
I0808 13:44:09.978433 20451 layer_factory.hpp:77] Creating layer InnerProduct98
I0808 13:44:09.978443 20451 net.cpp:91] Creating Layer InnerProduct98
I0808 13:44:09.978451 20451 net.cpp:425] InnerProduct98 <- InnerProduct97
I0808 13:44:09.978463 20451 net.cpp:399] InnerProduct98 -> InnerProduct98
I0808 13:44:09.978673 20451 net.cpp:141] Setting up InnerProduct98
I0808 13:44:09.978682 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.978688 20451 net.cpp:156] Memory required for data: 1650171392
I0808 13:44:09.978695 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.978703 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:09.978709 20451 layer_factory.hpp:77] Creating layer Convolution100
I0808 13:44:09.978723 20451 net.cpp:91] Creating Layer Convolution100
I0808 13:44:09.978729 20451 net.cpp:425] Convolution100 <- c17
I0808 13:44:09.978744 20451 net.cpp:399] Convolution100 -> Convolution100
I0808 13:44:09.979225 20451 net.cpp:141] Setting up Convolution100
I0808 13:44:09.979238 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:09.979248 20451 net.cpp:156] Memory required for data: 1668603392
I0808 13:44:09.979256 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:09.979266 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:09.979291 20451 layer_factory.hpp:77] Creating layer Pooling100
I0808 13:44:09.979307 20451 net.cpp:91] Creating Layer Pooling100
I0808 13:44:09.979317 20451 net.cpp:425] Pooling100 <- Convolution100
I0808 13:44:09.979331 20451 net.cpp:399] Pooling100 -> Pooling100
I0808 13:44:09.979416 20451 net.cpp:141] Setting up Pooling100
I0808 13:44:09.979427 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:09.979434 20451 net.cpp:156] Memory required for data: 1673211392
I0808 13:44:09.979440 20451 layer_factory.hpp:77] Creating layer Convolution101
I0808 13:44:09.979456 20451 net.cpp:91] Creating Layer Convolution101
I0808 13:44:09.979463 20451 net.cpp:425] Convolution101 <- Pooling100
I0808 13:44:09.979475 20451 net.cpp:399] Convolution101 -> Convolution101
I0808 13:44:09.980123 20451 net.cpp:141] Setting up Convolution101
I0808 13:44:09.980131 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:09.980139 20451 net.cpp:156] Memory required for data: 1681864192
I0808 13:44:09.980145 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:09.980152 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:09.980159 20451 layer_factory.hpp:77] Creating layer Pooling101
I0808 13:44:09.980168 20451 net.cpp:91] Creating Layer Pooling101
I0808 13:44:09.980175 20451 net.cpp:425] Pooling101 <- Convolution101
I0808 13:44:09.980186 20451 net.cpp:399] Pooling101 -> Pooling101
I0808 13:44:09.980249 20451 net.cpp:141] Setting up Pooling101
I0808 13:44:09.980257 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:09.980263 20451 net.cpp:156] Memory required for data: 1684027392
I0808 13:44:09.980270 20451 layer_factory.hpp:77] Creating layer Convolution102
I0808 13:44:09.980285 20451 net.cpp:91] Creating Layer Convolution102
I0808 13:44:09.980294 20451 net.cpp:425] Convolution102 <- Pooling101
I0808 13:44:09.980305 20451 net.cpp:399] Convolution102 -> Convolution102
I0808 13:44:09.981258 20451 net.cpp:141] Setting up Convolution102
I0808 13:44:09.981267 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:09.981273 20451 net.cpp:156] Memory required for data: 1685064192
I0808 13:44:09.981281 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:09.981288 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:09.981295 20451 layer_factory.hpp:77] Creating layer Pooling102
I0808 13:44:09.981323 20451 net.cpp:91] Creating Layer Pooling102
I0808 13:44:09.981329 20451 net.cpp:425] Pooling102 <- Convolution102
I0808 13:44:09.981339 20451 net.cpp:399] Pooling102 -> Pooling102
I0808 13:44:09.981403 20451 net.cpp:141] Setting up Pooling102
I0808 13:44:09.981412 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:09.981418 20451 net.cpp:156] Memory required for data: 1685384192
I0808 13:44:09.981425 20451 layer_factory.hpp:77] Creating layer InnerProduct99
I0808 13:44:09.981434 20451 net.cpp:91] Creating Layer InnerProduct99
I0808 13:44:09.981441 20451 net.cpp:425] InnerProduct99 <- Pooling102
I0808 13:44:09.981456 20451 net.cpp:399] InnerProduct99 -> InnerProduct99
I0808 13:44:09.983343 20451 net.cpp:141] Setting up InnerProduct99
I0808 13:44:09.983358 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.983364 20451 net.cpp:156] Memory required for data: 1685409792
I0808 13:44:09.983373 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:09.983381 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:09.983388 20451 layer_factory.hpp:77] Creating layer ReLU66
I0808 13:44:09.983398 20451 net.cpp:91] Creating Layer ReLU66
I0808 13:44:09.983407 20451 net.cpp:425] ReLU66 <- InnerProduct99
I0808 13:44:09.983415 20451 net.cpp:386] ReLU66 -> InnerProduct99 (in-place)
I0808 13:44:09.983428 20451 net.cpp:141] Setting up ReLU66
I0808 13:44:09.983436 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:09.983443 20451 net.cpp:156] Memory required for data: 1685435392
I0808 13:44:09.983448 20451 layer_factory.hpp:77] Creating layer InnerProduct100
I0808 13:44:09.983461 20451 net.cpp:91] Creating Layer InnerProduct100
I0808 13:44:09.983469 20451 net.cpp:425] InnerProduct100 <- InnerProduct99
I0808 13:44:09.983481 20451 net.cpp:399] InnerProduct100 -> InnerProduct100
I0808 13:44:09.983703 20451 net.cpp:141] Setting up InnerProduct100
I0808 13:44:09.983711 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:09.983717 20451 net.cpp:156] Memory required for data: 1685448192
I0808 13:44:09.983724 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:09.983732 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:10.002826 20451 layer_factory.hpp:77] Creating layer Concat17
I0808 13:44:10.002849 20451 net.cpp:91] Creating Layer Concat17
I0808 13:44:10.002861 20451 net.cpp:425] Concat17 <- InnerProduct98
I0808 13:44:10.002876 20451 net.cpp:425] Concat17 <- InnerProduct100
I0808 13:44:10.002892 20451 net.cpp:399] Concat17 -> Concat17
I0808 13:44:10.002971 20451 net.cpp:141] Setting up Concat17
I0808 13:44:10.002985 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.002993 20451 net.cpp:156] Memory required for data: 1685473792
I0808 13:44:10.003002 20451 layer_factory.hpp:77] Creating layer InnerProduct101
I0808 13:44:10.003020 20451 net.cpp:91] Creating Layer InnerProduct101
I0808 13:44:10.003028 20451 net.cpp:425] InnerProduct101 <- Concat17
I0808 13:44:10.003041 20451 net.cpp:399] InnerProduct101 -> InnerProduct101
I0808 13:44:10.003334 20451 net.cpp:141] Setting up InnerProduct101
I0808 13:44:10.003345 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:10.003351 20451 net.cpp:156] Memory required for data: 1685490176
I0808 13:44:10.003360 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:10.003368 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:10.003374 20451 layer_factory.hpp:77] Creating layer ReLU67
I0808 13:44:10.003384 20451 net.cpp:91] Creating Layer ReLU67
I0808 13:44:10.003391 20451 net.cpp:425] ReLU67 <- InnerProduct101
I0808 13:44:10.003409 20451 net.cpp:386] ReLU67 -> InnerProduct101 (in-place)
I0808 13:44:10.003420 20451 net.cpp:141] Setting up ReLU67
I0808 13:44:10.003429 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:10.003435 20451 net.cpp:156] Memory required for data: 1685506560
I0808 13:44:10.003456 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:10.003466 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:10.003473 20451 net.cpp:425] drop1 <- InnerProduct101
I0808 13:44:10.003487 20451 net.cpp:399] drop1 -> Dropout33
I0808 13:44:10.003547 20451 net.cpp:141] Setting up drop1
I0808 13:44:10.003556 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:10.003563 20451 net.cpp:156] Memory required for data: 1685522944
I0808 13:44:10.003569 20451 layer_factory.hpp:77] Creating layer InnerProduct102
I0808 13:44:10.003592 20451 net.cpp:91] Creating Layer InnerProduct102
I0808 13:44:10.003598 20451 net.cpp:425] InnerProduct102 <- Dropout33
I0808 13:44:10.003609 20451 net.cpp:399] InnerProduct102 -> InnerProduct102
I0808 13:44:10.003844 20451 net.cpp:141] Setting up InnerProduct102
I0808 13:44:10.003854 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:10.003861 20451 net.cpp:156] Memory required for data: 1685531136
I0808 13:44:10.003868 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:10.003877 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:10.003885 20451 layer_factory.hpp:77] Creating layer ReLU68
I0808 13:44:10.003895 20451 net.cpp:91] Creating Layer ReLU68
I0808 13:44:10.003902 20451 net.cpp:425] ReLU68 <- InnerProduct102
I0808 13:44:10.003911 20451 net.cpp:386] ReLU68 -> InnerProduct102 (in-place)
I0808 13:44:10.003922 20451 net.cpp:141] Setting up ReLU68
I0808 13:44:10.003931 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:10.003937 20451 net.cpp:156] Memory required for data: 1685539328
I0808 13:44:10.003943 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:10.003957 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:10.003965 20451 net.cpp:425] drop2 <- InnerProduct102
I0808 13:44:10.003978 20451 net.cpp:399] drop2 -> Dropout34
I0808 13:44:10.004045 20451 net.cpp:141] Setting up drop2
I0808 13:44:10.004055 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:10.004061 20451 net.cpp:156] Memory required for data: 1685547520
I0808 13:44:10.004068 20451 layer_factory.hpp:77] Creating layer dt16
I0808 13:44:10.004078 20451 net.cpp:91] Creating Layer dt16
I0808 13:44:10.004086 20451 net.cpp:425] dt16 <- Dropout34
I0808 13:44:10.004101 20451 net.cpp:399] dt16 -> dt16
I0808 13:44:10.004281 20451 net.cpp:141] Setting up dt16
I0808 13:44:10.004290 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:10.004297 20451 net.cpp:156] Memory required for data: 1685547776
I0808 13:44:10.004303 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:10.004312 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:10.004319 20451 layer_factory.hpp:77] Creating layer Convolution103
I0808 13:44:10.004336 20451 net.cpp:91] Creating Layer Convolution103
I0808 13:44:10.004344 20451 net.cpp:425] Convolution103 <- p2_p2_0_split_8
I0808 13:44:10.004357 20451 net.cpp:399] Convolution103 -> Convolution103
I0808 13:44:10.004806 20451 net.cpp:141] Setting up Convolution103
I0808 13:44:10.004818 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:10.004825 20451 net.cpp:156] Memory required for data: 1703979776
I0808 13:44:10.004835 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:10.004844 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:10.004853 20451 layer_factory.hpp:77] Creating layer Pooling103
I0808 13:44:10.004864 20451 net.cpp:91] Creating Layer Pooling103
I0808 13:44:10.004873 20451 net.cpp:425] Pooling103 <- Convolution103
I0808 13:44:10.004886 20451 net.cpp:399] Pooling103 -> Pooling103
I0808 13:44:10.004968 20451 net.cpp:141] Setting up Pooling103
I0808 13:44:10.004977 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:10.004984 20451 net.cpp:156] Memory required for data: 1708587776
I0808 13:44:10.004990 20451 layer_factory.hpp:77] Creating layer Convolution104
I0808 13:44:10.005019 20451 net.cpp:91] Creating Layer Convolution104
I0808 13:44:10.005028 20451 net.cpp:425] Convolution104 <- Pooling103
I0808 13:44:10.005040 20451 net.cpp:399] Convolution104 -> Convolution104
I0808 13:44:10.005717 20451 net.cpp:141] Setting up Convolution104
I0808 13:44:10.005728 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:10.005733 20451 net.cpp:156] Memory required for data: 1717240576
I0808 13:44:10.005741 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:10.005749 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:10.005756 20451 layer_factory.hpp:77] Creating layer Pooling104
I0808 13:44:10.005765 20451 net.cpp:91] Creating Layer Pooling104
I0808 13:44:10.005774 20451 net.cpp:425] Pooling104 <- Convolution104
I0808 13:44:10.005785 20451 net.cpp:399] Pooling104 -> Pooling104
I0808 13:44:10.005847 20451 net.cpp:141] Setting up Pooling104
I0808 13:44:10.005856 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:10.005862 20451 net.cpp:156] Memory required for data: 1719403776
I0808 13:44:10.005868 20451 layer_factory.hpp:77] Creating layer Convolution105
I0808 13:44:10.005883 20451 net.cpp:91] Creating Layer Convolution105
I0808 13:44:10.005890 20451 net.cpp:425] Convolution105 <- Pooling104
I0808 13:44:10.005903 20451 net.cpp:399] Convolution105 -> Convolution105
I0808 13:44:10.007853 20451 net.cpp:141] Setting up Convolution105
I0808 13:44:10.007889 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:10.007906 20451 net.cpp:156] Memory required for data: 1720440576
I0808 13:44:10.007925 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:10.007941 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:10.007956 20451 layer_factory.hpp:77] Creating layer Pooling105
I0808 13:44:10.007975 20451 net.cpp:91] Creating Layer Pooling105
I0808 13:44:10.007990 20451 net.cpp:425] Pooling105 <- Convolution105
I0808 13:44:10.008019 20451 net.cpp:399] Pooling105 -> Pooling105
I0808 13:44:10.008148 20451 net.cpp:141] Setting up Pooling105
I0808 13:44:10.035167 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:10.035192 20451 net.cpp:156] Memory required for data: 1720760576
I0808 13:44:10.035212 20451 layer_factory.hpp:77] Creating layer InnerProduct103
I0808 13:44:10.035243 20451 net.cpp:91] Creating Layer InnerProduct103
I0808 13:44:10.035262 20451 net.cpp:425] InnerProduct103 <- Pooling105
I0808 13:44:10.035315 20451 net.cpp:399] InnerProduct103 -> InnerProduct103
I0808 13:44:10.037962 20451 net.cpp:141] Setting up InnerProduct103
I0808 13:44:10.037987 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.038000 20451 net.cpp:156] Memory required for data: 1720786176
I0808 13:44:10.038017 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:10.038034 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:10.038048 20451 layer_factory.hpp:77] Creating layer ReLU69
I0808 13:44:10.038066 20451 net.cpp:91] Creating Layer ReLU69
I0808 13:44:10.038080 20451 net.cpp:425] ReLU69 <- InnerProduct103
I0808 13:44:10.038105 20451 net.cpp:386] ReLU69 -> InnerProduct103 (in-place)
I0808 13:44:10.038138 20451 net.cpp:141] Setting up ReLU69
I0808 13:44:10.038161 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.038178 20451 net.cpp:156] Memory required for data: 1720811776
I0808 13:44:10.038194 20451 layer_factory.hpp:77] Creating layer InnerProduct104
I0808 13:44:10.038223 20451 net.cpp:91] Creating Layer InnerProduct104
I0808 13:44:10.038242 20451 net.cpp:425] InnerProduct104 <- InnerProduct103
I0808 13:44:10.038267 20451 net.cpp:399] InnerProduct104 -> InnerProduct104
I0808 13:44:10.038699 20451 net.cpp:141] Setting up InnerProduct104
I0808 13:44:10.038717 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:10.038758 20451 net.cpp:156] Memory required for data: 1720824576
I0808 13:44:10.038772 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:10.038787 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:10.038800 20451 layer_factory.hpp:77] Creating layer Convolution106
I0808 13:44:10.038830 20451 net.cpp:91] Creating Layer Convolution106
I0808 13:44:10.038844 20451 net.cpp:425] Convolution106 <- c18
I0808 13:44:10.038868 20451 net.cpp:399] Convolution106 -> Convolution106
I0808 13:44:10.039609 20451 net.cpp:141] Setting up Convolution106
I0808 13:44:10.039619 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:10.039625 20451 net.cpp:156] Memory required for data: 1739256576
I0808 13:44:10.039633 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:10.039640 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:10.039647 20451 layer_factory.hpp:77] Creating layer Pooling106
I0808 13:44:10.039659 20451 net.cpp:91] Creating Layer Pooling106
I0808 13:44:10.039667 20451 net.cpp:425] Pooling106 <- Convolution106
I0808 13:44:10.039677 20451 net.cpp:399] Pooling106 -> Pooling106
I0808 13:44:10.039742 20451 net.cpp:141] Setting up Pooling106
I0808 13:44:10.039752 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:10.039757 20451 net.cpp:156] Memory required for data: 1743864576
I0808 13:44:10.039763 20451 layer_factory.hpp:77] Creating layer Convolution107
I0808 13:44:10.039778 20451 net.cpp:91] Creating Layer Convolution107
I0808 13:44:10.039785 20451 net.cpp:425] Convolution107 <- Pooling106
I0808 13:44:10.039796 20451 net.cpp:399] Convolution107 -> Convolution107
I0808 13:44:10.040443 20451 net.cpp:141] Setting up Convolution107
I0808 13:44:10.040452 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:10.040458 20451 net.cpp:156] Memory required for data: 1752517376
I0808 13:44:10.040465 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:10.040473 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:10.040480 20451 layer_factory.hpp:77] Creating layer Pooling107
I0808 13:44:10.040494 20451 net.cpp:91] Creating Layer Pooling107
I0808 13:44:10.040501 20451 net.cpp:425] Pooling107 <- Convolution107
I0808 13:44:10.040511 20451 net.cpp:399] Pooling107 -> Pooling107
I0808 13:44:10.040575 20451 net.cpp:141] Setting up Pooling107
I0808 13:44:10.040583 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:10.040590 20451 net.cpp:156] Memory required for data: 1754680576
I0808 13:44:10.040596 20451 layer_factory.hpp:77] Creating layer Convolution108
I0808 13:44:10.040611 20451 net.cpp:91] Creating Layer Convolution108
I0808 13:44:10.040617 20451 net.cpp:425] Convolution108 <- Pooling107
I0808 13:44:10.040630 20451 net.cpp:399] Convolution108 -> Convolution108
I0808 13:44:10.041601 20451 net.cpp:141] Setting up Convolution108
I0808 13:44:10.041611 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:10.041617 20451 net.cpp:156] Memory required for data: 1755717376
I0808 13:44:10.041625 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:10.041632 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:10.041638 20451 layer_factory.hpp:77] Creating layer Pooling108
I0808 13:44:10.041647 20451 net.cpp:91] Creating Layer Pooling108
I0808 13:44:10.041654 20451 net.cpp:425] Pooling108 <- Convolution108
I0808 13:44:10.041666 20451 net.cpp:399] Pooling108 -> Pooling108
I0808 13:44:10.041729 20451 net.cpp:141] Setting up Pooling108
I0808 13:44:10.041738 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:10.041744 20451 net.cpp:156] Memory required for data: 1756037376
I0808 13:44:10.041750 20451 layer_factory.hpp:77] Creating layer InnerProduct105
I0808 13:44:10.041775 20451 net.cpp:91] Creating Layer InnerProduct105
I0808 13:44:10.041782 20451 net.cpp:425] InnerProduct105 <- Pooling108
I0808 13:44:10.041795 20451 net.cpp:399] InnerProduct105 -> InnerProduct105
I0808 13:44:10.043715 20451 net.cpp:141] Setting up InnerProduct105
I0808 13:44:10.043730 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.043736 20451 net.cpp:156] Memory required for data: 1756062976
I0808 13:44:10.043745 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:10.043752 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:10.043759 20451 layer_factory.hpp:77] Creating layer ReLU70
I0808 13:44:10.043772 20451 net.cpp:91] Creating Layer ReLU70
I0808 13:44:10.043779 20451 net.cpp:425] ReLU70 <- InnerProduct105
I0808 13:44:10.043789 20451 net.cpp:386] ReLU70 -> InnerProduct105 (in-place)
I0808 13:44:10.043800 20451 net.cpp:141] Setting up ReLU70
I0808 13:44:10.043809 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.043815 20451 net.cpp:156] Memory required for data: 1756088576
I0808 13:44:10.043822 20451 layer_factory.hpp:77] Creating layer InnerProduct106
I0808 13:44:10.043834 20451 net.cpp:91] Creating Layer InnerProduct106
I0808 13:44:10.043840 20451 net.cpp:425] InnerProduct106 <- InnerProduct105
I0808 13:44:10.043851 20451 net.cpp:399] InnerProduct106 -> InnerProduct106
I0808 13:44:10.044077 20451 net.cpp:141] Setting up InnerProduct106
I0808 13:44:10.044086 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:10.044092 20451 net.cpp:156] Memory required for data: 1756101376
I0808 13:44:10.044100 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:10.044107 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:10.044114 20451 layer_factory.hpp:77] Creating layer Concat18
I0808 13:44:10.044123 20451 net.cpp:91] Creating Layer Concat18
I0808 13:44:10.044131 20451 net.cpp:425] Concat18 <- InnerProduct104
I0808 13:44:10.044139 20451 net.cpp:425] Concat18 <- InnerProduct106
I0808 13:44:10.044152 20451 net.cpp:399] Concat18 -> Concat18
I0808 13:44:10.044191 20451 net.cpp:141] Setting up Concat18
I0808 13:44:10.044200 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.044206 20451 net.cpp:156] Memory required for data: 1756126976
I0808 13:44:10.044212 20451 layer_factory.hpp:77] Creating layer InnerProduct107
I0808 13:44:10.044222 20451 net.cpp:91] Creating Layer InnerProduct107
I0808 13:44:10.044229 20451 net.cpp:425] InnerProduct107 <- Concat18
I0808 13:44:10.044242 20451 net.cpp:399] InnerProduct107 -> InnerProduct107
I0808 13:44:10.044477 20451 net.cpp:141] Setting up InnerProduct107
I0808 13:44:10.044486 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:10.044492 20451 net.cpp:156] Memory required for data: 1756143360
I0808 13:44:10.044499 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:10.044507 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:10.044514 20451 layer_factory.hpp:77] Creating layer ReLU71
I0808 13:44:10.044523 20451 net.cpp:91] Creating Layer ReLU71
I0808 13:44:10.044529 20451 net.cpp:425] ReLU71 <- InnerProduct107
I0808 13:44:10.044541 20451 net.cpp:386] ReLU71 -> InnerProduct107 (in-place)
I0808 13:44:10.044551 20451 net.cpp:141] Setting up ReLU71
I0808 13:44:10.044560 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:10.044566 20451 net.cpp:156] Memory required for data: 1756159744
I0808 13:44:10.044572 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:10.044581 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:10.044589 20451 net.cpp:425] drop1 <- InnerProduct107
I0808 13:44:10.044600 20451 net.cpp:399] drop1 -> Dropout35
I0808 13:44:10.044661 20451 net.cpp:141] Setting up drop1
I0808 13:44:10.044670 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:10.044677 20451 net.cpp:156] Memory required for data: 1756176128
I0808 13:44:10.044697 20451 layer_factory.hpp:77] Creating layer InnerProduct108
I0808 13:44:10.044710 20451 net.cpp:91] Creating Layer InnerProduct108
I0808 13:44:10.044718 20451 net.cpp:425] InnerProduct108 <- Dropout35
I0808 13:44:10.044728 20451 net.cpp:399] InnerProduct108 -> InnerProduct108
I0808 13:44:10.044930 20451 net.cpp:141] Setting up InnerProduct108
I0808 13:44:10.044939 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:10.044945 20451 net.cpp:156] Memory required for data: 1756184320
I0808 13:44:10.044951 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:10.044960 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:10.044966 20451 layer_factory.hpp:77] Creating layer ReLU72
I0808 13:44:10.045136 20451 net.cpp:91] Creating Layer ReLU72
I0808 13:44:10.045143 20451 net.cpp:425] ReLU72 <- InnerProduct108
I0808 13:44:10.045153 20451 net.cpp:386] ReLU72 -> InnerProduct108 (in-place)
I0808 13:44:10.045163 20451 net.cpp:141] Setting up ReLU72
I0808 13:44:10.045171 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:10.045177 20451 net.cpp:156] Memory required for data: 1756192512
I0808 13:44:10.045184 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:10.045193 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:10.045200 20451 net.cpp:425] drop2 <- InnerProduct108
I0808 13:44:10.045210 20451 net.cpp:399] drop2 -> Dropout36
I0808 13:44:10.045274 20451 net.cpp:141] Setting up drop2
I0808 13:44:10.045282 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:10.045289 20451 net.cpp:156] Memory required for data: 1756200704
I0808 13:44:10.045295 20451 layer_factory.hpp:77] Creating layer dt17
I0808 13:44:10.045306 20451 net.cpp:91] Creating Layer dt17
I0808 13:44:10.045313 20451 net.cpp:425] dt17 <- Dropout36
I0808 13:44:10.045327 20451 net.cpp:399] dt17 -> dt17
I0808 13:44:10.045511 20451 net.cpp:141] Setting up dt17
I0808 13:44:10.045519 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:10.045526 20451 net.cpp:156] Memory required for data: 1756200960
I0808 13:44:10.045532 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:10.045541 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:10.045547 20451 layer_factory.hpp:77] Creating layer Convolution109
I0808 13:44:10.045560 20451 net.cpp:91] Creating Layer Convolution109
I0808 13:44:10.045568 20451 net.cpp:425] Convolution109 <- p2_p2_0_split_9
I0808 13:44:10.045583 20451 net.cpp:399] Convolution109 -> Convolution109
I0808 13:44:10.046028 20451 net.cpp:141] Setting up Convolution109
I0808 13:44:10.046037 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:10.046043 20451 net.cpp:156] Memory required for data: 1774632960
I0808 13:44:10.046051 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:10.046058 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:10.046064 20451 layer_factory.hpp:77] Creating layer Pooling109
I0808 13:44:10.046074 20451 net.cpp:91] Creating Layer Pooling109
I0808 13:44:10.046082 20451 net.cpp:425] Pooling109 <- Convolution109
I0808 13:44:10.046093 20451 net.cpp:399] Pooling109 -> Pooling109
I0808 13:44:10.046155 20451 net.cpp:141] Setting up Pooling109
I0808 13:44:10.046164 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:10.046170 20451 net.cpp:156] Memory required for data: 1779240960
I0808 13:44:10.046176 20451 layer_factory.hpp:77] Creating layer Convolution110
I0808 13:44:10.046193 20451 net.cpp:91] Creating Layer Convolution110
I0808 13:44:10.046200 20451 net.cpp:425] Convolution110 <- Pooling109
I0808 13:44:10.046211 20451 net.cpp:399] Convolution110 -> Convolution110
I0808 13:44:10.046861 20451 net.cpp:141] Setting up Convolution110
I0808 13:44:10.046870 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:10.046876 20451 net.cpp:156] Memory required for data: 1787893760
I0808 13:44:10.046883 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:10.046901 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:10.046908 20451 layer_factory.hpp:77] Creating layer Pooling110
I0808 13:44:10.046917 20451 net.cpp:91] Creating Layer Pooling110
I0808 13:44:10.046924 20451 net.cpp:425] Pooling110 <- Convolution110
I0808 13:44:10.046936 20451 net.cpp:399] Pooling110 -> Pooling110
I0808 13:44:10.046999 20451 net.cpp:141] Setting up Pooling110
I0808 13:44:10.047008 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:10.047014 20451 net.cpp:156] Memory required for data: 1790056960
I0808 13:44:10.047020 20451 layer_factory.hpp:77] Creating layer Convolution111
I0808 13:44:10.047035 20451 net.cpp:91] Creating Layer Convolution111
I0808 13:44:10.047042 20451 net.cpp:425] Convolution111 <- Pooling110
I0808 13:44:10.047055 20451 net.cpp:399] Convolution111 -> Convolution111
I0808 13:44:10.048043 20451 net.cpp:141] Setting up Convolution111
I0808 13:44:10.048051 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:10.048058 20451 net.cpp:156] Memory required for data: 1791093760
I0808 13:44:10.048065 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:10.048074 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:10.048079 20451 layer_factory.hpp:77] Creating layer Pooling111
I0808 13:44:10.048091 20451 net.cpp:91] Creating Layer Pooling111
I0808 13:44:10.048099 20451 net.cpp:425] Pooling111 <- Convolution111
I0808 13:44:10.048108 20451 net.cpp:399] Pooling111 -> Pooling111
I0808 13:44:10.048173 20451 net.cpp:141] Setting up Pooling111
I0808 13:44:10.048182 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:10.048188 20451 net.cpp:156] Memory required for data: 1791413760
I0808 13:44:10.048194 20451 layer_factory.hpp:77] Creating layer InnerProduct109
I0808 13:44:10.048204 20451 net.cpp:91] Creating Layer InnerProduct109
I0808 13:44:10.048210 20451 net.cpp:425] InnerProduct109 <- Pooling111
I0808 13:44:10.063314 20451 net.cpp:399] InnerProduct109 -> InnerProduct109
I0808 13:44:10.065102 20451 net.cpp:141] Setting up InnerProduct109
I0808 13:44:10.065120 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.065129 20451 net.cpp:156] Memory required for data: 1791439360
I0808 13:44:10.065141 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:10.065152 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:10.065162 20451 layer_factory.hpp:77] Creating layer ReLU73
I0808 13:44:10.065176 20451 net.cpp:91] Creating Layer ReLU73
I0808 13:44:10.065186 20451 net.cpp:425] ReLU73 <- InnerProduct109
I0808 13:44:10.065201 20451 net.cpp:386] ReLU73 -> InnerProduct109 (in-place)
I0808 13:44:10.065217 20451 net.cpp:141] Setting up ReLU73
I0808 13:44:10.065228 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.065237 20451 net.cpp:156] Memory required for data: 1791464960
I0808 13:44:10.065245 20451 layer_factory.hpp:77] Creating layer InnerProduct110
I0808 13:44:10.065260 20451 net.cpp:91] Creating Layer InnerProduct110
I0808 13:44:10.065269 20451 net.cpp:425] InnerProduct110 <- InnerProduct109
I0808 13:44:10.065287 20451 net.cpp:399] InnerProduct110 -> InnerProduct110
I0808 13:44:10.065578 20451 net.cpp:141] Setting up InnerProduct110
I0808 13:44:10.065590 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:10.065598 20451 net.cpp:156] Memory required for data: 1791477760
I0808 13:44:10.065608 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:10.065618 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:10.065628 20451 layer_factory.hpp:77] Creating layer Convolution112
I0808 13:44:10.065649 20451 net.cpp:91] Creating Layer Convolution112
I0808 13:44:10.065657 20451 net.cpp:425] Convolution112 <- c19
I0808 13:44:10.065695 20451 net.cpp:399] Convolution112 -> Convolution112
I0808 13:44:10.066368 20451 net.cpp:141] Setting up Convolution112
I0808 13:44:10.066381 20451 net.cpp:148] Top shape: 64 20 60 60 (4608000)
I0808 13:44:10.066390 20451 net.cpp:156] Memory required for data: 1809909760
I0808 13:44:10.066400 20451 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'Convolution1', param index 0
I0808 13:44:10.066411 20451 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'Convolution1', param index 1
I0808 13:44:10.066419 20451 layer_factory.hpp:77] Creating layer Pooling112
I0808 13:44:10.066436 20451 net.cpp:91] Creating Layer Pooling112
I0808 13:44:10.066444 20451 net.cpp:425] Pooling112 <- Convolution112
I0808 13:44:10.066458 20451 net.cpp:399] Pooling112 -> Pooling112
I0808 13:44:10.066545 20451 net.cpp:141] Setting up Pooling112
I0808 13:44:10.066557 20451 net.cpp:148] Top shape: 64 20 30 30 (1152000)
I0808 13:44:10.066565 20451 net.cpp:156] Memory required for data: 1814517760
I0808 13:44:10.066573 20451 layer_factory.hpp:77] Creating layer Convolution113
I0808 13:44:10.066592 20451 net.cpp:91] Creating Layer Convolution113
I0808 13:44:10.066601 20451 net.cpp:425] Convolution113 <- Pooling112
I0808 13:44:10.066619 20451 net.cpp:399] Convolution113 -> Convolution113
I0808 13:44:10.067495 20451 net.cpp:141] Setting up Convolution113
I0808 13:44:10.067508 20451 net.cpp:148] Top shape: 64 50 26 26 (2163200)
I0808 13:44:10.067517 20451 net.cpp:156] Memory required for data: 1823170560
I0808 13:44:10.067526 20451 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'Convolution2', param index 0
I0808 13:44:10.067538 20451 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'Convolution2', param index 1
I0808 13:44:10.067545 20451 layer_factory.hpp:77] Creating layer Pooling113
I0808 13:44:10.067558 20451 net.cpp:91] Creating Layer Pooling113
I0808 13:44:10.067567 20451 net.cpp:425] Pooling113 <- Convolution113
I0808 13:44:10.067584 20451 net.cpp:399] Pooling113 -> Pooling113
I0808 13:44:10.067665 20451 net.cpp:141] Setting up Pooling113
I0808 13:44:10.067677 20451 net.cpp:148] Top shape: 64 50 13 13 (540800)
I0808 13:44:10.067685 20451 net.cpp:156] Memory required for data: 1825333760
I0808 13:44:10.067694 20451 layer_factory.hpp:77] Creating layer Convolution114
I0808 13:44:10.067713 20451 net.cpp:91] Creating Layer Convolution114
I0808 13:44:10.067723 20451 net.cpp:425] Convolution114 <- Pooling113
I0808 13:44:10.067740 20451 net.cpp:399] Convolution114 -> Convolution114
I0808 13:44:10.069844 20451 net.cpp:141] Setting up Convolution114
I0808 13:44:10.069864 20451 net.cpp:148] Top shape: 64 50 9 9 (259200)
I0808 13:44:10.069874 20451 net.cpp:156] Memory required for data: 1826370560
I0808 13:44:10.069885 20451 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'Convolution3', param index 0
I0808 13:44:10.069895 20451 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'Convolution3', param index 1
I0808 13:44:10.069905 20451 layer_factory.hpp:77] Creating layer Pooling114
I0808 13:44:10.069918 20451 net.cpp:91] Creating Layer Pooling114
I0808 13:44:10.069928 20451 net.cpp:425] Pooling114 <- Convolution114
I0808 13:44:10.069946 20451 net.cpp:399] Pooling114 -> Pooling114
I0808 13:44:10.070032 20451 net.cpp:141] Setting up Pooling114
I0808 13:44:10.070044 20451 net.cpp:148] Top shape: 64 50 5 5 (80000)
I0808 13:44:10.070052 20451 net.cpp:156] Memory required for data: 1826690560
I0808 13:44:10.070060 20451 layer_factory.hpp:77] Creating layer InnerProduct111
I0808 13:44:10.070077 20451 net.cpp:91] Creating Layer InnerProduct111
I0808 13:44:10.070086 20451 net.cpp:425] InnerProduct111 <- Pooling114
I0808 13:44:10.070106 20451 net.cpp:399] InnerProduct111 -> InnerProduct111
I0808 13:44:10.072648 20451 net.cpp:141] Setting up InnerProduct111
I0808 13:44:10.072667 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.072676 20451 net.cpp:156] Memory required for data: 1826716160
I0808 13:44:10.072687 20451 net.cpp:484] Sharing parameters 'ip1_w' owned by layer 'InnerProduct1', param index 0
I0808 13:44:10.072721 20451 net.cpp:484] Sharing parameters 'ip1_b' owned by layer 'InnerProduct1', param index 1
I0808 13:44:10.072729 20451 layer_factory.hpp:77] Creating layer ReLU74
I0808 13:44:10.072746 20451 net.cpp:91] Creating Layer ReLU74
I0808 13:44:10.072757 20451 net.cpp:425] ReLU74 <- InnerProduct111
I0808 13:44:10.072769 20451 net.cpp:386] ReLU74 -> InnerProduct111 (in-place)
I0808 13:44:10.072785 20451 net.cpp:141] Setting up ReLU74
I0808 13:44:10.072796 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.072804 20451 net.cpp:156] Memory required for data: 1826741760
I0808 13:44:10.072813 20451 layer_factory.hpp:77] Creating layer InnerProduct112
I0808 13:44:10.072826 20451 net.cpp:91] Creating Layer InnerProduct112
I0808 13:44:10.072835 20451 net.cpp:425] InnerProduct112 <- InnerProduct111
I0808 13:44:10.072854 20451 net.cpp:399] InnerProduct112 -> InnerProduct112
I0808 13:44:10.073154 20451 net.cpp:141] Setting up InnerProduct112
I0808 13:44:10.073166 20451 net.cpp:148] Top shape: 64 50 (3200)
I0808 13:44:10.073173 20451 net.cpp:156] Memory required for data: 1826754560
I0808 13:44:10.073184 20451 net.cpp:484] Sharing parameters 'ip2_w' owned by layer 'InnerProduct2', param index 0
I0808 13:44:10.073194 20451 net.cpp:484] Sharing parameters 'ip2_b' owned by layer 'InnerProduct2', param index 1
I0808 13:44:10.073202 20451 layer_factory.hpp:77] Creating layer Concat19
I0808 13:44:10.073215 20451 net.cpp:91] Creating Layer Concat19
I0808 13:44:10.073223 20451 net.cpp:425] Concat19 <- InnerProduct110
I0808 13:44:10.073235 20451 net.cpp:425] Concat19 <- InnerProduct112
I0808 13:44:10.073248 20451 net.cpp:399] Concat19 -> Concat19
I0808 13:44:10.073297 20451 net.cpp:141] Setting up Concat19
I0808 13:44:10.073307 20451 net.cpp:148] Top shape: 64 100 (6400)
I0808 13:44:10.073315 20451 net.cpp:156] Memory required for data: 1826780160
I0808 13:44:10.073324 20451 layer_factory.hpp:77] Creating layer InnerProduct113
I0808 13:44:10.073340 20451 net.cpp:91] Creating Layer InnerProduct113
I0808 13:44:10.090551 20451 net.cpp:425] InnerProduct113 <- Concat19
I0808 13:44:10.090606 20451 net.cpp:399] InnerProduct113 -> InnerProduct113
I0808 13:44:10.091075 20451 net.cpp:141] Setting up InnerProduct113
I0808 13:44:10.091094 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:10.091104 20451 net.cpp:156] Memory required for data: 1826796544
I0808 13:44:10.091117 20451 net.cpp:484] Sharing parameters 'fc1_w' owned by layer 'InnerProduct5', param index 0
I0808 13:44:10.091131 20451 net.cpp:484] Sharing parameters 'fc1_b' owned by layer 'InnerProduct5', param index 1
I0808 13:44:10.091142 20451 layer_factory.hpp:77] Creating layer ReLU75
I0808 13:44:10.091158 20451 net.cpp:91] Creating Layer ReLU75
I0808 13:44:10.091169 20451 net.cpp:425] ReLU75 <- InnerProduct113
I0808 13:44:10.091183 20451 net.cpp:386] ReLU75 -> InnerProduct113 (in-place)
I0808 13:44:10.091202 20451 net.cpp:141] Setting up ReLU75
I0808 13:44:10.091214 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:10.091223 20451 net.cpp:156] Memory required for data: 1826812928
I0808 13:44:10.091233 20451 layer_factory.hpp:77] Creating layer drop1
I0808 13:44:10.091251 20451 net.cpp:91] Creating Layer drop1
I0808 13:44:10.091265 20451 net.cpp:425] drop1 <- InnerProduct113
I0808 13:44:10.091305 20451 net.cpp:399] drop1 -> Dropout37
I0808 13:44:10.091410 20451 net.cpp:141] Setting up drop1
I0808 13:44:10.091428 20451 net.cpp:148] Top shape: 64 64 (4096)
I0808 13:44:10.091437 20451 net.cpp:156] Memory required for data: 1826829312
I0808 13:44:10.091447 20451 layer_factory.hpp:77] Creating layer InnerProduct114
I0808 13:44:10.091464 20451 net.cpp:91] Creating Layer InnerProduct114
I0808 13:44:10.091478 20451 net.cpp:425] InnerProduct114 <- Dropout37
I0808 13:44:10.091495 20451 net.cpp:399] InnerProduct114 -> InnerProduct114
I0808 13:44:10.091810 20451 net.cpp:141] Setting up InnerProduct114
I0808 13:44:10.091825 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:10.091835 20451 net.cpp:156] Memory required for data: 1826837504
I0808 13:44:10.091867 20451 net.cpp:484] Sharing parameters 'fc2_w' owned by layer 'InnerProduct6', param index 0
I0808 13:44:10.091881 20451 net.cpp:484] Sharing parameters 'fc2_b' owned by layer 'InnerProduct6', param index 1
I0808 13:44:10.091891 20451 layer_factory.hpp:77] Creating layer ReLU76
I0808 13:44:10.091903 20451 net.cpp:91] Creating Layer ReLU76
I0808 13:44:10.091915 20451 net.cpp:425] ReLU76 <- InnerProduct114
I0808 13:44:10.091934 20451 net.cpp:386] ReLU76 -> InnerProduct114 (in-place)
I0808 13:44:10.091953 20451 net.cpp:141] Setting up ReLU76
I0808 13:44:10.091965 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:10.091975 20451 net.cpp:156] Memory required for data: 1826845696
I0808 13:44:10.091985 20451 layer_factory.hpp:77] Creating layer drop2
I0808 13:44:10.091998 20451 net.cpp:91] Creating Layer drop2
I0808 13:44:10.092010 20451 net.cpp:425] drop2 <- InnerProduct114
I0808 13:44:10.092027 20451 net.cpp:399] drop2 -> Dropout38
I0808 13:44:10.092120 20451 net.cpp:141] Setting up drop2
I0808 13:44:10.092134 20451 net.cpp:148] Top shape: 64 32 (2048)
I0808 13:44:10.092145 20451 net.cpp:156] Memory required for data: 1826853888
I0808 13:44:10.092155 20451 layer_factory.hpp:77] Creating layer dt18
I0808 13:44:10.092171 20451 net.cpp:91] Creating Layer dt18
I0808 13:44:10.092183 20451 net.cpp:425] dt18 <- Dropout38
I0808 13:44:10.092201 20451 net.cpp:399] dt18 -> dt18
I0808 13:44:10.092488 20451 net.cpp:141] Setting up dt18
I0808 13:44:10.092501 20451 net.cpp:148] Top shape: 64 1 (64)
I0808 13:44:10.092511 20451 net.cpp:156] Memory required for data: 1826854144
I0808 13:44:10.092522 20451 net.cpp:484] Sharing parameters 'fc3_w' owned by layer 'dt0', param index 0
I0808 13:44:10.092535 20451 net.cpp:484] Sharing parameters 'fc3_b' owned by layer 'dt0', param index 1
I0808 13:44:10.092545 20451 layer_factory.hpp:77] Creating layer con
I0808 13:44:10.092567 20451 net.cpp:91] Creating Layer con
I0808 13:44:10.092579 20451 net.cpp:425] con <- dt0
I0808 13:44:10.092595 20451 net.cpp:425] con <- dt1
I0808 13:44:10.092609 20451 net.cpp:425] con <- dt2
I0808 13:44:10.092623 20451 net.cpp:425] con <- dt3
I0808 13:44:10.092636 20451 net.cpp:425] con <- dt4
I0808 13:44:10.092649 20451 net.cpp:425] con <- dt5
I0808 13:44:10.092663 20451 net.cpp:425] con <- dt6
I0808 13:44:10.092674 20451 net.cpp:425] con <- dt7
I0808 13:44:10.092686 20451 net.cpp:425] con <- dt8
I0808 13:44:10.092699 20451 net.cpp:425] con <- dt9
I0808 13:44:10.092710 20451 net.cpp:425] con <- dt10
I0808 13:44:10.092720 20451 net.cpp:425] con <- dt11
I0808 13:44:10.092735 20451 net.cpp:425] con <- dt12
I0808 13:44:10.092746 20451 net.cpp:425] con <- dt13
I0808 13:44:10.092756 20451 net.cpp:425] con <- dt14
I0808 13:44:10.092767 20451 net.cpp:425] con <- dt15
I0808 13:44:10.092778 20451 net.cpp:425] con <- dt16
I0808 13:44:10.092790 20451 net.cpp:425] con <- dt17
I0808 13:44:10.092802 20451 net.cpp:425] con <- dt18
I0808 13:44:10.092824 20451 net.cpp:399] con -> con
I0808 13:44:10.092887 20451 net.cpp:141] Setting up con
I0808 13:44:10.092901 20451 net.cpp:148] Top shape: 64 19 (1216)
I0808 13:44:10.092912 20451 net.cpp:156] Memory required for data: 1826859008
I0808 13:44:10.092923 20451 layer_factory.hpp:77] Creating layer r1
I0808 13:44:10.092941 20451 net.cpp:91] Creating Layer r1
I0808 13:44:10.092952 20451 net.cpp:425] r1 <- con
I0808 13:44:10.092970 20451 net.cpp:399] r1 -> r1
I0808 13:44:10.093026 20451 net.cpp:141] Setting up r1
I0808 13:44:10.093039 20451 net.cpp:148] Top shape: 64 1 1 19 (1216)
I0808 13:44:10.093046 20451 net.cpp:156] Memory required for data: 1826863872
I0808 13:44:10.093057 20451 layer_factory.hpp:77] Creating layer p
I0808 13:44:10.093073 20451 net.cpp:91] Creating Layer p
I0808 13:44:10.093085 20451 net.cpp:425] p <- r1
I0808 13:44:10.093099 20451 net.cpp:399] p -> p
I0808 13:44:10.093212 20451 net.cpp:141] Setting up p
I0808 13:44:10.093228 20451 net.cpp:148] Top shape: 64 1 1 1 (64)
I0808 13:44:10.093238 20451 net.cpp:156] Memory required for data: 1826864128
I0808 13:44:10.093248 20451 layer_factory.hpp:77] Creating layer r2
I0808 13:44:10.093286 20451 net.cpp:91] Creating Layer r2
I0808 13:44:10.093299 20451 net.cpp:425] r2 <- p
I0808 13:44:10.093315 20451 net.cpp:399] r2 -> r2
I0808 13:44:10.093379 20451 net.cpp:141] Setting up r2
I0808 13:44:10.093396 20451 net.cpp:148] Top shape: 64 1 1 1 (64)
I0808 13:44:10.093406 20451 net.cpp:156] Memory required for data: 1826864384
I0808 13:44:10.093417 20451 layer_factory.hpp:77] Creating layer padL
I0808 13:44:10.093432 20451 net.cpp:91] Creating Layer padL
I0808 13:44:10.093442 20451 net.cpp:425] padL <- label_data_1_split_1
I0808 13:44:10.093461 20451 net.cpp:399] padL -> padL
I0808 13:44:10.093521 20451 net.cpp:141] Setting up padL
I0808 13:44:10.093535 20451 net.cpp:148] Top shape: 64 1 1 1 (64)
I0808 13:44:10.093545 20451 net.cpp:156] Memory required for data: 1826864640
I0808 13:44:10.093554 20451 layer_factory.hpp:77] Creating layer pad
I0808 13:44:10.093569 20451 net.cpp:91] Creating Layer pad
I0808 13:44:10.093580 20451 net.cpp:425] pad <- r2
I0808 13:44:10.093592 20451 net.cpp:425] pad <- padL
I0808 13:44:10.093608 20451 net.cpp:399] pad -> pad
I0808 13:44:10.093669 20451 net.cpp:141] Setting up pad
I0808 13:44:10.093683 20451 net.cpp:148] Top shape: 64 2 1 1 (128)
I0808 13:44:10.093693 20451 net.cpp:156] Memory required for data: 1826865152
I0808 13:44:10.093703 20451 layer_factory.hpp:77] Creating layer pad_pad_0_split
I0808 13:44:10.093719 20451 net.cpp:91] Creating Layer pad_pad_0_split
I0808 13:44:10.093729 20451 net.cpp:425] pad_pad_0_split <- pad
I0808 13:44:10.093744 20451 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_0
I0808 13:44:10.093762 20451 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_1
I0808 13:44:10.094055 20451 net.cpp:141] Setting up pad_pad_0_split
I0808 13:44:10.094071 20451 net.cpp:148] Top shape: 64 2 1 1 (128)
I0808 13:44:10.094092 20451 net.cpp:148] Top shape: 64 2 1 1 (128)
I0808 13:44:10.094105 20451 net.cpp:156] Memory required for data: 1826866176
I0808 13:44:10.096117 20451 layer_factory.hpp:77] Creating layer loss
I0808 13:44:10.096139 20451 net.cpp:91] Creating Layer loss
I0808 13:44:10.096151 20451 net.cpp:425] loss <- pad_pad_0_split_0
I0808 13:44:10.096164 20451 net.cpp:425] loss <- th_th_0_split_0
I0808 13:44:10.096179 20451 net.cpp:399] loss -> loss
I0808 13:44:10.096253 20451 net.cpp:141] Setting up loss
I0808 13:44:10.096266 20451 net.cpp:148] Top shape: (1)
I0808 13:44:10.096274 20451 net.cpp:151]     with loss weight 1
I0808 13:44:10.096290 20451 net.cpp:156] Memory required for data: 1826866180
I0808 13:44:10.096299 20451 layer_factory.hpp:77] Creating layer accuracy
I0808 13:44:10.096319 20451 net.cpp:91] Creating Layer accuracy
I0808 13:44:10.096328 20451 net.cpp:425] accuracy <- pad_pad_0_split_1
I0808 13:44:10.096339 20451 net.cpp:425] accuracy <- th_th_0_split_1
I0808 13:44:10.096354 20451 net.cpp:399] accuracy -> accuracy
I0808 13:44:10.096371 20451 net.cpp:141] Setting up accuracy
I0808 13:44:10.096384 20451 net.cpp:148] Top shape: (1)
I0808 13:44:10.096391 20451 net.cpp:156] Memory required for data: 1826866184
I0808 13:44:10.096400 20451 net.cpp:219] accuracy does not need backward computation.
I0808 13:44:10.096410 20451 net.cpp:217] loss needs backward computation.
I0808 13:44:10.096420 20451 net.cpp:217] pad_pad_0_split needs backward computation.
I0808 13:44:10.096428 20451 net.cpp:217] pad needs backward computation.
I0808 13:44:10.096438 20451 net.cpp:219] padL does not need backward computation.
I0808 13:44:10.096448 20451 net.cpp:217] r2 needs backward computation.
I0808 13:44:10.096459 20451 net.cpp:217] p needs backward computation.
I0808 13:44:10.096472 20451 net.cpp:217] r1 needs backward computation.
I0808 13:44:10.096483 20451 net.cpp:217] con needs backward computation.
I0808 13:44:10.096504 20451 net.cpp:217] dt18 needs backward computation.
I0808 13:44:10.096515 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.096526 20451 net.cpp:217] ReLU76 needs backward computation.
I0808 13:44:10.096536 20451 net.cpp:217] InnerProduct114 needs backward computation.
I0808 13:44:10.096547 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.096580 20451 net.cpp:217] ReLU75 needs backward computation.
I0808 13:44:10.096590 20451 net.cpp:217] InnerProduct113 needs backward computation.
I0808 13:44:10.096601 20451 net.cpp:217] Concat19 needs backward computation.
I0808 13:44:10.096613 20451 net.cpp:217] InnerProduct112 needs backward computation.
I0808 13:44:10.096624 20451 net.cpp:217] ReLU74 needs backward computation.
I0808 13:44:10.096633 20451 net.cpp:217] InnerProduct111 needs backward computation.
I0808 13:44:10.096644 20451 net.cpp:217] Pooling114 needs backward computation.
I0808 13:44:10.096655 20451 net.cpp:217] Convolution114 needs backward computation.
I0808 13:44:10.096667 20451 net.cpp:217] Pooling113 needs backward computation.
I0808 13:44:10.096678 20451 net.cpp:217] Convolution113 needs backward computation.
I0808 13:44:10.096688 20451 net.cpp:217] Pooling112 needs backward computation.
I0808 13:44:10.096699 20451 net.cpp:217] Convolution112 needs backward computation.
I0808 13:44:10.096711 20451 net.cpp:217] InnerProduct110 needs backward computation.
I0808 13:44:10.096724 20451 net.cpp:217] ReLU73 needs backward computation.
I0808 13:44:10.096734 20451 net.cpp:217] InnerProduct109 needs backward computation.
I0808 13:44:10.096743 20451 net.cpp:217] Pooling111 needs backward computation.
I0808 13:44:10.096757 20451 net.cpp:217] Convolution111 needs backward computation.
I0808 13:44:10.096770 20451 net.cpp:217] Pooling110 needs backward computation.
I0808 13:44:10.096781 20451 net.cpp:217] Convolution110 needs backward computation.
I0808 13:44:10.096792 20451 net.cpp:217] Pooling109 needs backward computation.
I0808 13:44:10.096803 20451 net.cpp:217] Convolution109 needs backward computation.
I0808 13:44:10.096814 20451 net.cpp:217] dt17 needs backward computation.
I0808 13:44:10.096824 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.096835 20451 net.cpp:217] ReLU72 needs backward computation.
I0808 13:44:10.096845 20451 net.cpp:217] InnerProduct108 needs backward computation.
I0808 13:44:10.096855 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.096870 20451 net.cpp:217] ReLU71 needs backward computation.
I0808 13:44:10.096881 20451 net.cpp:217] InnerProduct107 needs backward computation.
I0808 13:44:10.096891 20451 net.cpp:217] Concat18 needs backward computation.
I0808 13:44:10.096904 20451 net.cpp:217] InnerProduct106 needs backward computation.
I0808 13:44:10.096913 20451 net.cpp:217] ReLU70 needs backward computation.
I0808 13:44:10.096925 20451 net.cpp:217] InnerProduct105 needs backward computation.
I0808 13:44:10.096935 20451 net.cpp:217] Pooling108 needs backward computation.
I0808 13:44:10.096946 20451 net.cpp:217] Convolution108 needs backward computation.
I0808 13:44:10.096956 20451 net.cpp:217] Pooling107 needs backward computation.
I0808 13:44:10.096967 20451 net.cpp:217] Convolution107 needs backward computation.
I0808 13:44:10.096979 20451 net.cpp:217] Pooling106 needs backward computation.
I0808 13:44:10.096990 20451 net.cpp:217] Convolution106 needs backward computation.
I0808 13:44:10.097002 20451 net.cpp:217] InnerProduct104 needs backward computation.
I0808 13:44:10.097013 20451 net.cpp:217] ReLU69 needs backward computation.
I0808 13:44:10.097024 20451 net.cpp:217] InnerProduct103 needs backward computation.
I0808 13:44:10.097035 20451 net.cpp:217] Pooling105 needs backward computation.
I0808 13:44:10.097046 20451 net.cpp:217] Convolution105 needs backward computation.
I0808 13:44:10.097057 20451 net.cpp:217] Pooling104 needs backward computation.
I0808 13:44:10.097069 20451 net.cpp:217] Convolution104 needs backward computation.
I0808 13:44:10.097079 20451 net.cpp:217] Pooling103 needs backward computation.
I0808 13:44:10.097090 20451 net.cpp:217] Convolution103 needs backward computation.
I0808 13:44:10.097101 20451 net.cpp:217] dt16 needs backward computation.
I0808 13:44:10.097112 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.097123 20451 net.cpp:217] ReLU68 needs backward computation.
I0808 13:44:10.097133 20451 net.cpp:217] InnerProduct102 needs backward computation.
I0808 13:44:10.097160 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.097172 20451 net.cpp:217] ReLU67 needs backward computation.
I0808 13:44:10.097182 20451 net.cpp:217] InnerProduct101 needs backward computation.
I0808 13:44:10.097194 20451 net.cpp:217] Concat17 needs backward computation.
I0808 13:44:10.097208 20451 net.cpp:217] InnerProduct100 needs backward computation.
I0808 13:44:10.097220 20451 net.cpp:217] ReLU66 needs backward computation.
I0808 13:44:10.097231 20451 net.cpp:217] InnerProduct99 needs backward computation.
I0808 13:44:10.097244 20451 net.cpp:217] Pooling102 needs backward computation.
I0808 13:44:10.097256 20451 net.cpp:217] Convolution102 needs backward computation.
I0808 13:44:10.097268 20451 net.cpp:217] Pooling101 needs backward computation.
I0808 13:44:10.097280 20451 net.cpp:217] Convolution101 needs backward computation.
I0808 13:44:10.097291 20451 net.cpp:217] Pooling100 needs backward computation.
I0808 13:44:10.097304 20451 net.cpp:217] Convolution100 needs backward computation.
I0808 13:44:10.097316 20451 net.cpp:217] InnerProduct98 needs backward computation.
I0808 13:44:10.097328 20451 net.cpp:217] ReLU65 needs backward computation.
I0808 13:44:10.097339 20451 net.cpp:217] InnerProduct97 needs backward computation.
I0808 13:44:10.097353 20451 net.cpp:217] Pooling99 needs backward computation.
I0808 13:44:10.097367 20451 net.cpp:217] Convolution99 needs backward computation.
I0808 13:44:10.097378 20451 net.cpp:217] Pooling98 needs backward computation.
I0808 13:44:10.097391 20451 net.cpp:217] Convolution98 needs backward computation.
I0808 13:44:10.097404 20451 net.cpp:217] Pooling97 needs backward computation.
I0808 13:44:10.097415 20451 net.cpp:217] Convolution97 needs backward computation.
I0808 13:44:10.126759 20451 net.cpp:217] dt15 needs backward computation.
I0808 13:44:10.126791 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.126807 20451 net.cpp:217] ReLU64 needs backward computation.
I0808 13:44:10.126821 20451 net.cpp:217] InnerProduct96 needs backward computation.
I0808 13:44:10.126837 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.126852 20451 net.cpp:217] ReLU63 needs backward computation.
I0808 13:44:10.126865 20451 net.cpp:217] InnerProduct95 needs backward computation.
I0808 13:44:10.126880 20451 net.cpp:217] Concat16 needs backward computation.
I0808 13:44:10.126895 20451 net.cpp:217] InnerProduct94 needs backward computation.
I0808 13:44:10.126910 20451 net.cpp:217] ReLU62 needs backward computation.
I0808 13:44:10.126924 20451 net.cpp:217] InnerProduct93 needs backward computation.
I0808 13:44:10.126938 20451 net.cpp:217] Pooling96 needs backward computation.
I0808 13:44:10.126953 20451 net.cpp:217] Convolution96 needs backward computation.
I0808 13:44:10.126967 20451 net.cpp:217] Pooling95 needs backward computation.
I0808 13:44:10.126982 20451 net.cpp:217] Convolution95 needs backward computation.
I0808 13:44:10.126996 20451 net.cpp:217] Pooling94 needs backward computation.
I0808 13:44:10.127012 20451 net.cpp:217] Convolution94 needs backward computation.
I0808 13:44:10.127025 20451 net.cpp:217] InnerProduct92 needs backward computation.
I0808 13:44:10.127039 20451 net.cpp:217] ReLU61 needs backward computation.
I0808 13:44:10.127053 20451 net.cpp:217] InnerProduct91 needs backward computation.
I0808 13:44:10.127068 20451 net.cpp:217] Pooling93 needs backward computation.
I0808 13:44:10.127082 20451 net.cpp:217] Convolution93 needs backward computation.
I0808 13:44:10.127096 20451 net.cpp:217] Pooling92 needs backward computation.
I0808 13:44:10.127112 20451 net.cpp:217] Convolution92 needs backward computation.
I0808 13:44:10.127130 20451 net.cpp:217] Pooling91 needs backward computation.
I0808 13:44:10.127147 20451 net.cpp:217] Convolution91 needs backward computation.
I0808 13:44:10.127167 20451 net.cpp:217] dt14 needs backward computation.
I0808 13:44:10.127184 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.127202 20451 net.cpp:217] ReLU60 needs backward computation.
I0808 13:44:10.127243 20451 net.cpp:217] InnerProduct90 needs backward computation.
I0808 13:44:10.127254 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.127265 20451 net.cpp:217] ReLU59 needs backward computation.
I0808 13:44:10.127281 20451 net.cpp:217] InnerProduct89 needs backward computation.
I0808 13:44:10.127291 20451 net.cpp:217] Concat15 needs backward computation.
I0808 13:44:10.127301 20451 net.cpp:217] InnerProduct88 needs backward computation.
I0808 13:44:10.127310 20451 net.cpp:217] ReLU58 needs backward computation.
I0808 13:44:10.127318 20451 net.cpp:217] InnerProduct87 needs backward computation.
I0808 13:44:10.127327 20451 net.cpp:217] Pooling90 needs backward computation.
I0808 13:44:10.127336 20451 net.cpp:217] Convolution90 needs backward computation.
I0808 13:44:10.127342 20451 net.cpp:217] Pooling89 needs backward computation.
I0808 13:44:10.127349 20451 net.cpp:217] Convolution89 needs backward computation.
I0808 13:44:10.127356 20451 net.cpp:217] Pooling88 needs backward computation.
I0808 13:44:10.127367 20451 net.cpp:217] Convolution88 needs backward computation.
I0808 13:44:10.127377 20451 net.cpp:217] InnerProduct86 needs backward computation.
I0808 13:44:10.127383 20451 net.cpp:217] ReLU57 needs backward computation.
I0808 13:44:10.127389 20451 net.cpp:217] InnerProduct85 needs backward computation.
I0808 13:44:10.127396 20451 net.cpp:217] Pooling87 needs backward computation.
I0808 13:44:10.127403 20451 net.cpp:217] Convolution87 needs backward computation.
I0808 13:44:10.127410 20451 net.cpp:217] Pooling86 needs backward computation.
I0808 13:44:10.127418 20451 net.cpp:217] Convolution86 needs backward computation.
I0808 13:44:10.127424 20451 net.cpp:217] Pooling85 needs backward computation.
I0808 13:44:10.127431 20451 net.cpp:217] Convolution85 needs backward computation.
I0808 13:44:10.127439 20451 net.cpp:217] dt13 needs backward computation.
I0808 13:44:10.127445 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.127452 20451 net.cpp:217] ReLU56 needs backward computation.
I0808 13:44:10.127460 20451 net.cpp:217] InnerProduct84 needs backward computation.
I0808 13:44:10.127465 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.127472 20451 net.cpp:217] ReLU55 needs backward computation.
I0808 13:44:10.127478 20451 net.cpp:217] InnerProduct83 needs backward computation.
I0808 13:44:10.127485 20451 net.cpp:217] Concat14 needs backward computation.
I0808 13:44:10.127492 20451 net.cpp:217] InnerProduct82 needs backward computation.
I0808 13:44:10.127499 20451 net.cpp:217] ReLU54 needs backward computation.
I0808 13:44:10.127506 20451 net.cpp:217] InnerProduct81 needs backward computation.
I0808 13:44:10.127512 20451 net.cpp:217] Pooling84 needs backward computation.
I0808 13:44:10.127519 20451 net.cpp:217] Convolution84 needs backward computation.
I0808 13:44:10.127526 20451 net.cpp:217] Pooling83 needs backward computation.
I0808 13:44:10.127533 20451 net.cpp:217] Convolution83 needs backward computation.
I0808 13:44:10.127539 20451 net.cpp:217] Pooling82 needs backward computation.
I0808 13:44:10.127547 20451 net.cpp:217] Convolution82 needs backward computation.
I0808 13:44:10.127553 20451 net.cpp:217] InnerProduct80 needs backward computation.
I0808 13:44:10.127560 20451 net.cpp:217] ReLU53 needs backward computation.
I0808 13:44:10.127568 20451 net.cpp:217] InnerProduct79 needs backward computation.
I0808 13:44:10.127573 20451 net.cpp:217] Pooling81 needs backward computation.
I0808 13:44:10.127580 20451 net.cpp:217] Convolution81 needs backward computation.
I0808 13:44:10.127588 20451 net.cpp:217] Pooling80 needs backward computation.
I0808 13:44:10.127593 20451 net.cpp:217] Convolution80 needs backward computation.
I0808 13:44:10.127600 20451 net.cpp:217] Pooling79 needs backward computation.
I0808 13:44:10.127607 20451 net.cpp:217] Convolution79 needs backward computation.
I0808 13:44:10.127617 20451 net.cpp:217] dt12 needs backward computation.
I0808 13:44:10.127624 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.127641 20451 net.cpp:217] ReLU52 needs backward computation.
I0808 13:44:10.127648 20451 net.cpp:217] InnerProduct78 needs backward computation.
I0808 13:44:10.127655 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.127662 20451 net.cpp:217] ReLU51 needs backward computation.
I0808 13:44:10.127668 20451 net.cpp:217] InnerProduct77 needs backward computation.
I0808 13:44:10.127676 20451 net.cpp:217] Concat13 needs backward computation.
I0808 13:44:10.127682 20451 net.cpp:217] InnerProduct76 needs backward computation.
I0808 13:44:10.127689 20451 net.cpp:217] ReLU50 needs backward computation.
I0808 13:44:10.127696 20451 net.cpp:217] InnerProduct75 needs backward computation.
I0808 13:44:10.127702 20451 net.cpp:217] Pooling78 needs backward computation.
I0808 13:44:10.127710 20451 net.cpp:217] Convolution78 needs backward computation.
I0808 13:44:10.127717 20451 net.cpp:217] Pooling77 needs backward computation.
I0808 13:44:10.127723 20451 net.cpp:217] Convolution77 needs backward computation.
I0808 13:44:10.127730 20451 net.cpp:217] Pooling76 needs backward computation.
I0808 13:44:10.127737 20451 net.cpp:217] Convolution76 needs backward computation.
I0808 13:44:10.127744 20451 net.cpp:217] InnerProduct74 needs backward computation.
I0808 13:44:10.127751 20451 net.cpp:217] ReLU49 needs backward computation.
I0808 13:44:10.127758 20451 net.cpp:217] InnerProduct73 needs backward computation.
I0808 13:44:10.127764 20451 net.cpp:217] Pooling75 needs backward computation.
I0808 13:44:10.127770 20451 net.cpp:217] Convolution75 needs backward computation.
I0808 13:44:10.127777 20451 net.cpp:217] Pooling74 needs backward computation.
I0808 13:44:10.127784 20451 net.cpp:217] Convolution74 needs backward computation.
I0808 13:44:10.157878 20451 net.cpp:217] Pooling73 needs backward computation.
I0808 13:44:10.157910 20451 net.cpp:217] Convolution73 needs backward computation.
I0808 13:44:10.157932 20451 net.cpp:217] dt11 needs backward computation.
I0808 13:44:10.157948 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.157963 20451 net.cpp:217] ReLU48 needs backward computation.
I0808 13:44:10.157977 20451 net.cpp:217] InnerProduct72 needs backward computation.
I0808 13:44:10.157991 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.158006 20451 net.cpp:217] ReLU47 needs backward computation.
I0808 13:44:10.158020 20451 net.cpp:217] InnerProduct71 needs backward computation.
I0808 13:44:10.158035 20451 net.cpp:217] Concat12 needs backward computation.
I0808 13:44:10.158051 20451 net.cpp:217] InnerProduct70 needs backward computation.
I0808 13:44:10.158066 20451 net.cpp:217] ReLU46 needs backward computation.
I0808 13:44:10.158078 20451 net.cpp:217] InnerProduct69 needs backward computation.
I0808 13:44:10.158093 20451 net.cpp:217] Pooling72 needs backward computation.
I0808 13:44:10.158107 20451 net.cpp:217] Convolution72 needs backward computation.
I0808 13:44:10.158123 20451 net.cpp:217] Pooling71 needs backward computation.
I0808 13:44:10.158136 20451 net.cpp:217] Convolution71 needs backward computation.
I0808 13:44:10.158150 20451 net.cpp:217] Pooling70 needs backward computation.
I0808 13:44:10.158164 20451 net.cpp:217] Convolution70 needs backward computation.
I0808 13:44:10.158180 20451 net.cpp:217] InnerProduct68 needs backward computation.
I0808 13:44:10.158193 20451 net.cpp:217] ReLU45 needs backward computation.
I0808 13:44:10.158206 20451 net.cpp:217] InnerProduct67 needs backward computation.
I0808 13:44:10.158221 20451 net.cpp:217] Pooling69 needs backward computation.
I0808 13:44:10.158236 20451 net.cpp:217] Convolution69 needs backward computation.
I0808 13:44:10.158249 20451 net.cpp:217] Pooling68 needs backward computation.
I0808 13:44:10.158263 20451 net.cpp:217] Convolution68 needs backward computation.
I0808 13:44:10.158278 20451 net.cpp:217] Pooling67 needs backward computation.
I0808 13:44:10.158293 20451 net.cpp:217] Convolution67 needs backward computation.
I0808 13:44:10.158318 20451 net.cpp:217] dt10 needs backward computation.
I0808 13:44:10.158367 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.158382 20451 net.cpp:217] ReLU44 needs backward computation.
I0808 13:44:10.158396 20451 net.cpp:217] InnerProduct66 needs backward computation.
I0808 13:44:10.158411 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.158424 20451 net.cpp:217] ReLU43 needs backward computation.
I0808 13:44:10.158437 20451 net.cpp:217] InnerProduct65 needs backward computation.
I0808 13:44:10.158452 20451 net.cpp:217] Concat11 needs backward computation.
I0808 13:44:10.158468 20451 net.cpp:217] InnerProduct64 needs backward computation.
I0808 13:44:10.158481 20451 net.cpp:217] ReLU42 needs backward computation.
I0808 13:44:10.158494 20451 net.cpp:217] InnerProduct63 needs backward computation.
I0808 13:44:10.158509 20451 net.cpp:217] Pooling66 needs backward computation.
I0808 13:44:10.158524 20451 net.cpp:217] Convolution66 needs backward computation.
I0808 13:44:10.158538 20451 net.cpp:217] Pooling65 needs backward computation.
I0808 13:44:10.158552 20451 net.cpp:217] Convolution65 needs backward computation.
I0808 13:44:10.158566 20451 net.cpp:217] Pooling64 needs backward computation.
I0808 13:44:10.158581 20451 net.cpp:217] Convolution64 needs backward computation.
I0808 13:44:10.158596 20451 net.cpp:217] InnerProduct62 needs backward computation.
I0808 13:44:10.158610 20451 net.cpp:217] ReLU41 needs backward computation.
I0808 13:44:10.158623 20451 net.cpp:217] InnerProduct61 needs backward computation.
I0808 13:44:10.158638 20451 net.cpp:217] Pooling63 needs backward computation.
I0808 13:44:10.158653 20451 net.cpp:217] Convolution63 needs backward computation.
I0808 13:44:10.158666 20451 net.cpp:217] Pooling62 needs backward computation.
I0808 13:44:10.158681 20451 net.cpp:217] Convolution62 needs backward computation.
I0808 13:44:10.158710 20451 net.cpp:217] Pooling61 needs backward computation.
I0808 13:44:10.158730 20451 net.cpp:217] Convolution61 needs backward computation.
I0808 13:44:10.158751 20451 net.cpp:217] dt9 needs backward computation.
I0808 13:44:10.158767 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.158784 20451 net.cpp:217] ReLU40 needs backward computation.
I0808 13:44:10.158800 20451 net.cpp:217] InnerProduct60 needs backward computation.
I0808 13:44:10.158815 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.158833 20451 net.cpp:217] ReLU39 needs backward computation.
I0808 13:44:10.158849 20451 net.cpp:217] InnerProduct59 needs backward computation.
I0808 13:44:10.158866 20451 net.cpp:217] Concat10 needs backward computation.
I0808 13:44:10.158885 20451 net.cpp:217] InnerProduct58 needs backward computation.
I0808 13:44:10.158901 20451 net.cpp:217] ReLU38 needs backward computation.
I0808 13:44:10.158917 20451 net.cpp:217] InnerProduct57 needs backward computation.
I0808 13:44:10.158942 20451 net.cpp:217] Pooling60 needs backward computation.
I0808 13:44:10.158958 20451 net.cpp:217] Convolution60 needs backward computation.
I0808 13:44:10.158975 20451 net.cpp:217] Pooling59 needs backward computation.
I0808 13:44:10.158993 20451 net.cpp:217] Convolution59 needs backward computation.
I0808 13:44:10.159013 20451 net.cpp:217] Pooling58 needs backward computation.
I0808 13:44:10.159029 20451 net.cpp:217] Convolution58 needs backward computation.
I0808 13:44:10.159046 20451 net.cpp:217] InnerProduct56 needs backward computation.
I0808 13:44:10.159061 20451 net.cpp:217] ReLU37 needs backward computation.
I0808 13:44:10.159076 20451 net.cpp:217] InnerProduct55 needs backward computation.
I0808 13:44:10.159092 20451 net.cpp:217] Pooling57 needs backward computation.
I0808 13:44:10.159108 20451 net.cpp:217] Convolution57 needs backward computation.
I0808 13:44:10.159123 20451 net.cpp:217] Pooling56 needs backward computation.
I0808 13:44:10.159139 20451 net.cpp:217] Convolution56 needs backward computation.
I0808 13:44:10.159155 20451 net.cpp:217] Pooling55 needs backward computation.
I0808 13:44:10.159173 20451 net.cpp:217] Convolution55 needs backward computation.
I0808 13:44:10.159216 20451 net.cpp:217] dt8 needs backward computation.
I0808 13:44:10.159235 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.159251 20451 net.cpp:217] ReLU36 needs backward computation.
I0808 13:44:10.159267 20451 net.cpp:217] InnerProduct54 needs backward computation.
I0808 13:44:10.159307 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.159325 20451 net.cpp:217] ReLU35 needs backward computation.
I0808 13:44:10.159342 20451 net.cpp:217] InnerProduct53 needs backward computation.
I0808 13:44:10.159359 20451 net.cpp:217] Concat9 needs backward computation.
I0808 13:44:10.159379 20451 net.cpp:217] InnerProduct52 needs backward computation.
I0808 13:44:10.159396 20451 net.cpp:217] ReLU34 needs backward computation.
I0808 13:44:10.159413 20451 net.cpp:217] InnerProduct51 needs backward computation.
I0808 13:44:10.159433 20451 net.cpp:217] Pooling54 needs backward computation.
I0808 13:44:10.159447 20451 net.cpp:217] Convolution54 needs backward computation.
I0808 13:44:10.159456 20451 net.cpp:217] Pooling53 needs backward computation.
I0808 13:44:10.159467 20451 net.cpp:217] Convolution53 needs backward computation.
I0808 13:44:10.159476 20451 net.cpp:217] Pooling52 needs backward computation.
I0808 13:44:10.159487 20451 net.cpp:217] Convolution52 needs backward computation.
I0808 13:44:10.159497 20451 net.cpp:217] InnerProduct50 needs backward computation.
I0808 13:44:10.159507 20451 net.cpp:217] ReLU33 needs backward computation.
I0808 13:44:10.159518 20451 net.cpp:217] InnerProduct49 needs backward computation.
I0808 13:44:10.159528 20451 net.cpp:217] Pooling51 needs backward computation.
I0808 13:44:10.159538 20451 net.cpp:217] Convolution51 needs backward computation.
I0808 13:44:10.159549 20451 net.cpp:217] Pooling50 needs backward computation.
I0808 13:44:10.159559 20451 net.cpp:217] Convolution50 needs backward computation.
I0808 13:44:10.159569 20451 net.cpp:217] Pooling49 needs backward computation.
I0808 13:44:10.159579 20451 net.cpp:217] Convolution49 needs backward computation.
I0808 13:44:10.159590 20451 net.cpp:217] dt7 needs backward computation.
I0808 13:44:10.159600 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.159610 20451 net.cpp:217] ReLU32 needs backward computation.
I0808 13:44:10.159618 20451 net.cpp:217] InnerProduct48 needs backward computation.
I0808 13:44:10.159628 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.159639 20451 net.cpp:217] ReLU31 needs backward computation.
I0808 13:44:10.159648 20451 net.cpp:217] InnerProduct47 needs backward computation.
I0808 13:44:10.159658 20451 net.cpp:217] Concat8 needs backward computation.
I0808 13:44:10.159672 20451 net.cpp:217] InnerProduct46 needs backward computation.
I0808 13:44:10.159682 20451 net.cpp:217] ReLU30 needs backward computation.
I0808 13:44:10.159692 20451 net.cpp:217] InnerProduct45 needs backward computation.
I0808 13:44:10.159703 20451 net.cpp:217] Pooling48 needs backward computation.
I0808 13:44:10.159716 20451 net.cpp:217] Convolution48 needs backward computation.
I0808 13:44:10.159728 20451 net.cpp:217] Pooling47 needs backward computation.
I0808 13:44:10.159739 20451 net.cpp:217] Convolution47 needs backward computation.
I0808 13:44:10.159749 20451 net.cpp:217] Pooling46 needs backward computation.
I0808 13:44:10.159756 20451 net.cpp:217] Convolution46 needs backward computation.
I0808 13:44:10.159765 20451 net.cpp:217] InnerProduct44 needs backward computation.
I0808 13:44:10.159773 20451 net.cpp:217] ReLU29 needs backward computation.
I0808 13:44:10.159780 20451 net.cpp:217] InnerProduct43 needs backward computation.
I0808 13:44:10.159790 20451 net.cpp:217] Pooling45 needs backward computation.
I0808 13:44:10.159798 20451 net.cpp:217] Convolution45 needs backward computation.
I0808 13:44:10.159806 20451 net.cpp:217] Pooling44 needs backward computation.
I0808 13:44:10.159816 20451 net.cpp:217] Convolution44 needs backward computation.
I0808 13:44:10.159824 20451 net.cpp:217] Pooling43 needs backward computation.
I0808 13:44:10.159847 20451 net.cpp:217] Convolution43 needs backward computation.
I0808 13:44:10.159857 20451 net.cpp:217] dt6 needs backward computation.
I0808 13:44:10.159867 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.159874 20451 net.cpp:217] ReLU28 needs backward computation.
I0808 13:44:10.159883 20451 net.cpp:217] InnerProduct42 needs backward computation.
I0808 13:44:10.159890 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.159899 20451 net.cpp:217] ReLU27 needs backward computation.
I0808 13:44:10.159907 20451 net.cpp:217] InnerProduct41 needs backward computation.
I0808 13:44:10.159915 20451 net.cpp:217] Concat7 needs backward computation.
I0808 13:44:10.159925 20451 net.cpp:217] InnerProduct40 needs backward computation.
I0808 13:44:10.159934 20451 net.cpp:217] ReLU26 needs backward computation.
I0808 13:44:10.159942 20451 net.cpp:217] InnerProduct39 needs backward computation.
I0808 13:44:10.159950 20451 net.cpp:217] Pooling42 needs backward computation.
I0808 13:44:10.159960 20451 net.cpp:217] Convolution42 needs backward computation.
I0808 13:44:10.159967 20451 net.cpp:217] Pooling41 needs backward computation.
I0808 13:44:10.159976 20451 net.cpp:217] Convolution41 needs backward computation.
I0808 13:44:10.159986 20451 net.cpp:217] Pooling40 needs backward computation.
I0808 13:44:10.159994 20451 net.cpp:217] Convolution40 needs backward computation.
I0808 13:44:10.160003 20451 net.cpp:217] InnerProduct38 needs backward computation.
I0808 13:44:10.160013 20451 net.cpp:217] ReLU25 needs backward computation.
I0808 13:44:10.160023 20451 net.cpp:217] InnerProduct37 needs backward computation.
I0808 13:44:10.160032 20451 net.cpp:217] Pooling39 needs backward computation.
I0808 13:44:10.160044 20451 net.cpp:217] Convolution39 needs backward computation.
I0808 13:44:10.160058 20451 net.cpp:217] Pooling38 needs backward computation.
I0808 13:44:10.160068 20451 net.cpp:217] Convolution38 needs backward computation.
I0808 13:44:10.160079 20451 net.cpp:217] Pooling37 needs backward computation.
I0808 13:44:10.160089 20451 net.cpp:217] Convolution37 needs backward computation.
I0808 13:44:10.160099 20451 net.cpp:217] dt5 needs backward computation.
I0808 13:44:10.160120 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.160130 20451 net.cpp:217] ReLU24 needs backward computation.
I0808 13:44:10.160137 20451 net.cpp:217] InnerProduct36 needs backward computation.
I0808 13:44:10.160145 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.160152 20451 net.cpp:217] ReLU23 needs backward computation.
I0808 13:44:10.160159 20451 net.cpp:217] InnerProduct35 needs backward computation.
I0808 13:44:10.160167 20451 net.cpp:217] Concat6 needs backward computation.
I0808 13:44:10.160178 20451 net.cpp:217] InnerProduct34 needs backward computation.
I0808 13:44:10.160187 20451 net.cpp:217] ReLU22 needs backward computation.
I0808 13:44:10.160192 20451 net.cpp:217] InnerProduct33 needs backward computation.
I0808 13:44:10.160200 20451 net.cpp:217] Pooling36 needs backward computation.
I0808 13:44:10.160208 20451 net.cpp:217] Convolution36 needs backward computation.
I0808 13:44:10.160215 20451 net.cpp:217] Pooling35 needs backward computation.
I0808 13:44:10.160223 20451 net.cpp:217] Convolution35 needs backward computation.
I0808 13:44:10.160230 20451 net.cpp:217] Pooling34 needs backward computation.
I0808 13:44:10.160238 20451 net.cpp:217] Convolution34 needs backward computation.
I0808 13:44:10.160246 20451 net.cpp:217] InnerProduct32 needs backward computation.
I0808 13:44:10.160254 20451 net.cpp:217] ReLU21 needs backward computation.
I0808 13:44:10.160261 20451 net.cpp:217] InnerProduct31 needs backward computation.
I0808 13:44:10.160270 20451 net.cpp:217] Pooling33 needs backward computation.
I0808 13:44:10.160281 20451 net.cpp:217] Convolution33 needs backward computation.
I0808 13:44:10.160290 20451 net.cpp:217] Pooling32 needs backward computation.
I0808 13:44:10.160300 20451 net.cpp:217] Convolution32 needs backward computation.
I0808 13:44:10.160320 20451 net.cpp:217] Pooling31 needs backward computation.
I0808 13:44:10.160329 20451 net.cpp:217] Convolution31 needs backward computation.
I0808 13:44:10.160341 20451 net.cpp:217] dt4 needs backward computation.
I0808 13:44:10.160351 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.160361 20451 net.cpp:217] ReLU20 needs backward computation.
I0808 13:44:10.160369 20451 net.cpp:217] InnerProduct30 needs backward computation.
I0808 13:44:10.160379 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.160389 20451 net.cpp:217] ReLU19 needs backward computation.
I0808 13:44:10.160399 20451 net.cpp:217] InnerProduct29 needs backward computation.
I0808 13:44:10.160410 20451 net.cpp:217] Concat5 needs backward computation.
I0808 13:44:10.160424 20451 net.cpp:217] InnerProduct28 needs backward computation.
I0808 13:44:10.160436 20451 net.cpp:217] ReLU18 needs backward computation.
I0808 13:44:10.160447 20451 net.cpp:217] InnerProduct27 needs backward computation.
I0808 13:44:10.160459 20451 net.cpp:217] Pooling30 needs backward computation.
I0808 13:44:10.160470 20451 net.cpp:217] Convolution30 needs backward computation.
I0808 13:44:10.160480 20451 net.cpp:217] Pooling29 needs backward computation.
I0808 13:44:10.160490 20451 net.cpp:217] Convolution29 needs backward computation.
I0808 13:44:10.160498 20451 net.cpp:217] Pooling28 needs backward computation.
I0808 13:44:10.160508 20451 net.cpp:217] Convolution28 needs backward computation.
I0808 13:44:10.160518 20451 net.cpp:217] InnerProduct26 needs backward computation.
I0808 13:44:10.160528 20451 net.cpp:217] ReLU17 needs backward computation.
I0808 13:44:10.160537 20451 net.cpp:217] InnerProduct25 needs backward computation.
I0808 13:44:10.186455 20451 net.cpp:217] Pooling27 needs backward computation.
I0808 13:44:10.186481 20451 net.cpp:217] Convolution27 needs backward computation.
I0808 13:44:10.186506 20451 net.cpp:217] Pooling26 needs backward computation.
I0808 13:44:10.186523 20451 net.cpp:217] Convolution26 needs backward computation.
I0808 13:44:10.186538 20451 net.cpp:217] Pooling25 needs backward computation.
I0808 13:44:10.186553 20451 net.cpp:217] Convolution25 needs backward computation.
I0808 13:44:10.186573 20451 net.cpp:217] dt3 needs backward computation.
I0808 13:44:10.186588 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.186602 20451 net.cpp:217] ReLU16 needs backward computation.
I0808 13:44:10.186616 20451 net.cpp:217] InnerProduct24 needs backward computation.
I0808 13:44:10.186631 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.186648 20451 net.cpp:217] ReLU15 needs backward computation.
I0808 13:44:10.186666 20451 net.cpp:217] InnerProduct23 needs backward computation.
I0808 13:44:10.186684 20451 net.cpp:217] Concat4 needs backward computation.
I0808 13:44:10.186705 20451 net.cpp:217] InnerProduct22 needs backward computation.
I0808 13:44:10.186722 20451 net.cpp:217] ReLU14 needs backward computation.
I0808 13:44:10.186739 20451 net.cpp:217] InnerProduct21 needs backward computation.
I0808 13:44:10.186758 20451 net.cpp:217] Pooling24 needs backward computation.
I0808 13:44:10.186777 20451 net.cpp:217] Convolution24 needs backward computation.
I0808 13:44:10.186787 20451 net.cpp:217] Pooling23 needs backward computation.
I0808 13:44:10.186796 20451 net.cpp:217] Convolution23 needs backward computation.
I0808 13:44:10.186805 20451 net.cpp:217] Pooling22 needs backward computation.
I0808 13:44:10.186813 20451 net.cpp:217] Convolution22 needs backward computation.
I0808 13:44:10.186825 20451 net.cpp:217] InnerProduct20 needs backward computation.
I0808 13:44:10.186836 20451 net.cpp:217] ReLU13 needs backward computation.
I0808 13:44:10.186844 20451 net.cpp:217] InnerProduct19 needs backward computation.
I0808 13:44:10.186853 20451 net.cpp:217] Pooling21 needs backward computation.
I0808 13:44:10.186863 20451 net.cpp:217] Convolution21 needs backward computation.
I0808 13:44:10.186872 20451 net.cpp:217] Pooling20 needs backward computation.
I0808 13:44:10.186882 20451 net.cpp:217] Convolution20 needs backward computation.
I0808 13:44:10.186908 20451 net.cpp:217] Pooling19 needs backward computation.
I0808 13:44:10.186918 20451 net.cpp:217] Convolution19 needs backward computation.
I0808 13:44:10.186928 20451 net.cpp:217] dt2 needs backward computation.
I0808 13:44:10.186939 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.186949 20451 net.cpp:217] ReLU12 needs backward computation.
I0808 13:44:10.186955 20451 net.cpp:217] InnerProduct18 needs backward computation.
I0808 13:44:10.186964 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.186970 20451 net.cpp:217] ReLU11 needs backward computation.
I0808 13:44:10.186977 20451 net.cpp:217] InnerProduct17 needs backward computation.
I0808 13:44:10.186985 20451 net.cpp:217] Concat3 needs backward computation.
I0808 13:44:10.186993 20451 net.cpp:217] InnerProduct16 needs backward computation.
I0808 13:44:10.187001 20451 net.cpp:217] ReLU10 needs backward computation.
I0808 13:44:10.187008 20451 net.cpp:217] InnerProduct15 needs backward computation.
I0808 13:44:10.187018 20451 net.cpp:217] Pooling18 needs backward computation.
I0808 13:44:10.187029 20451 net.cpp:217] Convolution18 needs backward computation.
I0808 13:44:10.187038 20451 net.cpp:217] Pooling17 needs backward computation.
I0808 13:44:10.187048 20451 net.cpp:217] Convolution17 needs backward computation.
I0808 13:44:10.187057 20451 net.cpp:217] Pooling16 needs backward computation.
I0808 13:44:10.187065 20451 net.cpp:217] Convolution16 needs backward computation.
I0808 13:44:10.187075 20451 net.cpp:217] InnerProduct14 needs backward computation.
I0808 13:44:10.187083 20451 net.cpp:217] ReLU9 needs backward computation.
I0808 13:44:10.187093 20451 net.cpp:217] InnerProduct13 needs backward computation.
I0808 13:44:10.187101 20451 net.cpp:217] Pooling15 needs backward computation.
I0808 13:44:10.187109 20451 net.cpp:217] Convolution15 needs backward computation.
I0808 13:44:10.187117 20451 net.cpp:217] Pooling14 needs backward computation.
I0808 13:44:10.187126 20451 net.cpp:217] Convolution14 needs backward computation.
I0808 13:44:10.187135 20451 net.cpp:217] Pooling13 needs backward computation.
I0808 13:44:10.187145 20451 net.cpp:217] Convolution13 needs backward computation.
I0808 13:44:10.187155 20451 net.cpp:217] dt1 needs backward computation.
I0808 13:44:10.187165 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.187175 20451 net.cpp:217] ReLU8 needs backward computation.
I0808 13:44:10.187185 20451 net.cpp:217] InnerProduct12 needs backward computation.
I0808 13:44:10.187193 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.187202 20451 net.cpp:217] ReLU7 needs backward computation.
I0808 13:44:10.187211 20451 net.cpp:217] InnerProduct11 needs backward computation.
I0808 13:44:10.187222 20451 net.cpp:217] Concat2 needs backward computation.
I0808 13:44:10.187232 20451 net.cpp:217] InnerProduct10 needs backward computation.
I0808 13:44:10.187242 20451 net.cpp:217] ReLU6 needs backward computation.
I0808 13:44:10.187252 20451 net.cpp:217] InnerProduct9 needs backward computation.
I0808 13:44:10.187261 20451 net.cpp:217] Pooling12 needs backward computation.
I0808 13:44:10.187290 20451 net.cpp:217] Convolution12 needs backward computation.
I0808 13:44:10.187302 20451 net.cpp:217] Pooling11 needs backward computation.
I0808 13:44:10.187314 20451 net.cpp:217] Convolution11 needs backward computation.
I0808 13:44:10.187324 20451 net.cpp:217] Pooling10 needs backward computation.
I0808 13:44:10.187335 20451 net.cpp:217] Convolution10 needs backward computation.
I0808 13:44:10.187346 20451 net.cpp:217] InnerProduct8 needs backward computation.
I0808 13:44:10.187355 20451 net.cpp:217] ReLU5 needs backward computation.
I0808 13:44:10.187366 20451 net.cpp:217] InnerProduct7 needs backward computation.
I0808 13:44:10.187376 20451 net.cpp:217] Pooling9 needs backward computation.
I0808 13:44:10.187386 20451 net.cpp:217] Convolution9 needs backward computation.
I0808 13:44:10.187396 20451 net.cpp:217] Pooling8 needs backward computation.
I0808 13:44:10.187422 20451 net.cpp:217] Convolution8 needs backward computation.
I0808 13:44:10.187433 20451 net.cpp:217] Pooling7 needs backward computation.
I0808 13:44:10.187443 20451 net.cpp:217] Convolution7 needs backward computation.
I0808 13:44:10.187453 20451 net.cpp:217] dt0 needs backward computation.
I0808 13:44:10.187464 20451 net.cpp:217] drop2 needs backward computation.
I0808 13:44:10.187476 20451 net.cpp:217] ReLU4 needs backward computation.
I0808 13:44:10.187485 20451 net.cpp:217] InnerProduct6 needs backward computation.
I0808 13:44:10.187496 20451 net.cpp:217] drop1 needs backward computation.
I0808 13:44:10.187506 20451 net.cpp:217] ReLU3 needs backward computation.
I0808 13:44:10.187516 20451 net.cpp:217] InnerProduct5 needs backward computation.
I0808 13:44:10.187526 20451 net.cpp:217] Concat1 needs backward computation.
I0808 13:44:10.187543 20451 net.cpp:217] InnerProduct4 needs backward computation.
I0808 13:44:10.187554 20451 net.cpp:217] ReLU2 needs backward computation.
I0808 13:44:10.187564 20451 net.cpp:217] InnerProduct3 needs backward computation.
I0808 13:44:10.187575 20451 net.cpp:217] Pooling6 needs backward computation.
I0808 13:44:10.187585 20451 net.cpp:217] Convolution6 needs backward computation.
I0808 13:44:10.187595 20451 net.cpp:217] Pooling5 needs backward computation.
I0808 13:44:10.187605 20451 net.cpp:217] Convolution5 needs backward computation.
I0808 13:44:10.187616 20451 net.cpp:217] Pooling4 needs backward computation.
I0808 13:44:10.187626 20451 net.cpp:217] Convolution4 needs backward computation.
I0808 13:44:10.187638 20451 net.cpp:217] InnerProduct2 needs backward computation.
I0808 13:44:10.219194 20451 net.cpp:217] ReLU1 needs backward computation.
I0808 13:44:10.219229 20451 net.cpp:217] InnerProduct1 needs backward computation.
I0808 13:44:10.219251 20451 net.cpp:217] Pooling3 needs backward computation.
I0808 13:44:10.219308 20451 net.cpp:217] Convolution3 needs backward computation.
I0808 13:44:10.219331 20451 net.cpp:217] Pooling2 needs backward computation.
I0808 13:44:10.219349 20451 net.cpp:217] Convolution2 needs backward computation.
I0808 13:44:10.219368 20451 net.cpp:217] Pooling1 needs backward computation.
I0808 13:44:10.219388 20451 net.cpp:217] Convolution1 needs backward computation.
I0808 13:44:10.219409 20451 net.cpp:219] c29 does not need backward computation.
I0808 13:44:10.219430 20451 net.cpp:219] Input18 does not need backward computation.
I0808 13:44:10.219446 20451 net.cpp:219] c28 does not need backward computation.
I0808 13:44:10.219465 20451 net.cpp:219] Input17 does not need backward computation.
I0808 13:44:10.219473 20451 net.cpp:219] c27 does not need backward computation.
I0808 13:44:10.219482 20451 net.cpp:219] Input16 does not need backward computation.
I0808 13:44:10.219491 20451 net.cpp:219] c26 does not need backward computation.
I0808 13:44:10.219501 20451 net.cpp:219] Input15 does not need backward computation.
I0808 13:44:10.219507 20451 net.cpp:219] c25 does not need backward computation.
I0808 13:44:10.219517 20451 net.cpp:219] Input14 does not need backward computation.
I0808 13:44:10.219524 20451 net.cpp:219] c24 does not need backward computation.
I0808 13:44:10.219534 20451 net.cpp:219] Input13 does not need backward computation.
I0808 13:44:10.219542 20451 net.cpp:219] c23 does not need backward computation.
I0808 13:44:10.219550 20451 net.cpp:219] Input12 does not need backward computation.
I0808 13:44:10.219558 20451 net.cpp:219] c22 does not need backward computation.
I0808 13:44:10.219568 20451 net.cpp:219] Input11 does not need backward computation.
I0808 13:44:10.219574 20451 net.cpp:219] c21 does not need backward computation.
I0808 13:44:10.219584 20451 net.cpp:219] Input10 does not need backward computation.
I0808 13:44:10.219591 20451 net.cpp:219] c19 does not need backward computation.
I0808 13:44:10.219601 20451 net.cpp:219] Input9 does not need backward computation.
I0808 13:44:10.219609 20451 net.cpp:219] c18 does not need backward computation.
I0808 13:44:10.219619 20451 net.cpp:219] Input8 does not need backward computation.
I0808 13:44:10.219647 20451 net.cpp:219] c17 does not need backward computation.
I0808 13:44:10.219657 20451 net.cpp:219] Input7 does not need backward computation.
I0808 13:44:10.219665 20451 net.cpp:219] c16 does not need backward computation.
I0808 13:44:10.219674 20451 net.cpp:219] Input6 does not need backward computation.
I0808 13:44:10.219681 20451 net.cpp:219] c15 does not need backward computation.
I0808 13:44:10.219691 20451 net.cpp:219] Input5 does not need backward computation.
I0808 13:44:10.219698 20451 net.cpp:219] c14 does not need backward computation.
I0808 13:44:10.219708 20451 net.cpp:219] Input4 does not need backward computation.
I0808 13:44:10.219718 20451 net.cpp:219] c13 does not need backward computation.
I0808 13:44:10.219728 20451 net.cpp:219] Input3 does not need backward computation.
I0808 13:44:10.219735 20451 net.cpp:219] c12 does not need backward computation.
I0808 13:44:10.219751 20451 net.cpp:219] Input2 does not need backward computation.
I0808 13:44:10.219758 20451 net.cpp:219] c11 does not need backward computation.
I0808 13:44:10.219769 20451 net.cpp:219] Input1 does not need backward computation.
I0808 13:44:10.219779 20451 net.cpp:219] p2_p2_0_split does not need backward computation.
I0808 13:44:10.219789 20451 net.cpp:219] p2 does not need backward computation.
I0808 13:44:10.219800 20451 net.cpp:219] p1_p1_0_split does not need backward computation.
I0808 13:44:10.219808 20451 net.cpp:219] p1 does not need backward computation.
I0808 13:44:10.219820 20451 net.cpp:219] i2_i1_1_split does not need backward computation.
I0808 13:44:10.219832 20451 net.cpp:219] i1_i1_0_split does not need backward computation.
I0808 13:44:10.219841 20451 net.cpp:219] i1 does not need backward computation.
I0808 13:44:10.219851 20451 net.cpp:219] th_th_0_split does not need backward computation.
I0808 13:44:10.219858 20451 net.cpp:219] th does not need backward computation.
I0808 13:44:10.219867 20451 net.cpp:219] label_data_1_split does not need backward computation.
I0808 13:44:10.219877 20451 net.cpp:219] data does not need backward computation.
I0808 13:44:10.219883 20451 net.cpp:261] This network produces output accuracy
I0808 13:44:10.219894 20451 net.cpp:261] This network produces output loss
I0808 13:44:10.242143 20451 net.cpp:274] Network initialization done.
I0808 13:44:10.246028 20451 solver.cpp:60] Solver scaffolding done.
I0808 13:44:10.247253 20451 caffe.cpp:219] Starting Optimization
I0808 13:44:10.247262 20451 solver.cpp:279] Solving 
I0808 13:44:10.247267 20451 solver.cpp:280] Learning Rate Policy: inv
I0808 13:44:10.248222 20451 solver.cpp:337] Iteration 0, Testing net (#0)
I0808 13:44:18.921754 20451 solver.cpp:404]     Test net output #0: accuracy = 1
I0808 13:44:18.921800 20451 solver.cpp:404]     Test net output #1: loss = 1.37239 (* 1 = 1.37239 loss)
I0808 13:44:21.184824 20451 solver.cpp:228] Iteration 0, loss = 1.42196
I0808 13:44:21.184875 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 13:44:21.184888 20451 solver.cpp:244]     Train net output #1: loss = 1.42196 (* 1 = 1.42196 loss)
I0808 13:44:21.184906 20451 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0808 13:44:43.781007 20451 solver.cpp:228] Iteration 10, loss = 1.03446
I0808 13:44:43.781253 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 13:44:43.781272 20451 solver.cpp:244]     Train net output #1: loss = 1.03446 (* 1 = 1.03446 loss)
I0808 13:44:43.781286 20451 sgd_solver.cpp:106] Iteration 10, lr = 0.000999251
I0808 13:45:06.239174 20451 solver.cpp:228] Iteration 20, loss = 0.863092
I0808 13:45:06.239243 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 13:45:06.239262 20451 solver.cpp:244]     Train net output #1: loss = 0.863092 (* 1 = 0.863092 loss)
I0808 13:45:06.239281 20451 sgd_solver.cpp:106] Iteration 20, lr = 0.000998503
I0808 13:45:28.714632 20451 solver.cpp:228] Iteration 30, loss = 0.66156
I0808 13:45:28.714774 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 13:45:28.714793 20451 solver.cpp:244]     Train net output #1: loss = 0.66156 (* 1 = 0.66156 loss)
I0808 13:45:28.714808 20451 sgd_solver.cpp:106] Iteration 30, lr = 0.000997756
I0808 13:45:51.178344 20451 solver.cpp:228] Iteration 40, loss = 0.547917
I0808 13:45:51.178381 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 13:45:51.178396 20451 solver.cpp:244]     Train net output #1: loss = 0.547917 (* 1 = 0.547917 loss)
I0808 13:45:51.178409 20451 sgd_solver.cpp:106] Iteration 40, lr = 0.000997011
I0808 13:46:13.523339 20451 solver.cpp:228] Iteration 50, loss = 0.336587
I0808 13:46:13.523528 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 13:46:13.523545 20451 solver.cpp:244]     Train net output #1: loss = 0.336587 (* 1 = 0.336587 loss)
I0808 13:46:13.523557 20451 sgd_solver.cpp:106] Iteration 50, lr = 0.000996266
I0808 13:46:36.700126 20451 solver.cpp:228] Iteration 60, loss = 0.218335
I0808 13:46:36.700177 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 13:46:36.700191 20451 solver.cpp:244]     Train net output #1: loss = 0.218335 (* 1 = 0.218335 loss)
I0808 13:46:36.700203 20451 sgd_solver.cpp:106] Iteration 60, lr = 0.000995524
I0808 13:46:59.008803 20451 solver.cpp:228] Iteration 70, loss = 0.198988
I0808 13:46:59.008988 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 13:46:59.009004 20451 solver.cpp:244]     Train net output #1: loss = 0.198988 (* 1 = 0.198988 loss)
I0808 13:46:59.009016 20451 sgd_solver.cpp:106] Iteration 70, lr = 0.000994782
I0808 13:47:21.312417 20451 solver.cpp:228] Iteration 80, loss = 0.165804
I0808 13:47:21.312469 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 13:47:21.312482 20451 solver.cpp:244]     Train net output #1: loss = 0.165804 (* 1 = 0.165804 loss)
I0808 13:47:21.312495 20451 sgd_solver.cpp:106] Iteration 80, lr = 0.000994042
I0808 13:47:43.628357 20451 solver.cpp:228] Iteration 90, loss = 0.102337
I0808 13:47:43.628535 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 13:47:43.628551 20451 solver.cpp:244]     Train net output #1: loss = 0.102337 (* 1 = 0.102337 loss)
I0808 13:47:43.628566 20451 sgd_solver.cpp:106] Iteration 90, lr = 0.000993303
I0808 13:48:03.713874 20451 solver.cpp:337] Iteration 100, Testing net (#0)
I0808 13:48:12.236661 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 13:48:12.236713 20451 solver.cpp:404]     Test net output #1: loss = 1.12124 (* 1 = 1.12124 loss)
I0808 13:48:14.442328 20451 solver.cpp:228] Iteration 100, loss = 0.233335
I0808 13:48:14.442430 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 13:48:14.442446 20451 solver.cpp:244]     Train net output #1: loss = 0.233335 (* 1 = 0.233335 loss)
I0808 13:48:14.442461 20451 sgd_solver.cpp:106] Iteration 100, lr = 0.000992565
I0808 13:48:36.728127 20451 solver.cpp:228] Iteration 110, loss = 0.328944
I0808 13:48:36.728174 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 13:48:36.728193 20451 solver.cpp:244]     Train net output #1: loss = 0.328944 (* 1 = 0.328944 loss)
I0808 13:48:36.728212 20451 sgd_solver.cpp:106] Iteration 110, lr = 0.000991829
I0808 13:48:59.030027 20451 solver.cpp:228] Iteration 120, loss = 0.032995
I0808 13:48:59.030215 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 13:48:59.030230 20451 solver.cpp:244]     Train net output #1: loss = 0.032995 (* 1 = 0.032995 loss)
I0808 13:48:59.030243 20451 sgd_solver.cpp:106] Iteration 120, lr = 0.000991094
I0808 13:49:21.328058 20451 solver.cpp:228] Iteration 130, loss = 0.0670864
I0808 13:49:21.328109 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 13:49:21.328125 20451 solver.cpp:244]     Train net output #1: loss = 0.0670864 (* 1 = 0.0670864 loss)
I0808 13:49:21.328136 20451 sgd_solver.cpp:106] Iteration 130, lr = 0.00099036
I0808 13:49:43.630928 20451 solver.cpp:228] Iteration 140, loss = 0.231029
I0808 13:49:43.631146 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 13:49:43.631166 20451 solver.cpp:244]     Train net output #1: loss = 0.231029 (* 1 = 0.231029 loss)
I0808 13:49:43.631183 20451 sgd_solver.cpp:106] Iteration 140, lr = 0.000989627
I0808 13:50:05.941202 20451 solver.cpp:228] Iteration 150, loss = 0.0960168
I0808 13:50:05.941256 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 13:50:05.941269 20451 solver.cpp:244]     Train net output #1: loss = 0.0960168 (* 1 = 0.0960168 loss)
I0808 13:50:05.941282 20451 sgd_solver.cpp:106] Iteration 150, lr = 0.000988896
I0808 13:50:28.234578 20451 solver.cpp:228] Iteration 160, loss = 0.032905
I0808 13:50:28.234764 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 13:50:28.234781 20451 solver.cpp:244]     Train net output #1: loss = 0.032905 (* 1 = 0.032905 loss)
I0808 13:50:28.234792 20451 sgd_solver.cpp:106] Iteration 160, lr = 0.000988166
I0808 13:50:50.540551 20451 solver.cpp:228] Iteration 170, loss = 0.192674
I0808 13:50:50.540604 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 13:50:50.540618 20451 solver.cpp:244]     Train net output #1: loss = 0.192674 (* 1 = 0.192674 loss)
I0808 13:50:50.540630 20451 sgd_solver.cpp:106] Iteration 170, lr = 0.000987437
I0808 13:51:12.850455 20451 solver.cpp:228] Iteration 180, loss = 0.0956833
I0808 13:51:12.850653 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 13:51:12.850668 20451 solver.cpp:244]     Train net output #1: loss = 0.0956833 (* 1 = 0.0956833 loss)
I0808 13:51:12.850682 20451 sgd_solver.cpp:106] Iteration 180, lr = 0.000986709
I0808 13:51:35.161583 20451 solver.cpp:228] Iteration 190, loss = 0.101298
I0808 13:51:35.161638 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 13:51:35.161651 20451 solver.cpp:244]     Train net output #1: loss = 0.101298 (* 1 = 0.101298 loss)
I0808 13:51:35.161664 20451 sgd_solver.cpp:106] Iteration 190, lr = 0.000985983
I0808 13:51:55.247150 20451 solver.cpp:337] Iteration 200, Testing net (#0)
I0808 13:52:03.774161 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0808 13:52:03.774205 20451 solver.cpp:404]     Test net output #1: loss = 1.03224 (* 1 = 1.03224 loss)
I0808 13:52:05.977514 20451 solver.cpp:228] Iteration 200, loss = 0.163156
I0808 13:52:05.977560 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 13:52:05.977578 20451 solver.cpp:244]     Train net output #1: loss = 0.163156 (* 1 = 0.163156 loss)
I0808 13:52:05.977604 20451 sgd_solver.cpp:106] Iteration 200, lr = 0.000985258
I0808 13:52:28.265017 20451 solver.cpp:228] Iteration 210, loss = 0.0986959
I0808 13:52:28.265121 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 13:52:28.265137 20451 solver.cpp:244]     Train net output #1: loss = 0.0986959 (* 1 = 0.0986959 loss)
I0808 13:52:28.265151 20451 sgd_solver.cpp:106] Iteration 210, lr = 0.000984534
I0808 13:52:50.570848 20451 solver.cpp:228] Iteration 220, loss = 0.223159
I0808 13:52:50.570902 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 13:52:50.570916 20451 solver.cpp:244]     Train net output #1: loss = 0.223159 (* 1 = 0.223159 loss)
I0808 13:52:50.570930 20451 sgd_solver.cpp:106] Iteration 220, lr = 0.000983811
I0808 13:53:12.886544 20451 solver.cpp:228] Iteration 230, loss = 0.0991044
I0808 13:53:12.886721 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 13:53:12.886736 20451 solver.cpp:244]     Train net output #1: loss = 0.0991044 (* 1 = 0.0991044 loss)
I0808 13:53:12.886749 20451 sgd_solver.cpp:106] Iteration 230, lr = 0.00098309
I0808 13:53:35.201829 20451 solver.cpp:228] Iteration 240, loss = 0.0680925
I0808 13:53:35.201879 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 13:53:35.201894 20451 solver.cpp:244]     Train net output #1: loss = 0.0680925 (* 1 = 0.0680925 loss)
I0808 13:53:35.201906 20451 sgd_solver.cpp:106] Iteration 240, lr = 0.00098237
I0808 13:53:57.501055 20451 solver.cpp:228] Iteration 250, loss = 0.193744
I0808 13:53:57.501274 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 13:53:57.501289 20451 solver.cpp:244]     Train net output #1: loss = 0.193744 (* 1 = 0.193744 loss)
I0808 13:53:57.501302 20451 sgd_solver.cpp:106] Iteration 250, lr = 0.000981651
I0808 13:54:19.804461 20451 solver.cpp:228] Iteration 260, loss = 0.192591
I0808 13:54:19.804517 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 13:54:19.804536 20451 solver.cpp:244]     Train net output #1: loss = 0.192591 (* 1 = 0.192591 loss)
I0808 13:54:19.804553 20451 sgd_solver.cpp:106] Iteration 260, lr = 0.000980933
I0808 13:54:42.109216 20451 solver.cpp:228] Iteration 270, loss = 0.191119
I0808 13:54:42.109406 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 13:54:42.109422 20451 solver.cpp:244]     Train net output #1: loss = 0.191119 (* 1 = 0.191119 loss)
I0808 13:54:42.109434 20451 sgd_solver.cpp:106] Iteration 270, lr = 0.000980217
I0808 13:55:04.425875 20451 solver.cpp:228] Iteration 280, loss = 0.193516
I0808 13:55:04.425922 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 13:55:04.425951 20451 solver.cpp:244]     Train net output #1: loss = 0.193516 (* 1 = 0.193516 loss)
I0808 13:55:04.425967 20451 sgd_solver.cpp:106] Iteration 280, lr = 0.000979502
I0808 13:55:26.740795 20451 solver.cpp:228] Iteration 290, loss = 0.0967695
I0808 13:55:26.740972 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 13:55:26.740988 20451 solver.cpp:244]     Train net output #1: loss = 0.0967695 (* 1 = 0.0967695 loss)
I0808 13:55:26.741001 20451 sgd_solver.cpp:106] Iteration 290, lr = 0.000978788
I0808 13:55:46.827834 20451 solver.cpp:337] Iteration 300, Testing net (#0)
I0808 13:55:55.353723 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0808 13:55:55.353767 20451 solver.cpp:404]     Test net output #1: loss = 1.0844 (* 1 = 1.0844 loss)
I0808 13:55:57.555424 20451 solver.cpp:228] Iteration 300, loss = 0.160522
I0808 13:55:57.555668 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 13:55:57.555686 20451 solver.cpp:244]     Train net output #1: loss = 0.160522 (* 1 = 0.160522 loss)
I0808 13:55:57.555703 20451 sgd_solver.cpp:106] Iteration 300, lr = 0.000978075
I0808 13:56:19.855605 20451 solver.cpp:228] Iteration 310, loss = 0.159321
I0808 13:56:19.855657 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 13:56:19.855676 20451 solver.cpp:244]     Train net output #1: loss = 0.159321 (* 1 = 0.159321 loss)
I0808 13:56:19.855691 20451 sgd_solver.cpp:106] Iteration 310, lr = 0.000977363
I0808 13:56:42.173059 20451 solver.cpp:228] Iteration 320, loss = 0.125764
I0808 13:56:42.173244 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 13:56:42.173264 20451 solver.cpp:244]     Train net output #1: loss = 0.125764 (* 1 = 0.125764 loss)
I0808 13:56:42.173279 20451 sgd_solver.cpp:106] Iteration 320, lr = 0.000976653
I0808 13:57:04.483721 20451 solver.cpp:228] Iteration 330, loss = 0.12917
I0808 13:57:04.483763 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 13:57:04.483780 20451 solver.cpp:244]     Train net output #1: loss = 0.12917 (* 1 = 0.12917 loss)
I0808 13:57:04.483794 20451 sgd_solver.cpp:106] Iteration 330, lr = 0.000975944
I0808 13:57:26.804818 20451 solver.cpp:228] Iteration 340, loss = 0.159981
I0808 13:57:26.804999 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 13:57:26.805014 20451 solver.cpp:244]     Train net output #1: loss = 0.159981 (* 1 = 0.159981 loss)
I0808 13:57:26.805027 20451 sgd_solver.cpp:106] Iteration 340, lr = 0.000975236
I0808 13:57:49.120417 20451 solver.cpp:228] Iteration 350, loss = 0.129119
I0808 13:57:49.120471 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 13:57:49.120483 20451 solver.cpp:244]     Train net output #1: loss = 0.129119 (* 1 = 0.129119 loss)
I0808 13:57:49.120496 20451 sgd_solver.cpp:106] Iteration 350, lr = 0.000974529
I0808 13:58:11.432265 20451 solver.cpp:228] Iteration 360, loss = 0.0955629
I0808 13:58:11.432482 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 13:58:11.432497 20451 solver.cpp:244]     Train net output #1: loss = 0.0955629 (* 1 = 0.0955629 loss)
I0808 13:58:11.432510 20451 sgd_solver.cpp:106] Iteration 360, lr = 0.000973823
I0808 13:58:33.749891 20451 solver.cpp:228] Iteration 370, loss = 0.25587
I0808 13:58:33.749944 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 13:58:33.749958 20451 solver.cpp:244]     Train net output #1: loss = 0.25587 (* 1 = 0.25587 loss)
I0808 13:58:33.749970 20451 sgd_solver.cpp:106] Iteration 370, lr = 0.000973119
I0808 13:58:56.073578 20451 solver.cpp:228] Iteration 380, loss = 0.127308
I0808 13:58:56.073755 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 13:58:56.073770 20451 solver.cpp:244]     Train net output #1: loss = 0.127308 (* 1 = 0.127308 loss)
I0808 13:58:56.073783 20451 sgd_solver.cpp:106] Iteration 380, lr = 0.000972416
I0808 13:59:18.387873 20451 solver.cpp:228] Iteration 390, loss = 0.127716
I0808 13:59:18.387925 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 13:59:18.387939 20451 solver.cpp:244]     Train net output #1: loss = 0.127716 (* 1 = 0.127716 loss)
I0808 13:59:18.387951 20451 sgd_solver.cpp:106] Iteration 390, lr = 0.000971714
I0808 13:59:38.483608 20451 solver.cpp:337] Iteration 400, Testing net (#0)
I0808 13:59:47.010432 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 13:59:47.010485 20451 solver.cpp:404]     Test net output #1: loss = 1.04075 (* 1 = 1.04075 loss)
I0808 13:59:49.213163 20451 solver.cpp:228] Iteration 400, loss = 0.318531
I0808 13:59:49.213215 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 13:59:49.213229 20451 solver.cpp:244]     Train net output #1: loss = 0.318531 (* 1 = 0.318531 loss)
I0808 13:59:49.213241 20451 sgd_solver.cpp:106] Iteration 400, lr = 0.000971013
I0808 14:00:11.511803 20451 solver.cpp:228] Iteration 410, loss = 0.19018
I0808 14:00:11.511909 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:00:11.511929 20451 solver.cpp:244]     Train net output #1: loss = 0.19018 (* 1 = 0.19018 loss)
I0808 14:00:11.511945 20451 sgd_solver.cpp:106] Iteration 410, lr = 0.000970313
I0808 14:00:33.826019 20451 solver.cpp:228] Iteration 420, loss = 0.0957851
I0808 14:00:33.826061 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:00:33.826088 20451 solver.cpp:244]     Train net output #1: loss = 0.0957851 (* 1 = 0.0957851 loss)
I0808 14:00:33.826103 20451 sgd_solver.cpp:106] Iteration 420, lr = 0.000969615
I0808 14:00:56.144126 20451 solver.cpp:228] Iteration 430, loss = 0.156687
I0808 14:00:56.144228 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:00:56.144248 20451 solver.cpp:244]     Train net output #1: loss = 0.156687 (* 1 = 0.156687 loss)
I0808 14:00:56.144263 20451 sgd_solver.cpp:106] Iteration 430, lr = 0.000968918
I0808 14:01:18.459062 20451 solver.cpp:228] Iteration 440, loss = 0.129525
I0808 14:01:18.459110 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:01:18.459128 20451 solver.cpp:244]     Train net output #1: loss = 0.129525 (* 1 = 0.129525 loss)
I0808 14:01:18.459143 20451 sgd_solver.cpp:106] Iteration 440, lr = 0.000968221
I0808 14:01:40.765167 20451 solver.cpp:228] Iteration 450, loss = 0.255232
I0808 14:01:40.765264 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:01:40.765282 20451 solver.cpp:244]     Train net output #1: loss = 0.255232 (* 1 = 0.255232 loss)
I0808 14:01:40.765298 20451 sgd_solver.cpp:106] Iteration 450, lr = 0.000967526
I0808 14:02:03.086504 20451 solver.cpp:228] Iteration 460, loss = 0.128198
I0808 14:02:03.086549 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:02:03.086568 20451 solver.cpp:244]     Train net output #1: loss = 0.128198 (* 1 = 0.128198 loss)
I0808 14:02:03.086585 20451 sgd_solver.cpp:106] Iteration 460, lr = 0.000966833
I0808 14:02:25.405316 20451 solver.cpp:228] Iteration 470, loss = 0.15843
I0808 14:02:25.405525 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:02:25.405540 20451 solver.cpp:244]     Train net output #1: loss = 0.15843 (* 1 = 0.15843 loss)
I0808 14:02:25.405553 20451 sgd_solver.cpp:106] Iteration 470, lr = 0.00096614
I0808 14:02:47.734433 20451 solver.cpp:228] Iteration 480, loss = 0.221478
I0808 14:02:47.734488 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:02:47.734503 20451 solver.cpp:244]     Train net output #1: loss = 0.221478 (* 1 = 0.221478 loss)
I0808 14:02:47.734514 20451 sgd_solver.cpp:106] Iteration 480, lr = 0.000965448
I0808 14:03:10.048816 20451 solver.cpp:228] Iteration 490, loss = 0.157754
I0808 14:03:10.048918 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:03:10.048931 20451 solver.cpp:244]     Train net output #1: loss = 0.157754 (* 1 = 0.157754 loss)
I0808 14:03:10.048943 20451 sgd_solver.cpp:106] Iteration 490, lr = 0.000964758
I0808 14:03:30.139484 20451 solver.cpp:337] Iteration 500, Testing net (#0)
I0808 14:03:38.663071 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 14:03:38.663112 20451 solver.cpp:404]     Test net output #1: loss = 1.00884 (* 1 = 1.00884 loss)
I0808 14:03:40.867904 20451 solver.cpp:228] Iteration 500, loss = 0.128305
I0808 14:03:40.868075 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:03:40.868090 20451 solver.cpp:244]     Train net output #1: loss = 0.128305 (* 1 = 0.128305 loss)
I0808 14:03:40.868103 20451 sgd_solver.cpp:106] Iteration 500, lr = 0.000964069
I0808 14:04:03.155135 20451 solver.cpp:228] Iteration 510, loss = 0.127752
I0808 14:04:03.155185 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:04:03.155200 20451 solver.cpp:244]     Train net output #1: loss = 0.127752 (* 1 = 0.127752 loss)
I0808 14:04:03.155211 20451 sgd_solver.cpp:106] Iteration 510, lr = 0.000963381
I0808 14:04:25.468796 20451 solver.cpp:228] Iteration 520, loss = 0.252341
I0808 14:04:25.468988 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:04:25.469004 20451 solver.cpp:244]     Train net output #1: loss = 0.252341 (* 1 = 0.252341 loss)
I0808 14:04:25.469017 20451 sgd_solver.cpp:106] Iteration 520, lr = 0.000962694
I0808 14:04:47.790541 20451 solver.cpp:228] Iteration 530, loss = 0.253709
I0808 14:04:47.790596 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:04:47.790609 20451 solver.cpp:244]     Train net output #1: loss = 0.253709 (* 1 = 0.253709 loss)
I0808 14:04:47.790622 20451 sgd_solver.cpp:106] Iteration 530, lr = 0.000962008
I0808 14:05:10.111230 20451 solver.cpp:228] Iteration 540, loss = 0.095826
I0808 14:05:10.111416 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:05:10.111431 20451 solver.cpp:244]     Train net output #1: loss = 0.095826 (* 1 = 0.095826 loss)
I0808 14:05:10.111443 20451 sgd_solver.cpp:106] Iteration 540, lr = 0.000961324
I0808 14:05:32.436447 20451 solver.cpp:228] Iteration 550, loss = 0.0640456
I0808 14:05:32.436501 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 14:05:32.436516 20451 solver.cpp:244]     Train net output #1: loss = 0.0640456 (* 1 = 0.0640456 loss)
I0808 14:05:32.436527 20451 sgd_solver.cpp:106] Iteration 550, lr = 0.00096064
I0808 14:05:54.747733 20451 solver.cpp:228] Iteration 560, loss = 0.189603
I0808 14:05:54.747879 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:05:54.747896 20451 solver.cpp:244]     Train net output #1: loss = 0.189603 (* 1 = 0.189603 loss)
I0808 14:05:54.747912 20451 sgd_solver.cpp:106] Iteration 560, lr = 0.000959958
I0808 14:06:17.058394 20451 solver.cpp:228] Iteration 570, loss = 0.000457689
I0808 14:06:17.058447 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 14:06:17.058461 20451 solver.cpp:244]     Train net output #1: loss = 0.000457689 (* 1 = 0.000457689 loss)
I0808 14:06:17.058473 20451 sgd_solver.cpp:106] Iteration 570, lr = 0.000959276
I0808 14:06:39.372944 20451 solver.cpp:228] Iteration 580, loss = 0.316278
I0808 14:06:39.373082 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 14:06:39.373102 20451 solver.cpp:244]     Train net output #1: loss = 0.316278 (* 1 = 0.316278 loss)
I0808 14:06:39.373118 20451 sgd_solver.cpp:106] Iteration 580, lr = 0.000958596
I0808 14:07:01.680943 20451 solver.cpp:228] Iteration 590, loss = 0.220561
I0808 14:07:01.680990 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:07:01.681008 20451 solver.cpp:244]     Train net output #1: loss = 0.220561 (* 1 = 0.220561 loss)
I0808 14:07:01.681025 20451 sgd_solver.cpp:106] Iteration 590, lr = 0.000957917
I0808 14:07:21.764904 20451 solver.cpp:337] Iteration 600, Testing net (#0)
I0808 14:07:30.299404 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 14:07:30.299448 20451 solver.cpp:404]     Test net output #1: loss = 1.01786 (* 1 = 1.01786 loss)
I0808 14:07:32.500730 20451 solver.cpp:228] Iteration 600, loss = 0.0962583
I0808 14:07:32.500773 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:07:32.500792 20451 solver.cpp:244]     Train net output #1: loss = 0.0962583 (* 1 = 0.0962583 loss)
I0808 14:07:32.500818 20451 sgd_solver.cpp:106] Iteration 600, lr = 0.00095724
I0808 14:07:54.799432 20451 solver.cpp:228] Iteration 610, loss = 0.189895
I0808 14:07:54.799602 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:07:54.799618 20451 solver.cpp:244]     Train net output #1: loss = 0.189895 (* 1 = 0.189895 loss)
I0808 14:07:54.799630 20451 sgd_solver.cpp:106] Iteration 610, lr = 0.000956563
I0808 14:08:17.120940 20451 solver.cpp:228] Iteration 620, loss = 0.220719
I0808 14:08:17.120991 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:08:17.121006 20451 solver.cpp:244]     Train net output #1: loss = 0.220719 (* 1 = 0.220719 loss)
I0808 14:08:17.121018 20451 sgd_solver.cpp:106] Iteration 620, lr = 0.000955887
I0808 14:08:39.434340 20451 solver.cpp:228] Iteration 630, loss = 0.315174
I0808 14:08:39.434588 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 14:08:39.434604 20451 solver.cpp:244]     Train net output #1: loss = 0.315174 (* 1 = 0.315174 loss)
I0808 14:08:39.434617 20451 sgd_solver.cpp:106] Iteration 630, lr = 0.000955213
I0808 14:09:01.747550 20451 solver.cpp:228] Iteration 640, loss = 0.189214
I0808 14:09:01.747597 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:09:01.747612 20451 solver.cpp:244]     Train net output #1: loss = 0.189214 (* 1 = 0.189214 loss)
I0808 14:09:01.747627 20451 sgd_solver.cpp:106] Iteration 640, lr = 0.000954539
I0808 14:09:24.058557 20451 solver.cpp:228] Iteration 650, loss = 0.220631
I0808 14:09:24.058719 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:09:24.058738 20451 solver.cpp:244]     Train net output #1: loss = 0.220631 (* 1 = 0.220631 loss)
I0808 14:09:24.058754 20451 sgd_solver.cpp:106] Iteration 650, lr = 0.000953867
I0808 14:09:46.376510 20451 solver.cpp:228] Iteration 660, loss = 0.0946999
I0808 14:09:46.376564 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:09:46.376577 20451 solver.cpp:244]     Train net output #1: loss = 0.0946999 (* 1 = 0.0946999 loss)
I0808 14:09:46.376590 20451 sgd_solver.cpp:106] Iteration 660, lr = 0.000953196
I0808 14:10:08.702503 20451 solver.cpp:228] Iteration 670, loss = 0.219739
I0808 14:10:08.702682 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:10:08.702697 20451 solver.cpp:244]     Train net output #1: loss = 0.219739 (* 1 = 0.219739 loss)
I0808 14:10:08.702710 20451 sgd_solver.cpp:106] Iteration 670, lr = 0.000952526
I0808 14:10:31.009202 20451 solver.cpp:228] Iteration 680, loss = 0.126073
I0808 14:10:31.009253 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:10:31.009268 20451 solver.cpp:244]     Train net output #1: loss = 0.126073 (* 1 = 0.126073 loss)
I0808 14:10:31.009279 20451 sgd_solver.cpp:106] Iteration 680, lr = 0.000951857
I0808 14:10:53.329246 20451 solver.cpp:228] Iteration 690, loss = 0.157679
I0808 14:10:53.329463 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:10:53.329478 20451 solver.cpp:244]     Train net output #1: loss = 0.157679 (* 1 = 0.157679 loss)
I0808 14:10:53.329491 20451 sgd_solver.cpp:106] Iteration 690, lr = 0.000951189
I0808 14:11:13.421797 20451 solver.cpp:337] Iteration 700, Testing net (#0)
I0808 14:11:21.946416 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 14:11:21.946467 20451 solver.cpp:404]     Test net output #1: loss = 1.01233 (* 1 = 1.01233 loss)
I0808 14:11:24.152503 20451 solver.cpp:228] Iteration 700, loss = 0.189609
I0808 14:11:24.152664 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:11:24.152681 20451 solver.cpp:244]     Train net output #1: loss = 0.189609 (* 1 = 0.189609 loss)
I0808 14:11:24.152693 20451 sgd_solver.cpp:106] Iteration 700, lr = 0.000950522
I0808 14:11:46.451340 20451 solver.cpp:228] Iteration 710, loss = 0.159129
I0808 14:11:46.451395 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:11:46.451409 20451 solver.cpp:244]     Train net output #1: loss = 0.159129 (* 1 = 0.159129 loss)
I0808 14:11:46.451421 20451 sgd_solver.cpp:106] Iteration 710, lr = 0.000949856
I0808 14:12:08.772956 20451 solver.cpp:228] Iteration 720, loss = 0.189658
I0808 14:12:08.773138 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:12:08.773154 20451 solver.cpp:244]     Train net output #1: loss = 0.189658 (* 1 = 0.189658 loss)
I0808 14:12:08.773166 20451 sgd_solver.cpp:106] Iteration 720, lr = 0.000949192
I0808 14:12:31.096124 20451 solver.cpp:228] Iteration 730, loss = 0.125776
I0808 14:12:31.096175 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:12:31.096189 20451 solver.cpp:244]     Train net output #1: loss = 0.125776 (* 1 = 0.125776 loss)
I0808 14:12:31.096200 20451 sgd_solver.cpp:106] Iteration 730, lr = 0.000948528
I0808 14:12:53.418825 20451 solver.cpp:228] Iteration 740, loss = 0.126807
I0808 14:12:53.419010 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:12:53.419026 20451 solver.cpp:244]     Train net output #1: loss = 0.126807 (* 1 = 0.126807 loss)
I0808 14:12:53.419039 20451 sgd_solver.cpp:106] Iteration 740, lr = 0.000947866
I0808 14:13:15.739871 20451 solver.cpp:228] Iteration 750, loss = 0.126023
I0808 14:13:15.739922 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:13:15.739935 20451 solver.cpp:244]     Train net output #1: loss = 0.126023 (* 1 = 0.126023 loss)
I0808 14:13:15.739948 20451 sgd_solver.cpp:106] Iteration 750, lr = 0.000947204
I0808 14:13:38.051468 20451 solver.cpp:228] Iteration 760, loss = 0.220663
I0808 14:13:38.051650 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:13:38.051666 20451 solver.cpp:244]     Train net output #1: loss = 0.220663 (* 1 = 0.220663 loss)
I0808 14:13:38.051678 20451 sgd_solver.cpp:106] Iteration 760, lr = 0.000946544
I0808 14:14:00.366124 20451 solver.cpp:228] Iteration 770, loss = 0.190149
I0808 14:14:00.366163 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:14:00.366178 20451 solver.cpp:244]     Train net output #1: loss = 0.190149 (* 1 = 0.190149 loss)
I0808 14:14:00.366190 20451 sgd_solver.cpp:106] Iteration 770, lr = 0.000945885
I0808 14:14:22.684887 20451 solver.cpp:228] Iteration 780, loss = 0.125425
I0808 14:14:22.685070 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:14:22.685084 20451 solver.cpp:244]     Train net output #1: loss = 0.125425 (* 1 = 0.125425 loss)
I0808 14:14:22.685097 20451 sgd_solver.cpp:106] Iteration 780, lr = 0.000945227
I0808 14:14:45.004001 20451 solver.cpp:228] Iteration 790, loss = 0.189194
I0808 14:14:45.004052 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:14:45.004066 20451 solver.cpp:244]     Train net output #1: loss = 0.189194 (* 1 = 0.189194 loss)
I0808 14:14:45.004078 20451 sgd_solver.cpp:106] Iteration 790, lr = 0.00094457
I0808 14:15:05.104362 20451 solver.cpp:337] Iteration 800, Testing net (#0)
I0808 14:15:13.625716 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 14:15:13.625766 20451 solver.cpp:404]     Test net output #1: loss = 1.01799 (* 1 = 1.01799 loss)
I0808 14:15:15.826711 20451 solver.cpp:228] Iteration 800, loss = 0.157178
I0808 14:15:15.826764 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:15:15.826777 20451 solver.cpp:244]     Train net output #1: loss = 0.157178 (* 1 = 0.157178 loss)
I0808 14:15:15.826789 20451 sgd_solver.cpp:106] Iteration 800, lr = 0.000943913
I0808 14:15:38.112004 20451 solver.cpp:228] Iteration 810, loss = 0.0941093
I0808 14:15:38.112180 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:15:38.112195 20451 solver.cpp:244]     Train net output #1: loss = 0.0941093 (* 1 = 0.0941093 loss)
I0808 14:15:38.112208 20451 sgd_solver.cpp:106] Iteration 810, lr = 0.000943259
I0808 14:16:00.425103 20451 solver.cpp:228] Iteration 820, loss = 0.156923
I0808 14:16:00.425156 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:16:00.425170 20451 solver.cpp:244]     Train net output #1: loss = 0.156923 (* 1 = 0.156923 loss)
I0808 14:16:00.425182 20451 sgd_solver.cpp:106] Iteration 820, lr = 0.000942605
I0808 14:16:22.732292 20451 solver.cpp:228] Iteration 830, loss = 0.28346
I0808 14:16:22.732390 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 14:16:22.732405 20451 solver.cpp:244]     Train net output #1: loss = 0.28346 (* 1 = 0.28346 loss)
I0808 14:16:22.732419 20451 sgd_solver.cpp:106] Iteration 830, lr = 0.000941952
I0808 14:16:45.044420 20451 solver.cpp:228] Iteration 840, loss = 0.157071
I0808 14:16:45.044471 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:16:45.044491 20451 solver.cpp:244]     Train net output #1: loss = 0.157071 (* 1 = 0.157071 loss)
I0808 14:16:45.044507 20451 sgd_solver.cpp:106] Iteration 840, lr = 0.0009413
I0808 14:17:07.370510 20451 solver.cpp:228] Iteration 850, loss = 0.189096
I0808 14:17:07.370693 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:17:07.370708 20451 solver.cpp:244]     Train net output #1: loss = 0.189096 (* 1 = 0.189096 loss)
I0808 14:17:07.370720 20451 sgd_solver.cpp:106] Iteration 850, lr = 0.000940649
I0808 14:17:29.675940 20451 solver.cpp:228] Iteration 860, loss = 0.188317
I0808 14:17:29.675992 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:17:29.676005 20451 solver.cpp:244]     Train net output #1: loss = 0.188317 (* 1 = 0.188317 loss)
I0808 14:17:29.676017 20451 sgd_solver.cpp:106] Iteration 860, lr = 0.00094
I0808 14:17:51.982774 20451 solver.cpp:228] Iteration 870, loss = 0.251365
I0808 14:17:51.982914 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:17:51.982930 20451 solver.cpp:244]     Train net output #1: loss = 0.251365 (* 1 = 0.251365 loss)
I0808 14:17:51.982944 20451 sgd_solver.cpp:106] Iteration 870, lr = 0.000939351
I0808 14:18:14.309072 20451 solver.cpp:228] Iteration 880, loss = 0.251297
I0808 14:18:14.309125 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:18:14.309140 20451 solver.cpp:244]     Train net output #1: loss = 0.251297 (* 1 = 0.251297 loss)
I0808 14:18:14.309152 20451 sgd_solver.cpp:106] Iteration 880, lr = 0.000938703
I0808 14:18:36.613350 20451 solver.cpp:228] Iteration 890, loss = 0.125673
I0808 14:18:36.613528 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 14:18:36.613544 20451 solver.cpp:244]     Train net output #1: loss = 0.125673 (* 1 = 0.125673 loss)
I0808 14:18:36.613557 20451 sgd_solver.cpp:106] Iteration 890, lr = 0.000938057
I0808 14:18:56.694255 20451 solver.cpp:337] Iteration 900, Testing net (#0)
I0808 14:19:05.218245 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 14:19:05.218297 20451 solver.cpp:404]     Test net output #1: loss = 1.01091 (* 1 = 1.01091 loss)
I0808 14:19:07.414834 20451 solver.cpp:228] Iteration 900, loss = 0.125853
I0808 14:19:07.414966 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:19:07.414981 20451 solver.cpp:244]     Train net output #1: loss = 0.125853 (* 1 = 0.125853 loss)
I0808 14:19:07.414994 20451 sgd_solver.cpp:106] Iteration 900, lr = 0.000937411
I0808 14:19:29.698745 20451 solver.cpp:228] Iteration 910, loss = 0.188305
I0808 14:19:29.698791 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:19:29.698808 20451 solver.cpp:244]     Train net output #1: loss = 0.188305 (* 1 = 0.188305 loss)
I0808 14:19:29.698824 20451 sgd_solver.cpp:106] Iteration 910, lr = 0.000936767
I0808 14:19:51.999850 20451 solver.cpp:228] Iteration 920, loss = 0.12606
I0808 14:19:51.999977 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:19:51.999994 20451 solver.cpp:244]     Train net output #1: loss = 0.12606 (* 1 = 0.12606 loss)
I0808 14:19:52.000006 20451 sgd_solver.cpp:106] Iteration 920, lr = 0.000936123
I0808 14:20:14.313395 20451 solver.cpp:228] Iteration 930, loss = 0.18809
I0808 14:20:14.313448 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:20:14.313462 20451 solver.cpp:244]     Train net output #1: loss = 0.18809 (* 1 = 0.18809 loss)
I0808 14:20:14.313474 20451 sgd_solver.cpp:106] Iteration 930, lr = 0.000935481
I0808 14:20:36.621358 20451 solver.cpp:228] Iteration 940, loss = 0.219897
I0808 14:20:36.621534 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:20:36.621549 20451 solver.cpp:244]     Train net output #1: loss = 0.219897 (* 1 = 0.219897 loss)
I0808 14:20:36.621563 20451 sgd_solver.cpp:106] Iteration 940, lr = 0.000934839
I0808 14:20:58.934725 20451 solver.cpp:228] Iteration 950, loss = 0.18828
I0808 14:20:58.934777 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:20:58.934792 20451 solver.cpp:244]     Train net output #1: loss = 0.18828 (* 1 = 0.18828 loss)
I0808 14:20:58.934803 20451 sgd_solver.cpp:106] Iteration 950, lr = 0.000934199
I0808 14:21:21.252988 20451 solver.cpp:228] Iteration 960, loss = 0.12564
I0808 14:21:21.253165 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:21:21.253181 20451 solver.cpp:244]     Train net output #1: loss = 0.12564 (* 1 = 0.12564 loss)
I0808 14:21:21.253193 20451 sgd_solver.cpp:106] Iteration 960, lr = 0.00093356
I0808 14:21:43.564962 20451 solver.cpp:228] Iteration 970, loss = 0.282565
I0808 14:21:43.565006 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 14:21:43.565021 20451 solver.cpp:244]     Train net output #1: loss = 0.282565 (* 1 = 0.282565 loss)
I0808 14:21:43.565034 20451 sgd_solver.cpp:106] Iteration 970, lr = 0.000932921
I0808 14:22:05.877310 20451 solver.cpp:228] Iteration 980, loss = 0.0945415
I0808 14:22:05.877418 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:22:05.877437 20451 solver.cpp:244]     Train net output #1: loss = 0.0945415 (* 1 = 0.0945415 loss)
I0808 14:22:05.877454 20451 sgd_solver.cpp:106] Iteration 980, lr = 0.000932284
I0808 14:22:28.190330 20451 solver.cpp:228] Iteration 990, loss = 0.219478
I0808 14:22:28.190373 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:22:28.190390 20451 solver.cpp:244]     Train net output #1: loss = 0.219478 (* 1 = 0.219478 loss)
I0808 14:22:28.190405 20451 sgd_solver.cpp:106] Iteration 990, lr = 0.000931648
I0808 14:22:48.281280 20451 solver.cpp:337] Iteration 1000, Testing net (#0)
I0808 14:22:56.799501 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0808 14:22:56.799545 20451 solver.cpp:404]     Test net output #1: loss = 0.966996 (* 1 = 0.966996 loss)
I0808 14:22:59.002915 20451 solver.cpp:228] Iteration 1000, loss = 0.188533
I0808 14:22:59.002964 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:22:59.002982 20451 solver.cpp:244]     Train net output #1: loss = 0.188533 (* 1 = 0.188533 loss)
I0808 14:22:59.002998 20451 sgd_solver.cpp:106] Iteration 1000, lr = 0.000931013
I0808 14:23:21.284968 20451 solver.cpp:228] Iteration 1010, loss = 0.187951
I0808 14:23:21.285189 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:23:21.285210 20451 solver.cpp:244]     Train net output #1: loss = 0.187951 (* 1 = 0.187951 loss)
I0808 14:23:21.285223 20451 sgd_solver.cpp:106] Iteration 1010, lr = 0.000930378
I0808 14:23:43.591475 20451 solver.cpp:228] Iteration 1020, loss = 0.09431
I0808 14:23:43.591524 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 14:23:43.591538 20451 solver.cpp:244]     Train net output #1: loss = 0.09431 (* 1 = 0.09431 loss)
I0808 14:23:43.591550 20451 sgd_solver.cpp:106] Iteration 1020, lr = 0.000929745
I0808 14:24:05.892861 20451 solver.cpp:228] Iteration 1030, loss = 0.125446
I0808 14:24:05.893045 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:24:05.893060 20451 solver.cpp:244]     Train net output #1: loss = 0.125446 (* 1 = 0.125446 loss)
I0808 14:24:05.893074 20451 sgd_solver.cpp:106] Iteration 1030, lr = 0.000929113
I0808 14:24:28.195338 20451 solver.cpp:228] Iteration 1040, loss = 0.0947214
I0808 14:24:28.195390 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:24:28.195405 20451 solver.cpp:244]     Train net output #1: loss = 0.0947214 (* 1 = 0.0947214 loss)
I0808 14:24:28.195417 20451 sgd_solver.cpp:106] Iteration 1040, lr = 0.000928481
I0808 14:24:50.509887 20451 solver.cpp:228] Iteration 1050, loss = 0.156727
I0808 14:24:50.510064 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 14:24:50.510080 20451 solver.cpp:244]     Train net output #1: loss = 0.156727 (* 1 = 0.156727 loss)
I0808 14:24:50.510093 20451 sgd_solver.cpp:106] Iteration 1050, lr = 0.000927851
I0808 14:25:12.826498 20451 solver.cpp:228] Iteration 1060, loss = 0.0941312
I0808 14:25:12.826550 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:25:12.826565 20451 solver.cpp:244]     Train net output #1: loss = 0.0941312 (* 1 = 0.0941312 loss)
I0808 14:25:12.826577 20451 sgd_solver.cpp:106] Iteration 1060, lr = 0.000927222
I0808 14:25:35.136001 20451 solver.cpp:228] Iteration 1070, loss = 0.250751
I0808 14:25:35.136098 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:25:35.136118 20451 solver.cpp:244]     Train net output #1: loss = 0.250751 (* 1 = 0.250751 loss)
I0808 14:25:35.136139 20451 sgd_solver.cpp:106] Iteration 1070, lr = 0.000926594
I0808 14:25:57.440945 20451 solver.cpp:228] Iteration 1080, loss = 0.18788
I0808 14:25:57.440990 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:25:57.441009 20451 solver.cpp:244]     Train net output #1: loss = 0.18788 (* 1 = 0.18788 loss)
I0808 14:25:57.441023 20451 sgd_solver.cpp:106] Iteration 1080, lr = 0.000925966
I0808 14:26:19.755244 20451 solver.cpp:228] Iteration 1090, loss = 0.156504
I0808 14:26:19.755350 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:26:19.755370 20451 solver.cpp:244]     Train net output #1: loss = 0.156504 (* 1 = 0.156504 loss)
I0808 14:26:19.755384 20451 sgd_solver.cpp:106] Iteration 1090, lr = 0.00092534
I0808 14:26:39.840267 20451 solver.cpp:337] Iteration 1100, Testing net (#0)
I0808 14:26:48.365404 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 14:26:48.365458 20451 solver.cpp:404]     Test net output #1: loss = 0.998192 (* 1 = 0.998192 loss)
I0808 14:26:50.566340 20451 solver.cpp:228] Iteration 1100, loss = 0.188279
I0808 14:26:50.566459 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:26:50.566478 20451 solver.cpp:244]     Train net output #1: loss = 0.188279 (* 1 = 0.188279 loss)
I0808 14:26:50.566493 20451 sgd_solver.cpp:106] Iteration 1100, lr = 0.000924715
I0808 14:27:12.851932 20451 solver.cpp:228] Iteration 1110, loss = 0.157151
I0808 14:27:12.851984 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:27:12.851996 20451 solver.cpp:244]     Train net output #1: loss = 0.157151 (* 1 = 0.157151 loss)
I0808 14:27:12.852010 20451 sgd_solver.cpp:106] Iteration 1110, lr = 0.00092409
I0808 14:27:35.161682 20451 solver.cpp:228] Iteration 1120, loss = 0.218676
I0808 14:27:35.161897 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:27:35.161913 20451 solver.cpp:244]     Train net output #1: loss = 0.218676 (* 1 = 0.218676 loss)
I0808 14:27:35.161926 20451 sgd_solver.cpp:106] Iteration 1120, lr = 0.000923467
I0808 14:27:57.471102 20451 solver.cpp:228] Iteration 1130, loss = 0.219297
I0808 14:27:57.471153 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:27:57.471168 20451 solver.cpp:244]     Train net output #1: loss = 0.219297 (* 1 = 0.219297 loss)
I0808 14:27:57.471180 20451 sgd_solver.cpp:106] Iteration 1130, lr = 0.000922845
I0808 14:28:19.787221 20451 solver.cpp:228] Iteration 1140, loss = 0.18799
I0808 14:28:19.787320 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:28:19.787336 20451 solver.cpp:244]     Train net output #1: loss = 0.18799 (* 1 = 0.18799 loss)
I0808 14:28:19.787350 20451 sgd_solver.cpp:106] Iteration 1140, lr = 0.000922223
I0808 14:28:42.093253 20451 solver.cpp:228] Iteration 1150, loss = 0.125665
I0808 14:28:42.093305 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:28:42.093319 20451 solver.cpp:244]     Train net output #1: loss = 0.125665 (* 1 = 0.125665 loss)
I0808 14:28:42.093332 20451 sgd_solver.cpp:106] Iteration 1150, lr = 0.000921603
I0808 14:29:04.395933 20451 solver.cpp:228] Iteration 1160, loss = 0.0944173
I0808 14:29:04.396029 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:29:04.396046 20451 solver.cpp:244]     Train net output #1: loss = 0.0944173 (* 1 = 0.0944173 loss)
I0808 14:29:04.396060 20451 sgd_solver.cpp:106] Iteration 1160, lr = 0.000920984
I0808 14:29:26.695938 20451 solver.cpp:228] Iteration 1170, loss = 0.125097
I0808 14:29:26.695989 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:29:26.696003 20451 solver.cpp:244]     Train net output #1: loss = 0.125097 (* 1 = 0.125097 loss)
I0808 14:29:26.696017 20451 sgd_solver.cpp:106] Iteration 1170, lr = 0.000920365
I0808 14:29:49.007710 20451 solver.cpp:228] Iteration 1180, loss = 0.156933
I0808 14:29:49.007813 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:29:49.007828 20451 solver.cpp:244]     Train net output #1: loss = 0.156933 (* 1 = 0.156933 loss)
I0808 14:29:49.007841 20451 sgd_solver.cpp:106] Iteration 1180, lr = 0.000919748
I0808 14:30:11.314826 20451 solver.cpp:228] Iteration 1190, loss = 0.281683
I0808 14:30:11.314868 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:30:11.314884 20451 solver.cpp:244]     Train net output #1: loss = 0.281683 (* 1 = 0.281683 loss)
I0808 14:30:11.314898 20451 sgd_solver.cpp:106] Iteration 1190, lr = 0.000919131
I0808 14:30:31.400362 20451 solver.cpp:337] Iteration 1200, Testing net (#0)
I0808 14:30:39.921457 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 14:30:39.921507 20451 solver.cpp:404]     Test net output #1: loss = 1.00245 (* 1 = 1.00245 loss)
I0808 14:30:42.123036 20451 solver.cpp:228] Iteration 1200, loss = 0.156958
I0808 14:30:42.123088 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:30:42.123103 20451 solver.cpp:244]     Train net output #1: loss = 0.156958 (* 1 = 0.156958 loss)
I0808 14:30:42.123116 20451 sgd_solver.cpp:106] Iteration 1200, lr = 0.000918516
I0808 14:31:04.418608 20451 solver.cpp:228] Iteration 1210, loss = 0.156582
I0808 14:31:04.418776 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:31:04.418792 20451 solver.cpp:244]     Train net output #1: loss = 0.156582 (* 1 = 0.156582 loss)
I0808 14:31:04.418804 20451 sgd_solver.cpp:106] Iteration 1210, lr = 0.000917901
I0808 14:31:26.727926 20451 solver.cpp:228] Iteration 1220, loss = 0.125439
I0808 14:31:26.727977 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 14:31:26.727991 20451 solver.cpp:244]     Train net output #1: loss = 0.125439 (* 1 = 0.125439 loss)
I0808 14:31:26.728003 20451 sgd_solver.cpp:106] Iteration 1220, lr = 0.000917287
I0808 14:31:49.041697 20451 solver.cpp:228] Iteration 1230, loss = 0.156565
I0808 14:31:49.041918 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:31:49.041932 20451 solver.cpp:244]     Train net output #1: loss = 0.156565 (* 1 = 0.156565 loss)
I0808 14:31:49.041946 20451 sgd_solver.cpp:106] Iteration 1230, lr = 0.000916675
I0808 14:32:11.354125 20451 solver.cpp:228] Iteration 1240, loss = 0.219573
I0808 14:32:11.354176 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:32:11.354189 20451 solver.cpp:244]     Train net output #1: loss = 0.219573 (* 1 = 0.219573 loss)
I0808 14:32:11.354202 20451 sgd_solver.cpp:106] Iteration 1240, lr = 0.000916063
I0808 14:32:33.672952 20451 solver.cpp:228] Iteration 1250, loss = 0.0942136
I0808 14:32:33.673135 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:32:33.673152 20451 solver.cpp:244]     Train net output #1: loss = 0.0942136 (* 1 = 0.0942136 loss)
I0808 14:32:33.673167 20451 sgd_solver.cpp:106] Iteration 1250, lr = 0.000915452
I0808 14:32:55.994536 20451 solver.cpp:228] Iteration 1260, loss = 0.250267
I0808 14:32:55.994580 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:32:55.994596 20451 solver.cpp:244]     Train net output #1: loss = 0.250267 (* 1 = 0.250267 loss)
I0808 14:32:55.994608 20451 sgd_solver.cpp:106] Iteration 1260, lr = 0.000914842
I0808 14:33:18.309965 20451 solver.cpp:228] Iteration 1270, loss = 0.250494
I0808 14:33:18.310145 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:33:18.310161 20451 solver.cpp:244]     Train net output #1: loss = 0.250494 (* 1 = 0.250494 loss)
I0808 14:33:18.310174 20451 sgd_solver.cpp:106] Iteration 1270, lr = 0.000914233
I0808 14:33:40.620263 20451 solver.cpp:228] Iteration 1280, loss = 0.0939697
I0808 14:33:40.620317 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:33:40.620331 20451 solver.cpp:244]     Train net output #1: loss = 0.0939697 (* 1 = 0.0939697 loss)
I0808 14:33:40.620343 20451 sgd_solver.cpp:106] Iteration 1280, lr = 0.000913625
I0808 14:34:02.933193 20451 solver.cpp:228] Iteration 1290, loss = 0.125192
I0808 14:34:02.933296 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:34:02.933315 20451 solver.cpp:244]     Train net output #1: loss = 0.125192 (* 1 = 0.125192 loss)
I0808 14:34:02.933331 20451 sgd_solver.cpp:106] Iteration 1290, lr = 0.000913018
I0808 14:34:23.020975 20451 solver.cpp:337] Iteration 1300, Testing net (#0)
I0808 14:34:31.543463 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0808 14:34:31.543515 20451 solver.cpp:404]     Test net output #1: loss = 0.992371 (* 1 = 0.992371 loss)
I0808 14:34:33.745856 20451 solver.cpp:228] Iteration 1300, loss = 0.0317472
I0808 14:34:33.746031 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 14:34:33.746047 20451 solver.cpp:244]     Train net output #1: loss = 0.0317472 (* 1 = 0.0317472 loss)
I0808 14:34:33.746059 20451 sgd_solver.cpp:106] Iteration 1300, lr = 0.000912412
I0808 14:34:56.033560 20451 solver.cpp:228] Iteration 1310, loss = 0.187936
I0808 14:34:56.033614 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:34:56.033628 20451 solver.cpp:244]     Train net output #1: loss = 0.187936 (* 1 = 0.187936 loss)
I0808 14:34:56.033640 20451 sgd_solver.cpp:106] Iteration 1310, lr = 0.000911807
I0808 14:35:18.351785 20451 solver.cpp:228] Iteration 1320, loss = 0.312821
I0808 14:35:18.351963 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:35:18.351979 20451 solver.cpp:244]     Train net output #1: loss = 0.312821 (* 1 = 0.312821 loss)
I0808 14:35:18.351991 20451 sgd_solver.cpp:106] Iteration 1320, lr = 0.000911203
I0808 14:35:40.663732 20451 solver.cpp:228] Iteration 1330, loss = 0.219663
I0808 14:35:40.663774 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:35:40.663789 20451 solver.cpp:244]     Train net output #1: loss = 0.219663 (* 1 = 0.219663 loss)
I0808 14:35:40.663801 20451 sgd_solver.cpp:106] Iteration 1330, lr = 0.0009106
I0808 14:36:02.982923 20451 solver.cpp:228] Iteration 1340, loss = 0.156363
I0808 14:36:02.983074 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:36:02.983093 20451 solver.cpp:244]     Train net output #1: loss = 0.156363 (* 1 = 0.156363 loss)
I0808 14:36:02.983108 20451 sgd_solver.cpp:106] Iteration 1340, lr = 0.000909997
I0808 14:36:25.292616 20451 solver.cpp:228] Iteration 1350, loss = 0.250528
I0808 14:36:25.292661 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:36:25.292680 20451 solver.cpp:244]     Train net output #1: loss = 0.250528 (* 1 = 0.250528 loss)
I0808 14:36:25.292704 20451 sgd_solver.cpp:106] Iteration 1350, lr = 0.000909396
I0808 14:36:47.613742 20451 solver.cpp:228] Iteration 1360, loss = 0.188062
I0808 14:36:47.613925 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:36:47.613941 20451 solver.cpp:244]     Train net output #1: loss = 0.188062 (* 1 = 0.188062 loss)
I0808 14:36:47.613953 20451 sgd_solver.cpp:106] Iteration 1360, lr = 0.000908796
I0808 14:37:09.924427 20451 solver.cpp:228] Iteration 1370, loss = 0.250235
I0808 14:37:09.924480 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:37:09.924494 20451 solver.cpp:244]     Train net output #1: loss = 0.250235 (* 1 = 0.250235 loss)
I0808 14:37:09.924506 20451 sgd_solver.cpp:106] Iteration 1370, lr = 0.000908196
I0808 14:37:32.238165 20451 solver.cpp:228] Iteration 1380, loss = 0.156487
I0808 14:37:32.238349 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:37:32.238364 20451 solver.cpp:244]     Train net output #1: loss = 0.156487 (* 1 = 0.156487 loss)
I0808 14:37:32.238378 20451 sgd_solver.cpp:106] Iteration 1380, lr = 0.000907598
I0808 14:37:54.548858 20451 solver.cpp:228] Iteration 1390, loss = 0.0938231
I0808 14:37:54.548909 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 14:37:54.548923 20451 solver.cpp:244]     Train net output #1: loss = 0.0938231 (* 1 = 0.0938231 loss)
I0808 14:37:54.548935 20451 sgd_solver.cpp:106] Iteration 1390, lr = 0.000907
I0808 14:38:14.634976 20451 solver.cpp:337] Iteration 1400, Testing net (#0)
I0808 14:38:23.159319 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0808 14:38:23.159366 20451 solver.cpp:404]     Test net output #1: loss = 1.03836 (* 1 = 1.03836 loss)
I0808 14:38:25.361207 20451 solver.cpp:228] Iteration 1400, loss = 0.281951
I0808 14:38:25.361253 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 14:38:25.361271 20451 solver.cpp:244]     Train net output #1: loss = 0.281951 (* 1 = 0.281951 loss)
I0808 14:38:25.361289 20451 sgd_solver.cpp:106] Iteration 1400, lr = 0.000906403
I0808 14:38:47.646663 20451 solver.cpp:228] Iteration 1410, loss = 0.0626051
I0808 14:38:47.646845 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 14:38:47.646862 20451 solver.cpp:244]     Train net output #1: loss = 0.0626051 (* 1 = 0.0626051 loss)
I0808 14:38:47.646874 20451 sgd_solver.cpp:106] Iteration 1410, lr = 0.000905807
I0808 14:39:09.952147 20451 solver.cpp:228] Iteration 1420, loss = 0.218959
I0808 14:39:09.952198 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:39:09.952214 20451 solver.cpp:244]     Train net output #1: loss = 0.218959 (* 1 = 0.218959 loss)
I0808 14:39:09.952225 20451 sgd_solver.cpp:106] Iteration 1420, lr = 0.000905212
I0808 14:39:32.267951 20451 solver.cpp:228] Iteration 1430, loss = 0.156698
I0808 14:39:32.268049 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:39:32.268069 20451 solver.cpp:244]     Train net output #1: loss = 0.156698 (* 1 = 0.156698 loss)
I0808 14:39:32.268084 20451 sgd_solver.cpp:106] Iteration 1430, lr = 0.000904618
I0808 14:39:54.582473 20451 solver.cpp:228] Iteration 1440, loss = 0.06294
I0808 14:39:54.582526 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 14:39:54.582540 20451 solver.cpp:244]     Train net output #1: loss = 0.06294 (* 1 = 0.06294 loss)
I0808 14:39:54.582552 20451 sgd_solver.cpp:106] Iteration 1440, lr = 0.000904025
I0808 14:40:16.889997 20451 solver.cpp:228] Iteration 1450, loss = 0.25063
I0808 14:40:16.890207 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:40:16.890223 20451 solver.cpp:244]     Train net output #1: loss = 0.25063 (* 1 = 0.25063 loss)
I0808 14:40:16.890235 20451 sgd_solver.cpp:106] Iteration 1450, lr = 0.000903433
I0808 14:40:39.192219 20451 solver.cpp:228] Iteration 1460, loss = 0.156577
I0808 14:40:39.192260 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:40:39.192276 20451 solver.cpp:244]     Train net output #1: loss = 0.156577 (* 1 = 0.156577 loss)
I0808 14:40:39.192289 20451 sgd_solver.cpp:106] Iteration 1460, lr = 0.000902842
I0808 14:41:01.483909 20451 solver.cpp:228] Iteration 1470, loss = 0.156439
I0808 14:41:01.484089 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:41:01.484105 20451 solver.cpp:244]     Train net output #1: loss = 0.156439 (* 1 = 0.156439 loss)
I0808 14:41:01.484118 20451 sgd_solver.cpp:106] Iteration 1470, lr = 0.000902251
I0808 14:41:23.775797 20451 solver.cpp:228] Iteration 1480, loss = 0.0938435
I0808 14:41:23.775849 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:41:23.775863 20451 solver.cpp:244]     Train net output #1: loss = 0.0938434 (* 1 = 0.0938434 loss)
I0808 14:41:23.775876 20451 sgd_solver.cpp:106] Iteration 1480, lr = 0.000901662
I0808 14:41:46.072075 20451 solver.cpp:228] Iteration 1490, loss = 0.219161
I0808 14:41:46.072190 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:41:46.072209 20451 solver.cpp:244]     Train net output #1: loss = 0.219161 (* 1 = 0.219161 loss)
I0808 14:41:46.072224 20451 sgd_solver.cpp:106] Iteration 1490, lr = 0.000901073
I0808 14:42:06.148334 20451 solver.cpp:337] Iteration 1500, Testing net (#0)
I0808 14:42:14.672309 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 14:42:14.672360 20451 solver.cpp:404]     Test net output #1: loss = 0.986194 (* 1 = 0.986194 loss)
I0808 14:42:16.874735 20451 solver.cpp:228] Iteration 1500, loss = 0.187828
I0808 14:42:16.874836 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:42:16.874852 20451 solver.cpp:244]     Train net output #1: loss = 0.187828 (* 1 = 0.187828 loss)
I0808 14:42:16.874866 20451 sgd_solver.cpp:106] Iteration 1500, lr = 0.000900485
I0808 14:42:39.154202 20451 solver.cpp:228] Iteration 1510, loss = 0.250563
I0808 14:42:39.154244 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:42:39.154258 20451 solver.cpp:244]     Train net output #1: loss = 0.250563 (* 1 = 0.250563 loss)
I0808 14:42:39.154271 20451 sgd_solver.cpp:106] Iteration 1510, lr = 0.000899898
I0808 14:43:01.464373 20451 solver.cpp:228] Iteration 1520, loss = 0.156625
I0808 14:43:01.464551 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:43:01.464566 20451 solver.cpp:244]     Train net output #1: loss = 0.156625 (* 1 = 0.156625 loss)
I0808 14:43:01.464579 20451 sgd_solver.cpp:106] Iteration 1520, lr = 0.000899313
I0808 14:43:23.763428 20451 solver.cpp:228] Iteration 1530, loss = 0.125098
I0808 14:43:23.763481 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:43:23.763496 20451 solver.cpp:244]     Train net output #1: loss = 0.125098 (* 1 = 0.125098 loss)
I0808 14:43:23.763509 20451 sgd_solver.cpp:106] Iteration 1530, lr = 0.000898728
I0808 14:43:46.057214 20451 solver.cpp:228] Iteration 1540, loss = 0.219062
I0808 14:43:46.057395 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:43:46.057410 20451 solver.cpp:244]     Train net output #1: loss = 0.219062 (* 1 = 0.219062 loss)
I0808 14:43:46.057425 20451 sgd_solver.cpp:106] Iteration 1540, lr = 0.000898143
I0808 14:44:08.362541 20451 solver.cpp:228] Iteration 1550, loss = 0.218935
I0808 14:44:08.362589 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:44:08.362608 20451 solver.cpp:244]     Train net output #1: loss = 0.218935 (* 1 = 0.218935 loss)
I0808 14:44:08.362623 20451 sgd_solver.cpp:106] Iteration 1550, lr = 0.00089756
I0808 14:44:30.680527 20451 solver.cpp:228] Iteration 1560, loss = 0.312464
I0808 14:44:30.680796 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:44:30.680872 20451 solver.cpp:244]     Train net output #1: loss = 0.312464 (* 1 = 0.312464 loss)
I0808 14:44:30.680912 20451 sgd_solver.cpp:106] Iteration 1560, lr = 0.000896978
I0808 14:44:52.980219 20451 solver.cpp:228] Iteration 1570, loss = 0.25029
I0808 14:44:52.980267 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:44:52.980285 20451 solver.cpp:244]     Train net output #1: loss = 0.25029 (* 1 = 0.25029 loss)
I0808 14:44:52.980300 20451 sgd_solver.cpp:106] Iteration 1570, lr = 0.000896396
I0808 14:45:15.281747 20451 solver.cpp:228] Iteration 1580, loss = 0.187933
I0808 14:45:15.281858 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:45:15.281873 20451 solver.cpp:244]     Train net output #1: loss = 0.187933 (* 1 = 0.187933 loss)
I0808 14:45:15.281886 20451 sgd_solver.cpp:106] Iteration 1580, lr = 0.000895816
I0808 14:45:37.577342 20451 solver.cpp:228] Iteration 1590, loss = 0.250263
I0808 14:45:37.577396 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:45:37.577410 20451 solver.cpp:244]     Train net output #1: loss = 0.250263 (* 1 = 0.250263 loss)
I0808 14:45:37.577424 20451 sgd_solver.cpp:106] Iteration 1590, lr = 0.000895236
I0808 14:45:57.659729 20451 solver.cpp:337] Iteration 1600, Testing net (#0)
I0808 14:46:06.180033 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0808 14:46:06.180084 20451 solver.cpp:404]     Test net output #1: loss = 0.971857 (* 1 = 0.971857 loss)
I0808 14:46:08.383293 20451 solver.cpp:228] Iteration 1600, loss = 0.282184
I0808 14:46:08.383344 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:46:08.383358 20451 solver.cpp:244]     Train net output #1: loss = 0.282184 (* 1 = 0.282184 loss)
I0808 14:46:08.383370 20451 sgd_solver.cpp:106] Iteration 1600, lr = 0.000894657
I0808 14:46:30.664110 20451 solver.cpp:228] Iteration 1610, loss = 0.312898
I0808 14:46:30.664258 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 14:46:30.664278 20451 solver.cpp:244]     Train net output #1: loss = 0.312898 (* 1 = 0.312898 loss)
I0808 14:46:30.664296 20451 sgd_solver.cpp:106] Iteration 1610, lr = 0.000894079
I0808 14:46:52.969490 20451 solver.cpp:228] Iteration 1620, loss = 0.312791
I0808 14:46:52.969542 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 14:46:52.969557 20451 solver.cpp:244]     Train net output #1: loss = 0.31279 (* 1 = 0.31279 loss)
I0808 14:46:52.969568 20451 sgd_solver.cpp:106] Iteration 1620, lr = 0.000893502
I0808 14:47:15.280282 20451 solver.cpp:228] Iteration 1630, loss = 0.0314774
I0808 14:47:15.280455 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 14:47:15.280472 20451 solver.cpp:244]     Train net output #1: loss = 0.0314774 (* 1 = 0.0314774 loss)
I0808 14:47:15.280483 20451 sgd_solver.cpp:106] Iteration 1630, lr = 0.000892926
I0808 14:47:37.583345 20451 solver.cpp:228] Iteration 1640, loss = 0.250161
I0808 14:47:37.583400 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:47:37.583415 20451 solver.cpp:244]     Train net output #1: loss = 0.250161 (* 1 = 0.250161 loss)
I0808 14:47:37.583426 20451 sgd_solver.cpp:106] Iteration 1640, lr = 0.00089235
I0808 14:47:59.898514 20451 solver.cpp:228] Iteration 1650, loss = 0.281428
I0808 14:47:59.898689 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:47:59.898705 20451 solver.cpp:244]     Train net output #1: loss = 0.281428 (* 1 = 0.281428 loss)
I0808 14:47:59.898718 20451 sgd_solver.cpp:106] Iteration 1650, lr = 0.000891776
I0808 14:48:22.209846 20451 solver.cpp:228] Iteration 1660, loss = 0.218953
I0808 14:48:22.209897 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:48:22.209910 20451 solver.cpp:244]     Train net output #1: loss = 0.218953 (* 1 = 0.218953 loss)
I0808 14:48:22.209923 20451 sgd_solver.cpp:106] Iteration 1660, lr = 0.000891202
I0808 14:48:44.526337 20451 solver.cpp:228] Iteration 1670, loss = 0.313233
I0808 14:48:44.526625 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 14:48:44.526695 20451 solver.cpp:244]     Train net output #1: loss = 0.313233 (* 1 = 0.313233 loss)
I0808 14:48:44.526729 20451 sgd_solver.cpp:106] Iteration 1670, lr = 0.000890629
I0808 14:49:06.844465 20451 solver.cpp:228] Iteration 1680, loss = 0.125143
I0808 14:49:06.844516 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:49:06.844528 20451 solver.cpp:244]     Train net output #1: loss = 0.125143 (* 1 = 0.125143 loss)
I0808 14:49:06.844540 20451 sgd_solver.cpp:106] Iteration 1680, lr = 0.000890057
I0808 14:49:29.157171 20451 solver.cpp:228] Iteration 1690, loss = 0.0940271
I0808 14:49:29.157346 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 14:49:29.157361 20451 solver.cpp:244]     Train net output #1: loss = 0.094027 (* 1 = 0.094027 loss)
I0808 14:49:29.157374 20451 sgd_solver.cpp:106] Iteration 1690, lr = 0.000889486
I0808 14:49:49.239564 20451 solver.cpp:337] Iteration 1700, Testing net (#0)
I0808 14:49:57.763803 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 14:49:57.763846 20451 solver.cpp:404]     Test net output #1: loss = 1.00948 (* 1 = 1.00948 loss)
I0808 14:49:59.969056 20451 solver.cpp:228] Iteration 1700, loss = 0.125142
I0808 14:49:59.969240 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:49:59.969259 20451 solver.cpp:244]     Train net output #1: loss = 0.125142 (* 1 = 0.125142 loss)
I0808 14:49:59.969274 20451 sgd_solver.cpp:106] Iteration 1700, lr = 0.000888916
I0808 14:50:22.245822 20451 solver.cpp:228] Iteration 1710, loss = 0.218964
I0808 14:50:22.245872 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:50:22.245887 20451 solver.cpp:244]     Train net output #1: loss = 0.218964 (* 1 = 0.218964 loss)
I0808 14:50:22.245900 20451 sgd_solver.cpp:106] Iteration 1710, lr = 0.000888346
I0808 14:50:44.554657 20451 solver.cpp:228] Iteration 1720, loss = 0.219328
I0808 14:50:44.554841 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:50:44.554857 20451 solver.cpp:244]     Train net output #1: loss = 0.219328 (* 1 = 0.219328 loss)
I0808 14:50:44.554870 20451 sgd_solver.cpp:106] Iteration 1720, lr = 0.000887778
I0808 14:51:06.871650 20451 solver.cpp:228] Iteration 1730, loss = 0.18801
I0808 14:51:06.871701 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:51:06.871714 20451 solver.cpp:244]     Train net output #1: loss = 0.18801 (* 1 = 0.18801 loss)
I0808 14:51:06.871726 20451 sgd_solver.cpp:106] Iteration 1730, lr = 0.00088721
I0808 14:51:29.192258 20451 solver.cpp:228] Iteration 1740, loss = 0.187814
I0808 14:51:29.192435 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:51:29.192451 20451 solver.cpp:244]     Train net output #1: loss = 0.187814 (* 1 = 0.187814 loss)
I0808 14:51:29.192463 20451 sgd_solver.cpp:106] Iteration 1740, lr = 0.000886643
I0808 14:51:51.498095 20451 solver.cpp:228] Iteration 1750, loss = 0.187583
I0808 14:51:51.498147 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:51:51.498160 20451 solver.cpp:244]     Train net output #1: loss = 0.187583 (* 1 = 0.187583 loss)
I0808 14:51:51.498172 20451 sgd_solver.cpp:106] Iteration 1750, lr = 0.000886077
I0808 14:52:13.811540 20451 solver.cpp:228] Iteration 1760, loss = 0.218869
I0808 14:52:13.811733 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:52:13.811750 20451 solver.cpp:244]     Train net output #1: loss = 0.218869 (* 1 = 0.218869 loss)
I0808 14:52:13.811764 20451 sgd_solver.cpp:106] Iteration 1760, lr = 0.000885512
I0808 14:52:36.125452 20451 solver.cpp:228] Iteration 1770, loss = 0.156601
I0808 14:52:36.125505 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:52:36.125519 20451 solver.cpp:244]     Train net output #1: loss = 0.156601 (* 1 = 0.156601 loss)
I0808 14:52:36.125531 20451 sgd_solver.cpp:106] Iteration 1770, lr = 0.000884948
I0808 14:52:58.429190 20451 solver.cpp:228] Iteration 1780, loss = 0.0939419
I0808 14:52:58.429410 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:52:58.429431 20451 solver.cpp:244]     Train net output #1: loss = 0.0939418 (* 1 = 0.0939418 loss)
I0808 14:52:58.429471 20451 sgd_solver.cpp:106] Iteration 1780, lr = 0.000884384
I0808 14:53:20.739589 20451 solver.cpp:228] Iteration 1790, loss = 0.219114
I0808 14:53:20.739640 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:53:20.739655 20451 solver.cpp:244]     Train net output #1: loss = 0.219114 (* 1 = 0.219114 loss)
I0808 14:53:20.739667 20451 sgd_solver.cpp:106] Iteration 1790, lr = 0.000883822
I0808 14:53:40.815690 20451 solver.cpp:337] Iteration 1800, Testing net (#0)
I0808 14:53:49.336120 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0808 14:53:49.336170 20451 solver.cpp:404]     Test net output #1: loss = 1.01363 (* 1 = 1.01363 loss)
I0808 14:53:51.539913 20451 solver.cpp:228] Iteration 1800, loss = 0.125218
I0808 14:53:51.539965 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:53:51.539979 20451 solver.cpp:244]     Train net output #1: loss = 0.125218 (* 1 = 0.125218 loss)
I0808 14:53:51.539993 20451 sgd_solver.cpp:106] Iteration 1800, lr = 0.00088326
I0808 14:54:13.834861 20451 solver.cpp:228] Iteration 1810, loss = 0.218916
I0808 14:54:13.834959 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:54:13.834975 20451 solver.cpp:244]     Train net output #1: loss = 0.218916 (* 1 = 0.218916 loss)
I0808 14:54:13.834987 20451 sgd_solver.cpp:106] Iteration 1810, lr = 0.000882699
I0808 14:54:36.138557 20451 solver.cpp:228] Iteration 1820, loss = 0.125156
I0808 14:54:36.138609 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:54:36.138624 20451 solver.cpp:244]     Train net output #1: loss = 0.125156 (* 1 = 0.125156 loss)
I0808 14:54:36.138636 20451 sgd_solver.cpp:106] Iteration 1820, lr = 0.000882139
I0808 14:54:58.444926 20451 solver.cpp:228] Iteration 1830, loss = 0.187756
I0808 14:54:58.445099 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 14:54:58.445114 20451 solver.cpp:244]     Train net output #1: loss = 0.187756 (* 1 = 0.187756 loss)
I0808 14:54:58.445127 20451 sgd_solver.cpp:106] Iteration 1830, lr = 0.000881579
I0808 14:55:20.750427 20451 solver.cpp:228] Iteration 1840, loss = 0.312835
I0808 14:55:20.750481 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:55:20.750495 20451 solver.cpp:244]     Train net output #1: loss = 0.312835 (* 1 = 0.312835 loss)
I0808 14:55:20.750509 20451 sgd_solver.cpp:106] Iteration 1840, lr = 0.000881021
I0808 14:55:43.056154 20451 solver.cpp:228] Iteration 1850, loss = 0.250628
I0808 14:55:43.056329 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:55:43.056349 20451 solver.cpp:244]     Train net output #1: loss = 0.250628 (* 1 = 0.250628 loss)
I0808 14:55:43.056361 20451 sgd_solver.cpp:106] Iteration 1850, lr = 0.000880463
I0808 14:56:05.363720 20451 solver.cpp:228] Iteration 1860, loss = 0.187693
I0808 14:56:05.363771 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 14:56:05.363786 20451 solver.cpp:244]     Train net output #1: loss = 0.187693 (* 1 = 0.187693 loss)
I0808 14:56:05.363800 20451 sgd_solver.cpp:106] Iteration 1860, lr = 0.000879906
I0808 14:56:27.669458 20451 solver.cpp:228] Iteration 1870, loss = 0.281413
I0808 14:56:27.669641 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 14:56:27.669656 20451 solver.cpp:244]     Train net output #1: loss = 0.281413 (* 1 = 0.281413 loss)
I0808 14:56:27.669669 20451 sgd_solver.cpp:106] Iteration 1870, lr = 0.00087935
I0808 14:56:49.979354 20451 solver.cpp:228] Iteration 1880, loss = 0.219048
I0808 14:56:49.979400 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:56:49.979420 20451 solver.cpp:244]     Train net output #1: loss = 0.219048 (* 1 = 0.219048 loss)
I0808 14:56:49.979435 20451 sgd_solver.cpp:106] Iteration 1880, lr = 0.000878795
I0808 14:57:12.287814 20451 solver.cpp:228] Iteration 1890, loss = 0.31268
I0808 14:57:12.287950 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 14:57:12.287964 20451 solver.cpp:244]     Train net output #1: loss = 0.31268 (* 1 = 0.31268 loss)
I0808 14:57:12.287978 20451 sgd_solver.cpp:106] Iteration 1890, lr = 0.000878241
I0808 14:57:32.360013 20451 solver.cpp:337] Iteration 1900, Testing net (#0)
I0808 14:57:40.882871 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 14:57:40.882916 20451 solver.cpp:404]     Test net output #1: loss = 0.985786 (* 1 = 0.985786 loss)
I0808 14:57:43.085692 20451 solver.cpp:228] Iteration 1900, loss = 0.125277
I0808 14:57:43.085866 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:57:43.085882 20451 solver.cpp:244]     Train net output #1: loss = 0.125277 (* 1 = 0.125277 loss)
I0808 14:57:43.085896 20451 sgd_solver.cpp:106] Iteration 1900, lr = 0.000877687
I0808 14:58:05.371333 20451 solver.cpp:228] Iteration 1910, loss = 0.125175
I0808 14:58:05.371386 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:58:05.371399 20451 solver.cpp:244]     Train net output #1: loss = 0.125175 (* 1 = 0.125175 loss)
I0808 14:58:05.371412 20451 sgd_solver.cpp:106] Iteration 1910, lr = 0.000877135
I0808 14:58:27.678165 20451 solver.cpp:228] Iteration 1920, loss = 0.0938151
I0808 14:58:27.678262 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:58:27.678277 20451 solver.cpp:244]     Train net output #1: loss = 0.0938151 (* 1 = 0.0938151 loss)
I0808 14:58:27.678290 20451 sgd_solver.cpp:106] Iteration 1920, lr = 0.000876583
I0808 14:58:49.982611 20451 solver.cpp:228] Iteration 1930, loss = 0.312751
I0808 14:58:49.982657 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 14:58:49.982676 20451 solver.cpp:244]     Train net output #1: loss = 0.312751 (* 1 = 0.312751 loss)
I0808 14:58:49.982689 20451 sgd_solver.cpp:106] Iteration 1930, lr = 0.000876031
I0808 14:59:12.292891 20451 solver.cpp:228] Iteration 1940, loss = 0.125149
I0808 14:59:12.293077 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 14:59:12.293119 20451 solver.cpp:244]     Train net output #1: loss = 0.125149 (* 1 = 0.125149 loss)
I0808 14:59:12.293190 20451 sgd_solver.cpp:106] Iteration 1940, lr = 0.000875481
I0808 14:59:34.611095 20451 solver.cpp:228] Iteration 1950, loss = 0.15639
I0808 14:59:34.611141 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 14:59:34.611160 20451 solver.cpp:244]     Train net output #1: loss = 0.156389 (* 1 = 0.156389 loss)
I0808 14:59:34.611176 20451 sgd_solver.cpp:106] Iteration 1950, lr = 0.000874932
I0808 14:59:56.926048 20451 solver.cpp:228] Iteration 1960, loss = 0.250174
I0808 14:59:56.926223 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 14:59:56.926237 20451 solver.cpp:244]     Train net output #1: loss = 0.250174 (* 1 = 0.250174 loss)
I0808 14:59:56.926250 20451 sgd_solver.cpp:106] Iteration 1960, lr = 0.000874383
I0808 15:00:19.236656 20451 solver.cpp:228] Iteration 1970, loss = 0.250395
I0808 15:00:19.236706 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:00:19.236721 20451 solver.cpp:244]     Train net output #1: loss = 0.250395 (* 1 = 0.250395 loss)
I0808 15:00:19.236733 20451 sgd_solver.cpp:106] Iteration 1970, lr = 0.000873835
I0808 15:00:41.552469 20451 solver.cpp:228] Iteration 1980, loss = 0.125052
I0808 15:00:41.552639 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:00:41.552654 20451 solver.cpp:244]     Train net output #1: loss = 0.125052 (* 1 = 0.125052 loss)
I0808 15:00:41.552667 20451 sgd_solver.cpp:106] Iteration 1980, lr = 0.000873288
I0808 15:01:03.973768 20451 solver.cpp:228] Iteration 1990, loss = 0.0938739
I0808 15:01:03.973817 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:01:03.973832 20451 solver.cpp:244]     Train net output #1: loss = 0.0938738 (* 1 = 0.0938738 loss)
I0808 15:01:03.973845 20451 sgd_solver.cpp:106] Iteration 1990, lr = 0.000872742
I0808 15:01:24.424644 20451 solver.cpp:337] Iteration 2000, Testing net (#0)
I0808 15:01:32.945540 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 15:01:32.945590 20451 solver.cpp:404]     Test net output #1: loss = 1.00385 (* 1 = 1.00385 loss)
I0808 15:01:35.145732 20451 solver.cpp:228] Iteration 2000, loss = 0.125152
I0808 15:01:35.145805 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:01:35.145829 20451 solver.cpp:244]     Train net output #1: loss = 0.125152 (* 1 = 0.125152 loss)
I0808 15:01:35.145848 20451 sgd_solver.cpp:106] Iteration 2000, lr = 0.000872196
I0808 15:01:57.428325 20451 solver.cpp:228] Iteration 2010, loss = 0.250191
I0808 15:01:57.428568 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:01:57.428583 20451 solver.cpp:244]     Train net output #1: loss = 0.250191 (* 1 = 0.250191 loss)
I0808 15:01:57.428596 20451 sgd_solver.cpp:106] Iteration 2010, lr = 0.000871651
I0808 15:02:19.730859 20451 solver.cpp:228] Iteration 2020, loss = 0.125128
I0808 15:02:19.730906 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:02:19.730923 20451 solver.cpp:244]     Train net output #1: loss = 0.125128 (* 1 = 0.125128 loss)
I0808 15:02:19.730938 20451 sgd_solver.cpp:106] Iteration 2020, lr = 0.000871107
I0808 15:02:42.024461 20451 solver.cpp:228] Iteration 2030, loss = 0.125068
I0808 15:02:42.024641 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:02:42.024657 20451 solver.cpp:244]     Train net output #1: loss = 0.125068 (* 1 = 0.125068 loss)
I0808 15:02:42.024670 20451 sgd_solver.cpp:106] Iteration 2030, lr = 0.000870564
I0808 15:03:04.315053 20451 solver.cpp:228] Iteration 2040, loss = 0.0312682
I0808 15:03:04.315096 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 15:03:04.315110 20451 solver.cpp:244]     Train net output #1: loss = 0.0312681 (* 1 = 0.0312681 loss)
I0808 15:03:04.315124 20451 sgd_solver.cpp:106] Iteration 2040, lr = 0.000870022
I0808 15:03:26.607079 20451 solver.cpp:228] Iteration 2050, loss = 0.0626094
I0808 15:03:26.607267 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 15:03:26.607292 20451 solver.cpp:244]     Train net output #1: loss = 0.0626093 (* 1 = 0.0626093 loss)
I0808 15:03:26.607308 20451 sgd_solver.cpp:106] Iteration 2050, lr = 0.00086948
I0808 15:03:48.994900 20451 solver.cpp:228] Iteration 2060, loss = 0.21895
I0808 15:03:48.994943 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:03:48.994961 20451 solver.cpp:244]     Train net output #1: loss = 0.21895 (* 1 = 0.21895 loss)
I0808 15:03:48.994974 20451 sgd_solver.cpp:106] Iteration 2060, lr = 0.00086894
I0808 15:04:11.403941 20451 solver.cpp:228] Iteration 2070, loss = 0.031334
I0808 15:04:11.404047 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 15:04:11.404063 20451 solver.cpp:244]     Train net output #1: loss = 0.031334 (* 1 = 0.031334 loss)
I0808 15:04:11.404078 20451 sgd_solver.cpp:106] Iteration 2070, lr = 0.0008684
I0808 15:04:33.824196 20451 solver.cpp:228] Iteration 2080, loss = 0.218955
I0808 15:04:33.824249 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:04:33.824262 20451 solver.cpp:244]     Train net output #1: loss = 0.218955 (* 1 = 0.218955 loss)
I0808 15:04:33.824275 20451 sgd_solver.cpp:106] Iteration 2080, lr = 0.00086786
I0808 15:04:56.269199 20451 solver.cpp:228] Iteration 2090, loss = 0.0938671
I0808 15:04:56.269304 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:04:56.269322 20451 solver.cpp:244]     Train net output #1: loss = 0.093867 (* 1 = 0.093867 loss)
I0808 15:04:56.269336 20451 sgd_solver.cpp:106] Iteration 2090, lr = 0.000867322
I0808 15:05:16.534430 20451 solver.cpp:337] Iteration 2100, Testing net (#0)
I0808 15:05:25.117724 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 15:05:25.117777 20451 solver.cpp:404]     Test net output #1: loss = 0.975829 (* 1 = 0.975829 loss)
I0808 15:05:27.337905 20451 solver.cpp:228] Iteration 2100, loss = 0.0938167
I0808 15:05:27.338050 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:05:27.338068 20451 solver.cpp:244]     Train net output #1: loss = 0.0938166 (* 1 = 0.0938166 loss)
I0808 15:05:27.338083 20451 sgd_solver.cpp:106] Iteration 2100, lr = 0.000866784
I0808 15:05:49.720360 20451 solver.cpp:228] Iteration 2110, loss = 0.156482
I0808 15:05:49.720403 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:05:49.720422 20451 solver.cpp:244]     Train net output #1: loss = 0.156482 (* 1 = 0.156482 loss)
I0808 15:05:49.720438 20451 sgd_solver.cpp:106] Iteration 2110, lr = 0.000866247
I0808 15:06:12.163839 20451 solver.cpp:228] Iteration 2120, loss = 0.219002
I0808 15:06:12.164026 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:06:12.164041 20451 solver.cpp:244]     Train net output #1: loss = 0.219002 (* 1 = 0.219002 loss)
I0808 15:06:12.164054 20451 sgd_solver.cpp:106] Iteration 2120, lr = 0.000865711
I0808 15:06:34.490200 20451 solver.cpp:228] Iteration 2130, loss = 0.156345
I0808 15:06:34.490269 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:06:34.490298 20451 solver.cpp:244]     Train net output #1: loss = 0.156345 (* 1 = 0.156345 loss)
I0808 15:06:34.490322 20451 sgd_solver.cpp:106] Iteration 2130, lr = 0.000865176
I0808 15:06:56.816954 20451 solver.cpp:228] Iteration 2140, loss = 0.156531
I0808 15:06:56.817138 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:06:56.817154 20451 solver.cpp:244]     Train net output #1: loss = 0.156531 (* 1 = 0.156531 loss)
I0808 15:06:56.817167 20451 sgd_solver.cpp:106] Iteration 2140, lr = 0.000864641
I0808 15:07:19.262459 20451 solver.cpp:228] Iteration 2150, loss = 0.250053
I0808 15:07:19.262511 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 15:07:19.262524 20451 solver.cpp:244]     Train net output #1: loss = 0.250053 (* 1 = 0.250053 loss)
I0808 15:07:19.262537 20451 sgd_solver.cpp:106] Iteration 2150, lr = 0.000864108
I0808 15:07:41.592690 20451 solver.cpp:228] Iteration 2160, loss = 0.0938522
I0808 15:07:41.592882 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 15:07:41.592901 20451 solver.cpp:244]     Train net output #1: loss = 0.0938522 (* 1 = 0.0938522 loss)
I0808 15:07:41.592916 20451 sgd_solver.cpp:106] Iteration 2160, lr = 0.000863575
I0808 15:08:03.909507 20451 solver.cpp:228] Iteration 2170, loss = 0.0625972
I0808 15:08:03.909559 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 15:08:03.909574 20451 solver.cpp:244]     Train net output #1: loss = 0.0625971 (* 1 = 0.0625971 loss)
I0808 15:08:03.909585 20451 sgd_solver.cpp:106] Iteration 2170, lr = 0.000863042
I0808 15:08:26.259639 20451 solver.cpp:228] Iteration 2180, loss = 0.15635
I0808 15:08:26.259816 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:08:26.259832 20451 solver.cpp:244]     Train net output #1: loss = 0.15635 (* 1 = 0.15635 loss)
I0808 15:08:26.259845 20451 sgd_solver.cpp:106] Iteration 2180, lr = 0.000862511
I0808 15:08:48.639683 20451 solver.cpp:228] Iteration 2190, loss = 0.250356
I0808 15:08:48.639732 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:08:48.639746 20451 solver.cpp:244]     Train net output #1: loss = 0.250355 (* 1 = 0.250355 loss)
I0808 15:08:48.639758 20451 sgd_solver.cpp:106] Iteration 2190, lr = 0.00086198
I0808 15:09:08.722594 20451 solver.cpp:337] Iteration 2200, Testing net (#0)
I0808 15:09:17.243356 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0808 15:09:17.243408 20451 solver.cpp:404]     Test net output #1: loss = 1.01897 (* 1 = 1.01897 loss)
I0808 15:09:19.448185 20451 solver.cpp:228] Iteration 2200, loss = 0.250616
I0808 15:09:19.448225 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:09:19.448240 20451 solver.cpp:244]     Train net output #1: loss = 0.250616 (* 1 = 0.250616 loss)
I0808 15:09:19.448253 20451 sgd_solver.cpp:106] Iteration 2200, lr = 0.00086145
I0808 15:09:41.767868 20451 solver.cpp:228] Iteration 2210, loss = 0.28144
I0808 15:09:41.768051 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:09:41.768066 20451 solver.cpp:244]     Train net output #1: loss = 0.28144 (* 1 = 0.28144 loss)
I0808 15:09:41.768079 20451 sgd_solver.cpp:106] Iteration 2210, lr = 0.000860921
I0808 15:10:04.286577 20451 solver.cpp:228] Iteration 2220, loss = 0.15653
I0808 15:10:04.286626 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:10:04.286644 20451 solver.cpp:244]     Train net output #1: loss = 0.15653 (* 1 = 0.15653 loss)
I0808 15:10:04.286660 20451 sgd_solver.cpp:106] Iteration 2220, lr = 0.000860393
I0808 15:10:26.719143 20451 solver.cpp:228] Iteration 2230, loss = 0.187652
I0808 15:10:26.719324 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:10:26.719339 20451 solver.cpp:244]     Train net output #1: loss = 0.187652 (* 1 = 0.187652 loss)
I0808 15:10:26.719352 20451 sgd_solver.cpp:106] Iteration 2230, lr = 0.000859865
I0808 15:10:49.119617 20451 solver.cpp:228] Iteration 2240, loss = 0.187669
I0808 15:10:49.119662 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:10:49.119679 20451 solver.cpp:244]     Train net output #1: loss = 0.187669 (* 1 = 0.187669 loss)
I0808 15:10:49.119694 20451 sgd_solver.cpp:106] Iteration 2240, lr = 0.000859338
I0808 15:11:11.555399 20451 solver.cpp:228] Iteration 2250, loss = 0.156382
I0808 15:11:11.555498 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:11:11.555516 20451 solver.cpp:244]     Train net output #1: loss = 0.156382 (* 1 = 0.156382 loss)
I0808 15:11:11.555532 20451 sgd_solver.cpp:106] Iteration 2250, lr = 0.000858812
I0808 15:11:34.000473 20451 solver.cpp:228] Iteration 2260, loss = 0.156382
I0808 15:11:34.000526 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:11:34.000540 20451 solver.cpp:244]     Train net output #1: loss = 0.156382 (* 1 = 0.156382 loss)
I0808 15:11:34.000553 20451 sgd_solver.cpp:106] Iteration 2260, lr = 0.000858286
I0808 15:11:56.419757 20451 solver.cpp:228] Iteration 2270, loss = 0.187678
I0808 15:11:56.419939 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:11:56.419955 20451 solver.cpp:244]     Train net output #1: loss = 0.187678 (* 1 = 0.187678 loss)
I0808 15:11:56.419966 20451 sgd_solver.cpp:106] Iteration 2270, lr = 0.000857762
I0808 15:12:18.736132 20451 solver.cpp:228] Iteration 2280, loss = 0.218928
I0808 15:12:18.736184 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:12:18.736199 20451 solver.cpp:244]     Train net output #1: loss = 0.218928 (* 1 = 0.218928 loss)
I0808 15:12:18.736212 20451 sgd_solver.cpp:106] Iteration 2280, lr = 0.000857238
I0808 15:12:41.119420 20451 solver.cpp:228] Iteration 2290, loss = 0.156643
I0808 15:12:41.119583 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:12:41.119599 20451 solver.cpp:244]     Train net output #1: loss = 0.156643 (* 1 = 0.156643 loss)
I0808 15:12:41.119612 20451 sgd_solver.cpp:106] Iteration 2290, lr = 0.000856714
I0808 15:13:01.305688 20451 solver.cpp:337] Iteration 2300, Testing net (#0)
I0808 15:13:09.878744 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 15:13:09.878795 20451 solver.cpp:404]     Test net output #1: loss = 1.0038 (* 1 = 1.0038 loss)
I0808 15:13:12.102342 20451 solver.cpp:228] Iteration 2300, loss = 0.281398
I0808 15:13:12.102527 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:13:12.102543 20451 solver.cpp:244]     Train net output #1: loss = 0.281398 (* 1 = 0.281398 loss)
I0808 15:13:12.102556 20451 sgd_solver.cpp:106] Iteration 2300, lr = 0.000856192
I0808 15:13:34.462806 20451 solver.cpp:228] Iteration 2310, loss = 0.125118
I0808 15:13:34.462849 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:13:34.462878 20451 solver.cpp:244]     Train net output #1: loss = 0.125118 (* 1 = 0.125118 loss)
I0808 15:13:34.462895 20451 sgd_solver.cpp:106] Iteration 2310, lr = 0.00085567
I0808 15:13:56.769608 20451 solver.cpp:228] Iteration 2320, loss = 0.0939435
I0808 15:13:56.769839 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 15:13:56.769853 20451 solver.cpp:244]     Train net output #1: loss = 0.0939435 (* 1 = 0.0939435 loss)
I0808 15:13:56.769866 20451 sgd_solver.cpp:106] Iteration 2320, lr = 0.000855149
I0808 15:14:19.141770 20451 solver.cpp:228] Iteration 2330, loss = 0.125031
I0808 15:14:19.141822 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:14:19.141837 20451 solver.cpp:244]     Train net output #1: loss = 0.125031 (* 1 = 0.125031 loss)
I0808 15:14:19.141849 20451 sgd_solver.cpp:106] Iteration 2330, lr = 0.000854629
I0808 15:14:41.540191 20451 solver.cpp:228] Iteration 2340, loss = 0.125308
I0808 15:14:41.540282 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:14:41.540297 20451 solver.cpp:244]     Train net output #1: loss = 0.125308 (* 1 = 0.125308 loss)
I0808 15:14:41.540310 20451 sgd_solver.cpp:106] Iteration 2340, lr = 0.00085411
I0808 15:15:03.993878 20451 solver.cpp:228] Iteration 2350, loss = 0.18766
I0808 15:15:03.993923 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:15:03.993938 20451 solver.cpp:244]     Train net output #1: loss = 0.18766 (* 1 = 0.18766 loss)
I0808 15:15:03.993952 20451 sgd_solver.cpp:106] Iteration 2350, lr = 0.000853591
I0808 15:15:26.432298 20451 solver.cpp:228] Iteration 2360, loss = 0.219013
I0808 15:15:26.439457 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:15:26.439527 20451 solver.cpp:244]     Train net output #1: loss = 0.219013 (* 1 = 0.219013 loss)
I0808 15:15:26.439574 20451 sgd_solver.cpp:106] Iteration 2360, lr = 0.000853073
I0808 15:15:48.892547 20451 solver.cpp:228] Iteration 2370, loss = 0.187721
I0808 15:15:48.892596 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:15:48.892611 20451 solver.cpp:244]     Train net output #1: loss = 0.187721 (* 1 = 0.187721 loss)
I0808 15:15:48.892622 20451 sgd_solver.cpp:106] Iteration 2370, lr = 0.000852556
I0808 15:16:11.242815 20451 solver.cpp:228] Iteration 2380, loss = 0.0938993
I0808 15:16:11.242992 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:16:11.243008 20451 solver.cpp:244]     Train net output #1: loss = 0.0938993 (* 1 = 0.0938993 loss)
I0808 15:16:11.243021 20451 sgd_solver.cpp:106] Iteration 2380, lr = 0.000852039
I0808 15:16:33.565274 20451 solver.cpp:228] Iteration 2390, loss = 0.28144
I0808 15:16:33.565325 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:16:33.565338 20451 solver.cpp:244]     Train net output #1: loss = 0.28144 (* 1 = 0.28144 loss)
I0808 15:16:33.565351 20451 sgd_solver.cpp:106] Iteration 2390, lr = 0.000851523
I0808 15:16:53.667043 20451 solver.cpp:337] Iteration 2400, Testing net (#0)
I0808 15:17:02.219825 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 15:17:02.219868 20451 solver.cpp:404]     Test net output #1: loss = 0.976092 (* 1 = 0.976092 loss)
I0808 15:17:04.431413 20451 solver.cpp:228] Iteration 2400, loss = 0.218991
I0808 15:17:04.431452 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:17:04.431468 20451 solver.cpp:244]     Train net output #1: loss = 0.218991 (* 1 = 0.218991 loss)
I0808 15:17:04.431479 20451 sgd_solver.cpp:106] Iteration 2400, lr = 0.000851008
I0808 15:17:27.227342 20451 solver.cpp:228] Iteration 2410, loss = 0.281461
I0808 15:17:27.227533 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:17:27.227550 20451 solver.cpp:244]     Train net output #1: loss = 0.281461 (* 1 = 0.281461 loss)
I0808 15:17:27.227563 20451 sgd_solver.cpp:106] Iteration 2410, lr = 0.000850494
I0808 15:17:49.545092 20451 solver.cpp:228] Iteration 2420, loss = 0.18775
I0808 15:17:49.545138 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:17:49.545156 20451 solver.cpp:244]     Train net output #1: loss = 0.18775 (* 1 = 0.18775 loss)
I0808 15:17:49.545169 20451 sgd_solver.cpp:106] Iteration 2420, lr = 0.00084998
I0808 15:18:12.093502 20451 solver.cpp:228] Iteration 2430, loss = 0.156423
I0808 15:18:12.093685 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:18:12.093703 20451 solver.cpp:244]     Train net output #1: loss = 0.156423 (* 1 = 0.156423 loss)
I0808 15:18:12.093719 20451 sgd_solver.cpp:106] Iteration 2430, lr = 0.000849467
I0808 15:18:34.512042 20451 solver.cpp:228] Iteration 2440, loss = 0.125175
I0808 15:18:34.512091 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 15:18:34.512105 20451 solver.cpp:244]     Train net output #1: loss = 0.125175 (* 1 = 0.125175 loss)
I0808 15:18:34.512118 20451 sgd_solver.cpp:106] Iteration 2440, lr = 0.000848955
I0808 15:18:56.926412 20451 solver.cpp:228] Iteration 2450, loss = 0.312755
I0808 15:18:56.926595 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:18:56.926611 20451 solver.cpp:244]     Train net output #1: loss = 0.312755 (* 1 = 0.312755 loss)
I0808 15:18:56.926625 20451 sgd_solver.cpp:106] Iteration 2450, lr = 0.000848444
I0808 15:19:19.340189 20451 solver.cpp:228] Iteration 2460, loss = 0.250298
I0808 15:19:19.340240 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:19:19.340253 20451 solver.cpp:244]     Train net output #1: loss = 0.250298 (* 1 = 0.250298 loss)
I0808 15:19:19.340265 20451 sgd_solver.cpp:106] Iteration 2460, lr = 0.000847933
I0808 15:19:41.796838 20451 solver.cpp:228] Iteration 2470, loss = 0.156461
I0808 15:19:41.797008 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:19:41.797024 20451 solver.cpp:244]     Train net output #1: loss = 0.156461 (* 1 = 0.156461 loss)
I0808 15:19:41.797036 20451 sgd_solver.cpp:106] Iteration 2470, lr = 0.000847423
I0808 15:20:04.118541 20451 solver.cpp:228] Iteration 2480, loss = 0.125139
I0808 15:20:04.118584 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:20:04.118599 20451 solver.cpp:244]     Train net output #1: loss = 0.125139 (* 1 = 0.125139 loss)
I0808 15:20:04.118613 20451 sgd_solver.cpp:106] Iteration 2480, lr = 0.000846914
I0808 15:20:26.517531 20451 solver.cpp:228] Iteration 2490, loss = 0.281382
I0808 15:20:26.517711 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:20:26.517727 20451 solver.cpp:244]     Train net output #1: loss = 0.281382 (* 1 = 0.281382 loss)
I0808 15:20:26.517740 20451 sgd_solver.cpp:106] Iteration 2490, lr = 0.000846405
I0808 15:20:46.711724 20451 solver.cpp:337] Iteration 2500, Testing net (#0)
I0808 15:20:55.304790 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 15:20:55.304839 20451 solver.cpp:404]     Test net output #1: loss = 0.994213 (* 1 = 0.994213 loss)
I0808 15:20:57.520342 20451 solver.cpp:228] Iteration 2500, loss = 0.156367
I0808 15:20:57.520447 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:20:57.520467 20451 solver.cpp:244]     Train net output #1: loss = 0.156367 (* 1 = 0.156367 loss)
I0808 15:20:57.520483 20451 sgd_solver.cpp:106] Iteration 2500, lr = 0.000845897
I0808 15:21:19.959780 20451 solver.cpp:228] Iteration 2510, loss = 0.188128
I0808 15:21:19.959822 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:21:19.959847 20451 solver.cpp:244]     Train net output #1: loss = 0.188128 (* 1 = 0.188128 loss)
I0808 15:21:19.959862 20451 sgd_solver.cpp:106] Iteration 2510, lr = 0.00084539
I0808 15:21:42.315737 20451 solver.cpp:228] Iteration 2520, loss = 0.0313336
I0808 15:21:42.315959 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 15:21:42.315974 20451 solver.cpp:244]     Train net output #1: loss = 0.0313336 (* 1 = 0.0313336 loss)
I0808 15:21:42.315987 20451 sgd_solver.cpp:106] Iteration 2520, lr = 0.000844883
I0808 15:22:04.707409 20451 solver.cpp:228] Iteration 2530, loss = 0.125097
I0808 15:22:04.707453 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:22:04.707470 20451 solver.cpp:244]     Train net output #1: loss = 0.125097 (* 1 = 0.125097 loss)
I0808 15:22:04.707485 20451 sgd_solver.cpp:106] Iteration 2530, lr = 0.000844378
I0808 15:22:27.029963 20451 solver.cpp:228] Iteration 2540, loss = 0.15653
I0808 15:22:27.030143 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:22:27.030161 20451 solver.cpp:244]     Train net output #1: loss = 0.15653 (* 1 = 0.15653 loss)
I0808 15:22:27.030177 20451 sgd_solver.cpp:106] Iteration 2540, lr = 0.000843873
I0808 15:22:49.338738 20451 solver.cpp:228] Iteration 2550, loss = 0.156387
I0808 15:22:49.338785 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:22:49.338804 20451 solver.cpp:244]     Train net output #1: loss = 0.156387 (* 1 = 0.156387 loss)
I0808 15:22:49.338829 20451 sgd_solver.cpp:106] Iteration 2550, lr = 0.000843368
I0808 15:23:11.746953 20451 solver.cpp:228] Iteration 2560, loss = 0.187657
I0808 15:23:11.747130 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:23:11.747145 20451 solver.cpp:244]     Train net output #1: loss = 0.187657 (* 1 = 0.187657 loss)
I0808 15:23:11.747158 20451 sgd_solver.cpp:106] Iteration 2560, lr = 0.000842865
I0808 15:23:34.209746 20451 solver.cpp:228] Iteration 2570, loss = 0.125092
I0808 15:23:34.209797 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:23:34.209811 20451 solver.cpp:244]     Train net output #1: loss = 0.125092 (* 1 = 0.125092 loss)
I0808 15:23:34.209825 20451 sgd_solver.cpp:106] Iteration 2570, lr = 0.000842362
I0808 15:23:56.635365 20451 solver.cpp:228] Iteration 2580, loss = 0.219025
I0808 15:23:56.635547 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:23:56.635567 20451 solver.cpp:244]     Train net output #1: loss = 0.219025 (* 1 = 0.219025 loss)
I0808 15:23:56.635582 20451 sgd_solver.cpp:106] Iteration 2580, lr = 0.000841859
I0808 15:24:18.990988 20451 solver.cpp:228] Iteration 2590, loss = 0.12502
I0808 15:24:18.991032 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:24:18.991049 20451 solver.cpp:244]     Train net output #1: loss = 0.12502 (* 1 = 0.12502 loss)
I0808 15:24:18.991062 20451 sgd_solver.cpp:106] Iteration 2590, lr = 0.000841358
I0808 15:24:39.166944 20451 solver.cpp:337] Iteration 2600, Testing net (#0)
I0808 15:24:47.731348 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 15:24:47.731394 20451 solver.cpp:404]     Test net output #1: loss = 1.00412 (* 1 = 1.00412 loss)
I0808 15:24:49.948987 20451 solver.cpp:228] Iteration 2600, loss = 0.281496
I0808 15:24:49.949029 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:24:49.949048 20451 solver.cpp:244]     Train net output #1: loss = 0.281496 (* 1 = 0.281496 loss)
I0808 15:24:49.949074 20451 sgd_solver.cpp:106] Iteration 2600, lr = 0.000840857
I0808 15:25:12.367163 20451 solver.cpp:228] Iteration 2610, loss = 0.18769
I0808 15:25:12.367347 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:25:12.367364 20451 solver.cpp:244]     Train net output #1: loss = 0.18769 (* 1 = 0.18769 loss)
I0808 15:25:12.367379 20451 sgd_solver.cpp:106] Iteration 2610, lr = 0.000840357
I0808 15:25:34.829051 20451 solver.cpp:228] Iteration 2620, loss = 0.15641
I0808 15:25:34.829104 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:25:34.829124 20451 solver.cpp:244]     Train net output #1: loss = 0.15641 (* 1 = 0.15641 loss)
I0808 15:25:34.829140 20451 sgd_solver.cpp:106] Iteration 2620, lr = 0.000839857
I0808 15:25:57.232146 20451 solver.cpp:228] Iteration 2630, loss = 7.36117e-06
I0808 15:25:57.232296 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 15:25:57.232312 20451 solver.cpp:244]     Train net output #1: loss = 7.35838e-06 (* 1 = 7.35838e-06 loss)
I0808 15:25:57.232326 20451 sgd_solver.cpp:106] Iteration 2630, lr = 0.000839359
I0808 15:26:19.707499 20451 solver.cpp:228] Iteration 2640, loss = 0.125122
I0808 15:26:19.707545 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:26:19.707561 20451 solver.cpp:244]     Train net output #1: loss = 0.125122 (* 1 = 0.125122 loss)
I0808 15:26:19.707576 20451 sgd_solver.cpp:106] Iteration 2640, lr = 0.00083886
I0808 15:26:42.203927 20451 solver.cpp:228] Iteration 2650, loss = 0.156681
I0808 15:26:42.204109 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:26:42.204124 20451 solver.cpp:244]     Train net output #1: loss = 0.156681 (* 1 = 0.156681 loss)
I0808 15:26:42.204138 20451 sgd_solver.cpp:106] Iteration 2650, lr = 0.000838363
I0808 15:27:04.646051 20451 solver.cpp:228] Iteration 2660, loss = 0.187736
I0808 15:27:04.646103 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:27:04.646117 20451 solver.cpp:244]     Train net output #1: loss = 0.187736 (* 1 = 0.187736 loss)
I0808 15:27:04.646129 20451 sgd_solver.cpp:106] Iteration 2660, lr = 0.000837866
I0808 15:27:27.021026 20451 solver.cpp:228] Iteration 2670, loss = 0.12513
I0808 15:27:27.021193 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:27:27.021209 20451 solver.cpp:244]     Train net output #1: loss = 0.12513 (* 1 = 0.12513 loss)
I0808 15:27:27.021221 20451 sgd_solver.cpp:106] Iteration 2670, lr = 0.00083737
I0808 15:27:49.365458 20451 solver.cpp:228] Iteration 2680, loss = 0.281501
I0808 15:27:49.365507 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:27:49.365520 20451 solver.cpp:244]     Train net output #1: loss = 0.281501 (* 1 = 0.281501 loss)
I0808 15:27:49.365532 20451 sgd_solver.cpp:106] Iteration 2680, lr = 0.000836875
I0808 15:28:11.708848 20451 solver.cpp:228] Iteration 2690, loss = 0.156308
I0808 15:28:11.709029 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:28:11.709044 20451 solver.cpp:244]     Train net output #1: loss = 0.156308 (* 1 = 0.156308 loss)
I0808 15:28:11.709058 20451 sgd_solver.cpp:106] Iteration 2690, lr = 0.00083638
I0808 15:28:31.944339 20451 solver.cpp:337] Iteration 2700, Testing net (#0)
I0808 15:28:40.472810 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0808 15:28:40.472880 20451 solver.cpp:404]     Test net output #1: loss = 0.966262 (* 1 = 0.966262 loss)
I0808 15:28:42.699573 20451 solver.cpp:228] Iteration 2700, loss = 0.0939152
I0808 15:28:42.699688 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:28:42.699707 20451 solver.cpp:244]     Train net output #1: loss = 0.0939152 (* 1 = 0.0939152 loss)
I0808 15:28:42.699720 20451 sgd_solver.cpp:106] Iteration 2700, lr = 0.000835886
I0808 15:29:05.079622 20451 solver.cpp:228] Iteration 2710, loss = 0.250092
I0808 15:29:05.079674 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:29:05.079687 20451 solver.cpp:244]     Train net output #1: loss = 0.250092 (* 1 = 0.250092 loss)
I0808 15:29:05.079699 20451 sgd_solver.cpp:106] Iteration 2710, lr = 0.000835393
I0808 15:29:27.470602 20451 solver.cpp:228] Iteration 2720, loss = 0.219022
I0808 15:29:27.470783 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:29:27.470798 20451 solver.cpp:244]     Train net output #1: loss = 0.219022 (* 1 = 0.219022 loss)
I0808 15:29:27.470811 20451 sgd_solver.cpp:106] Iteration 2720, lr = 0.0008349
I0808 15:29:49.945031 20451 solver.cpp:228] Iteration 2730, loss = 0.250337
I0808 15:29:49.945082 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:29:49.945096 20451 solver.cpp:244]     Train net output #1: loss = 0.250337 (* 1 = 0.250337 loss)
I0808 15:29:49.945109 20451 sgd_solver.cpp:106] Iteration 2730, lr = 0.000834409
I0808 15:30:12.328229 20451 solver.cpp:228] Iteration 2740, loss = 0.0938138
I0808 15:30:12.328438 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:30:12.328452 20451 solver.cpp:244]     Train net output #1: loss = 0.0938138 (* 1 = 0.0938138 loss)
I0808 15:30:12.328465 20451 sgd_solver.cpp:106] Iteration 2740, lr = 0.000833917
I0808 15:30:34.831670 20451 solver.cpp:228] Iteration 2750, loss = 0.125124
I0808 15:30:34.831718 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:30:34.831738 20451 solver.cpp:244]     Train net output #1: loss = 0.125124 (* 1 = 0.125124 loss)
I0808 15:30:34.831754 20451 sgd_solver.cpp:106] Iteration 2750, lr = 0.000833427
I0808 15:30:57.382884 20451 solver.cpp:228] Iteration 2760, loss = 0.218847
I0808 15:30:57.383057 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:30:57.383072 20451 solver.cpp:244]     Train net output #1: loss = 0.218847 (* 1 = 0.218847 loss)
I0808 15:30:57.383085 20451 sgd_solver.cpp:106] Iteration 2760, lr = 0.000832937
I0808 15:31:19.807144 20451 solver.cpp:228] Iteration 2770, loss = 0.125289
I0808 15:31:19.807191 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 15:31:19.807209 20451 solver.cpp:244]     Train net output #1: loss = 0.125289 (* 1 = 0.125289 loss)
I0808 15:31:19.807224 20451 sgd_solver.cpp:106] Iteration 2770, lr = 0.000832447
I0808 15:31:42.247968 20451 solver.cpp:228] Iteration 2780, loss = 0.187748
I0808 15:31:42.248113 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:31:42.248142 20451 solver.cpp:244]     Train net output #1: loss = 0.187748 (* 1 = 0.187748 loss)
I0808 15:31:42.248164 20451 sgd_solver.cpp:106] Iteration 2780, lr = 0.000831959
I0808 15:32:04.643615 20451 solver.cpp:228] Iteration 2790, loss = 0.250189
I0808 15:32:04.643656 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:32:04.643671 20451 solver.cpp:244]     Train net output #1: loss = 0.250189 (* 1 = 0.250189 loss)
I0808 15:32:04.643682 20451 sgd_solver.cpp:106] Iteration 2790, lr = 0.000831471
I0808 15:32:24.747889 20451 solver.cpp:337] Iteration 2800, Testing net (#0)
I0808 15:32:33.465204 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0808 15:32:33.465251 20451 solver.cpp:404]     Test net output #1: loss = 1.03243 (* 1 = 1.03243 loss)
I0808 15:32:35.671028 20451 solver.cpp:228] Iteration 2800, loss = 0.156668
I0808 15:32:35.671069 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:32:35.671087 20451 solver.cpp:244]     Train net output #1: loss = 0.156668 (* 1 = 0.156668 loss)
I0808 15:32:35.671103 20451 sgd_solver.cpp:106] Iteration 2800, lr = 0.000830984
I0808 15:32:58.033015 20451 solver.cpp:228] Iteration 2810, loss = 0.281402
I0808 15:32:58.033188 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:32:58.033203 20451 solver.cpp:244]     Train net output #1: loss = 0.281402 (* 1 = 0.281402 loss)
I0808 15:32:58.033216 20451 sgd_solver.cpp:106] Iteration 2810, lr = 0.000830497
I0808 15:33:20.410754 20451 solver.cpp:228] Iteration 2820, loss = 0.281318
I0808 15:33:20.410799 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:33:20.410814 20451 solver.cpp:244]     Train net output #1: loss = 0.281318 (* 1 = 0.281318 loss)
I0808 15:33:20.410826 20451 sgd_solver.cpp:106] Iteration 2820, lr = 0.000830011
I0808 15:33:42.772768 20451 solver.cpp:228] Iteration 2830, loss = 0.312913
I0808 15:33:42.772949 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 15:33:42.772964 20451 solver.cpp:244]     Train net output #1: loss = 0.312913 (* 1 = 0.312913 loss)
I0808 15:33:42.772977 20451 sgd_solver.cpp:106] Iteration 2830, lr = 0.000829526
I0808 15:34:05.180768 20451 solver.cpp:228] Iteration 2840, loss = 0.187567
I0808 15:34:05.180806 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:34:05.180824 20451 solver.cpp:244]     Train net output #1: loss = 0.187567 (* 1 = 0.187567 loss)
I0808 15:34:05.180837 20451 sgd_solver.cpp:106] Iteration 2840, lr = 0.000829042
I0808 15:34:27.562726 20451 solver.cpp:228] Iteration 2850, loss = 0.187749
I0808 15:34:27.563046 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:34:27.563063 20451 solver.cpp:244]     Train net output #1: loss = 0.187749 (* 1 = 0.187749 loss)
I0808 15:34:27.563076 20451 sgd_solver.cpp:106] Iteration 2850, lr = 0.000828558
I0808 15:34:49.956217 20451 solver.cpp:228] Iteration 2860, loss = 0.156415
I0808 15:34:49.956267 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:34:49.956281 20451 solver.cpp:244]     Train net output #1: loss = 0.156415 (* 1 = 0.156415 loss)
I0808 15:34:49.956295 20451 sgd_solver.cpp:106] Iteration 2860, lr = 0.000828074
I0808 15:35:12.414010 20451 solver.cpp:228] Iteration 2870, loss = 0.156393
I0808 15:35:12.414185 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:35:12.414199 20451 solver.cpp:244]     Train net output #1: loss = 0.156393 (* 1 = 0.156393 loss)
I0808 15:35:12.414212 20451 sgd_solver.cpp:106] Iteration 2870, lr = 0.000827592
I0808 15:35:34.876221 20451 solver.cpp:228] Iteration 2880, loss = 0.0938132
I0808 15:35:34.876274 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:35:34.876296 20451 solver.cpp:244]     Train net output #1: loss = 0.0938133 (* 1 = 0.0938133 loss)
I0808 15:35:34.876312 20451 sgd_solver.cpp:106] Iteration 2880, lr = 0.00082711
I0808 15:35:57.188261 20451 solver.cpp:228] Iteration 2890, loss = 0.125198
I0808 15:35:57.188428 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:35:57.188443 20451 solver.cpp:244]     Train net output #1: loss = 0.125198 (* 1 = 0.125198 loss)
I0808 15:35:57.188457 20451 sgd_solver.cpp:106] Iteration 2890, lr = 0.000826628
I0808 15:36:17.284449 20451 solver.cpp:337] Iteration 2900, Testing net (#0)
I0808 15:36:25.829891 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 15:36:25.829942 20451 solver.cpp:404]     Test net output #1: loss = 1.00337 (* 1 = 1.00337 loss)
I0808 15:36:28.030655 20451 solver.cpp:228] Iteration 2900, loss = 0.21887
I0808 15:36:28.030838 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 15:36:28.030853 20451 solver.cpp:244]     Train net output #1: loss = 0.21887 (* 1 = 0.21887 loss)
I0808 15:36:28.030866 20451 sgd_solver.cpp:106] Iteration 2900, lr = 0.000826148
I0808 15:36:50.405305 20451 solver.cpp:228] Iteration 2910, loss = 0.281944
I0808 15:36:50.405349 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:36:50.405367 20451 solver.cpp:244]     Train net output #1: loss = 0.281945 (* 1 = 0.281945 loss)
I0808 15:36:50.405383 20451 sgd_solver.cpp:106] Iteration 2910, lr = 0.000825668
I0808 15:37:12.802182 20451 solver.cpp:228] Iteration 2920, loss = 0.0937969
I0808 15:37:12.802358 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:37:12.802374 20451 solver.cpp:244]     Train net output #1: loss = 0.093797 (* 1 = 0.093797 loss)
I0808 15:37:12.802387 20451 sgd_solver.cpp:106] Iteration 2920, lr = 0.000825188
I0808 15:37:35.124209 20451 solver.cpp:228] Iteration 2930, loss = 0.187554
I0808 15:37:35.124259 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:37:35.124274 20451 solver.cpp:244]     Train net output #1: loss = 0.187554 (* 1 = 0.187554 loss)
I0808 15:37:35.124285 20451 sgd_solver.cpp:106] Iteration 2930, lr = 0.00082471
I0808 15:37:57.474030 20451 solver.cpp:228] Iteration 2940, loss = 0.187836
I0808 15:37:57.474244 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:37:57.474259 20451 solver.cpp:244]     Train net output #1: loss = 0.187836 (* 1 = 0.187836 loss)
I0808 15:37:57.474272 20451 sgd_solver.cpp:106] Iteration 2940, lr = 0.000824232
I0808 15:38:19.793623 20451 solver.cpp:228] Iteration 2950, loss = 0.125128
I0808 15:38:19.793673 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:38:19.793690 20451 solver.cpp:244]     Train net output #1: loss = 0.125128 (* 1 = 0.125128 loss)
I0808 15:38:19.793706 20451 sgd_solver.cpp:106] Iteration 2950, lr = 0.000823754
I0808 15:38:42.342224 20451 solver.cpp:228] Iteration 2960, loss = 0.125124
I0808 15:38:42.342370 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 15:38:42.342388 20451 solver.cpp:244]     Train net output #1: loss = 0.125124 (* 1 = 0.125124 loss)
I0808 15:38:42.342403 20451 sgd_solver.cpp:106] Iteration 2960, lr = 0.000823278
I0808 15:39:04.759882 20451 solver.cpp:228] Iteration 2970, loss = 0.218961
I0808 15:39:04.759940 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:39:04.759958 20451 solver.cpp:244]     Train net output #1: loss = 0.218961 (* 1 = 0.218961 loss)
I0808 15:39:04.759970 20451 sgd_solver.cpp:106] Iteration 2970, lr = 0.000822801
I0808 15:39:27.148032 20451 solver.cpp:228] Iteration 2980, loss = 0.250291
I0808 15:39:27.148134 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:39:27.148149 20451 solver.cpp:244]     Train net output #1: loss = 0.250291 (* 1 = 0.250291 loss)
I0808 15:39:27.148162 20451 sgd_solver.cpp:106] Iteration 2980, lr = 0.000822326
I0808 15:39:49.474854 20451 solver.cpp:228] Iteration 2990, loss = 0.187659
I0808 15:39:49.474905 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:39:49.474918 20451 solver.cpp:244]     Train net output #1: loss = 0.187659 (* 1 = 0.187659 loss)
I0808 15:39:49.474931 20451 sgd_solver.cpp:106] Iteration 2990, lr = 0.000821851
I0808 15:40:09.609297 20451 solver.cpp:337] Iteration 3000, Testing net (#0)
I0808 15:40:18.177182 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 15:40:18.177233 20451 solver.cpp:404]     Test net output #1: loss = 0.985109 (* 1 = 0.985109 loss)
I0808 15:40:20.401227 20451 solver.cpp:228] Iteration 3000, loss = 0.281468
I0808 15:40:20.401278 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:40:20.401293 20451 solver.cpp:244]     Train net output #1: loss = 0.281468 (* 1 = 0.281468 loss)
I0808 15:40:20.401304 20451 sgd_solver.cpp:106] Iteration 3000, lr = 0.000821377
I0808 15:40:42.879515 20451 solver.cpp:228] Iteration 3010, loss = 0.156431
I0808 15:40:42.879694 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:40:42.879712 20451 solver.cpp:244]     Train net output #1: loss = 0.156431 (* 1 = 0.156431 loss)
I0808 15:40:42.879729 20451 sgd_solver.cpp:106] Iteration 3010, lr = 0.000820903
I0808 15:41:05.290834 20451 solver.cpp:228] Iteration 3020, loss = 0.187603
I0808 15:41:05.290892 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:41:05.290906 20451 solver.cpp:244]     Train net output #1: loss = 0.187603 (* 1 = 0.187603 loss)
I0808 15:41:05.290918 20451 sgd_solver.cpp:106] Iteration 3020, lr = 0.00082043
I0808 15:41:27.707897 20451 solver.cpp:228] Iteration 3030, loss = 0.218824
I0808 15:41:27.707995 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:41:27.708010 20451 solver.cpp:244]     Train net output #1: loss = 0.218824 (* 1 = 0.218824 loss)
I0808 15:41:27.708024 20451 sgd_solver.cpp:106] Iteration 3030, lr = 0.000819958
I0808 15:41:50.047066 20451 solver.cpp:228] Iteration 3040, loss = 0.187612
I0808 15:41:50.047116 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 15:41:50.047130 20451 solver.cpp:244]     Train net output #1: loss = 0.187612 (* 1 = 0.187612 loss)
I0808 15:41:50.047143 20451 sgd_solver.cpp:106] Iteration 3040, lr = 0.000819487
I0808 15:42:12.414417 20451 solver.cpp:228] Iteration 3050, loss = 0.187598
I0808 15:42:12.414592 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:42:12.414608 20451 solver.cpp:244]     Train net output #1: loss = 0.187598 (* 1 = 0.187598 loss)
I0808 15:42:12.414620 20451 sgd_solver.cpp:106] Iteration 3050, lr = 0.000819015
I0808 15:42:34.770931 20451 solver.cpp:228] Iteration 3060, loss = 0.0938431
I0808 15:42:34.770978 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 15:42:34.770998 20451 solver.cpp:244]     Train net output #1: loss = 0.0938431 (* 1 = 0.0938431 loss)
I0808 15:42:34.771014 20451 sgd_solver.cpp:106] Iteration 3060, lr = 0.000818545
I0808 15:42:57.170967 20451 solver.cpp:228] Iteration 3070, loss = 0.0938309
I0808 15:42:57.171113 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:42:57.171128 20451 solver.cpp:244]     Train net output #1: loss = 0.0938309 (* 1 = 0.0938309 loss)
I0808 15:42:57.171141 20451 sgd_solver.cpp:106] Iteration 3070, lr = 0.000818075
I0808 15:43:19.494761 20451 solver.cpp:228] Iteration 3080, loss = 0.125187
I0808 15:43:19.494812 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:43:19.494825 20451 solver.cpp:244]     Train net output #1: loss = 0.125187 (* 1 = 0.125187 loss)
I0808 15:43:19.494838 20451 sgd_solver.cpp:106] Iteration 3080, lr = 0.000817606
I0808 15:43:41.812258 20451 solver.cpp:228] Iteration 3090, loss = 0.125395
I0808 15:43:41.812444 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:43:41.812463 20451 solver.cpp:244]     Train net output #1: loss = 0.125395 (* 1 = 0.125395 loss)
I0808 15:43:41.812479 20451 sgd_solver.cpp:106] Iteration 3090, lr = 0.000817138
I0808 15:44:01.934962 20451 solver.cpp:337] Iteration 3100, Testing net (#0)
I0808 15:44:10.446214 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 15:44:10.446259 20451 solver.cpp:404]     Test net output #1: loss = 0.999039 (* 1 = 0.999039 loss)
I0808 15:44:12.647930 20451 solver.cpp:228] Iteration 3100, loss = 0.187711
I0808 15:44:12.648100 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:44:12.648119 20451 solver.cpp:244]     Train net output #1: loss = 0.187711 (* 1 = 0.187711 loss)
I0808 15:44:12.648135 20451 sgd_solver.cpp:106] Iteration 3100, lr = 0.00081667
I0808 15:44:34.994691 20451 solver.cpp:228] Iteration 3110, loss = 0.156629
I0808 15:44:34.994737 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:44:34.994753 20451 solver.cpp:244]     Train net output #1: loss = 0.156629 (* 1 = 0.156629 loss)
I0808 15:44:34.994766 20451 sgd_solver.cpp:106] Iteration 3110, lr = 0.000816203
I0808 15:44:57.390466 20451 solver.cpp:228] Iteration 3120, loss = 0.187636
I0808 15:44:57.390645 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:44:57.390661 20451 solver.cpp:244]     Train net output #1: loss = 0.187636 (* 1 = 0.187636 loss)
I0808 15:44:57.390673 20451 sgd_solver.cpp:106] Iteration 3120, lr = 0.000815736
I0808 15:45:19.795879 20451 solver.cpp:228] Iteration 3130, loss = 0.156547
I0808 15:45:19.795936 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:45:19.795953 20451 solver.cpp:244]     Train net output #1: loss = 0.156547 (* 1 = 0.156547 loss)
I0808 15:45:19.795965 20451 sgd_solver.cpp:106] Iteration 3130, lr = 0.00081527
I0808 15:45:42.235988 20451 solver.cpp:228] Iteration 3140, loss = 0.187547
I0808 15:45:42.236177 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:45:42.236193 20451 solver.cpp:244]     Train net output #1: loss = 0.187547 (* 1 = 0.187547 loss)
I0808 15:45:42.236205 20451 sgd_solver.cpp:106] Iteration 3140, lr = 0.000814805
I0808 15:46:04.717478 20451 solver.cpp:228] Iteration 3150, loss = 0.281578
I0808 15:46:04.717526 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:46:04.717545 20451 solver.cpp:244]     Train net output #1: loss = 0.281578 (* 1 = 0.281578 loss)
I0808 15:46:04.717561 20451 sgd_solver.cpp:106] Iteration 3150, lr = 0.00081434
I0808 15:46:27.247181 20451 solver.cpp:228] Iteration 3160, loss = 0.344002
I0808 15:46:27.247369 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 15:46:27.247387 20451 solver.cpp:244]     Train net output #1: loss = 0.344002 (* 1 = 0.344002 loss)
I0808 15:46:27.247402 20451 sgd_solver.cpp:106] Iteration 3160, lr = 0.000813876
I0808 15:46:49.668377 20451 solver.cpp:228] Iteration 3170, loss = 0.0937868
I0808 15:46:49.668419 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:46:49.668437 20451 solver.cpp:244]     Train net output #1: loss = 0.0937868 (* 1 = 0.0937868 loss)
I0808 15:46:49.668452 20451 sgd_solver.cpp:106] Iteration 3170, lr = 0.000813412
I0808 15:47:12.016758 20451 solver.cpp:228] Iteration 3180, loss = 0.125171
I0808 15:47:12.016975 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:47:12.016990 20451 solver.cpp:244]     Train net output #1: loss = 0.125171 (* 1 = 0.125171 loss)
I0808 15:47:12.017004 20451 sgd_solver.cpp:106] Iteration 3180, lr = 0.000812949
I0808 15:47:34.449002 20451 solver.cpp:228] Iteration 3190, loss = 0.0938836
I0808 15:47:34.449054 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:47:34.449069 20451 solver.cpp:244]     Train net output #1: loss = 0.0938836 (* 1 = 0.0938836 loss)
I0808 15:47:34.449080 20451 sgd_solver.cpp:106] Iteration 3190, lr = 0.000812487
I0808 15:47:54.659621 20451 solver.cpp:337] Iteration 3200, Testing net (#0)
I0808 15:48:03.228955 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 15:48:03.229007 20451 solver.cpp:404]     Test net output #1: loss = 0.99904 (* 1 = 0.99904 loss)
I0808 15:48:05.446072 20451 solver.cpp:228] Iteration 3200, loss = 0.156381
I0808 15:48:05.446121 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:48:05.446135 20451 solver.cpp:244]     Train net output #1: loss = 0.156381 (* 1 = 0.156381 loss)
I0808 15:48:05.446147 20451 sgd_solver.cpp:106] Iteration 3200, lr = 0.000812025
I0808 15:48:27.871004 20451 solver.cpp:228] Iteration 3210, loss = 0.156477
I0808 15:48:27.871178 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 15:48:27.871196 20451 solver.cpp:244]     Train net output #1: loss = 0.156477 (* 1 = 0.156477 loss)
I0808 15:48:27.871208 20451 sgd_solver.cpp:106] Iteration 3210, lr = 0.000811564
I0808 15:48:50.289264 20451 solver.cpp:228] Iteration 3220, loss = 0.187646
I0808 15:48:50.289307 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:48:50.289321 20451 solver.cpp:244]     Train net output #1: loss = 0.187646 (* 1 = 0.187646 loss)
I0808 15:48:50.289335 20451 sgd_solver.cpp:106] Iteration 3220, lr = 0.000811104
I0808 15:49:12.641312 20451 solver.cpp:228] Iteration 3230, loss = 0.125036
I0808 15:49:12.641413 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:49:12.641428 20451 solver.cpp:244]     Train net output #1: loss = 0.125036 (* 1 = 0.125036 loss)
I0808 15:49:12.641441 20451 sgd_solver.cpp:106] Iteration 3230, lr = 0.000810644
I0808 15:49:34.968264 20451 solver.cpp:228] Iteration 3240, loss = 0.125099
I0808 15:49:34.968303 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:49:34.968320 20451 solver.cpp:244]     Train net output #1: loss = 0.125099 (* 1 = 0.125099 loss)
I0808 15:49:34.968333 20451 sgd_solver.cpp:106] Iteration 3240, lr = 0.000810185
I0808 15:49:57.465616 20451 solver.cpp:228] Iteration 3250, loss = 0.0313114
I0808 15:49:57.465719 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 15:49:57.465735 20451 solver.cpp:244]     Train net output #1: loss = 0.0313114 (* 1 = 0.0313114 loss)
I0808 15:49:57.465749 20451 sgd_solver.cpp:106] Iteration 3250, lr = 0.000809726
I0808 15:50:19.955224 20451 solver.cpp:228] Iteration 3260, loss = 0.250113
I0808 15:50:19.955282 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:50:19.955297 20451 solver.cpp:244]     Train net output #1: loss = 0.250113 (* 1 = 0.250113 loss)
I0808 15:50:19.955310 20451 sgd_solver.cpp:106] Iteration 3260, lr = 0.000809268
I0808 15:50:42.434252 20451 solver.cpp:228] Iteration 3270, loss = 0.250131
I0808 15:50:42.434429 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:50:42.434448 20451 solver.cpp:244]     Train net output #1: loss = 0.250131 (* 1 = 0.250131 loss)
I0808 15:50:42.434463 20451 sgd_solver.cpp:106] Iteration 3270, lr = 0.000808811
I0808 15:51:04.874830 20451 solver.cpp:228] Iteration 3280, loss = 0.281486
I0808 15:51:04.874884 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:51:04.874898 20451 solver.cpp:244]     Train net output #1: loss = 0.281486 (* 1 = 0.281486 loss)
I0808 15:51:04.874912 20451 sgd_solver.cpp:106] Iteration 3280, lr = 0.000808354
I0808 15:51:27.345700 20451 solver.cpp:228] Iteration 3290, loss = 0.125087
I0808 15:51:27.345918 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 15:51:27.345934 20451 solver.cpp:244]     Train net output #1: loss = 0.125087 (* 1 = 0.125087 loss)
I0808 15:51:27.345947 20451 sgd_solver.cpp:106] Iteration 3290, lr = 0.000807898
I0808 15:51:47.490941 20451 solver.cpp:337] Iteration 3300, Testing net (#0)
I0808 15:51:56.026271 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 15:51:56.026319 20451 solver.cpp:404]     Test net output #1: loss = 1.00796 (* 1 = 1.00796 loss)
I0808 15:51:58.230111 20451 solver.cpp:228] Iteration 3300, loss = 0.218927
I0808 15:51:58.230206 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:51:58.230223 20451 solver.cpp:244]     Train net output #1: loss = 0.218927 (* 1 = 0.218927 loss)
I0808 15:51:58.230239 20451 sgd_solver.cpp:106] Iteration 3300, lr = 0.000807442
I0808 15:52:20.591650 20451 solver.cpp:228] Iteration 3310, loss = 0.218841
I0808 15:52:20.591692 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:52:20.591711 20451 solver.cpp:244]     Train net output #1: loss = 0.218841 (* 1 = 0.218841 loss)
I0808 15:52:20.591725 20451 sgd_solver.cpp:106] Iteration 3310, lr = 0.000806987
I0808 15:52:42.987004 20451 solver.cpp:228] Iteration 3320, loss = 0.156323
I0808 15:52:42.987119 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:52:42.987134 20451 solver.cpp:244]     Train net output #1: loss = 0.156323 (* 1 = 0.156323 loss)
I0808 15:52:42.987148 20451 sgd_solver.cpp:106] Iteration 3320, lr = 0.000806532
I0808 15:53:05.353909 20451 solver.cpp:228] Iteration 3330, loss = 0.250114
I0808 15:53:05.353960 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:53:05.353973 20451 solver.cpp:244]     Train net output #1: loss = 0.250114 (* 1 = 0.250114 loss)
I0808 15:53:05.353986 20451 sgd_solver.cpp:106] Iteration 3330, lr = 0.000806079
I0808 15:53:27.708600 20451 solver.cpp:228] Iteration 3340, loss = 0.187656
I0808 15:53:27.708780 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:53:27.708796 20451 solver.cpp:244]     Train net output #1: loss = 0.187656 (* 1 = 0.187656 loss)
I0808 15:53:27.708808 20451 sgd_solver.cpp:106] Iteration 3340, lr = 0.000805625
I0808 15:53:50.062693 20451 solver.cpp:228] Iteration 3350, loss = 0.250199
I0808 15:53:50.062736 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:53:50.062750 20451 solver.cpp:244]     Train net output #1: loss = 0.250199 (* 1 = 0.250199 loss)
I0808 15:53:50.062763 20451 sgd_solver.cpp:106] Iteration 3350, lr = 0.000805173
I0808 15:54:13.039352 20451 solver.cpp:228] Iteration 3360, loss = 0.18755
I0808 15:54:13.039535 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:54:13.039552 20451 solver.cpp:244]     Train net output #1: loss = 0.18755 (* 1 = 0.18755 loss)
I0808 15:54:13.039566 20451 sgd_solver.cpp:106] Iteration 3360, lr = 0.000804721
I0808 15:54:35.489979 20451 solver.cpp:228] Iteration 3370, loss = 0.0938772
I0808 15:54:35.490031 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:54:35.490043 20451 solver.cpp:244]     Train net output #1: loss = 0.0938772 (* 1 = 0.0938772 loss)
I0808 15:54:35.490056 20451 sgd_solver.cpp:106] Iteration 3370, lr = 0.000804269
I0808 15:54:57.895571 20451 solver.cpp:228] Iteration 3380, loss = 0.187702
I0808 15:54:57.895660 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:54:57.895675 20451 solver.cpp:244]     Train net output #1: loss = 0.187701 (* 1 = 0.187701 loss)
I0808 15:54:57.895689 20451 sgd_solver.cpp:106] Iteration 3380, lr = 0.000803818
I0808 15:55:20.218906 20451 solver.cpp:228] Iteration 3390, loss = 0.0938493
I0808 15:55:20.218951 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:55:20.218971 20451 solver.cpp:244]     Train net output #1: loss = 0.0938492 (* 1 = 0.0938492 loss)
I0808 15:55:20.218986 20451 sgd_solver.cpp:106] Iteration 3390, lr = 0.000803368
I0808 15:55:40.433475 20451 solver.cpp:337] Iteration 3400, Testing net (#0)
I0808 15:55:48.976666 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 15:55:48.976717 20451 solver.cpp:404]     Test net output #1: loss = 1.00385 (* 1 = 1.00385 loss)
I0808 15:55:51.183909 20451 solver.cpp:228] Iteration 3400, loss = 0.187664
I0808 15:55:51.183954 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:55:51.183969 20451 solver.cpp:244]     Train net output #1: loss = 0.187664 (* 1 = 0.187664 loss)
I0808 15:55:51.183980 20451 sgd_solver.cpp:106] Iteration 3400, lr = 0.000802918
I0808 15:56:13.690006 20451 solver.cpp:228] Iteration 3410, loss = 0.093767
I0808 15:56:13.690115 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 15:56:13.690131 20451 solver.cpp:244]     Train net output #1: loss = 0.0937669 (* 1 = 0.0937669 loss)
I0808 15:56:13.690150 20451 sgd_solver.cpp:106] Iteration 3410, lr = 0.000802469
I0808 15:56:36.185304 20451 solver.cpp:228] Iteration 3420, loss = 0.0937936
I0808 15:56:36.185353 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 15:56:36.185367 20451 solver.cpp:244]     Train net output #1: loss = 0.0937936 (* 1 = 0.0937936 loss)
I0808 15:56:36.185384 20451 sgd_solver.cpp:106] Iteration 3420, lr = 0.000802021
I0808 15:56:58.642350 20451 solver.cpp:228] Iteration 3430, loss = 0.250057
I0808 15:56:58.642459 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:56:58.642475 20451 solver.cpp:244]     Train net output #1: loss = 0.250057 (* 1 = 0.250057 loss)
I0808 15:56:58.642490 20451 sgd_solver.cpp:106] Iteration 3430, lr = 0.000801573
I0808 15:57:21.130184 20451 solver.cpp:228] Iteration 3440, loss = 0.281421
I0808 15:57:21.130230 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:57:21.130249 20451 solver.cpp:244]     Train net output #1: loss = 0.281421 (* 1 = 0.281421 loss)
I0808 15:57:21.130264 20451 sgd_solver.cpp:106] Iteration 3440, lr = 0.000801126
I0808 15:57:43.577424 20451 solver.cpp:228] Iteration 3450, loss = 0.218836
I0808 15:57:43.577601 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 15:57:43.577617 20451 solver.cpp:244]     Train net output #1: loss = 0.218836 (* 1 = 0.218836 loss)
I0808 15:57:43.577630 20451 sgd_solver.cpp:106] Iteration 3450, lr = 0.000800679
I0808 15:58:05.908041 20451 solver.cpp:228] Iteration 3460, loss = 0.250172
I0808 15:58:05.908092 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 15:58:05.908104 20451 solver.cpp:244]     Train net output #1: loss = 0.250172 (* 1 = 0.250172 loss)
I0808 15:58:05.908118 20451 sgd_solver.cpp:106] Iteration 3460, lr = 0.000800233
I0808 15:58:28.231561 20451 solver.cpp:228] Iteration 3470, loss = 0.156457
I0808 15:58:28.231736 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:58:28.231751 20451 solver.cpp:244]     Train net output #1: loss = 0.156457 (* 1 = 0.156457 loss)
I0808 15:58:28.231765 20451 sgd_solver.cpp:106] Iteration 3470, lr = 0.000799787
I0808 15:58:50.622648 20451 solver.cpp:228] Iteration 3480, loss = 0.281439
I0808 15:58:50.622699 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 15:58:50.622714 20451 solver.cpp:244]     Train net output #1: loss = 0.281439 (* 1 = 0.281439 loss)
I0808 15:58:50.622725 20451 sgd_solver.cpp:106] Iteration 3480, lr = 0.000799342
I0808 15:59:12.984087 20451 solver.cpp:228] Iteration 3490, loss = 0.156414
I0808 15:59:12.984273 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 15:59:12.984288 20451 solver.cpp:244]     Train net output #1: loss = 0.156414 (* 1 = 0.156414 loss)
I0808 15:59:12.984302 20451 sgd_solver.cpp:106] Iteration 3490, lr = 0.000798898
I0808 15:59:33.315398 20451 solver.cpp:337] Iteration 3500, Testing net (#0)
I0808 15:59:41.923365 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0808 15:59:41.923414 20451 solver.cpp:404]     Test net output #1: loss = 0.961435 (* 1 = 0.961435 loss)
I0808 15:59:44.123380 20451 solver.cpp:228] Iteration 3500, loss = 0.18761
I0808 15:59:44.123534 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 15:59:44.123555 20451 solver.cpp:244]     Train net output #1: loss = 0.18761 (* 1 = 0.18761 loss)
I0808 15:59:44.123569 20451 sgd_solver.cpp:106] Iteration 3500, lr = 0.000798454
I0808 16:00:06.625911 20451 solver.cpp:228] Iteration 3510, loss = 0.312676
I0808 16:00:06.625952 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 16:00:06.625969 20451 solver.cpp:244]     Train net output #1: loss = 0.312676 (* 1 = 0.312676 loss)
I0808 16:00:06.625985 20451 sgd_solver.cpp:106] Iteration 3510, lr = 0.00079801
I0808 16:00:29.001199 20451 solver.cpp:228] Iteration 3520, loss = 0.187637
I0808 16:00:29.001302 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:00:29.001318 20451 solver.cpp:244]     Train net output #1: loss = 0.187637 (* 1 = 0.187637 loss)
I0808 16:00:29.001332 20451 sgd_solver.cpp:106] Iteration 3520, lr = 0.000797568
I0808 16:00:51.495712 20451 solver.cpp:228] Iteration 3530, loss = 0.15661
I0808 16:00:51.495761 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 16:00:51.495775 20451 solver.cpp:244]     Train net output #1: loss = 0.15661 (* 1 = 0.15661 loss)
I0808 16:00:51.495787 20451 sgd_solver.cpp:106] Iteration 3530, lr = 0.000797125
I0808 16:01:13.944058 20451 solver.cpp:228] Iteration 3540, loss = 0.125034
I0808 16:01:13.944236 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:01:13.944254 20451 solver.cpp:244]     Train net output #1: loss = 0.125034 (* 1 = 0.125034 loss)
I0808 16:01:13.944270 20451 sgd_solver.cpp:106] Iteration 3540, lr = 0.000796684
I0808 16:01:36.358139 20451 solver.cpp:228] Iteration 3550, loss = 0.093821
I0808 16:01:36.358181 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:01:36.358206 20451 solver.cpp:244]     Train net output #1: loss = 0.0938209 (* 1 = 0.0938209 loss)
I0808 16:01:36.358222 20451 sgd_solver.cpp:106] Iteration 3550, lr = 0.000796243
I0808 16:01:58.762964 20451 solver.cpp:228] Iteration 3560, loss = 0.250066
I0808 16:01:58.763154 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:01:58.763195 20451 solver.cpp:244]     Train net output #1: loss = 0.250066 (* 1 = 0.250066 loss)
I0808 16:01:58.763232 20451 sgd_solver.cpp:106] Iteration 3560, lr = 0.000795802
I0808 16:02:21.205953 20451 solver.cpp:228] Iteration 3570, loss = 0.125076
I0808 16:02:21.205998 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:02:21.206018 20451 solver.cpp:244]     Train net output #1: loss = 0.125076 (* 1 = 0.125076 loss)
I0808 16:02:21.206034 20451 sgd_solver.cpp:106] Iteration 3570, lr = 0.000795363
I0808 16:02:43.603621 20451 solver.cpp:228] Iteration 3580, loss = 0.218911
I0808 16:02:43.603799 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:02:43.603816 20451 solver.cpp:244]     Train net output #1: loss = 0.218911 (* 1 = 0.218911 loss)
I0808 16:02:43.603828 20451 sgd_solver.cpp:106] Iteration 3580, lr = 0.000794923
I0808 16:03:06.078794 20451 solver.cpp:228] Iteration 3590, loss = 0.218878
I0808 16:03:06.078835 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:03:06.078850 20451 solver.cpp:244]     Train net output #1: loss = 0.218878 (* 1 = 0.218878 loss)
I0808 16:03:06.078862 20451 sgd_solver.cpp:106] Iteration 3590, lr = 0.000794485
I0808 16:03:26.274147 20451 solver.cpp:337] Iteration 3600, Testing net (#0)
I0808 16:03:34.833832 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 16:03:34.833959 20451 solver.cpp:404]     Test net output #1: loss = 0.99443 (* 1 = 0.99443 loss)
I0808 16:03:37.075009 20451 solver.cpp:228] Iteration 3600, loss = 0.281511
I0808 16:03:37.075063 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 16:03:37.075078 20451 solver.cpp:244]     Train net output #1: loss = 0.281511 (* 1 = 0.281511 loss)
I0808 16:03:37.075090 20451 sgd_solver.cpp:106] Iteration 3600, lr = 0.000794046
I0808 16:03:59.527443 20451 solver.cpp:228] Iteration 3610, loss = 0.0625777
I0808 16:03:59.527565 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 16:03:59.527581 20451 solver.cpp:244]     Train net output #1: loss = 0.0625777 (* 1 = 0.0625777 loss)
I0808 16:03:59.527593 20451 sgd_solver.cpp:106] Iteration 3610, lr = 0.000793609
I0808 16:04:21.999162 20451 solver.cpp:228] Iteration 3620, loss = 0.281489
I0808 16:04:21.999213 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 16:04:21.999228 20451 solver.cpp:244]     Train net output #1: loss = 0.281489 (* 1 = 0.281489 loss)
I0808 16:04:21.999240 20451 sgd_solver.cpp:106] Iteration 3620, lr = 0.000793172
I0808 16:04:44.451462 20451 solver.cpp:228] Iteration 3630, loss = 0.156346
I0808 16:04:44.451634 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:04:44.451650 20451 solver.cpp:244]     Train net output #1: loss = 0.156346 (* 1 = 0.156346 loss)
I0808 16:04:44.451663 20451 sgd_solver.cpp:106] Iteration 3630, lr = 0.000792735
I0808 16:05:06.950919 20451 solver.cpp:228] Iteration 3640, loss = 0.187656
I0808 16:05:06.950965 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:05:06.950984 20451 solver.cpp:244]     Train net output #1: loss = 0.187656 (* 1 = 0.187656 loss)
I0808 16:05:06.950999 20451 sgd_solver.cpp:106] Iteration 3640, lr = 0.000792299
I0808 16:05:29.427670 20451 solver.cpp:228] Iteration 3650, loss = 0.344132
I0808 16:05:29.427753 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 16:05:29.427770 20451 solver.cpp:244]     Train net output #1: loss = 0.344132 (* 1 = 0.344132 loss)
I0808 16:05:29.427786 20451 sgd_solver.cpp:106] Iteration 3650, lr = 0.000791864
I0808 16:05:51.923099 20451 solver.cpp:228] Iteration 3660, loss = 0.0625921
I0808 16:05:51.923152 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 16:05:51.923173 20451 solver.cpp:244]     Train net output #1: loss = 0.0625921 (* 1 = 0.0625921 loss)
I0808 16:05:51.923189 20451 sgd_solver.cpp:106] Iteration 3660, lr = 0.000791429
I0808 16:06:14.292345 20451 solver.cpp:228] Iteration 3670, loss = 0.250073
I0808 16:06:14.292531 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:06:14.292549 20451 solver.cpp:244]     Train net output #1: loss = 0.250073 (* 1 = 0.250073 loss)
I0808 16:06:14.292565 20451 sgd_solver.cpp:106] Iteration 3670, lr = 0.000790995
I0808 16:06:36.706871 20451 solver.cpp:228] Iteration 3680, loss = 0.093873
I0808 16:06:36.706923 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:06:36.706936 20451 solver.cpp:244]     Train net output #1: loss = 0.093873 (* 1 = 0.093873 loss)
I0808 16:06:36.706948 20451 sgd_solver.cpp:106] Iteration 3680, lr = 0.000790561
I0808 16:06:59.175537 20451 solver.cpp:228] Iteration 3690, loss = 0.0625476
I0808 16:06:59.175714 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 16:06:59.175734 20451 solver.cpp:244]     Train net output #1: loss = 0.0625476 (* 1 = 0.0625476 loss)
I0808 16:06:59.175750 20451 sgd_solver.cpp:106] Iteration 3690, lr = 0.000790128
I0808 16:07:19.414439 20451 solver.cpp:337] Iteration 3700, Testing net (#0)
I0808 16:07:28.048923 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 16:07:28.048964 20451 solver.cpp:404]     Test net output #1: loss = 0.999355 (* 1 = 0.999355 loss)
I0808 16:07:30.271636 20451 solver.cpp:228] Iteration 3700, loss = 0.15644
I0808 16:07:30.271809 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:07:30.271824 20451 solver.cpp:244]     Train net output #1: loss = 0.15644 (* 1 = 0.15644 loss)
I0808 16:07:30.271837 20451 sgd_solver.cpp:106] Iteration 3700, lr = 0.000789695
I0808 16:07:52.750104 20451 solver.cpp:228] Iteration 3710, loss = 0.250535
I0808 16:07:52.750160 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 16:07:52.750179 20451 solver.cpp:244]     Train net output #1: loss = 0.250535 (* 1 = 0.250535 loss)
I0808 16:07:52.750193 20451 sgd_solver.cpp:106] Iteration 3710, lr = 0.000789263
I0808 16:08:15.269145 20451 solver.cpp:228] Iteration 3720, loss = 0.156297
I0808 16:08:15.269258 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:08:15.269274 20451 solver.cpp:244]     Train net output #1: loss = 0.156297 (* 1 = 0.156297 loss)
I0808 16:08:15.269287 20451 sgd_solver.cpp:106] Iteration 3720, lr = 0.000788832
I0808 16:08:37.566699 20451 solver.cpp:228] Iteration 3730, loss = 0.218996
I0808 16:08:37.566740 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:08:37.566754 20451 solver.cpp:244]     Train net output #1: loss = 0.218996 (* 1 = 0.218996 loss)
I0808 16:08:37.566767 20451 sgd_solver.cpp:106] Iteration 3730, lr = 0.000788401
I0808 16:08:59.857537 20451 solver.cpp:228] Iteration 3740, loss = 0.0939503
I0808 16:08:59.857645 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 16:08:59.857663 20451 solver.cpp:244]     Train net output #1: loss = 0.0939503 (* 1 = 0.0939503 loss)
I0808 16:08:59.857678 20451 sgd_solver.cpp:106] Iteration 3740, lr = 0.000787971
I0808 16:09:22.144659 20451 solver.cpp:228] Iteration 3750, loss = 0.28146
I0808 16:09:22.144712 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 16:09:22.144726 20451 solver.cpp:244]     Train net output #1: loss = 0.28146 (* 1 = 0.28146 loss)
I0808 16:09:22.144739 20451 sgd_solver.cpp:106] Iteration 3750, lr = 0.000787541
I0808 16:09:44.423048 20451 solver.cpp:228] Iteration 3760, loss = 0.187723
I0808 16:09:44.423241 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 16:09:44.423257 20451 solver.cpp:244]     Train net output #1: loss = 0.187723 (* 1 = 0.187723 loss)
I0808 16:09:44.423270 20451 sgd_solver.cpp:106] Iteration 3760, lr = 0.000787111
I0808 16:10:06.715914 20451 solver.cpp:228] Iteration 3770, loss = 0.156439
I0808 16:10:06.715965 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:10:06.715979 20451 solver.cpp:244]     Train net output #1: loss = 0.156439 (* 1 = 0.156439 loss)
I0808 16:10:06.715992 20451 sgd_solver.cpp:106] Iteration 3770, lr = 0.000786683
I0808 16:10:29.006302 20451 solver.cpp:228] Iteration 3780, loss = 0.250429
I0808 16:10:29.006476 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 16:10:29.006492 20451 solver.cpp:244]     Train net output #1: loss = 0.250429 (* 1 = 0.250429 loss)
I0808 16:10:29.006505 20451 sgd_solver.cpp:106] Iteration 3780, lr = 0.000786254
I0808 16:10:51.288254 20451 solver.cpp:228] Iteration 3790, loss = 0.156439
I0808 16:10:51.288317 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 16:10:51.288336 20451 solver.cpp:244]     Train net output #1: loss = 0.156439 (* 1 = 0.156439 loss)
I0808 16:10:51.288349 20451 sgd_solver.cpp:106] Iteration 3790, lr = 0.000785827
I0808 16:11:11.361037 20451 solver.cpp:337] Iteration 3800, Testing net (#0)
I0808 16:11:19.873703 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0808 16:11:19.873749 20451 solver.cpp:404]     Test net output #1: loss = 0.989191 (* 1 = 0.989191 loss)
I0808 16:11:22.076176 20451 solver.cpp:228] Iteration 3800, loss = 0.218821
I0808 16:11:22.076228 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:11:22.076242 20451 solver.cpp:244]     Train net output #1: loss = 0.218821 (* 1 = 0.218821 loss)
I0808 16:11:22.076254 20451 sgd_solver.cpp:106] Iteration 3800, lr = 0.0007854
I0808 16:11:44.419744 20451 solver.cpp:228] Iteration 3810, loss = 0.125153
I0808 16:11:44.419843 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:11:44.419859 20451 solver.cpp:244]     Train net output #1: loss = 0.125153 (* 1 = 0.125153 loss)
I0808 16:11:44.419872 20451 sgd_solver.cpp:106] Iteration 3810, lr = 0.000784973
I0808 16:12:06.708554 20451 solver.cpp:228] Iteration 3820, loss = 0.281422
I0808 16:12:06.708613 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 16:12:06.708631 20451 solver.cpp:244]     Train net output #1: loss = 0.281422 (* 1 = 0.281422 loss)
I0808 16:12:06.708645 20451 sgd_solver.cpp:106] Iteration 3820, lr = 0.000784547
I0808 16:12:28.992789 20451 solver.cpp:228] Iteration 3830, loss = 0.187629
I0808 16:12:28.992923 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:12:28.992938 20451 solver.cpp:244]     Train net output #1: loss = 0.187629 (* 1 = 0.187629 loss)
I0808 16:12:28.992951 20451 sgd_solver.cpp:106] Iteration 3830, lr = 0.000784122
I0808 16:12:51.276515 20451 solver.cpp:228] Iteration 3840, loss = 0.0625542
I0808 16:12:51.276567 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 16:12:51.276582 20451 solver.cpp:244]     Train net output #1: loss = 0.0625542 (* 1 = 0.0625542 loss)
I0808 16:12:51.276592 20451 sgd_solver.cpp:106] Iteration 3840, lr = 0.000783697
I0808 16:13:13.563266 20451 solver.cpp:228] Iteration 3850, loss = 0.312707
I0808 16:13:13.563462 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 16:13:13.563536 20451 solver.cpp:244]     Train net output #1: loss = 0.312707 (* 1 = 0.312707 loss)
I0808 16:13:13.563575 20451 sgd_solver.cpp:106] Iteration 3850, lr = 0.000783272
I0808 16:13:35.844341 20451 solver.cpp:228] Iteration 3860, loss = 0.0939011
I0808 16:13:35.844393 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:13:35.844408 20451 solver.cpp:244]     Train net output #1: loss = 0.093901 (* 1 = 0.093901 loss)
I0808 16:13:35.844419 20451 sgd_solver.cpp:106] Iteration 3860, lr = 0.000782848
I0808 16:13:58.166359 20451 solver.cpp:228] Iteration 3870, loss = 0.187832
I0808 16:13:58.166544 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 16:13:58.166563 20451 solver.cpp:244]     Train net output #1: loss = 0.187832 (* 1 = 0.187832 loss)
I0808 16:13:58.166574 20451 sgd_solver.cpp:106] Iteration 3870, lr = 0.000782425
I0808 16:14:20.537392 20451 solver.cpp:228] Iteration 3880, loss = 0.187526
I0808 16:14:20.537442 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:14:20.537456 20451 solver.cpp:244]     Train net output #1: loss = 0.187526 (* 1 = 0.187526 loss)
I0808 16:14:20.537468 20451 sgd_solver.cpp:106] Iteration 3880, lr = 0.000782002
I0808 16:14:42.993219 20451 solver.cpp:228] Iteration 3890, loss = 0.281479
I0808 16:14:42.993321 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 16:14:42.993337 20451 solver.cpp:244]     Train net output #1: loss = 0.281479 (* 1 = 0.281479 loss)
I0808 16:14:42.993350 20451 sgd_solver.cpp:106] Iteration 3890, lr = 0.00078158
I0808 16:15:03.198565 20451 solver.cpp:337] Iteration 3900, Testing net (#0)
I0808 16:15:11.726284 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0808 16:15:11.726336 20451 solver.cpp:404]     Test net output #1: loss = 1.03605 (* 1 = 1.03605 loss)
I0808 16:15:13.930433 20451 solver.cpp:228] Iteration 3900, loss = 0.250019
I0808 16:15:13.930605 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 16:15:13.930620 20451 solver.cpp:244]     Train net output #1: loss = 0.250019 (* 1 = 0.250019 loss)
I0808 16:15:13.930634 20451 sgd_solver.cpp:106] Iteration 3900, lr = 0.000781158
I0808 16:15:36.269740 20451 solver.cpp:228] Iteration 3910, loss = 0.0938739
I0808 16:15:36.269789 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:15:36.269804 20451 solver.cpp:244]     Train net output #1: loss = 0.0938739 (* 1 = 0.0938739 loss)
I0808 16:15:36.269816 20451 sgd_solver.cpp:106] Iteration 3910, lr = 0.000780737
I0808 16:15:58.627339 20451 solver.cpp:228] Iteration 3920, loss = 0.187651
I0808 16:15:58.627516 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:15:58.627531 20451 solver.cpp:244]     Train net output #1: loss = 0.187651 (* 1 = 0.187651 loss)
I0808 16:15:58.627544 20451 sgd_solver.cpp:106] Iteration 3920, lr = 0.000780316
I0808 16:16:21.018103 20451 solver.cpp:228] Iteration 3930, loss = 0.187943
I0808 16:16:21.018157 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:16:21.018170 20451 solver.cpp:244]     Train net output #1: loss = 0.187943 (* 1 = 0.187943 loss)
I0808 16:16:21.018183 20451 sgd_solver.cpp:106] Iteration 3930, lr = 0.000779896
I0808 16:16:43.422955 20451 solver.cpp:228] Iteration 3940, loss = 0.0938211
I0808 16:16:43.423090 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:16:43.423106 20451 solver.cpp:244]     Train net output #1: loss = 0.0938211 (* 1 = 0.0938211 loss)
I0808 16:16:43.423120 20451 sgd_solver.cpp:106] Iteration 3940, lr = 0.000779476
I0808 16:17:05.998699 20451 solver.cpp:228] Iteration 3950, loss = 0.0937909
I0808 16:17:05.998741 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:17:05.998760 20451 solver.cpp:244]     Train net output #1: loss = 0.0937908 (* 1 = 0.0937908 loss)
I0808 16:17:05.998778 20451 sgd_solver.cpp:106] Iteration 3950, lr = 0.000779057
I0808 16:17:28.359696 20451 solver.cpp:228] Iteration 3960, loss = 0.218936
I0808 16:17:28.359875 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:17:28.359890 20451 solver.cpp:244]     Train net output #1: loss = 0.218936 (* 1 = 0.218936 loss)
I0808 16:17:28.359904 20451 sgd_solver.cpp:106] Iteration 3960, lr = 0.000778639
I0808 16:17:50.725733 20451 solver.cpp:228] Iteration 3970, loss = 0.156367
I0808 16:17:50.725781 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:17:50.725795 20451 solver.cpp:244]     Train net output #1: loss = 0.156367 (* 1 = 0.156367 loss)
I0808 16:17:50.725808 20451 sgd_solver.cpp:106] Iteration 3970, lr = 0.000778221
I0808 16:18:13.200672 20451 solver.cpp:228] Iteration 3980, loss = 0.187724
I0808 16:18:13.200858 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:18:13.200873 20451 solver.cpp:244]     Train net output #1: loss = 0.187724 (* 1 = 0.187724 loss)
I0808 16:18:13.200886 20451 sgd_solver.cpp:106] Iteration 3980, lr = 0.000777803
I0808 16:18:35.658324 20451 solver.cpp:228] Iteration 3990, loss = 0.281433
I0808 16:18:35.658366 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 16:18:35.658385 20451 solver.cpp:244]     Train net output #1: loss = 0.281433 (* 1 = 0.281433 loss)
I0808 16:18:35.658398 20451 sgd_solver.cpp:106] Iteration 3990, lr = 0.000777386
I0808 16:18:55.931978 20451 solver.cpp:337] Iteration 4000, Testing net (#0)
I0808 16:19:04.561894 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 16:19:04.561947 20451 solver.cpp:404]     Test net output #1: loss = 0.984678 (* 1 = 0.984678 loss)
I0808 16:19:06.788775 20451 solver.cpp:228] Iteration 4000, loss = 0.156338
I0808 16:19:06.788830 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:19:06.788844 20451 solver.cpp:244]     Train net output #1: loss = 0.156338 (* 1 = 0.156338 loss)
I0808 16:19:06.788856 20451 sgd_solver.cpp:106] Iteration 4000, lr = 0.00077697
I0808 16:19:29.227075 20451 solver.cpp:228] Iteration 4010, loss = 0.031287
I0808 16:19:29.227179 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 16:19:29.227197 20451 solver.cpp:244]     Train net output #1: loss = 0.031287 (* 1 = 0.031287 loss)
I0808 16:19:29.227215 20451 sgd_solver.cpp:106] Iteration 4010, lr = 0.000776554
I0808 16:19:51.586990 20451 solver.cpp:228] Iteration 4020, loss = 0.18763
I0808 16:19:51.587039 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:19:51.587054 20451 solver.cpp:244]     Train net output #1: loss = 0.18763 (* 1 = 0.18763 loss)
I0808 16:19:51.587065 20451 sgd_solver.cpp:106] Iteration 4020, lr = 0.000776138
I0808 16:20:13.964998 20451 solver.cpp:228] Iteration 4030, loss = 0.218987
I0808 16:20:13.965186 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:20:13.965201 20451 solver.cpp:244]     Train net output #1: loss = 0.218987 (* 1 = 0.218987 loss)
I0808 16:20:13.965214 20451 sgd_solver.cpp:106] Iteration 4030, lr = 0.000775723
I0808 16:20:36.365927 20451 solver.cpp:228] Iteration 4040, loss = 0.187792
I0808 16:20:36.365969 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:20:36.365988 20451 solver.cpp:244]     Train net output #1: loss = 0.187792 (* 1 = 0.187792 loss)
I0808 16:20:36.366001 20451 sgd_solver.cpp:106] Iteration 4040, lr = 0.000775309
I0808 16:20:58.714078 20451 solver.cpp:228] Iteration 4050, loss = 0.0625254
I0808 16:20:58.714213 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 16:20:58.714233 20451 solver.cpp:244]     Train net output #1: loss = 0.0625254 (* 1 = 0.0625254 loss)
I0808 16:20:58.714251 20451 sgd_solver.cpp:106] Iteration 4050, lr = 0.000774895
I0808 16:21:21.100941 20451 solver.cpp:228] Iteration 4060, loss = 0.125093
I0808 16:21:21.100993 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:21:21.101008 20451 solver.cpp:244]     Train net output #1: loss = 0.125093 (* 1 = 0.125093 loss)
I0808 16:21:21.101022 20451 sgd_solver.cpp:106] Iteration 4060, lr = 0.000774481
I0808 16:21:43.553050 20451 solver.cpp:228] Iteration 4070, loss = 0.218907
I0808 16:21:43.553234 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:21:43.553252 20451 solver.cpp:244]     Train net output #1: loss = 0.218907 (* 1 = 0.218907 loss)
I0808 16:21:43.553267 20451 sgd_solver.cpp:106] Iteration 4070, lr = 0.000774069
I0808 16:22:05.939326 20451 solver.cpp:228] Iteration 4080, loss = 0.281613
I0808 16:22:05.939375 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 16:22:05.939391 20451 solver.cpp:244]     Train net output #1: loss = 0.281613 (* 1 = 0.281613 loss)
I0808 16:22:05.939405 20451 sgd_solver.cpp:106] Iteration 4080, lr = 0.000773656
I0808 16:22:28.356643 20451 solver.cpp:228] Iteration 4090, loss = 0.281398
I0808 16:22:28.356822 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 16:22:28.356837 20451 solver.cpp:244]     Train net output #1: loss = 0.281398 (* 1 = 0.281398 loss)
I0808 16:22:28.356849 20451 sgd_solver.cpp:106] Iteration 4090, lr = 0.000773244
I0808 16:22:48.566035 20451 solver.cpp:337] Iteration 4100, Testing net (#0)
I0808 16:22:57.106313 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0808 16:22:57.106365 20451 solver.cpp:404]     Test net output #1: loss = 0.970926 (* 1 = 0.970926 loss)
I0808 16:22:59.307261 20451 solver.cpp:228] Iteration 4100, loss = 0.125099
I0808 16:22:59.307454 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:22:59.307469 20451 solver.cpp:244]     Train net output #1: loss = 0.125099 (* 1 = 0.125099 loss)
I0808 16:22:59.307483 20451 sgd_solver.cpp:106] Iteration 4100, lr = 0.000772833
I0808 16:23:21.828347 20451 solver.cpp:228] Iteration 4110, loss = 0.218849
I0808 16:23:21.828387 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:23:21.828402 20451 solver.cpp:244]     Train net output #1: loss = 0.218849 (* 1 = 0.218849 loss)
I0808 16:23:21.828415 20451 sgd_solver.cpp:106] Iteration 4110, lr = 0.000772422
I0808 16:23:44.141295 20451 solver.cpp:228] Iteration 4120, loss = 0.187649
I0808 16:23:44.141471 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:23:44.141487 20451 solver.cpp:244]     Train net output #1: loss = 0.187649 (* 1 = 0.187649 loss)
I0808 16:23:44.141500 20451 sgd_solver.cpp:106] Iteration 4120, lr = 0.000772012
I0808 16:24:06.696837 20451 solver.cpp:228] Iteration 4130, loss = 0.218789
I0808 16:24:06.696877 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:24:06.696892 20451 solver.cpp:244]     Train net output #1: loss = 0.218789 (* 1 = 0.218789 loss)
I0808 16:24:06.696904 20451 sgd_solver.cpp:106] Iteration 4130, lr = 0.000771602
I0808 16:24:29.335458 20451 solver.cpp:228] Iteration 4140, loss = 0.187656
I0808 16:24:29.335644 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:24:29.335659 20451 solver.cpp:244]     Train net output #1: loss = 0.187656 (* 1 = 0.187656 loss)
I0808 16:24:29.335672 20451 sgd_solver.cpp:106] Iteration 4140, lr = 0.000771193
I0808 16:24:51.818328 20451 solver.cpp:228] Iteration 4150, loss = 0.21894
I0808 16:24:51.818379 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:24:51.818394 20451 solver.cpp:244]     Train net output #1: loss = 0.21894 (* 1 = 0.21894 loss)
I0808 16:24:51.818406 20451 sgd_solver.cpp:106] Iteration 4150, lr = 0.000770784
I0808 16:25:14.250888 20451 solver.cpp:228] Iteration 4160, loss = 0.281467
I0808 16:25:14.251106 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 16:25:14.251122 20451 solver.cpp:244]     Train net output #1: loss = 0.281467 (* 1 = 0.281467 loss)
I0808 16:25:14.251135 20451 sgd_solver.cpp:106] Iteration 4160, lr = 0.000770376
I0808 16:25:36.698045 20451 solver.cpp:228] Iteration 4170, loss = 0.125126
I0808 16:25:36.698091 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:25:36.698106 20451 solver.cpp:244]     Train net output #1: loss = 0.125126 (* 1 = 0.125126 loss)
I0808 16:25:36.698118 20451 sgd_solver.cpp:106] Iteration 4170, lr = 0.000769968
I0808 16:25:59.080916 20451 solver.cpp:228] Iteration 4180, loss = 0.0938672
I0808 16:25:59.081101 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:25:59.081117 20451 solver.cpp:244]     Train net output #1: loss = 0.0938672 (* 1 = 0.0938672 loss)
I0808 16:25:59.081130 20451 sgd_solver.cpp:106] Iteration 4180, lr = 0.000769561
I0808 16:26:21.641193 20451 solver.cpp:228] Iteration 4190, loss = 0.062516
I0808 16:26:21.641239 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 16:26:21.641258 20451 solver.cpp:244]     Train net output #1: loss = 0.062516 (* 1 = 0.062516 loss)
I0808 16:26:21.641273 20451 sgd_solver.cpp:106] Iteration 4190, lr = 0.000769154
I0808 16:26:41.738996 20451 solver.cpp:337] Iteration 4200, Testing net (#0)
I0808 16:26:50.277035 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 16:26:50.277086 20451 solver.cpp:404]     Test net output #1: loss = 1.0079 (* 1 = 1.0079 loss)
I0808 16:26:52.476296 20451 solver.cpp:228] Iteration 4200, loss = 0.156272
I0808 16:26:52.476443 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:26:52.476483 20451 solver.cpp:244]     Train net output #1: loss = 0.156272 (* 1 = 0.156272 loss)
I0808 16:26:52.476517 20451 sgd_solver.cpp:106] Iteration 4200, lr = 0.000768748
I0808 16:27:14.845103 20451 solver.cpp:228] Iteration 4210, loss = 0.093775
I0808 16:27:14.845284 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:27:14.845302 20451 solver.cpp:244]     Train net output #1: loss = 0.0937749 (* 1 = 0.0937749 loss)
I0808 16:27:14.845319 20451 sgd_solver.cpp:106] Iteration 4210, lr = 0.000768342
I0808 16:27:37.254513 20451 solver.cpp:228] Iteration 4220, loss = 0.156301
I0808 16:27:37.254557 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:27:37.254585 20451 solver.cpp:244]     Train net output #1: loss = 0.156301 (* 1 = 0.156301 loss)
I0808 16:27:37.254601 20451 sgd_solver.cpp:106] Iteration 4220, lr = 0.000767937
I0808 16:27:59.617558 20451 solver.cpp:228] Iteration 4230, loss = 0.187672
I0808 16:27:59.617669 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 16:27:59.617686 20451 solver.cpp:244]     Train net output #1: loss = 0.187672 (* 1 = 0.187672 loss)
I0808 16:27:59.617700 20451 sgd_solver.cpp:106] Iteration 4230, lr = 0.000767532
I0808 16:28:21.997090 20451 solver.cpp:228] Iteration 4240, loss = 0.0939736
I0808 16:28:21.997141 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:28:21.997156 20451 solver.cpp:244]     Train net output #1: loss = 0.0939735 (* 1 = 0.0939735 loss)
I0808 16:28:21.997167 20451 sgd_solver.cpp:106] Iteration 4240, lr = 0.000767127
I0808 16:28:44.322484 20451 solver.cpp:228] Iteration 4250, loss = 0.312661
I0808 16:28:44.322700 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 16:28:44.322715 20451 solver.cpp:244]     Train net output #1: loss = 0.312661 (* 1 = 0.312661 loss)
I0808 16:28:44.322728 20451 sgd_solver.cpp:106] Iteration 4250, lr = 0.000766724
I0808 16:29:06.652921 20451 solver.cpp:228] Iteration 4260, loss = 0.218898
I0808 16:29:06.652961 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:29:06.652976 20451 solver.cpp:244]     Train net output #1: loss = 0.218898 (* 1 = 0.218898 loss)
I0808 16:29:06.652987 20451 sgd_solver.cpp:106] Iteration 4260, lr = 0.00076632
I0808 16:29:29.047987 20451 solver.cpp:228] Iteration 4270, loss = 0.218878
I0808 16:29:29.048172 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:29:29.048188 20451 solver.cpp:244]     Train net output #1: loss = 0.218878 (* 1 = 0.218878 loss)
I0808 16:29:29.048200 20451 sgd_solver.cpp:106] Iteration 4270, lr = 0.000765918
I0808 16:29:51.488351 20451 solver.cpp:228] Iteration 4280, loss = 0.156392
I0808 16:29:51.488400 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:29:51.488415 20451 solver.cpp:244]     Train net output #1: loss = 0.156392 (* 1 = 0.156392 loss)
I0808 16:29:51.488426 20451 sgd_solver.cpp:106] Iteration 4280, lr = 0.000765515
I0808 16:30:13.834059 20451 solver.cpp:228] Iteration 4290, loss = 0.156469
I0808 16:30:13.834158 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:30:13.834174 20451 solver.cpp:244]     Train net output #1: loss = 0.156469 (* 1 = 0.156469 loss)
I0808 16:30:13.834188 20451 sgd_solver.cpp:106] Iteration 4290, lr = 0.000765113
I0808 16:30:34.020036 20451 solver.cpp:337] Iteration 4300, Testing net (#0)
I0808 16:30:42.560859 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0808 16:30:42.560905 20451 solver.cpp:404]     Test net output #1: loss = 1.01271 (* 1 = 1.01271 loss)
I0808 16:30:44.767570 20451 solver.cpp:228] Iteration 4300, loss = 0.218903
I0808 16:30:44.767741 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:30:44.767755 20451 solver.cpp:244]     Train net output #1: loss = 0.218903 (* 1 = 0.218903 loss)
I0808 16:30:44.767768 20451 sgd_solver.cpp:106] Iteration 4300, lr = 0.000764712
I0808 16:31:07.159935 20451 solver.cpp:228] Iteration 4310, loss = 0.187554
I0808 16:31:07.159999 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:31:07.160018 20451 solver.cpp:244]     Train net output #1: loss = 0.187554 (* 1 = 0.187554 loss)
I0808 16:31:07.160033 20451 sgd_solver.cpp:106] Iteration 4310, lr = 0.000764311
I0808 16:31:29.561270 20451 solver.cpp:228] Iteration 4320, loss = 0.187673
I0808 16:31:29.561447 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:31:29.561462 20451 solver.cpp:244]     Train net output #1: loss = 0.187673 (* 1 = 0.187673 loss)
I0808 16:31:29.561475 20451 sgd_solver.cpp:106] Iteration 4320, lr = 0.000763911
I0808 16:31:52.095433 20451 solver.cpp:228] Iteration 4330, loss = 0.156359
I0808 16:31:52.095479 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:31:52.095497 20451 solver.cpp:244]     Train net output #1: loss = 0.156359 (* 1 = 0.156359 loss)
I0808 16:31:52.095513 20451 sgd_solver.cpp:106] Iteration 4330, lr = 0.000763511
I0808 16:32:14.571012 20451 solver.cpp:228] Iteration 4340, loss = 0.0937943
I0808 16:32:14.571182 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:32:14.571198 20451 solver.cpp:244]     Train net output #1: loss = 0.0937943 (* 1 = 0.0937943 loss)
I0808 16:32:14.571210 20451 sgd_solver.cpp:106] Iteration 4340, lr = 0.000763112
I0808 16:32:36.953675 20451 solver.cpp:228] Iteration 4350, loss = 0.125126
I0808 16:32:36.953724 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:32:36.953738 20451 solver.cpp:244]     Train net output #1: loss = 0.125126 (* 1 = 0.125126 loss)
I0808 16:32:36.953750 20451 sgd_solver.cpp:106] Iteration 4350, lr = 0.000762713
I0808 16:32:59.388065 20451 solver.cpp:228] Iteration 4360, loss = 0.344048
I0808 16:32:59.388278 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 16:32:59.388294 20451 solver.cpp:244]     Train net output #1: loss = 0.344048 (* 1 = 0.344048 loss)
I0808 16:32:59.388309 20451 sgd_solver.cpp:106] Iteration 4360, lr = 0.000762315
I0808 16:33:21.771085 20451 solver.cpp:228] Iteration 4370, loss = 0.218948
I0808 16:33:21.771136 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:33:21.771150 20451 solver.cpp:244]     Train net output #1: loss = 0.218948 (* 1 = 0.218948 loss)
I0808 16:33:21.771162 20451 sgd_solver.cpp:106] Iteration 4370, lr = 0.000761917
I0808 16:33:44.227541 20451 solver.cpp:228] Iteration 4380, loss = 0.156343
I0808 16:33:44.227643 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:33:44.227656 20451 solver.cpp:244]     Train net output #1: loss = 0.156342 (* 1 = 0.156342 loss)
I0808 16:33:44.227669 20451 sgd_solver.cpp:106] Iteration 4380, lr = 0.000761519
I0808 16:34:06.695838 20451 solver.cpp:228] Iteration 4390, loss = 0.187755
I0808 16:34:06.695888 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:34:06.695906 20451 solver.cpp:244]     Train net output #1: loss = 0.187755 (* 1 = 0.187755 loss)
I0808 16:34:06.695922 20451 sgd_solver.cpp:106] Iteration 4390, lr = 0.000761122
I0808 16:34:26.956322 20451 solver.cpp:337] Iteration 4400, Testing net (#0)
I0808 16:34:35.482429 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 16:34:35.482481 20451 solver.cpp:404]     Test net output #1: loss = 0.984541 (* 1 = 0.984541 loss)
I0808 16:34:37.684327 20451 solver.cpp:228] Iteration 4400, loss = 0.187527
I0808 16:34:37.684375 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:34:37.684393 20451 solver.cpp:244]     Train net output #1: loss = 0.187527 (* 1 = 0.187527 loss)
I0808 16:34:37.684409 20451 sgd_solver.cpp:106] Iteration 4400, lr = 0.000760726
I0808 16:35:00.156610 20451 solver.cpp:228] Iteration 4410, loss = 0.0937693
I0808 16:35:00.156713 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:35:00.156729 20451 solver.cpp:244]     Train net output #1: loss = 0.0937692 (* 1 = 0.0937692 loss)
I0808 16:35:00.156741 20451 sgd_solver.cpp:106] Iteration 4410, lr = 0.00076033
I0808 16:35:22.584802 20451 solver.cpp:228] Iteration 4420, loss = 0.125139
I0808 16:35:22.584849 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 16:35:22.584868 20451 solver.cpp:244]     Train net output #1: loss = 0.125139 (* 1 = 0.125139 loss)
I0808 16:35:22.584884 20451 sgd_solver.cpp:106] Iteration 4420, lr = 0.000759934
I0808 16:35:44.910488 20451 solver.cpp:228] Iteration 4430, loss = 0.156306
I0808 16:35:44.910676 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:35:44.910694 20451 solver.cpp:244]     Train net output #1: loss = 0.156306 (* 1 = 0.156306 loss)
I0808 16:35:44.910709 20451 sgd_solver.cpp:106] Iteration 4430, lr = 0.000759539
I0808 16:36:07.199064 20451 solver.cpp:228] Iteration 4440, loss = 0.187737
I0808 16:36:07.199107 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:36:07.199136 20451 solver.cpp:244]     Train net output #1: loss = 0.187737 (* 1 = 0.187737 loss)
I0808 16:36:07.199151 20451 sgd_solver.cpp:106] Iteration 4440, lr = 0.000759145
I0808 16:36:29.486323 20451 solver.cpp:228] Iteration 4450, loss = 0.125031
I0808 16:36:29.486433 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:36:29.486451 20451 solver.cpp:244]     Train net output #1: loss = 0.125031 (* 1 = 0.125031 loss)
I0808 16:36:29.486467 20451 sgd_solver.cpp:106] Iteration 4450, lr = 0.000758751
I0808 16:36:51.775667 20451 solver.cpp:228] Iteration 4460, loss = 0.0938502
I0808 16:36:51.775720 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:36:51.775734 20451 solver.cpp:244]     Train net output #1: loss = 0.0938501 (* 1 = 0.0938501 loss)
I0808 16:36:51.775746 20451 sgd_solver.cpp:106] Iteration 4460, lr = 0.000758357
I0808 16:37:14.073729 20451 solver.cpp:228] Iteration 4470, loss = 0.0938084
I0808 16:37:14.073874 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:37:14.073894 20451 solver.cpp:244]     Train net output #1: loss = 0.0938084 (* 1 = 0.0938084 loss)
I0808 16:37:14.073911 20451 sgd_solver.cpp:106] Iteration 4470, lr = 0.000757964
I0808 16:37:36.368376 20451 solver.cpp:228] Iteration 4480, loss = 0.0625681
I0808 16:37:36.368428 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 16:37:36.368443 20451 solver.cpp:244]     Train net output #1: loss = 0.062568 (* 1 = 0.062568 loss)
I0808 16:37:36.368455 20451 sgd_solver.cpp:106] Iteration 4480, lr = 0.000757571
I0808 16:37:58.660852 20451 solver.cpp:228] Iteration 4490, loss = 0.0937882
I0808 16:37:58.661039 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:37:58.661056 20451 solver.cpp:244]     Train net output #1: loss = 0.0937881 (* 1 = 0.0937881 loss)
I0808 16:37:58.661067 20451 sgd_solver.cpp:106] Iteration 4490, lr = 0.000757179
I0808 16:38:18.731128 20451 solver.cpp:337] Iteration 4500, Testing net (#0)
I0808 16:38:27.249215 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 16:38:27.249269 20451 solver.cpp:404]     Test net output #1: loss = 1.00381 (* 1 = 1.00381 loss)
I0808 16:38:29.449781 20451 solver.cpp:228] Iteration 4500, loss = 0.218954
I0808 16:38:29.456542 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:38:29.456563 20451 solver.cpp:244]     Train net output #1: loss = 0.218953 (* 1 = 0.218953 loss)
I0808 16:38:29.456578 20451 sgd_solver.cpp:106] Iteration 4500, lr = 0.000756788
I0808 16:38:51.731087 20451 solver.cpp:228] Iteration 4510, loss = 0.093779
I0808 16:38:51.731135 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:38:51.731155 20451 solver.cpp:244]     Train net output #1: loss = 0.0937789 (* 1 = 0.0937789 loss)
I0808 16:38:51.731170 20451 sgd_solver.cpp:106] Iteration 4510, lr = 0.000756396
I0808 16:39:14.022135 20451 solver.cpp:228] Iteration 4520, loss = 0.281638
I0808 16:39:14.022310 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 16:39:14.022325 20451 solver.cpp:244]     Train net output #1: loss = 0.281638 (* 1 = 0.281638 loss)
I0808 16:39:14.022337 20451 sgd_solver.cpp:106] Iteration 4520, lr = 0.000756006
I0808 16:39:36.301836 20451 solver.cpp:228] Iteration 4530, loss = 0.156439
I0808 16:39:36.301887 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:39:36.301901 20451 solver.cpp:244]     Train net output #1: loss = 0.156439 (* 1 = 0.156439 loss)
I0808 16:39:36.301913 20451 sgd_solver.cpp:106] Iteration 4530, lr = 0.000755615
I0808 16:39:58.595788 20451 solver.cpp:228] Iteration 4540, loss = 0.125102
I0808 16:39:58.595959 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:39:58.595974 20451 solver.cpp:244]     Train net output #1: loss = 0.125102 (* 1 = 0.125102 loss)
I0808 16:39:58.595993 20451 sgd_solver.cpp:106] Iteration 4540, lr = 0.000755226
I0808 16:40:20.894497 20451 solver.cpp:228] Iteration 4550, loss = 0.156435
I0808 16:40:20.894542 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:40:20.894567 20451 solver.cpp:244]     Train net output #1: loss = 0.156435 (* 1 = 0.156435 loss)
I0808 16:40:20.894582 20451 sgd_solver.cpp:106] Iteration 4550, lr = 0.000754836
I0808 16:40:43.184062 20451 solver.cpp:228] Iteration 4560, loss = 0.156345
I0808 16:40:43.184255 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:40:43.184272 20451 solver.cpp:244]     Train net output #1: loss = 0.156345 (* 1 = 0.156345 loss)
I0808 16:40:43.184283 20451 sgd_solver.cpp:106] Iteration 4560, lr = 0.000754447
I0808 16:41:05.500795 20451 solver.cpp:228] Iteration 4570, loss = 0.312842
I0808 16:41:05.500845 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 16:41:05.500859 20451 solver.cpp:244]     Train net output #1: loss = 0.312842 (* 1 = 0.312842 loss)
I0808 16:41:05.500871 20451 sgd_solver.cpp:106] Iteration 4570, lr = 0.000754059
I0808 16:41:27.786787 20451 solver.cpp:228] Iteration 4580, loss = 0.156374
I0808 16:41:27.786929 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:41:27.786945 20451 solver.cpp:244]     Train net output #1: loss = 0.156374 (* 1 = 0.156374 loss)
I0808 16:41:27.786957 20451 sgd_solver.cpp:106] Iteration 4580, lr = 0.000753671
I0808 16:41:50.079102 20451 solver.cpp:228] Iteration 4590, loss = 0.187704
I0808 16:41:50.079164 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 16:41:50.079179 20451 solver.cpp:244]     Train net output #1: loss = 0.187704 (* 1 = 0.187704 loss)
I0808 16:41:50.079191 20451 sgd_solver.cpp:106] Iteration 4590, lr = 0.000753284
I0808 16:42:10.145984 20451 solver.cpp:337] Iteration 4600, Testing net (#0)
I0808 16:42:18.654985 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 16:42:18.655037 20451 solver.cpp:404]     Test net output #1: loss = 0.975119 (* 1 = 0.975119 loss)
I0808 16:42:20.856081 20451 solver.cpp:228] Iteration 4600, loss = 0.125015
I0808 16:42:20.856130 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:42:20.856144 20451 solver.cpp:244]     Train net output #1: loss = 0.125015 (* 1 = 0.125015 loss)
I0808 16:42:20.856155 20451 sgd_solver.cpp:106] Iteration 4600, lr = 0.000752897
I0808 16:42:43.131428 20451 solver.cpp:228] Iteration 4610, loss = 0.21903
I0808 16:42:43.131610 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:42:43.131625 20451 solver.cpp:244]     Train net output #1: loss = 0.21903 (* 1 = 0.21903 loss)
I0808 16:42:43.131639 20451 sgd_solver.cpp:106] Iteration 4610, lr = 0.00075251
I0808 16:43:05.415326 20451 solver.cpp:228] Iteration 4620, loss = 0.156348
I0808 16:43:05.415370 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:43:05.415385 20451 solver.cpp:244]     Train net output #1: loss = 0.156348 (* 1 = 0.156348 loss)
I0808 16:43:05.415398 20451 sgd_solver.cpp:106] Iteration 4620, lr = 0.000752124
I0808 16:43:27.701169 20451 solver.cpp:228] Iteration 4630, loss = 0.250184
I0808 16:43:27.701347 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 16:43:27.701364 20451 solver.cpp:244]     Train net output #1: loss = 0.250184 (* 1 = 0.250184 loss)
I0808 16:43:27.701376 20451 sgd_solver.cpp:106] Iteration 4630, lr = 0.000751738
I0808 16:43:49.987321 20451 solver.cpp:228] Iteration 4640, loss = 0.093835
I0808 16:43:49.987381 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:43:49.987396 20451 solver.cpp:244]     Train net output #1: loss = 0.0938349 (* 1 = 0.0938349 loss)
I0808 16:43:49.987408 20451 sgd_solver.cpp:106] Iteration 4640, lr = 0.000751353
I0808 16:44:12.280671 20451 solver.cpp:228] Iteration 4650, loss = 0.343852
I0808 16:44:12.280851 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 16:44:12.280866 20451 solver.cpp:244]     Train net output #1: loss = 0.343852 (* 1 = 0.343852 loss)
I0808 16:44:12.280879 20451 sgd_solver.cpp:106] Iteration 4650, lr = 0.000750969
I0808 16:44:34.576203 20451 solver.cpp:228] Iteration 4660, loss = 0.156519
I0808 16:44:34.576257 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:44:34.576272 20451 solver.cpp:244]     Train net output #1: loss = 0.156519 (* 1 = 0.156519 loss)
I0808 16:44:34.576283 20451 sgd_solver.cpp:106] Iteration 4660, lr = 0.000750584
I0808 16:44:56.867365 20451 solver.cpp:228] Iteration 4670, loss = 0.156404
I0808 16:44:56.867466 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:44:56.867486 20451 solver.cpp:244]     Train net output #1: loss = 0.156404 (* 1 = 0.156404 loss)
I0808 16:44:56.867501 20451 sgd_solver.cpp:106] Iteration 4670, lr = 0.000750201
I0808 16:45:19.150210 20451 solver.cpp:228] Iteration 4680, loss = 0.250201
I0808 16:45:19.150262 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 16:45:19.150275 20451 solver.cpp:244]     Train net output #1: loss = 0.250201 (* 1 = 0.250201 loss)
I0808 16:45:19.150288 20451 sgd_solver.cpp:106] Iteration 4680, lr = 0.000749817
I0808 16:45:41.441810 20451 solver.cpp:228] Iteration 4690, loss = 0.125106
I0808 16:45:41.442033 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:45:41.442049 20451 solver.cpp:244]     Train net output #1: loss = 0.125106 (* 1 = 0.125106 loss)
I0808 16:45:41.442065 20451 sgd_solver.cpp:106] Iteration 4690, lr = 0.000749435
I0808 16:46:01.503348 20451 solver.cpp:337] Iteration 4700, Testing net (#0)
I0808 16:46:10.007139 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0808 16:46:10.007184 20451 solver.cpp:404]     Test net output #1: loss = 1.01763 (* 1 = 1.01763 loss)
I0808 16:46:12.204866 20451 solver.cpp:228] Iteration 4700, loss = 0.0312677
I0808 16:46:12.204963 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 16:46:12.204982 20451 solver.cpp:244]     Train net output #1: loss = 0.0312676 (* 1 = 0.0312676 loss)
I0808 16:46:12.204998 20451 sgd_solver.cpp:106] Iteration 4700, lr = 0.000749052
I0808 16:46:34.488689 20451 solver.cpp:228] Iteration 4710, loss = 0.156299
I0808 16:46:34.488741 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:46:34.488755 20451 solver.cpp:244]     Train net output #1: loss = 0.156299 (* 1 = 0.156299 loss)
I0808 16:46:34.488767 20451 sgd_solver.cpp:106] Iteration 4710, lr = 0.00074867
I0808 16:46:56.779448 20451 solver.cpp:228] Iteration 4720, loss = 0.093789
I0808 16:46:56.779623 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:46:56.779638 20451 solver.cpp:244]     Train net output #1: loss = 0.093789 (* 1 = 0.093789 loss)
I0808 16:46:56.779650 20451 sgd_solver.cpp:106] Iteration 4720, lr = 0.000748289
I0808 16:47:19.295907 20451 solver.cpp:228] Iteration 4730, loss = 0.125194
I0808 16:47:19.295953 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:47:19.295970 20451 solver.cpp:244]     Train net output #1: loss = 0.125194 (* 1 = 0.125194 loss)
I0808 16:47:19.295985 20451 sgd_solver.cpp:106] Iteration 4730, lr = 0.000747908
I0808 16:47:41.961453 20451 solver.cpp:228] Iteration 4740, loss = 0.156336
I0808 16:47:41.961545 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:47:41.961560 20451 solver.cpp:244]     Train net output #1: loss = 0.156336 (* 1 = 0.156336 loss)
I0808 16:47:41.961572 20451 sgd_solver.cpp:106] Iteration 4740, lr = 0.000747527
I0808 16:48:05.131664 20451 solver.cpp:228] Iteration 4750, loss = 0.125103
I0808 16:48:05.131716 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:48:05.131731 20451 solver.cpp:244]     Train net output #1: loss = 0.125103 (* 1 = 0.125103 loss)
I0808 16:48:05.131743 20451 sgd_solver.cpp:106] Iteration 4750, lr = 0.000747147
I0808 16:48:27.453382 20451 solver.cpp:228] Iteration 4760, loss = 0.156359
I0808 16:48:27.453565 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:48:27.453580 20451 solver.cpp:244]     Train net output #1: loss = 0.156359 (* 1 = 0.156359 loss)
I0808 16:48:27.453593 20451 sgd_solver.cpp:106] Iteration 4760, lr = 0.000746767
I0808 16:48:49.746712 20451 solver.cpp:228] Iteration 4770, loss = 0.281343
I0808 16:48:49.746758 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 16:48:49.746773 20451 solver.cpp:244]     Train net output #1: loss = 0.281343 (* 1 = 0.281343 loss)
I0808 16:48:49.746786 20451 sgd_solver.cpp:106] Iteration 4770, lr = 0.000746388
I0808 16:49:12.064880 20451 solver.cpp:228] Iteration 4780, loss = 0.187688
I0808 16:49:12.065058 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:49:12.065074 20451 solver.cpp:244]     Train net output #1: loss = 0.187688 (* 1 = 0.187688 loss)
I0808 16:49:12.065088 20451 sgd_solver.cpp:106] Iteration 4780, lr = 0.000746009
I0808 16:49:34.369954 20451 solver.cpp:228] Iteration 4790, loss = 0.218878
I0808 16:49:34.370007 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:49:34.370020 20451 solver.cpp:244]     Train net output #1: loss = 0.218878 (* 1 = 0.218878 loss)
I0808 16:49:34.370033 20451 sgd_solver.cpp:106] Iteration 4790, lr = 0.000745631
I0808 16:49:54.453982 20451 solver.cpp:337] Iteration 4800, Testing net (#0)
I0808 16:50:02.988298 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 16:50:02.988345 20451 solver.cpp:404]     Test net output #1: loss = 1.00333 (* 1 = 1.00333 loss)
I0808 16:50:05.194237 20451 solver.cpp:228] Iteration 4800, loss = 0.187593
I0808 16:50:05.194288 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:50:05.194301 20451 solver.cpp:244]     Train net output #1: loss = 0.187592 (* 1 = 0.187592 loss)
I0808 16:50:05.194314 20451 sgd_solver.cpp:106] Iteration 4800, lr = 0.000745253
I0808 16:50:27.478322 20451 solver.cpp:228] Iteration 4810, loss = 0.156341
I0808 16:50:27.478513 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:50:27.478528 20451 solver.cpp:244]     Train net output #1: loss = 0.156341 (* 1 = 0.156341 loss)
I0808 16:50:27.478540 20451 sgd_solver.cpp:106] Iteration 4810, lr = 0.000744876
I0808 16:50:49.784426 20451 solver.cpp:228] Iteration 4820, loss = 0.156257
I0808 16:50:49.784474 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:50:49.784489 20451 solver.cpp:244]     Train net output #1: loss = 0.156257 (* 1 = 0.156257 loss)
I0808 16:50:49.784502 20451 sgd_solver.cpp:106] Iteration 4820, lr = 0.000744499
I0808 16:51:12.096822 20451 solver.cpp:228] Iteration 4830, loss = 0.156437
I0808 16:51:12.096998 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:51:12.097018 20451 solver.cpp:244]     Train net output #1: loss = 0.156437 (* 1 = 0.156437 loss)
I0808 16:51:12.097029 20451 sgd_solver.cpp:106] Iteration 4830, lr = 0.000744122
I0808 16:51:34.402153 20451 solver.cpp:228] Iteration 4840, loss = 0.093916
I0808 16:51:34.402205 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:51:34.402220 20451 solver.cpp:244]     Train net output #1: loss = 0.0939159 (* 1 = 0.0939159 loss)
I0808 16:51:34.402232 20451 sgd_solver.cpp:106] Iteration 4840, lr = 0.000743746
I0808 16:51:56.710415 20451 solver.cpp:228] Iteration 4850, loss = 0.156462
I0808 16:51:56.710590 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:51:56.710605 20451 solver.cpp:244]     Train net output #1: loss = 0.156462 (* 1 = 0.156462 loss)
I0808 16:51:56.710618 20451 sgd_solver.cpp:106] Iteration 4850, lr = 0.00074337
I0808 16:52:19.017783 20451 solver.cpp:228] Iteration 4860, loss = 0.218882
I0808 16:52:19.017837 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:52:19.017850 20451 solver.cpp:244]     Train net output #1: loss = 0.218882 (* 1 = 0.218882 loss)
I0808 16:52:19.017863 20451 sgd_solver.cpp:106] Iteration 4860, lr = 0.000742995
I0808 16:52:41.321420 20451 solver.cpp:228] Iteration 4870, loss = 0.187603
I0808 16:52:41.321600 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:52:41.321615 20451 solver.cpp:244]     Train net output #1: loss = 0.187603 (* 1 = 0.187603 loss)
I0808 16:52:41.321626 20451 sgd_solver.cpp:106] Iteration 4870, lr = 0.00074262
I0808 16:53:03.625031 20451 solver.cpp:228] Iteration 4880, loss = 0.125057
I0808 16:53:03.625088 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:53:03.625103 20451 solver.cpp:244]     Train net output #1: loss = 0.125057 (* 1 = 0.125057 loss)
I0808 16:53:03.625115 20451 sgd_solver.cpp:106] Iteration 4880, lr = 0.000742246
I0808 16:53:25.923343 20451 solver.cpp:228] Iteration 4890, loss = 0.281339
I0808 16:53:25.923521 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 16:53:25.923537 20451 solver.cpp:244]     Train net output #1: loss = 0.281338 (* 1 = 0.281338 loss)
I0808 16:53:25.923549 20451 sgd_solver.cpp:106] Iteration 4890, lr = 0.000741872
I0808 16:53:45.999455 20451 solver.cpp:337] Iteration 4900, Testing net (#0)
I0808 16:53:54.521973 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 16:53:54.522017 20451 solver.cpp:404]     Test net output #1: loss = 0.975508 (* 1 = 0.975508 loss)
I0808 16:53:56.725391 20451 solver.cpp:228] Iteration 4900, loss = 0.218893
I0808 16:53:56.725617 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:53:56.725633 20451 solver.cpp:244]     Train net output #1: loss = 0.218893 (* 1 = 0.218893 loss)
I0808 16:53:56.725646 20451 sgd_solver.cpp:106] Iteration 4900, lr = 0.000741499
I0808 16:54:19.007437 20451 solver.cpp:228] Iteration 4910, loss = 0.250249
I0808 16:54:19.007479 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 16:54:19.007493 20451 solver.cpp:244]     Train net output #1: loss = 0.250249 (* 1 = 0.250249 loss)
I0808 16:54:19.007505 20451 sgd_solver.cpp:106] Iteration 4910, lr = 0.000741126
I0808 16:54:41.310143 20451 solver.cpp:228] Iteration 4920, loss = 0.0625389
I0808 16:54:41.310250 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 16:54:41.310264 20451 solver.cpp:244]     Train net output #1: loss = 0.0625388 (* 1 = 0.0625388 loss)
I0808 16:54:41.310276 20451 sgd_solver.cpp:106] Iteration 4920, lr = 0.000740753
I0808 16:55:03.609944 20451 solver.cpp:228] Iteration 4930, loss = 0.250321
I0808 16:55:03.609997 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 16:55:03.610013 20451 solver.cpp:244]     Train net output #1: loss = 0.250321 (* 1 = 0.250321 loss)
I0808 16:55:03.610024 20451 sgd_solver.cpp:106] Iteration 4930, lr = 0.000740381
I0808 16:55:25.908088 20451 solver.cpp:228] Iteration 4940, loss = 0.219069
I0808 16:55:25.908196 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:55:25.908212 20451 solver.cpp:244]     Train net output #1: loss = 0.219069 (* 1 = 0.219069 loss)
I0808 16:55:25.908226 20451 sgd_solver.cpp:106] Iteration 4940, lr = 0.000740009
I0808 16:55:48.212769 20451 solver.cpp:228] Iteration 4950, loss = 0.0939872
I0808 16:55:48.212819 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 16:55:48.212833 20451 solver.cpp:244]     Train net output #1: loss = 0.0939872 (* 1 = 0.0939872 loss)
I0808 16:55:48.212846 20451 sgd_solver.cpp:106] Iteration 4950, lr = 0.000739638
I0808 16:56:10.509747 20451 solver.cpp:228] Iteration 4960, loss = 0.125037
I0808 16:56:10.509852 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 16:56:10.509868 20451 solver.cpp:244]     Train net output #1: loss = 0.125037 (* 1 = 0.125037 loss)
I0808 16:56:10.509881 20451 sgd_solver.cpp:106] Iteration 4960, lr = 0.000739267
I0808 16:56:32.817577 20451 solver.cpp:228] Iteration 4970, loss = 0.187728
I0808 16:56:32.817617 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:56:32.817631 20451 solver.cpp:244]     Train net output #1: loss = 0.187728 (* 1 = 0.187728 loss)
I0808 16:56:32.817644 20451 sgd_solver.cpp:106] Iteration 4970, lr = 0.000738897
I0808 16:56:55.112442 20451 solver.cpp:228] Iteration 4980, loss = 0.250043
I0808 16:56:55.112628 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 16:56:55.112644 20451 solver.cpp:244]     Train net output #1: loss = 0.250043 (* 1 = 0.250043 loss)
I0808 16:56:55.112656 20451 sgd_solver.cpp:106] Iteration 4980, lr = 0.000738527
I0808 16:57:17.416024 20451 solver.cpp:228] Iteration 4990, loss = 0.187806
I0808 16:57:17.416075 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 16:57:17.416090 20451 solver.cpp:244]     Train net output #1: loss = 0.187806 (* 1 = 0.187806 loss)
I0808 16:57:17.416101 20451 sgd_solver.cpp:106] Iteration 4990, lr = 0.000738157
I0808 16:57:37.488672 20451 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_5000.caffemodel
I0808 16:57:37.886456 20451 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_5000.solverstate
I0808 16:57:37.889206 20451 solver.cpp:337] Iteration 5000, Testing net (#0)
I0808 16:57:46.392604 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 16:57:46.392647 20451 solver.cpp:404]     Test net output #1: loss = 0.994055 (* 1 = 0.994055 loss)
I0808 16:57:48.599747 20451 solver.cpp:228] Iteration 5000, loss = 0.156323
I0808 16:57:48.599797 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:57:48.599812 20451 solver.cpp:244]     Train net output #1: loss = 0.156323 (* 1 = 0.156323 loss)
I0808 16:57:48.599823 20451 sgd_solver.cpp:106] Iteration 5000, lr = 0.000737788
I0808 16:58:10.905179 20451 solver.cpp:228] Iteration 5010, loss = 0.218757
I0808 16:58:10.905315 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 16:58:10.905331 20451 solver.cpp:244]     Train net output #1: loss = 0.218757 (* 1 = 0.218757 loss)
I0808 16:58:10.905344 20451 sgd_solver.cpp:106] Iteration 5010, lr = 0.000737419
I0808 16:58:33.205406 20451 solver.cpp:228] Iteration 5020, loss = 0.218828
I0808 16:58:33.205457 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 16:58:33.205471 20451 solver.cpp:244]     Train net output #1: loss = 0.218828 (* 1 = 0.218828 loss)
I0808 16:58:33.205482 20451 sgd_solver.cpp:106] Iteration 5020, lr = 0.000737051
I0808 16:58:55.503834 20451 solver.cpp:228] Iteration 5030, loss = 0.156457
I0808 16:58:55.503947 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:58:55.503962 20451 solver.cpp:244]     Train net output #1: loss = 0.156457 (* 1 = 0.156457 loss)
I0808 16:58:55.503974 20451 sgd_solver.cpp:106] Iteration 5030, lr = 0.000736683
I0808 16:59:17.809919 20451 solver.cpp:228] Iteration 5040, loss = 0.156523
I0808 16:59:17.809962 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 16:59:17.809988 20451 solver.cpp:244]     Train net output #1: loss = 0.156523 (* 1 = 0.156523 loss)
I0808 16:59:17.810003 20451 sgd_solver.cpp:106] Iteration 5040, lr = 0.000736316
I0808 16:59:40.108886 20451 solver.cpp:228] Iteration 5050, loss = 0.25052
I0808 16:59:40.108999 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 16:59:40.109015 20451 solver.cpp:244]     Train net output #1: loss = 0.25052 (* 1 = 0.25052 loss)
I0808 16:59:40.109030 20451 sgd_solver.cpp:106] Iteration 5050, lr = 0.000735949
I0808 17:00:02.420243 20451 solver.cpp:228] Iteration 5060, loss = 0.0938652
I0808 17:00:02.420286 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:00:02.420315 20451 solver.cpp:244]     Train net output #1: loss = 0.0938652 (* 1 = 0.0938652 loss)
I0808 17:00:02.420331 20451 sgd_solver.cpp:106] Iteration 5060, lr = 0.000735582
I0808 17:00:24.725430 20451 solver.cpp:228] Iteration 5070, loss = 0.15653
I0808 17:00:24.725618 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:00:24.725636 20451 solver.cpp:244]     Train net output #1: loss = 0.15653 (* 1 = 0.15653 loss)
I0808 17:00:24.725651 20451 sgd_solver.cpp:106] Iteration 5070, lr = 0.000735216
I0808 17:00:47.031572 20451 solver.cpp:228] Iteration 5080, loss = 0.0938625
I0808 17:00:47.031626 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:00:47.031641 20451 solver.cpp:244]     Train net output #1: loss = 0.0938625 (* 1 = 0.0938625 loss)
I0808 17:00:47.031654 20451 sgd_solver.cpp:106] Iteration 5080, lr = 0.000734851
I0808 17:01:09.337219 20451 solver.cpp:228] Iteration 5090, loss = 0.187899
I0808 17:01:09.337400 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 17:01:09.337416 20451 solver.cpp:244]     Train net output #1: loss = 0.187899 (* 1 = 0.187899 loss)
I0808 17:01:09.337430 20451 sgd_solver.cpp:106] Iteration 5090, lr = 0.000734485
I0808 17:01:29.415802 20451 solver.cpp:337] Iteration 5100, Testing net (#0)
I0808 17:01:37.941076 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 17:01:37.941126 20451 solver.cpp:404]     Test net output #1: loss = 1.00335 (* 1 = 1.00335 loss)
I0808 17:01:40.143093 20451 solver.cpp:228] Iteration 5100, loss = 0.156291
I0808 17:01:40.143259 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:01:40.143278 20451 solver.cpp:244]     Train net output #1: loss = 0.156291 (* 1 = 0.156291 loss)
I0808 17:01:40.143291 20451 sgd_solver.cpp:106] Iteration 5100, lr = 0.00073412
I0808 17:02:02.426082 20451 solver.cpp:228] Iteration 5110, loss = 0.250136
I0808 17:02:02.426133 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 17:02:02.426147 20451 solver.cpp:244]     Train net output #1: loss = 0.250136 (* 1 = 0.250136 loss)
I0808 17:02:02.426159 20451 sgd_solver.cpp:106] Iteration 5110, lr = 0.000733756
I0808 17:02:24.720940 20451 solver.cpp:228] Iteration 5120, loss = 0.218872
I0808 17:02:24.721156 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:02:24.721171 20451 solver.cpp:244]     Train net output #1: loss = 0.218872 (* 1 = 0.218872 loss)
I0808 17:02:24.721184 20451 sgd_solver.cpp:106] Iteration 5120, lr = 0.000733392
I0808 17:02:47.026038 20451 solver.cpp:228] Iteration 5130, loss = 0.218951
I0808 17:02:47.026089 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:02:47.026103 20451 solver.cpp:244]     Train net output #1: loss = 0.218951 (* 1 = 0.218951 loss)
I0808 17:02:47.026116 20451 sgd_solver.cpp:106] Iteration 5130, lr = 0.000733028
I0808 17:03:09.342151 20451 solver.cpp:228] Iteration 5140, loss = 0.312655
I0808 17:03:09.342331 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 17:03:09.342350 20451 solver.cpp:244]     Train net output #1: loss = 0.312655 (* 1 = 0.312655 loss)
I0808 17:03:09.342366 20451 sgd_solver.cpp:106] Iteration 5140, lr = 0.000732665
I0808 17:03:31.645084 20451 solver.cpp:228] Iteration 5150, loss = 0.125118
I0808 17:03:31.645129 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:03:31.645148 20451 solver.cpp:244]     Train net output #1: loss = 0.125118 (* 1 = 0.125118 loss)
I0808 17:03:31.645164 20451 sgd_solver.cpp:106] Iteration 5150, lr = 0.000732303
I0808 17:03:53.952108 20451 solver.cpp:228] Iteration 5160, loss = 0.156343
I0808 17:03:53.952285 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:03:53.952299 20451 solver.cpp:244]     Train net output #1: loss = 0.156343 (* 1 = 0.156343 loss)
I0808 17:03:53.952312 20451 sgd_solver.cpp:106] Iteration 5160, lr = 0.00073194
I0808 17:04:16.247475 20451 solver.cpp:228] Iteration 5170, loss = 0.218981
I0808 17:04:16.247527 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:04:16.247541 20451 solver.cpp:244]     Train net output #1: loss = 0.218981 (* 1 = 0.218981 loss)
I0808 17:04:16.247553 20451 sgd_solver.cpp:106] Iteration 5170, lr = 0.000731578
I0808 17:04:38.554891 20451 solver.cpp:228] Iteration 5180, loss = 0.218846
I0808 17:04:38.555068 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:04:38.555083 20451 solver.cpp:244]     Train net output #1: loss = 0.218846 (* 1 = 0.218846 loss)
I0808 17:04:38.555095 20451 sgd_solver.cpp:106] Iteration 5180, lr = 0.000731217
I0808 17:05:00.872241 20451 solver.cpp:228] Iteration 5190, loss = 0.125103
I0808 17:05:00.872293 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:05:00.872308 20451 solver.cpp:244]     Train net output #1: loss = 0.125103 (* 1 = 0.125103 loss)
I0808 17:05:00.872320 20451 sgd_solver.cpp:106] Iteration 5190, lr = 0.000730856
I0808 17:05:20.945289 20451 solver.cpp:337] Iteration 5200, Testing net (#0)
I0808 17:05:29.462438 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0808 17:05:29.462489 20451 solver.cpp:404]     Test net output #1: loss = 0.966108 (* 1 = 0.966108 loss)
I0808 17:05:31.664635 20451 solver.cpp:228] Iteration 5200, loss = 0.187621
I0808 17:05:31.664685 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:05:31.664697 20451 solver.cpp:244]     Train net output #1: loss = 0.187621 (* 1 = 0.187621 loss)
I0808 17:05:31.664710 20451 sgd_solver.cpp:106] Iteration 5200, lr = 0.000730495
I0808 17:05:53.948882 20451 solver.cpp:228] Iteration 5210, loss = 0.125055
I0808 17:05:53.949059 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:05:53.949074 20451 solver.cpp:244]     Train net output #1: loss = 0.125054 (* 1 = 0.125054 loss)
I0808 17:05:53.949087 20451 sgd_solver.cpp:106] Iteration 5210, lr = 0.000730135
I0808 17:06:16.250026 20451 solver.cpp:228] Iteration 5220, loss = 0.156674
I0808 17:06:16.250068 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:06:16.250083 20451 solver.cpp:244]     Train net output #1: loss = 0.156674 (* 1 = 0.156674 loss)
I0808 17:06:16.250097 20451 sgd_solver.cpp:106] Iteration 5220, lr = 0.000729775
I0808 17:06:38.548189 20451 solver.cpp:228] Iteration 5230, loss = 0.187729
I0808 17:06:38.548393 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:06:38.548408 20451 solver.cpp:244]     Train net output #1: loss = 0.187729 (* 1 = 0.187729 loss)
I0808 17:06:38.548420 20451 sgd_solver.cpp:106] Iteration 5230, lr = 0.000729416
I0808 17:07:00.850914 20451 solver.cpp:228] Iteration 5240, loss = 0.344535
I0808 17:07:00.850965 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 17:07:00.850978 20451 solver.cpp:244]     Train net output #1: loss = 0.344535 (* 1 = 0.344535 loss)
I0808 17:07:00.850991 20451 sgd_solver.cpp:106] Iteration 5240, lr = 0.000729057
I0808 17:07:23.151784 20451 solver.cpp:228] Iteration 5250, loss = 0.250288
I0808 17:07:23.151912 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 17:07:23.151931 20451 solver.cpp:244]     Train net output #1: loss = 0.250288 (* 1 = 0.250288 loss)
I0808 17:07:23.151942 20451 sgd_solver.cpp:106] Iteration 5250, lr = 0.000728698
I0808 17:07:45.460239 20451 solver.cpp:228] Iteration 5260, loss = 0.125153
I0808 17:07:45.460292 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:07:45.460306 20451 solver.cpp:244]     Train net output #1: loss = 0.125153 (* 1 = 0.125153 loss)
I0808 17:07:45.460319 20451 sgd_solver.cpp:106] Iteration 5260, lr = 0.00072834
I0808 17:08:07.762634 20451 solver.cpp:228] Iteration 5270, loss = 0.15647
I0808 17:08:07.762743 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:08:07.762763 20451 solver.cpp:244]     Train net output #1: loss = 0.15647 (* 1 = 0.15647 loss)
I0808 17:08:07.762776 20451 sgd_solver.cpp:106] Iteration 5270, lr = 0.000727982
I0808 17:08:30.061123 20451 solver.cpp:228] Iteration 5280, loss = 0.156704
I0808 17:08:30.061169 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:08:30.061188 20451 solver.cpp:244]     Train net output #1: loss = 0.156704 (* 1 = 0.156704 loss)
I0808 17:08:30.061214 20451 sgd_solver.cpp:106] Iteration 5280, lr = 0.000727625
I0808 17:08:52.365738 20451 solver.cpp:228] Iteration 5290, loss = 0.156721
I0808 17:08:52.365914 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:08:52.365931 20451 solver.cpp:244]     Train net output #1: loss = 0.156721 (* 1 = 0.156721 loss)
I0808 17:08:52.365947 20451 sgd_solver.cpp:106] Iteration 5290, lr = 0.000727268
I0808 17:09:12.442327 20451 solver.cpp:337] Iteration 5300, Testing net (#0)
I0808 17:09:20.967365 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0808 17:09:20.967417 20451 solver.cpp:404]     Test net output #1: loss = 1.03144 (* 1 = 1.03144 loss)
I0808 17:09:23.170123 20451 solver.cpp:228] Iteration 5300, loss = 0.156285
I0808 17:09:23.170302 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:09:23.170320 20451 solver.cpp:244]     Train net output #1: loss = 0.156285 (* 1 = 0.156285 loss)
I0808 17:09:23.170336 20451 sgd_solver.cpp:106] Iteration 5300, lr = 0.000726911
I0808 17:09:45.442198 20451 solver.cpp:228] Iteration 5310, loss = 0.093889
I0808 17:09:45.442243 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:09:45.442272 20451 solver.cpp:244]     Train net output #1: loss = 0.093889 (* 1 = 0.093889 loss)
I0808 17:09:45.442288 20451 sgd_solver.cpp:106] Iteration 5310, lr = 0.000726555
I0808 17:10:07.739987 20451 solver.cpp:228] Iteration 5320, loss = 0.187617
I0808 17:10:07.740100 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:10:07.740120 20451 solver.cpp:244]     Train net output #1: loss = 0.187617 (* 1 = 0.187617 loss)
I0808 17:10:07.740134 20451 sgd_solver.cpp:106] Iteration 5320, lr = 0.000726199
I0808 17:10:30.042817 20451 solver.cpp:228] Iteration 5330, loss = 0.1563
I0808 17:10:30.042862 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:10:30.042881 20451 solver.cpp:244]     Train net output #1: loss = 0.1563 (* 1 = 0.1563 loss)
I0808 17:10:30.042906 20451 sgd_solver.cpp:106] Iteration 5330, lr = 0.000725844
I0808 17:10:52.334514 20451 solver.cpp:228] Iteration 5340, loss = 0.187695
I0808 17:10:52.334652 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:10:52.334668 20451 solver.cpp:244]     Train net output #1: loss = 0.187695 (* 1 = 0.187695 loss)
I0808 17:10:52.334681 20451 sgd_solver.cpp:106] Iteration 5340, lr = 0.000725489
I0808 17:11:14.644567 20451 solver.cpp:228] Iteration 5350, loss = 0.250166
I0808 17:11:14.644620 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 17:11:14.644634 20451 solver.cpp:244]     Train net output #1: loss = 0.250166 (* 1 = 0.250166 loss)
I0808 17:11:14.644646 20451 sgd_solver.cpp:106] Iteration 5350, lr = 0.000725135
I0808 17:11:36.940662 20451 solver.cpp:228] Iteration 5360, loss = 0.218922
I0808 17:11:36.940871 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:11:36.940886 20451 solver.cpp:244]     Train net output #1: loss = 0.218922 (* 1 = 0.218922 loss)
I0808 17:11:36.940899 20451 sgd_solver.cpp:106] Iteration 5360, lr = 0.000724781
I0808 17:11:59.241761 20451 solver.cpp:228] Iteration 5370, loss = 0.218961
I0808 17:11:59.241814 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:11:59.241828 20451 solver.cpp:244]     Train net output #1: loss = 0.218961 (* 1 = 0.218961 loss)
I0808 17:11:59.241840 20451 sgd_solver.cpp:106] Iteration 5370, lr = 0.000724427
I0808 17:12:21.543892 20451 solver.cpp:228] Iteration 5380, loss = 0.312627
I0808 17:12:21.544072 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 17:12:21.544087 20451 solver.cpp:244]     Train net output #1: loss = 0.312627 (* 1 = 0.312627 loss)
I0808 17:12:21.544100 20451 sgd_solver.cpp:106] Iteration 5380, lr = 0.000724074
I0808 17:12:43.855888 20451 solver.cpp:228] Iteration 5390, loss = 0.218774
I0808 17:12:43.855937 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:12:43.855957 20451 solver.cpp:244]     Train net output #1: loss = 0.218774 (* 1 = 0.218774 loss)
I0808 17:12:43.855972 20451 sgd_solver.cpp:106] Iteration 5390, lr = 0.000723721
I0808 17:13:03.936915 20451 solver.cpp:337] Iteration 5400, Testing net (#0)
I0808 17:13:12.453395 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 17:13:12.453450 20451 solver.cpp:404]     Test net output #1: loss = 1.00374 (* 1 = 1.00374 loss)
I0808 17:13:14.655974 20451 solver.cpp:228] Iteration 5400, loss = 0.187659
I0808 17:13:14.656028 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:13:14.656041 20451 solver.cpp:244]     Train net output #1: loss = 0.187659 (* 1 = 0.187659 loss)
I0808 17:13:14.656054 20451 sgd_solver.cpp:106] Iteration 5400, lr = 0.000723368
I0808 17:13:36.942412 20451 solver.cpp:228] Iteration 5410, loss = 0.125108
I0808 17:13:36.942597 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:13:36.942612 20451 solver.cpp:244]     Train net output #1: loss = 0.125108 (* 1 = 0.125108 loss)
I0808 17:13:36.942625 20451 sgd_solver.cpp:106] Iteration 5410, lr = 0.000723016
I0808 17:13:59.242103 20451 solver.cpp:228] Iteration 5420, loss = 0.18762
I0808 17:13:59.242156 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:13:59.242169 20451 solver.cpp:244]     Train net output #1: loss = 0.18762 (* 1 = 0.18762 loss)
I0808 17:13:59.242182 20451 sgd_solver.cpp:106] Iteration 5420, lr = 0.000722665
I0808 17:14:21.538035 20451 solver.cpp:228] Iteration 5430, loss = 0.156328
I0808 17:14:21.538203 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:14:21.538218 20451 solver.cpp:244]     Train net output #1: loss = 0.156328 (* 1 = 0.156328 loss)
I0808 17:14:21.538231 20451 sgd_solver.cpp:106] Iteration 5430, lr = 0.000722313
I0808 17:14:43.837653 20451 solver.cpp:228] Iteration 5440, loss = 0.281359
I0808 17:14:43.837714 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 17:14:43.837730 20451 solver.cpp:244]     Train net output #1: loss = 0.281359 (* 1 = 0.281359 loss)
I0808 17:14:43.837743 20451 sgd_solver.cpp:106] Iteration 5440, lr = 0.000721962
I0808 17:15:06.135717 20451 solver.cpp:228] Iteration 5450, loss = 0.18754
I0808 17:15:06.135872 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:15:06.135887 20451 solver.cpp:244]     Train net output #1: loss = 0.18754 (* 1 = 0.18754 loss)
I0808 17:15:06.135900 20451 sgd_solver.cpp:106] Iteration 5450, lr = 0.000721612
I0808 17:15:28.430315 20451 solver.cpp:228] Iteration 5460, loss = 0.219106
I0808 17:15:28.430372 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:15:28.430387 20451 solver.cpp:244]     Train net output #1: loss = 0.219106 (* 1 = 0.219106 loss)
I0808 17:15:28.430399 20451 sgd_solver.cpp:106] Iteration 5460, lr = 0.000721262
I0808 17:15:50.732887 20451 solver.cpp:228] Iteration 5470, loss = 0.187961
I0808 17:15:50.733063 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:15:50.733078 20451 solver.cpp:244]     Train net output #1: loss = 0.187961 (* 1 = 0.187961 loss)
I0808 17:15:50.733091 20451 sgd_solver.cpp:106] Iteration 5470, lr = 0.000720912
I0808 17:16:13.032945 20451 solver.cpp:228] Iteration 5480, loss = 0.218831
I0808 17:16:13.032996 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:16:13.033010 20451 solver.cpp:244]     Train net output #1: loss = 0.218831 (* 1 = 0.218831 loss)
I0808 17:16:13.033022 20451 sgd_solver.cpp:106] Iteration 5480, lr = 0.000720563
I0808 17:16:35.338122 20451 solver.cpp:228] Iteration 5490, loss = 0.0938216
I0808 17:16:35.338295 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:16:35.338311 20451 solver.cpp:244]     Train net output #1: loss = 0.0938216 (* 1 = 0.0938216 loss)
I0808 17:16:35.338325 20451 sgd_solver.cpp:106] Iteration 5490, lr = 0.000720214
I0808 17:16:55.418952 20451 solver.cpp:337] Iteration 5500, Testing net (#0)
I0808 17:17:03.946720 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 17:17:03.946771 20451 solver.cpp:404]     Test net output #1: loss = 0.984588 (* 1 = 0.984588 loss)
I0808 17:17:06.154651 20451 solver.cpp:228] Iteration 5500, loss = 0.187552
I0808 17:17:06.154829 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:17:06.154844 20451 solver.cpp:244]     Train net output #1: loss = 0.187552 (* 1 = 0.187552 loss)
I0808 17:17:06.154856 20451 sgd_solver.cpp:106] Iteration 5500, lr = 0.000719865
I0808 17:17:28.433604 20451 solver.cpp:228] Iteration 5510, loss = 0.187566
I0808 17:17:28.433657 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 17:17:28.433671 20451 solver.cpp:244]     Train net output #1: loss = 0.187566 (* 1 = 0.187566 loss)
I0808 17:17:28.433683 20451 sgd_solver.cpp:106] Iteration 5510, lr = 0.000719517
I0808 17:17:50.739715 20451 solver.cpp:228] Iteration 5520, loss = 0.156338
I0808 17:17:50.739891 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:17:50.739905 20451 solver.cpp:244]     Train net output #1: loss = 0.156338 (* 1 = 0.156338 loss)
I0808 17:17:50.739917 20451 sgd_solver.cpp:106] Iteration 5520, lr = 0.000719169
I0808 17:18:13.058522 20451 solver.cpp:228] Iteration 5530, loss = 0.187633
I0808 17:18:13.058573 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 17:18:13.058585 20451 solver.cpp:244]     Train net output #1: loss = 0.187633 (* 1 = 0.187633 loss)
I0808 17:18:13.058598 20451 sgd_solver.cpp:106] Iteration 5530, lr = 0.000718822
I0808 17:18:35.372512 20451 solver.cpp:228] Iteration 5540, loss = 0.156361
I0808 17:18:35.372736 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 17:18:35.372751 20451 solver.cpp:244]     Train net output #1: loss = 0.156361 (* 1 = 0.156361 loss)
I0808 17:18:35.372763 20451 sgd_solver.cpp:106] Iteration 5540, lr = 0.000718475
I0808 17:18:57.677304 20451 solver.cpp:228] Iteration 5550, loss = 0.344036
I0808 17:18:57.677356 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 17:18:57.677369 20451 solver.cpp:244]     Train net output #1: loss = 0.344036 (* 1 = 0.344036 loss)
I0808 17:18:57.677381 20451 sgd_solver.cpp:106] Iteration 5550, lr = 0.000718129
I0808 17:19:19.989111 20451 solver.cpp:228] Iteration 5560, loss = 0.125014
I0808 17:19:19.989215 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:19:19.989230 20451 solver.cpp:244]     Train net output #1: loss = 0.125014 (* 1 = 0.125014 loss)
I0808 17:19:19.989243 20451 sgd_solver.cpp:106] Iteration 5560, lr = 0.000717782
I0808 17:19:42.303469 20451 solver.cpp:228] Iteration 5570, loss = 0.250167
I0808 17:19:42.303522 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 17:19:42.303536 20451 solver.cpp:244]     Train net output #1: loss = 0.250167 (* 1 = 0.250167 loss)
I0808 17:19:42.303550 20451 sgd_solver.cpp:106] Iteration 5570, lr = 0.000717437
I0808 17:20:04.617516 20451 solver.cpp:228] Iteration 5580, loss = 0.188036
I0808 17:20:04.617694 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:20:04.617709 20451 solver.cpp:244]     Train net output #1: loss = 0.188036 (* 1 = 0.188036 loss)
I0808 17:20:04.617722 20451 sgd_solver.cpp:106] Iteration 5580, lr = 0.000717091
I0808 17:20:26.924585 20451 solver.cpp:228] Iteration 5590, loss = 0.156414
I0808 17:20:26.924638 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:20:26.924652 20451 solver.cpp:244]     Train net output #1: loss = 0.156414 (* 1 = 0.156414 loss)
I0808 17:20:26.924664 20451 sgd_solver.cpp:106] Iteration 5590, lr = 0.000716746
I0808 17:20:46.999586 20451 solver.cpp:337] Iteration 5600, Testing net (#0)
I0808 17:20:55.517974 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 17:20:55.518024 20451 solver.cpp:404]     Test net output #1: loss = 0.999964 (* 1 = 0.999964 loss)
I0808 17:20:57.719959 20451 solver.cpp:228] Iteration 5600, loss = 0.187918
I0808 17:20:57.720011 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:20:57.720026 20451 solver.cpp:244]     Train net output #1: loss = 0.187918 (* 1 = 0.187918 loss)
I0808 17:20:57.720038 20451 sgd_solver.cpp:106] Iteration 5600, lr = 0.000716402
I0808 17:21:20.005596 20451 solver.cpp:228] Iteration 5610, loss = 0.250123
I0808 17:21:20.005702 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 17:21:20.005722 20451 solver.cpp:244]     Train net output #1: loss = 0.250123 (* 1 = 0.250123 loss)
I0808 17:21:20.005738 20451 sgd_solver.cpp:106] Iteration 5610, lr = 0.000716057
I0808 17:21:42.302228 20451 solver.cpp:228] Iteration 5620, loss = 0.156617
I0808 17:21:42.302271 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:21:42.302299 20451 solver.cpp:244]     Train net output #1: loss = 0.156617 (* 1 = 0.156617 loss)
I0808 17:21:42.302315 20451 sgd_solver.cpp:106] Iteration 5620, lr = 0.000715714
I0808 17:22:04.596125 20451 solver.cpp:228] Iteration 5630, loss = 0.187589
I0808 17:22:04.596304 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:22:04.596319 20451 solver.cpp:244]     Train net output #1: loss = 0.187589 (* 1 = 0.187589 loss)
I0808 17:22:04.596333 20451 sgd_solver.cpp:106] Iteration 5630, lr = 0.00071537
I0808 17:22:26.899752 20451 solver.cpp:228] Iteration 5640, loss = 0.438863
I0808 17:22:26.899801 20451 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0808 17:22:26.899819 20451 solver.cpp:244]     Train net output #1: loss = 0.438863 (* 1 = 0.438863 loss)
I0808 17:22:26.899835 20451 sgd_solver.cpp:106] Iteration 5640, lr = 0.000715027
I0808 17:22:49.212841 20451 solver.cpp:228] Iteration 5650, loss = 0.219013
I0808 17:22:49.213057 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:22:49.213073 20451 solver.cpp:244]     Train net output #1: loss = 0.219013 (* 1 = 0.219013 loss)
I0808 17:22:49.213085 20451 sgd_solver.cpp:106] Iteration 5650, lr = 0.000714684
I0808 17:23:11.512573 20451 solver.cpp:228] Iteration 5660, loss = 0.312596
I0808 17:23:11.512626 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 17:23:11.512640 20451 solver.cpp:244]     Train net output #1: loss = 0.312596 (* 1 = 0.312596 loss)
I0808 17:23:11.512652 20451 sgd_solver.cpp:106] Iteration 5660, lr = 0.000714342
I0808 17:23:33.813896 20451 solver.cpp:228] Iteration 5670, loss = 0.312664
I0808 17:23:33.814061 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 17:23:33.814077 20451 solver.cpp:244]     Train net output #1: loss = 0.312664 (* 1 = 0.312664 loss)
I0808 17:23:33.814090 20451 sgd_solver.cpp:106] Iteration 5670, lr = 0.000714
I0808 17:23:56.113979 20451 solver.cpp:228] Iteration 5680, loss = 0.125039
I0808 17:23:56.114030 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:23:56.114045 20451 solver.cpp:244]     Train net output #1: loss = 0.125039 (* 1 = 0.125039 loss)
I0808 17:23:56.114056 20451 sgd_solver.cpp:106] Iteration 5680, lr = 0.000713659
I0808 17:24:18.434069 20451 solver.cpp:228] Iteration 5690, loss = 0.156364
I0808 17:24:18.434267 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:24:18.434334 20451 solver.cpp:244]     Train net output #1: loss = 0.156364 (* 1 = 0.156364 loss)
I0808 17:24:18.434355 20451 sgd_solver.cpp:106] Iteration 5690, lr = 0.000713317
I0808 17:24:38.515568 20451 solver.cpp:337] Iteration 5700, Testing net (#0)
I0808 17:24:47.037204 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 17:24:47.037253 20451 solver.cpp:404]     Test net output #1: loss = 0.998509 (* 1 = 0.998509 loss)
I0808 17:24:49.239573 20451 solver.cpp:228] Iteration 5700, loss = 0.031391
I0808 17:24:49.239744 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:24:49.239760 20451 solver.cpp:244]     Train net output #1: loss = 0.031391 (* 1 = 0.031391 loss)
I0808 17:24:49.239773 20451 sgd_solver.cpp:106] Iteration 5700, lr = 0.000712977
I0808 17:25:11.518693 20451 solver.cpp:228] Iteration 5710, loss = 0.125131
I0808 17:25:11.518745 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:25:11.518759 20451 solver.cpp:244]     Train net output #1: loss = 0.125131 (* 1 = 0.125131 loss)
I0808 17:25:11.518772 20451 sgd_solver.cpp:106] Iteration 5710, lr = 0.000712636
I0808 17:25:33.827366 20451 solver.cpp:228] Iteration 5720, loss = 0.250168
I0808 17:25:33.827543 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 17:25:33.827559 20451 solver.cpp:244]     Train net output #1: loss = 0.250168 (* 1 = 0.250168 loss)
I0808 17:25:33.827572 20451 sgd_solver.cpp:106] Iteration 5720, lr = 0.000712296
I0808 17:25:56.123219 20451 solver.cpp:228] Iteration 5730, loss = 0.125051
I0808 17:25:56.123270 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:25:56.123287 20451 solver.cpp:244]     Train net output #1: loss = 0.125051 (* 1 = 0.125051 loss)
I0808 17:25:56.123299 20451 sgd_solver.cpp:106] Iteration 5730, lr = 0.000711957
I0808 17:26:18.433432 20451 solver.cpp:228] Iteration 5740, loss = 0.156435
I0808 17:26:18.433624 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:26:18.433639 20451 solver.cpp:244]     Train net output #1: loss = 0.156435 (* 1 = 0.156435 loss)
I0808 17:26:18.433651 20451 sgd_solver.cpp:106] Iteration 5740, lr = 0.000711617
I0808 17:26:40.736291 20451 solver.cpp:228] Iteration 5750, loss = 0.1251
I0808 17:26:40.736337 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:26:40.736353 20451 solver.cpp:244]     Train net output #1: loss = 0.1251 (* 1 = 0.1251 loss)
I0808 17:26:40.736366 20451 sgd_solver.cpp:106] Iteration 5750, lr = 0.000711278
I0808 17:27:03.048650 20451 solver.cpp:228] Iteration 5760, loss = 0.250078
I0808 17:27:03.048785 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 17:27:03.048805 20451 solver.cpp:244]     Train net output #1: loss = 0.250078 (* 1 = 0.250078 loss)
I0808 17:27:03.048821 20451 sgd_solver.cpp:106] Iteration 5760, lr = 0.00071094
I0808 17:27:25.336419 20451 solver.cpp:228] Iteration 5770, loss = 0.250013
I0808 17:27:25.336472 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:27:25.336486 20451 solver.cpp:244]     Train net output #1: loss = 0.250013 (* 1 = 0.250013 loss)
I0808 17:27:25.336498 20451 sgd_solver.cpp:106] Iteration 5770, lr = 0.000710602
I0808 17:27:47.629374 20451 solver.cpp:228] Iteration 5780, loss = 0.187584
I0808 17:27:47.629546 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:27:47.629561 20451 solver.cpp:244]     Train net output #1: loss = 0.187584 (* 1 = 0.187584 loss)
I0808 17:27:47.629573 20451 sgd_solver.cpp:106] Iteration 5780, lr = 0.000710264
I0808 17:28:09.931421 20451 solver.cpp:228] Iteration 5790, loss = 0.187531
I0808 17:28:09.931463 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:28:09.931478 20451 solver.cpp:244]     Train net output #1: loss = 0.187531 (* 1 = 0.187531 loss)
I0808 17:28:09.931491 20451 sgd_solver.cpp:106] Iteration 5790, lr = 0.000709927
I0808 17:28:30.010229 20451 solver.cpp:337] Iteration 5800, Testing net (#0)
I0808 17:28:38.533372 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 17:28:38.533422 20451 solver.cpp:404]     Test net output #1: loss = 1.00787 (* 1 = 1.00787 loss)
I0808 17:28:40.735793 20451 solver.cpp:228] Iteration 5800, loss = 0.31253
I0808 17:28:40.735839 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 17:28:40.735858 20451 solver.cpp:244]     Train net output #1: loss = 0.31253 (* 1 = 0.31253 loss)
I0808 17:28:40.735872 20451 sgd_solver.cpp:106] Iteration 5800, lr = 0.00070959
I0808 17:29:03.019481 20451 solver.cpp:228] Iteration 5810, loss = 0.312625
I0808 17:29:03.019659 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 17:29:03.019676 20451 solver.cpp:244]     Train net output #1: loss = 0.312625 (* 1 = 0.312625 loss)
I0808 17:29:03.019691 20451 sgd_solver.cpp:106] Iteration 5810, lr = 0.000709253
I0808 17:29:25.315850 20451 solver.cpp:228] Iteration 5820, loss = 0.187538
I0808 17:29:25.315903 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:29:25.315917 20451 solver.cpp:244]     Train net output #1: loss = 0.187538 (* 1 = 0.187538 loss)
I0808 17:29:25.315929 20451 sgd_solver.cpp:106] Iteration 5820, lr = 0.000708917
I0808 17:29:47.617118 20451 solver.cpp:228] Iteration 5830, loss = 0.125032
I0808 17:29:47.617298 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:29:47.617313 20451 solver.cpp:244]     Train net output #1: loss = 0.125032 (* 1 = 0.125032 loss)
I0808 17:29:47.617326 20451 sgd_solver.cpp:106] Iteration 5830, lr = 0.000708581
I0808 17:30:09.919756 20451 solver.cpp:228] Iteration 5840, loss = 0.156441
I0808 17:30:09.919809 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:30:09.919823 20451 solver.cpp:244]     Train net output #1: loss = 0.156441 (* 1 = 0.156441 loss)
I0808 17:30:09.919836 20451 sgd_solver.cpp:106] Iteration 5840, lr = 0.000708245
I0808 17:30:32.223763 20451 solver.cpp:228] Iteration 5850, loss = 0.218915
I0808 17:30:32.223948 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:30:32.223963 20451 solver.cpp:244]     Train net output #1: loss = 0.218915 (* 1 = 0.218915 loss)
I0808 17:30:32.223976 20451 sgd_solver.cpp:106] Iteration 5850, lr = 0.00070791
I0808 17:30:54.522984 20451 solver.cpp:228] Iteration 5860, loss = 0.125104
I0808 17:30:54.523036 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:30:54.523051 20451 solver.cpp:244]     Train net output #1: loss = 0.125104 (* 1 = 0.125104 loss)
I0808 17:30:54.523063 20451 sgd_solver.cpp:106] Iteration 5860, lr = 0.000707575
I0808 17:31:16.829797 20451 solver.cpp:228] Iteration 5870, loss = 0.218806
I0808 17:31:16.830314 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:31:16.830350 20451 solver.cpp:244]     Train net output #1: loss = 0.218806 (* 1 = 0.218806 loss)
I0808 17:31:16.830391 20451 sgd_solver.cpp:106] Iteration 5870, lr = 0.000707241
I0808 17:31:39.135256 20451 solver.cpp:228] Iteration 5880, loss = 0.156316
I0808 17:31:39.135311 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:31:39.135325 20451 solver.cpp:244]     Train net output #1: loss = 0.156316 (* 1 = 0.156316 loss)
I0808 17:31:39.135339 20451 sgd_solver.cpp:106] Iteration 5880, lr = 0.000706907
I0808 17:32:01.431948 20451 solver.cpp:228] Iteration 5890, loss = 0.15635
I0808 17:32:01.432135 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:32:01.432150 20451 solver.cpp:244]     Train net output #1: loss = 0.15635 (* 1 = 0.15635 loss)
I0808 17:32:01.432163 20451 sgd_solver.cpp:106] Iteration 5890, lr = 0.000706573
I0808 17:32:21.503304 20451 solver.cpp:337] Iteration 5900, Testing net (#0)
I0808 17:32:30.019250 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 17:32:30.019309 20451 solver.cpp:404]     Test net output #1: loss = 1.0037 (* 1 = 1.0037 loss)
I0808 17:32:32.219928 20451 solver.cpp:228] Iteration 5900, loss = 0.125124
I0808 17:32:32.220037 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:32:32.220052 20451 solver.cpp:244]     Train net output #1: loss = 0.125124 (* 1 = 0.125124 loss)
I0808 17:32:32.220065 20451 sgd_solver.cpp:106] Iteration 5900, lr = 0.00070624
I0808 17:32:54.498805 20451 solver.cpp:228] Iteration 5910, loss = 0.187643
I0808 17:32:54.498913 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:32:54.498965 20451 solver.cpp:244]     Train net output #1: loss = 0.187643 (* 1 = 0.187643 loss)
I0808 17:32:54.499114 20451 sgd_solver.cpp:106] Iteration 5910, lr = 0.000705907
I0808 17:33:16.795320 20451 solver.cpp:228] Iteration 5920, loss = 0.156326
I0808 17:33:16.795469 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:33:16.795485 20451 solver.cpp:244]     Train net output #1: loss = 0.156326 (* 1 = 0.156326 loss)
I0808 17:33:16.795497 20451 sgd_solver.cpp:106] Iteration 5920, lr = 0.000705574
I0808 17:33:39.104939 20451 solver.cpp:228] Iteration 5930, loss = 0.0938206
I0808 17:33:39.104990 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:33:39.105005 20451 solver.cpp:244]     Train net output #1: loss = 0.0938206 (* 1 = 0.0938206 loss)
I0808 17:33:39.105016 20451 sgd_solver.cpp:106] Iteration 5930, lr = 0.000705242
I0808 17:34:01.408124 20451 solver.cpp:228] Iteration 5940, loss = 0.0312722
I0808 17:34:01.408290 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 17:34:01.408305 20451 solver.cpp:244]     Train net output #1: loss = 0.0312722 (* 1 = 0.0312722 loss)
I0808 17:34:01.408318 20451 sgd_solver.cpp:106] Iteration 5940, lr = 0.00070491
I0808 17:34:23.712460 20451 solver.cpp:228] Iteration 5950, loss = 0.0938122
I0808 17:34:23.712509 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:34:23.712524 20451 solver.cpp:244]     Train net output #1: loss = 0.0938122 (* 1 = 0.0938122 loss)
I0808 17:34:23.712537 20451 sgd_solver.cpp:106] Iteration 5950, lr = 0.000704579
I0808 17:34:46.014034 20451 solver.cpp:228] Iteration 5960, loss = 0.218836
I0808 17:34:46.014144 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:34:46.014160 20451 solver.cpp:244]     Train net output #1: loss = 0.218836 (* 1 = 0.218836 loss)
I0808 17:34:46.014173 20451 sgd_solver.cpp:106] Iteration 5960, lr = 0.000704248
I0808 17:35:08.314657 20451 solver.cpp:228] Iteration 5970, loss = 0.125214
I0808 17:35:08.314708 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:35:08.314723 20451 solver.cpp:244]     Train net output #1: loss = 0.125214 (* 1 = 0.125214 loss)
I0808 17:35:08.314735 20451 sgd_solver.cpp:106] Iteration 5970, lr = 0.000703917
I0808 17:35:30.614017 20451 solver.cpp:228] Iteration 5980, loss = 0.0939152
I0808 17:35:30.614171 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:35:30.614192 20451 solver.cpp:244]     Train net output #1: loss = 0.0939152 (* 1 = 0.0939152 loss)
I0808 17:35:30.614207 20451 sgd_solver.cpp:106] Iteration 5980, lr = 0.000703586
I0808 17:35:52.910945 20451 solver.cpp:228] Iteration 5990, loss = 0.18802
I0808 17:35:52.910991 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:35:52.911010 20451 solver.cpp:244]     Train net output #1: loss = 0.18802 (* 1 = 0.18802 loss)
I0808 17:35:52.911026 20451 sgd_solver.cpp:106] Iteration 5990, lr = 0.000703256
I0808 17:36:12.999043 20451 solver.cpp:337] Iteration 6000, Testing net (#0)
I0808 17:36:21.517446 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0808 17:36:21.517489 20451 solver.cpp:404]     Test net output #1: loss = 0.961162 (* 1 = 0.961162 loss)
I0808 17:36:23.718911 20451 solver.cpp:228] Iteration 6000, loss = 0.12559
I0808 17:36:23.718956 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:36:23.718973 20451 solver.cpp:244]     Train net output #1: loss = 0.12559 (* 1 = 0.12559 loss)
I0808 17:36:23.718998 20451 sgd_solver.cpp:106] Iteration 6000, lr = 0.000702927
I0808 17:36:45.996412 20451 solver.cpp:228] Iteration 6010, loss = 0.187871
I0808 17:36:45.996511 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:36:45.996531 20451 solver.cpp:244]     Train net output #1: loss = 0.187871 (* 1 = 0.187871 loss)
I0808 17:36:45.996547 20451 sgd_solver.cpp:106] Iteration 6010, lr = 0.000702597
I0808 17:37:08.307332 20451 solver.cpp:228] Iteration 6020, loss = 0.187729
I0808 17:37:08.307377 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:37:08.307395 20451 solver.cpp:244]     Train net output #1: loss = 0.187729 (* 1 = 0.187729 loss)
I0808 17:37:08.307410 20451 sgd_solver.cpp:106] Iteration 6020, lr = 0.000702268
I0808 17:37:30.604437 20451 solver.cpp:228] Iteration 6030, loss = 0.219231
I0808 17:37:30.604621 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:37:30.604636 20451 solver.cpp:244]     Train net output #1: loss = 0.219231 (* 1 = 0.219231 loss)
I0808 17:37:30.604648 20451 sgd_solver.cpp:106] Iteration 6030, lr = 0.00070194
I0808 17:37:52.894928 20451 solver.cpp:228] Iteration 6040, loss = 0.187699
I0808 17:37:52.894982 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:37:52.894995 20451 solver.cpp:244]     Train net output #1: loss = 0.187699 (* 1 = 0.187699 loss)
I0808 17:37:52.895007 20451 sgd_solver.cpp:106] Iteration 6040, lr = 0.000701612
I0808 17:38:15.196362 20451 solver.cpp:228] Iteration 6050, loss = 0.187738
I0808 17:38:15.196537 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:38:15.196552 20451 solver.cpp:244]     Train net output #1: loss = 0.187738 (* 1 = 0.187738 loss)
I0808 17:38:15.196564 20451 sgd_solver.cpp:106] Iteration 6050, lr = 0.000701284
I0808 17:38:37.493669 20451 solver.cpp:228] Iteration 6060, loss = 0.12519
I0808 17:38:37.493712 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 17:38:37.493738 20451 solver.cpp:244]     Train net output #1: loss = 0.12519 (* 1 = 0.12519 loss)
I0808 17:38:37.493755 20451 sgd_solver.cpp:106] Iteration 6060, lr = 0.000700956
I0808 17:38:59.797118 20451 solver.cpp:228] Iteration 6070, loss = 0.0625236
I0808 17:38:59.797250 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 17:38:59.797266 20451 solver.cpp:244]     Train net output #1: loss = 0.0625236 (* 1 = 0.0625236 loss)
I0808 17:38:59.797281 20451 sgd_solver.cpp:106] Iteration 6070, lr = 0.000700629
I0808 17:39:22.109024 20451 solver.cpp:228] Iteration 6080, loss = 0.0937672
I0808 17:39:22.109077 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:39:22.109091 20451 solver.cpp:244]     Train net output #1: loss = 0.0937672 (* 1 = 0.0937672 loss)
I0808 17:39:22.109103 20451 sgd_solver.cpp:106] Iteration 6080, lr = 0.000700302
I0808 17:39:44.415612 20451 solver.cpp:228] Iteration 6090, loss = 0.125044
I0808 17:39:44.415829 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:39:44.415845 20451 solver.cpp:244]     Train net output #1: loss = 0.125044 (* 1 = 0.125044 loss)
I0808 17:39:44.415858 20451 sgd_solver.cpp:106] Iteration 6090, lr = 0.000699976
I0808 17:40:04.495039 20451 solver.cpp:337] Iteration 6100, Testing net (#0)
I0808 17:40:13.018108 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 17:40:13.018159 20451 solver.cpp:404]     Test net output #1: loss = 0.994245 (* 1 = 0.994245 loss)
I0808 17:40:15.220926 20451 solver.cpp:228] Iteration 6100, loss = 0.343991
I0808 17:40:15.221099 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 17:40:15.221114 20451 solver.cpp:244]     Train net output #1: loss = 0.343991 (* 1 = 0.343991 loss)
I0808 17:40:15.221127 20451 sgd_solver.cpp:106] Iteration 6100, lr = 0.00069965
I0808 17:40:37.500447 20451 solver.cpp:228] Iteration 6110, loss = 0.187646
I0808 17:40:37.500500 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:40:37.500515 20451 solver.cpp:244]     Train net output #1: loss = 0.187646 (* 1 = 0.187646 loss)
I0808 17:40:37.500529 20451 sgd_solver.cpp:106] Iteration 6110, lr = 0.000699324
I0808 17:40:59.810129 20451 solver.cpp:228] Iteration 6120, loss = 0.218873
I0808 17:40:59.810322 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:40:59.810338 20451 solver.cpp:244]     Train net output #1: loss = 0.218873 (* 1 = 0.218873 loss)
I0808 17:40:59.810351 20451 sgd_solver.cpp:106] Iteration 6120, lr = 0.000698999
I0808 17:41:22.122849 20451 solver.cpp:228] Iteration 6130, loss = 0.21899
I0808 17:41:22.122905 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:41:22.122925 20451 solver.cpp:244]     Train net output #1: loss = 0.21899 (* 1 = 0.21899 loss)
I0808 17:41:22.122941 20451 sgd_solver.cpp:106] Iteration 6130, lr = 0.000698673
I0808 17:41:44.422319 20451 solver.cpp:228] Iteration 6140, loss = 0.156297
I0808 17:41:44.422504 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:41:44.422523 20451 solver.cpp:244]     Train net output #1: loss = 0.156297 (* 1 = 0.156297 loss)
I0808 17:41:44.422538 20451 sgd_solver.cpp:106] Iteration 6140, lr = 0.000698349
I0808 17:42:06.732172 20451 solver.cpp:228] Iteration 6150, loss = 0.0938516
I0808 17:42:06.732220 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:42:06.732237 20451 solver.cpp:244]     Train net output #1: loss = 0.0938516 (* 1 = 0.0938516 loss)
I0808 17:42:06.732254 20451 sgd_solver.cpp:106] Iteration 6150, lr = 0.000698024
I0808 17:42:29.038856 20451 solver.cpp:228] Iteration 6160, loss = 0.187623
I0808 17:42:29.038964 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:42:29.038985 20451 solver.cpp:244]     Train net output #1: loss = 0.187623 (* 1 = 0.187623 loss)
I0808 17:42:29.038998 20451 sgd_solver.cpp:106] Iteration 6160, lr = 0.0006977
I0808 17:42:51.343741 20451 solver.cpp:228] Iteration 6170, loss = 0.125158
I0808 17:42:51.343794 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:42:51.343812 20451 solver.cpp:244]     Train net output #1: loss = 0.125158 (* 1 = 0.125158 loss)
I0808 17:42:51.343828 20451 sgd_solver.cpp:106] Iteration 6170, lr = 0.000697377
I0808 17:43:13.647136 20451 solver.cpp:228] Iteration 6180, loss = 0.187606
I0808 17:43:13.647325 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:43:13.647342 20451 solver.cpp:244]     Train net output #1: loss = 0.187606 (* 1 = 0.187606 loss)
I0808 17:43:13.647358 20451 sgd_solver.cpp:106] Iteration 6180, lr = 0.000697054
I0808 17:43:35.960018 20451 solver.cpp:228] Iteration 6190, loss = 0.125085
I0808 17:43:35.960064 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:43:35.960081 20451 solver.cpp:244]     Train net output #1: loss = 0.125085 (* 1 = 0.125085 loss)
I0808 17:43:35.960098 20451 sgd_solver.cpp:106] Iteration 6190, lr = 0.000696731
I0808 17:43:56.041498 20451 solver.cpp:337] Iteration 6200, Testing net (#0)
I0808 17:44:04.570428 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 17:44:04.570480 20451 solver.cpp:404]     Test net output #1: loss = 0.999 (* 1 = 0.999 loss)
I0808 17:44:06.775287 20451 solver.cpp:228] Iteration 6200, loss = 0.0938227
I0808 17:44:06.775338 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:44:06.775352 20451 solver.cpp:244]     Train net output #1: loss = 0.0938227 (* 1 = 0.0938227 loss)
I0808 17:44:06.775364 20451 sgd_solver.cpp:106] Iteration 6200, lr = 0.000696408
I0808 17:44:29.058073 20451 solver.cpp:228] Iteration 6210, loss = 0.187662
I0808 17:44:29.058183 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:44:29.058198 20451 solver.cpp:244]     Train net output #1: loss = 0.187662 (* 1 = 0.187662 loss)
I0808 17:44:29.058212 20451 sgd_solver.cpp:106] Iteration 6210, lr = 0.000696086
I0808 17:44:51.365669 20451 solver.cpp:228] Iteration 6220, loss = 0.250137
I0808 17:44:51.365722 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 17:44:51.365736 20451 solver.cpp:244]     Train net output #1: loss = 0.250137 (* 1 = 0.250137 loss)
I0808 17:44:51.365748 20451 sgd_solver.cpp:106] Iteration 6220, lr = 0.000695764
I0808 17:45:13.677546 20451 solver.cpp:228] Iteration 6230, loss = 0.156432
I0808 17:45:13.677728 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:45:13.677744 20451 solver.cpp:244]     Train net output #1: loss = 0.156432 (* 1 = 0.156432 loss)
I0808 17:45:13.677757 20451 sgd_solver.cpp:106] Iteration 6230, lr = 0.000695442
I0808 17:45:35.985775 20451 solver.cpp:228] Iteration 6240, loss = 0.0941026
I0808 17:45:35.985821 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:45:35.985839 20451 solver.cpp:244]     Train net output #1: loss = 0.0941026 (* 1 = 0.0941026 loss)
I0808 17:45:35.985854 20451 sgd_solver.cpp:106] Iteration 6240, lr = 0.000695121
I0808 17:45:58.287634 20451 solver.cpp:228] Iteration 6250, loss = 0.0312686
I0808 17:45:58.287820 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 17:45:58.287839 20451 solver.cpp:244]     Train net output #1: loss = 0.0312686 (* 1 = 0.0312686 loss)
I0808 17:45:58.287855 20451 sgd_solver.cpp:106] Iteration 6250, lr = 0.0006948
I0808 17:46:20.597401 20451 solver.cpp:228] Iteration 6260, loss = 0.0941225
I0808 17:46:20.597447 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:46:20.597466 20451 solver.cpp:244]     Train net output #1: loss = 0.0941225 (* 1 = 0.0941225 loss)
I0808 17:46:20.597481 20451 sgd_solver.cpp:106] Iteration 6260, lr = 0.00069448
I0808 17:46:42.902979 20451 solver.cpp:228] Iteration 6270, loss = 0.156282
I0808 17:46:42.903162 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:46:42.903177 20451 solver.cpp:244]     Train net output #1: loss = 0.156282 (* 1 = 0.156282 loss)
I0808 17:46:42.903190 20451 sgd_solver.cpp:106] Iteration 6270, lr = 0.00069416
I0808 17:47:05.199581 20451 solver.cpp:228] Iteration 6280, loss = 0.281355
I0808 17:47:05.199635 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:47:05.199648 20451 solver.cpp:244]     Train net output #1: loss = 0.281355 (* 1 = 0.281355 loss)
I0808 17:47:05.199661 20451 sgd_solver.cpp:106] Iteration 6280, lr = 0.00069384
I0808 17:47:27.511380 20451 solver.cpp:228] Iteration 6290, loss = 0.281317
I0808 17:47:27.511559 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 17:47:27.511574 20451 solver.cpp:244]     Train net output #1: loss = 0.281317 (* 1 = 0.281317 loss)
I0808 17:47:27.511587 20451 sgd_solver.cpp:106] Iteration 6290, lr = 0.00069352
I0808 17:47:47.595614 20451 solver.cpp:337] Iteration 6300, Testing net (#0)
I0808 17:47:56.123013 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0808 17:47:56.123064 20451 solver.cpp:404]     Test net output #1: loss = 0.989106 (* 1 = 0.989106 loss)
I0808 17:47:58.325549 20451 solver.cpp:228] Iteration 6300, loss = 0.250181
I0808 17:47:58.325759 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:47:58.325775 20451 solver.cpp:244]     Train net output #1: loss = 0.250181 (* 1 = 0.250181 loss)
I0808 17:47:58.325788 20451 sgd_solver.cpp:106] Iteration 6300, lr = 0.000693201
I0808 17:48:21.233167 20451 solver.cpp:228] Iteration 6310, loss = 0.187532
I0808 17:48:21.233211 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:48:21.233228 20451 solver.cpp:244]     Train net output #1: loss = 0.187532 (* 1 = 0.187532 loss)
I0808 17:48:21.233242 20451 sgd_solver.cpp:106] Iteration 6310, lr = 0.000692882
I0808 17:48:43.657232 20451 solver.cpp:228] Iteration 6320, loss = 0.125045
I0808 17:48:43.657415 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:48:43.657435 20451 solver.cpp:244]     Train net output #1: loss = 0.125045 (* 1 = 0.125045 loss)
I0808 17:48:43.657450 20451 sgd_solver.cpp:106] Iteration 6320, lr = 0.000692564
I0808 17:49:05.964859 20451 solver.cpp:228] Iteration 6330, loss = 0.156292
I0808 17:49:05.964902 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:49:05.964928 20451 solver.cpp:244]     Train net output #1: loss = 0.156292 (* 1 = 0.156292 loss)
I0808 17:49:05.964944 20451 sgd_solver.cpp:106] Iteration 6330, lr = 0.000692246
I0808 17:49:28.264420 20451 solver.cpp:228] Iteration 6340, loss = 0.437769
I0808 17:49:28.264602 20451 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0808 17:49:28.264621 20451 solver.cpp:244]     Train net output #1: loss = 0.437769 (* 1 = 0.437769 loss)
I0808 17:49:28.264637 20451 sgd_solver.cpp:106] Iteration 6340, lr = 0.000691928
I0808 17:49:50.557215 20451 solver.cpp:228] Iteration 6350, loss = 0.218903
I0808 17:49:50.557270 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:49:50.557283 20451 solver.cpp:244]     Train net output #1: loss = 0.218903 (* 1 = 0.218903 loss)
I0808 17:49:50.557294 20451 sgd_solver.cpp:106] Iteration 6350, lr = 0.000691611
I0808 17:50:12.867096 20451 solver.cpp:228] Iteration 6360, loss = 0.125062
I0808 17:50:12.867210 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:50:12.867230 20451 solver.cpp:244]     Train net output #1: loss = 0.125062 (* 1 = 0.125062 loss)
I0808 17:50:12.867244 20451 sgd_solver.cpp:106] Iteration 6360, lr = 0.000691294
I0808 17:50:35.166033 20451 solver.cpp:228] Iteration 6370, loss = 0.156343
I0808 17:50:35.166087 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:50:35.166101 20451 solver.cpp:244]     Train net output #1: loss = 0.156343 (* 1 = 0.156343 loss)
I0808 17:50:35.166113 20451 sgd_solver.cpp:106] Iteration 6370, lr = 0.000690977
I0808 17:50:57.471915 20451 solver.cpp:228] Iteration 6380, loss = 0.156273
I0808 17:50:57.472095 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:50:57.472110 20451 solver.cpp:244]     Train net output #1: loss = 0.156273 (* 1 = 0.156273 loss)
I0808 17:50:57.472121 20451 sgd_solver.cpp:106] Iteration 6380, lr = 0.00069066
I0808 17:51:19.764642 20451 solver.cpp:228] Iteration 6390, loss = 0.093918
I0808 17:51:19.764688 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 17:51:19.764708 20451 solver.cpp:244]     Train net output #1: loss = 0.093918 (* 1 = 0.093918 loss)
I0808 17:51:19.764722 20451 sgd_solver.cpp:106] Iteration 6390, lr = 0.000690344
I0808 17:51:39.835443 20451 solver.cpp:337] Iteration 6400, Testing net (#0)
I0808 17:51:48.356767 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0808 17:51:48.356820 20451 solver.cpp:404]     Test net output #1: loss = 1.03649 (* 1 = 1.03649 loss)
I0808 17:51:50.559607 20451 solver.cpp:228] Iteration 6400, loss = 0.156366
I0808 17:51:50.559650 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:51:50.559665 20451 solver.cpp:244]     Train net output #1: loss = 0.156366 (* 1 = 0.156366 loss)
I0808 17:51:50.559679 20451 sgd_solver.cpp:106] Iteration 6400, lr = 0.000690029
I0808 17:52:12.851472 20451 solver.cpp:228] Iteration 6410, loss = 0.343796
I0808 17:52:12.851694 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 17:52:12.851711 20451 solver.cpp:244]     Train net output #1: loss = 0.343796 (* 1 = 0.343796 loss)
I0808 17:52:12.851722 20451 sgd_solver.cpp:106] Iteration 6410, lr = 0.000689713
I0808 17:52:35.160931 20451 solver.cpp:228] Iteration 6420, loss = 0.156276
I0808 17:52:35.160984 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:52:35.160997 20451 solver.cpp:244]     Train net output #1: loss = 0.156276 (* 1 = 0.156276 loss)
I0808 17:52:35.161010 20451 sgd_solver.cpp:106] Iteration 6420, lr = 0.000689398
I0808 17:52:57.473609 20451 solver.cpp:228] Iteration 6430, loss = 0.0937881
I0808 17:52:57.473788 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:52:57.473803 20451 solver.cpp:244]     Train net output #1: loss = 0.0937881 (* 1 = 0.0937881 loss)
I0808 17:52:57.473815 20451 sgd_solver.cpp:106] Iteration 6430, lr = 0.000689083
I0808 17:53:19.780910 20451 solver.cpp:228] Iteration 6440, loss = 0.0938157
I0808 17:53:19.780963 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 17:53:19.780983 20451 solver.cpp:244]     Train net output #1: loss = 0.0938157 (* 1 = 0.0938157 loss)
I0808 17:53:19.780999 20451 sgd_solver.cpp:106] Iteration 6440, lr = 0.000688769
I0808 17:53:42.083050 20451 solver.cpp:228] Iteration 6450, loss = 0.156262
I0808 17:53:42.083180 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:53:42.083200 20451 solver.cpp:244]     Train net output #1: loss = 0.156262 (* 1 = 0.156262 loss)
I0808 17:53:42.083217 20451 sgd_solver.cpp:106] Iteration 6450, lr = 0.000688455
I0808 17:54:04.392019 20451 solver.cpp:228] Iteration 6460, loss = 0.312796
I0808 17:54:04.392063 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 17:54:04.392081 20451 solver.cpp:244]     Train net output #1: loss = 0.312796 (* 1 = 0.312796 loss)
I0808 17:54:04.392107 20451 sgd_solver.cpp:106] Iteration 6460, lr = 0.000688141
I0808 17:54:26.699321 20451 solver.cpp:228] Iteration 6470, loss = 0.219198
I0808 17:54:26.699429 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:54:26.699446 20451 solver.cpp:244]     Train net output #1: loss = 0.219198 (* 1 = 0.219198 loss)
I0808 17:54:26.699461 20451 sgd_solver.cpp:106] Iteration 6470, lr = 0.000687828
I0808 17:54:49.018237 20451 solver.cpp:228] Iteration 6480, loss = 0.125038
I0808 17:54:49.018282 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:54:49.018309 20451 solver.cpp:244]     Train net output #1: loss = 0.125038 (* 1 = 0.125038 loss)
I0808 17:54:49.018326 20451 sgd_solver.cpp:106] Iteration 6480, lr = 0.000687515
I0808 17:55:11.333101 20451 solver.cpp:228] Iteration 6490, loss = 0.0937946
I0808 17:55:11.333283 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:55:11.333299 20451 solver.cpp:244]     Train net output #1: loss = 0.0937946 (* 1 = 0.0937946 loss)
I0808 17:55:11.333312 20451 sgd_solver.cpp:106] Iteration 6490, lr = 0.000687202
I0808 17:55:31.405194 20451 solver.cpp:337] Iteration 6500, Testing net (#0)
I0808 17:55:39.929177 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 17:55:39.929219 20451 solver.cpp:404]     Test net output #1: loss = 0.984892 (* 1 = 0.984892 loss)
I0808 17:55:42.134151 20451 solver.cpp:228] Iteration 6500, loss = 0.250183
I0808 17:55:42.134325 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 17:55:42.134341 20451 solver.cpp:244]     Train net output #1: loss = 0.250183 (* 1 = 0.250183 loss)
I0808 17:55:42.134352 20451 sgd_solver.cpp:106] Iteration 6500, lr = 0.00068689
I0808 17:56:04.411041 20451 solver.cpp:228] Iteration 6510, loss = 0.187552
I0808 17:56:04.411085 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:56:04.411100 20451 solver.cpp:244]     Train net output #1: loss = 0.187552 (* 1 = 0.187552 loss)
I0808 17:56:04.411113 20451 sgd_solver.cpp:106] Iteration 6510, lr = 0.000686578
I0808 17:56:26.703073 20451 solver.cpp:228] Iteration 6520, loss = 0.218929
I0808 17:56:26.703223 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 17:56:26.703244 20451 solver.cpp:244]     Train net output #1: loss = 0.218929 (* 1 = 0.218929 loss)
I0808 17:56:26.703259 20451 sgd_solver.cpp:106] Iteration 6520, lr = 0.000686266
I0808 17:56:49.006312 20451 solver.cpp:228] Iteration 6530, loss = 0.156299
I0808 17:56:49.006358 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 17:56:49.006376 20451 solver.cpp:244]     Train net output #1: loss = 0.156299 (* 1 = 0.156299 loss)
I0808 17:56:49.006392 20451 sgd_solver.cpp:106] Iteration 6530, lr = 0.000685955
I0808 17:57:11.318378 20451 solver.cpp:228] Iteration 6540, loss = 0.125075
I0808 17:57:11.318567 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:57:11.318585 20451 solver.cpp:244]     Train net output #1: loss = 0.125075 (* 1 = 0.125075 loss)
I0808 17:57:11.318600 20451 sgd_solver.cpp:106] Iteration 6540, lr = 0.000685644
I0808 17:57:33.621464 20451 solver.cpp:228] Iteration 6550, loss = 0.125111
I0808 17:57:33.621506 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:57:33.621531 20451 solver.cpp:244]     Train net output #1: loss = 0.125111 (* 1 = 0.125111 loss)
I0808 17:57:33.621544 20451 sgd_solver.cpp:106] Iteration 6550, lr = 0.000685333
I0808 17:57:55.928586 20451 solver.cpp:228] Iteration 6560, loss = 0.125069
I0808 17:57:55.928769 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:57:55.928788 20451 solver.cpp:244]     Train net output #1: loss = 0.125069 (* 1 = 0.125069 loss)
I0808 17:57:55.928803 20451 sgd_solver.cpp:106] Iteration 6560, lr = 0.000685022
I0808 17:58:18.224817 20451 solver.cpp:228] Iteration 6570, loss = 0.312876
I0808 17:58:18.224869 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 17:58:18.224882 20451 solver.cpp:244]     Train net output #1: loss = 0.312876 (* 1 = 0.312876 loss)
I0808 17:58:18.224895 20451 sgd_solver.cpp:106] Iteration 6570, lr = 0.000684712
I0808 17:58:40.521335 20451 solver.cpp:228] Iteration 6580, loss = 0.250055
I0808 17:58:40.521522 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 17:58:40.521536 20451 solver.cpp:244]     Train net output #1: loss = 0.250055 (* 1 = 0.250055 loss)
I0808 17:58:40.521549 20451 sgd_solver.cpp:106] Iteration 6580, lr = 0.000684403
I0808 17:59:02.827960 20451 solver.cpp:228] Iteration 6590, loss = 0.187685
I0808 17:59:02.828013 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 17:59:02.828027 20451 solver.cpp:244]     Train net output #1: loss = 0.187685 (* 1 = 0.187685 loss)
I0808 17:59:02.828039 20451 sgd_solver.cpp:106] Iteration 6590, lr = 0.000684093
I0808 17:59:22.899343 20451 solver.cpp:337] Iteration 6600, Testing net (#0)
I0808 17:59:31.430161 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0808 17:59:31.430213 20451 solver.cpp:404]     Test net output #1: loss = 0.97072 (* 1 = 0.97072 loss)
I0808 17:59:33.629900 20451 solver.cpp:228] Iteration 6600, loss = 0.125076
I0808 17:59:33.629941 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 17:59:33.629956 20451 solver.cpp:244]     Train net output #1: loss = 0.125076 (* 1 = 0.125076 loss)
I0808 17:59:33.629967 20451 sgd_solver.cpp:106] Iteration 6600, lr = 0.000683784
I0808 17:59:55.903254 20451 solver.cpp:228] Iteration 6610, loss = 0.0938169
I0808 17:59:55.903370 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 17:59:55.903391 20451 solver.cpp:244]     Train net output #1: loss = 0.0938169 (* 1 = 0.0938169 loss)
I0808 17:59:55.903408 20451 sgd_solver.cpp:106] Iteration 6610, lr = 0.000683475
I0808 18:00:18.202661 20451 solver.cpp:228] Iteration 6620, loss = 0.125069
I0808 18:00:18.202704 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:00:18.202719 20451 solver.cpp:244]     Train net output #1: loss = 0.125069 (* 1 = 0.125069 loss)
I0808 18:00:18.202733 20451 sgd_solver.cpp:106] Iteration 6620, lr = 0.000683167
I0808 18:00:40.502470 20451 solver.cpp:228] Iteration 6630, loss = 0.281456
I0808 18:00:40.502682 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 18:00:40.502698 20451 solver.cpp:244]     Train net output #1: loss = 0.281455 (* 1 = 0.281455 loss)
I0808 18:00:40.502710 20451 sgd_solver.cpp:106] Iteration 6630, lr = 0.000682859
I0808 18:01:02.821812 20451 solver.cpp:228] Iteration 6640, loss = 0.344035
I0808 18:01:02.821866 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 18:01:02.821879 20451 solver.cpp:244]     Train net output #1: loss = 0.344035 (* 1 = 0.344035 loss)
I0808 18:01:02.821892 20451 sgd_solver.cpp:106] Iteration 6640, lr = 0.000682551
I0808 18:01:25.130951 20451 solver.cpp:228] Iteration 6650, loss = 0.2501
I0808 18:01:25.131134 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:01:25.131147 20451 solver.cpp:244]     Train net output #1: loss = 0.2501 (* 1 = 0.2501 loss)
I0808 18:01:25.131160 20451 sgd_solver.cpp:106] Iteration 6650, lr = 0.000682243
I0808 18:01:47.437082 20451 solver.cpp:228] Iteration 6660, loss = 0.156369
I0808 18:01:47.437120 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:01:47.437139 20451 solver.cpp:244]     Train net output #1: loss = 0.156368 (* 1 = 0.156368 loss)
I0808 18:01:47.437152 20451 sgd_solver.cpp:106] Iteration 6660, lr = 0.000681936
I0808 18:02:09.743126 20451 solver.cpp:228] Iteration 6670, loss = 0.218843
I0808 18:02:09.743326 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:02:09.743341 20451 solver.cpp:244]     Train net output #1: loss = 0.218843 (* 1 = 0.218843 loss)
I0808 18:02:09.743355 20451 sgd_solver.cpp:106] Iteration 6670, lr = 0.000681629
I0808 18:02:32.037456 20451 solver.cpp:228] Iteration 6680, loss = 0.187642
I0808 18:02:32.037506 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:02:32.037520 20451 solver.cpp:244]     Train net output #1: loss = 0.187642 (* 1 = 0.187642 loss)
I0808 18:02:32.037533 20451 sgd_solver.cpp:106] Iteration 6680, lr = 0.000681323
I0808 18:02:54.331337 20451 solver.cpp:228] Iteration 6690, loss = 0.281426
I0808 18:02:54.331512 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 18:02:54.331528 20451 solver.cpp:244]     Train net output #1: loss = 0.281426 (* 1 = 0.281426 loss)
I0808 18:02:54.331540 20451 sgd_solver.cpp:106] Iteration 6690, lr = 0.000681017
I0808 18:03:14.418092 20451 solver.cpp:337] Iteration 6700, Testing net (#0)
I0808 18:03:22.936221 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 18:03:22.936274 20451 solver.cpp:404]     Test net output #1: loss = 1.0084 (* 1 = 1.0084 loss)
I0808 18:03:25.137482 20451 solver.cpp:228] Iteration 6700, loss = 0.281485
I0808 18:03:25.137666 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 18:03:25.137681 20451 solver.cpp:244]     Train net output #1: loss = 0.281485 (* 1 = 0.281485 loss)
I0808 18:03:25.137694 20451 sgd_solver.cpp:106] Iteration 6700, lr = 0.000680711
I0808 18:03:47.406697 20451 solver.cpp:228] Iteration 6710, loss = 0.156387
I0808 18:03:47.406750 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:03:47.406764 20451 solver.cpp:244]     Train net output #1: loss = 0.156387 (* 1 = 0.156387 loss)
I0808 18:03:47.406776 20451 sgd_solver.cpp:106] Iteration 6710, lr = 0.000680405
I0808 18:04:09.704872 20451 solver.cpp:228] Iteration 6720, loss = 0.125076
I0808 18:04:09.705056 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:04:09.705071 20451 solver.cpp:244]     Train net output #1: loss = 0.125076 (* 1 = 0.125076 loss)
I0808 18:04:09.705083 20451 sgd_solver.cpp:106] Iteration 6720, lr = 0.0006801
I0808 18:04:32.001510 20451 solver.cpp:228] Iteration 6730, loss = 0.218961
I0808 18:04:32.001556 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:04:32.001571 20451 solver.cpp:244]     Train net output #1: loss = 0.218961 (* 1 = 0.218961 loss)
I0808 18:04:32.001585 20451 sgd_solver.cpp:106] Iteration 6730, lr = 0.000679795
I0808 18:04:54.301744 20451 solver.cpp:228] Iteration 6740, loss = 0.18763
I0808 18:04:54.301957 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:04:54.301973 20451 solver.cpp:244]     Train net output #1: loss = 0.18763 (* 1 = 0.18763 loss)
I0808 18:04:54.301986 20451 sgd_solver.cpp:106] Iteration 6740, lr = 0.000679491
I0808 18:05:16.598742 20451 solver.cpp:228] Iteration 6750, loss = 0.313153
I0808 18:05:16.598793 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 18:05:16.598808 20451 solver.cpp:244]     Train net output #1: loss = 0.313153 (* 1 = 0.313153 loss)
I0808 18:05:16.598819 20451 sgd_solver.cpp:106] Iteration 6750, lr = 0.000679186
I0808 18:05:38.901895 20451 solver.cpp:228] Iteration 6760, loss = 0.250159
I0808 18:05:38.902073 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:05:38.902089 20451 solver.cpp:244]     Train net output #1: loss = 0.250159 (* 1 = 0.250159 loss)
I0808 18:05:38.902102 20451 sgd_solver.cpp:106] Iteration 6760, lr = 0.000678882
I0808 18:06:01.206028 20451 solver.cpp:228] Iteration 6770, loss = 0.0937771
I0808 18:06:01.206071 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:06:01.206086 20451 solver.cpp:244]     Train net output #1: loss = 0.093777 (* 1 = 0.093777 loss)
I0808 18:06:01.206099 20451 sgd_solver.cpp:106] Iteration 6770, lr = 0.000678579
I0808 18:06:23.515776 20451 solver.cpp:228] Iteration 6780, loss = 0.0937901
I0808 18:06:23.515964 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:06:23.515980 20451 solver.cpp:244]     Train net output #1: loss = 0.0937901 (* 1 = 0.0937901 loss)
I0808 18:06:23.515993 20451 sgd_solver.cpp:106] Iteration 6780, lr = 0.000678275
I0808 18:06:45.813405 20451 solver.cpp:228] Iteration 6790, loss = 0.125032
I0808 18:06:45.813452 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:06:45.813470 20451 solver.cpp:244]     Train net output #1: loss = 0.125032 (* 1 = 0.125032 loss)
I0808 18:06:45.813486 20451 sgd_solver.cpp:106] Iteration 6790, lr = 0.000677972
I0808 18:07:05.899996 20451 solver.cpp:337] Iteration 6800, Testing net (#0)
I0808 18:07:14.422040 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0808 18:07:14.422086 20451 solver.cpp:404]     Test net output #1: loss = 1.01313 (* 1 = 1.01313 loss)
I0808 18:07:16.624892 20451 solver.cpp:228] Iteration 6800, loss = 0.156386
I0808 18:07:16.624938 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:07:16.624956 20451 solver.cpp:244]     Train net output #1: loss = 0.156386 (* 1 = 0.156386 loss)
I0808 18:07:16.624981 20451 sgd_solver.cpp:106] Iteration 6800, lr = 0.00067767
I0808 18:07:38.900800 20451 solver.cpp:228] Iteration 6810, loss = 0.125114
I0808 18:07:38.900980 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:07:38.900996 20451 solver.cpp:244]     Train net output #1: loss = 0.125114 (* 1 = 0.125114 loss)
I0808 18:07:38.901010 20451 sgd_solver.cpp:106] Iteration 6810, lr = 0.000677367
I0808 18:08:01.197537 20451 solver.cpp:228] Iteration 6820, loss = 0.125085
I0808 18:08:01.197588 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:08:01.197603 20451 solver.cpp:244]     Train net output #1: loss = 0.125085 (* 1 = 0.125085 loss)
I0808 18:08:01.197615 20451 sgd_solver.cpp:106] Iteration 6820, lr = 0.000677065
I0808 18:08:23.498872 20451 solver.cpp:228] Iteration 6830, loss = 0.0312825
I0808 18:08:23.498987 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 18:08:23.499004 20451 solver.cpp:244]     Train net output #1: loss = 0.0312824 (* 1 = 0.0312824 loss)
I0808 18:08:23.499017 20451 sgd_solver.cpp:106] Iteration 6830, lr = 0.000676764
I0808 18:08:45.795537 20451 solver.cpp:228] Iteration 6840, loss = 0.0937656
I0808 18:08:45.795593 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:08:45.795608 20451 solver.cpp:244]     Train net output #1: loss = 0.0937655 (* 1 = 0.0937655 loss)
I0808 18:08:45.795620 20451 sgd_solver.cpp:106] Iteration 6840, lr = 0.000676462
I0808 18:09:08.103652 20451 solver.cpp:228] Iteration 6850, loss = 0.250102
I0808 18:09:08.103864 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:09:08.103880 20451 solver.cpp:244]     Train net output #1: loss = 0.250102 (* 1 = 0.250102 loss)
I0808 18:09:08.103893 20451 sgd_solver.cpp:106] Iteration 6850, lr = 0.000676161
I0808 18:09:30.403846 20451 solver.cpp:228] Iteration 6860, loss = 0.187593
I0808 18:09:30.403899 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:09:30.403913 20451 solver.cpp:244]     Train net output #1: loss = 0.187593 (* 1 = 0.187593 loss)
I0808 18:09:30.403924 20451 sgd_solver.cpp:106] Iteration 6860, lr = 0.00067586
I0808 18:09:52.704373 20451 solver.cpp:228] Iteration 6870, loss = 0.0312502
I0808 18:09:52.704476 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:09:52.704496 20451 solver.cpp:244]     Train net output #1: loss = 0.0312501 (* 1 = 0.0312501 loss)
I0808 18:09:52.704512 20451 sgd_solver.cpp:106] Iteration 6870, lr = 0.00067556
I0808 18:10:15.014205 20451 solver.cpp:228] Iteration 6880, loss = 0.156358
I0808 18:10:15.014250 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:10:15.014267 20451 solver.cpp:244]     Train net output #1: loss = 0.156358 (* 1 = 0.156358 loss)
I0808 18:10:15.014283 20451 sgd_solver.cpp:106] Iteration 6880, lr = 0.00067526
I0808 18:10:37.313072 20451 solver.cpp:228] Iteration 6890, loss = 0.218842
I0808 18:10:37.313251 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:10:37.313266 20451 solver.cpp:244]     Train net output #1: loss = 0.218842 (* 1 = 0.218842 loss)
I0808 18:10:37.313278 20451 sgd_solver.cpp:106] Iteration 6890, lr = 0.00067496
I0808 18:10:57.389822 20451 solver.cpp:337] Iteration 6900, Testing net (#0)
I0808 18:11:05.916908 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 18:11:05.916966 20451 solver.cpp:404]     Test net output #1: loss = 0.985024 (* 1 = 0.985024 loss)
I0808 18:11:08.121554 20451 solver.cpp:228] Iteration 6900, loss = 0.187679
I0808 18:11:08.121665 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:11:08.121682 20451 solver.cpp:244]     Train net output #1: loss = 0.187679 (* 1 = 0.187679 loss)
I0808 18:11:08.121696 20451 sgd_solver.cpp:106] Iteration 6900, lr = 0.00067466
I0808 18:11:30.403192 20451 solver.cpp:228] Iteration 6910, loss = 0.125108
I0808 18:11:30.403244 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:11:30.403259 20451 solver.cpp:244]     Train net output #1: loss = 0.125108 (* 1 = 0.125108 loss)
I0808 18:11:30.403270 20451 sgd_solver.cpp:106] Iteration 6910, lr = 0.000674361
I0808 18:11:52.706768 20451 solver.cpp:228] Iteration 6920, loss = 0.21889
I0808 18:11:52.706885 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:11:52.706905 20451 solver.cpp:244]     Train net output #1: loss = 0.21889 (* 1 = 0.21889 loss)
I0808 18:11:52.706920 20451 sgd_solver.cpp:106] Iteration 6920, lr = 0.000674062
I0808 18:12:15.023653 20451 solver.cpp:228] Iteration 6930, loss = 0.125207
I0808 18:12:15.023699 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:12:15.023725 20451 solver.cpp:244]     Train net output #1: loss = 0.125207 (* 1 = 0.125207 loss)
I0808 18:12:15.023739 20451 sgd_solver.cpp:106] Iteration 6930, lr = 0.000673763
I0808 18:12:37.328938 20451 solver.cpp:228] Iteration 6940, loss = 0.125085
I0808 18:12:37.329113 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:12:37.329128 20451 solver.cpp:244]     Train net output #1: loss = 0.125084 (* 1 = 0.125084 loss)
I0808 18:12:37.329139 20451 sgd_solver.cpp:106] Iteration 6940, lr = 0.000673465
I0808 18:12:59.632637 20451 solver.cpp:228] Iteration 6950, loss = 0.12505
I0808 18:12:59.632690 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:12:59.632704 20451 solver.cpp:244]     Train net output #1: loss = 0.12505 (* 1 = 0.12505 loss)
I0808 18:12:59.632716 20451 sgd_solver.cpp:106] Iteration 6950, lr = 0.000673167
I0808 18:13:21.926079 20451 solver.cpp:228] Iteration 6960, loss = 0.250104
I0808 18:13:21.926285 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:13:21.926301 20451 solver.cpp:244]     Train net output #1: loss = 0.250104 (* 1 = 0.250104 loss)
I0808 18:13:21.926314 20451 sgd_solver.cpp:106] Iteration 6960, lr = 0.000672869
I0808 18:13:44.217442 20451 solver.cpp:228] Iteration 6970, loss = 0.125055
I0808 18:13:44.217499 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:13:44.217514 20451 solver.cpp:244]     Train net output #1: loss = 0.125055 (* 1 = 0.125055 loss)
I0808 18:13:44.217526 20451 sgd_solver.cpp:106] Iteration 6970, lr = 0.000672572
I0808 18:14:06.516268 20451 solver.cpp:228] Iteration 6980, loss = 0.187684
I0808 18:14:06.516371 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:14:06.516386 20451 solver.cpp:244]     Train net output #1: loss = 0.187684 (* 1 = 0.187684 loss)
I0808 18:14:06.516398 20451 sgd_solver.cpp:106] Iteration 6980, lr = 0.000672275
I0808 18:14:28.814682 20451 solver.cpp:228] Iteration 6990, loss = 0.250121
I0808 18:14:28.814735 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:14:28.814755 20451 solver.cpp:244]     Train net output #1: loss = 0.25012 (* 1 = 0.25012 loss)
I0808 18:14:28.814769 20451 sgd_solver.cpp:106] Iteration 6990, lr = 0.000671978
I0808 18:14:48.897383 20451 solver.cpp:337] Iteration 7000, Testing net (#0)
I0808 18:14:57.422598 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 18:14:57.422641 20451 solver.cpp:404]     Test net output #1: loss = 1.00345 (* 1 = 1.00345 loss)
I0808 18:14:59.626570 20451 solver.cpp:228] Iteration 7000, loss = 0.281365
I0808 18:14:59.626612 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 18:14:59.626629 20451 solver.cpp:244]     Train net output #1: loss = 0.281365 (* 1 = 0.281365 loss)
I0808 18:14:59.626653 20451 sgd_solver.cpp:106] Iteration 7000, lr = 0.000671681
I0808 18:15:21.902173 20451 solver.cpp:228] Iteration 7010, loss = 0.218946
I0808 18:15:21.902271 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:15:21.902292 20451 solver.cpp:244]     Train net output #1: loss = 0.218946 (* 1 = 0.218946 loss)
I0808 18:15:21.902307 20451 sgd_solver.cpp:106] Iteration 7010, lr = 0.000671385
I0808 18:15:44.205152 20451 solver.cpp:228] Iteration 7020, loss = 0.125068
I0808 18:15:44.205204 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:15:44.205216 20451 solver.cpp:244]     Train net output #1: loss = 0.125068 (* 1 = 0.125068 loss)
I0808 18:15:44.205229 20451 sgd_solver.cpp:106] Iteration 7020, lr = 0.000671089
I0808 18:16:06.507397 20451 solver.cpp:228] Iteration 7030, loss = 0.437947
I0808 18:16:06.507581 20451 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0808 18:16:06.507596 20451 solver.cpp:244]     Train net output #1: loss = 0.437947 (* 1 = 0.437947 loss)
I0808 18:16:06.507608 20451 sgd_solver.cpp:106] Iteration 7030, lr = 0.000670794
I0808 18:16:28.809942 20451 solver.cpp:228] Iteration 7040, loss = 0.0938793
I0808 18:16:28.809991 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:16:28.810009 20451 solver.cpp:244]     Train net output #1: loss = 0.0938793 (* 1 = 0.0938793 loss)
I0808 18:16:28.810022 20451 sgd_solver.cpp:106] Iteration 7040, lr = 0.000670499
I0808 18:16:51.104079 20451 solver.cpp:228] Iteration 7050, loss = 0.156576
I0808 18:16:51.104218 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:16:51.104234 20451 solver.cpp:244]     Train net output #1: loss = 0.156576 (* 1 = 0.156576 loss)
I0808 18:16:51.104248 20451 sgd_solver.cpp:106] Iteration 7050, lr = 0.000670204
I0808 18:17:13.401201 20451 solver.cpp:228] Iteration 7060, loss = 0.125177
I0808 18:17:13.401252 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:17:13.401264 20451 solver.cpp:244]     Train net output #1: loss = 0.125177 (* 1 = 0.125177 loss)
I0808 18:17:13.401276 20451 sgd_solver.cpp:106] Iteration 7060, lr = 0.000669909
I0808 18:17:35.697865 20451 solver.cpp:228] Iteration 7070, loss = 0.187756
I0808 18:17:35.698077 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:17:35.698096 20451 solver.cpp:244]     Train net output #1: loss = 0.187756 (* 1 = 0.187756 loss)
I0808 18:17:35.698112 20451 sgd_solver.cpp:106] Iteration 7070, lr = 0.000669615
I0808 18:17:57.983924 20451 solver.cpp:228] Iteration 7080, loss = 0.187883
I0808 18:17:57.983969 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:17:57.983988 20451 solver.cpp:244]     Train net output #1: loss = 0.187883 (* 1 = 0.187883 loss)
I0808 18:17:57.984002 20451 sgd_solver.cpp:106] Iteration 7080, lr = 0.000669321
I0808 18:18:20.281946 20451 solver.cpp:228] Iteration 7090, loss = 0.0625505
I0808 18:18:20.282126 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 18:18:20.282150 20451 solver.cpp:244]     Train net output #1: loss = 0.0625504 (* 1 = 0.0625504 loss)
I0808 18:18:20.282166 20451 sgd_solver.cpp:106] Iteration 7090, lr = 0.000669027
I0808 18:18:40.357669 20451 solver.cpp:337] Iteration 7100, Testing net (#0)
I0808 18:18:48.882890 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 18:18:48.882942 20451 solver.cpp:404]     Test net output #1: loss = 0.975068 (* 1 = 0.975068 loss)
I0808 18:18:51.087347 20451 solver.cpp:228] Iteration 7100, loss = 0.250141
I0808 18:18:51.087524 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 18:18:51.087539 20451 solver.cpp:244]     Train net output #1: loss = 0.250141 (* 1 = 0.250141 loss)
I0808 18:18:51.087553 20451 sgd_solver.cpp:106] Iteration 7100, lr = 0.000668733
I0808 18:19:13.366917 20451 solver.cpp:228] Iteration 7110, loss = 0.281477
I0808 18:19:13.366958 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:19:13.366972 20451 solver.cpp:244]     Train net output #1: loss = 0.281477 (* 1 = 0.281477 loss)
I0808 18:19:13.366986 20451 sgd_solver.cpp:106] Iteration 7110, lr = 0.00066844
I0808 18:19:35.661018 20451 solver.cpp:228] Iteration 7120, loss = 0.125208
I0808 18:19:35.661202 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:19:35.661221 20451 solver.cpp:244]     Train net output #1: loss = 0.125208 (* 1 = 0.125208 loss)
I0808 18:19:35.661237 20451 sgd_solver.cpp:106] Iteration 7120, lr = 0.000668147
I0808 18:19:57.954627 20451 solver.cpp:228] Iteration 7130, loss = 0.187581
I0808 18:19:57.954679 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:19:57.954694 20451 solver.cpp:244]     Train net output #1: loss = 0.187581 (* 1 = 0.187581 loss)
I0808 18:19:57.954705 20451 sgd_solver.cpp:106] Iteration 7130, lr = 0.000667855
I0808 18:20:20.267966 20451 solver.cpp:228] Iteration 7140, loss = 0.094124
I0808 18:20:20.268139 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:20:20.268156 20451 solver.cpp:244]     Train net output #1: loss = 0.094124 (* 1 = 0.094124 loss)
I0808 18:20:20.268168 20451 sgd_solver.cpp:106] Iteration 7140, lr = 0.000667562
I0808 18:20:42.563983 20451 solver.cpp:228] Iteration 7150, loss = 0.0937947
I0808 18:20:42.564041 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:20:42.564055 20451 solver.cpp:244]     Train net output #1: loss = 0.0937947 (* 1 = 0.0937947 loss)
I0808 18:20:42.564067 20451 sgd_solver.cpp:106] Iteration 7150, lr = 0.000667271
I0808 18:21:04.860812 20451 solver.cpp:228] Iteration 7160, loss = 0.187527
I0808 18:21:04.860991 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:21:04.861006 20451 solver.cpp:244]     Train net output #1: loss = 0.187527 (* 1 = 0.187527 loss)
I0808 18:21:04.861019 20451 sgd_solver.cpp:106] Iteration 7160, lr = 0.000666979
I0808 18:21:27.162183 20451 solver.cpp:228] Iteration 7170, loss = 0.187582
I0808 18:21:27.162235 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:21:27.162248 20451 solver.cpp:244]     Train net output #1: loss = 0.187582 (* 1 = 0.187582 loss)
I0808 18:21:27.162261 20451 sgd_solver.cpp:106] Iteration 7170, lr = 0.000666687
I0808 18:21:49.459182 20451 solver.cpp:228] Iteration 7180, loss = 0.0625359
I0808 18:21:49.459334 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 18:21:49.459350 20451 solver.cpp:244]     Train net output #1: loss = 0.0625358 (* 1 = 0.0625358 loss)
I0808 18:21:49.459364 20451 sgd_solver.cpp:106] Iteration 7180, lr = 0.000666396
I0808 18:22:11.757259 20451 solver.cpp:228] Iteration 7190, loss = 0.0312748
I0808 18:22:11.757311 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 18:22:11.757325 20451 solver.cpp:244]     Train net output #1: loss = 0.0312748 (* 1 = 0.0312748 loss)
I0808 18:22:11.757339 20451 sgd_solver.cpp:106] Iteration 7190, lr = 0.000666106
I0808 18:22:31.832748 20451 solver.cpp:337] Iteration 7200, Testing net (#0)
I0808 18:22:40.350728 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0808 18:22:40.350770 20451 solver.cpp:404]     Test net output #1: loss = 1.01761 (* 1 = 1.01761 loss)
I0808 18:22:42.552122 20451 solver.cpp:228] Iteration 7200, loss = 0.156343
I0808 18:22:42.552171 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:22:42.552186 20451 solver.cpp:244]     Train net output #1: loss = 0.156342 (* 1 = 0.156342 loss)
I0808 18:22:42.552197 20451 sgd_solver.cpp:106] Iteration 7200, lr = 0.000665815
I0808 18:23:04.817308 20451 solver.cpp:228] Iteration 7210, loss = 0.0938222
I0808 18:23:04.817412 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:23:04.817430 20451 solver.cpp:244]     Train net output #1: loss = 0.0938222 (* 1 = 0.0938222 loss)
I0808 18:23:04.817443 20451 sgd_solver.cpp:106] Iteration 7210, lr = 0.000665525
I0808 18:23:27.106839 20451 solver.cpp:228] Iteration 7220, loss = 0.187609
I0808 18:23:27.106892 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:23:27.106905 20451 solver.cpp:244]     Train net output #1: loss = 0.187609 (* 1 = 0.187609 loss)
I0808 18:23:27.106917 20451 sgd_solver.cpp:106] Iteration 7220, lr = 0.000665235
I0808 18:23:49.400960 20451 solver.cpp:228] Iteration 7230, loss = 0.312634
I0808 18:23:49.401144 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 18:23:49.401161 20451 solver.cpp:244]     Train net output #1: loss = 0.312634 (* 1 = 0.312634 loss)
I0808 18:23:49.401176 20451 sgd_solver.cpp:106] Iteration 7230, lr = 0.000664946
I0808 18:24:11.695930 20451 solver.cpp:228] Iteration 7240, loss = 0.375228
I0808 18:24:11.695982 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0808 18:24:11.695996 20451 solver.cpp:244]     Train net output #1: loss = 0.375228 (* 1 = 0.375228 loss)
I0808 18:24:11.696007 20451 sgd_solver.cpp:106] Iteration 7240, lr = 0.000664656
I0808 18:24:33.994814 20451 solver.cpp:228] Iteration 7250, loss = 0.187632
I0808 18:24:33.994907 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:24:33.994923 20451 solver.cpp:244]     Train net output #1: loss = 0.187632 (* 1 = 0.187632 loss)
I0808 18:24:33.994936 20451 sgd_solver.cpp:106] Iteration 7250, lr = 0.000664367
I0808 18:24:56.290088 20451 solver.cpp:228] Iteration 7260, loss = 0.187679
I0808 18:24:56.290138 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:24:56.290153 20451 solver.cpp:244]     Train net output #1: loss = 0.187679 (* 1 = 0.187679 loss)
I0808 18:24:56.290164 20451 sgd_solver.cpp:106] Iteration 7260, lr = 0.000664079
I0808 18:25:18.593319 20451 solver.cpp:228] Iteration 7270, loss = 0.0937933
I0808 18:25:18.593497 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:25:18.593511 20451 solver.cpp:244]     Train net output #1: loss = 0.0937933 (* 1 = 0.0937933 loss)
I0808 18:25:18.593524 20451 sgd_solver.cpp:106] Iteration 7270, lr = 0.00066379
I0808 18:25:40.894667 20451 solver.cpp:228] Iteration 7280, loss = 0.125068
I0808 18:25:40.894721 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:25:40.894734 20451 solver.cpp:244]     Train net output #1: loss = 0.125068 (* 1 = 0.125068 loss)
I0808 18:25:40.894747 20451 sgd_solver.cpp:106] Iteration 7280, lr = 0.000663502
I0808 18:26:03.199895 20451 solver.cpp:228] Iteration 7290, loss = 0.125016
I0808 18:26:03.200114 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:26:03.200129 20451 solver.cpp:244]     Train net output #1: loss = 0.125016 (* 1 = 0.125016 loss)
I0808 18:26:03.200141 20451 sgd_solver.cpp:106] Iteration 7290, lr = 0.000663214
I0808 18:26:23.269629 20451 solver.cpp:337] Iteration 7300, Testing net (#0)
I0808 18:26:31.780724 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 18:26:31.780792 20451 solver.cpp:404]     Test net output #1: loss = 1.00344 (* 1 = 1.00344 loss)
I0808 18:26:33.985363 20451 solver.cpp:228] Iteration 7300, loss = 0.281368
I0808 18:26:33.985466 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 18:26:33.985486 20451 solver.cpp:244]     Train net output #1: loss = 0.281368 (* 1 = 0.281368 loss)
I0808 18:26:33.985502 20451 sgd_solver.cpp:106] Iteration 7300, lr = 0.000662927
I0808 18:26:56.261637 20451 solver.cpp:228] Iteration 7310, loss = 0.187567
I0808 18:26:56.261682 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:26:56.261700 20451 solver.cpp:244]     Train net output #1: loss = 0.187567 (* 1 = 0.187567 loss)
I0808 18:26:56.261714 20451 sgd_solver.cpp:106] Iteration 7310, lr = 0.000662639
I0808 18:27:18.563411 20451 solver.cpp:228] Iteration 7320, loss = 0.125073
I0808 18:27:18.563546 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:27:18.563562 20451 solver.cpp:244]     Train net output #1: loss = 0.125073 (* 1 = 0.125073 loss)
I0808 18:27:18.563575 20451 sgd_solver.cpp:106] Iteration 7320, lr = 0.000662352
I0808 18:27:40.860276 20451 solver.cpp:228] Iteration 7330, loss = 0.344057
I0808 18:27:40.860319 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:27:40.860334 20451 solver.cpp:244]     Train net output #1: loss = 0.344057 (* 1 = 0.344057 loss)
I0808 18:27:40.860347 20451 sgd_solver.cpp:106] Iteration 7330, lr = 0.000662066
I0808 18:28:03.151026 20451 solver.cpp:228] Iteration 7340, loss = 0.125387
I0808 18:28:03.151206 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:28:03.151221 20451 solver.cpp:244]     Train net output #1: loss = 0.125387 (* 1 = 0.125387 loss)
I0808 18:28:03.151234 20451 sgd_solver.cpp:106] Iteration 7340, lr = 0.000661779
I0808 18:28:25.437913 20451 solver.cpp:228] Iteration 7350, loss = 0.125085
I0808 18:28:25.437968 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:28:25.437981 20451 solver.cpp:244]     Train net output #1: loss = 0.125085 (* 1 = 0.125085 loss)
I0808 18:28:25.437994 20451 sgd_solver.cpp:106] Iteration 7350, lr = 0.000661493
I0808 18:28:47.722358 20451 solver.cpp:228] Iteration 7360, loss = 0.187734
I0808 18:28:47.722542 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:28:47.722559 20451 solver.cpp:244]     Train net output #1: loss = 0.187734 (* 1 = 0.187734 loss)
I0808 18:28:47.722574 20451 sgd_solver.cpp:106] Iteration 7360, lr = 0.000661207
I0808 18:29:10.020824 20451 solver.cpp:228] Iteration 7370, loss = 0.156285
I0808 18:29:10.020869 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:29:10.020887 20451 solver.cpp:244]     Train net output #1: loss = 0.156285 (* 1 = 0.156285 loss)
I0808 18:29:10.020906 20451 sgd_solver.cpp:106] Iteration 7370, lr = 0.000660922
I0808 18:29:32.317818 20451 solver.cpp:228] Iteration 7380, loss = 0.187651
I0808 18:29:32.317993 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:29:32.318012 20451 solver.cpp:244]     Train net output #1: loss = 0.187651 (* 1 = 0.187651 loss)
I0808 18:29:32.318028 20451 sgd_solver.cpp:106] Iteration 7380, lr = 0.000660637
I0808 18:29:54.613283 20451 solver.cpp:228] Iteration 7390, loss = 0.187589
I0808 18:29:54.613325 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:29:54.613339 20451 solver.cpp:244]     Train net output #1: loss = 0.187589 (* 1 = 0.187589 loss)
I0808 18:29:54.613351 20451 sgd_solver.cpp:106] Iteration 7390, lr = 0.000660352
I0808 18:30:14.692749 20451 solver.cpp:337] Iteration 7400, Testing net (#0)
I0808 18:30:23.206042 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 18:30:23.206091 20451 solver.cpp:404]     Test net output #1: loss = 0.975602 (* 1 = 0.975602 loss)
I0808 18:30:25.407054 20451 solver.cpp:228] Iteration 7400, loss = 0.281496
I0808 18:30:25.407107 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 18:30:25.407120 20451 solver.cpp:244]     Train net output #1: loss = 0.281496 (* 1 = 0.281496 loss)
I0808 18:30:25.407133 20451 sgd_solver.cpp:106] Iteration 7400, lr = 0.000660067
I0808 18:30:47.682804 20451 solver.cpp:228] Iteration 7410, loss = 0.187661
I0808 18:30:47.682996 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:30:47.683012 20451 solver.cpp:244]     Train net output #1: loss = 0.187661 (* 1 = 0.187661 loss)
I0808 18:30:47.683024 20451 sgd_solver.cpp:106] Iteration 7410, lr = 0.000659783
I0808 18:31:09.993427 20451 solver.cpp:228] Iteration 7420, loss = 0.156478
I0808 18:31:09.993471 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 18:31:09.993486 20451 solver.cpp:244]     Train net output #1: loss = 0.156478 (* 1 = 0.156478 loss)
I0808 18:31:09.993499 20451 sgd_solver.cpp:106] Iteration 7420, lr = 0.000659499
I0808 18:31:32.288924 20451 solver.cpp:228] Iteration 7430, loss = 0.281558
I0808 18:31:32.289116 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:31:32.289135 20451 solver.cpp:244]     Train net output #1: loss = 0.281558 (* 1 = 0.281558 loss)
I0808 18:31:32.289155 20451 sgd_solver.cpp:106] Iteration 7430, lr = 0.000659215
I0808 18:31:54.593817 20451 solver.cpp:228] Iteration 7440, loss = 0.125254
I0808 18:31:54.593860 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:31:54.593878 20451 solver.cpp:244]     Train net output #1: loss = 0.125254 (* 1 = 0.125254 loss)
I0808 18:31:54.593893 20451 sgd_solver.cpp:106] Iteration 7440, lr = 0.000658931
I0808 18:32:16.897747 20451 solver.cpp:228] Iteration 7450, loss = 0.125043
I0808 18:32:16.897923 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:32:16.897943 20451 solver.cpp:244]     Train net output #1: loss = 0.125043 (* 1 = 0.125043 loss)
I0808 18:32:16.897958 20451 sgd_solver.cpp:106] Iteration 7450, lr = 0.000658648
I0808 18:32:39.195345 20451 solver.cpp:228] Iteration 7460, loss = 0.218818
I0808 18:32:39.195389 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:32:39.195407 20451 solver.cpp:244]     Train net output #1: loss = 0.218818 (* 1 = 0.218818 loss)
I0808 18:32:39.195421 20451 sgd_solver.cpp:106] Iteration 7460, lr = 0.000658365
I0808 18:33:01.493850 20451 solver.cpp:228] Iteration 7470, loss = 0.125039
I0808 18:33:01.494050 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:33:01.494065 20451 solver.cpp:244]     Train net output #1: loss = 0.125039 (* 1 = 0.125039 loss)
I0808 18:33:01.494078 20451 sgd_solver.cpp:106] Iteration 7470, lr = 0.000658082
I0808 18:33:23.792070 20451 solver.cpp:228] Iteration 7480, loss = 0.0938951
I0808 18:33:23.792125 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:33:23.792140 20451 solver.cpp:244]     Train net output #1: loss = 0.093895 (* 1 = 0.093895 loss)
I0808 18:33:23.792152 20451 sgd_solver.cpp:106] Iteration 7480, lr = 0.0006578
I0808 18:33:46.093185 20451 solver.cpp:228] Iteration 7490, loss = 0.343995
I0808 18:33:46.093358 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 18:33:46.093374 20451 solver.cpp:244]     Train net output #1: loss = 0.343995 (* 1 = 0.343995 loss)
I0808 18:33:46.093385 20451 sgd_solver.cpp:106] Iteration 7490, lr = 0.000657518
I0808 18:34:06.167534 20451 solver.cpp:337] Iteration 7500, Testing net (#0)
I0808 18:34:14.686432 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 18:34:14.686485 20451 solver.cpp:404]     Test net output #1: loss = 0.995484 (* 1 = 0.995484 loss)
I0808 18:34:16.887905 20451 solver.cpp:228] Iteration 7500, loss = 0.156653
I0808 18:34:16.888087 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:34:16.888106 20451 solver.cpp:244]     Train net output #1: loss = 0.156653 (* 1 = 0.156653 loss)
I0808 18:34:16.888121 20451 sgd_solver.cpp:106] Iteration 7500, lr = 0.000657236
I0808 18:34:39.159734 20451 solver.cpp:228] Iteration 7510, loss = 0.31305
I0808 18:34:39.159787 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 18:34:39.159801 20451 solver.cpp:244]     Train net output #1: loss = 0.31305 (* 1 = 0.31305 loss)
I0808 18:34:39.159813 20451 sgd_solver.cpp:106] Iteration 7510, lr = 0.000656955
I0808 18:35:01.464270 20451 solver.cpp:228] Iteration 7520, loss = 0.156506
I0808 18:35:01.464445 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:35:01.464460 20451 solver.cpp:244]     Train net output #1: loss = 0.156506 (* 1 = 0.156506 loss)
I0808 18:35:01.464473 20451 sgd_solver.cpp:106] Iteration 7520, lr = 0.000656673
I0808 18:35:23.757797 20451 solver.cpp:228] Iteration 7530, loss = 0.156307
I0808 18:35:23.757851 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:35:23.757865 20451 solver.cpp:244]     Train net output #1: loss = 0.156307 (* 1 = 0.156307 loss)
I0808 18:35:23.757879 20451 sgd_solver.cpp:106] Iteration 7530, lr = 0.000656392
I0808 18:35:46.042333 20451 solver.cpp:228] Iteration 7540, loss = 0.156363
I0808 18:35:46.042510 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:35:46.042526 20451 solver.cpp:244]     Train net output #1: loss = 0.156363 (* 1 = 0.156363 loss)
I0808 18:35:46.042538 20451 sgd_solver.cpp:106] Iteration 7540, lr = 0.000656112
I0808 18:36:08.337723 20451 solver.cpp:228] Iteration 7550, loss = 0.218791
I0808 18:36:08.337764 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:36:08.337779 20451 solver.cpp:244]     Train net output #1: loss = 0.218791 (* 1 = 0.218791 loss)
I0808 18:36:08.337795 20451 sgd_solver.cpp:106] Iteration 7550, lr = 0.000655831
I0808 18:36:30.639082 20451 solver.cpp:228] Iteration 7560, loss = 0.0938153
I0808 18:36:30.639256 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:36:30.639276 20451 solver.cpp:244]     Train net output #1: loss = 0.0938152 (* 1 = 0.0938152 loss)
I0808 18:36:30.639291 20451 sgd_solver.cpp:106] Iteration 7560, lr = 0.000655551
I0808 18:36:52.936473 20451 solver.cpp:228] Iteration 7570, loss = 0.250117
I0808 18:36:52.936527 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:36:52.936542 20451 solver.cpp:244]     Train net output #1: loss = 0.250117 (* 1 = 0.250117 loss)
I0808 18:36:52.936554 20451 sgd_solver.cpp:106] Iteration 7570, lr = 0.000655271
I0808 18:37:15.234441 20451 solver.cpp:228] Iteration 7580, loss = 0.125025
I0808 18:37:15.234622 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:37:15.234638 20451 solver.cpp:244]     Train net output #1: loss = 0.125025 (* 1 = 0.125025 loss)
I0808 18:37:15.234652 20451 sgd_solver.cpp:106] Iteration 7580, lr = 0.000654992
I0808 18:37:37.530378 20451 solver.cpp:228] Iteration 7590, loss = 0.125038
I0808 18:37:37.530427 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:37:37.530441 20451 solver.cpp:244]     Train net output #1: loss = 0.125038 (* 1 = 0.125038 loss)
I0808 18:37:37.530453 20451 sgd_solver.cpp:106] Iteration 7590, lr = 0.000654712
I0808 18:37:57.598511 20451 solver.cpp:337] Iteration 7600, Testing net (#0)
I0808 18:38:06.117219 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 18:38:06.117270 20451 solver.cpp:404]     Test net output #1: loss = 1.00322 (* 1 = 1.00322 loss)
I0808 18:38:08.319133 20451 solver.cpp:228] Iteration 7600, loss = 0.187528
I0808 18:38:08.319183 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:38:08.319197 20451 solver.cpp:244]     Train net output #1: loss = 0.187528 (* 1 = 0.187528 loss)
I0808 18:38:08.319211 20451 sgd_solver.cpp:106] Iteration 7600, lr = 0.000654434
I0808 18:38:30.588949 20451 solver.cpp:228] Iteration 7610, loss = 0.250179
I0808 18:38:30.589118 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:38:30.589133 20451 solver.cpp:244]     Train net output #1: loss = 0.250179 (* 1 = 0.250179 loss)
I0808 18:38:30.589145 20451 sgd_solver.cpp:106] Iteration 7610, lr = 0.000654155
I0808 18:38:52.879834 20451 solver.cpp:228] Iteration 7620, loss = 0.343979
I0808 18:38:52.879881 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 18:38:52.879897 20451 solver.cpp:244]     Train net output #1: loss = 0.343979 (* 1 = 0.343979 loss)
I0808 18:38:52.879914 20451 sgd_solver.cpp:106] Iteration 7620, lr = 0.000653876
I0808 18:39:15.173588 20451 solver.cpp:228] Iteration 7630, loss = 0.28144
I0808 18:39:15.173769 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 18:39:15.173784 20451 solver.cpp:244]     Train net output #1: loss = 0.28144 (* 1 = 0.28144 loss)
I0808 18:39:15.173797 20451 sgd_solver.cpp:106] Iteration 7630, lr = 0.000653598
I0808 18:39:37.469442 20451 solver.cpp:228] Iteration 7640, loss = 0.156389
I0808 18:39:37.469494 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:39:37.469508 20451 solver.cpp:244]     Train net output #1: loss = 0.156389 (* 1 = 0.156389 loss)
I0808 18:39:37.469519 20451 sgd_solver.cpp:106] Iteration 7640, lr = 0.00065332
I0808 18:39:59.757566 20451 solver.cpp:228] Iteration 7650, loss = 0.250197
I0808 18:39:59.757745 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:39:59.757761 20451 solver.cpp:244]     Train net output #1: loss = 0.250197 (* 1 = 0.250197 loss)
I0808 18:39:59.757772 20451 sgd_solver.cpp:106] Iteration 7650, lr = 0.000653043
I0808 18:40:22.056581 20451 solver.cpp:228] Iteration 7660, loss = 0.187547
I0808 18:40:22.056634 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:40:22.056648 20451 solver.cpp:244]     Train net output #1: loss = 0.187547 (* 1 = 0.187547 loss)
I0808 18:40:22.056660 20451 sgd_solver.cpp:106] Iteration 7660, lr = 0.000652765
I0808 18:40:44.348253 20451 solver.cpp:228] Iteration 7670, loss = 0.187829
I0808 18:40:44.348372 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:40:44.348387 20451 solver.cpp:244]     Train net output #1: loss = 0.187829 (* 1 = 0.187829 loss)
I0808 18:40:44.348400 20451 sgd_solver.cpp:106] Iteration 7670, lr = 0.000652488
I0808 18:41:06.642364 20451 solver.cpp:228] Iteration 7680, loss = 0.187564
I0808 18:41:06.642416 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:41:06.642431 20451 solver.cpp:244]     Train net output #1: loss = 0.187564 (* 1 = 0.187564 loss)
I0808 18:41:06.642443 20451 sgd_solver.cpp:106] Iteration 7680, lr = 0.000652211
I0808 18:41:28.937155 20451 solver.cpp:228] Iteration 7690, loss = 0.250065
I0808 18:41:28.937330 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:41:28.937345 20451 solver.cpp:244]     Train net output #1: loss = 0.250065 (* 1 = 0.250065 loss)
I0808 18:41:28.937358 20451 sgd_solver.cpp:106] Iteration 7690, lr = 0.000651935
I0808 18:41:49.012368 20451 solver.cpp:337] Iteration 7700, Testing net (#0)
I0808 18:41:57.531744 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0808 18:41:57.531785 20451 solver.cpp:404]     Test net output #1: loss = 0.966007 (* 1 = 0.966007 loss)
I0808 18:41:59.730891 20451 solver.cpp:228] Iteration 7700, loss = 0.12507
I0808 18:41:59.731062 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:41:59.731077 20451 solver.cpp:244]     Train net output #1: loss = 0.12507 (* 1 = 0.12507 loss)
I0808 18:41:59.731089 20451 sgd_solver.cpp:106] Iteration 7700, lr = 0.000651659
I0808 18:42:21.998554 20451 solver.cpp:228] Iteration 7710, loss = 0.312754
I0808 18:42:21.998602 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 18:42:21.998618 20451 solver.cpp:244]     Train net output #1: loss = 0.312754 (* 1 = 0.312754 loss)
I0808 18:42:21.998631 20451 sgd_solver.cpp:106] Iteration 7710, lr = 0.000651383
I0808 18:42:44.288046 20451 solver.cpp:228] Iteration 7720, loss = 0.312604
I0808 18:42:44.288259 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 18:42:44.288275 20451 solver.cpp:244]     Train net output #1: loss = 0.312604 (* 1 = 0.312604 loss)
I0808 18:42:44.288288 20451 sgd_solver.cpp:106] Iteration 7720, lr = 0.000651107
I0808 18:43:06.585736 20451 solver.cpp:228] Iteration 7730, loss = 0.187727
I0808 18:43:06.585788 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:43:06.585803 20451 solver.cpp:244]     Train net output #1: loss = 0.187727 (* 1 = 0.187727 loss)
I0808 18:43:06.585813 20451 sgd_solver.cpp:106] Iteration 7730, lr = 0.000650831
I0808 18:43:28.880825 20451 solver.cpp:228] Iteration 7740, loss = 0.0626518
I0808 18:43:28.881000 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 18:43:28.881016 20451 solver.cpp:244]     Train net output #1: loss = 0.0626519 (* 1 = 0.0626519 loss)
I0808 18:43:28.881028 20451 sgd_solver.cpp:106] Iteration 7740, lr = 0.000650556
I0808 18:43:51.181717 20451 solver.cpp:228] Iteration 7750, loss = 0.156323
I0808 18:43:51.181769 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:43:51.181784 20451 solver.cpp:244]     Train net output #1: loss = 0.156323 (* 1 = 0.156323 loss)
I0808 18:43:51.181797 20451 sgd_solver.cpp:106] Iteration 7750, lr = 0.000650281
I0808 18:44:13.473115 20451 solver.cpp:228] Iteration 7760, loss = 0.18769
I0808 18:44:13.473299 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:44:13.473315 20451 solver.cpp:244]     Train net output #1: loss = 0.18769 (* 1 = 0.18769 loss)
I0808 18:44:13.473327 20451 sgd_solver.cpp:106] Iteration 7760, lr = 0.000650007
I0808 18:44:35.772595 20451 solver.cpp:228] Iteration 7770, loss = 0.187631
I0808 18:44:35.772640 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:44:35.772666 20451 solver.cpp:244]     Train net output #1: loss = 0.187631 (* 1 = 0.187631 loss)
I0808 18:44:35.772682 20451 sgd_solver.cpp:106] Iteration 7770, lr = 0.000649732
I0808 18:44:58.058835 20451 solver.cpp:228] Iteration 7780, loss = 0.18769
I0808 18:44:58.059015 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:44:58.059029 20451 solver.cpp:244]     Train net output #1: loss = 0.18769 (* 1 = 0.18769 loss)
I0808 18:44:58.059042 20451 sgd_solver.cpp:106] Iteration 7780, lr = 0.000649458
I0808 18:45:20.352444 20451 solver.cpp:228] Iteration 7790, loss = 0.250071
I0808 18:45:20.352499 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:45:20.352514 20451 solver.cpp:244]     Train net output #1: loss = 0.250071 (* 1 = 0.250071 loss)
I0808 18:45:20.352525 20451 sgd_solver.cpp:106] Iteration 7790, lr = 0.000649184
I0808 18:45:40.413918 20451 solver.cpp:337] Iteration 7800, Testing net (#0)
I0808 18:45:48.935233 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0808 18:45:48.935287 20451 solver.cpp:404]     Test net output #1: loss = 1.03186 (* 1 = 1.03186 loss)
I0808 18:45:51.137665 20451 solver.cpp:228] Iteration 7800, loss = 0.281528
I0808 18:45:51.137707 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 18:45:51.137722 20451 solver.cpp:244]     Train net output #1: loss = 0.281528 (* 1 = 0.281528 loss)
I0808 18:45:51.137735 20451 sgd_solver.cpp:106] Iteration 7800, lr = 0.000648911
I0808 18:46:13.419600 20451 solver.cpp:228] Iteration 7810, loss = 0.125077
I0808 18:46:13.419805 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:46:13.419819 20451 solver.cpp:244]     Train net output #1: loss = 0.125077 (* 1 = 0.125077 loss)
I0808 18:46:13.419832 20451 sgd_solver.cpp:106] Iteration 7810, lr = 0.000648638
I0808 18:46:35.716119 20451 solver.cpp:228] Iteration 7820, loss = 0.250308
I0808 18:46:35.716171 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:46:35.716186 20451 solver.cpp:244]     Train net output #1: loss = 0.250308 (* 1 = 0.250308 loss)
I0808 18:46:35.716198 20451 sgd_solver.cpp:106] Iteration 7820, lr = 0.000648364
I0808 18:46:58.012583 20451 solver.cpp:228] Iteration 7830, loss = 0.0937681
I0808 18:46:58.012827 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:46:58.012843 20451 solver.cpp:244]     Train net output #1: loss = 0.0937681 (* 1 = 0.0937681 loss)
I0808 18:46:58.012856 20451 sgd_solver.cpp:106] Iteration 7830, lr = 0.000648092
I0808 18:47:20.315037 20451 solver.cpp:228] Iteration 7840, loss = 0.218868
I0808 18:47:20.315089 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:47:20.315104 20451 solver.cpp:244]     Train net output #1: loss = 0.218868 (* 1 = 0.218868 loss)
I0808 18:47:20.315116 20451 sgd_solver.cpp:106] Iteration 7840, lr = 0.000647819
I0808 18:47:42.614866 20451 solver.cpp:228] Iteration 7850, loss = 0.156388
I0808 18:47:42.615052 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:47:42.615068 20451 solver.cpp:244]     Train net output #1: loss = 0.156388 (* 1 = 0.156388 loss)
I0808 18:47:42.615082 20451 sgd_solver.cpp:106] Iteration 7850, lr = 0.000647547
I0808 18:48:04.919133 20451 solver.cpp:228] Iteration 7860, loss = 0.250181
I0808 18:48:04.919188 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:48:04.919201 20451 solver.cpp:244]     Train net output #1: loss = 0.250181 (* 1 = 0.250181 loss)
I0808 18:48:04.919214 20451 sgd_solver.cpp:106] Iteration 7860, lr = 0.000647275
I0808 18:48:27.221642 20451 solver.cpp:228] Iteration 7870, loss = 0.15632
I0808 18:48:27.221818 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:48:27.221834 20451 solver.cpp:244]     Train net output #1: loss = 0.15632 (* 1 = 0.15632 loss)
I0808 18:48:27.221846 20451 sgd_solver.cpp:106] Iteration 7870, lr = 0.000647003
I0808 18:48:49.521649 20451 solver.cpp:228] Iteration 7880, loss = 0.156617
I0808 18:48:49.521700 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:48:49.521713 20451 solver.cpp:244]     Train net output #1: loss = 0.156617 (* 1 = 0.156617 loss)
I0808 18:48:49.521725 20451 sgd_solver.cpp:106] Iteration 7880, lr = 0.000646732
I0808 18:49:11.835198 20451 solver.cpp:228] Iteration 7890, loss = 0.156293
I0808 18:49:11.835309 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:49:11.835324 20451 solver.cpp:244]     Train net output #1: loss = 0.156293 (* 1 = 0.156293 loss)
I0808 18:49:11.835335 20451 sgd_solver.cpp:106] Iteration 7890, lr = 0.000646461
I0808 18:49:31.909571 20451 solver.cpp:337] Iteration 7900, Testing net (#0)
I0808 18:49:40.432457 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 18:49:40.432508 20451 solver.cpp:404]     Test net output #1: loss = 1.00332 (* 1 = 1.00332 loss)
I0808 18:49:42.635813 20451 solver.cpp:228] Iteration 7900, loss = 0.312613
I0808 18:49:42.635995 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 18:49:42.636009 20451 solver.cpp:244]     Train net output #1: loss = 0.312613 (* 1 = 0.312613 loss)
I0808 18:49:42.636023 20451 sgd_solver.cpp:106] Iteration 7900, lr = 0.00064619
I0808 18:50:04.913352 20451 solver.cpp:228] Iteration 7910, loss = 0.250193
I0808 18:50:04.913403 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:50:04.913417 20451 solver.cpp:244]     Train net output #1: loss = 0.250193 (* 1 = 0.250193 loss)
I0808 18:50:04.913429 20451 sgd_solver.cpp:106] Iteration 7910, lr = 0.000645919
I0808 18:50:27.213610 20451 solver.cpp:228] Iteration 7920, loss = 0.0625404
I0808 18:50:27.213821 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 18:50:27.213841 20451 solver.cpp:244]     Train net output #1: loss = 0.0625404 (* 1 = 0.0625404 loss)
I0808 18:50:27.213857 20451 sgd_solver.cpp:106] Iteration 7920, lr = 0.000645649
I0808 18:50:49.505213 20451 solver.cpp:228] Iteration 7930, loss = 0.093775
I0808 18:50:49.505265 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:50:49.505278 20451 solver.cpp:244]     Train net output #1: loss = 0.093775 (* 1 = 0.093775 loss)
I0808 18:50:49.505290 20451 sgd_solver.cpp:106] Iteration 7930, lr = 0.000645379
I0808 18:51:11.794865 20451 solver.cpp:228] Iteration 7940, loss = 0.187569
I0808 18:51:11.795048 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:51:11.795063 20451 solver.cpp:244]     Train net output #1: loss = 0.187569 (* 1 = 0.187569 loss)
I0808 18:51:11.795075 20451 sgd_solver.cpp:106] Iteration 7940, lr = 0.000645109
I0808 18:51:34.091395 20451 solver.cpp:228] Iteration 7950, loss = 0.31257
I0808 18:51:34.091449 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:51:34.091464 20451 solver.cpp:244]     Train net output #1: loss = 0.31257 (* 1 = 0.31257 loss)
I0808 18:51:34.091475 20451 sgd_solver.cpp:106] Iteration 7950, lr = 0.00064484
I0808 18:51:56.386185 20451 solver.cpp:228] Iteration 7960, loss = 0.281575
I0808 18:51:56.386370 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 18:51:56.386387 20451 solver.cpp:244]     Train net output #1: loss = 0.281575 (* 1 = 0.281575 loss)
I0808 18:51:56.386400 20451 sgd_solver.cpp:106] Iteration 7960, lr = 0.00064457
I0808 18:52:18.682658 20451 solver.cpp:228] Iteration 7970, loss = 0.125251
I0808 18:52:18.682710 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:52:18.682723 20451 solver.cpp:244]     Train net output #1: loss = 0.125251 (* 1 = 0.125251 loss)
I0808 18:52:18.682735 20451 sgd_solver.cpp:106] Iteration 7970, lr = 0.000644301
I0808 18:52:40.984048 20451 solver.cpp:228] Iteration 7980, loss = 0.0937567
I0808 18:52:40.984148 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:52:40.984164 20451 solver.cpp:244]     Train net output #1: loss = 0.0937568 (* 1 = 0.0937568 loss)
I0808 18:52:40.984176 20451 sgd_solver.cpp:106] Iteration 7980, lr = 0.000644032
I0808 18:53:03.291857 20451 solver.cpp:228] Iteration 7990, loss = 0.0312736
I0808 18:53:03.291908 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 18:53:03.291923 20451 solver.cpp:244]     Train net output #1: loss = 0.0312737 (* 1 = 0.0312737 loss)
I0808 18:53:03.291934 20451 sgd_solver.cpp:106] Iteration 7990, lr = 0.000643764
I0808 18:53:23.364047 20451 solver.cpp:337] Iteration 8000, Testing net (#0)
I0808 18:53:31.886970 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 18:53:31.887023 20451 solver.cpp:404]     Test net output #1: loss = 0.984908 (* 1 = 0.984908 loss)
I0808 18:53:34.087327 20451 solver.cpp:228] Iteration 8000, loss = 0.187643
I0808 18:53:34.087378 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:53:34.087393 20451 solver.cpp:244]     Train net output #1: loss = 0.187643 (* 1 = 0.187643 loss)
I0808 18:53:34.087404 20451 sgd_solver.cpp:106] Iteration 8000, lr = 0.000643496
I0808 18:53:56.360512 20451 solver.cpp:228] Iteration 8010, loss = 0.187562
I0808 18:53:56.360620 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:53:56.360637 20451 solver.cpp:244]     Train net output #1: loss = 0.187562 (* 1 = 0.187562 loss)
I0808 18:53:56.360653 20451 sgd_solver.cpp:106] Iteration 8010, lr = 0.000643228
I0808 18:54:18.649868 20451 solver.cpp:228] Iteration 8020, loss = 0.0938042
I0808 18:54:18.649920 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:54:18.649935 20451 solver.cpp:244]     Train net output #1: loss = 0.0938043 (* 1 = 0.0938043 loss)
I0808 18:54:18.649946 20451 sgd_solver.cpp:106] Iteration 8020, lr = 0.00064296
I0808 18:54:40.948442 20451 solver.cpp:228] Iteration 8030, loss = 0.0625506
I0808 18:54:40.948581 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 18:54:40.948598 20451 solver.cpp:244]     Train net output #1: loss = 0.0625506 (* 1 = 0.0625506 loss)
I0808 18:54:40.948611 20451 sgd_solver.cpp:106] Iteration 8030, lr = 0.000642692
I0808 18:55:03.249953 20451 solver.cpp:228] Iteration 8040, loss = 0.125069
I0808 18:55:03.250001 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:55:03.250015 20451 solver.cpp:244]     Train net output #1: loss = 0.125069 (* 1 = 0.125069 loss)
I0808 18:55:03.250027 20451 sgd_solver.cpp:106] Iteration 8040, lr = 0.000642425
I0808 18:55:25.548730 20451 solver.cpp:228] Iteration 8050, loss = 0.0625355
I0808 18:55:25.548915 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 18:55:25.548933 20451 solver.cpp:244]     Train net output #1: loss = 0.0625356 (* 1 = 0.0625356 loss)
I0808 18:55:25.548944 20451 sgd_solver.cpp:106] Iteration 8050, lr = 0.000642158
I0808 18:55:47.845171 20451 solver.cpp:228] Iteration 8060, loss = 0.187586
I0808 18:55:47.845224 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:55:47.845239 20451 solver.cpp:244]     Train net output #1: loss = 0.187586 (* 1 = 0.187586 loss)
I0808 18:55:47.845252 20451 sgd_solver.cpp:106] Iteration 8060, lr = 0.000641892
I0808 18:56:10.145104 20451 solver.cpp:228] Iteration 8070, loss = 0.156395
I0808 18:56:10.145277 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:56:10.145292 20451 solver.cpp:244]     Train net output #1: loss = 0.156395 (* 1 = 0.156395 loss)
I0808 18:56:10.145303 20451 sgd_solver.cpp:106] Iteration 8070, lr = 0.000641625
I0808 18:56:32.441565 20451 solver.cpp:228] Iteration 8080, loss = 0.156352
I0808 18:56:32.441614 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 18:56:32.441628 20451 solver.cpp:244]     Train net output #1: loss = 0.156352 (* 1 = 0.156352 loss)
I0808 18:56:32.441642 20451 sgd_solver.cpp:106] Iteration 8080, lr = 0.000641359
I0808 18:56:54.744525 20451 solver.cpp:228] Iteration 8090, loss = 0.218979
I0808 18:56:54.744706 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 18:56:54.744721 20451 solver.cpp:244]     Train net output #1: loss = 0.218979 (* 1 = 0.218979 loss)
I0808 18:56:54.744734 20451 sgd_solver.cpp:106] Iteration 8090, lr = 0.000641093
I0808 18:57:14.821557 20451 solver.cpp:337] Iteration 8100, Testing net (#0)
I0808 18:57:23.338613 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 18:57:23.338656 20451 solver.cpp:404]     Test net output #1: loss = 0.998553 (* 1 = 0.998553 loss)
I0808 18:57:25.541368 20451 solver.cpp:228] Iteration 8100, loss = 0.187533
I0808 18:57:25.541538 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:57:25.541553 20451 solver.cpp:244]     Train net output #1: loss = 0.187533 (* 1 = 0.187533 loss)
I0808 18:57:25.541565 20451 sgd_solver.cpp:106] Iteration 8100, lr = 0.000640827
I0808 18:57:47.814306 20451 solver.cpp:228] Iteration 8110, loss = 0.15626
I0808 18:57:47.814360 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:57:47.814374 20451 solver.cpp:244]     Train net output #1: loss = 0.15626 (* 1 = 0.15626 loss)
I0808 18:57:47.814388 20451 sgd_solver.cpp:106] Iteration 8110, lr = 0.000640562
I0808 18:58:10.116869 20451 solver.cpp:228] Iteration 8120, loss = 0.09379
I0808 18:58:10.117054 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 18:58:10.117070 20451 solver.cpp:244]     Train net output #1: loss = 0.09379 (* 1 = 0.09379 loss)
I0808 18:58:10.117084 20451 sgd_solver.cpp:106] Iteration 8120, lr = 0.000640297
I0808 18:58:32.412926 20451 solver.cpp:228] Iteration 8130, loss = 0.250176
I0808 18:58:32.412977 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:58:32.412992 20451 solver.cpp:244]     Train net output #1: loss = 0.250176 (* 1 = 0.250176 loss)
I0808 18:58:32.413003 20451 sgd_solver.cpp:106] Iteration 8130, lr = 0.000640032
I0808 18:58:54.711607 20451 solver.cpp:228] Iteration 8140, loss = 0.250107
I0808 18:58:54.711747 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 18:58:54.711767 20451 solver.cpp:244]     Train net output #1: loss = 0.250107 (* 1 = 0.250107 loss)
I0808 18:58:54.711783 20451 sgd_solver.cpp:106] Iteration 8140, lr = 0.000639767
I0808 18:59:17.016765 20451 solver.cpp:228] Iteration 8150, loss = 0.187653
I0808 18:59:17.016809 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 18:59:17.016839 20451 solver.cpp:244]     Train net output #1: loss = 0.187653 (* 1 = 0.187653 loss)
I0808 18:59:17.016855 20451 sgd_solver.cpp:106] Iteration 8150, lr = 0.000639503
I0808 18:59:39.305832 20451 solver.cpp:228] Iteration 8160, loss = 0.125078
I0808 18:59:39.306010 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 18:59:39.306025 20451 solver.cpp:244]     Train net output #1: loss = 0.125078 (* 1 = 0.125078 loss)
I0808 18:59:39.306036 20451 sgd_solver.cpp:106] Iteration 8160, lr = 0.000639239
I0808 19:00:01.604059 20451 solver.cpp:228] Iteration 8170, loss = 0.156344
I0808 19:00:01.604109 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:00:01.604121 20451 solver.cpp:244]     Train net output #1: loss = 0.156344 (* 1 = 0.156344 loss)
I0808 19:00:01.604133 20451 sgd_solver.cpp:106] Iteration 8170, lr = 0.000638975
I0808 19:00:23.903977 20451 solver.cpp:228] Iteration 8180, loss = 0.125068
I0808 19:00:23.906582 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:00:23.906601 20451 solver.cpp:244]     Train net output #1: loss = 0.125068 (* 1 = 0.125068 loss)
I0808 19:00:23.906615 20451 sgd_solver.cpp:106] Iteration 8180, lr = 0.000638711
I0808 19:00:46.197593 20451 solver.cpp:228] Iteration 8190, loss = 0.031266
I0808 19:00:46.197646 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 19:00:46.197661 20451 solver.cpp:244]     Train net output #1: loss = 0.0312662 (* 1 = 0.0312662 loss)
I0808 19:00:46.197672 20451 sgd_solver.cpp:106] Iteration 8190, lr = 0.000638448
I0808 19:01:06.272444 20451 solver.cpp:337] Iteration 8200, Testing net (#0)
I0808 19:01:14.796218 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 19:01:14.796269 20451 solver.cpp:404]     Test net output #1: loss = 0.998654 (* 1 = 0.998654 loss)
I0808 19:01:16.997978 20451 solver.cpp:228] Iteration 8200, loss = 0.0937779
I0808 19:01:16.998024 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:01:16.998040 20451 solver.cpp:244]     Train net output #1: loss = 0.093778 (* 1 = 0.093778 loss)
I0808 19:01:16.998054 20451 sgd_solver.cpp:106] Iteration 8200, lr = 0.000638185
I0808 19:01:39.267213 20451 solver.cpp:228] Iteration 8210, loss = 0.0937867
I0808 19:01:39.267388 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:01:39.267405 20451 solver.cpp:244]     Train net output #1: loss = 0.0937868 (* 1 = 0.0937868 loss)
I0808 19:01:39.267418 20451 sgd_solver.cpp:106] Iteration 8210, lr = 0.000637922
I0808 19:02:01.562249 20451 solver.cpp:228] Iteration 8220, loss = 0.093775
I0808 19:02:01.562301 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:02:01.562315 20451 solver.cpp:244]     Train net output #1: loss = 0.0937751 (* 1 = 0.0937751 loss)
I0808 19:02:01.562328 20451 sgd_solver.cpp:106] Iteration 8220, lr = 0.000637659
I0808 19:02:23.860378 20451 solver.cpp:228] Iteration 8230, loss = 0.250061
I0808 19:02:23.860558 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:02:23.860572 20451 solver.cpp:244]     Train net output #1: loss = 0.250061 (* 1 = 0.250061 loss)
I0808 19:02:23.860585 20451 sgd_solver.cpp:106] Iteration 8230, lr = 0.000637397
I0808 19:02:46.152770 20451 solver.cpp:228] Iteration 8240, loss = 0.0312704
I0808 19:02:46.152822 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 19:02:46.152837 20451 solver.cpp:244]     Train net output #1: loss = 0.0312705 (* 1 = 0.0312705 loss)
I0808 19:02:46.152848 20451 sgd_solver.cpp:106] Iteration 8240, lr = 0.000637135
I0808 19:03:08.453563 20451 solver.cpp:228] Iteration 8250, loss = 0.187575
I0808 19:03:08.453778 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:03:08.453794 20451 solver.cpp:244]     Train net output #1: loss = 0.187575 (* 1 = 0.187575 loss)
I0808 19:03:08.453806 20451 sgd_solver.cpp:106] Iteration 8250, lr = 0.000636873
I0808 19:03:30.761677 20451 solver.cpp:228] Iteration 8260, loss = 0.344037
I0808 19:03:30.761729 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 19:03:30.761742 20451 solver.cpp:244]     Train net output #1: loss = 0.344037 (* 1 = 0.344037 loss)
I0808 19:03:30.761754 20451 sgd_solver.cpp:106] Iteration 8260, lr = 0.000636611
I0808 19:03:53.071833 20451 solver.cpp:228] Iteration 8270, loss = 0.156345
I0808 19:03:53.072016 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:03:53.072034 20451 solver.cpp:244]     Train net output #1: loss = 0.156346 (* 1 = 0.156346 loss)
I0808 19:03:53.072051 20451 sgd_solver.cpp:106] Iteration 8270, lr = 0.00063635
I0808 19:04:15.372561 20451 solver.cpp:228] Iteration 8280, loss = 0.28151
I0808 19:04:15.372613 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 19:04:15.372627 20451 solver.cpp:244]     Train net output #1: loss = 0.281511 (* 1 = 0.281511 loss)
I0808 19:04:15.372638 20451 sgd_solver.cpp:106] Iteration 8280, lr = 0.000636089
I0808 19:04:37.670506 20451 solver.cpp:228] Iteration 8290, loss = 0.156296
I0808 19:04:37.670693 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:04:37.670708 20451 solver.cpp:244]     Train net output #1: loss = 0.156297 (* 1 = 0.156297 loss)
I0808 19:04:37.670720 20451 sgd_solver.cpp:106] Iteration 8290, lr = 0.000635828
I0808 19:04:57.745677 20451 solver.cpp:337] Iteration 8300, Testing net (#0)
I0808 19:05:06.277412 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 19:05:06.277463 20451 solver.cpp:404]     Test net output #1: loss = 1.00875 (* 1 = 1.00875 loss)
I0808 19:05:08.477838 20451 solver.cpp:228] Iteration 8300, loss = 0.187755
I0808 19:05:08.477942 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:05:08.477962 20451 solver.cpp:244]     Train net output #1: loss = 0.187755 (* 1 = 0.187755 loss)
I0808 19:05:08.477978 20451 sgd_solver.cpp:106] Iteration 8300, lr = 0.000635568
I0808 19:05:30.761756 20451 solver.cpp:228] Iteration 8310, loss = 0.15631
I0808 19:05:30.761798 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:05:30.761826 20451 solver.cpp:244]     Train net output #1: loss = 0.156311 (* 1 = 0.156311 loss)
I0808 19:05:30.761842 20451 sgd_solver.cpp:106] Iteration 8310, lr = 0.000635307
I0808 19:05:53.060617 20451 solver.cpp:228] Iteration 8320, loss = 0.312796
I0808 19:05:53.060796 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 19:05:53.060811 20451 solver.cpp:244]     Train net output #1: loss = 0.312796 (* 1 = 0.312796 loss)
I0808 19:05:53.060823 20451 sgd_solver.cpp:106] Iteration 8320, lr = 0.000635047
I0808 19:06:15.359601 20451 solver.cpp:228] Iteration 8330, loss = 0.125077
I0808 19:06:15.359642 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:06:15.359658 20451 solver.cpp:244]     Train net output #1: loss = 0.125077 (* 1 = 0.125077 loss)
I0808 19:06:15.359669 20451 sgd_solver.cpp:106] Iteration 8330, lr = 0.000634787
I0808 19:06:37.656971 20451 solver.cpp:228] Iteration 8340, loss = 0.312712
I0808 19:06:37.657150 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 19:06:37.657165 20451 solver.cpp:244]     Train net output #1: loss = 0.312712 (* 1 = 0.312712 loss)
I0808 19:06:37.657177 20451 sgd_solver.cpp:106] Iteration 8340, lr = 0.000634528
I0808 19:06:59.950647 20451 solver.cpp:228] Iteration 8350, loss = 0.187614
I0808 19:06:59.950698 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:06:59.950712 20451 solver.cpp:244]     Train net output #1: loss = 0.187614 (* 1 = 0.187614 loss)
I0808 19:06:59.950724 20451 sgd_solver.cpp:106] Iteration 8350, lr = 0.000634268
I0808 19:07:22.256701 20451 solver.cpp:228] Iteration 8360, loss = 0.156291
I0808 19:07:22.256894 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:07:22.256909 20451 solver.cpp:244]     Train net output #1: loss = 0.156291 (* 1 = 0.156291 loss)
I0808 19:07:22.256922 20451 sgd_solver.cpp:106] Iteration 8360, lr = 0.000634009
I0808 19:07:44.562587 20451 solver.cpp:228] Iteration 8370, loss = 0.250217
I0808 19:07:44.562639 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:07:44.562654 20451 solver.cpp:244]     Train net output #1: loss = 0.250217 (* 1 = 0.250217 loss)
I0808 19:07:44.562665 20451 sgd_solver.cpp:106] Iteration 8370, lr = 0.00063375
I0808 19:08:06.866168 20451 solver.cpp:228] Iteration 8380, loss = 0.187814
I0808 19:08:06.866349 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:08:06.866364 20451 solver.cpp:244]     Train net output #1: loss = 0.187814 (* 1 = 0.187814 loss)
I0808 19:08:06.866376 20451 sgd_solver.cpp:106] Iteration 8380, lr = 0.000633492
I0808 19:08:29.174639 20451 solver.cpp:228] Iteration 8390, loss = 0.125257
I0808 19:08:29.174693 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:08:29.174707 20451 solver.cpp:244]     Train net output #1: loss = 0.125258 (* 1 = 0.125258 loss)
I0808 19:08:29.174721 20451 sgd_solver.cpp:106] Iteration 8390, lr = 0.000633233
I0808 19:08:49.249186 20451 solver.cpp:337] Iteration 8400, Testing net (#0)
I0808 19:08:57.774065 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 19:08:57.774116 20451 solver.cpp:404]     Test net output #1: loss = 1.00346 (* 1 = 1.00346 loss)
I0808 19:08:59.975807 20451 solver.cpp:228] Iteration 8400, loss = 0.156325
I0808 19:08:59.975862 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:08:59.975874 20451 solver.cpp:244]     Train net output #1: loss = 0.156326 (* 1 = 0.156326 loss)
I0808 19:08:59.975886 20451 sgd_solver.cpp:106] Iteration 8400, lr = 0.000632975
I0808 19:09:22.256009 20451 solver.cpp:228] Iteration 8410, loss = 0.156479
I0808 19:09:22.256188 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:09:22.256203 20451 solver.cpp:244]     Train net output #1: loss = 0.156479 (* 1 = 0.156479 loss)
I0808 19:09:22.256217 20451 sgd_solver.cpp:106] Iteration 8410, lr = 0.000632717
I0808 19:09:44.551385 20451 solver.cpp:228] Iteration 8420, loss = 0.125045
I0808 19:09:44.551439 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:09:44.551452 20451 solver.cpp:244]     Train net output #1: loss = 0.125045 (* 1 = 0.125045 loss)
I0808 19:09:44.551465 20451 sgd_solver.cpp:106] Iteration 8420, lr = 0.00063246
I0808 19:10:06.847115 20451 solver.cpp:228] Iteration 8430, loss = 0.343893
I0808 19:10:06.847205 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 19:10:06.847219 20451 solver.cpp:244]     Train net output #1: loss = 0.343893 (* 1 = 0.343893 loss)
I0808 19:10:06.847231 20451 sgd_solver.cpp:106] Iteration 8430, lr = 0.000632202
I0808 19:10:29.150312 20451 solver.cpp:228] Iteration 8440, loss = 0.187566
I0808 19:10:29.150362 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:10:29.150377 20451 solver.cpp:244]     Train net output #1: loss = 0.187567 (* 1 = 0.187567 loss)
I0808 19:10:29.150388 20451 sgd_solver.cpp:106] Iteration 8440, lr = 0.000631945
I0808 19:10:51.449911 20451 solver.cpp:228] Iteration 8450, loss = 0.156329
I0808 19:10:51.450089 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:10:51.450104 20451 solver.cpp:244]     Train net output #1: loss = 0.156329 (* 1 = 0.156329 loss)
I0808 19:10:51.450117 20451 sgd_solver.cpp:106] Iteration 8450, lr = 0.000631688
I0808 19:11:13.740368 20451 solver.cpp:228] Iteration 8460, loss = 0.156353
I0808 19:11:13.740417 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:11:13.740437 20451 solver.cpp:244]     Train net output #1: loss = 0.156353 (* 1 = 0.156353 loss)
I0808 19:11:13.740453 20451 sgd_solver.cpp:106] Iteration 8460, lr = 0.000631432
I0808 19:11:36.038861 20451 solver.cpp:228] Iteration 8470, loss = 0.0938334
I0808 19:11:36.039083 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:11:36.039103 20451 solver.cpp:244]     Train net output #1: loss = 0.0938335 (* 1 = 0.0938335 loss)
I0808 19:11:36.039118 20451 sgd_solver.cpp:106] Iteration 8470, lr = 0.000631175
I0808 19:11:58.321851 20451 solver.cpp:228] Iteration 8480, loss = 0.125035
I0808 19:11:58.321905 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:11:58.321919 20451 solver.cpp:244]     Train net output #1: loss = 0.125035 (* 1 = 0.125035 loss)
I0808 19:11:58.321933 20451 sgd_solver.cpp:106] Iteration 8480, lr = 0.000630919
I0808 19:12:20.620767 20451 solver.cpp:228] Iteration 8490, loss = 0.218847
I0808 19:12:20.620864 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:12:20.620879 20451 solver.cpp:244]     Train net output #1: loss = 0.218847 (* 1 = 0.218847 loss)
I0808 19:12:20.620893 20451 sgd_solver.cpp:106] Iteration 8490, lr = 0.000630663
I0808 19:12:40.702136 20451 solver.cpp:337] Iteration 8500, Testing net (#0)
I0808 19:12:49.227540 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0808 19:12:49.227584 20451 solver.cpp:404]     Test net output #1: loss = 0.96102 (* 1 = 0.96102 loss)
I0808 19:12:51.429419 20451 solver.cpp:228] Iteration 8500, loss = 0.250167
I0808 19:12:51.429600 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:12:51.429618 20451 solver.cpp:244]     Train net output #1: loss = 0.250167 (* 1 = 0.250167 loss)
I0808 19:12:51.429633 20451 sgd_solver.cpp:106] Iteration 8500, lr = 0.000630407
I0808 19:13:13.709791 20451 solver.cpp:228] Iteration 8510, loss = 0.0625426
I0808 19:13:13.709837 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 19:13:13.709856 20451 solver.cpp:244]     Train net output #1: loss = 0.0625427 (* 1 = 0.0625427 loss)
I0808 19:13:13.709870 20451 sgd_solver.cpp:106] Iteration 8510, lr = 0.000630152
I0808 19:13:36.009796 20451 solver.cpp:228] Iteration 8520, loss = 0.0626577
I0808 19:13:36.009969 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 19:13:36.009984 20451 solver.cpp:244]     Train net output #1: loss = 0.0626578 (* 1 = 0.0626578 loss)
I0808 19:13:36.009997 20451 sgd_solver.cpp:106] Iteration 8520, lr = 0.000629897
I0808 19:13:58.306134 20451 solver.cpp:228] Iteration 8530, loss = 0.156278
I0808 19:13:58.306186 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:13:58.306200 20451 solver.cpp:244]     Train net output #1: loss = 0.156278 (* 1 = 0.156278 loss)
I0808 19:13:58.306212 20451 sgd_solver.cpp:106] Iteration 8530, lr = 0.000629642
I0808 19:14:20.621830 20451 solver.cpp:228] Iteration 8540, loss = 0.125035
I0808 19:14:20.622006 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:14:20.622022 20451 solver.cpp:244]     Train net output #1: loss = 0.125036 (* 1 = 0.125036 loss)
I0808 19:14:20.622035 20451 sgd_solver.cpp:106] Iteration 8540, lr = 0.000629387
I0808 19:14:42.918220 20451 solver.cpp:228] Iteration 8550, loss = 0.0937813
I0808 19:14:42.918272 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:14:42.918285 20451 solver.cpp:244]     Train net output #1: loss = 0.0937814 (* 1 = 0.0937814 loss)
I0808 19:14:42.918298 20451 sgd_solver.cpp:106] Iteration 8550, lr = 0.000629132
I0808 19:15:05.225267 20451 solver.cpp:228] Iteration 8560, loss = 0.156344
I0808 19:15:05.225451 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:15:05.225467 20451 solver.cpp:244]     Train net output #1: loss = 0.156344 (* 1 = 0.156344 loss)
I0808 19:15:05.225481 20451 sgd_solver.cpp:106] Iteration 8560, lr = 0.000628878
I0808 19:15:27.527895 20451 solver.cpp:228] Iteration 8570, loss = 0.250173
I0808 19:15:27.527947 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:15:27.527961 20451 solver.cpp:244]     Train net output #1: loss = 0.250173 (* 1 = 0.250173 loss)
I0808 19:15:27.527973 20451 sgd_solver.cpp:106] Iteration 8570, lr = 0.000628624
I0808 19:15:49.825999 20451 solver.cpp:228] Iteration 8580, loss = 0.156301
I0808 19:15:49.826143 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:15:49.826164 20451 solver.cpp:244]     Train net output #1: loss = 0.156301 (* 1 = 0.156301 loss)
I0808 19:15:49.826179 20451 sgd_solver.cpp:106] Iteration 8580, lr = 0.00062837
I0808 19:16:12.123215 20451 solver.cpp:228] Iteration 8590, loss = 0.218935
I0808 19:16:12.123260 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:16:12.123291 20451 solver.cpp:244]     Train net output #1: loss = 0.218935 (* 1 = 0.218935 loss)
I0808 19:16:12.123306 20451 sgd_solver.cpp:106] Iteration 8590, lr = 0.000628117
I0808 19:16:32.194398 20451 solver.cpp:337] Iteration 8600, Testing net (#0)
I0808 19:16:40.711269 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 19:16:40.711323 20451 solver.cpp:404]     Test net output #1: loss = 0.994197 (* 1 = 0.994197 loss)
I0808 19:16:42.913033 20451 solver.cpp:228] Iteration 8600, loss = 0.156352
I0808 19:16:42.913076 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:16:42.913094 20451 solver.cpp:244]     Train net output #1: loss = 0.156352 (* 1 = 0.156352 loss)
I0808 19:16:42.913110 20451 sgd_solver.cpp:106] Iteration 8600, lr = 0.000627864
I0808 19:17:05.192340 20451 solver.cpp:228] Iteration 8610, loss = 0.218854
I0808 19:17:05.192519 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:17:05.192538 20451 solver.cpp:244]     Train net output #1: loss = 0.218854 (* 1 = 0.218854 loss)
I0808 19:17:05.192553 20451 sgd_solver.cpp:106] Iteration 8610, lr = 0.000627611
I0808 19:17:27.479776 20451 solver.cpp:228] Iteration 8620, loss = 0.125079
I0808 19:17:27.479822 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:17:27.479841 20451 solver.cpp:244]     Train net output #1: loss = 0.125079 (* 1 = 0.125079 loss)
I0808 19:17:27.479857 20451 sgd_solver.cpp:106] Iteration 8620, lr = 0.000627358
I0808 19:17:49.774629 20451 solver.cpp:228] Iteration 8630, loss = 0.156398
I0808 19:17:49.774725 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:17:49.774745 20451 solver.cpp:244]     Train net output #1: loss = 0.156398 (* 1 = 0.156398 loss)
I0808 19:17:49.774761 20451 sgd_solver.cpp:106] Iteration 8630, lr = 0.000627105
I0808 19:18:12.084617 20451 solver.cpp:228] Iteration 8640, loss = 0.125361
I0808 19:18:12.084671 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:18:12.084684 20451 solver.cpp:244]     Train net output #1: loss = 0.125361 (* 1 = 0.125361 loss)
I0808 19:18:12.084697 20451 sgd_solver.cpp:106] Iteration 8640, lr = 0.000626853
I0808 19:18:34.377691 20451 solver.cpp:228] Iteration 8650, loss = 0.125012
I0808 19:18:34.377873 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:18:34.377889 20451 solver.cpp:244]     Train net output #1: loss = 0.125012 (* 1 = 0.125012 loss)
I0808 19:18:34.377902 20451 sgd_solver.cpp:106] Iteration 8650, lr = 0.000626601
I0808 19:18:56.673899 20451 solver.cpp:228] Iteration 8660, loss = 0.187531
I0808 19:18:56.673948 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:18:56.673966 20451 solver.cpp:244]     Train net output #1: loss = 0.187531 (* 1 = 0.187531 loss)
I0808 19:18:56.673992 20451 sgd_solver.cpp:106] Iteration 8660, lr = 0.000626349
I0808 19:19:18.978415 20451 solver.cpp:228] Iteration 8670, loss = 0.125065
I0808 19:19:18.978528 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:19:18.978543 20451 solver.cpp:244]     Train net output #1: loss = 0.125065 (* 1 = 0.125065 loss)
I0808 19:19:18.978555 20451 sgd_solver.cpp:106] Iteration 8670, lr = 0.000626097
I0808 19:19:41.284096 20451 solver.cpp:228] Iteration 8680, loss = 0.187638
I0808 19:19:41.284148 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:19:41.284162 20451 solver.cpp:244]     Train net output #1: loss = 0.187638 (* 1 = 0.187638 loss)
I0808 19:19:41.284174 20451 sgd_solver.cpp:106] Iteration 8680, lr = 0.000625846
I0808 19:20:03.587076 20451 solver.cpp:228] Iteration 8690, loss = 0.12526
I0808 19:20:03.587301 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:20:03.587321 20451 solver.cpp:244]     Train net output #1: loss = 0.125261 (* 1 = 0.125261 loss)
I0808 19:20:03.587337 20451 sgd_solver.cpp:106] Iteration 8690, lr = 0.000625595
I0808 19:20:23.658777 20451 solver.cpp:337] Iteration 8700, Testing net (#0)
I0808 19:20:32.181193 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 19:20:32.181246 20451 solver.cpp:404]     Test net output #1: loss = 0.999237 (* 1 = 0.999237 loss)
I0808 19:20:34.383127 20451 solver.cpp:228] Iteration 8700, loss = 0.250286
I0808 19:20:34.383323 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:20:34.383338 20451 solver.cpp:244]     Train net output #1: loss = 0.250286 (* 1 = 0.250286 loss)
I0808 19:20:34.383352 20451 sgd_solver.cpp:106] Iteration 8700, lr = 0.000625344
I0808 19:20:56.652935 20451 solver.cpp:228] Iteration 8710, loss = 0.093922
I0808 19:20:56.652987 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:20:56.653000 20451 solver.cpp:244]     Train net output #1: loss = 0.0939222 (* 1 = 0.0939222 loss)
I0808 19:20:56.653012 20451 sgd_solver.cpp:106] Iteration 8710, lr = 0.000625093
I0808 19:21:18.952147 20451 solver.cpp:228] Iteration 8720, loss = 0.0939093
I0808 19:21:18.952262 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:21:18.952281 20451 solver.cpp:244]     Train net output #1: loss = 0.0939095 (* 1 = 0.0939095 loss)
I0808 19:21:18.952297 20451 sgd_solver.cpp:106] Iteration 8720, lr = 0.000624843
I0808 19:21:41.255216 20451 solver.cpp:228] Iteration 8730, loss = 0.218824
I0808 19:21:41.255270 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:21:41.255287 20451 solver.cpp:244]     Train net output #1: loss = 0.218824 (* 1 = 0.218824 loss)
I0808 19:21:41.255300 20451 sgd_solver.cpp:106] Iteration 8730, lr = 0.000624592
I0808 19:22:03.551933 20451 solver.cpp:228] Iteration 8740, loss = 0.125046
I0808 19:22:03.552116 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:22:03.552132 20451 solver.cpp:244]     Train net output #1: loss = 0.125046 (* 1 = 0.125046 loss)
I0808 19:22:03.552145 20451 sgd_solver.cpp:106] Iteration 8740, lr = 0.000624342
I0808 19:22:25.855798 20451 solver.cpp:228] Iteration 8750, loss = 0.218925
I0808 19:22:25.855851 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:22:25.855866 20451 solver.cpp:244]     Train net output #1: loss = 0.218925 (* 1 = 0.218925 loss)
I0808 19:22:25.855878 20451 sgd_solver.cpp:106] Iteration 8750, lr = 0.000624093
I0808 19:22:48.145671 20451 solver.cpp:228] Iteration 8760, loss = 0.0939574
I0808 19:22:48.145772 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:22:48.145787 20451 solver.cpp:244]     Train net output #1: loss = 0.0939576 (* 1 = 0.0939576 loss)
I0808 19:22:48.145800 20451 sgd_solver.cpp:106] Iteration 8760, lr = 0.000623843
I0808 19:23:10.447867 20451 solver.cpp:228] Iteration 8770, loss = 0.0626637
I0808 19:23:10.447921 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 19:23:10.447935 20451 solver.cpp:244]     Train net output #1: loss = 0.0626639 (* 1 = 0.0626639 loss)
I0808 19:23:10.447948 20451 sgd_solver.cpp:106] Iteration 8770, lr = 0.000623594
I0808 19:23:32.738407 20451 solver.cpp:228] Iteration 8780, loss = 0.156342
I0808 19:23:32.738499 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:23:32.738518 20451 solver.cpp:244]     Train net output #1: loss = 0.156342 (* 1 = 0.156342 loss)
I0808 19:23:32.738534 20451 sgd_solver.cpp:106] Iteration 8780, lr = 0.000623345
I0808 19:23:55.033087 20451 solver.cpp:228] Iteration 8790, loss = 0.313046
I0808 19:23:55.033138 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 19:23:55.033152 20451 solver.cpp:244]     Train net output #1: loss = 0.313046 (* 1 = 0.313046 loss)
I0808 19:23:55.033165 20451 sgd_solver.cpp:106] Iteration 8790, lr = 0.000623096
I0808 19:24:15.112645 20451 solver.cpp:337] Iteration 8800, Testing net (#0)
I0808 19:24:23.642599 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0808 19:24:23.642640 20451 solver.cpp:404]     Test net output #1: loss = 0.989102 (* 1 = 0.989102 loss)
I0808 19:24:25.846650 20451 solver.cpp:228] Iteration 8800, loss = 0.156258
I0808 19:24:25.846704 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:24:25.846719 20451 solver.cpp:244]     Train net output #1: loss = 0.156258 (* 1 = 0.156258 loss)
I0808 19:24:25.846730 20451 sgd_solver.cpp:106] Iteration 8800, lr = 0.000622847
I0808 19:24:48.120702 20451 solver.cpp:228] Iteration 8810, loss = 0.187695
I0808 19:24:48.120874 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:24:48.120889 20451 solver.cpp:244]     Train net output #1: loss = 0.187695 (* 1 = 0.187695 loss)
I0808 19:24:48.120903 20451 sgd_solver.cpp:106] Iteration 8810, lr = 0.000622599
I0808 19:25:10.427037 20451 solver.cpp:228] Iteration 8820, loss = 0.250369
I0808 19:25:10.427094 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:25:10.427112 20451 solver.cpp:244]     Train net output #1: loss = 0.250369 (* 1 = 0.250369 loss)
I0808 19:25:10.427129 20451 sgd_solver.cpp:106] Iteration 8820, lr = 0.000622351
I0808 19:25:32.712867 20451 solver.cpp:228] Iteration 8830, loss = 0.218967
I0808 19:25:32.713052 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:25:32.713073 20451 solver.cpp:244]     Train net output #1: loss = 0.218968 (* 1 = 0.218968 loss)
I0808 19:25:32.713088 20451 sgd_solver.cpp:106] Iteration 8830, lr = 0.000622103
I0808 19:25:55.017163 20451 solver.cpp:228] Iteration 8840, loss = 0.125127
I0808 19:25:55.017205 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:25:55.017220 20451 solver.cpp:244]     Train net output #1: loss = 0.125127 (* 1 = 0.125127 loss)
I0808 19:25:55.017231 20451 sgd_solver.cpp:106] Iteration 8840, lr = 0.000621855
I0808 19:26:17.326758 20451 solver.cpp:228] Iteration 8850, loss = 0.0938061
I0808 19:26:17.326937 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:26:17.326953 20451 solver.cpp:244]     Train net output #1: loss = 0.0938063 (* 1 = 0.0938063 loss)
I0808 19:26:17.326967 20451 sgd_solver.cpp:106] Iteration 8850, lr = 0.000621608
I0808 19:26:39.629796 20451 solver.cpp:228] Iteration 8860, loss = 0.218802
I0808 19:26:39.629848 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:26:39.629861 20451 solver.cpp:244]     Train net output #1: loss = 0.218802 (* 1 = 0.218802 loss)
I0808 19:26:39.629873 20451 sgd_solver.cpp:106] Iteration 8860, lr = 0.000621361
I0808 19:27:01.935225 20451 solver.cpp:228] Iteration 8870, loss = 0.0938081
I0808 19:27:01.935431 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:27:01.935446 20451 solver.cpp:244]     Train net output #1: loss = 0.0938084 (* 1 = 0.0938084 loss)
I0808 19:27:01.935459 20451 sgd_solver.cpp:106] Iteration 8870, lr = 0.000621114
I0808 19:27:24.239699 20451 solver.cpp:228] Iteration 8880, loss = 0.187656
I0808 19:27:24.239750 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:27:24.239765 20451 solver.cpp:244]     Train net output #1: loss = 0.187656 (* 1 = 0.187656 loss)
I0808 19:27:24.239778 20451 sgd_solver.cpp:106] Iteration 8880, lr = 0.000620867
I0808 19:27:46.537142 20451 solver.cpp:228] Iteration 8890, loss = 0.312604
I0808 19:27:46.537248 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 19:27:46.537264 20451 solver.cpp:244]     Train net output #1: loss = 0.312604 (* 1 = 0.312604 loss)
I0808 19:27:46.537277 20451 sgd_solver.cpp:106] Iteration 8890, lr = 0.00062062
I0808 19:28:06.609433 20451 solver.cpp:337] Iteration 8900, Testing net (#0)
I0808 19:28:15.127203 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0808 19:28:15.127246 20451 solver.cpp:404]     Test net output #1: loss = 1.03637 (* 1 = 1.03637 loss)
I0808 19:28:17.328375 20451 solver.cpp:228] Iteration 8900, loss = 0.281413
I0808 19:28:17.328593 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 19:28:17.328609 20451 solver.cpp:244]     Train net output #1: loss = 0.281413 (* 1 = 0.281413 loss)
I0808 19:28:17.328621 20451 sgd_solver.cpp:106] Iteration 8900, lr = 0.000620374
I0808 19:28:39.587936 20451 solver.cpp:228] Iteration 8910, loss = 0.187554
I0808 19:28:39.587987 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:28:39.588002 20451 solver.cpp:244]     Train net output #1: loss = 0.187555 (* 1 = 0.187555 loss)
I0808 19:28:39.588013 20451 sgd_solver.cpp:106] Iteration 8910, lr = 0.000620128
I0808 19:29:01.875313 20451 solver.cpp:228] Iteration 8920, loss = 0.0937947
I0808 19:29:01.875483 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:29:01.875526 20451 solver.cpp:244]     Train net output #1: loss = 0.093795 (* 1 = 0.093795 loss)
I0808 19:29:01.875561 20451 sgd_solver.cpp:106] Iteration 8920, lr = 0.000619882
I0808 19:29:24.166280 20451 solver.cpp:228] Iteration 8930, loss = 0.187652
I0808 19:29:24.166332 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:29:24.166345 20451 solver.cpp:244]     Train net output #1: loss = 0.187652 (* 1 = 0.187652 loss)
I0808 19:29:24.166357 20451 sgd_solver.cpp:106] Iteration 8930, lr = 0.000619637
I0808 19:29:46.464463 20451 solver.cpp:228] Iteration 8940, loss = 0.219076
I0808 19:29:46.464638 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:29:46.464654 20451 solver.cpp:244]     Train net output #1: loss = 0.219076 (* 1 = 0.219076 loss)
I0808 19:29:46.464666 20451 sgd_solver.cpp:106] Iteration 8940, lr = 0.000619391
I0808 19:30:08.759256 20451 solver.cpp:228] Iteration 8950, loss = 0.0625293
I0808 19:30:08.759320 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 19:30:08.759340 20451 solver.cpp:244]     Train net output #1: loss = 0.0625296 (* 1 = 0.0625296 loss)
I0808 19:30:08.759356 20451 sgd_solver.cpp:106] Iteration 8950, lr = 0.000619146
I0808 19:30:31.068737 20451 solver.cpp:228] Iteration 8960, loss = 0.218778
I0808 19:30:31.068917 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:30:31.068931 20451 solver.cpp:244]     Train net output #1: loss = 0.218779 (* 1 = 0.218779 loss)
I0808 19:30:31.068944 20451 sgd_solver.cpp:106] Iteration 8960, lr = 0.000618901
I0808 19:30:53.375988 20451 solver.cpp:228] Iteration 8970, loss = 0.187541
I0808 19:30:53.376041 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:30:53.376056 20451 solver.cpp:244]     Train net output #1: loss = 0.187541 (* 1 = 0.187541 loss)
I0808 19:30:53.376068 20451 sgd_solver.cpp:106] Iteration 8970, lr = 0.000618656
I0808 19:31:15.678398 20451 solver.cpp:228] Iteration 8980, loss = 0.125047
I0808 19:31:15.678575 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:31:15.678589 20451 solver.cpp:244]     Train net output #1: loss = 0.125047 (* 1 = 0.125047 loss)
I0808 19:31:15.678602 20451 sgd_solver.cpp:106] Iteration 8980, lr = 0.000618412
I0808 19:31:37.981763 20451 solver.cpp:228] Iteration 8990, loss = 0.218903
I0808 19:31:37.981811 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:31:37.981829 20451 solver.cpp:244]     Train net output #1: loss = 0.218904 (* 1 = 0.218904 loss)
I0808 19:31:37.981844 20451 sgd_solver.cpp:106] Iteration 8990, lr = 0.000618168
I0808 19:31:58.050755 20451 solver.cpp:337] Iteration 9000, Testing net (#0)
I0808 19:32:06.580723 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 19:32:06.580767 20451 solver.cpp:404]     Test net output #1: loss = 0.985049 (* 1 = 0.985049 loss)
I0808 19:32:08.783982 20451 solver.cpp:228] Iteration 9000, loss = 0.344085
I0808 19:32:08.784039 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 19:32:08.784054 20451 solver.cpp:244]     Train net output #1: loss = 0.344085 (* 1 = 0.344085 loss)
I0808 19:32:08.784065 20451 sgd_solver.cpp:106] Iteration 9000, lr = 0.000617924
I0808 19:32:31.063055 20451 solver.cpp:228] Iteration 9010, loss = 0.343807
I0808 19:32:31.063354 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 19:32:31.063393 20451 solver.cpp:244]     Train net output #1: loss = 0.343807 (* 1 = 0.343807 loss)
I0808 19:32:31.063428 20451 sgd_solver.cpp:106] Iteration 9010, lr = 0.00061768
I0808 19:32:53.376296 20451 solver.cpp:228] Iteration 9020, loss = 0.12509
I0808 19:32:53.376348 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:32:53.376361 20451 solver.cpp:244]     Train net output #1: loss = 0.12509 (* 1 = 0.12509 loss)
I0808 19:32:53.376374 20451 sgd_solver.cpp:106] Iteration 9020, lr = 0.000617436
I0808 19:33:15.684439 20451 solver.cpp:228] Iteration 9030, loss = 0.25014
I0808 19:33:15.684624 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:33:15.684639 20451 solver.cpp:244]     Train net output #1: loss = 0.250141 (* 1 = 0.250141 loss)
I0808 19:33:15.684651 20451 sgd_solver.cpp:106] Iteration 9030, lr = 0.000617193
I0808 19:33:37.986215 20451 solver.cpp:228] Iteration 9040, loss = 0.156421
I0808 19:33:37.986263 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:33:37.986281 20451 solver.cpp:244]     Train net output #1: loss = 0.156421 (* 1 = 0.156421 loss)
I0808 19:33:37.986295 20451 sgd_solver.cpp:106] Iteration 9040, lr = 0.00061695
I0808 19:34:00.292013 20451 solver.cpp:228] Iteration 9050, loss = 0.218773
I0808 19:34:00.292191 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:34:00.292206 20451 solver.cpp:244]     Train net output #1: loss = 0.218773 (* 1 = 0.218773 loss)
I0808 19:34:00.292218 20451 sgd_solver.cpp:106] Iteration 9050, lr = 0.000616707
I0808 19:34:22.599036 20451 solver.cpp:228] Iteration 9060, loss = 0.187681
I0808 19:34:22.599084 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:34:22.599102 20451 solver.cpp:244]     Train net output #1: loss = 0.187681 (* 1 = 0.187681 loss)
I0808 19:34:22.599117 20451 sgd_solver.cpp:106] Iteration 9060, lr = 0.000616464
I0808 19:34:44.897173 20451 solver.cpp:228] Iteration 9070, loss = 1.10269e-06
I0808 19:34:44.897279 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:34:44.897299 20451 solver.cpp:244]     Train net output #1: loss = 1.38674e-06 (* 1 = 1.38674e-06 loss)
I0808 19:34:44.897313 20451 sgd_solver.cpp:106] Iteration 9070, lr = 0.000616222
I0808 19:35:07.204763 20451 solver.cpp:228] Iteration 9080, loss = 0.125069
I0808 19:35:07.204815 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:35:07.204829 20451 solver.cpp:244]     Train net output #1: loss = 0.125069 (* 1 = 0.125069 loss)
I0808 19:35:07.204843 20451 sgd_solver.cpp:106] Iteration 9080, lr = 0.000615979
I0808 19:35:29.511747 20451 solver.cpp:228] Iteration 9090, loss = 0.156327
I0808 19:35:29.511935 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:35:29.511955 20451 solver.cpp:244]     Train net output #1: loss = 0.156327 (* 1 = 0.156327 loss)
I0808 19:35:29.511970 20451 sgd_solver.cpp:106] Iteration 9090, lr = 0.000615737
I0808 19:35:49.580240 20451 solver.cpp:337] Iteration 9100, Testing net (#0)
I0808 19:35:58.105510 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0808 19:35:58.105553 20451 solver.cpp:404]     Test net output #1: loss = 0.970722 (* 1 = 0.970722 loss)
I0808 19:36:00.311904 20451 solver.cpp:228] Iteration 9100, loss = 0.0938053
I0808 19:36:00.312083 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:36:00.312098 20451 solver.cpp:244]     Train net output #1: loss = 0.0938056 (* 1 = 0.0938056 loss)
I0808 19:36:00.312110 20451 sgd_solver.cpp:106] Iteration 9100, lr = 0.000615496
I0808 19:36:22.577956 20451 solver.cpp:228] Iteration 9110, loss = 0.156622
I0808 19:36:22.578014 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:36:22.578035 20451 solver.cpp:244]     Train net output #1: loss = 0.156623 (* 1 = 0.156623 loss)
I0808 19:36:22.578049 20451 sgd_solver.cpp:106] Iteration 9110, lr = 0.000615254
I0808 19:36:44.883555 20451 solver.cpp:228] Iteration 9120, loss = 0.093797
I0808 19:36:44.883733 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:36:44.883749 20451 solver.cpp:244]     Train net output #1: loss = 0.0937973 (* 1 = 0.0937973 loss)
I0808 19:36:44.883762 20451 sgd_solver.cpp:106] Iteration 9120, lr = 0.000615013
I0808 19:37:07.188848 20451 solver.cpp:228] Iteration 9130, loss = 0.343963
I0808 19:37:07.188890 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 19:37:07.188908 20451 solver.cpp:244]     Train net output #1: loss = 0.343963 (* 1 = 0.343963 loss)
I0808 19:37:07.188922 20451 sgd_solver.cpp:106] Iteration 9130, lr = 0.000614772
I0808 19:37:29.497792 20451 solver.cpp:228] Iteration 9140, loss = 0.312768
I0808 19:37:29.497978 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 19:37:29.497997 20451 solver.cpp:244]     Train net output #1: loss = 0.312768 (* 1 = 0.312768 loss)
I0808 19:37:29.498013 20451 sgd_solver.cpp:106] Iteration 9140, lr = 0.000614531
I0808 19:37:51.790650 20451 solver.cpp:228] Iteration 9150, loss = 0.125086
I0808 19:37:51.790704 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:37:51.790719 20451 solver.cpp:244]     Train net output #1: loss = 0.125086 (* 1 = 0.125086 loss)
I0808 19:37:51.790730 20451 sgd_solver.cpp:106] Iteration 9150, lr = 0.00061429
I0808 19:38:14.095252 20451 solver.cpp:228] Iteration 9160, loss = 0.12502
I0808 19:38:14.095369 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:38:14.095386 20451 solver.cpp:244]     Train net output #1: loss = 0.125021 (* 1 = 0.125021 loss)
I0808 19:38:14.095398 20451 sgd_solver.cpp:106] Iteration 9160, lr = 0.00061405
I0808 19:38:36.399008 20451 solver.cpp:228] Iteration 9170, loss = 0.312803
I0808 19:38:36.399058 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 19:38:36.399072 20451 solver.cpp:244]     Train net output #1: loss = 0.312804 (* 1 = 0.312804 loss)
I0808 19:38:36.399085 20451 sgd_solver.cpp:106] Iteration 9170, lr = 0.000613809
I0808 19:38:58.700814 20451 solver.cpp:228] Iteration 9180, loss = 0.125024
I0808 19:38:58.700913 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:38:58.700933 20451 solver.cpp:244]     Train net output #1: loss = 0.125024 (* 1 = 0.125024 loss)
I0808 19:38:58.700948 20451 sgd_solver.cpp:106] Iteration 9180, lr = 0.000613569
I0808 19:39:21.002182 20451 solver.cpp:228] Iteration 9190, loss = 0.250149
I0808 19:39:21.002228 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:39:21.002245 20451 solver.cpp:244]     Train net output #1: loss = 0.250149 (* 1 = 0.250149 loss)
I0808 19:39:21.002259 20451 sgd_solver.cpp:106] Iteration 9190, lr = 0.000613329
I0808 19:39:41.078871 20451 solver.cpp:337] Iteration 9200, Testing net (#0)
I0808 19:39:49.601876 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 19:39:49.601929 20451 solver.cpp:404]     Test net output #1: loss = 1.00808 (* 1 = 1.00808 loss)
I0808 19:39:51.805253 20451 solver.cpp:228] Iteration 9200, loss = 0.250093
I0808 19:39:51.805297 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:39:51.805312 20451 solver.cpp:244]     Train net output #1: loss = 0.250094 (* 1 = 0.250094 loss)
I0808 19:39:51.805325 20451 sgd_solver.cpp:106] Iteration 9200, lr = 0.00061309
I0808 19:40:14.079653 20451 solver.cpp:228] Iteration 9210, loss = 0.187641
I0808 19:40:14.079831 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:40:14.079846 20451 solver.cpp:244]     Train net output #1: loss = 0.187641 (* 1 = 0.187641 loss)
I0808 19:40:14.079859 20451 sgd_solver.cpp:106] Iteration 9210, lr = 0.00061285
I0808 19:40:36.359638 20451 solver.cpp:228] Iteration 9220, loss = 0.156371
I0808 19:40:36.359691 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:40:36.359705 20451 solver.cpp:244]     Train net output #1: loss = 0.156371 (* 1 = 0.156371 loss)
I0808 19:40:36.359717 20451 sgd_solver.cpp:106] Iteration 9220, lr = 0.000612611
I0808 19:40:58.650645 20451 solver.cpp:228] Iteration 9230, loss = 0.0312507
I0808 19:40:58.650895 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 19:40:58.650961 20451 solver.cpp:244]     Train net output #1: loss = 0.031251 (* 1 = 0.031251 loss)
I0808 19:40:58.650985 20451 sgd_solver.cpp:106] Iteration 9230, lr = 0.000612372
I0808 19:41:20.946085 20451 solver.cpp:228] Iteration 9240, loss = 0.218886
I0808 19:41:20.946137 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:41:20.946151 20451 solver.cpp:244]     Train net output #1: loss = 0.218886 (* 1 = 0.218886 loss)
I0808 19:41:20.946162 20451 sgd_solver.cpp:106] Iteration 9240, lr = 0.000612134
I0808 19:41:43.229704 20451 solver.cpp:228] Iteration 9250, loss = 0.0625336
I0808 19:41:43.229882 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 19:41:43.229898 20451 solver.cpp:244]     Train net output #1: loss = 0.0625339 (* 1 = 0.0625339 loss)
I0808 19:41:43.229912 20451 sgd_solver.cpp:106] Iteration 9250, lr = 0.000611895
I0808 19:42:05.522610 20451 solver.cpp:228] Iteration 9260, loss = 0.343926
I0808 19:42:05.522665 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 19:42:05.522680 20451 solver.cpp:244]     Train net output #1: loss = 0.343926 (* 1 = 0.343926 loss)
I0808 19:42:05.522691 20451 sgd_solver.cpp:106] Iteration 9260, lr = 0.000611657
I0808 19:42:27.815498 20451 solver.cpp:228] Iteration 9270, loss = 0.156373
I0808 19:42:27.815680 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 19:42:27.815695 20451 solver.cpp:244]     Train net output #1: loss = 0.156374 (* 1 = 0.156374 loss)
I0808 19:42:27.815706 20451 sgd_solver.cpp:106] Iteration 9270, lr = 0.000611419
I0808 19:42:50.107080 20451 solver.cpp:228] Iteration 9280, loss = 0.218821
I0808 19:42:50.107133 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:42:50.107147 20451 solver.cpp:244]     Train net output #1: loss = 0.218822 (* 1 = 0.218822 loss)
I0808 19:42:50.107159 20451 sgd_solver.cpp:106] Iteration 9280, lr = 0.000611181
I0808 19:43:12.408063 20451 solver.cpp:228] Iteration 9290, loss = 0.0938775
I0808 19:43:12.408241 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:43:12.408257 20451 solver.cpp:244]     Train net output #1: loss = 0.0938778 (* 1 = 0.0938778 loss)
I0808 19:43:12.408269 20451 sgd_solver.cpp:106] Iteration 9290, lr = 0.000610943
I0808 19:43:32.485106 20451 solver.cpp:337] Iteration 9300, Testing net (#0)
I0808 19:43:41.006103 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0808 19:43:41.006153 20451 solver.cpp:404]     Test net output #1: loss = 1.01263 (* 1 = 1.01263 loss)
I0808 19:43:43.207736 20451 solver.cpp:228] Iteration 9300, loss = 0.343809
I0808 19:43:43.207835 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 19:43:43.207850 20451 solver.cpp:244]     Train net output #1: loss = 0.343809 (* 1 = 0.343809 loss)
I0808 19:43:43.207862 20451 sgd_solver.cpp:106] Iteration 9300, lr = 0.000610706
I0808 19:44:05.490367 20451 solver.cpp:228] Iteration 9310, loss = 0.218972
I0808 19:44:05.490411 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:44:05.490427 20451 solver.cpp:244]     Train net output #1: loss = 0.218972 (* 1 = 0.218972 loss)
I0808 19:44:05.490438 20451 sgd_solver.cpp:106] Iteration 9310, lr = 0.000610469
I0808 19:44:27.785676 20451 solver.cpp:228] Iteration 9320, loss = 0.0937558
I0808 19:44:27.785854 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:44:27.785869 20451 solver.cpp:244]     Train net output #1: loss = 0.0937561 (* 1 = 0.0937561 loss)
I0808 19:44:27.785881 20451 sgd_solver.cpp:106] Iteration 9320, lr = 0.000610232
I0808 19:44:50.088852 20451 solver.cpp:228] Iteration 9330, loss = 0.187611
I0808 19:44:50.088906 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:44:50.088919 20451 solver.cpp:244]     Train net output #1: loss = 0.187611 (* 1 = 0.187611 loss)
I0808 19:44:50.088932 20451 sgd_solver.cpp:106] Iteration 9330, lr = 0.000609995
I0808 19:45:12.395202 20451 solver.cpp:228] Iteration 9340, loss = 0.15653
I0808 19:45:12.395416 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:45:12.395432 20451 solver.cpp:244]     Train net output #1: loss = 0.156531 (* 1 = 0.156531 loss)
I0808 19:45:12.395444 20451 sgd_solver.cpp:106] Iteration 9340, lr = 0.000609758
I0808 19:45:34.696887 20451 solver.cpp:228] Iteration 9350, loss = 0.125224
I0808 19:45:34.696933 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:45:34.696950 20451 solver.cpp:244]     Train net output #1: loss = 0.125224 (* 1 = 0.125224 loss)
I0808 19:45:34.696965 20451 sgd_solver.cpp:106] Iteration 9350, lr = 0.000609522
I0808 19:45:57.004861 20451 solver.cpp:228] Iteration 9360, loss = 0.21877
I0808 19:45:57.004967 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:45:57.004987 20451 solver.cpp:244]     Train net output #1: loss = 0.21877 (* 1 = 0.21877 loss)
I0808 19:45:57.005002 20451 sgd_solver.cpp:106] Iteration 9360, lr = 0.000609286
I0808 19:46:19.310124 20451 solver.cpp:228] Iteration 9370, loss = 0.125036
I0808 19:46:19.310178 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:46:19.310194 20451 solver.cpp:244]     Train net output #1: loss = 0.125036 (* 1 = 0.125036 loss)
I0808 19:46:19.310206 20451 sgd_solver.cpp:106] Iteration 9370, lr = 0.00060905
I0808 19:46:41.607095 20451 solver.cpp:228] Iteration 9380, loss = 0.187654
I0808 19:46:41.607286 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:46:41.607301 20451 solver.cpp:244]     Train net output #1: loss = 0.187654 (* 1 = 0.187654 loss)
I0808 19:46:41.607314 20451 sgd_solver.cpp:106] Iteration 9380, lr = 0.000608814
I0808 19:47:03.915932 20451 solver.cpp:228] Iteration 9390, loss = 0.187574
I0808 19:47:03.915974 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:47:03.916000 20451 solver.cpp:244]     Train net output #1: loss = 0.187574 (* 1 = 0.187574 loss)
I0808 19:47:03.916014 20451 sgd_solver.cpp:106] Iteration 9390, lr = 0.000608579
I0808 19:47:24.004514 20451 solver.cpp:337] Iteration 9400, Testing net (#0)
I0808 19:47:32.524194 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 19:47:32.524240 20451 solver.cpp:404]     Test net output #1: loss = 0.984775 (* 1 = 0.984775 loss)
I0808 19:47:34.728073 20451 solver.cpp:228] Iteration 9400, loss = 0.343949
I0808 19:47:34.728118 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 19:47:34.728137 20451 solver.cpp:244]     Train net output #1: loss = 0.343949 (* 1 = 0.343949 loss)
I0808 19:47:34.728152 20451 sgd_solver.cpp:106] Iteration 9400, lr = 0.000608343
I0808 19:47:57.016825 20451 solver.cpp:228] Iteration 9410, loss = 0.12508
I0808 19:47:57.016924 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:47:57.016944 20451 solver.cpp:244]     Train net output #1: loss = 0.12508 (* 1 = 0.12508 loss)
I0808 19:47:57.016959 20451 sgd_solver.cpp:106] Iteration 9410, lr = 0.000608108
I0808 19:48:19.323000 20451 solver.cpp:228] Iteration 9420, loss = 0.18761
I0808 19:48:19.323051 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:48:19.323065 20451 solver.cpp:244]     Train net output #1: loss = 0.18761 (* 1 = 0.18761 loss)
I0808 19:48:19.323076 20451 sgd_solver.cpp:106] Iteration 9420, lr = 0.000607873
I0808 19:48:41.626081 20451 solver.cpp:228] Iteration 9430, loss = 0.125065
I0808 19:48:41.626260 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:48:41.626274 20451 solver.cpp:244]     Train net output #1: loss = 0.125066 (* 1 = 0.125066 loss)
I0808 19:48:41.626287 20451 sgd_solver.cpp:106] Iteration 9430, lr = 0.000607639
I0808 19:49:03.936106 20451 solver.cpp:228] Iteration 9440, loss = 0.281321
I0808 19:49:03.936151 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 19:49:03.936168 20451 solver.cpp:244]     Train net output #1: loss = 0.281321 (* 1 = 0.281321 loss)
I0808 19:49:03.936182 20451 sgd_solver.cpp:106] Iteration 9440, lr = 0.000607404
I0808 19:49:26.236394 20451 solver.cpp:228] Iteration 9450, loss = 0.0938189
I0808 19:49:26.236613 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:49:26.236632 20451 solver.cpp:244]     Train net output #1: loss = 0.0938191 (* 1 = 0.0938191 loss)
I0808 19:49:26.236649 20451 sgd_solver.cpp:106] Iteration 9450, lr = 0.00060717
I0808 19:49:48.539144 20451 solver.cpp:228] Iteration 9460, loss = 0.250069
I0808 19:49:48.539186 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:49:48.539214 20451 solver.cpp:244]     Train net output #1: loss = 0.250069 (* 1 = 0.250069 loss)
I0808 19:49:48.539229 20451 sgd_solver.cpp:106] Iteration 9460, lr = 0.000606936
I0808 19:50:10.841987 20451 solver.cpp:228] Iteration 9470, loss = 0.156499
I0808 19:50:10.842144 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 19:50:10.842186 20451 solver.cpp:244]     Train net output #1: loss = 0.156499 (* 1 = 0.156499 loss)
I0808 19:50:10.842221 20451 sgd_solver.cpp:106] Iteration 9470, lr = 0.000606702
I0808 19:50:33.145359 20451 solver.cpp:228] Iteration 9480, loss = 0.0626037
I0808 19:50:33.145402 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 19:50:33.145419 20451 solver.cpp:244]     Train net output #1: loss = 0.062604 (* 1 = 0.062604 loss)
I0808 19:50:33.145436 20451 sgd_solver.cpp:106] Iteration 9480, lr = 0.000606469
I0808 19:50:55.448912 20451 solver.cpp:228] Iteration 9490, loss = 0.187582
I0808 19:50:55.449101 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:50:55.449116 20451 solver.cpp:244]     Train net output #1: loss = 0.187582 (* 1 = 0.187582 loss)
I0808 19:50:55.449128 20451 sgd_solver.cpp:106] Iteration 9490, lr = 0.000606235
I0808 19:51:15.524049 20451 solver.cpp:337] Iteration 9500, Testing net (#0)
I0808 19:51:24.044468 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 19:51:24.044522 20451 solver.cpp:404]     Test net output #1: loss = 1.00323 (* 1 = 1.00323 loss)
I0808 19:51:26.246459 20451 solver.cpp:228] Iteration 9500, loss = 0.218783
I0808 19:51:26.246639 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:51:26.246657 20451 solver.cpp:244]     Train net output #1: loss = 0.218783 (* 1 = 0.218783 loss)
I0808 19:51:26.246672 20451 sgd_solver.cpp:106] Iteration 9500, lr = 0.000606002
I0808 19:51:48.517788 20451 solver.cpp:228] Iteration 9510, loss = 0.0937574
I0808 19:51:48.517834 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:51:48.517853 20451 solver.cpp:244]     Train net output #1: loss = 0.0937576 (* 1 = 0.0937576 loss)
I0808 19:51:48.517866 20451 sgd_solver.cpp:106] Iteration 9510, lr = 0.000605769
I0808 19:52:10.811684 20451 solver.cpp:228] Iteration 9520, loss = 0.250077
I0808 19:52:10.811782 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:52:10.811801 20451 solver.cpp:244]     Train net output #1: loss = 0.250077 (* 1 = 0.250077 loss)
I0808 19:52:10.811816 20451 sgd_solver.cpp:106] Iteration 9520, lr = 0.000605536
I0808 19:52:33.119984 20451 solver.cpp:228] Iteration 9530, loss = 0.125087
I0808 19:52:33.120028 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:52:33.120045 20451 solver.cpp:244]     Train net output #1: loss = 0.125087 (* 1 = 0.125087 loss)
I0808 19:52:33.120070 20451 sgd_solver.cpp:106] Iteration 9530, lr = 0.000605304
I0808 19:52:55.419087 20451 solver.cpp:228] Iteration 9540, loss = 0.25032
I0808 19:52:55.419292 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:52:55.419311 20451 solver.cpp:244]     Train net output #1: loss = 0.25032 (* 1 = 0.25032 loss)
I0808 19:52:55.419325 20451 sgd_solver.cpp:106] Iteration 9540, lr = 0.000605071
I0808 19:53:17.724220 20451 solver.cpp:228] Iteration 9550, loss = 0.218808
I0808 19:53:17.724264 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:53:17.724282 20451 solver.cpp:244]     Train net output #1: loss = 0.218808 (* 1 = 0.218808 loss)
I0808 19:53:17.724295 20451 sgd_solver.cpp:106] Iteration 9550, lr = 0.000604839
I0808 19:53:40.026058 20451 solver.cpp:228] Iteration 9560, loss = 0.25026
I0808 19:53:40.026269 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:53:40.026285 20451 solver.cpp:244]     Train net output #1: loss = 0.25026 (* 1 = 0.25026 loss)
I0808 19:53:40.026298 20451 sgd_solver.cpp:106] Iteration 9560, lr = 0.000604607
I0808 19:54:02.335582 20451 solver.cpp:228] Iteration 9570, loss = 0.187603
I0808 19:54:02.335636 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:54:02.335650 20451 solver.cpp:244]     Train net output #1: loss = 0.187603 (* 1 = 0.187603 loss)
I0808 19:54:02.335664 20451 sgd_solver.cpp:106] Iteration 9570, lr = 0.000604376
I0808 19:54:24.638221 20451 solver.cpp:228] Iteration 9580, loss = 0.125055
I0808 19:54:24.638401 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:54:24.638417 20451 solver.cpp:244]     Train net output #1: loss = 0.125055 (* 1 = 0.125055 loss)
I0808 19:54:24.638429 20451 sgd_solver.cpp:106] Iteration 9580, lr = 0.000604144
I0808 19:54:46.944605 20451 solver.cpp:228] Iteration 9590, loss = 0.125058
I0808 19:54:46.944658 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:54:46.944672 20451 solver.cpp:244]     Train net output #1: loss = 0.125059 (* 1 = 0.125059 loss)
I0808 19:54:46.944684 20451 sgd_solver.cpp:106] Iteration 9590, lr = 0.000603913
I0808 19:55:07.024441 20451 solver.cpp:337] Iteration 9600, Testing net (#0)
I0808 19:55:15.538861 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 19:55:15.538915 20451 solver.cpp:404]     Test net output #1: loss = 0.975175 (* 1 = 0.975175 loss)
I0808 19:55:17.744155 20451 solver.cpp:228] Iteration 9600, loss = 0.125036
I0808 19:55:17.744209 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:55:17.744222 20451 solver.cpp:244]     Train net output #1: loss = 0.125036 (* 1 = 0.125036 loss)
I0808 19:55:17.744235 20451 sgd_solver.cpp:106] Iteration 9600, lr = 0.000603682
I0808 19:55:40.016144 20451 solver.cpp:228] Iteration 9610, loss = 0.250017
I0808 19:55:40.016245 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:55:40.016261 20451 solver.cpp:244]     Train net output #1: loss = 0.250017 (* 1 = 0.250017 loss)
I0808 19:55:40.016273 20451 sgd_solver.cpp:106] Iteration 9610, lr = 0.000603451
I0808 19:56:02.324156 20451 solver.cpp:228] Iteration 9620, loss = 0.219388
I0808 19:56:02.324208 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:56:02.324223 20451 solver.cpp:244]     Train net output #1: loss = 0.219388 (* 1 = 0.219388 loss)
I0808 19:56:02.324234 20451 sgd_solver.cpp:106] Iteration 9620, lr = 0.00060322
I0808 19:56:24.632844 20451 solver.cpp:228] Iteration 9630, loss = 0.281475
I0808 19:56:24.632953 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 19:56:24.632968 20451 solver.cpp:244]     Train net output #1: loss = 0.281475 (* 1 = 0.281475 loss)
I0808 19:56:24.632982 20451 sgd_solver.cpp:106] Iteration 9630, lr = 0.00060299
I0808 19:56:46.933722 20451 solver.cpp:228] Iteration 9640, loss = 0.250602
I0808 19:56:46.933774 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 19:56:46.933789 20451 solver.cpp:244]     Train net output #1: loss = 0.250602 (* 1 = 0.250602 loss)
I0808 19:56:46.933800 20451 sgd_solver.cpp:106] Iteration 9640, lr = 0.000602759
I0808 19:57:09.243237 20451 solver.cpp:228] Iteration 9650, loss = 0.0312919
I0808 19:57:09.243422 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 19:57:09.243437 20451 solver.cpp:244]     Train net output #1: loss = 0.0312922 (* 1 = 0.0312922 loss)
I0808 19:57:09.243449 20451 sgd_solver.cpp:106] Iteration 9650, lr = 0.000602529
I0808 19:57:31.540374 20451 solver.cpp:228] Iteration 9660, loss = 0.0626165
I0808 19:57:31.540426 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 19:57:31.540439 20451 solver.cpp:244]     Train net output #1: loss = 0.0626168 (* 1 = 0.0626168 loss)
I0808 19:57:31.540451 20451 sgd_solver.cpp:106] Iteration 9660, lr = 0.000602299
I0808 19:57:53.832098 20451 solver.cpp:228] Iteration 9670, loss = 0.187882
I0808 19:57:53.832309 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 19:57:53.832325 20451 solver.cpp:244]     Train net output #1: loss = 0.187882 (* 1 = 0.187882 loss)
I0808 19:57:53.832339 20451 sgd_solver.cpp:106] Iteration 9670, lr = 0.00060207
I0808 19:58:16.134321 20451 solver.cpp:228] Iteration 9680, loss = 0.218755
I0808 19:58:16.134374 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:58:16.134388 20451 solver.cpp:244]     Train net output #1: loss = 0.218756 (* 1 = 0.218756 loss)
I0808 19:58:16.134402 20451 sgd_solver.cpp:106] Iteration 9680, lr = 0.00060184
I0808 19:58:38.432147 20451 solver.cpp:228] Iteration 9690, loss = 0.219102
I0808 19:58:38.432327 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 19:58:38.432348 20451 solver.cpp:244]     Train net output #1: loss = 0.219102 (* 1 = 0.219102 loss)
I0808 19:58:38.432363 20451 sgd_solver.cpp:106] Iteration 9690, lr = 0.000601611
I0808 19:58:58.513717 20451 solver.cpp:337] Iteration 9700, Testing net (#0)
I0808 19:59:07.038514 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0808 19:59:07.038565 20451 solver.cpp:404]     Test net output #1: loss = 1.01745 (* 1 = 1.01745 loss)
I0808 19:59:09.242264 20451 solver.cpp:228] Iteration 9700, loss = 0.12505
I0808 19:59:09.242441 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 19:59:09.242456 20451 solver.cpp:244]     Train net output #1: loss = 0.12505 (* 1 = 0.12505 loss)
I0808 19:59:09.242468 20451 sgd_solver.cpp:106] Iteration 9700, lr = 0.000601382
I0808 19:59:31.509220 20451 solver.cpp:228] Iteration 9710, loss = 0.0938481
I0808 19:59:31.509274 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 19:59:31.509287 20451 solver.cpp:244]     Train net output #1: loss = 0.0938484 (* 1 = 0.0938484 loss)
I0808 19:59:31.509299 20451 sgd_solver.cpp:106] Iteration 9710, lr = 0.000601153
I0808 19:59:53.804883 20451 solver.cpp:228] Iteration 9720, loss = 0.250126
I0808 19:59:53.804983 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 19:59:53.804998 20451 solver.cpp:244]     Train net output #1: loss = 0.250126 (* 1 = 0.250126 loss)
I0808 19:59:53.805011 20451 sgd_solver.cpp:106] Iteration 9720, lr = 0.000600924
I0808 20:00:16.107297 20451 solver.cpp:228] Iteration 9730, loss = 0.250319
I0808 20:00:16.107352 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:00:16.107365 20451 solver.cpp:244]     Train net output #1: loss = 0.25032 (* 1 = 0.25032 loss)
I0808 20:00:16.107378 20451 sgd_solver.cpp:106] Iteration 9730, lr = 0.000600696
I0808 20:00:38.408759 20451 solver.cpp:228] Iteration 9740, loss = 0.156286
I0808 20:00:38.408936 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:00:38.408951 20451 solver.cpp:244]     Train net output #1: loss = 0.156286 (* 1 = 0.156286 loss)
I0808 20:00:38.408963 20451 sgd_solver.cpp:106] Iteration 9740, lr = 0.000600468
I0808 20:01:00.715981 20451 solver.cpp:228] Iteration 9750, loss = 0.218836
I0808 20:01:00.716032 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 20:01:00.716047 20451 solver.cpp:244]     Train net output #1: loss = 0.218836 (* 1 = 0.218836 loss)
I0808 20:01:00.716058 20451 sgd_solver.cpp:106] Iteration 9750, lr = 0.00060024
I0808 20:01:23.026903 20451 solver.cpp:228] Iteration 9760, loss = 0.12511
I0808 20:01:23.027119 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 20:01:23.027135 20451 solver.cpp:244]     Train net output #1: loss = 0.12511 (* 1 = 0.12511 loss)
I0808 20:01:23.027148 20451 sgd_solver.cpp:106] Iteration 9760, lr = 0.000600012
I0808 20:01:45.337272 20451 solver.cpp:228] Iteration 9770, loss = 0.1877
I0808 20:01:45.337324 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:01:45.337337 20451 solver.cpp:244]     Train net output #1: loss = 0.1877 (* 1 = 0.1877 loss)
I0808 20:01:45.337349 20451 sgd_solver.cpp:106] Iteration 9770, lr = 0.000599784
I0808 20:02:07.650902 20451 solver.cpp:228] Iteration 9780, loss = 0.0937879
I0808 20:02:07.651084 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 20:02:07.651099 20451 solver.cpp:244]     Train net output #1: loss = 0.0937882 (* 1 = 0.0937882 loss)
I0808 20:02:07.651111 20451 sgd_solver.cpp:106] Iteration 9780, lr = 0.000599557
I0808 20:02:29.962406 20451 solver.cpp:228] Iteration 9790, loss = 0.281498
I0808 20:02:29.962460 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 20:02:29.962474 20451 solver.cpp:244]     Train net output #1: loss = 0.281498 (* 1 = 0.281498 loss)
I0808 20:02:29.962486 20451 sgd_solver.cpp:106] Iteration 9790, lr = 0.00059933
I0808 20:02:50.042793 20451 solver.cpp:337] Iteration 9800, Testing net (#0)
I0808 20:02:58.572909 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 20:02:58.572952 20451 solver.cpp:404]     Test net output #1: loss = 1.00337 (* 1 = 1.00337 loss)
I0808 20:03:00.779819 20451 solver.cpp:228] Iteration 9800, loss = 0.156316
I0808 20:03:00.779867 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:03:00.779881 20451 solver.cpp:244]     Train net output #1: loss = 0.156317 (* 1 = 0.156317 loss)
I0808 20:03:00.779892 20451 sgd_solver.cpp:106] Iteration 9800, lr = 0.000599102
I0808 20:03:23.054245 20451 solver.cpp:228] Iteration 9810, loss = 0.125075
I0808 20:03:23.054422 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:03:23.054437 20451 solver.cpp:244]     Train net output #1: loss = 0.125075 (* 1 = 0.125075 loss)
I0808 20:03:23.054450 20451 sgd_solver.cpp:106] Iteration 9810, lr = 0.000598876
I0808 20:03:45.358543 20451 solver.cpp:228] Iteration 9820, loss = 0.187604
I0808 20:03:45.358595 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:03:45.358609 20451 solver.cpp:244]     Train net output #1: loss = 0.187605 (* 1 = 0.187605 loss)
I0808 20:03:45.358621 20451 sgd_solver.cpp:106] Iteration 9820, lr = 0.000598649
I0808 20:04:07.664142 20451 solver.cpp:228] Iteration 9830, loss = 0.218866
I0808 20:04:07.664250 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:04:07.664269 20451 solver.cpp:244]     Train net output #1: loss = 0.218866 (* 1 = 0.218866 loss)
I0808 20:04:07.664285 20451 sgd_solver.cpp:106] Iteration 9830, lr = 0.000598423
I0808 20:04:29.964352 20451 solver.cpp:228] Iteration 9840, loss = 0.125087
I0808 20:04:29.964396 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:04:29.964416 20451 solver.cpp:244]     Train net output #1: loss = 0.125087 (* 1 = 0.125087 loss)
I0808 20:04:29.964440 20451 sgd_solver.cpp:106] Iteration 9840, lr = 0.000598196
I0808 20:04:52.258708 20451 solver.cpp:228] Iteration 9850, loss = 0.250139
I0808 20:04:52.258810 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:04:52.258826 20451 solver.cpp:244]     Train net output #1: loss = 0.250139 (* 1 = 0.250139 loss)
I0808 20:04:52.258837 20451 sgd_solver.cpp:106] Iteration 9850, lr = 0.00059797
I0808 20:05:14.569866 20451 solver.cpp:228] Iteration 9860, loss = 0.250255
I0808 20:05:14.569917 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 20:05:14.569931 20451 solver.cpp:244]     Train net output #1: loss = 0.250256 (* 1 = 0.250256 loss)
I0808 20:05:14.569943 20451 sgd_solver.cpp:106] Iteration 9860, lr = 0.000597744
I0808 20:05:36.873219 20451 solver.cpp:228] Iteration 9870, loss = 0.218783
I0808 20:05:36.873432 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:05:36.873448 20451 solver.cpp:244]     Train net output #1: loss = 0.218783 (* 1 = 0.218783 loss)
I0808 20:05:36.873461 20451 sgd_solver.cpp:106] Iteration 9870, lr = 0.000597519
I0808 20:05:59.185734 20451 solver.cpp:228] Iteration 9880, loss = 0.187609
I0808 20:05:59.185788 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:05:59.185803 20451 solver.cpp:244]     Train net output #1: loss = 0.187609 (* 1 = 0.187609 loss)
I0808 20:05:59.185816 20451 sgd_solver.cpp:106] Iteration 9880, lr = 0.000597293
I0808 20:06:21.492297 20451 solver.cpp:228] Iteration 9890, loss = 0.031396
I0808 20:06:21.492465 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 20:06:21.492480 20451 solver.cpp:244]     Train net output #1: loss = 0.0313963 (* 1 = 0.0313963 loss)
I0808 20:06:21.492492 20451 sgd_solver.cpp:106] Iteration 9890, lr = 0.000597068
I0808 20:06:41.568958 20451 solver.cpp:337] Iteration 9900, Testing net (#0)
I0808 20:06:50.095099 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 20:06:50.095152 20451 solver.cpp:404]     Test net output #1: loss = 0.975209 (* 1 = 0.975209 loss)
I0808 20:06:52.295290 20451 solver.cpp:228] Iteration 9900, loss = 0.156363
I0808 20:06:52.295469 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:06:52.295486 20451 solver.cpp:244]     Train net output #1: loss = 0.156364 (* 1 = 0.156364 loss)
I0808 20:06:52.295501 20451 sgd_solver.cpp:106] Iteration 9900, lr = 0.000596843
I0808 20:07:14.582638 20451 solver.cpp:228] Iteration 9910, loss = 0.0937549
I0808 20:07:14.582690 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 20:07:14.582703 20451 solver.cpp:244]     Train net output #1: loss = 0.0937552 (* 1 = 0.0937552 loss)
I0808 20:07:14.582715 20451 sgd_solver.cpp:106] Iteration 9910, lr = 0.000596618
I0808 20:07:36.886381 20451 solver.cpp:228] Iteration 9920, loss = 0.125023
I0808 20:07:36.886567 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:07:36.886582 20451 solver.cpp:244]     Train net output #1: loss = 0.125023 (* 1 = 0.125023 loss)
I0808 20:07:36.886595 20451 sgd_solver.cpp:106] Iteration 9920, lr = 0.000596394
I0808 20:07:59.200685 20451 solver.cpp:228] Iteration 9930, loss = 0.125202
I0808 20:07:59.200737 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 20:07:59.200752 20451 solver.cpp:244]     Train net output #1: loss = 0.125202 (* 1 = 0.125202 loss)
I0808 20:07:59.200762 20451 sgd_solver.cpp:106] Iteration 9930, lr = 0.000596169
I0808 20:08:21.502082 20451 solver.cpp:228] Iteration 9940, loss = 0.218863
I0808 20:08:21.502194 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:08:21.502210 20451 solver.cpp:244]     Train net output #1: loss = 0.218863 (* 1 = 0.218863 loss)
I0808 20:08:21.502223 20451 sgd_solver.cpp:106] Iteration 9940, lr = 0.000595945
I0808 20:08:43.798028 20451 solver.cpp:228] Iteration 9950, loss = 0.125019
I0808 20:08:43.798075 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:08:43.798092 20451 solver.cpp:244]     Train net output #1: loss = 0.125019 (* 1 = 0.125019 loss)
I0808 20:08:43.798106 20451 sgd_solver.cpp:106] Iteration 9950, lr = 0.000595721
I0808 20:09:06.095494 20451 solver.cpp:228] Iteration 9960, loss = 0.156318
I0808 20:09:06.095677 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:09:06.095692 20451 solver.cpp:244]     Train net output #1: loss = 0.156318 (* 1 = 0.156318 loss)
I0808 20:09:06.095705 20451 sgd_solver.cpp:106] Iteration 9960, lr = 0.000595497
I0808 20:09:28.391827 20451 solver.cpp:228] Iteration 9970, loss = 0.187656
I0808 20:09:28.391885 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:09:28.391898 20451 solver.cpp:244]     Train net output #1: loss = 0.187656 (* 1 = 0.187656 loss)
I0808 20:09:28.391911 20451 sgd_solver.cpp:106] Iteration 9970, lr = 0.000595273
I0808 20:09:50.690832 20451 solver.cpp:228] Iteration 9980, loss = 0.187588
I0808 20:09:50.691051 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:09:50.691066 20451 solver.cpp:244]     Train net output #1: loss = 0.187588 (* 1 = 0.187588 loss)
I0808 20:09:50.691078 20451 sgd_solver.cpp:106] Iteration 9980, lr = 0.00059505
I0808 20:10:12.992933 20451 solver.cpp:228] Iteration 9990, loss = 0.281488
I0808 20:10:12.992979 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 20:10:12.992996 20451 solver.cpp:244]     Train net output #1: loss = 0.281488 (* 1 = 0.281488 loss)
I0808 20:10:12.993011 20451 sgd_solver.cpp:106] Iteration 9990, lr = 0.000594827
I0808 20:10:33.067868 20451 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_10000.caffemodel
I0808 20:10:33.552475 20451 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_10000.solverstate
I0808 20:10:33.554956 20451 solver.cpp:337] Iteration 10000, Testing net (#0)
I0808 20:10:42.050073 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 20:10:42.050127 20451 solver.cpp:404]     Test net output #1: loss = 0.99408 (* 1 = 0.99408 loss)
I0808 20:10:44.254923 20451 solver.cpp:228] Iteration 10000, loss = 0.0625298
I0808 20:10:44.254976 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 20:10:44.254989 20451 solver.cpp:244]     Train net output #1: loss = 0.0625301 (* 1 = 0.0625301 loss)
I0808 20:10:44.255002 20451 sgd_solver.cpp:106] Iteration 10000, lr = 0.000594604
I0808 20:11:06.555435 20451 solver.cpp:228] Iteration 10010, loss = 0.125192
I0808 20:11:06.555616 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 20:11:06.555631 20451 solver.cpp:244]     Train net output #1: loss = 0.125193 (* 1 = 0.125193 loss)
I0808 20:11:06.555644 20451 sgd_solver.cpp:106] Iteration 10010, lr = 0.000594381
I0808 20:11:28.864593 20451 solver.cpp:228] Iteration 10020, loss = 0.156486
I0808 20:11:28.864645 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 20:11:28.864660 20451 solver.cpp:244]     Train net output #1: loss = 0.156487 (* 1 = 0.156487 loss)
I0808 20:11:28.864671 20451 sgd_solver.cpp:106] Iteration 10020, lr = 0.000594158
I0808 20:11:51.151971 20451 solver.cpp:228] Iteration 10030, loss = 0.187557
I0808 20:11:51.152153 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:11:51.152169 20451 solver.cpp:244]     Train net output #1: loss = 0.187557 (* 1 = 0.187557 loss)
I0808 20:11:51.152181 20451 sgd_solver.cpp:106] Iteration 10030, lr = 0.000593936
I0808 20:12:13.458106 20451 solver.cpp:228] Iteration 10040, loss = 0.156286
I0808 20:12:13.458159 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:12:13.458173 20451 solver.cpp:244]     Train net output #1: loss = 0.156287 (* 1 = 0.156287 loss)
I0808 20:12:13.458184 20451 sgd_solver.cpp:106] Iteration 10040, lr = 0.000593713
I0808 20:12:35.760578 20451 solver.cpp:228] Iteration 10050, loss = 0.12507
I0808 20:12:35.760995 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:12:35.761010 20451 solver.cpp:244]     Train net output #1: loss = 0.125071 (* 1 = 0.125071 loss)
I0808 20:12:35.761023 20451 sgd_solver.cpp:106] Iteration 10050, lr = 0.000593491
I0808 20:12:58.062425 20451 solver.cpp:228] Iteration 10060, loss = 0.156387
I0808 20:12:58.062479 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:12:58.062492 20451 solver.cpp:244]     Train net output #1: loss = 0.156388 (* 1 = 0.156388 loss)
I0808 20:12:58.062505 20451 sgd_solver.cpp:106] Iteration 10060, lr = 0.000593269
I0808 20:13:20.369624 20451 solver.cpp:228] Iteration 10070, loss = 0.218892
I0808 20:13:20.369806 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:13:20.369822 20451 solver.cpp:244]     Train net output #1: loss = 0.218893 (* 1 = 0.218893 loss)
I0808 20:13:20.369834 20451 sgd_solver.cpp:106] Iteration 10070, lr = 0.000593048
I0808 20:13:42.673957 20451 solver.cpp:228] Iteration 10080, loss = 0.218897
I0808 20:13:42.674010 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:13:42.674023 20451 solver.cpp:244]     Train net output #1: loss = 0.218897 (* 1 = 0.218897 loss)
I0808 20:13:42.674034 20451 sgd_solver.cpp:106] Iteration 10080, lr = 0.000592826
I0808 20:14:04.985361 20451 solver.cpp:228] Iteration 10090, loss = 0.187842
I0808 20:14:04.985497 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 20:14:04.985513 20451 solver.cpp:244]     Train net output #1: loss = 0.187843 (* 1 = 0.187843 loss)
I0808 20:14:04.985527 20451 sgd_solver.cpp:106] Iteration 10090, lr = 0.000592605
I0808 20:14:25.067983 20451 solver.cpp:337] Iteration 10100, Testing net (#0)
I0808 20:14:33.591667 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 20:14:33.591724 20451 solver.cpp:404]     Test net output #1: loss = 1.00353 (* 1 = 1.00353 loss)
I0808 20:14:35.793932 20451 solver.cpp:228] Iteration 10100, loss = 0.125073
I0808 20:14:35.794111 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:14:35.794127 20451 solver.cpp:244]     Train net output #1: loss = 0.125073 (* 1 = 0.125073 loss)
I0808 20:14:35.794139 20451 sgd_solver.cpp:106] Iteration 10100, lr = 0.000592384
I0808 20:14:58.057823 20451 solver.cpp:228] Iteration 10110, loss = 0.156306
I0808 20:14:58.057865 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:14:58.057880 20451 solver.cpp:244]     Train net output #1: loss = 0.156307 (* 1 = 0.156307 loss)
I0808 20:14:58.057893 20451 sgd_solver.cpp:106] Iteration 10110, lr = 0.000592163
I0808 20:15:20.360255 20451 solver.cpp:228] Iteration 10120, loss = 0.312591
I0808 20:15:20.360429 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 20:15:20.360445 20451 solver.cpp:244]     Train net output #1: loss = 0.312591 (* 1 = 0.312591 loss)
I0808 20:15:20.360458 20451 sgd_solver.cpp:106] Iteration 10120, lr = 0.000591942
I0808 20:15:42.663811 20451 solver.cpp:228] Iteration 10130, loss = 0.218816
I0808 20:15:42.663863 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:15:42.663877 20451 solver.cpp:244]     Train net output #1: loss = 0.218817 (* 1 = 0.218817 loss)
I0808 20:15:42.663889 20451 sgd_solver.cpp:106] Iteration 10130, lr = 0.000591721
I0808 20:16:04.966298 20451 solver.cpp:228] Iteration 10140, loss = 0.187549
I0808 20:16:04.966408 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:16:04.966423 20451 solver.cpp:244]     Train net output #1: loss = 0.18755 (* 1 = 0.18755 loss)
I0808 20:16:04.966437 20451 sgd_solver.cpp:106] Iteration 10140, lr = 0.000591501
I0808 20:16:27.259685 20451 solver.cpp:228] Iteration 10150, loss = 0.15631
I0808 20:16:27.259735 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:16:27.259749 20451 solver.cpp:244]     Train net output #1: loss = 0.15631 (* 1 = 0.15631 loss)
I0808 20:16:27.259762 20451 sgd_solver.cpp:106] Iteration 10150, lr = 0.000591281
I0808 20:16:49.565377 20451 solver.cpp:228] Iteration 10160, loss = 0.0625322
I0808 20:16:49.565480 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 20:16:49.565495 20451 solver.cpp:244]     Train net output #1: loss = 0.0625325 (* 1 = 0.0625325 loss)
I0808 20:16:49.565506 20451 sgd_solver.cpp:106] Iteration 10160, lr = 0.000591061
I0808 20:17:11.878469 20451 solver.cpp:228] Iteration 10170, loss = 0.312654
I0808 20:17:11.878523 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 20:17:11.878537 20451 solver.cpp:244]     Train net output #1: loss = 0.312655 (* 1 = 0.312655 loss)
I0808 20:17:11.878550 20451 sgd_solver.cpp:106] Iteration 10170, lr = 0.000590841
I0808 20:17:34.175261 20451 solver.cpp:228] Iteration 10180, loss = 0.218916
I0808 20:17:34.175443 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:17:34.175459 20451 solver.cpp:244]     Train net output #1: loss = 0.218917 (* 1 = 0.218917 loss)
I0808 20:17:34.175472 20451 sgd_solver.cpp:106] Iteration 10180, lr = 0.000590621
I0808 20:17:56.487081 20451 solver.cpp:228] Iteration 10190, loss = 0.187528
I0808 20:17:56.487128 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:17:56.487145 20451 solver.cpp:244]     Train net output #1: loss = 0.187529 (* 1 = 0.187529 loss)
I0808 20:17:56.487159 20451 sgd_solver.cpp:106] Iteration 10190, lr = 0.000590402
I0808 20:18:16.567363 20451 solver.cpp:337] Iteration 10200, Testing net (#0)
I0808 20:18:25.092793 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0808 20:18:25.092844 20451 solver.cpp:404]     Test net output #1: loss = 0.966346 (* 1 = 0.966346 loss)
I0808 20:18:27.297544 20451 solver.cpp:228] Iteration 10200, loss = 0.15642
I0808 20:18:27.297595 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:18:27.297610 20451 solver.cpp:244]     Train net output #1: loss = 0.15642 (* 1 = 0.15642 loss)
I0808 20:18:27.297621 20451 sgd_solver.cpp:106] Iteration 10200, lr = 0.000590183
I0808 20:18:49.569612 20451 solver.cpp:228] Iteration 10210, loss = 0.250235
I0808 20:18:49.569794 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:18:49.569813 20451 solver.cpp:244]     Train net output #1: loss = 0.250235 (* 1 = 0.250235 loss)
I0808 20:18:49.569824 20451 sgd_solver.cpp:106] Iteration 10210, lr = 0.000589964
I0808 20:19:11.865223 20451 solver.cpp:228] Iteration 10220, loss = 0.156536
I0808 20:19:11.865277 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:19:11.865290 20451 solver.cpp:244]     Train net output #1: loss = 0.156536 (* 1 = 0.156536 loss)
I0808 20:19:11.865303 20451 sgd_solver.cpp:106] Iteration 10220, lr = 0.000589745
I0808 20:19:34.163857 20451 solver.cpp:228] Iteration 10230, loss = 0.125141
I0808 20:19:34.163962 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:19:34.163977 20451 solver.cpp:244]     Train net output #1: loss = 0.125142 (* 1 = 0.125142 loss)
I0808 20:19:34.163990 20451 sgd_solver.cpp:106] Iteration 10230, lr = 0.000589526
I0808 20:19:56.465173 20451 solver.cpp:228] Iteration 10240, loss = 0.219313
I0808 20:19:56.465227 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:19:56.465240 20451 solver.cpp:244]     Train net output #1: loss = 0.219314 (* 1 = 0.219314 loss)
I0808 20:19:56.465253 20451 sgd_solver.cpp:106] Iteration 10240, lr = 0.000589308
I0808 20:20:18.768458 20451 solver.cpp:228] Iteration 10250, loss = 0.156575
I0808 20:20:18.768631 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 20:20:18.768646 20451 solver.cpp:244]     Train net output #1: loss = 0.156575 (* 1 = 0.156575 loss)
I0808 20:20:18.768657 20451 sgd_solver.cpp:106] Iteration 10250, lr = 0.000589089
I0808 20:20:41.073066 20451 solver.cpp:228] Iteration 10260, loss = 0.156581
I0808 20:20:41.073122 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:20:41.073140 20451 solver.cpp:244]     Train net output #1: loss = 0.156582 (* 1 = 0.156582 loss)
I0808 20:20:41.073156 20451 sgd_solver.cpp:106] Iteration 10260, lr = 0.000588871
I0808 20:21:03.372673 20451 solver.cpp:228] Iteration 10270, loss = 0.250111
I0808 20:21:03.372862 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:21:03.372880 20451 solver.cpp:244]     Train net output #1: loss = 0.250112 (* 1 = 0.250112 loss)
I0808 20:21:03.372895 20451 sgd_solver.cpp:106] Iteration 10270, lr = 0.000588653
I0808 20:21:25.670884 20451 solver.cpp:228] Iteration 10280, loss = 0.250328
I0808 20:21:25.670935 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:21:25.670949 20451 solver.cpp:244]     Train net output #1: loss = 0.250328 (* 1 = 0.250328 loss)
I0808 20:21:25.670961 20451 sgd_solver.cpp:106] Iteration 10280, lr = 0.000588436
I0808 20:21:47.974604 20451 solver.cpp:228] Iteration 10290, loss = 0.218786
I0808 20:21:47.974799 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:21:47.974814 20451 solver.cpp:244]     Train net output #1: loss = 0.218787 (* 1 = 0.218787 loss)
I0808 20:21:47.974828 20451 sgd_solver.cpp:106] Iteration 10290, lr = 0.000588218
I0808 20:22:08.053617 20451 solver.cpp:337] Iteration 10300, Testing net (#0)
I0808 20:22:16.567940 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0808 20:22:16.567992 20451 solver.cpp:404]     Test net output #1: loss = 1.03166 (* 1 = 1.03166 loss)
I0808 20:22:18.771522 20451 solver.cpp:228] Iteration 10300, loss = 0.156341
I0808 20:22:18.771733 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:22:18.771747 20451 solver.cpp:244]     Train net output #1: loss = 0.156341 (* 1 = 0.156341 loss)
I0808 20:22:18.771760 20451 sgd_solver.cpp:106] Iteration 10300, lr = 0.000588001
I0808 20:22:41.050994 20451 solver.cpp:228] Iteration 10310, loss = 0.250142
I0808 20:22:41.051048 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:22:41.051061 20451 solver.cpp:244]     Train net output #1: loss = 0.250142 (* 1 = 0.250142 loss)
I0808 20:22:41.051074 20451 sgd_solver.cpp:106] Iteration 10310, lr = 0.000587784
I0808 20:23:03.346169 20451 solver.cpp:228] Iteration 10320, loss = 0.156353
I0808 20:23:03.346348 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:23:03.346361 20451 solver.cpp:244]     Train net output #1: loss = 0.156353 (* 1 = 0.156353 loss)
I0808 20:23:03.346374 20451 sgd_solver.cpp:106] Iteration 10320, lr = 0.000587567
I0808 20:23:25.651013 20451 solver.cpp:228] Iteration 10330, loss = 0.125075
I0808 20:23:25.651065 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:23:25.651079 20451 solver.cpp:244]     Train net output #1: loss = 0.125075 (* 1 = 0.125075 loss)
I0808 20:23:25.651092 20451 sgd_solver.cpp:106] Iteration 10330, lr = 0.00058735
I0808 20:23:47.953438 20451 solver.cpp:228] Iteration 10340, loss = 0.125041
I0808 20:23:47.953536 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:23:47.953555 20451 solver.cpp:244]     Train net output #1: loss = 0.125041 (* 1 = 0.125041 loss)
I0808 20:23:47.953567 20451 sgd_solver.cpp:106] Iteration 10340, lr = 0.000587133
I0808 20:24:10.257716 20451 solver.cpp:228] Iteration 10350, loss = 0.0937998
I0808 20:24:10.257769 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 20:24:10.257783 20451 solver.cpp:244]     Train net output #1: loss = 0.0938002 (* 1 = 0.0938002 loss)
I0808 20:24:10.257797 20451 sgd_solver.cpp:106] Iteration 10350, lr = 0.000586917
I0808 20:24:32.567414 20451 solver.cpp:228] Iteration 10360, loss = 0.125042
I0808 20:24:32.567598 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:24:32.567613 20451 solver.cpp:244]     Train net output #1: loss = 0.125042 (* 1 = 0.125042 loss)
I0808 20:24:32.567625 20451 sgd_solver.cpp:106] Iteration 10360, lr = 0.000586701
I0808 20:24:54.874724 20451 solver.cpp:228] Iteration 10370, loss = 0.250121
I0808 20:24:54.874776 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:24:54.874790 20451 solver.cpp:244]     Train net output #1: loss = 0.250122 (* 1 = 0.250122 loss)
I0808 20:24:54.874804 20451 sgd_solver.cpp:106] Iteration 10370, lr = 0.000586485
I0808 20:25:17.183358 20451 solver.cpp:228] Iteration 10380, loss = 0.156272
I0808 20:25:17.183532 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:25:17.183547 20451 solver.cpp:244]     Train net output #1: loss = 0.156272 (* 1 = 0.156272 loss)
I0808 20:25:17.183562 20451 sgd_solver.cpp:106] Iteration 10380, lr = 0.000586269
I0808 20:25:39.488749 20451 solver.cpp:228] Iteration 10390, loss = 0.187699
I0808 20:25:39.488801 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:25:39.488816 20451 solver.cpp:244]     Train net output #1: loss = 0.187699 (* 1 = 0.187699 loss)
I0808 20:25:39.488827 20451 sgd_solver.cpp:106] Iteration 10390, lr = 0.000586053
I0808 20:25:59.567549 20451 solver.cpp:337] Iteration 10400, Testing net (#0)
I0808 20:26:08.092510 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 20:26:08.092561 20451 solver.cpp:404]     Test net output #1: loss = 1.00339 (* 1 = 1.00339 loss)
I0808 20:26:10.294448 20451 solver.cpp:228] Iteration 10400, loss = 0.125043
I0808 20:26:10.294498 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:26:10.294512 20451 solver.cpp:244]     Train net output #1: loss = 0.125043 (* 1 = 0.125043 loss)
I0808 20:26:10.294524 20451 sgd_solver.cpp:106] Iteration 10400, lr = 0.000585838
I0808 20:26:32.580445 20451 solver.cpp:228] Iteration 10410, loss = 0.156278
I0808 20:26:32.580557 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:26:32.580577 20451 solver.cpp:244]     Train net output #1: loss = 0.156278 (* 1 = 0.156278 loss)
I0808 20:26:32.580592 20451 sgd_solver.cpp:106] Iteration 10410, lr = 0.000585623
I0808 20:26:54.898241 20451 solver.cpp:228] Iteration 10420, loss = 0.281322
I0808 20:26:54.898291 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 20:26:54.898305 20451 solver.cpp:244]     Train net output #1: loss = 0.281322 (* 1 = 0.281322 loss)
I0808 20:26:54.898318 20451 sgd_solver.cpp:106] Iteration 10420, lr = 0.000585407
I0808 20:27:17.211700 20451 solver.cpp:228] Iteration 10430, loss = 0.0625183
I0808 20:27:17.211884 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 20:27:17.211899 20451 solver.cpp:244]     Train net output #1: loss = 0.0625186 (* 1 = 0.0625186 loss)
I0808 20:27:17.211912 20451 sgd_solver.cpp:106] Iteration 10430, lr = 0.000585193
I0808 20:27:39.517941 20451 solver.cpp:228] Iteration 10440, loss = 0.125082
I0808 20:27:39.517993 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:27:39.518007 20451 solver.cpp:244]     Train net output #1: loss = 0.125082 (* 1 = 0.125082 loss)
I0808 20:27:39.518018 20451 sgd_solver.cpp:106] Iteration 10440, lr = 0.000584978
I0808 20:28:01.820780 20451 solver.cpp:228] Iteration 10450, loss = 0.0625243
I0808 20:28:01.820884 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 20:28:01.820904 20451 solver.cpp:244]     Train net output #1: loss = 0.0625246 (* 1 = 0.0625246 loss)
I0808 20:28:01.820919 20451 sgd_solver.cpp:106] Iteration 10450, lr = 0.000584763
I0808 20:28:24.116837 20451 solver.cpp:228] Iteration 10460, loss = 0.187657
I0808 20:28:24.116890 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:28:24.116904 20451 solver.cpp:244]     Train net output #1: loss = 0.187657 (* 1 = 0.187657 loss)
I0808 20:28:24.116916 20451 sgd_solver.cpp:106] Iteration 10460, lr = 0.000584549
I0808 20:28:46.419265 20451 solver.cpp:228] Iteration 10470, loss = 0.187568
I0808 20:28:46.419445 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:28:46.419459 20451 solver.cpp:244]     Train net output #1: loss = 0.187568 (* 1 = 0.187568 loss)
I0808 20:28:46.419471 20451 sgd_solver.cpp:106] Iteration 10470, lr = 0.000584335
I0808 20:29:08.730693 20451 solver.cpp:228] Iteration 10480, loss = 0.218869
I0808 20:29:08.730746 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:29:08.730761 20451 solver.cpp:244]     Train net output #1: loss = 0.21887 (* 1 = 0.21887 loss)
I0808 20:29:08.730772 20451 sgd_solver.cpp:106] Iteration 10480, lr = 0.000584121
I0808 20:29:31.036000 20451 solver.cpp:228] Iteration 10490, loss = 0.218834
I0808 20:29:31.036111 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:29:31.036126 20451 solver.cpp:244]     Train net output #1: loss = 0.218834 (* 1 = 0.218834 loss)
I0808 20:29:31.036139 20451 sgd_solver.cpp:106] Iteration 10490, lr = 0.000583907
I0808 20:29:51.107902 20451 solver.cpp:337] Iteration 10500, Testing net (#0)
I0808 20:29:59.627389 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 20:29:59.627439 20451 solver.cpp:404]     Test net output #1: loss = 0.984784 (* 1 = 0.984784 loss)
I0808 20:30:01.833788 20451 solver.cpp:228] Iteration 10500, loss = 0.187612
I0808 20:30:01.833887 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:30:01.833907 20451 solver.cpp:244]     Train net output #1: loss = 0.187613 (* 1 = 0.187613 loss)
I0808 20:30:01.833923 20451 sgd_solver.cpp:106] Iteration 10500, lr = 0.000583693
I0808 20:30:24.107432 20451 solver.cpp:228] Iteration 10510, loss = 0.125068
I0808 20:30:24.107478 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:30:24.107507 20451 solver.cpp:244]     Train net output #1: loss = 0.125069 (* 1 = 0.125069 loss)
I0808 20:30:24.107524 20451 sgd_solver.cpp:106] Iteration 10510, lr = 0.00058348
I0808 20:30:46.399972 20451 solver.cpp:228] Iteration 10520, loss = 0.281421
I0808 20:30:46.400195 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 20:30:46.400212 20451 solver.cpp:244]     Train net output #1: loss = 0.281422 (* 1 = 0.281422 loss)
I0808 20:30:46.400228 20451 sgd_solver.cpp:106] Iteration 10520, lr = 0.000583266
I0808 20:31:08.703256 20451 solver.cpp:228] Iteration 10530, loss = 0.40643
I0808 20:31:08.703310 20451 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0808 20:31:08.703325 20451 solver.cpp:244]     Train net output #1: loss = 0.40643 (* 1 = 0.40643 loss)
I0808 20:31:08.703337 20451 sgd_solver.cpp:106] Iteration 10530, lr = 0.000583053
I0808 20:31:31.004750 20451 solver.cpp:228] Iteration 10540, loss = 0.093855
I0808 20:31:31.004861 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 20:31:31.004878 20451 solver.cpp:244]     Train net output #1: loss = 0.0938553 (* 1 = 0.0938553 loss)
I0808 20:31:31.004890 20451 sgd_solver.cpp:106] Iteration 10540, lr = 0.00058284
I0808 20:31:53.311054 20451 solver.cpp:228] Iteration 10550, loss = 0.249985
I0808 20:31:53.311106 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:31:53.311120 20451 solver.cpp:244]     Train net output #1: loss = 0.249986 (* 1 = 0.249986 loss)
I0808 20:31:53.311133 20451 sgd_solver.cpp:106] Iteration 10550, lr = 0.000582628
I0808 20:32:15.607117 20451 solver.cpp:228] Iteration 10560, loss = 0.15631
I0808 20:32:15.607293 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:32:15.607312 20451 solver.cpp:244]     Train net output #1: loss = 0.15631 (* 1 = 0.15631 loss)
I0808 20:32:15.607328 20451 sgd_solver.cpp:106] Iteration 10560, lr = 0.000582415
I0808 20:32:37.918382 20451 solver.cpp:228] Iteration 10570, loss = 0.125051
I0808 20:32:37.918434 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:32:37.918449 20451 solver.cpp:244]     Train net output #1: loss = 0.125051 (* 1 = 0.125051 loss)
I0808 20:32:37.918462 20451 sgd_solver.cpp:106] Iteration 10570, lr = 0.000582203
I0808 20:33:00.231493 20451 solver.cpp:228] Iteration 10580, loss = 0.0938289
I0808 20:33:00.231674 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 20:33:00.231689 20451 solver.cpp:244]     Train net output #1: loss = 0.0938292 (* 1 = 0.0938292 loss)
I0808 20:33:00.231703 20451 sgd_solver.cpp:106] Iteration 10580, lr = 0.000581991
I0808 20:33:22.527701 20451 solver.cpp:228] Iteration 10590, loss = 0.281359
I0808 20:33:22.527753 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 20:33:22.527767 20451 solver.cpp:244]     Train net output #1: loss = 0.281359 (* 1 = 0.281359 loss)
I0808 20:33:22.527781 20451 sgd_solver.cpp:106] Iteration 10590, lr = 0.000581779
I0808 20:33:42.598680 20451 solver.cpp:337] Iteration 10600, Testing net (#0)
I0808 20:33:51.119702 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 20:33:51.119753 20451 solver.cpp:404]     Test net output #1: loss = 0.999077 (* 1 = 0.999077 loss)
I0808 20:33:53.323719 20451 solver.cpp:228] Iteration 10600, loss = 0.250235
I0808 20:33:53.323768 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:33:53.323783 20451 solver.cpp:244]     Train net output #1: loss = 0.250235 (* 1 = 0.250235 loss)
I0808 20:33:53.323796 20451 sgd_solver.cpp:106] Iteration 10600, lr = 0.000581567
I0808 20:34:15.599278 20451 solver.cpp:228] Iteration 10610, loss = 0.343892
I0808 20:34:15.599452 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 20:34:15.599467 20451 solver.cpp:244]     Train net output #1: loss = 0.343893 (* 1 = 0.343893 loss)
I0808 20:34:15.599480 20451 sgd_solver.cpp:106] Iteration 10610, lr = 0.000581355
I0808 20:34:37.900424 20451 solver.cpp:228] Iteration 10620, loss = 0.2189
I0808 20:34:37.900476 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:34:37.900490 20451 solver.cpp:244]     Train net output #1: loss = 0.218901 (* 1 = 0.218901 loss)
I0808 20:34:37.900502 20451 sgd_solver.cpp:106] Iteration 10620, lr = 0.000581144
I0808 20:35:00.207027 20451 solver.cpp:228] Iteration 10630, loss = 0.187645
I0808 20:35:00.207238 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:35:00.207253 20451 solver.cpp:244]     Train net output #1: loss = 0.187645 (* 1 = 0.187645 loss)
I0808 20:35:00.207267 20451 sgd_solver.cpp:106] Iteration 10630, lr = 0.000580932
I0808 20:35:22.500268 20451 solver.cpp:228] Iteration 10640, loss = 0.25011
I0808 20:35:22.500322 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:35:22.500336 20451 solver.cpp:244]     Train net output #1: loss = 0.25011 (* 1 = 0.25011 loss)
I0808 20:35:22.500349 20451 sgd_solver.cpp:106] Iteration 10640, lr = 0.000580721
I0808 20:35:44.797941 20451 solver.cpp:228] Iteration 10650, loss = 0.156323
I0808 20:35:44.798116 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:35:44.798131 20451 solver.cpp:244]     Train net output #1: loss = 0.156323 (* 1 = 0.156323 loss)
I0808 20:35:44.798144 20451 sgd_solver.cpp:106] Iteration 10650, lr = 0.00058051
I0808 20:36:07.102193 20451 solver.cpp:228] Iteration 10660, loss = 0.250271
I0808 20:36:07.102248 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:36:07.102262 20451 solver.cpp:244]     Train net output #1: loss = 0.250272 (* 1 = 0.250272 loss)
I0808 20:36:07.102274 20451 sgd_solver.cpp:106] Iteration 10660, lr = 0.0005803
I0808 20:36:29.398144 20451 solver.cpp:228] Iteration 10670, loss = 0.156422
I0808 20:36:29.398314 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:36:29.398329 20451 solver.cpp:244]     Train net output #1: loss = 0.156423 (* 1 = 0.156423 loss)
I0808 20:36:29.398342 20451 sgd_solver.cpp:106] Iteration 10670, lr = 0.000580089
I0808 20:36:51.685755 20451 solver.cpp:228] Iteration 10680, loss = 0.156415
I0808 20:36:51.685808 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:36:51.685822 20451 solver.cpp:244]     Train net output #1: loss = 0.156415 (* 1 = 0.156415 loss)
I0808 20:36:51.685835 20451 sgd_solver.cpp:106] Iteration 10680, lr = 0.000579879
I0808 20:37:13.983927 20451 solver.cpp:228] Iteration 10690, loss = 0.250062
I0808 20:37:13.984021 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 20:37:13.984037 20451 solver.cpp:244]     Train net output #1: loss = 0.250062 (* 1 = 0.250062 loss)
I0808 20:37:13.984050 20451 sgd_solver.cpp:106] Iteration 10690, lr = 0.000579668
I0808 20:37:34.055531 20451 solver.cpp:337] Iteration 10700, Testing net (#0)
I0808 20:37:42.574518 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 20:37:42.574566 20451 solver.cpp:404]     Test net output #1: loss = 0.999483 (* 1 = 0.999483 loss)
I0808 20:37:44.779194 20451 solver.cpp:228] Iteration 10700, loss = 0.15649
I0808 20:37:44.779310 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:37:44.779330 20451 solver.cpp:244]     Train net output #1: loss = 0.15649 (* 1 = 0.15649 loss)
I0808 20:37:44.779345 20451 sgd_solver.cpp:106] Iteration 10700, lr = 0.000579458
I0808 20:38:07.050938 20451 solver.cpp:228] Iteration 10710, loss = 0.187584
I0808 20:38:07.050982 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:38:07.051000 20451 solver.cpp:244]     Train net output #1: loss = 0.187585 (* 1 = 0.187585 loss)
I0808 20:38:07.051017 20451 sgd_solver.cpp:106] Iteration 10710, lr = 0.000579249
I0808 20:38:29.348440 20451 solver.cpp:228] Iteration 10720, loss = 0.0625626
I0808 20:38:29.348654 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 20:38:29.348670 20451 solver.cpp:244]     Train net output #1: loss = 0.0625629 (* 1 = 0.0625629 loss)
I0808 20:38:29.348683 20451 sgd_solver.cpp:106] Iteration 10720, lr = 0.000579039
I0808 20:38:51.650632 20451 solver.cpp:228] Iteration 10730, loss = 0.187709
I0808 20:38:51.650684 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:38:51.650699 20451 solver.cpp:244]     Train net output #1: loss = 0.18771 (* 1 = 0.18771 loss)
I0808 20:38:51.650712 20451 sgd_solver.cpp:106] Iteration 10730, lr = 0.000578829
I0808 20:39:13.951706 20451 solver.cpp:228] Iteration 10740, loss = 0.18793
I0808 20:39:13.951885 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:39:13.951901 20451 solver.cpp:244]     Train net output #1: loss = 0.187931 (* 1 = 0.187931 loss)
I0808 20:39:13.951915 20451 sgd_solver.cpp:106] Iteration 10740, lr = 0.00057862
I0808 20:39:36.242686 20451 solver.cpp:228] Iteration 10750, loss = 0.250115
I0808 20:39:36.242728 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:39:36.242743 20451 solver.cpp:244]     Train net output #1: loss = 0.250116 (* 1 = 0.250116 loss)
I0808 20:39:36.242756 20451 sgd_solver.cpp:106] Iteration 10750, lr = 0.000578411
I0808 20:39:58.536979 20451 solver.cpp:228] Iteration 10760, loss = 0.21912
I0808 20:39:58.537147 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:39:58.537161 20451 solver.cpp:244]     Train net output #1: loss = 0.219121 (* 1 = 0.219121 loss)
I0808 20:39:58.537173 20451 sgd_solver.cpp:106] Iteration 10760, lr = 0.000578202
I0808 20:40:20.841274 20451 solver.cpp:228] Iteration 10770, loss = 0.187709
I0808 20:40:20.841331 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:40:20.841346 20451 solver.cpp:244]     Train net output #1: loss = 0.187709 (* 1 = 0.187709 loss)
I0808 20:40:20.841359 20451 sgd_solver.cpp:106] Iteration 10770, lr = 0.000577993
I0808 20:40:43.142832 20451 solver.cpp:228] Iteration 10780, loss = 0.219141
I0808 20:40:43.143009 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:40:43.143024 20451 solver.cpp:244]     Train net output #1: loss = 0.219141 (* 1 = 0.219141 loss)
I0808 20:40:43.143038 20451 sgd_solver.cpp:106] Iteration 10780, lr = 0.000577784
I0808 20:41:05.455329 20451 solver.cpp:228] Iteration 10790, loss = 0.218887
I0808 20:41:05.455381 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:41:05.455395 20451 solver.cpp:244]     Train net output #1: loss = 0.218887 (* 1 = 0.218887 loss)
I0808 20:41:05.455407 20451 sgd_solver.cpp:106] Iteration 10790, lr = 0.000577576
I0808 20:41:25.522390 20451 solver.cpp:337] Iteration 10800, Testing net (#0)
I0808 20:41:34.047798 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 20:41:34.047850 20451 solver.cpp:404]     Test net output #1: loss = 1.00935 (* 1 = 1.00935 loss)
I0808 20:41:36.253195 20451 solver.cpp:228] Iteration 10800, loss = 0.344529
I0808 20:41:36.253245 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 20:41:36.253260 20451 solver.cpp:244]     Train net output #1: loss = 0.34453 (* 1 = 0.34453 loss)
I0808 20:41:36.253271 20451 sgd_solver.cpp:106] Iteration 10800, lr = 0.000577368
I0808 20:41:58.532858 20451 solver.cpp:228] Iteration 10810, loss = 0.250027
I0808 20:41:58.533035 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:41:58.533049 20451 solver.cpp:244]     Train net output #1: loss = 0.250028 (* 1 = 0.250028 loss)
I0808 20:41:58.533062 20451 sgd_solver.cpp:106] Iteration 10810, lr = 0.00057716
I0808 20:42:20.842726 20451 solver.cpp:228] Iteration 10820, loss = 0.219069
I0808 20:42:20.842777 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:42:20.842792 20451 solver.cpp:244]     Train net output #1: loss = 0.219069 (* 1 = 0.219069 loss)
I0808 20:42:20.842803 20451 sgd_solver.cpp:106] Iteration 10820, lr = 0.000576952
I0808 20:42:43.141599 20451 solver.cpp:228] Iteration 10830, loss = 0.343883
I0808 20:42:43.141805 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 20:42:43.141821 20451 solver.cpp:244]     Train net output #1: loss = 0.343883 (* 1 = 0.343883 loss)
I0808 20:42:43.141832 20451 sgd_solver.cpp:106] Iteration 10830, lr = 0.000576744
I0808 20:43:05.447798 20451 solver.cpp:228] Iteration 10840, loss = 0.218944
I0808 20:43:05.447852 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:43:05.447867 20451 solver.cpp:244]     Train net output #1: loss = 0.218944 (* 1 = 0.218944 loss)
I0808 20:43:05.447880 20451 sgd_solver.cpp:106] Iteration 10840, lr = 0.000576536
I0808 20:43:27.746867 20451 solver.cpp:228] Iteration 10850, loss = 0.218815
I0808 20:43:27.747045 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:43:27.747059 20451 solver.cpp:244]     Train net output #1: loss = 0.218816 (* 1 = 0.218816 loss)
I0808 20:43:27.747071 20451 sgd_solver.cpp:106] Iteration 10850, lr = 0.000576329
I0808 20:43:50.049528 20451 solver.cpp:228] Iteration 10860, loss = 0.0938058
I0808 20:43:50.049582 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 20:43:50.049597 20451 solver.cpp:244]     Train net output #1: loss = 0.093806 (* 1 = 0.093806 loss)
I0808 20:43:50.049609 20451 sgd_solver.cpp:106] Iteration 10860, lr = 0.000576122
I0808 20:44:12.355203 20451 solver.cpp:228] Iteration 10870, loss = 0.250118
I0808 20:44:12.355396 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:44:12.355412 20451 solver.cpp:244]     Train net output #1: loss = 0.250119 (* 1 = 0.250119 loss)
I0808 20:44:12.355423 20451 sgd_solver.cpp:106] Iteration 10870, lr = 0.000575915
I0808 20:44:34.656533 20451 solver.cpp:228] Iteration 10880, loss = 0.12521
I0808 20:44:34.656584 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 20:44:34.656599 20451 solver.cpp:244]     Train net output #1: loss = 0.12521 (* 1 = 0.12521 loss)
I0808 20:44:34.656610 20451 sgd_solver.cpp:106] Iteration 10880, lr = 0.000575708
I0808 20:44:56.959625 20451 solver.cpp:228] Iteration 10890, loss = 0.125086
I0808 20:44:56.959720 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:44:56.959735 20451 solver.cpp:244]     Train net output #1: loss = 0.125086 (* 1 = 0.125086 loss)
I0808 20:44:56.959748 20451 sgd_solver.cpp:106] Iteration 10890, lr = 0.000575501
I0808 20:45:17.042337 20451 solver.cpp:337] Iteration 10900, Testing net (#0)
I0808 20:45:25.563719 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 20:45:25.563771 20451 solver.cpp:404]     Test net output #1: loss = 1.00341 (* 1 = 1.00341 loss)
I0808 20:45:27.767413 20451 solver.cpp:228] Iteration 10900, loss = 0.312646
I0808 20:45:27.767580 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 20:45:27.767594 20451 solver.cpp:244]     Train net output #1: loss = 0.312646 (* 1 = 0.312646 loss)
I0808 20:45:27.767607 20451 sgd_solver.cpp:106] Iteration 10900, lr = 0.000575295
I0808 20:45:50.053522 20451 solver.cpp:228] Iteration 10910, loss = 0.125062
I0808 20:45:50.053576 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:45:50.053589 20451 solver.cpp:244]     Train net output #1: loss = 0.125063 (* 1 = 0.125063 loss)
I0808 20:45:50.053601 20451 sgd_solver.cpp:106] Iteration 10910, lr = 0.000575088
I0808 20:46:12.354372 20451 solver.cpp:228] Iteration 10920, loss = 0.0938185
I0808 20:46:12.354487 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 20:46:12.354506 20451 solver.cpp:244]     Train net output #1: loss = 0.0938187 (* 1 = 0.0938187 loss)
I0808 20:46:12.354522 20451 sgd_solver.cpp:106] Iteration 10920, lr = 0.000574882
I0808 20:46:34.666669 20451 solver.cpp:228] Iteration 10930, loss = 0.15635
I0808 20:46:34.666713 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:46:34.666731 20451 solver.cpp:244]     Train net output #1: loss = 0.15635 (* 1 = 0.15635 loss)
I0808 20:46:34.666746 20451 sgd_solver.cpp:106] Iteration 10930, lr = 0.000574676
I0808 20:46:56.970552 20451 solver.cpp:228] Iteration 10940, loss = 0.281719
I0808 20:46:56.970763 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 20:46:56.970780 20451 solver.cpp:244]     Train net output #1: loss = 0.28172 (* 1 = 0.28172 loss)
I0808 20:46:56.970793 20451 sgd_solver.cpp:106] Iteration 10940, lr = 0.00057447
I0808 20:47:19.277503 20451 solver.cpp:228] Iteration 10950, loss = 0.219141
I0808 20:47:19.277555 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:47:19.277568 20451 solver.cpp:244]     Train net output #1: loss = 0.219141 (* 1 = 0.219141 loss)
I0808 20:47:19.277580 20451 sgd_solver.cpp:106] Iteration 10950, lr = 0.000574265
I0808 20:47:41.577338 20451 solver.cpp:228] Iteration 10960, loss = 0.218797
I0808 20:47:41.577527 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:47:41.577540 20451 solver.cpp:244]     Train net output #1: loss = 0.218797 (* 1 = 0.218797 loss)
I0808 20:47:41.577553 20451 sgd_solver.cpp:106] Iteration 10960, lr = 0.000574059
I0808 20:48:03.873791 20451 solver.cpp:228] Iteration 10970, loss = 0.125055
I0808 20:48:03.873844 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:48:03.873858 20451 solver.cpp:244]     Train net output #1: loss = 0.125055 (* 1 = 0.125055 loss)
I0808 20:48:03.873872 20451 sgd_solver.cpp:106] Iteration 10970, lr = 0.000573854
I0808 20:48:26.173743 20451 solver.cpp:228] Iteration 10980, loss = 0.125044
I0808 20:48:26.173928 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:48:26.173943 20451 solver.cpp:244]     Train net output #1: loss = 0.125044 (* 1 = 0.125044 loss)
I0808 20:48:26.173955 20451 sgd_solver.cpp:106] Iteration 10980, lr = 0.000573649
I0808 20:48:48.485731 20451 solver.cpp:228] Iteration 10990, loss = 0.187614
I0808 20:48:48.485785 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:48:48.485798 20451 solver.cpp:244]     Train net output #1: loss = 0.187614 (* 1 = 0.187614 loss)
I0808 20:48:48.485810 20451 sgd_solver.cpp:106] Iteration 10990, lr = 0.000573444
I0808 20:49:08.572448 20451 solver.cpp:337] Iteration 11000, Testing net (#0)
I0808 20:49:17.095911 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0808 20:49:17.095963 20451 solver.cpp:404]     Test net output #1: loss = 0.96117 (* 1 = 0.96117 loss)
I0808 20:49:19.299412 20451 solver.cpp:228] Iteration 11000, loss = 0.125043
I0808 20:49:19.299463 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:49:19.299475 20451 solver.cpp:244]     Train net output #1: loss = 0.125043 (* 1 = 0.125043 loss)
I0808 20:49:19.299487 20451 sgd_solver.cpp:106] Iteration 11000, lr = 0.000573239
I0808 20:49:41.579519 20451 solver.cpp:228] Iteration 11010, loss = 0.0312739
I0808 20:49:41.579700 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 20:49:41.579718 20451 solver.cpp:244]     Train net output #1: loss = 0.0312742 (* 1 = 0.0312742 loss)
I0808 20:49:41.579733 20451 sgd_solver.cpp:106] Iteration 11010, lr = 0.000573034
I0808 20:50:03.888790 20451 solver.cpp:228] Iteration 11020, loss = 0.344274
I0808 20:50:03.888844 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 20:50:03.888859 20451 solver.cpp:244]     Train net output #1: loss = 0.344274 (* 1 = 0.344274 loss)
I0808 20:50:03.888870 20451 sgd_solver.cpp:106] Iteration 11020, lr = 0.00057283
I0808 20:50:26.201575 20451 solver.cpp:228] Iteration 11030, loss = 0.156379
I0808 20:50:26.201766 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:50:26.201786 20451 solver.cpp:244]     Train net output #1: loss = 0.15638 (* 1 = 0.15638 loss)
I0808 20:50:26.201800 20451 sgd_solver.cpp:106] Iteration 11030, lr = 0.000572625
I0808 20:50:48.519558 20451 solver.cpp:228] Iteration 11040, loss = 0.12526
I0808 20:50:48.519604 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:50:48.519623 20451 solver.cpp:244]     Train net output #1: loss = 0.125261 (* 1 = 0.125261 loss)
I0808 20:50:48.519639 20451 sgd_solver.cpp:106] Iteration 11040, lr = 0.000572421
I0808 20:51:10.835602 20451 solver.cpp:228] Iteration 11050, loss = 0.2815
I0808 20:51:10.835813 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 20:51:10.835830 20451 solver.cpp:244]     Train net output #1: loss = 0.281501 (* 1 = 0.281501 loss)
I0808 20:51:10.835844 20451 sgd_solver.cpp:106] Iteration 11050, lr = 0.000572217
I0808 20:51:33.138721 20451 solver.cpp:228] Iteration 11060, loss = 0.219253
I0808 20:51:33.138772 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:51:33.138787 20451 solver.cpp:244]     Train net output #1: loss = 0.219253 (* 1 = 0.219253 loss)
I0808 20:51:33.138799 20451 sgd_solver.cpp:106] Iteration 11060, lr = 0.000572013
I0808 20:51:55.429850 20451 solver.cpp:228] Iteration 11070, loss = 0.250255
I0808 20:51:55.430033 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 20:51:55.430049 20451 solver.cpp:244]     Train net output #1: loss = 0.250256 (* 1 = 0.250256 loss)
I0808 20:51:55.430063 20451 sgd_solver.cpp:106] Iteration 11070, lr = 0.00057181
I0808 20:52:17.732020 20451 solver.cpp:228] Iteration 11080, loss = 0.219235
I0808 20:52:17.732062 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 20:52:17.732079 20451 solver.cpp:244]     Train net output #1: loss = 0.219236 (* 1 = 0.219236 loss)
I0808 20:52:17.732094 20451 sgd_solver.cpp:106] Iteration 11080, lr = 0.000571606
I0808 20:52:40.040272 20451 solver.cpp:228] Iteration 11090, loss = 0.18781
I0808 20:52:40.040455 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:52:40.040474 20451 solver.cpp:244]     Train net output #1: loss = 0.18781 (* 1 = 0.18781 loss)
I0808 20:52:40.040490 20451 sgd_solver.cpp:106] Iteration 11090, lr = 0.000571403
I0808 20:53:00.126992 20451 solver.cpp:337] Iteration 11100, Testing net (#0)
I0808 20:53:08.653004 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 20:53:08.653055 20451 solver.cpp:404]     Test net output #1: loss = 0.994023 (* 1 = 0.994023 loss)
I0808 20:53:10.856077 20451 solver.cpp:228] Iteration 11100, loss = 0.12505
I0808 20:53:10.856263 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:53:10.856281 20451 solver.cpp:244]     Train net output #1: loss = 0.12505 (* 1 = 0.12505 loss)
I0808 20:53:10.856293 20451 sgd_solver.cpp:106] Iteration 11100, lr = 0.0005712
I0808 20:53:33.137627 20451 solver.cpp:228] Iteration 11110, loss = 0.156333
I0808 20:53:33.137676 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:53:33.137691 20451 solver.cpp:244]     Train net output #1: loss = 0.156333 (* 1 = 0.156333 loss)
I0808 20:53:33.137702 20451 sgd_solver.cpp:106] Iteration 11110, lr = 0.000570997
I0808 20:53:55.438961 20451 solver.cpp:228] Iteration 11120, loss = 0.187965
I0808 20:53:55.439134 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:53:55.439149 20451 solver.cpp:244]     Train net output #1: loss = 0.187966 (* 1 = 0.187966 loss)
I0808 20:53:55.439162 20451 sgd_solver.cpp:106] Iteration 11120, lr = 0.000570794
I0808 20:54:17.745193 20451 solver.cpp:228] Iteration 11130, loss = 0.156384
I0808 20:54:17.745246 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:54:17.745260 20451 solver.cpp:244]     Train net output #1: loss = 0.156384 (* 1 = 0.156384 loss)
I0808 20:54:17.745272 20451 sgd_solver.cpp:106] Iteration 11130, lr = 0.000570592
I0808 20:54:40.037271 20451 solver.cpp:228] Iteration 11140, loss = 0.125269
I0808 20:54:40.037454 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:54:40.037473 20451 solver.cpp:244]     Train net output #1: loss = 0.12527 (* 1 = 0.12527 loss)
I0808 20:54:40.037490 20451 sgd_solver.cpp:106] Iteration 11140, lr = 0.000570389
I0808 20:55:02.349439 20451 solver.cpp:228] Iteration 11150, loss = 0.28163
I0808 20:55:02.349488 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 20:55:02.349506 20451 solver.cpp:244]     Train net output #1: loss = 0.28163 (* 1 = 0.28163 loss)
I0808 20:55:02.349521 20451 sgd_solver.cpp:106] Iteration 11150, lr = 0.000570187
I0808 20:55:24.664645 20451 solver.cpp:228] Iteration 11160, loss = 0.125212
I0808 20:55:24.664865 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 20:55:24.664880 20451 solver.cpp:244]     Train net output #1: loss = 0.125213 (* 1 = 0.125213 loss)
I0808 20:55:24.664893 20451 sgd_solver.cpp:106] Iteration 11160, lr = 0.000569985
I0808 20:55:46.967072 20451 solver.cpp:228] Iteration 11170, loss = 0.0937812
I0808 20:55:46.967123 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 20:55:46.967138 20451 solver.cpp:244]     Train net output #1: loss = 0.0937815 (* 1 = 0.0937815 loss)
I0808 20:55:46.967149 20451 sgd_solver.cpp:106] Iteration 11170, lr = 0.000569783
I0808 20:56:09.277992 20451 solver.cpp:228] Iteration 11180, loss = 0.31333
I0808 20:56:09.278098 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 20:56:09.278113 20451 solver.cpp:244]     Train net output #1: loss = 0.31333 (* 1 = 0.31333 loss)
I0808 20:56:09.278126 20451 sgd_solver.cpp:106] Iteration 11180, lr = 0.000569581
I0808 20:56:31.572788 20451 solver.cpp:228] Iteration 11190, loss = 0.344157
I0808 20:56:31.572840 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 20:56:31.572854 20451 solver.cpp:244]     Train net output #1: loss = 0.344157 (* 1 = 0.344157 loss)
I0808 20:56:31.572866 20451 sgd_solver.cpp:106] Iteration 11190, lr = 0.000569379
I0808 20:56:51.643537 20451 solver.cpp:337] Iteration 11200, Testing net (#0)
I0808 20:57:00.166543 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 20:57:00.166594 20451 solver.cpp:404]     Test net output #1: loss = 0.999767 (* 1 = 0.999767 loss)
I0808 20:57:02.371343 20451 solver.cpp:228] Iteration 11200, loss = 0.187871
I0808 20:57:02.371397 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:57:02.371412 20451 solver.cpp:244]     Train net output #1: loss = 0.187871 (* 1 = 0.187871 loss)
I0808 20:57:02.371423 20451 sgd_solver.cpp:106] Iteration 11200, lr = 0.000569178
I0808 20:57:24.653522 20451 solver.cpp:228] Iteration 11210, loss = 0.187752
I0808 20:57:24.653611 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:57:24.653628 20451 solver.cpp:244]     Train net output #1: loss = 0.187752 (* 1 = 0.187752 loss)
I0808 20:57:24.653640 20451 sgd_solver.cpp:106] Iteration 11210, lr = 0.000568977
I0808 20:57:46.964433 20451 solver.cpp:228] Iteration 11220, loss = 0.156464
I0808 20:57:46.964484 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:57:46.964498 20451 solver.cpp:244]     Train net output #1: loss = 0.156464 (* 1 = 0.156464 loss)
I0808 20:57:46.964510 20451 sgd_solver.cpp:106] Iteration 11220, lr = 0.000568776
I0808 20:58:09.277206 20451 solver.cpp:228] Iteration 11230, loss = 0.156324
I0808 20:58:09.277379 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 20:58:09.277395 20451 solver.cpp:244]     Train net output #1: loss = 0.156324 (* 1 = 0.156324 loss)
I0808 20:58:09.277407 20451 sgd_solver.cpp:106] Iteration 11230, lr = 0.000568575
I0808 20:58:31.587995 20451 solver.cpp:228] Iteration 11240, loss = 0.218778
I0808 20:58:31.588045 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:58:31.588059 20451 solver.cpp:244]     Train net output #1: loss = 0.218779 (* 1 = 0.218779 loss)
I0808 20:58:31.588071 20451 sgd_solver.cpp:106] Iteration 11240, lr = 0.000568374
I0808 20:58:53.892858 20451 solver.cpp:228] Iteration 11250, loss = 0.187648
I0808 20:58:53.893038 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:58:53.893054 20451 solver.cpp:244]     Train net output #1: loss = 0.187648 (* 1 = 0.187648 loss)
I0808 20:58:53.893066 20451 sgd_solver.cpp:106] Iteration 11250, lr = 0.000568173
I0808 20:59:16.189779 20451 solver.cpp:228] Iteration 11260, loss = 0.187569
I0808 20:59:16.189836 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 20:59:16.189849 20451 solver.cpp:244]     Train net output #1: loss = 0.18757 (* 1 = 0.18757 loss)
I0808 20:59:16.189862 20451 sgd_solver.cpp:106] Iteration 11260, lr = 0.000567973
I0808 20:59:38.488898 20451 solver.cpp:228] Iteration 11270, loss = 0.343875
I0808 20:59:38.489104 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 20:59:38.489120 20451 solver.cpp:244]     Train net output #1: loss = 0.343875 (* 1 = 0.343875 loss)
I0808 20:59:38.489132 20451 sgd_solver.cpp:106] Iteration 11270, lr = 0.000567773
I0808 21:00:00.787448 20451 solver.cpp:228] Iteration 11280, loss = 0.250041
I0808 21:00:00.787490 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:00:00.787506 20451 solver.cpp:244]     Train net output #1: loss = 0.250041 (* 1 = 0.250041 loss)
I0808 21:00:00.787519 20451 sgd_solver.cpp:106] Iteration 11280, lr = 0.000567572
I0808 21:00:23.099064 20451 solver.cpp:228] Iteration 11290, loss = 0.218901
I0808 21:00:23.099242 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:00:23.099258 20451 solver.cpp:244]     Train net output #1: loss = 0.218901 (* 1 = 0.218901 loss)
I0808 21:00:23.099275 20451 sgd_solver.cpp:106] Iteration 11290, lr = 0.000567372
I0808 21:00:43.189834 20451 solver.cpp:337] Iteration 11300, Testing net (#0)
I0808 21:00:51.717494 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0808 21:00:51.717540 20451 solver.cpp:404]     Test net output #1: loss = 0.989168 (* 1 = 0.989168 loss)
I0808 21:00:53.918129 20451 solver.cpp:228] Iteration 11300, loss = 0.187549
I0808 21:00:53.918273 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:00:53.918293 20451 solver.cpp:244]     Train net output #1: loss = 0.18755 (* 1 = 0.18755 loss)
I0808 21:00:53.918308 20451 sgd_solver.cpp:106] Iteration 11300, lr = 0.000567173
I0808 21:01:16.191653 20451 solver.cpp:228] Iteration 11310, loss = 0.343802
I0808 21:01:16.191705 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 21:01:16.191720 20451 solver.cpp:244]     Train net output #1: loss = 0.343802 (* 1 = 0.343802 loss)
I0808 21:01:16.191732 20451 sgd_solver.cpp:106] Iteration 11310, lr = 0.000566973
I0808 21:01:38.500691 20451 solver.cpp:228] Iteration 11320, loss = 0.218746
I0808 21:01:38.500880 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:01:38.500900 20451 solver.cpp:244]     Train net output #1: loss = 0.218746 (* 1 = 0.218746 loss)
I0808 21:01:38.500916 20451 sgd_solver.cpp:106] Iteration 11320, lr = 0.000566774
I0808 21:02:00.804849 20451 solver.cpp:228] Iteration 11330, loss = 0.156298
I0808 21:02:00.804893 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:02:00.804909 20451 solver.cpp:244]     Train net output #1: loss = 0.156298 (* 1 = 0.156298 loss)
I0808 21:02:00.804924 20451 sgd_solver.cpp:106] Iteration 11330, lr = 0.000566574
I0808 21:02:23.107944 20451 solver.cpp:228] Iteration 11340, loss = 0.31256
I0808 21:02:23.108042 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 21:02:23.108062 20451 solver.cpp:244]     Train net output #1: loss = 0.31256 (* 1 = 0.31256 loss)
I0808 21:02:23.108080 20451 sgd_solver.cpp:106] Iteration 11340, lr = 0.000566375
I0808 21:02:45.421094 20451 solver.cpp:228] Iteration 11350, loss = 0.0938028
I0808 21:02:45.421149 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:02:45.421164 20451 solver.cpp:244]     Train net output #1: loss = 0.0938031 (* 1 = 0.0938031 loss)
I0808 21:02:45.421175 20451 sgd_solver.cpp:106] Iteration 11350, lr = 0.000566176
I0808 21:03:07.727217 20451 solver.cpp:228] Iteration 11360, loss = 0.187555
I0808 21:03:07.727377 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:03:07.727417 20451 solver.cpp:244]     Train net output #1: loss = 0.187555 (* 1 = 0.187555 loss)
I0808 21:03:07.727450 20451 sgd_solver.cpp:106] Iteration 11360, lr = 0.000565977
I0808 21:03:30.035454 20451 solver.cpp:228] Iteration 11370, loss = 0.125028
I0808 21:03:30.035504 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:03:30.035519 20451 solver.cpp:244]     Train net output #1: loss = 0.125029 (* 1 = 0.125029 loss)
I0808 21:03:30.035532 20451 sgd_solver.cpp:106] Iteration 11370, lr = 0.000565779
I0808 21:03:52.346252 20451 solver.cpp:228] Iteration 11380, loss = 0.0625131
I0808 21:03:52.346457 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 21:03:52.346472 20451 solver.cpp:244]     Train net output #1: loss = 0.0625133 (* 1 = 0.0625133 loss)
I0808 21:03:52.346487 20451 sgd_solver.cpp:106] Iteration 11380, lr = 0.00056558
I0808 21:04:14.666558 20451 solver.cpp:228] Iteration 11390, loss = 0.187518
I0808 21:04:14.666613 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:04:14.666627 20451 solver.cpp:244]     Train net output #1: loss = 0.187519 (* 1 = 0.187519 loss)
I0808 21:04:14.666640 20451 sgd_solver.cpp:106] Iteration 11390, lr = 0.000565382
I0808 21:04:34.739650 20451 solver.cpp:337] Iteration 11400, Testing net (#0)
I0808 21:04:43.262403 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0808 21:04:43.262452 20451 solver.cpp:404]     Test net output #1: loss = 1.03599 (* 1 = 1.03599 loss)
I0808 21:04:45.463960 20451 solver.cpp:228] Iteration 11400, loss = 0.187514
I0808 21:04:45.464013 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:04:45.464026 20451 solver.cpp:244]     Train net output #1: loss = 0.187514 (* 1 = 0.187514 loss)
I0808 21:04:45.464040 20451 sgd_solver.cpp:106] Iteration 11400, lr = 0.000565184
I0808 21:05:07.742645 20451 solver.cpp:228] Iteration 11410, loss = 0.312638
I0808 21:05:07.742746 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:05:07.742765 20451 solver.cpp:244]     Train net output #1: loss = 0.312639 (* 1 = 0.312639 loss)
I0808 21:05:07.742781 20451 sgd_solver.cpp:106] Iteration 11410, lr = 0.000564986
I0808 21:05:30.048789 20451 solver.cpp:228] Iteration 11420, loss = 0.281322
I0808 21:05:30.048846 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 21:05:30.048866 20451 solver.cpp:244]     Train net output #1: loss = 0.281322 (* 1 = 0.281322 loss)
I0808 21:05:30.048879 20451 sgd_solver.cpp:106] Iteration 11420, lr = 0.000564788
I0808 21:05:52.352995 20451 solver.cpp:228] Iteration 11430, loss = 0.219137
I0808 21:05:52.353169 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:05:52.353183 20451 solver.cpp:244]     Train net output #1: loss = 0.219137 (* 1 = 0.219137 loss)
I0808 21:05:52.353195 20451 sgd_solver.cpp:106] Iteration 11430, lr = 0.00056459
I0808 21:06:14.654893 20451 solver.cpp:228] Iteration 11440, loss = 0.281691
I0808 21:06:14.654937 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:06:14.654954 20451 solver.cpp:244]     Train net output #1: loss = 0.281691 (* 1 = 0.281691 loss)
I0808 21:06:14.654980 20451 sgd_solver.cpp:106] Iteration 11440, lr = 0.000564393
I0808 21:06:36.949398 20451 solver.cpp:228] Iteration 11450, loss = 0.219208
I0808 21:06:36.949584 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:06:36.949602 20451 solver.cpp:244]     Train net output #1: loss = 0.219208 (* 1 = 0.219208 loss)
I0808 21:06:36.949617 20451 sgd_solver.cpp:106] Iteration 11450, lr = 0.000564195
I0808 21:06:59.252074 20451 solver.cpp:228] Iteration 11460, loss = 0.125034
I0808 21:06:59.252125 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:06:59.252140 20451 solver.cpp:244]     Train net output #1: loss = 0.125034 (* 1 = 0.125034 loss)
I0808 21:06:59.252151 20451 sgd_solver.cpp:106] Iteration 11460, lr = 0.000563998
I0808 21:07:21.554540 20451 solver.cpp:228] Iteration 11470, loss = 0.0625678
I0808 21:07:21.554733 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 21:07:21.554749 20451 solver.cpp:244]     Train net output #1: loss = 0.062568 (* 1 = 0.062568 loss)
I0808 21:07:21.554762 20451 sgd_solver.cpp:106] Iteration 11470, lr = 0.000563801
I0808 21:07:43.859407 20451 solver.cpp:228] Iteration 11480, loss = 0.156397
I0808 21:07:43.859455 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:07:43.859473 20451 solver.cpp:244]     Train net output #1: loss = 0.156397 (* 1 = 0.156397 loss)
I0808 21:07:43.859489 20451 sgd_solver.cpp:106] Iteration 11480, lr = 0.000563604
I0808 21:08:06.170186 20451 solver.cpp:228] Iteration 11490, loss = 0.093795
I0808 21:08:06.170325 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:08:06.170341 20451 solver.cpp:244]     Train net output #1: loss = 0.0937952 (* 1 = 0.0937952 loss)
I0808 21:08:06.170353 20451 sgd_solver.cpp:106] Iteration 11490, lr = 0.000563408
I0808 21:08:26.260069 20451 solver.cpp:337] Iteration 11500, Testing net (#0)
I0808 21:08:34.781533 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 21:08:34.781577 20451 solver.cpp:404]     Test net output #1: loss = 0.984885 (* 1 = 0.984885 loss)
I0808 21:08:36.986739 20451 solver.cpp:228] Iteration 11500, loss = 0.218917
I0808 21:08:36.986852 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:08:36.986872 20451 solver.cpp:244]     Train net output #1: loss = 0.218917 (* 1 = 0.218917 loss)
I0808 21:08:36.986887 20451 sgd_solver.cpp:106] Iteration 11500, lr = 0.000563211
I0808 21:08:59.264271 20451 solver.cpp:228] Iteration 11510, loss = 0.250123
I0808 21:08:59.264324 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:08:59.264338 20451 solver.cpp:244]     Train net output #1: loss = 0.250124 (* 1 = 0.250124 loss)
I0808 21:08:59.264349 20451 sgd_solver.cpp:106] Iteration 11510, lr = 0.000563015
I0808 21:09:21.576094 20451 solver.cpp:228] Iteration 11520, loss = 0.187628
I0808 21:09:21.576263 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:09:21.576277 20451 solver.cpp:244]     Train net output #1: loss = 0.187628 (* 1 = 0.187628 loss)
I0808 21:09:21.576290 20451 sgd_solver.cpp:106] Iteration 11520, lr = 0.000562818
I0808 21:09:43.883160 20451 solver.cpp:228] Iteration 11530, loss = 0.375202
I0808 21:09:43.883213 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0808 21:09:43.883229 20451 solver.cpp:244]     Train net output #1: loss = 0.375202 (* 1 = 0.375202 loss)
I0808 21:09:43.883240 20451 sgd_solver.cpp:106] Iteration 11530, lr = 0.000562622
I0808 21:10:06.195488 20451 solver.cpp:228] Iteration 11540, loss = 0.093803
I0808 21:10:06.195669 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:10:06.195685 20451 solver.cpp:244]     Train net output #1: loss = 0.0938032 (* 1 = 0.0938032 loss)
I0808 21:10:06.195698 20451 sgd_solver.cpp:106] Iteration 11540, lr = 0.000562427
I0808 21:10:28.500921 20451 solver.cpp:228] Iteration 11550, loss = 0.218842
I0808 21:10:28.500963 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:10:28.500988 20451 solver.cpp:244]     Train net output #1: loss = 0.218842 (* 1 = 0.218842 loss)
I0808 21:10:28.501004 20451 sgd_solver.cpp:106] Iteration 11550, lr = 0.000562231
I0808 21:10:50.804453 20451 solver.cpp:228] Iteration 11560, loss = 0.187756
I0808 21:10:50.804589 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:10:50.804603 20451 solver.cpp:244]     Train net output #1: loss = 0.187756 (* 1 = 0.187756 loss)
I0808 21:10:50.804615 20451 sgd_solver.cpp:106] Iteration 11560, lr = 0.000562035
I0808 21:11:13.111804 20451 solver.cpp:228] Iteration 11570, loss = 0.218819
I0808 21:11:13.111845 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:11:13.111865 20451 solver.cpp:244]     Train net output #1: loss = 0.21882 (* 1 = 0.21882 loss)
I0808 21:11:13.111879 20451 sgd_solver.cpp:106] Iteration 11570, lr = 0.00056184
I0808 21:11:35.417078 20451 solver.cpp:228] Iteration 11580, loss = 0.125237
I0808 21:11:35.417258 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:11:35.417273 20451 solver.cpp:244]     Train net output #1: loss = 0.125237 (* 1 = 0.125237 loss)
I0808 21:11:35.417285 20451 sgd_solver.cpp:106] Iteration 11580, lr = 0.000561644
I0808 21:11:57.726604 20451 solver.cpp:228] Iteration 11590, loss = 0.125078
I0808 21:11:57.726655 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:11:57.726670 20451 solver.cpp:244]     Train net output #1: loss = 0.125078 (* 1 = 0.125078 loss)
I0808 21:11:57.726681 20451 sgd_solver.cpp:106] Iteration 11590, lr = 0.000561449
I0808 21:12:17.812096 20451 solver.cpp:337] Iteration 11600, Testing net (#0)
I0808 21:12:26.334712 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0808 21:12:26.334776 20451 solver.cpp:404]     Test net output #1: loss = 0.970749 (* 1 = 0.970749 loss)
I0808 21:12:28.537793 20451 solver.cpp:228] Iteration 11600, loss = 0.156352
I0808 21:12:28.537844 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:12:28.537858 20451 solver.cpp:244]     Train net output #1: loss = 0.156353 (* 1 = 0.156353 loss)
I0808 21:12:28.537870 20451 sgd_solver.cpp:106] Iteration 11600, lr = 0.000561254
I0808 21:12:50.835772 20451 solver.cpp:228] Iteration 11610, loss = 0.125082
I0808 21:12:50.835949 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:12:50.835964 20451 solver.cpp:244]     Train net output #1: loss = 0.125082 (* 1 = 0.125082 loss)
I0808 21:12:50.835978 20451 sgd_solver.cpp:106] Iteration 11610, lr = 0.00056106
I0808 21:13:13.144119 20451 solver.cpp:228] Iteration 11620, loss = 0.0938247
I0808 21:13:13.144168 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:13:13.144182 20451 solver.cpp:244]     Train net output #1: loss = 0.0938249 (* 1 = 0.0938249 loss)
I0808 21:13:13.144194 20451 sgd_solver.cpp:106] Iteration 11620, lr = 0.000560865
I0808 21:13:35.457474 20451 solver.cpp:228] Iteration 11630, loss = 0.125288
I0808 21:13:35.457654 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:13:35.457669 20451 solver.cpp:244]     Train net output #1: loss = 0.125288 (* 1 = 0.125288 loss)
I0808 21:13:35.457682 20451 sgd_solver.cpp:106] Iteration 11630, lr = 0.00056067
I0808 21:13:57.754155 20451 solver.cpp:228] Iteration 11640, loss = 0.250077
I0808 21:13:57.754207 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:13:57.754220 20451 solver.cpp:244]     Train net output #1: loss = 0.250077 (* 1 = 0.250077 loss)
I0808 21:13:57.754232 20451 sgd_solver.cpp:106] Iteration 11640, lr = 0.000560476
I0808 21:14:20.060585 20451 solver.cpp:228] Iteration 11650, loss = 0.0627562
I0808 21:14:20.060796 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:14:20.060839 20451 solver.cpp:244]     Train net output #1: loss = 0.0627564 (* 1 = 0.0627564 loss)
I0808 21:14:20.060859 20451 sgd_solver.cpp:106] Iteration 11650, lr = 0.000560282
I0808 21:14:42.354845 20451 solver.cpp:228] Iteration 11660, loss = 0.156285
I0808 21:14:42.354907 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:14:42.354929 20451 solver.cpp:244]     Train net output #1: loss = 0.156285 (* 1 = 0.156285 loss)
I0808 21:14:42.354946 20451 sgd_solver.cpp:106] Iteration 11660, lr = 0.000560088
I0808 21:15:04.665329 20451 solver.cpp:228] Iteration 11670, loss = 0.125077
I0808 21:15:04.665510 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:15:04.665529 20451 solver.cpp:244]     Train net output #1: loss = 0.125077 (* 1 = 0.125077 loss)
I0808 21:15:04.665545 20451 sgd_solver.cpp:106] Iteration 11670, lr = 0.000559894
I0808 21:15:26.978126 20451 solver.cpp:228] Iteration 11680, loss = 0.125074
I0808 21:15:26.978170 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:15:26.978189 20451 solver.cpp:244]     Train net output #1: loss = 0.125074 (* 1 = 0.125074 loss)
I0808 21:15:26.978215 20451 sgd_solver.cpp:106] Iteration 11680, lr = 0.0005597
I0808 21:15:49.273315 20451 solver.cpp:228] Iteration 11690, loss = 0.187606
I0808 21:15:49.273496 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:15:49.273515 20451 solver.cpp:244]     Train net output #1: loss = 0.187606 (* 1 = 0.187606 loss)
I0808 21:15:49.273530 20451 sgd_solver.cpp:106] Iteration 11690, lr = 0.000559507
I0808 21:16:09.362108 20451 solver.cpp:337] Iteration 11700, Testing net (#0)
I0808 21:16:17.887771 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 21:16:17.887822 20451 solver.cpp:404]     Test net output #1: loss = 1.00814 (* 1 = 1.00814 loss)
I0808 21:16:20.090782 20451 solver.cpp:228] Iteration 11700, loss = 0.312649
I0808 21:16:20.090931 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 21:16:20.090952 20451 solver.cpp:244]     Train net output #1: loss = 0.31265 (* 1 = 0.31265 loss)
I0808 21:16:20.090967 20451 sgd_solver.cpp:106] Iteration 11700, lr = 0.000559313
I0808 21:16:42.371390 20451 solver.cpp:228] Iteration 11710, loss = 0.187558
I0808 21:16:42.371443 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:16:42.371455 20451 solver.cpp:244]     Train net output #1: loss = 0.187558 (* 1 = 0.187558 loss)
I0808 21:16:42.371467 20451 sgd_solver.cpp:106] Iteration 11710, lr = 0.00055912
I0808 21:17:04.667150 20451 solver.cpp:228] Iteration 11720, loss = 0.281488
I0808 21:17:04.667333 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 21:17:04.667348 20451 solver.cpp:244]     Train net output #1: loss = 0.281488 (* 1 = 0.281488 loss)
I0808 21:17:04.667361 20451 sgd_solver.cpp:106] Iteration 11720, lr = 0.000558927
I0808 21:17:26.975878 20451 solver.cpp:228] Iteration 11730, loss = 0.0937828
I0808 21:17:26.975931 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:17:26.975945 20451 solver.cpp:244]     Train net output #1: loss = 0.093783 (* 1 = 0.093783 loss)
I0808 21:17:26.975957 20451 sgd_solver.cpp:106] Iteration 11730, lr = 0.000558734
I0808 21:17:49.280777 20451 solver.cpp:228] Iteration 11740, loss = 0.156292
I0808 21:17:49.280958 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:17:49.280973 20451 solver.cpp:244]     Train net output #1: loss = 0.156292 (* 1 = 0.156292 loss)
I0808 21:17:49.280985 20451 sgd_solver.cpp:106] Iteration 11740, lr = 0.000558541
I0808 21:18:11.585846 20451 solver.cpp:228] Iteration 11750, loss = 0.156293
I0808 21:18:11.585894 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:18:11.585912 20451 solver.cpp:244]     Train net output #1: loss = 0.156293 (* 1 = 0.156293 loss)
I0808 21:18:11.585927 20451 sgd_solver.cpp:106] Iteration 11750, lr = 0.000558349
I0808 21:18:33.899577 20451 solver.cpp:228] Iteration 11760, loss = 0.18752
I0808 21:18:33.899739 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:18:33.899758 20451 solver.cpp:244]     Train net output #1: loss = 0.18752 (* 1 = 0.18752 loss)
I0808 21:18:33.899775 20451 sgd_solver.cpp:106] Iteration 11760, lr = 0.000558156
I0808 21:18:56.210958 20451 solver.cpp:228] Iteration 11770, loss = 0.156632
I0808 21:18:56.211012 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:18:56.211026 20451 solver.cpp:244]     Train net output #1: loss = 0.156632 (* 1 = 0.156632 loss)
I0808 21:18:56.211038 20451 sgd_solver.cpp:106] Iteration 11770, lr = 0.000557964
I0808 21:19:18.514938 20451 solver.cpp:228] Iteration 11780, loss = 0.0625403
I0808 21:19:18.515035 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 21:19:18.515054 20451 solver.cpp:244]     Train net output #1: loss = 0.0625405 (* 1 = 0.0625405 loss)
I0808 21:19:18.515069 20451 sgd_solver.cpp:106] Iteration 11780, lr = 0.000557772
I0808 21:19:40.807495 20451 solver.cpp:228] Iteration 11790, loss = 0.281603
I0808 21:19:40.807550 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 21:19:40.807570 20451 solver.cpp:244]     Train net output #1: loss = 0.281603 (* 1 = 0.281603 loss)
I0808 21:19:40.807588 20451 sgd_solver.cpp:106] Iteration 11790, lr = 0.00055758
I0808 21:20:00.886307 20451 solver.cpp:337] Iteration 11800, Testing net (#0)
I0808 21:20:09.409593 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0808 21:20:09.409646 20451 solver.cpp:404]     Test net output #1: loss = 1.01285 (* 1 = 1.01285 loss)
I0808 21:20:11.610884 20451 solver.cpp:228] Iteration 11800, loss = 0.218861
I0808 21:20:11.610937 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:20:11.610951 20451 solver.cpp:244]     Train net output #1: loss = 0.218862 (* 1 = 0.218862 loss)
I0808 21:20:11.610963 20451 sgd_solver.cpp:106] Iteration 11800, lr = 0.000557388
I0808 21:20:33.895737 20451 solver.cpp:228] Iteration 11810, loss = 0.344412
I0808 21:20:33.895948 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 21:20:33.895964 20451 solver.cpp:244]     Train net output #1: loss = 0.344412 (* 1 = 0.344412 loss)
I0808 21:20:33.895992 20451 sgd_solver.cpp:106] Iteration 11810, lr = 0.000557196
I0808 21:20:56.200309 20451 solver.cpp:228] Iteration 11820, loss = 0.343858
I0808 21:20:56.200348 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:20:56.200366 20451 solver.cpp:244]     Train net output #1: loss = 0.343858 (* 1 = 0.343858 loss)
I0808 21:20:56.200378 20451 sgd_solver.cpp:106] Iteration 11820, lr = 0.000557005
I0808 21:21:18.517544 20451 solver.cpp:228] Iteration 11830, loss = 0.312888
I0808 21:21:18.517673 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 21:21:18.517686 20451 solver.cpp:244]     Train net output #1: loss = 0.312889 (* 1 = 0.312889 loss)
I0808 21:21:18.517699 20451 sgd_solver.cpp:106] Iteration 11830, lr = 0.000556813
I0808 21:21:40.834238 20451 solver.cpp:228] Iteration 11840, loss = 0.281292
I0808 21:21:40.834283 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 21:21:40.834300 20451 solver.cpp:244]     Train net output #1: loss = 0.281292 (* 1 = 0.281292 loss)
I0808 21:21:40.834312 20451 sgd_solver.cpp:106] Iteration 11840, lr = 0.000556622
I0808 21:22:03.145557 20451 solver.cpp:228] Iteration 11850, loss = 0.156392
I0808 21:22:03.145731 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:22:03.145748 20451 solver.cpp:244]     Train net output #1: loss = 0.156393 (* 1 = 0.156393 loss)
I0808 21:22:03.145761 20451 sgd_solver.cpp:106] Iteration 11850, lr = 0.000556431
I0808 21:22:25.462735 20451 solver.cpp:228] Iteration 11860, loss = 0.125056
I0808 21:22:25.462785 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:22:25.462800 20451 solver.cpp:244]     Train net output #1: loss = 0.125056 (* 1 = 0.125056 loss)
I0808 21:22:25.462811 20451 sgd_solver.cpp:106] Iteration 11860, lr = 0.00055624
I0808 21:22:47.771055 20451 solver.cpp:228] Iteration 11870, loss = 0.125063
I0808 21:22:47.771232 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:22:47.771248 20451 solver.cpp:244]     Train net output #1: loss = 0.125063 (* 1 = 0.125063 loss)
I0808 21:22:47.771261 20451 sgd_solver.cpp:106] Iteration 11870, lr = 0.00055605
I0808 21:23:10.080327 20451 solver.cpp:228] Iteration 11880, loss = 0.156364
I0808 21:23:10.080379 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:23:10.080392 20451 solver.cpp:244]     Train net output #1: loss = 0.156364 (* 1 = 0.156364 loss)
I0808 21:23:10.080404 20451 sgd_solver.cpp:106] Iteration 11880, lr = 0.000555859
I0808 21:23:32.379237 20451 solver.cpp:228] Iteration 11890, loss = 0.156314
I0808 21:23:32.379427 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:23:32.379442 20451 solver.cpp:244]     Train net output #1: loss = 0.156314 (* 1 = 0.156314 loss)
I0808 21:23:32.379456 20451 sgd_solver.cpp:106] Iteration 11890, lr = 0.000555668
I0808 21:23:52.456048 20451 solver.cpp:337] Iteration 11900, Testing net (#0)
I0808 21:24:00.982386 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 21:24:00.982432 20451 solver.cpp:404]     Test net output #1: loss = 0.98488 (* 1 = 0.98488 loss)
I0808 21:24:03.186347 20451 solver.cpp:228] Iteration 11900, loss = 0.09382
I0808 21:24:03.186532 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:24:03.186548 20451 solver.cpp:244]     Train net output #1: loss = 0.0938202 (* 1 = 0.0938202 loss)
I0808 21:24:03.186561 20451 sgd_solver.cpp:106] Iteration 11900, lr = 0.000555478
I0808 21:24:25.463631 20451 solver.cpp:228] Iteration 11910, loss = 0.0937762
I0808 21:24:25.463685 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:24:25.463699 20451 solver.cpp:244]     Train net output #1: loss = 0.0937764 (* 1 = 0.0937764 loss)
I0808 21:24:25.463711 20451 sgd_solver.cpp:106] Iteration 11910, lr = 0.000555288
I0808 21:24:47.773074 20451 solver.cpp:228] Iteration 11920, loss = 0.125022
I0808 21:24:47.773285 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:24:47.773300 20451 solver.cpp:244]     Train net output #1: loss = 0.125022 (* 1 = 0.125022 loss)
I0808 21:24:47.773313 20451 sgd_solver.cpp:106] Iteration 11920, lr = 0.000555098
I0808 21:25:10.091312 20451 solver.cpp:228] Iteration 11930, loss = 0.250069
I0808 21:25:10.091356 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:25:10.091373 20451 solver.cpp:244]     Train net output #1: loss = 0.250069 (* 1 = 0.250069 loss)
I0808 21:25:10.091388 20451 sgd_solver.cpp:106] Iteration 11930, lr = 0.000554908
I0808 21:25:32.402659 20451 solver.cpp:228] Iteration 11940, loss = 0.218848
I0808 21:25:32.402835 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:25:32.402853 20451 solver.cpp:244]     Train net output #1: loss = 0.218848 (* 1 = 0.218848 loss)
I0808 21:25:32.402868 20451 sgd_solver.cpp:106] Iteration 11940, lr = 0.000554718
I0808 21:25:54.701613 20451 solver.cpp:228] Iteration 11950, loss = 0.156329
I0808 21:25:54.701668 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:25:54.701680 20451 solver.cpp:244]     Train net output #1: loss = 0.15633 (* 1 = 0.15633 loss)
I0808 21:25:54.701694 20451 sgd_solver.cpp:106] Iteration 11950, lr = 0.000554529
I0808 21:26:17.014889 20451 solver.cpp:228] Iteration 11960, loss = 0.187549
I0808 21:26:17.015064 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:26:17.015079 20451 solver.cpp:244]     Train net output #1: loss = 0.187549 (* 1 = 0.187549 loss)
I0808 21:26:17.015091 20451 sgd_solver.cpp:106] Iteration 11960, lr = 0.000554339
I0808 21:26:39.307932 20451 solver.cpp:228] Iteration 11970, loss = 0.18757
I0808 21:26:39.307987 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:26:39.308001 20451 solver.cpp:244]     Train net output #1: loss = 0.18757 (* 1 = 0.18757 loss)
I0808 21:26:39.308014 20451 sgd_solver.cpp:106] Iteration 11970, lr = 0.00055415
I0808 21:27:01.610152 20451 solver.cpp:228] Iteration 11980, loss = 0.12503
I0808 21:27:01.610328 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:27:01.610344 20451 solver.cpp:244]     Train net output #1: loss = 0.12503 (* 1 = 0.12503 loss)
I0808 21:27:01.610358 20451 sgd_solver.cpp:106] Iteration 11980, lr = 0.000553961
I0808 21:27:23.918236 20451 solver.cpp:228] Iteration 11990, loss = 0.218813
I0808 21:27:23.918288 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:27:23.918303 20451 solver.cpp:244]     Train net output #1: loss = 0.218813 (* 1 = 0.218813 loss)
I0808 21:27:23.918315 20451 sgd_solver.cpp:106] Iteration 11990, lr = 0.000553772
I0808 21:27:44.002993 20451 solver.cpp:337] Iteration 12000, Testing net (#0)
I0808 21:27:52.520606 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 21:27:52.520656 20451 solver.cpp:404]     Test net output #1: loss = 1.0032 (* 1 = 1.0032 loss)
I0808 21:27:54.727105 20451 solver.cpp:228] Iteration 12000, loss = 0.156461
I0808 21:27:54.727156 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:27:54.727169 20451 solver.cpp:244]     Train net output #1: loss = 0.156461 (* 1 = 0.156461 loss)
I0808 21:27:54.727181 20451 sgd_solver.cpp:106] Iteration 12000, lr = 0.000553583
I0808 21:28:17.008008 20451 solver.cpp:228] Iteration 12010, loss = 0.21876
I0808 21:28:17.008097 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:28:17.008113 20451 solver.cpp:244]     Train net output #1: loss = 0.21876 (* 1 = 0.21876 loss)
I0808 21:28:17.008126 20451 sgd_solver.cpp:106] Iteration 12010, lr = 0.000553395
I0808 21:28:39.318747 20451 solver.cpp:228] Iteration 12020, loss = 0.0625111
I0808 21:28:39.318800 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 21:28:39.318815 20451 solver.cpp:244]     Train net output #1: loss = 0.0625112 (* 1 = 0.0625112 loss)
I0808 21:28:39.318827 20451 sgd_solver.cpp:106] Iteration 12020, lr = 0.000553206
I0808 21:29:01.632300 20451 solver.cpp:228] Iteration 12030, loss = 0.187582
I0808 21:29:01.632406 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:29:01.632419 20451 solver.cpp:244]     Train net output #1: loss = 0.187582 (* 1 = 0.187582 loss)
I0808 21:29:01.632431 20451 sgd_solver.cpp:106] Iteration 12030, lr = 0.000553018
I0808 21:29:23.935850 20451 solver.cpp:228] Iteration 12040, loss = 0.250162
I0808 21:29:23.935899 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:29:23.935917 20451 solver.cpp:244]     Train net output #1: loss = 0.250162 (* 1 = 0.250162 loss)
I0808 21:29:23.935932 20451 sgd_solver.cpp:106] Iteration 12040, lr = 0.00055283
I0808 21:29:46.241582 20451 solver.cpp:228] Iteration 12050, loss = 0.218884
I0808 21:29:46.241765 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:29:46.241780 20451 solver.cpp:244]     Train net output #1: loss = 0.218884 (* 1 = 0.218884 loss)
I0808 21:29:46.241793 20451 sgd_solver.cpp:106] Iteration 12050, lr = 0.000552642
I0808 21:30:08.551486 20451 solver.cpp:228] Iteration 12060, loss = 0.0625304
I0808 21:30:08.551537 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 21:30:08.551551 20451 solver.cpp:244]     Train net output #1: loss = 0.0625306 (* 1 = 0.0625306 loss)
I0808 21:30:08.551563 20451 sgd_solver.cpp:106] Iteration 12060, lr = 0.000552454
I0808 21:30:30.863085 20451 solver.cpp:228] Iteration 12070, loss = 0.125043
I0808 21:30:30.863258 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:30:30.863277 20451 solver.cpp:244]     Train net output #1: loss = 0.125043 (* 1 = 0.125043 loss)
I0808 21:30:30.863291 20451 sgd_solver.cpp:106] Iteration 12070, lr = 0.000552266
I0808 21:30:53.175685 20451 solver.cpp:228] Iteration 12080, loss = 0.187642
I0808 21:30:53.175730 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:30:53.175748 20451 solver.cpp:244]     Train net output #1: loss = 0.187642 (* 1 = 0.187642 loss)
I0808 21:30:53.175763 20451 sgd_solver.cpp:106] Iteration 12080, lr = 0.000552078
I0808 21:31:15.481037 20451 solver.cpp:228] Iteration 12090, loss = 0.125005
I0808 21:31:15.481230 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:31:15.481250 20451 solver.cpp:244]     Train net output #1: loss = 0.125005 (* 1 = 0.125005 loss)
I0808 21:31:15.481264 20451 sgd_solver.cpp:106] Iteration 12090, lr = 0.000551891
I0808 21:31:35.554195 20451 solver.cpp:337] Iteration 12100, Testing net (#0)
I0808 21:31:44.074893 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 21:31:44.074946 20451 solver.cpp:404]     Test net output #1: loss = 0.975291 (* 1 = 0.975291 loss)
I0808 21:31:46.277396 20451 solver.cpp:228] Iteration 12100, loss = 0.187581
I0808 21:31:46.277505 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:31:46.277525 20451 solver.cpp:244]     Train net output #1: loss = 0.187581 (* 1 = 0.187581 loss)
I0808 21:31:46.277541 20451 sgd_solver.cpp:106] Iteration 12100, lr = 0.000551704
I0808 21:32:08.571233 20451 solver.cpp:228] Iteration 12110, loss = 0.125016
I0808 21:32:08.571286 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:32:08.571300 20451 solver.cpp:244]     Train net output #1: loss = 0.125016 (* 1 = 0.125016 loss)
I0808 21:32:08.571311 20451 sgd_solver.cpp:106] Iteration 12110, lr = 0.000551516
I0808 21:32:30.875334 20451 solver.cpp:228] Iteration 12120, loss = 0.250244
I0808 21:32:30.875519 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:32:30.875540 20451 solver.cpp:244]     Train net output #1: loss = 0.250244 (* 1 = 0.250244 loss)
I0808 21:32:30.875555 20451 sgd_solver.cpp:106] Iteration 12120, lr = 0.000551329
I0808 21:32:53.188454 20451 solver.cpp:228] Iteration 12130, loss = 0.156313
I0808 21:32:53.188500 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:32:53.188520 20451 solver.cpp:244]     Train net output #1: loss = 0.156313 (* 1 = 0.156313 loss)
I0808 21:32:53.188535 20451 sgd_solver.cpp:106] Iteration 12130, lr = 0.000551143
I0808 21:33:15.495954 20451 solver.cpp:228] Iteration 12140, loss = 0.187602
I0808 21:33:15.496186 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:33:15.496206 20451 solver.cpp:244]     Train net output #1: loss = 0.187602 (* 1 = 0.187602 loss)
I0808 21:33:15.496222 20451 sgd_solver.cpp:106] Iteration 12140, lr = 0.000550956
I0808 21:33:37.798393 20451 solver.cpp:228] Iteration 12150, loss = 0.0937794
I0808 21:33:37.798442 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:33:37.798462 20451 solver.cpp:244]     Train net output #1: loss = 0.0937795 (* 1 = 0.0937795 loss)
I0808 21:33:37.798478 20451 sgd_solver.cpp:106] Iteration 12150, lr = 0.000550769
I0808 21:34:00.099686 20451 solver.cpp:228] Iteration 12160, loss = 0.250112
I0808 21:34:00.099866 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:34:00.099880 20451 solver.cpp:244]     Train net output #1: loss = 0.250112 (* 1 = 0.250112 loss)
I0808 21:34:00.099894 20451 sgd_solver.cpp:106] Iteration 12160, lr = 0.000550583
I0808 21:34:22.407021 20451 solver.cpp:228] Iteration 12170, loss = 0.124998
I0808 21:34:22.407073 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:34:22.407088 20451 solver.cpp:244]     Train net output #1: loss = 0.124998 (* 1 = 0.124998 loss)
I0808 21:34:22.407100 20451 sgd_solver.cpp:106] Iteration 12170, lr = 0.000550397
I0808 21:34:44.721724 20451 solver.cpp:228] Iteration 12180, loss = 0.156341
I0808 21:34:44.721901 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:34:44.721916 20451 solver.cpp:244]     Train net output #1: loss = 0.156341 (* 1 = 0.156341 loss)
I0808 21:34:44.721930 20451 sgd_solver.cpp:106] Iteration 12180, lr = 0.00055021
I0808 21:35:07.031985 20451 solver.cpp:228] Iteration 12190, loss = 0.125075
I0808 21:35:07.032037 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:35:07.032050 20451 solver.cpp:244]     Train net output #1: loss = 0.125075 (* 1 = 0.125075 loss)
I0808 21:35:07.032063 20451 sgd_solver.cpp:106] Iteration 12190, lr = 0.000550025
I0808 21:35:27.115883 20451 solver.cpp:337] Iteration 12200, Testing net (#0)
I0808 21:35:35.639014 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0808 21:35:35.639065 20451 solver.cpp:404]     Test net output #1: loss = 1.0174 (* 1 = 1.0174 loss)
I0808 21:35:37.841393 20451 solver.cpp:228] Iteration 12200, loss = 0.156297
I0808 21:35:37.841440 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:35:37.841456 20451 solver.cpp:244]     Train net output #1: loss = 0.156297 (* 1 = 0.156297 loss)
I0808 21:35:37.841470 20451 sgd_solver.cpp:106] Iteration 12200, lr = 0.000549839
I0808 21:36:00.115567 20451 solver.cpp:228] Iteration 12210, loss = 0.250193
I0808 21:36:00.115748 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:36:00.115762 20451 solver.cpp:244]     Train net output #1: loss = 0.250193 (* 1 = 0.250193 loss)
I0808 21:36:00.115775 20451 sgd_solver.cpp:106] Iteration 12210, lr = 0.000549653
I0808 21:36:22.429424 20451 solver.cpp:228] Iteration 12220, loss = 0.187568
I0808 21:36:22.429474 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:36:22.429488 20451 solver.cpp:244]     Train net output #1: loss = 0.187569 (* 1 = 0.187569 loss)
I0808 21:36:22.429500 20451 sgd_solver.cpp:106] Iteration 12220, lr = 0.000549467
I0808 21:36:44.746386 20451 solver.cpp:228] Iteration 12230, loss = 0.281411
I0808 21:36:44.746533 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 21:36:44.746549 20451 solver.cpp:244]     Train net output #1: loss = 0.281411 (* 1 = 0.281411 loss)
I0808 21:36:44.746562 20451 sgd_solver.cpp:106] Iteration 12230, lr = 0.000549282
I0808 21:37:07.053892 20451 solver.cpp:228] Iteration 12240, loss = 0.0312594
I0808 21:37:07.053943 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 21:37:07.053957 20451 solver.cpp:244]     Train net output #1: loss = 0.0312595 (* 1 = 0.0312595 loss)
I0808 21:37:07.053969 20451 sgd_solver.cpp:106] Iteration 12240, lr = 0.000549097
I0808 21:37:29.358567 20451 solver.cpp:228] Iteration 12250, loss = 0.156376
I0808 21:37:29.358739 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:37:29.358754 20451 solver.cpp:244]     Train net output #1: loss = 0.156376 (* 1 = 0.156376 loss)
I0808 21:37:29.358767 20451 sgd_solver.cpp:106] Iteration 12250, lr = 0.000548912
I0808 21:37:51.664285 20451 solver.cpp:228] Iteration 12260, loss = 0.0937898
I0808 21:37:51.664347 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:37:51.664361 20451 solver.cpp:244]     Train net output #1: loss = 0.0937899 (* 1 = 0.0937899 loss)
I0808 21:37:51.664372 20451 sgd_solver.cpp:106] Iteration 12260, lr = 0.000548727
I0808 21:38:13.968883 20451 solver.cpp:228] Iteration 12270, loss = 0.18765
I0808 21:38:13.969063 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:38:13.969077 20451 solver.cpp:244]     Train net output #1: loss = 0.18765 (* 1 = 0.18765 loss)
I0808 21:38:13.969090 20451 sgd_solver.cpp:106] Iteration 12270, lr = 0.000548542
I0808 21:38:36.274571 20451 solver.cpp:228] Iteration 12280, loss = 0.218842
I0808 21:38:36.274624 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:38:36.274638 20451 solver.cpp:244]     Train net output #1: loss = 0.218842 (* 1 = 0.218842 loss)
I0808 21:38:36.274649 20451 sgd_solver.cpp:106] Iteration 12280, lr = 0.000548357
I0808 21:38:58.576555 20451 solver.cpp:228] Iteration 12290, loss = 0.156326
I0808 21:38:58.576741 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:38:58.576756 20451 solver.cpp:244]     Train net output #1: loss = 0.156326 (* 1 = 0.156326 loss)
I0808 21:38:58.576768 20451 sgd_solver.cpp:106] Iteration 12290, lr = 0.000548173
I0808 21:39:18.669414 20451 solver.cpp:337] Iteration 12300, Testing net (#0)
I0808 21:39:27.185678 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 21:39:27.185720 20451 solver.cpp:404]     Test net output #1: loss = 1.00344 (* 1 = 1.00344 loss)
I0808 21:39:29.387581 20451 solver.cpp:228] Iteration 12300, loss = 0.156321
I0808 21:39:29.387763 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:39:29.387778 20451 solver.cpp:244]     Train net output #1: loss = 0.156321 (* 1 = 0.156321 loss)
I0808 21:39:29.387790 20451 sgd_solver.cpp:106] Iteration 12300, lr = 0.000547988
I0808 21:39:51.675321 20451 solver.cpp:228] Iteration 12310, loss = 0.218853
I0808 21:39:51.675374 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:39:51.675387 20451 solver.cpp:244]     Train net output #1: loss = 0.218853 (* 1 = 0.218853 loss)
I0808 21:39:51.675400 20451 sgd_solver.cpp:106] Iteration 12310, lr = 0.000547804
I0808 21:40:13.979285 20451 solver.cpp:228] Iteration 12320, loss = 0.0937614
I0808 21:40:13.979398 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:40:13.979416 20451 solver.cpp:244]     Train net output #1: loss = 0.0937615 (* 1 = 0.0937615 loss)
I0808 21:40:13.979432 20451 sgd_solver.cpp:106] Iteration 12320, lr = 0.00054762
I0808 21:40:36.281352 20451 solver.cpp:228] Iteration 12330, loss = 0.156399
I0808 21:40:36.281493 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:40:36.281535 20451 solver.cpp:244]     Train net output #1: loss = 0.1564 (* 1 = 0.1564 loss)
I0808 21:40:36.281572 20451 sgd_solver.cpp:106] Iteration 12330, lr = 0.000547436
I0808 21:40:58.581260 20451 solver.cpp:228] Iteration 12340, loss = 0.156289
I0808 21:40:58.581403 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:40:58.581423 20451 solver.cpp:244]     Train net output #1: loss = 0.15629 (* 1 = 0.15629 loss)
I0808 21:40:58.581439 20451 sgd_solver.cpp:106] Iteration 12340, lr = 0.000547252
I0808 21:41:20.889077 20451 solver.cpp:228] Iteration 12350, loss = 0.0937529
I0808 21:41:20.889123 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:41:20.889152 20451 solver.cpp:244]     Train net output #1: loss = 0.093753 (* 1 = 0.093753 loss)
I0808 21:41:20.889168 20451 sgd_solver.cpp:106] Iteration 12350, lr = 0.000547069
I0808 21:41:43.196737 20451 solver.cpp:228] Iteration 12360, loss = 0.156273
I0808 21:41:43.196847 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:41:43.196867 20451 solver.cpp:244]     Train net output #1: loss = 0.156274 (* 1 = 0.156274 loss)
I0808 21:41:43.196882 20451 sgd_solver.cpp:106] Iteration 12360, lr = 0.000546885
I0808 21:42:05.499313 20451 solver.cpp:228] Iteration 12370, loss = 0.156335
I0808 21:42:05.499357 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:42:05.499385 20451 solver.cpp:244]     Train net output #1: loss = 0.156335 (* 1 = 0.156335 loss)
I0808 21:42:05.499400 20451 sgd_solver.cpp:106] Iteration 12370, lr = 0.000546702
I0808 21:42:27.807533 20451 solver.cpp:228] Iteration 12380, loss = 0.218774
I0808 21:42:27.807643 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:42:27.807662 20451 solver.cpp:244]     Train net output #1: loss = 0.218774 (* 1 = 0.218774 loss)
I0808 21:42:27.807677 20451 sgd_solver.cpp:106] Iteration 12380, lr = 0.000546519
I0808 21:42:50.105607 20451 solver.cpp:228] Iteration 12390, loss = 0.0625595
I0808 21:42:50.105660 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 21:42:50.105674 20451 solver.cpp:244]     Train net output #1: loss = 0.0625595 (* 1 = 0.0625595 loss)
I0808 21:42:50.105686 20451 sgd_solver.cpp:106] Iteration 12390, lr = 0.000546336
I0808 21:43:10.192222 20451 solver.cpp:337] Iteration 12400, Testing net (#0)
I0808 21:43:18.709033 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 21:43:18.709086 20451 solver.cpp:404]     Test net output #1: loss = 0.975435 (* 1 = 0.975435 loss)
I0808 21:43:20.913365 20451 solver.cpp:228] Iteration 12400, loss = 0.125081
I0808 21:43:20.913414 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:43:20.913431 20451 solver.cpp:244]     Train net output #1: loss = 0.125081 (* 1 = 0.125081 loss)
I0808 21:43:20.913444 20451 sgd_solver.cpp:106] Iteration 12400, lr = 0.000546153
I0808 21:43:43.193164 20451 solver.cpp:228] Iteration 12410, loss = 0.156398
I0808 21:43:43.193338 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:43:43.193356 20451 solver.cpp:244]     Train net output #1: loss = 0.156398 (* 1 = 0.156398 loss)
I0808 21:43:43.193367 20451 sgd_solver.cpp:106] Iteration 12410, lr = 0.00054597
I0808 21:44:05.499835 20451 solver.cpp:228] Iteration 12420, loss = 0.219367
I0808 21:44:05.499897 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:44:05.499918 20451 solver.cpp:244]     Train net output #1: loss = 0.219367 (* 1 = 0.219367 loss)
I0808 21:44:05.499936 20451 sgd_solver.cpp:106] Iteration 12420, lr = 0.000545787
I0808 21:44:27.810149 20451 solver.cpp:228] Iteration 12430, loss = 0.250056
I0808 21:44:27.810328 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:44:27.810346 20451 solver.cpp:244]     Train net output #1: loss = 0.250056 (* 1 = 0.250056 loss)
I0808 21:44:27.810362 20451 sgd_solver.cpp:106] Iteration 12430, lr = 0.000545605
I0808 21:44:50.115334 20451 solver.cpp:228] Iteration 12440, loss = 0.156284
I0808 21:44:50.115378 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:44:50.115396 20451 solver.cpp:244]     Train net output #1: loss = 0.156284 (* 1 = 0.156284 loss)
I0808 21:44:50.115422 20451 sgd_solver.cpp:106] Iteration 12440, lr = 0.000545422
I0808 21:45:12.427160 20451 solver.cpp:228] Iteration 12450, loss = 0.187609
I0808 21:45:12.427373 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:45:12.427393 20451 solver.cpp:244]     Train net output #1: loss = 0.187609 (* 1 = 0.187609 loss)
I0808 21:45:12.427409 20451 sgd_solver.cpp:106] Iteration 12450, lr = 0.00054524
I0808 21:45:34.733633 20451 solver.cpp:228] Iteration 12460, loss = 0.125065
I0808 21:45:34.733678 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:45:34.733696 20451 solver.cpp:244]     Train net output #1: loss = 0.125065 (* 1 = 0.125065 loss)
I0808 21:45:34.733711 20451 sgd_solver.cpp:106] Iteration 12460, lr = 0.000545058
I0808 21:45:57.040563 20451 solver.cpp:228] Iteration 12470, loss = 0.312783
I0808 21:45:57.040733 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 21:45:57.040751 20451 solver.cpp:244]     Train net output #1: loss = 0.312783 (* 1 = 0.312783 loss)
I0808 21:45:57.040766 20451 sgd_solver.cpp:106] Iteration 12470, lr = 0.000544876
I0808 21:46:19.338454 20451 solver.cpp:228] Iteration 12480, loss = 0.187781
I0808 21:46:19.338506 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:46:19.338521 20451 solver.cpp:244]     Train net output #1: loss = 0.187781 (* 1 = 0.187781 loss)
I0808 21:46:19.338533 20451 sgd_solver.cpp:106] Iteration 12480, lr = 0.000544694
I0808 21:46:41.645912 20451 solver.cpp:228] Iteration 12490, loss = 0.156524
I0808 21:46:41.646090 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:46:41.646106 20451 solver.cpp:244]     Train net output #1: loss = 0.156524 (* 1 = 0.156524 loss)
I0808 21:46:41.646116 20451 sgd_solver.cpp:106] Iteration 12490, lr = 0.000544513
I0808 21:47:01.727252 20451 solver.cpp:337] Iteration 12500, Testing net (#0)
I0808 21:47:10.247546 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 21:47:10.247596 20451 solver.cpp:404]     Test net output #1: loss = 0.99443 (* 1 = 0.99443 loss)
I0808 21:47:12.455024 20451 solver.cpp:228] Iteration 12500, loss = 0.0938461
I0808 21:47:12.455200 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 21:47:12.455215 20451 solver.cpp:244]     Train net output #1: loss = 0.0938462 (* 1 = 0.0938462 loss)
I0808 21:47:12.455229 20451 sgd_solver.cpp:106] Iteration 12500, lr = 0.000544331
I0808 21:47:34.732372 20451 solver.cpp:228] Iteration 12510, loss = 0.312968
I0808 21:47:34.732416 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 21:47:34.732431 20451 solver.cpp:244]     Train net output #1: loss = 0.312968 (* 1 = 0.312968 loss)
I0808 21:47:34.732445 20451 sgd_solver.cpp:106] Iteration 12510, lr = 0.00054415
I0808 21:47:57.034668 20451 solver.cpp:228] Iteration 12520, loss = 0.218803
I0808 21:47:57.034839 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:47:57.034929 20451 solver.cpp:244]     Train net output #1: loss = 0.218803 (* 1 = 0.218803 loss)
I0808 21:47:57.034982 20451 sgd_solver.cpp:106] Iteration 12520, lr = 0.000543969
I0808 21:48:19.336470 20451 solver.cpp:228] Iteration 12530, loss = 0.187713
I0808 21:48:19.336515 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:48:19.336534 20451 solver.cpp:244]     Train net output #1: loss = 0.187713 (* 1 = 0.187713 loss)
I0808 21:48:19.336549 20451 sgd_solver.cpp:106] Iteration 12530, lr = 0.000543787
I0808 21:48:41.643111 20451 solver.cpp:228] Iteration 12540, loss = 0.218815
I0808 21:48:41.643299 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:48:41.643318 20451 solver.cpp:244]     Train net output #1: loss = 0.218815 (* 1 = 0.218815 loss)
I0808 21:48:41.643334 20451 sgd_solver.cpp:106] Iteration 12540, lr = 0.000543606
I0808 21:49:03.955472 20451 solver.cpp:228] Iteration 12550, loss = 0.218898
I0808 21:49:03.955514 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:49:03.955533 20451 solver.cpp:244]     Train net output #1: loss = 0.218898 (* 1 = 0.218898 loss)
I0808 21:49:03.955557 20451 sgd_solver.cpp:106] Iteration 12550, lr = 0.000543426
I0808 21:49:26.261677 20451 solver.cpp:228] Iteration 12560, loss = 0.250155
I0808 21:49:26.261827 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:49:26.261847 20451 solver.cpp:244]     Train net output #1: loss = 0.250155 (* 1 = 0.250155 loss)
I0808 21:49:26.261862 20451 sgd_solver.cpp:106] Iteration 12560, lr = 0.000543245
I0808 21:49:48.563279 20451 solver.cpp:228] Iteration 12570, loss = 0.21889
I0808 21:49:48.563331 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:49:48.563345 20451 solver.cpp:244]     Train net output #1: loss = 0.21889 (* 1 = 0.21889 loss)
I0808 21:49:48.563359 20451 sgd_solver.cpp:106] Iteration 12570, lr = 0.000543064
I0808 21:50:10.867929 20451 solver.cpp:228] Iteration 12580, loss = 0.125414
I0808 21:50:10.868113 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:50:10.868131 20451 solver.cpp:244]     Train net output #1: loss = 0.125414 (* 1 = 0.125414 loss)
I0808 21:50:10.868147 20451 sgd_solver.cpp:106] Iteration 12580, lr = 0.000542884
I0808 21:50:33.163563 20451 solver.cpp:228] Iteration 12590, loss = 0.187949
I0808 21:50:33.163605 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:50:33.163630 20451 solver.cpp:244]     Train net output #1: loss = 0.18795 (* 1 = 0.18795 loss)
I0808 21:50:33.163647 20451 sgd_solver.cpp:106] Iteration 12590, lr = 0.000542704
I0808 21:50:53.244778 20451 solver.cpp:337] Iteration 12600, Testing net (#0)
I0808 21:51:01.767841 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 21:51:01.767886 20451 solver.cpp:404]     Test net output #1: loss = 1.00321 (* 1 = 1.00321 loss)
I0808 21:51:03.974203 20451 solver.cpp:228] Iteration 12600, loss = 0.218963
I0808 21:51:03.974254 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 21:51:03.974268 20451 solver.cpp:244]     Train net output #1: loss = 0.218963 (* 1 = 0.218963 loss)
I0808 21:51:03.974280 20451 sgd_solver.cpp:106] Iteration 12600, lr = 0.000542524
I0808 21:51:26.248888 20451 solver.cpp:228] Iteration 12610, loss = 0.125265
I0808 21:51:26.248982 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:51:26.248998 20451 solver.cpp:244]     Train net output #1: loss = 0.125265 (* 1 = 0.125265 loss)
I0808 21:51:26.249011 20451 sgd_solver.cpp:106] Iteration 12610, lr = 0.000542344
I0808 21:51:48.541414 20451 solver.cpp:228] Iteration 12620, loss = 0.125055
I0808 21:51:48.541465 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:51:48.541481 20451 solver.cpp:244]     Train net output #1: loss = 0.125055 (* 1 = 0.125055 loss)
I0808 21:51:48.541491 20451 sgd_solver.cpp:106] Iteration 12620, lr = 0.000542164
I0808 21:52:10.846990 20451 solver.cpp:228] Iteration 12630, loss = 0.312643
I0808 21:52:10.847092 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 21:52:10.847112 20451 solver.cpp:244]     Train net output #1: loss = 0.312643 (* 1 = 0.312643 loss)
I0808 21:52:10.847127 20451 sgd_solver.cpp:106] Iteration 12630, lr = 0.000541984
I0808 21:52:33.145153 20451 solver.cpp:228] Iteration 12640, loss = 0.0312598
I0808 21:52:33.145203 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 21:52:33.145218 20451 solver.cpp:244]     Train net output #1: loss = 0.0312599 (* 1 = 0.0312599 loss)
I0808 21:52:33.145229 20451 sgd_solver.cpp:106] Iteration 12640, lr = 0.000541805
I0808 21:52:55.449190 20451 solver.cpp:228] Iteration 12650, loss = 0.187619
I0808 21:52:55.449300 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 21:52:55.449317 20451 solver.cpp:244]     Train net output #1: loss = 0.187619 (* 1 = 0.187619 loss)
I0808 21:52:55.449333 20451 sgd_solver.cpp:106] Iteration 12650, lr = 0.000541625
I0808 21:53:17.764482 20451 solver.cpp:228] Iteration 12660, loss = 0.156295
I0808 21:53:17.764534 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:53:17.764549 20451 solver.cpp:244]     Train net output #1: loss = 0.156295 (* 1 = 0.156295 loss)
I0808 21:53:17.764561 20451 sgd_solver.cpp:106] Iteration 12660, lr = 0.000541446
I0808 21:53:40.084265 20451 solver.cpp:228] Iteration 12670, loss = 0.218814
I0808 21:53:40.084475 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:53:40.084491 20451 solver.cpp:244]     Train net output #1: loss = 0.218814 (* 1 = 0.218814 loss)
I0808 21:53:40.084503 20451 sgd_solver.cpp:106] Iteration 12670, lr = 0.000541267
I0808 21:54:02.389396 20451 solver.cpp:228] Iteration 12680, loss = 0.187604
I0808 21:54:02.389448 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:54:02.389462 20451 solver.cpp:244]     Train net output #1: loss = 0.187604 (* 1 = 0.187604 loss)
I0808 21:54:02.389474 20451 sgd_solver.cpp:106] Iteration 12680, lr = 0.000541088
I0808 21:54:24.683681 20451 solver.cpp:228] Iteration 12690, loss = 0.12501
I0808 21:54:24.683857 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 21:54:24.683872 20451 solver.cpp:244]     Train net output #1: loss = 0.125011 (* 1 = 0.125011 loss)
I0808 21:54:24.683884 20451 sgd_solver.cpp:106] Iteration 12690, lr = 0.000540909
I0808 21:54:44.758080 20451 solver.cpp:337] Iteration 12700, Testing net (#0)
I0808 21:54:53.284524 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0808 21:54:53.284576 20451 solver.cpp:404]     Test net output #1: loss = 0.965882 (* 1 = 0.965882 loss)
I0808 21:54:55.486485 20451 solver.cpp:228] Iteration 12700, loss = 0.187574
I0808 21:54:55.486657 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:54:55.486672 20451 solver.cpp:244]     Train net output #1: loss = 0.187574 (* 1 = 0.187574 loss)
I0808 21:54:55.486685 20451 sgd_solver.cpp:106] Iteration 12700, lr = 0.00054073
I0808 21:55:17.768167 20451 solver.cpp:228] Iteration 12710, loss = 0.219263
I0808 21:55:17.768218 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:55:17.768231 20451 solver.cpp:244]     Train net output #1: loss = 0.219263 (* 1 = 0.219263 loss)
I0808 21:55:17.768244 20451 sgd_solver.cpp:106] Iteration 12710, lr = 0.000540552
I0808 21:55:40.072788 20451 solver.cpp:228] Iteration 12720, loss = 0.219111
I0808 21:55:40.072921 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:55:40.072935 20451 solver.cpp:244]     Train net output #1: loss = 0.219111 (* 1 = 0.219111 loss)
I0808 21:55:40.072948 20451 sgd_solver.cpp:106] Iteration 12720, lr = 0.000540373
I0808 21:56:02.370318 20451 solver.cpp:228] Iteration 12730, loss = 0.18767
I0808 21:56:02.370371 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 21:56:02.370386 20451 solver.cpp:244]     Train net output #1: loss = 0.18767 (* 1 = 0.18767 loss)
I0808 21:56:02.370398 20451 sgd_solver.cpp:106] Iteration 12730, lr = 0.000540195
I0808 21:56:24.666752 20451 solver.cpp:228] Iteration 12740, loss = 0.156324
I0808 21:56:24.666932 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:56:24.666947 20451 solver.cpp:244]     Train net output #1: loss = 0.156324 (* 1 = 0.156324 loss)
I0808 21:56:24.666960 20451 sgd_solver.cpp:106] Iteration 12740, lr = 0.000540017
I0808 21:56:46.964129 20451 solver.cpp:228] Iteration 12750, loss = 0.156518
I0808 21:56:46.964184 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:56:46.964198 20451 solver.cpp:244]     Train net output #1: loss = 0.156518 (* 1 = 0.156518 loss)
I0808 21:56:46.964210 20451 sgd_solver.cpp:106] Iteration 12750, lr = 0.000539839
I0808 21:57:09.260470 20451 solver.cpp:228] Iteration 12760, loss = 0.15634
I0808 21:57:09.260653 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:57:09.260668 20451 solver.cpp:244]     Train net output #1: loss = 0.15634 (* 1 = 0.15634 loss)
I0808 21:57:09.260681 20451 sgd_solver.cpp:106] Iteration 12760, lr = 0.000539661
I0808 21:57:31.566859 20451 solver.cpp:228] Iteration 12770, loss = 0.219233
I0808 21:57:31.566910 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:57:31.566925 20451 solver.cpp:244]     Train net output #1: loss = 0.219233 (* 1 = 0.219233 loss)
I0808 21:57:31.566936 20451 sgd_solver.cpp:106] Iteration 12770, lr = 0.000539483
I0808 21:57:53.876778 20451 solver.cpp:228] Iteration 12780, loss = 0.219068
I0808 21:57:53.876986 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:57:53.877002 20451 solver.cpp:244]     Train net output #1: loss = 0.219068 (* 1 = 0.219068 loss)
I0808 21:57:53.877014 20451 sgd_solver.cpp:106] Iteration 12780, lr = 0.000539305
I0808 21:58:16.179587 20451 solver.cpp:228] Iteration 12790, loss = 0.218813
I0808 21:58:16.179628 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 21:58:16.179644 20451 solver.cpp:244]     Train net output #1: loss = 0.218813 (* 1 = 0.218813 loss)
I0808 21:58:16.179656 20451 sgd_solver.cpp:106] Iteration 12790, lr = 0.000539128
I0808 21:58:36.262948 20451 solver.cpp:337] Iteration 12800, Testing net (#0)
I0808 21:58:44.780658 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0808 21:58:44.780709 20451 solver.cpp:404]     Test net output #1: loss = 1.03194 (* 1 = 1.03194 loss)
I0808 21:58:46.982892 20451 solver.cpp:228] Iteration 12800, loss = 0.281528
I0808 21:58:46.982939 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 21:58:46.982960 20451 solver.cpp:244]     Train net output #1: loss = 0.281528 (* 1 = 0.281528 loss)
I0808 21:58:46.982977 20451 sgd_solver.cpp:106] Iteration 12800, lr = 0.00053895
I0808 21:59:09.264118 20451 solver.cpp:228] Iteration 12810, loss = 0.156311
I0808 21:59:09.264297 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:59:09.264312 20451 solver.cpp:244]     Train net output #1: loss = 0.156311 (* 1 = 0.156311 loss)
I0808 21:59:09.264324 20451 sgd_solver.cpp:106] Iteration 12810, lr = 0.000538773
I0808 21:59:31.575769 20451 solver.cpp:228] Iteration 12820, loss = 0.250135
I0808 21:59:31.575824 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 21:59:31.575837 20451 solver.cpp:244]     Train net output #1: loss = 0.250135 (* 1 = 0.250135 loss)
I0808 21:59:31.575850 20451 sgd_solver.cpp:106] Iteration 12820, lr = 0.000538596
I0808 21:59:53.879601 20451 solver.cpp:228] Iteration 12830, loss = 0.156343
I0808 21:59:53.879784 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 21:59:53.879801 20451 solver.cpp:244]     Train net output #1: loss = 0.156343 (* 1 = 0.156343 loss)
I0808 21:59:53.879813 20451 sgd_solver.cpp:106] Iteration 12830, lr = 0.000538419
I0808 22:00:16.180766 20451 solver.cpp:228] Iteration 12840, loss = 0.250065
I0808 22:00:16.180822 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:00:16.180842 20451 solver.cpp:244]     Train net output #1: loss = 0.250065 (* 1 = 0.250065 loss)
I0808 22:00:16.180857 20451 sgd_solver.cpp:106] Iteration 12840, lr = 0.000538242
I0808 22:00:38.485781 20451 solver.cpp:228] Iteration 12850, loss = 0.250236
I0808 22:00:38.485965 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:00:38.485980 20451 solver.cpp:244]     Train net output #1: loss = 0.250236 (* 1 = 0.250236 loss)
I0808 22:00:38.485993 20451 sgd_solver.cpp:106] Iteration 12850, lr = 0.000538066
I0808 22:01:00.793117 20451 solver.cpp:228] Iteration 12860, loss = 0.156297
I0808 22:01:00.793166 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:01:00.793180 20451 solver.cpp:244]     Train net output #1: loss = 0.156298 (* 1 = 0.156298 loss)
I0808 22:01:00.793192 20451 sgd_solver.cpp:106] Iteration 12860, lr = 0.000537889
I0808 22:01:23.095572 20451 solver.cpp:228] Iteration 12870, loss = 0.0938258
I0808 22:01:23.095751 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 22:01:23.095767 20451 solver.cpp:244]     Train net output #1: loss = 0.0938259 (* 1 = 0.0938259 loss)
I0808 22:01:23.095779 20451 sgd_solver.cpp:106] Iteration 12870, lr = 0.000537713
I0808 22:01:45.391436 20451 solver.cpp:228] Iteration 12880, loss = 0.0938818
I0808 22:01:45.391489 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:01:45.391504 20451 solver.cpp:244]     Train net output #1: loss = 0.0938819 (* 1 = 0.0938819 loss)
I0808 22:01:45.391516 20451 sgd_solver.cpp:106] Iteration 12880, lr = 0.000537537
I0808 22:02:07.688290 20451 solver.cpp:228] Iteration 12890, loss = 0.125104
I0808 22:02:07.688426 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:02:07.688446 20451 solver.cpp:244]     Train net output #1: loss = 0.125104 (* 1 = 0.125104 loss)
I0808 22:02:07.688462 20451 sgd_solver.cpp:106] Iteration 12890, lr = 0.00053736
I0808 22:02:27.763248 20451 solver.cpp:337] Iteration 12900, Testing net (#0)
I0808 22:02:36.282367 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 22:02:36.282418 20451 solver.cpp:404]     Test net output #1: loss = 1.00318 (* 1 = 1.00318 loss)
I0808 22:02:38.487429 20451 solver.cpp:228] Iteration 12900, loss = 0.218768
I0808 22:02:38.487607 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:02:38.487622 20451 solver.cpp:244]     Train net output #1: loss = 0.218768 (* 1 = 0.218768 loss)
I0808 22:02:38.487635 20451 sgd_solver.cpp:106] Iteration 12900, lr = 0.000537184
I0808 22:03:00.765758 20451 solver.cpp:228] Iteration 12910, loss = 0.250065
I0808 22:03:00.765810 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:03:00.765823 20451 solver.cpp:244]     Train net output #1: loss = 0.250065 (* 1 = 0.250065 loss)
I0808 22:03:00.765836 20451 sgd_solver.cpp:106] Iteration 12910, lr = 0.000537009
I0808 22:03:23.072764 20451 solver.cpp:228] Iteration 12920, loss = 0.125047
I0808 22:03:23.072870 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:03:23.072885 20451 solver.cpp:244]     Train net output #1: loss = 0.125047 (* 1 = 0.125047 loss)
I0808 22:03:23.072897 20451 sgd_solver.cpp:106] Iteration 12920, lr = 0.000536833
I0808 22:03:45.380694 20451 solver.cpp:228] Iteration 12930, loss = 0.281497
I0808 22:03:45.380744 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 22:03:45.380759 20451 solver.cpp:244]     Train net output #1: loss = 0.281497 (* 1 = 0.281497 loss)
I0808 22:03:45.380770 20451 sgd_solver.cpp:106] Iteration 12930, lr = 0.000536657
I0808 22:04:07.683750 20451 solver.cpp:228] Iteration 12940, loss = 0.156279
I0808 22:04:07.683936 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:04:07.683953 20451 solver.cpp:244]     Train net output #1: loss = 0.156279 (* 1 = 0.156279 loss)
I0808 22:04:07.683965 20451 sgd_solver.cpp:106] Iteration 12940, lr = 0.000536482
I0808 22:04:29.983032 20451 solver.cpp:228] Iteration 12950, loss = 0.125076
I0808 22:04:29.983078 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:04:29.983095 20451 solver.cpp:244]     Train net output #1: loss = 0.125076 (* 1 = 0.125076 loss)
I0808 22:04:29.983110 20451 sgd_solver.cpp:106] Iteration 12950, lr = 0.000536306
I0808 22:04:52.286792 20451 solver.cpp:228] Iteration 12960, loss = 0.250075
I0808 22:04:52.286887 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:04:52.286906 20451 solver.cpp:244]     Train net output #1: loss = 0.250075 (* 1 = 0.250075 loss)
I0808 22:04:52.286922 20451 sgd_solver.cpp:106] Iteration 12960, lr = 0.000536131
I0808 22:05:14.592875 20451 solver.cpp:228] Iteration 12970, loss = 0.156327
I0808 22:05:14.592926 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:05:14.592941 20451 solver.cpp:244]     Train net output #1: loss = 0.156327 (* 1 = 0.156327 loss)
I0808 22:05:14.592954 20451 sgd_solver.cpp:106] Iteration 12970, lr = 0.000535956
I0808 22:05:36.899758 20451 solver.cpp:228] Iteration 12980, loss = 0.156293
I0808 22:05:36.899870 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:05:36.899885 20451 solver.cpp:244]     Train net output #1: loss = 0.156293 (* 1 = 0.156293 loss)
I0808 22:05:36.899898 20451 sgd_solver.cpp:106] Iteration 12980, lr = 0.000535781
I0808 22:05:59.202605 20451 solver.cpp:228] Iteration 12990, loss = 0.0312868
I0808 22:05:59.202657 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 22:05:59.202672 20451 solver.cpp:244]     Train net output #1: loss = 0.0312869 (* 1 = 0.0312869 loss)
I0808 22:05:59.202683 20451 sgd_solver.cpp:106] Iteration 12990, lr = 0.000535606
I0808 22:06:19.286223 20451 solver.cpp:337] Iteration 13000, Testing net (#0)
I0808 22:06:27.809440 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 22:06:27.809491 20451 solver.cpp:404]     Test net output #1: loss = 0.984482 (* 1 = 0.984482 loss)
I0808 22:06:30.012801 20451 solver.cpp:228] Iteration 13000, loss = 0.218792
I0808 22:06:30.012842 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:06:30.012857 20451 solver.cpp:244]     Train net output #1: loss = 0.218792 (* 1 = 0.218792 loss)
I0808 22:06:30.012871 20451 sgd_solver.cpp:106] Iteration 13000, lr = 0.000535432
I0808 22:06:52.289197 20451 solver.cpp:228] Iteration 13010, loss = 0.218946
I0808 22:06:52.289379 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:06:52.289394 20451 solver.cpp:244]     Train net output #1: loss = 0.218946 (* 1 = 0.218946 loss)
I0808 22:06:52.289408 20451 sgd_solver.cpp:106] Iteration 13010, lr = 0.000535257
I0808 22:07:14.600503 20451 solver.cpp:228] Iteration 13020, loss = 0.18761
I0808 22:07:14.600544 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:07:14.600564 20451 solver.cpp:244]     Train net output #1: loss = 0.18761 (* 1 = 0.18761 loss)
I0808 22:07:14.600576 20451 sgd_solver.cpp:106] Iteration 13020, lr = 0.000535083
I0808 22:07:36.911633 20451 solver.cpp:228] Iteration 13030, loss = 0.156374
I0808 22:07:36.911748 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:07:36.911767 20451 solver.cpp:244]     Train net output #1: loss = 0.156374 (* 1 = 0.156374 loss)
I0808 22:07:36.911783 20451 sgd_solver.cpp:106] Iteration 13030, lr = 0.000534909
I0808 22:07:59.228502 20451 solver.cpp:228] Iteration 13040, loss = 0.250293
I0808 22:07:59.228555 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:07:59.228569 20451 solver.cpp:244]     Train net output #1: loss = 0.250293 (* 1 = 0.250293 loss)
I0808 22:07:59.228581 20451 sgd_solver.cpp:106] Iteration 13040, lr = 0.000534734
I0808 22:08:21.536480 20451 solver.cpp:228] Iteration 13050, loss = 0.156465
I0808 22:08:21.536659 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:08:21.536674 20451 solver.cpp:244]     Train net output #1: loss = 0.156465 (* 1 = 0.156465 loss)
I0808 22:08:21.536686 20451 sgd_solver.cpp:106] Iteration 13050, lr = 0.00053456
I0808 22:08:43.857857 20451 solver.cpp:228] Iteration 13060, loss = 0.343993
I0808 22:08:43.857910 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 22:08:43.857925 20451 solver.cpp:244]     Train net output #1: loss = 0.343993 (* 1 = 0.343993 loss)
I0808 22:08:43.857936 20451 sgd_solver.cpp:106] Iteration 13060, lr = 0.000534387
I0808 22:09:06.165834 20451 solver.cpp:228] Iteration 13070, loss = 0.312971
I0808 22:09:06.165933 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 22:09:06.165949 20451 solver.cpp:244]     Train net output #1: loss = 0.312971 (* 1 = 0.312971 loss)
I0808 22:09:06.165962 20451 sgd_solver.cpp:106] Iteration 13070, lr = 0.000534213
I0808 22:09:28.467644 20451 solver.cpp:228] Iteration 13080, loss = 0.0937645
I0808 22:09:28.467697 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 22:09:28.467712 20451 solver.cpp:244]     Train net output #1: loss = 0.0937646 (* 1 = 0.0937646 loss)
I0808 22:09:28.467725 20451 sgd_solver.cpp:106] Iteration 13080, lr = 0.000534039
I0808 22:09:50.776722 20451 solver.cpp:228] Iteration 13090, loss = 0.250127
I0808 22:09:50.776898 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:09:50.776914 20451 solver.cpp:244]     Train net output #1: loss = 0.250127 (* 1 = 0.250127 loss)
I0808 22:09:50.776926 20451 sgd_solver.cpp:106] Iteration 13090, lr = 0.000533866
I0808 22:10:10.852617 20451 solver.cpp:337] Iteration 13100, Testing net (#0)
I0808 22:10:19.367036 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 22:10:19.367089 20451 solver.cpp:404]     Test net output #1: loss = 0.998741 (* 1 = 0.998741 loss)
I0808 22:10:21.571715 20451 solver.cpp:228] Iteration 13100, loss = 0.218847
I0808 22:10:21.571928 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:10:21.571944 20451 solver.cpp:244]     Train net output #1: loss = 0.218847 (* 1 = 0.218847 loss)
I0808 22:10:21.571957 20451 sgd_solver.cpp:106] Iteration 13100, lr = 0.000533692
I0808 22:10:43.857169 20451 solver.cpp:228] Iteration 13110, loss = 0.093828
I0808 22:10:43.857214 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 22:10:43.857233 20451 solver.cpp:244]     Train net output #1: loss = 0.0938281 (* 1 = 0.0938281 loss)
I0808 22:10:43.857247 20451 sgd_solver.cpp:106] Iteration 13110, lr = 0.000533519
I0808 22:11:06.157052 20451 solver.cpp:228] Iteration 13120, loss = 0.343799
I0808 22:11:06.157230 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 22:11:06.157245 20451 solver.cpp:244]     Train net output #1: loss = 0.3438 (* 1 = 0.3438 loss)
I0808 22:11:06.157258 20451 sgd_solver.cpp:106] Iteration 13120, lr = 0.000533346
I0808 22:11:28.452095 20451 solver.cpp:228] Iteration 13130, loss = 0.125022
I0808 22:11:28.452149 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:11:28.452163 20451 solver.cpp:244]     Train net output #1: loss = 0.125022 (* 1 = 0.125022 loss)
I0808 22:11:28.452177 20451 sgd_solver.cpp:106] Iteration 13130, lr = 0.000533173
I0808 22:11:50.759516 20451 solver.cpp:228] Iteration 13140, loss = 0.125095
I0808 22:11:50.759690 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:11:50.759704 20451 solver.cpp:244]     Train net output #1: loss = 0.125095 (* 1 = 0.125095 loss)
I0808 22:11:50.759717 20451 sgd_solver.cpp:106] Iteration 13140, lr = 0.000533
I0808 22:12:13.068994 20451 solver.cpp:228] Iteration 13150, loss = 0.0312591
I0808 22:12:13.069046 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 22:12:13.069059 20451 solver.cpp:244]     Train net output #1: loss = 0.0312592 (* 1 = 0.0312592 loss)
I0808 22:12:13.069072 20451 sgd_solver.cpp:106] Iteration 13150, lr = 0.000532828
I0808 22:12:35.369501 20451 solver.cpp:228] Iteration 13160, loss = 0.281411
I0808 22:12:35.369606 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 22:12:35.369621 20451 solver.cpp:244]     Train net output #1: loss = 0.281411 (* 1 = 0.281411 loss)
I0808 22:12:35.369634 20451 sgd_solver.cpp:106] Iteration 13160, lr = 0.000532655
I0808 22:12:57.667966 20451 solver.cpp:228] Iteration 13170, loss = 0.125049
I0808 22:12:57.668017 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:12:57.668031 20451 solver.cpp:244]     Train net output #1: loss = 0.125049 (* 1 = 0.125049 loss)
I0808 22:12:57.668043 20451 sgd_solver.cpp:106] Iteration 13170, lr = 0.000532483
I0808 22:13:19.971307 20451 solver.cpp:228] Iteration 13180, loss = 0.156345
I0808 22:13:19.971470 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:13:19.971485 20451 solver.cpp:244]     Train net output #1: loss = 0.156345 (* 1 = 0.156345 loss)
I0808 22:13:19.971498 20451 sgd_solver.cpp:106] Iteration 13180, lr = 0.00053231
I0808 22:13:42.267441 20451 solver.cpp:228] Iteration 13190, loss = 0.250136
I0808 22:13:42.267494 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:13:42.267508 20451 solver.cpp:244]     Train net output #1: loss = 0.250137 (* 1 = 0.250137 loss)
I0808 22:13:42.267519 20451 sgd_solver.cpp:106] Iteration 13190, lr = 0.000532138
I0808 22:14:02.353435 20451 solver.cpp:337] Iteration 13200, Testing net (#0)
I0808 22:14:10.872195 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 22:14:10.872242 20451 solver.cpp:404]     Test net output #1: loss = 0.998472 (* 1 = 0.998472 loss)
I0808 22:14:13.073223 20451 solver.cpp:228] Iteration 13200, loss = 0.18754
I0808 22:14:13.073272 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:14:13.073287 20451 solver.cpp:244]     Train net output #1: loss = 0.18754 (* 1 = 0.18754 loss)
I0808 22:14:13.073298 20451 sgd_solver.cpp:106] Iteration 13200, lr = 0.000531966
I0808 22:14:35.358569 20451 solver.cpp:228] Iteration 13210, loss = 0.187642
I0808 22:14:35.358708 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:14:35.358723 20451 solver.cpp:244]     Train net output #1: loss = 0.187642 (* 1 = 0.187642 loss)
I0808 22:14:35.358736 20451 sgd_solver.cpp:106] Iteration 13210, lr = 0.000531794
I0808 22:14:57.661649 20451 solver.cpp:228] Iteration 13220, loss = 0.218858
I0808 22:14:57.661700 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:14:57.661713 20451 solver.cpp:244]     Train net output #1: loss = 0.218859 (* 1 = 0.218859 loss)
I0808 22:14:57.661726 20451 sgd_solver.cpp:106] Iteration 13220, lr = 0.000531622
I0808 22:15:19.961499 20451 solver.cpp:228] Iteration 13230, loss = 0.187616
I0808 22:15:19.961601 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:15:19.961619 20451 solver.cpp:244]     Train net output #1: loss = 0.187616 (* 1 = 0.187616 loss)
I0808 22:15:19.961635 20451 sgd_solver.cpp:106] Iteration 13230, lr = 0.000531451
I0808 22:15:42.266728 20451 solver.cpp:228] Iteration 13240, loss = 0.0312779
I0808 22:15:42.266774 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 22:15:42.266793 20451 solver.cpp:244]     Train net output #1: loss = 0.0312781 (* 1 = 0.0312781 loss)
I0808 22:15:42.266808 20451 sgd_solver.cpp:106] Iteration 13240, lr = 0.000531279
I0808 22:16:04.573460 20451 solver.cpp:228] Iteration 13250, loss = 0.125036
I0808 22:16:04.573647 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:16:04.573665 20451 solver.cpp:244]     Train net output #1: loss = 0.125036 (* 1 = 0.125036 loss)
I0808 22:16:04.573680 20451 sgd_solver.cpp:106] Iteration 13250, lr = 0.000531108
I0808 22:16:26.883324 20451 solver.cpp:228] Iteration 13260, loss = 0.187558
I0808 22:16:26.883368 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:16:26.883386 20451 solver.cpp:244]     Train net output #1: loss = 0.187558 (* 1 = 0.187558 loss)
I0808 22:16:26.883401 20451 sgd_solver.cpp:106] Iteration 13260, lr = 0.000530937
I0808 22:16:49.188586 20451 solver.cpp:228] Iteration 13270, loss = 0.218834
I0808 22:16:49.188706 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:16:49.188726 20451 solver.cpp:244]     Train net output #1: loss = 0.218834 (* 1 = 0.218834 loss)
I0808 22:16:49.188741 20451 sgd_solver.cpp:106] Iteration 13270, lr = 0.000530766
I0808 22:17:11.493266 20451 solver.cpp:228] Iteration 13280, loss = 0.125076
I0808 22:17:11.493314 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:17:11.493341 20451 solver.cpp:244]     Train net output #1: loss = 0.125076 (* 1 = 0.125076 loss)
I0808 22:17:11.493357 20451 sgd_solver.cpp:106] Iteration 13280, lr = 0.000530595
I0808 22:17:33.789743 20451 solver.cpp:228] Iteration 13290, loss = 0.0626197
I0808 22:17:33.789922 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:17:33.789942 20451 solver.cpp:244]     Train net output #1: loss = 0.0626199 (* 1 = 0.0626199 loss)
I0808 22:17:33.789957 20451 sgd_solver.cpp:106] Iteration 13290, lr = 0.000530424
I0808 22:17:53.871228 20451 solver.cpp:337] Iteration 13300, Testing net (#0)
I0808 22:18:02.389214 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 22:18:02.389267 20451 solver.cpp:404]     Test net output #1: loss = 1.00819 (* 1 = 1.00819 loss)
I0808 22:18:04.591125 20451 solver.cpp:228] Iteration 13300, loss = 0.187602
I0808 22:18:04.591326 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:18:04.591341 20451 solver.cpp:244]     Train net output #1: loss = 0.187602 (* 1 = 0.187602 loss)
I0808 22:18:04.591353 20451 sgd_solver.cpp:106] Iteration 13300, lr = 0.000530253
I0808 22:18:26.871786 20451 solver.cpp:228] Iteration 13310, loss = 0.125265
I0808 22:18:26.871836 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:18:26.871850 20451 solver.cpp:244]     Train net output #1: loss = 0.125265 (* 1 = 0.125265 loss)
I0808 22:18:26.871862 20451 sgd_solver.cpp:106] Iteration 13310, lr = 0.000530082
I0808 22:18:49.177485 20451 solver.cpp:228] Iteration 13320, loss = 0.156489
I0808 22:18:49.177655 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:18:49.177672 20451 solver.cpp:244]     Train net output #1: loss = 0.15649 (* 1 = 0.15649 loss)
I0808 22:18:49.177686 20451 sgd_solver.cpp:106] Iteration 13320, lr = 0.000529912
I0808 22:19:11.489780 20451 solver.cpp:228] Iteration 13330, loss = 0.12511
I0808 22:19:11.489832 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:19:11.489846 20451 solver.cpp:244]     Train net output #1: loss = 0.12511 (* 1 = 0.12511 loss)
I0808 22:19:11.489858 20451 sgd_solver.cpp:106] Iteration 13330, lr = 0.000529741
I0808 22:19:33.790992 20451 solver.cpp:228] Iteration 13340, loss = 0.219166
I0808 22:19:33.791175 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:19:33.791190 20451 solver.cpp:244]     Train net output #1: loss = 0.219166 (* 1 = 0.219166 loss)
I0808 22:19:33.791203 20451 sgd_solver.cpp:106] Iteration 13340, lr = 0.000529571
I0808 22:19:56.099834 20451 solver.cpp:228] Iteration 13350, loss = 0.125055
I0808 22:19:56.099879 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:19:56.099905 20451 solver.cpp:244]     Train net output #1: loss = 0.125055 (* 1 = 0.125055 loss)
I0808 22:19:56.099920 20451 sgd_solver.cpp:106] Iteration 13350, lr = 0.000529401
I0808 22:20:18.406898 20451 solver.cpp:228] Iteration 13360, loss = 0.219195
I0808 22:20:18.407086 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:20:18.407101 20451 solver.cpp:244]     Train net output #1: loss = 0.219195 (* 1 = 0.219195 loss)
I0808 22:20:18.407115 20451 sgd_solver.cpp:106] Iteration 13360, lr = 0.000529231
I0808 22:20:40.712316 20451 solver.cpp:228] Iteration 13370, loss = 0.37535
I0808 22:20:40.712427 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:20:40.712471 20451 solver.cpp:244]     Train net output #1: loss = 0.37535 (* 1 = 0.37535 loss)
I0808 22:20:40.712512 20451 sgd_solver.cpp:106] Iteration 13370, lr = 0.000529061
I0808 22:21:03.022197 20451 solver.cpp:228] Iteration 13380, loss = 0.218978
I0808 22:21:03.022377 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:21:03.022395 20451 solver.cpp:244]     Train net output #1: loss = 0.218978 (* 1 = 0.218978 loss)
I0808 22:21:03.022410 20451 sgd_solver.cpp:106] Iteration 13380, lr = 0.000528892
I0808 22:21:25.318289 20451 solver.cpp:228] Iteration 13390, loss = 0.125011
I0808 22:21:25.318337 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:21:25.318367 20451 solver.cpp:244]     Train net output #1: loss = 0.125011 (* 1 = 0.125011 loss)
I0808 22:21:25.318382 20451 sgd_solver.cpp:106] Iteration 13390, lr = 0.000528722
I0808 22:21:45.394464 20451 solver.cpp:337] Iteration 13400, Testing net (#0)
I0808 22:21:53.915719 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 22:21:53.915767 20451 solver.cpp:404]     Test net output #1: loss = 1.00401 (* 1 = 1.00401 loss)
I0808 22:21:56.119673 20451 solver.cpp:228] Iteration 13400, loss = 0.344202
I0808 22:21:56.119724 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 22:21:56.119738 20451 solver.cpp:244]     Train net output #1: loss = 0.344202 (* 1 = 0.344202 loss)
I0808 22:21:56.119750 20451 sgd_solver.cpp:106] Iteration 13400, lr = 0.000528553
I0808 22:22:18.405853 20451 solver.cpp:228] Iteration 13410, loss = 0.125161
I0808 22:22:18.406064 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:22:18.406078 20451 solver.cpp:244]     Train net output #1: loss = 0.125161 (* 1 = 0.125161 loss)
I0808 22:22:18.406091 20451 sgd_solver.cpp:106] Iteration 13410, lr = 0.000528383
I0808 22:22:40.706069 20451 solver.cpp:228] Iteration 13420, loss = 0.219153
I0808 22:22:40.706115 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:22:40.706135 20451 solver.cpp:244]     Train net output #1: loss = 0.219154 (* 1 = 0.219154 loss)
I0808 22:22:40.706148 20451 sgd_solver.cpp:106] Iteration 13420, lr = 0.000528214
I0808 22:23:03.003878 20451 solver.cpp:228] Iteration 13430, loss = 0.187533
I0808 22:23:03.004056 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:23:03.004070 20451 solver.cpp:244]     Train net output #1: loss = 0.187533 (* 1 = 0.187533 loss)
I0808 22:23:03.004083 20451 sgd_solver.cpp:106] Iteration 13430, lr = 0.000528045
I0808 22:23:25.298966 20451 solver.cpp:228] Iteration 13440, loss = 0.125106
I0808 22:23:25.299018 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:23:25.299032 20451 solver.cpp:244]     Train net output #1: loss = 0.125106 (* 1 = 0.125106 loss)
I0808 22:23:25.299043 20451 sgd_solver.cpp:106] Iteration 13440, lr = 0.000527876
I0808 22:23:47.601341 20451 solver.cpp:228] Iteration 13450, loss = 0.187599
I0808 22:23:47.601534 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:23:47.601557 20451 solver.cpp:244]     Train net output #1: loss = 0.187599 (* 1 = 0.187599 loss)
I0808 22:23:47.601575 20451 sgd_solver.cpp:106] Iteration 13450, lr = 0.000527707
I0808 22:24:09.907392 20451 solver.cpp:228] Iteration 13460, loss = 0.250025
I0808 22:24:09.907445 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 22:24:09.907459 20451 solver.cpp:244]     Train net output #1: loss = 0.250025 (* 1 = 0.250025 loss)
I0808 22:24:09.907472 20451 sgd_solver.cpp:106] Iteration 13460, lr = 0.000527538
I0808 22:24:32.217469 20451 solver.cpp:228] Iteration 13470, loss = 0.156336
I0808 22:24:32.217648 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:24:32.217663 20451 solver.cpp:244]     Train net output #1: loss = 0.156336 (* 1 = 0.156336 loss)
I0808 22:24:32.217675 20451 sgd_solver.cpp:106] Iteration 13470, lr = 0.00052737
I0808 22:24:54.525748 20451 solver.cpp:228] Iteration 13480, loss = 0.187761
I0808 22:24:54.525804 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:24:54.525817 20451 solver.cpp:244]     Train net output #1: loss = 0.187762 (* 1 = 0.187762 loss)
I0808 22:24:54.525830 20451 sgd_solver.cpp:106] Iteration 13480, lr = 0.000527201
I0808 22:25:16.837507 20451 solver.cpp:228] Iteration 13490, loss = 0.250121
I0808 22:25:16.837602 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:25:16.837617 20451 solver.cpp:244]     Train net output #1: loss = 0.250121 (* 1 = 0.250121 loss)
I0808 22:25:16.837630 20451 sgd_solver.cpp:106] Iteration 13490, lr = 0.000527033
I0808 22:25:36.919759 20451 solver.cpp:337] Iteration 13500, Testing net (#0)
I0808 22:25:45.446583 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0808 22:25:45.446633 20451 solver.cpp:404]     Test net output #1: loss = 0.961067 (* 1 = 0.961067 loss)
I0808 22:25:47.650104 20451 solver.cpp:228] Iteration 13500, loss = 0.156561
I0808 22:25:47.650197 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:25:47.650213 20451 solver.cpp:244]     Train net output #1: loss = 0.156561 (* 1 = 0.156561 loss)
I0808 22:25:47.650225 20451 sgd_solver.cpp:106] Iteration 13500, lr = 0.000526865
I0808 22:26:09.922330 20451 solver.cpp:228] Iteration 13510, loss = 0.125337
I0808 22:26:09.922374 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:26:09.922389 20451 solver.cpp:244]     Train net output #1: loss = 0.125338 (* 1 = 0.125338 loss)
I0808 22:26:09.922400 20451 sgd_solver.cpp:106] Iteration 13510, lr = 0.000526697
I0808 22:26:32.221467 20451 solver.cpp:228] Iteration 13520, loss = 0.12506
I0808 22:26:32.221678 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:26:32.221694 20451 solver.cpp:244]     Train net output #1: loss = 0.12506 (* 1 = 0.12506 loss)
I0808 22:26:32.221706 20451 sgd_solver.cpp:106] Iteration 13520, lr = 0.000526529
I0808 22:26:54.526080 20451 solver.cpp:228] Iteration 13530, loss = 0.187596
I0808 22:26:54.526131 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:26:54.526144 20451 solver.cpp:244]     Train net output #1: loss = 0.187596 (* 1 = 0.187596 loss)
I0808 22:26:54.526156 20451 sgd_solver.cpp:106] Iteration 13530, lr = 0.000526361
I0808 22:27:16.841688 20451 solver.cpp:228] Iteration 13540, loss = 0.187544
I0808 22:27:16.841802 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:27:16.841822 20451 solver.cpp:244]     Train net output #1: loss = 0.187544 (* 1 = 0.187544 loss)
I0808 22:27:16.841837 20451 sgd_solver.cpp:106] Iteration 13540, lr = 0.000526193
I0808 22:27:39.146667 20451 solver.cpp:228] Iteration 13550, loss = 0.15627
I0808 22:27:39.146718 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:27:39.146731 20451 solver.cpp:244]     Train net output #1: loss = 0.15627 (* 1 = 0.15627 loss)
I0808 22:27:39.146744 20451 sgd_solver.cpp:106] Iteration 13550, lr = 0.000526026
I0808 22:28:01.453155 20451 solver.cpp:228] Iteration 13560, loss = 0.187541
I0808 22:28:01.453333 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:28:01.453349 20451 solver.cpp:244]     Train net output #1: loss = 0.187541 (* 1 = 0.187541 loss)
I0808 22:28:01.453362 20451 sgd_solver.cpp:106] Iteration 13560, lr = 0.000525858
I0808 22:28:23.764349 20451 solver.cpp:228] Iteration 13570, loss = 0.250144
I0808 22:28:23.764402 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:28:23.764416 20451 solver.cpp:244]     Train net output #1: loss = 0.250144 (* 1 = 0.250144 loss)
I0808 22:28:23.764428 20451 sgd_solver.cpp:106] Iteration 13570, lr = 0.000525691
I0808 22:28:46.079988 20451 solver.cpp:228] Iteration 13580, loss = 0.281784
I0808 22:28:46.080169 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 22:28:46.080184 20451 solver.cpp:244]     Train net output #1: loss = 0.281784 (* 1 = 0.281784 loss)
I0808 22:28:46.080198 20451 sgd_solver.cpp:106] Iteration 13580, lr = 0.000525524
I0808 22:29:08.389626 20451 solver.cpp:228] Iteration 13590, loss = 0.18755
I0808 22:29:08.389679 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:29:08.389693 20451 solver.cpp:244]     Train net output #1: loss = 0.18755 (* 1 = 0.18755 loss)
I0808 22:29:08.389705 20451 sgd_solver.cpp:106] Iteration 13590, lr = 0.000525356
I0808 22:29:28.470160 20451 solver.cpp:337] Iteration 13600, Testing net (#0)
I0808 22:29:36.981647 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 22:29:36.981693 20451 solver.cpp:404]     Test net output #1: loss = 0.993883 (* 1 = 0.993883 loss)
I0808 22:29:39.184634 20451 solver.cpp:228] Iteration 13600, loss = 0.218819
I0808 22:29:39.184686 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:29:39.184700 20451 solver.cpp:244]     Train net output #1: loss = 0.218819 (* 1 = 0.218819 loss)
I0808 22:29:39.184712 20451 sgd_solver.cpp:106] Iteration 13600, lr = 0.000525189
I0808 22:30:01.470099 20451 solver.cpp:228] Iteration 13610, loss = 0.250124
I0808 22:30:01.470274 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:30:01.470290 20451 solver.cpp:244]     Train net output #1: loss = 0.250124 (* 1 = 0.250124 loss)
I0808 22:30:01.470302 20451 sgd_solver.cpp:106] Iteration 13610, lr = 0.000525023
I0808 22:30:23.769781 20451 solver.cpp:228] Iteration 13620, loss = 0.0625238
I0808 22:30:23.769824 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 22:30:23.769843 20451 solver.cpp:244]     Train net output #1: loss = 0.0625239 (* 1 = 0.0625239 loss)
I0808 22:30:23.769858 20451 sgd_solver.cpp:106] Iteration 13620, lr = 0.000524856
I0808 22:30:46.069023 20451 solver.cpp:228] Iteration 13630, loss = 0.125012
I0808 22:30:46.069243 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:30:46.069262 20451 solver.cpp:244]     Train net output #1: loss = 0.125012 (* 1 = 0.125012 loss)
I0808 22:30:46.069278 20451 sgd_solver.cpp:106] Iteration 13630, lr = 0.000524689
I0808 22:31:08.366919 20451 solver.cpp:228] Iteration 13640, loss = 0.156285
I0808 22:31:08.366973 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:31:08.366987 20451 solver.cpp:244]     Train net output #1: loss = 0.156286 (* 1 = 0.156286 loss)
I0808 22:31:08.366999 20451 sgd_solver.cpp:106] Iteration 13640, lr = 0.000524523
I0808 22:31:30.663358 20451 solver.cpp:228] Iteration 13650, loss = 0.18762
I0808 22:31:30.663539 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:31:30.663555 20451 solver.cpp:244]     Train net output #1: loss = 0.18762 (* 1 = 0.18762 loss)
I0808 22:31:30.663568 20451 sgd_solver.cpp:106] Iteration 13650, lr = 0.000524356
I0808 22:31:52.962998 20451 solver.cpp:228] Iteration 13660, loss = 0.0626273
I0808 22:31:52.963053 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 22:31:52.963068 20451 solver.cpp:244]     Train net output #1: loss = 0.0626274 (* 1 = 0.0626274 loss)
I0808 22:31:52.963080 20451 sgd_solver.cpp:106] Iteration 13660, lr = 0.00052419
I0808 22:32:15.268314 20451 solver.cpp:228] Iteration 13670, loss = 0.0939085
I0808 22:32:15.268503 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 22:32:15.268519 20451 solver.cpp:244]     Train net output #1: loss = 0.0939086 (* 1 = 0.0939086 loss)
I0808 22:32:15.268532 20451 sgd_solver.cpp:106] Iteration 13670, lr = 0.000524024
I0808 22:32:37.578899 20451 solver.cpp:228] Iteration 13680, loss = 0.0625584
I0808 22:32:37.578953 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 22:32:37.578968 20451 solver.cpp:244]     Train net output #1: loss = 0.0625585 (* 1 = 0.0625585 loss)
I0808 22:32:37.578980 20451 sgd_solver.cpp:106] Iteration 13680, lr = 0.000523858
I0808 22:32:59.891911 20451 solver.cpp:228] Iteration 13690, loss = 0.156583
I0808 22:32:59.892101 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:32:59.892117 20451 solver.cpp:244]     Train net output #1: loss = 0.156583 (* 1 = 0.156583 loss)
I0808 22:32:59.892128 20451 sgd_solver.cpp:106] Iteration 13690, lr = 0.000523692
I0808 22:33:19.977552 20451 solver.cpp:337] Iteration 13700, Testing net (#0)
I0808 22:33:28.501588 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 22:33:28.501639 20451 solver.cpp:404]     Test net output #1: loss = 0.998491 (* 1 = 0.998491 loss)
I0808 22:33:30.705273 20451 solver.cpp:228] Iteration 13700, loss = 0.218769
I0808 22:33:30.705456 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:33:30.705476 20451 solver.cpp:244]     Train net output #1: loss = 0.218769 (* 1 = 0.218769 loss)
I0808 22:33:30.705488 20451 sgd_solver.cpp:106] Iteration 13700, lr = 0.000523527
I0808 22:33:52.987555 20451 solver.cpp:228] Iteration 13710, loss = 0.187637
I0808 22:33:52.987665 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:33:52.987705 20451 solver.cpp:244]     Train net output #1: loss = 0.187637 (* 1 = 0.187637 loss)
I0808 22:33:52.987741 20451 sgd_solver.cpp:106] Iteration 13710, lr = 0.000523361
I0808 22:34:15.288944 20451 solver.cpp:228] Iteration 13720, loss = 0.0937897
I0808 22:34:15.289126 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 22:34:15.289146 20451 solver.cpp:244]     Train net output #1: loss = 0.0937898 (* 1 = 0.0937898 loss)
I0808 22:34:15.289161 20451 sgd_solver.cpp:106] Iteration 13720, lr = 0.000523195
I0808 22:34:37.598546 20451 solver.cpp:228] Iteration 13730, loss = 0.0938312
I0808 22:34:37.598599 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 22:34:37.598615 20451 solver.cpp:244]     Train net output #1: loss = 0.0938313 (* 1 = 0.0938313 loss)
I0808 22:34:37.598628 20451 sgd_solver.cpp:106] Iteration 13730, lr = 0.00052303
I0808 22:34:59.904191 20451 solver.cpp:228] Iteration 13740, loss = 0.2188
I0808 22:34:59.904341 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:34:59.904362 20451 solver.cpp:244]     Train net output #1: loss = 0.218801 (* 1 = 0.218801 loss)
I0808 22:34:59.904376 20451 sgd_solver.cpp:106] Iteration 13740, lr = 0.000522865
I0808 22:35:22.209287 20451 solver.cpp:228] Iteration 13750, loss = 0.156302
I0808 22:35:22.209337 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:35:22.209352 20451 solver.cpp:244]     Train net output #1: loss = 0.156302 (* 1 = 0.156302 loss)
I0808 22:35:22.209363 20451 sgd_solver.cpp:106] Iteration 13750, lr = 0.0005227
I0808 22:35:44.496286 20451 solver.cpp:228] Iteration 13760, loss = 0.156334
I0808 22:35:44.496395 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:35:44.496410 20451 solver.cpp:244]     Train net output #1: loss = 0.156334 (* 1 = 0.156334 loss)
I0808 22:35:44.496423 20451 sgd_solver.cpp:106] Iteration 13760, lr = 0.000522535
I0808 22:36:06.794852 20451 solver.cpp:228] Iteration 13770, loss = 0.343986
I0808 22:36:06.794905 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 22:36:06.794919 20451 solver.cpp:244]     Train net output #1: loss = 0.343986 (* 1 = 0.343986 loss)
I0808 22:36:06.794931 20451 sgd_solver.cpp:106] Iteration 13770, lr = 0.00052237
I0808 22:36:29.089119 20451 solver.cpp:228] Iteration 13780, loss = 0.125039
I0808 22:36:29.089296 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:36:29.089311 20451 solver.cpp:244]     Train net output #1: loss = 0.125039 (* 1 = 0.125039 loss)
I0808 22:36:29.089323 20451 sgd_solver.cpp:106] Iteration 13780, lr = 0.000522205
I0808 22:36:51.378895 20451 solver.cpp:228] Iteration 13790, loss = 0.187652
I0808 22:36:51.378945 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:36:51.378958 20451 solver.cpp:244]     Train net output #1: loss = 0.187652 (* 1 = 0.187652 loss)
I0808 22:36:51.378970 20451 sgd_solver.cpp:106] Iteration 13790, lr = 0.00052204
I0808 22:37:11.439322 20451 solver.cpp:337] Iteration 13800, Testing net (#0)
I0808 22:37:19.963012 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0808 22:37:19.963063 20451 solver.cpp:404]     Test net output #1: loss = 0.989264 (* 1 = 0.989264 loss)
I0808 22:37:22.167007 20451 solver.cpp:228] Iteration 13800, loss = 0.0625183
I0808 22:37:22.167057 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 22:37:22.167070 20451 solver.cpp:244]     Train net output #1: loss = 0.0625184 (* 1 = 0.0625184 loss)
I0808 22:37:22.167083 20451 sgd_solver.cpp:106] Iteration 13800, lr = 0.000521876
I0808 22:37:44.441054 20451 solver.cpp:228] Iteration 13810, loss = 0.0938283
I0808 22:37:44.441233 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 22:37:44.441249 20451 solver.cpp:244]     Train net output #1: loss = 0.0938285 (* 1 = 0.0938285 loss)
I0808 22:37:44.441262 20451 sgd_solver.cpp:106] Iteration 13810, lr = 0.000521712
I0808 22:38:06.736544 20451 solver.cpp:228] Iteration 13820, loss = 0.125013
I0808 22:38:06.736587 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:38:06.736613 20451 solver.cpp:244]     Train net output #1: loss = 0.125013 (* 1 = 0.125013 loss)
I0808 22:38:06.736629 20451 sgd_solver.cpp:106] Iteration 13820, lr = 0.000521547
I0808 22:38:29.033339 20451 solver.cpp:228] Iteration 13830, loss = 0.250097
I0808 22:38:29.033519 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:38:29.033535 20451 solver.cpp:244]     Train net output #1: loss = 0.250097 (* 1 = 0.250097 loss)
I0808 22:38:29.033548 20451 sgd_solver.cpp:106] Iteration 13830, lr = 0.000521383
I0808 22:38:51.332592 20451 solver.cpp:228] Iteration 13840, loss = 0.343812
I0808 22:38:51.332643 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 22:38:51.332658 20451 solver.cpp:244]     Train net output #1: loss = 0.343812 (* 1 = 0.343812 loss)
I0808 22:38:51.332669 20451 sgd_solver.cpp:106] Iteration 13840, lr = 0.000521219
I0808 22:39:13.635084 20451 solver.cpp:228] Iteration 13850, loss = 0.375212
I0808 22:39:13.635305 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0808 22:39:13.635324 20451 solver.cpp:244]     Train net output #1: loss = 0.375212 (* 1 = 0.375212 loss)
I0808 22:39:13.635339 20451 sgd_solver.cpp:106] Iteration 13850, lr = 0.000521055
I0808 22:39:35.939167 20451 solver.cpp:228] Iteration 13860, loss = 0.125022
I0808 22:39:35.939218 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:39:35.939232 20451 solver.cpp:244]     Train net output #1: loss = 0.125022 (* 1 = 0.125022 loss)
I0808 22:39:35.939244 20451 sgd_solver.cpp:106] Iteration 13860, lr = 0.000520891
I0808 22:39:58.233022 20451 solver.cpp:228] Iteration 13870, loss = 0.218775
I0808 22:39:58.233204 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:39:58.233220 20451 solver.cpp:244]     Train net output #1: loss = 0.218775 (* 1 = 0.218775 loss)
I0808 22:39:58.233233 20451 sgd_solver.cpp:106] Iteration 13870, lr = 0.000520728
I0808 22:40:20.542441 20451 solver.cpp:228] Iteration 13880, loss = 0.250108
I0808 22:40:20.542493 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:40:20.542507 20451 solver.cpp:244]     Train net output #1: loss = 0.250109 (* 1 = 0.250109 loss)
I0808 22:40:20.542520 20451 sgd_solver.cpp:106] Iteration 13880, lr = 0.000520564
I0808 22:40:42.848356 20451 solver.cpp:228] Iteration 13890, loss = 0.187519
I0808 22:40:42.848528 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:40:42.848543 20451 solver.cpp:244]     Train net output #1: loss = 0.18752 (* 1 = 0.18752 loss)
I0808 22:40:42.848556 20451 sgd_solver.cpp:106] Iteration 13890, lr = 0.000520401
I0808 22:41:02.933519 20451 solver.cpp:337] Iteration 13900, Testing net (#0)
I0808 22:41:11.463383 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0808 22:41:11.463435 20451 solver.cpp:404]     Test net output #1: loss = 1.03616 (* 1 = 1.03616 loss)
I0808 22:41:13.663177 20451 solver.cpp:228] Iteration 13900, loss = 0.0937793
I0808 22:41:13.663357 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 22:41:13.663372 20451 solver.cpp:244]     Train net output #1: loss = 0.0937794 (* 1 = 0.0937794 loss)
I0808 22:41:13.663385 20451 sgd_solver.cpp:106] Iteration 13900, lr = 0.000520237
I0808 22:41:35.940299 20451 solver.cpp:228] Iteration 13910, loss = 0.0625527
I0808 22:41:35.940351 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 22:41:35.940366 20451 solver.cpp:244]     Train net output #1: loss = 0.0625529 (* 1 = 0.0625529 loss)
I0808 22:41:35.940377 20451 sgd_solver.cpp:106] Iteration 13910, lr = 0.000520074
I0808 22:41:58.229528 20451 solver.cpp:228] Iteration 13920, loss = 0.125064
I0808 22:41:58.229739 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:41:58.229754 20451 solver.cpp:244]     Train net output #1: loss = 0.125064 (* 1 = 0.125064 loss)
I0808 22:41:58.229768 20451 sgd_solver.cpp:106] Iteration 13920, lr = 0.000519911
I0808 22:42:20.545300 20451 solver.cpp:228] Iteration 13930, loss = 0.18757
I0808 22:42:20.545349 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:42:20.545364 20451 solver.cpp:244]     Train net output #1: loss = 0.18757 (* 1 = 0.18757 loss)
I0808 22:42:20.545377 20451 sgd_solver.cpp:106] Iteration 13930, lr = 0.000519748
I0808 22:42:42.854687 20451 solver.cpp:228] Iteration 13940, loss = 0.187591
I0808 22:42:42.854872 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:42:42.854888 20451 solver.cpp:244]     Train net output #1: loss = 0.187591 (* 1 = 0.187591 loss)
I0808 22:42:42.854902 20451 sgd_solver.cpp:106] Iteration 13940, lr = 0.000519585
I0808 22:43:05.164227 20451 solver.cpp:228] Iteration 13950, loss = 0.218842
I0808 22:43:05.164280 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:43:05.164294 20451 solver.cpp:244]     Train net output #1: loss = 0.218843 (* 1 = 0.218843 loss)
I0808 22:43:05.164306 20451 sgd_solver.cpp:106] Iteration 13950, lr = 0.000519423
I0808 22:43:27.473386 20451 solver.cpp:228] Iteration 13960, loss = 0.218781
I0808 22:43:27.473611 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:43:27.473626 20451 solver.cpp:244]     Train net output #1: loss = 0.218781 (* 1 = 0.218781 loss)
I0808 22:43:27.473639 20451 sgd_solver.cpp:106] Iteration 13960, lr = 0.00051926
I0808 22:43:49.788557 20451 solver.cpp:228] Iteration 13970, loss = 0.125032
I0808 22:43:49.788602 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 22:43:49.788621 20451 solver.cpp:244]     Train net output #1: loss = 0.125032 (* 1 = 0.125032 loss)
I0808 22:43:49.788636 20451 sgd_solver.cpp:106] Iteration 13970, lr = 0.000519098
I0808 22:44:12.104356 20451 solver.cpp:228] Iteration 13980, loss = 0.156373
I0808 22:44:12.104535 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:44:12.104552 20451 solver.cpp:244]     Train net output #1: loss = 0.156374 (* 1 = 0.156374 loss)
I0808 22:44:12.104563 20451 sgd_solver.cpp:106] Iteration 13980, lr = 0.000518935
I0808 22:44:34.411051 20451 solver.cpp:228] Iteration 13990, loss = 0.250055
I0808 22:44:34.411115 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:44:34.411137 20451 solver.cpp:244]     Train net output #1: loss = 0.250055 (* 1 = 0.250055 loss)
I0808 22:44:34.411154 20451 sgd_solver.cpp:106] Iteration 13990, lr = 0.000518773
I0808 22:44:54.487455 20451 solver.cpp:337] Iteration 14000, Testing net (#0)
I0808 22:45:03.011329 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 22:45:03.011376 20451 solver.cpp:404]     Test net output #1: loss = 0.985066 (* 1 = 0.985066 loss)
I0808 22:45:05.215315 20451 solver.cpp:228] Iteration 14000, loss = 0.218974
I0808 22:45:05.215361 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:45:05.215381 20451 solver.cpp:244]     Train net output #1: loss = 0.218974 (* 1 = 0.218974 loss)
I0808 22:45:05.215406 20451 sgd_solver.cpp:106] Iteration 14000, lr = 0.000518611
I0808 22:45:27.506232 20451 solver.cpp:228] Iteration 14010, loss = 0.187572
I0808 22:45:27.506404 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:45:27.506418 20451 solver.cpp:244]     Train net output #1: loss = 0.187572 (* 1 = 0.187572 loss)
I0808 22:45:27.506431 20451 sgd_solver.cpp:106] Iteration 14010, lr = 0.000518449
I0808 22:45:49.809996 20451 solver.cpp:228] Iteration 14020, loss = 0.156313
I0808 22:45:49.810045 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:45:49.810060 20451 solver.cpp:244]     Train net output #1: loss = 0.156313 (* 1 = 0.156313 loss)
I0808 22:45:49.810072 20451 sgd_solver.cpp:106] Iteration 14020, lr = 0.000518287
I0808 22:46:12.121582 20451 solver.cpp:228] Iteration 14030, loss = 0.281628
I0808 22:46:12.121737 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 22:46:12.121752 20451 solver.cpp:244]     Train net output #1: loss = 0.281628 (* 1 = 0.281628 loss)
I0808 22:46:12.121764 20451 sgd_solver.cpp:106] Iteration 14030, lr = 0.000518125
I0808 22:46:34.427733 20451 solver.cpp:228] Iteration 14040, loss = 0.0625904
I0808 22:46:34.427780 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 22:46:34.427798 20451 solver.cpp:244]     Train net output #1: loss = 0.0625906 (* 1 = 0.0625906 loss)
I0808 22:46:34.427814 20451 sgd_solver.cpp:106] Iteration 14040, lr = 0.000517964
I0808 22:46:56.730701 20451 solver.cpp:228] Iteration 14050, loss = 0.156327
I0808 22:46:56.730893 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:46:56.730911 20451 solver.cpp:244]     Train net output #1: loss = 0.156327 (* 1 = 0.156327 loss)
I0808 22:46:56.730927 20451 sgd_solver.cpp:106] Iteration 14050, lr = 0.000517802
I0808 22:47:19.022938 20451 solver.cpp:228] Iteration 14060, loss = 0.187612
I0808 22:47:19.022981 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:47:19.023007 20451 solver.cpp:244]     Train net output #1: loss = 0.187613 (* 1 = 0.187613 loss)
I0808 22:47:19.023025 20451 sgd_solver.cpp:106] Iteration 14060, lr = 0.000517641
I0808 22:47:41.326246 20451 solver.cpp:228] Iteration 14070, loss = 0.218777
I0808 22:47:41.326465 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:47:41.326481 20451 solver.cpp:244]     Train net output #1: loss = 0.218777 (* 1 = 0.218777 loss)
I0808 22:47:41.326493 20451 sgd_solver.cpp:106] Iteration 14070, lr = 0.000517479
I0808 22:48:03.631041 20451 solver.cpp:228] Iteration 14080, loss = 0.125071
I0808 22:48:03.631090 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:48:03.631103 20451 solver.cpp:244]     Train net output #1: loss = 0.125071 (* 1 = 0.125071 loss)
I0808 22:48:03.631114 20451 sgd_solver.cpp:106] Iteration 14080, lr = 0.000517318
I0808 22:48:25.937583 20451 solver.cpp:228] Iteration 14090, loss = 0.281366
I0808 22:48:25.937762 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 22:48:25.937778 20451 solver.cpp:244]     Train net output #1: loss = 0.281366 (* 1 = 0.281366 loss)
I0808 22:48:25.937791 20451 sgd_solver.cpp:106] Iteration 14090, lr = 0.000517157
I0808 22:48:46.016878 20451 solver.cpp:337] Iteration 14100, Testing net (#0)
I0808 22:48:54.538784 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0808 22:48:54.538836 20451 solver.cpp:404]     Test net output #1: loss = 0.970654 (* 1 = 0.970654 loss)
I0808 22:48:56.744258 20451 solver.cpp:228] Iteration 14100, loss = 0.0625321
I0808 22:48:56.744423 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 22:48:56.744438 20451 solver.cpp:244]     Train net output #1: loss = 0.0625322 (* 1 = 0.0625322 loss)
I0808 22:48:56.744451 20451 sgd_solver.cpp:106] Iteration 14100, lr = 0.000516996
I0808 22:49:19.024997 20451 solver.cpp:228] Iteration 14110, loss = 0.187586
I0808 22:49:19.025049 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:49:19.025063 20451 solver.cpp:244]     Train net output #1: loss = 0.187586 (* 1 = 0.187586 loss)
I0808 22:49:19.025075 20451 sgd_solver.cpp:106] Iteration 14110, lr = 0.000516835
I0808 22:49:41.326807 20451 solver.cpp:228] Iteration 14120, loss = 0.187622
I0808 22:49:41.326982 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:49:41.326997 20451 solver.cpp:244]     Train net output #1: loss = 0.187622 (* 1 = 0.187622 loss)
I0808 22:49:41.327009 20451 sgd_solver.cpp:106] Iteration 14120, lr = 0.000516675
I0808 22:50:03.629509 20451 solver.cpp:228] Iteration 14130, loss = 0.187575
I0808 22:50:03.629559 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:50:03.629571 20451 solver.cpp:244]     Train net output #1: loss = 0.187575 (* 1 = 0.187575 loss)
I0808 22:50:03.629583 20451 sgd_solver.cpp:106] Iteration 14130, lr = 0.000516514
I0808 22:50:25.938143 20451 solver.cpp:228] Iteration 14140, loss = 0.187646
I0808 22:50:25.938246 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:50:25.938261 20451 solver.cpp:244]     Train net output #1: loss = 0.187646 (* 1 = 0.187646 loss)
I0808 22:50:25.938273 20451 sgd_solver.cpp:106] Iteration 14140, lr = 0.000516353
I0808 22:50:48.241629 20451 solver.cpp:228] Iteration 14150, loss = 0.0937701
I0808 22:50:48.241683 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 22:50:48.241698 20451 solver.cpp:244]     Train net output #1: loss = 0.0937703 (* 1 = 0.0937703 loss)
I0808 22:50:48.241709 20451 sgd_solver.cpp:106] Iteration 14150, lr = 0.000516193
I0808 22:51:10.548444 20451 solver.cpp:228] Iteration 14160, loss = 0.187579
I0808 22:51:10.548624 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:51:10.548641 20451 solver.cpp:244]     Train net output #1: loss = 0.187579 (* 1 = 0.187579 loss)
I0808 22:51:10.548657 20451 sgd_solver.cpp:106] Iteration 14160, lr = 0.000516033
I0808 22:51:32.852816 20451 solver.cpp:228] Iteration 14170, loss = 0.156283
I0808 22:51:32.852859 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:51:32.852874 20451 solver.cpp:244]     Train net output #1: loss = 0.156283 (* 1 = 0.156283 loss)
I0808 22:51:32.852885 20451 sgd_solver.cpp:106] Iteration 14170, lr = 0.000515873
I0808 22:51:55.156566 20451 solver.cpp:228] Iteration 14180, loss = 0.187557
I0808 22:51:55.156774 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:51:55.156790 20451 solver.cpp:244]     Train net output #1: loss = 0.187557 (* 1 = 0.187557 loss)
I0808 22:51:55.156802 20451 sgd_solver.cpp:106] Iteration 14180, lr = 0.000515713
I0808 22:52:17.463850 20451 solver.cpp:228] Iteration 14190, loss = 0.2188
I0808 22:52:17.463901 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:52:17.463914 20451 solver.cpp:244]     Train net output #1: loss = 0.2188 (* 1 = 0.2188 loss)
I0808 22:52:17.463927 20451 sgd_solver.cpp:106] Iteration 14190, lr = 0.000515553
I0808 22:52:37.542594 20451 solver.cpp:337] Iteration 14200, Testing net (#0)
I0808 22:52:46.051352 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 22:52:46.051401 20451 solver.cpp:404]     Test net output #1: loss = 1.00832 (* 1 = 1.00832 loss)
I0808 22:52:48.254679 20451 solver.cpp:228] Iteration 14200, loss = 0.18764
I0808 22:52:48.254730 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:52:48.254745 20451 solver.cpp:244]     Train net output #1: loss = 0.18764 (* 1 = 0.18764 loss)
I0808 22:52:48.254756 20451 sgd_solver.cpp:106] Iteration 14200, lr = 0.000515393
I0808 22:53:10.529147 20451 solver.cpp:228] Iteration 14210, loss = 0.187524
I0808 22:53:10.529328 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:53:10.529345 20451 solver.cpp:244]     Train net output #1: loss = 0.187524 (* 1 = 0.187524 loss)
I0808 22:53:10.529357 20451 sgd_solver.cpp:106] Iteration 14210, lr = 0.000515233
I0808 22:53:32.826623 20451 solver.cpp:228] Iteration 14220, loss = 0.0625091
I0808 22:53:32.826679 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 22:53:32.826694 20451 solver.cpp:244]     Train net output #1: loss = 0.0625093 (* 1 = 0.0625093 loss)
I0808 22:53:32.826706 20451 sgd_solver.cpp:106] Iteration 14220, lr = 0.000515074
I0808 22:53:55.129601 20451 solver.cpp:228] Iteration 14230, loss = 0.281439
I0808 22:53:55.129782 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 22:53:55.129797 20451 solver.cpp:244]     Train net output #1: loss = 0.281439 (* 1 = 0.281439 loss)
I0808 22:53:55.129811 20451 sgd_solver.cpp:106] Iteration 14230, lr = 0.000514914
I0808 22:54:17.438993 20451 solver.cpp:228] Iteration 14240, loss = 0.250115
I0808 22:54:17.439049 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:54:17.439062 20451 solver.cpp:244]     Train net output #1: loss = 0.250116 (* 1 = 0.250116 loss)
I0808 22:54:17.439074 20451 sgd_solver.cpp:106] Iteration 14240, lr = 0.000514755
I0808 22:54:39.739883 20451 solver.cpp:228] Iteration 14250, loss = 0.218841
I0808 22:54:39.740061 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:54:39.740075 20451 solver.cpp:244]     Train net output #1: loss = 0.218841 (* 1 = 0.218841 loss)
I0808 22:54:39.740087 20451 sgd_solver.cpp:106] Iteration 14250, lr = 0.000514596
I0808 22:55:02.042704 20451 solver.cpp:228] Iteration 14260, loss = 0.0937902
I0808 22:55:02.042755 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 22:55:02.042770 20451 solver.cpp:244]     Train net output #1: loss = 0.0937904 (* 1 = 0.0937904 loss)
I0808 22:55:02.042783 20451 sgd_solver.cpp:106] Iteration 14260, lr = 0.000514437
I0808 22:55:24.339265 20451 solver.cpp:228] Iteration 14270, loss = 0.156355
I0808 22:55:24.339447 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:55:24.339462 20451 solver.cpp:244]     Train net output #1: loss = 0.156356 (* 1 = 0.156356 loss)
I0808 22:55:24.339474 20451 sgd_solver.cpp:106] Iteration 14270, lr = 0.000514278
I0808 22:55:46.645701 20451 solver.cpp:228] Iteration 14280, loss = 0.187599
I0808 22:55:46.645755 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:55:46.645768 20451 solver.cpp:244]     Train net output #1: loss = 0.187599 (* 1 = 0.187599 loss)
I0808 22:55:46.645781 20451 sgd_solver.cpp:106] Iteration 14280, lr = 0.000514119
I0808 22:56:08.949038 20451 solver.cpp:228] Iteration 14290, loss = 0.156367
I0808 22:56:08.949264 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:56:08.949280 20451 solver.cpp:244]     Train net output #1: loss = 0.156367 (* 1 = 0.156367 loss)
I0808 22:56:08.949292 20451 sgd_solver.cpp:106] Iteration 14290, lr = 0.00051396
I0808 22:56:29.021378 20451 solver.cpp:337] Iteration 14300, Testing net (#0)
I0808 22:56:37.540668 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0808 22:56:37.540719 20451 solver.cpp:404]     Test net output #1: loss = 1.01269 (* 1 = 1.01269 loss)
I0808 22:56:39.741708 20451 solver.cpp:228] Iteration 14300, loss = 0.218809
I0808 22:56:39.741883 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:56:39.741899 20451 solver.cpp:244]     Train net output #1: loss = 0.218809 (* 1 = 0.218809 loss)
I0808 22:56:39.741910 20451 sgd_solver.cpp:106] Iteration 14300, lr = 0.000513801
I0808 22:57:02.026223 20451 solver.cpp:228] Iteration 14310, loss = 0.25013
I0808 22:57:02.026276 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 22:57:02.026290 20451 solver.cpp:244]     Train net output #1: loss = 0.250131 (* 1 = 0.250131 loss)
I0808 22:57:02.026301 20451 sgd_solver.cpp:106] Iteration 14310, lr = 0.000513643
I0808 22:57:24.328202 20451 solver.cpp:228] Iteration 14320, loss = 0.187586
I0808 22:57:24.328387 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:57:24.328402 20451 solver.cpp:244]     Train net output #1: loss = 0.187586 (* 1 = 0.187586 loss)
I0808 22:57:24.328414 20451 sgd_solver.cpp:106] Iteration 14320, lr = 0.000513485
I0808 22:57:46.636318 20451 solver.cpp:228] Iteration 14330, loss = 0.156324
I0808 22:57:46.636370 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:57:46.636384 20451 solver.cpp:244]     Train net output #1: loss = 0.156324 (* 1 = 0.156324 loss)
I0808 22:57:46.636396 20451 sgd_solver.cpp:106] Iteration 14330, lr = 0.000513326
I0808 22:58:08.935055 20451 solver.cpp:228] Iteration 14340, loss = 0.218888
I0808 22:58:08.935155 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:58:08.935174 20451 solver.cpp:244]     Train net output #1: loss = 0.218888 (* 1 = 0.218888 loss)
I0808 22:58:08.935190 20451 sgd_solver.cpp:106] Iteration 14340, lr = 0.000513168
I0808 22:58:31.232333 20451 solver.cpp:228] Iteration 14350, loss = 0.218878
I0808 22:58:31.232379 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 22:58:31.232404 20451 solver.cpp:244]     Train net output #1: loss = 0.218878 (* 1 = 0.218878 loss)
I0808 22:58:31.232421 20451 sgd_solver.cpp:106] Iteration 14350, lr = 0.00051301
I0808 22:58:53.532614 20451 solver.cpp:228] Iteration 14360, loss = 0.187532
I0808 22:58:53.532794 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 22:58:53.532810 20451 solver.cpp:244]     Train net output #1: loss = 0.187532 (* 1 = 0.187532 loss)
I0808 22:58:53.532824 20451 sgd_solver.cpp:106] Iteration 14360, lr = 0.000512852
I0808 22:59:15.835280 20451 solver.cpp:228] Iteration 14370, loss = 0.156383
I0808 22:59:15.835330 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 22:59:15.835346 20451 solver.cpp:244]     Train net output #1: loss = 0.156383 (* 1 = 0.156383 loss)
I0808 22:59:15.835358 20451 sgd_solver.cpp:106] Iteration 14370, lr = 0.000512694
I0808 22:59:38.142089 20451 solver.cpp:228] Iteration 14380, loss = 0.218856
I0808 22:59:38.142268 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 22:59:38.142283 20451 solver.cpp:244]     Train net output #1: loss = 0.218857 (* 1 = 0.218857 loss)
I0808 22:59:38.142295 20451 sgd_solver.cpp:106] Iteration 14380, lr = 0.000512536
I0808 23:00:00.454006 20451 solver.cpp:228] Iteration 14390, loss = 0.156328
I0808 23:00:00.454058 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:00:00.454072 20451 solver.cpp:244]     Train net output #1: loss = 0.156328 (* 1 = 0.156328 loss)
I0808 23:00:00.454084 20451 sgd_solver.cpp:106] Iteration 14390, lr = 0.000512379
I0808 23:00:20.533306 20451 solver.cpp:337] Iteration 14400, Testing net (#0)
I0808 23:00:29.054628 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 23:00:29.054679 20451 solver.cpp:404]     Test net output #1: loss = 0.984469 (* 1 = 0.984469 loss)
I0808 23:00:31.257643 20451 solver.cpp:228] Iteration 14400, loss = 0.0625082
I0808 23:00:31.257696 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 23:00:31.257710 20451 solver.cpp:244]     Train net output #1: loss = 0.0625084 (* 1 = 0.0625084 loss)
I0808 23:00:31.257724 20451 sgd_solver.cpp:106] Iteration 14400, lr = 0.000512221
I0808 23:00:53.541918 20451 solver.cpp:228] Iteration 14410, loss = 0.187586
I0808 23:00:53.542098 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:00:53.542112 20451 solver.cpp:244]     Train net output #1: loss = 0.187586 (* 1 = 0.187586 loss)
I0808 23:00:53.542125 20451 sgd_solver.cpp:106] Iteration 14410, lr = 0.000512064
I0808 23:01:15.848587 20451 solver.cpp:228] Iteration 14420, loss = 0.156283
I0808 23:01:15.848631 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:01:15.848646 20451 solver.cpp:244]     Train net output #1: loss = 0.156283 (* 1 = 0.156283 loss)
I0808 23:01:15.848659 20451 sgd_solver.cpp:106] Iteration 14420, lr = 0.000511907
I0808 23:01:38.147179 20451 solver.cpp:228] Iteration 14430, loss = 0.156346
I0808 23:01:38.147368 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:01:38.147383 20451 solver.cpp:244]     Train net output #1: loss = 0.156347 (* 1 = 0.156347 loss)
I0808 23:01:38.147397 20451 sgd_solver.cpp:106] Iteration 14430, lr = 0.00051175
I0808 23:02:00.449764 20451 solver.cpp:228] Iteration 14440, loss = 0.187581
I0808 23:02:00.449812 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:02:00.449826 20451 solver.cpp:244]     Train net output #1: loss = 0.187581 (* 1 = 0.187581 loss)
I0808 23:02:00.449837 20451 sgd_solver.cpp:106] Iteration 14440, lr = 0.000511592
I0808 23:02:22.756953 20451 solver.cpp:228] Iteration 14450, loss = 0.0312654
I0808 23:02:22.757051 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 23:02:22.757067 20451 solver.cpp:244]     Train net output #1: loss = 0.0312655 (* 1 = 0.0312655 loss)
I0808 23:02:22.757081 20451 sgd_solver.cpp:106] Iteration 14450, lr = 0.000511436
I0808 23:02:45.066344 20451 solver.cpp:228] Iteration 14460, loss = 0.156337
I0808 23:02:45.066396 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:02:45.066411 20451 solver.cpp:244]     Train net output #1: loss = 0.156337 (* 1 = 0.156337 loss)
I0808 23:02:45.066423 20451 sgd_solver.cpp:106] Iteration 14460, lr = 0.000511279
I0808 23:03:07.358949 20451 solver.cpp:228] Iteration 14470, loss = 0.125017
I0808 23:03:07.359133 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:03:07.359148 20451 solver.cpp:244]     Train net output #1: loss = 0.125017 (* 1 = 0.125017 loss)
I0808 23:03:07.359161 20451 sgd_solver.cpp:106] Iteration 14470, lr = 0.000511122
I0808 23:03:29.653759 20451 solver.cpp:228] Iteration 14480, loss = 0.0937515
I0808 23:03:29.653815 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:03:29.653830 20451 solver.cpp:244]     Train net output #1: loss = 0.0937517 (* 1 = 0.0937517 loss)
I0808 23:03:29.653841 20451 sgd_solver.cpp:106] Iteration 14480, lr = 0.000510965
I0808 23:03:51.953850 20451 solver.cpp:228] Iteration 14490, loss = 0.312659
I0808 23:03:51.954025 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 23:03:51.954040 20451 solver.cpp:244]     Train net output #1: loss = 0.312659 (* 1 = 0.312659 loss)
I0808 23:03:51.954051 20451 sgd_solver.cpp:106] Iteration 14490, lr = 0.000510809
I0808 23:04:12.036774 20451 solver.cpp:337] Iteration 14500, Testing net (#0)
I0808 23:04:20.558853 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 23:04:20.558904 20451 solver.cpp:404]     Test net output #1: loss = 1.00322 (* 1 = 1.00322 loss)
I0808 23:04:22.758719 20451 solver.cpp:228] Iteration 14500, loss = 0.0937629
I0808 23:04:22.758852 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:04:22.758872 20451 solver.cpp:244]     Train net output #1: loss = 0.0937631 (* 1 = 0.0937631 loss)
I0808 23:04:22.758888 20451 sgd_solver.cpp:106] Iteration 14500, lr = 0.000510653
I0808 23:04:45.031278 20451 solver.cpp:228] Iteration 14510, loss = 0.187632
I0808 23:04:45.031322 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:04:45.031352 20451 solver.cpp:244]     Train net output #1: loss = 0.187632 (* 1 = 0.187632 loss)
I0808 23:04:45.031366 20451 sgd_solver.cpp:106] Iteration 14510, lr = 0.000510496
I0808 23:05:07.328325 20451 solver.cpp:228] Iteration 14520, loss = 0.15628
I0808 23:05:07.328470 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:05:07.328490 20451 solver.cpp:244]     Train net output #1: loss = 0.15628 (* 1 = 0.15628 loss)
I0808 23:05:07.328505 20451 sgd_solver.cpp:106] Iteration 14520, lr = 0.00051034
I0808 23:05:29.621266 20451 solver.cpp:228] Iteration 14530, loss = 0.312684
I0808 23:05:29.621320 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 23:05:29.621340 20451 solver.cpp:244]     Train net output #1: loss = 0.312684 (* 1 = 0.312684 loss)
I0808 23:05:29.621357 20451 sgd_solver.cpp:106] Iteration 14530, lr = 0.000510184
I0808 23:05:51.927538 20451 solver.cpp:228] Iteration 14540, loss = 0.25019
I0808 23:05:51.927654 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:05:51.927669 20451 solver.cpp:244]     Train net output #1: loss = 0.25019 (* 1 = 0.25019 loss)
I0808 23:05:51.927680 20451 sgd_solver.cpp:106] Iteration 14540, lr = 0.000510028
I0808 23:06:14.231184 20451 solver.cpp:228] Iteration 14550, loss = 0.156339
I0808 23:06:14.231225 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:06:14.231252 20451 solver.cpp:244]     Train net output #1: loss = 0.156339 (* 1 = 0.156339 loss)
I0808 23:06:14.231268 20451 sgd_solver.cpp:106] Iteration 14550, lr = 0.000509872
I0808 23:06:36.534042 20451 solver.cpp:228] Iteration 14560, loss = 0.312516
I0808 23:06:36.534225 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 23:06:36.534240 20451 solver.cpp:244]     Train net output #1: loss = 0.312516 (* 1 = 0.312516 loss)
I0808 23:06:36.534252 20451 sgd_solver.cpp:106] Iteration 14560, lr = 0.000509717
I0808 23:06:58.826026 20451 solver.cpp:228] Iteration 14570, loss = 0.281594
I0808 23:06:58.826076 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 23:06:58.826092 20451 solver.cpp:244]     Train net output #1: loss = 0.281594 (* 1 = 0.281594 loss)
I0808 23:06:58.826105 20451 sgd_solver.cpp:106] Iteration 14570, lr = 0.000509561
I0808 23:07:21.126433 20451 solver.cpp:228] Iteration 14580, loss = 0.125076
I0808 23:07:21.126618 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:07:21.126636 20451 solver.cpp:244]     Train net output #1: loss = 0.125076 (* 1 = 0.125076 loss)
I0808 23:07:21.126653 20451 sgd_solver.cpp:106] Iteration 14580, lr = 0.000509406
I0808 23:07:43.422204 20451 solver.cpp:228] Iteration 14590, loss = 0.281365
I0808 23:07:43.422250 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:07:43.422268 20451 solver.cpp:244]     Train net output #1: loss = 0.281365 (* 1 = 0.281365 loss)
I0808 23:07:43.422282 20451 sgd_solver.cpp:106] Iteration 14590, lr = 0.00050925
I0808 23:08:03.497122 20451 solver.cpp:337] Iteration 14600, Testing net (#0)
I0808 23:08:12.012078 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 23:08:12.012130 20451 solver.cpp:404]     Test net output #1: loss = 0.975328 (* 1 = 0.975328 loss)
I0808 23:08:14.215133 20451 solver.cpp:228] Iteration 14600, loss = 0.187615
I0808 23:08:14.215186 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:08:14.215201 20451 solver.cpp:244]     Train net output #1: loss = 0.187615 (* 1 = 0.187615 loss)
I0808 23:08:14.215214 20451 sgd_solver.cpp:106] Iteration 14600, lr = 0.000509095
I0808 23:08:36.498352 20451 solver.cpp:228] Iteration 14610, loss = 0.375241
I0808 23:08:36.498528 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0808 23:08:36.498543 20451 solver.cpp:244]     Train net output #1: loss = 0.375241 (* 1 = 0.375241 loss)
I0808 23:08:36.498555 20451 sgd_solver.cpp:106] Iteration 14610, lr = 0.00050894
I0808 23:08:58.794719 20451 solver.cpp:228] Iteration 14620, loss = 0.4064
I0808 23:08:58.794767 20451 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0808 23:08:58.794787 20451 solver.cpp:244]     Train net output #1: loss = 0.406401 (* 1 = 0.406401 loss)
I0808 23:08:58.794803 20451 sgd_solver.cpp:106] Iteration 14620, lr = 0.000508785
I0808 23:09:21.097575 20451 solver.cpp:228] Iteration 14630, loss = 0.156298
I0808 23:09:21.097687 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:09:21.097705 20451 solver.cpp:244]     Train net output #1: loss = 0.156298 (* 1 = 0.156298 loss)
I0808 23:09:21.097721 20451 sgd_solver.cpp:106] Iteration 14630, lr = 0.00050863
I0808 23:09:43.398574 20451 solver.cpp:228] Iteration 14640, loss = 0.281544
I0808 23:09:43.398627 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 23:09:43.398640 20451 solver.cpp:244]     Train net output #1: loss = 0.281544 (* 1 = 0.281544 loss)
I0808 23:09:43.398653 20451 sgd_solver.cpp:106] Iteration 14640, lr = 0.000508475
I0808 23:10:05.708925 20451 solver.cpp:228] Iteration 14650, loss = 0.219062
I0808 23:10:05.709105 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:10:05.709120 20451 solver.cpp:244]     Train net output #1: loss = 0.219062 (* 1 = 0.219062 loss)
I0808 23:10:05.709131 20451 sgd_solver.cpp:106] Iteration 14650, lr = 0.00050832
I0808 23:10:28.005975 20451 solver.cpp:228] Iteration 14660, loss = 0.218961
I0808 23:10:28.006021 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:10:28.006036 20451 solver.cpp:244]     Train net output #1: loss = 0.218961 (* 1 = 0.218961 loss)
I0808 23:10:28.006048 20451 sgd_solver.cpp:106] Iteration 14660, lr = 0.000508166
I0808 23:10:50.316946 20451 solver.cpp:228] Iteration 14670, loss = 0.281754
I0808 23:10:50.317123 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 23:10:50.317138 20451 solver.cpp:244]     Train net output #1: loss = 0.281754 (* 1 = 0.281754 loss)
I0808 23:10:50.317152 20451 sgd_solver.cpp:106] Iteration 14670, lr = 0.000508011
I0808 23:11:12.630132 20451 solver.cpp:228] Iteration 14680, loss = 0.125153
I0808 23:11:12.630185 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:11:12.630198 20451 solver.cpp:244]     Train net output #1: loss = 0.125153 (* 1 = 0.125153 loss)
I0808 23:11:12.630210 20451 sgd_solver.cpp:106] Iteration 14680, lr = 0.000507857
I0808 23:11:34.936429 20451 solver.cpp:228] Iteration 14690, loss = 0.093884
I0808 23:11:34.936605 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:11:34.936620 20451 solver.cpp:244]     Train net output #1: loss = 0.0938841 (* 1 = 0.0938841 loss)
I0808 23:11:34.936635 20451 sgd_solver.cpp:106] Iteration 14690, lr = 0.000507702
I0808 23:11:55.023412 20451 solver.cpp:337] Iteration 14700, Testing net (#0)
I0808 23:12:03.546676 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0808 23:12:03.546732 20451 solver.cpp:404]     Test net output #1: loss = 1.01832 (* 1 = 1.01832 loss)
I0808 23:12:05.749006 20451 solver.cpp:228] Iteration 14700, loss = 0.125207
I0808 23:12:05.749224 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:12:05.749243 20451 solver.cpp:244]     Train net output #1: loss = 0.125207 (* 1 = 0.125207 loss)
I0808 23:12:05.749256 20451 sgd_solver.cpp:106] Iteration 14700, lr = 0.000507548
I0808 23:12:28.018697 20451 solver.cpp:228] Iteration 14710, loss = 0.218795
I0808 23:12:28.018748 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:12:28.018762 20451 solver.cpp:244]     Train net output #1: loss = 0.218795 (* 1 = 0.218795 loss)
I0808 23:12:28.018774 20451 sgd_solver.cpp:106] Iteration 14710, lr = 0.000507394
I0808 23:12:50.321180 20451 solver.cpp:228] Iteration 14720, loss = 0.25018
I0808 23:12:50.321362 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:12:50.321378 20451 solver.cpp:244]     Train net output #1: loss = 0.25018 (* 1 = 0.25018 loss)
I0808 23:12:50.321391 20451 sgd_solver.cpp:106] Iteration 14720, lr = 0.00050724
I0808 23:13:12.624063 20451 solver.cpp:228] Iteration 14730, loss = 0.218842
I0808 23:13:12.624114 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:13:12.624127 20451 solver.cpp:244]     Train net output #1: loss = 0.218842 (* 1 = 0.218842 loss)
I0808 23:13:12.624140 20451 sgd_solver.cpp:106] Iteration 14730, lr = 0.000507086
I0808 23:13:34.926955 20451 solver.cpp:228] Iteration 14740, loss = 0.156317
I0808 23:13:34.927129 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:13:34.927145 20451 solver.cpp:244]     Train net output #1: loss = 0.156317 (* 1 = 0.156317 loss)
I0808 23:13:34.927157 20451 sgd_solver.cpp:106] Iteration 14740, lr = 0.000506933
I0808 23:13:57.229239 20451 solver.cpp:228] Iteration 14750, loss = 0.250047
I0808 23:13:57.229290 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:13:57.229305 20451 solver.cpp:244]     Train net output #1: loss = 0.250048 (* 1 = 0.250048 loss)
I0808 23:13:57.229317 20451 sgd_solver.cpp:106] Iteration 14750, lr = 0.000506779
I0808 23:14:19.531026 20451 solver.cpp:228] Iteration 14760, loss = 0.0625177
I0808 23:14:19.531215 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 23:14:19.531231 20451 solver.cpp:244]     Train net output #1: loss = 0.0625178 (* 1 = 0.0625178 loss)
I0808 23:14:19.531244 20451 sgd_solver.cpp:106] Iteration 14760, lr = 0.000506626
I0808 23:14:41.834575 20451 solver.cpp:228] Iteration 14770, loss = 0.125045
I0808 23:14:41.834630 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:14:41.834645 20451 solver.cpp:244]     Train net output #1: loss = 0.125045 (* 1 = 0.125045 loss)
I0808 23:14:41.834656 20451 sgd_solver.cpp:106] Iteration 14770, lr = 0.000506472
I0808 23:15:04.135232 20451 solver.cpp:228] Iteration 14780, loss = 0.25007
I0808 23:15:04.135387 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:15:04.135403 20451 solver.cpp:244]     Train net output #1: loss = 0.25007 (* 1 = 0.25007 loss)
I0808 23:15:04.135416 20451 sgd_solver.cpp:106] Iteration 14780, lr = 0.000506319
I0808 23:15:26.439841 20451 solver.cpp:228] Iteration 14790, loss = 0.15632
I0808 23:15:26.439889 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:15:26.439915 20451 solver.cpp:244]     Train net output #1: loss = 0.15632 (* 1 = 0.15632 loss)
I0808 23:15:26.439931 20451 sgd_solver.cpp:106] Iteration 14790, lr = 0.000506166
I0808 23:15:46.517478 20451 solver.cpp:337] Iteration 14800, Testing net (#0)
I0808 23:15:55.043159 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 23:15:55.043210 20451 solver.cpp:404]     Test net output #1: loss = 1.00352 (* 1 = 1.00352 loss)
I0808 23:15:57.248386 20451 solver.cpp:228] Iteration 14800, loss = 0.156341
I0808 23:15:57.248435 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:15:57.248450 20451 solver.cpp:244]     Train net output #1: loss = 0.156341 (* 1 = 0.156341 loss)
I0808 23:15:57.248461 20451 sgd_solver.cpp:106] Iteration 14800, lr = 0.000506013
I0808 23:16:19.535316 20451 solver.cpp:228] Iteration 14810, loss = 0.0625216
I0808 23:16:19.535542 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 23:16:19.535557 20451 solver.cpp:244]     Train net output #1: loss = 0.0625217 (* 1 = 0.0625217 loss)
I0808 23:16:19.535570 20451 sgd_solver.cpp:106] Iteration 14810, lr = 0.00050586
I0808 23:16:41.854562 20451 solver.cpp:228] Iteration 14820, loss = 0.218833
I0808 23:16:41.854614 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:16:41.854629 20451 solver.cpp:244]     Train net output #1: loss = 0.218833 (* 1 = 0.218833 loss)
I0808 23:16:41.854640 20451 sgd_solver.cpp:106] Iteration 14820, lr = 0.000505707
I0808 23:17:04.170402 20451 solver.cpp:228] Iteration 14830, loss = 0.156278
I0808 23:17:04.170578 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:17:04.170593 20451 solver.cpp:244]     Train net output #1: loss = 0.156278 (* 1 = 0.156278 loss)
I0808 23:17:04.170608 20451 sgd_solver.cpp:106] Iteration 14830, lr = 0.000505554
I0808 23:17:26.487377 20451 solver.cpp:228] Iteration 14840, loss = 0.0625081
I0808 23:17:26.487428 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 23:17:26.487442 20451 solver.cpp:244]     Train net output #1: loss = 0.0625082 (* 1 = 0.0625082 loss)
I0808 23:17:26.487454 20451 sgd_solver.cpp:106] Iteration 14840, lr = 0.000505401
I0808 23:17:48.796506 20451 solver.cpp:228] Iteration 14850, loss = 0.156536
I0808 23:17:48.796612 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:17:48.796628 20451 solver.cpp:244]     Train net output #1: loss = 0.156536 (* 1 = 0.156536 loss)
I0808 23:17:48.796641 20451 sgd_solver.cpp:106] Iteration 14850, lr = 0.000505249
I0808 23:18:11.105530 20451 solver.cpp:228] Iteration 14860, loss = 0.125033
I0808 23:18:11.105584 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:18:11.105599 20451 solver.cpp:244]     Train net output #1: loss = 0.125033 (* 1 = 0.125033 loss)
I0808 23:18:11.105612 20451 sgd_solver.cpp:106] Iteration 14860, lr = 0.000505096
I0808 23:18:33.416806 20451 solver.cpp:228] Iteration 14870, loss = 0.218774
I0808 23:18:33.416900 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:18:33.416915 20451 solver.cpp:244]     Train net output #1: loss = 0.218774 (* 1 = 0.218774 loss)
I0808 23:18:33.416927 20451 sgd_solver.cpp:106] Iteration 14870, lr = 0.000504944
I0808 23:18:55.719688 20451 solver.cpp:228] Iteration 14880, loss = 0.156331
I0808 23:18:55.719730 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:18:55.719745 20451 solver.cpp:244]     Train net output #1: loss = 0.156331 (* 1 = 0.156331 loss)
I0808 23:18:55.719758 20451 sgd_solver.cpp:106] Iteration 14880, lr = 0.000504792
I0808 23:19:18.032299 20451 solver.cpp:228] Iteration 14890, loss = 0.125029
I0808 23:19:18.032474 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:19:18.032491 20451 solver.cpp:244]     Train net output #1: loss = 0.125029 (* 1 = 0.125029 loss)
I0808 23:19:18.032503 20451 sgd_solver.cpp:106] Iteration 14890, lr = 0.00050464
I0808 23:19:38.115857 20451 solver.cpp:337] Iteration 14900, Testing net (#0)
I0808 23:19:46.639291 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0808 23:19:46.639341 20451 solver.cpp:404]     Test net output #1: loss = 0.975063 (* 1 = 0.975063 loss)
I0808 23:19:48.843636 20451 solver.cpp:228] Iteration 14900, loss = 0.156263
I0808 23:19:48.843808 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:19:48.843823 20451 solver.cpp:244]     Train net output #1: loss = 0.156263 (* 1 = 0.156263 loss)
I0808 23:19:48.843835 20451 sgd_solver.cpp:106] Iteration 14900, lr = 0.000504488
I0808 23:20:11.124256 20451 solver.cpp:228] Iteration 14910, loss = 0.375078
I0808 23:20:11.124308 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0808 23:20:11.124322 20451 solver.cpp:244]     Train net output #1: loss = 0.375078 (* 1 = 0.375078 loss)
I0808 23:20:11.124335 20451 sgd_solver.cpp:106] Iteration 14910, lr = 0.000504336
I0808 23:20:33.430248 20451 solver.cpp:228] Iteration 14920, loss = 0.218828
I0808 23:20:33.430383 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:20:33.430402 20451 solver.cpp:244]     Train net output #1: loss = 0.218828 (* 1 = 0.218828 loss)
I0808 23:20:33.430418 20451 sgd_solver.cpp:106] Iteration 14920, lr = 0.000504184
I0808 23:20:55.737021 20451 solver.cpp:228] Iteration 14930, loss = 0.218791
I0808 23:20:55.737076 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:20:55.737092 20451 solver.cpp:244]     Train net output #1: loss = 0.218791 (* 1 = 0.218791 loss)
I0808 23:20:55.737107 20451 sgd_solver.cpp:106] Iteration 14930, lr = 0.000504032
I0808 23:21:18.048151 20451 solver.cpp:228] Iteration 14940, loss = 0.281365
I0808 23:21:18.048327 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 23:21:18.048342 20451 solver.cpp:244]     Train net output #1: loss = 0.281365 (* 1 = 0.281365 loss)
I0808 23:21:18.048354 20451 sgd_solver.cpp:106] Iteration 14940, lr = 0.000503881
I0808 23:21:40.353876 20451 solver.cpp:228] Iteration 14950, loss = 0.31255
I0808 23:21:40.353929 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:21:40.353943 20451 solver.cpp:244]     Train net output #1: loss = 0.31255 (* 1 = 0.31255 loss)
I0808 23:21:40.353955 20451 sgd_solver.cpp:106] Iteration 14950, lr = 0.000503729
I0808 23:22:02.657958 20451 solver.cpp:228] Iteration 14960, loss = 0.218867
I0808 23:22:02.658140 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:22:02.658155 20451 solver.cpp:244]     Train net output #1: loss = 0.218867 (* 1 = 0.218867 loss)
I0808 23:22:02.658169 20451 sgd_solver.cpp:106] Iteration 14960, lr = 0.000503578
I0808 23:22:24.968497 20451 solver.cpp:228] Iteration 14970, loss = 0.0937892
I0808 23:22:24.968551 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:22:24.968565 20451 solver.cpp:244]     Train net output #1: loss = 0.0937893 (* 1 = 0.0937893 loss)
I0808 23:22:24.968578 20451 sgd_solver.cpp:106] Iteration 14970, lr = 0.000503427
I0808 23:22:47.288142 20451 solver.cpp:228] Iteration 14980, loss = 0.281355
I0808 23:22:47.288321 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 23:22:47.288337 20451 solver.cpp:244]     Train net output #1: loss = 0.281355 (* 1 = 0.281355 loss)
I0808 23:22:47.288350 20451 sgd_solver.cpp:106] Iteration 14980, lr = 0.000503275
I0808 23:23:09.592695 20451 solver.cpp:228] Iteration 14990, loss = 0.250104
I0808 23:23:09.592746 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:23:09.592761 20451 solver.cpp:244]     Train net output #1: loss = 0.250104 (* 1 = 0.250104 loss)
I0808 23:23:09.592773 20451 sgd_solver.cpp:106] Iteration 14990, lr = 0.000503124
I0808 23:23:29.672405 20451 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_15000.caffemodel
I0808 23:23:29.871773 20451 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_15000.solverstate
I0808 23:23:29.874346 20451 solver.cpp:337] Iteration 15000, Testing net (#0)
I0808 23:23:38.378226 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0808 23:23:38.378275 20451 solver.cpp:404]     Test net output #1: loss = 0.994046 (* 1 = 0.994046 loss)
I0808 23:23:40.582046 20451 solver.cpp:228] Iteration 15000, loss = 0.0312634
I0808 23:23:40.582094 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 23:23:40.582109 20451 solver.cpp:244]     Train net output #1: loss = 0.0312635 (* 1 = 0.0312635 loss)
I0808 23:23:40.582121 20451 sgd_solver.cpp:106] Iteration 15000, lr = 0.000502973
I0808 23:24:02.891971 20451 solver.cpp:228] Iteration 15010, loss = 0.0937832
I0808 23:24:02.892153 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:24:02.892169 20451 solver.cpp:244]     Train net output #1: loss = 0.0937833 (* 1 = 0.0937833 loss)
I0808 23:24:02.892182 20451 sgd_solver.cpp:106] Iteration 15010, lr = 0.000502823
I0808 23:24:25.205142 20451 solver.cpp:228] Iteration 15020, loss = 0.187795
I0808 23:24:25.205195 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:24:25.205209 20451 solver.cpp:244]     Train net output #1: loss = 0.187796 (* 1 = 0.187796 loss)
I0808 23:24:25.205222 20451 sgd_solver.cpp:106] Iteration 15020, lr = 0.000502672
I0808 23:24:47.514204 20451 solver.cpp:228] Iteration 15030, loss = 0.125027
I0808 23:24:47.514477 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:24:47.514552 20451 solver.cpp:244]     Train net output #1: loss = 0.125027 (* 1 = 0.125027 loss)
I0808 23:24:47.514578 20451 sgd_solver.cpp:106] Iteration 15030, lr = 0.000502521
I0808 23:25:09.823985 20451 solver.cpp:228] Iteration 15040, loss = 0.125244
I0808 23:25:09.824038 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:25:09.824051 20451 solver.cpp:244]     Train net output #1: loss = 0.125244 (* 1 = 0.125244 loss)
I0808 23:25:09.824064 20451 sgd_solver.cpp:106] Iteration 15040, lr = 0.000502371
I0808 23:25:32.133363 20451 solver.cpp:228] Iteration 15050, loss = 0.218826
I0808 23:25:32.133554 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:25:32.133572 20451 solver.cpp:244]     Train net output #1: loss = 0.218826 (* 1 = 0.218826 loss)
I0808 23:25:32.133585 20451 sgd_solver.cpp:106] Iteration 15050, lr = 0.00050222
I0808 23:25:54.440855 20451 solver.cpp:228] Iteration 15060, loss = 0.218798
I0808 23:25:54.440898 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:25:54.440917 20451 solver.cpp:244]     Train net output #1: loss = 0.218798 (* 1 = 0.218798 loss)
I0808 23:25:54.440932 20451 sgd_solver.cpp:106] Iteration 15060, lr = 0.00050207
I0808 23:26:16.749749 20451 solver.cpp:228] Iteration 15070, loss = 0.218909
I0808 23:26:16.749852 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:26:16.749871 20451 solver.cpp:244]     Train net output #1: loss = 0.218909 (* 1 = 0.218909 loss)
I0808 23:26:16.749887 20451 sgd_solver.cpp:106] Iteration 15070, lr = 0.00050192
I0808 23:26:39.052686 20451 solver.cpp:228] Iteration 15080, loss = 0.250068
I0808 23:26:39.052731 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:26:39.052749 20451 solver.cpp:244]     Train net output #1: loss = 0.250068 (* 1 = 0.250068 loss)
I0808 23:26:39.052764 20451 sgd_solver.cpp:106] Iteration 15080, lr = 0.00050177
I0808 23:27:01.354691 20451 solver.cpp:228] Iteration 15090, loss = 0.156313
I0808 23:27:01.354785 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0808 23:27:01.354804 20451 solver.cpp:244]     Train net output #1: loss = 0.156313 (* 1 = 0.156313 loss)
I0808 23:27:01.354820 20451 sgd_solver.cpp:106] Iteration 15090, lr = 0.00050162
I0808 23:27:21.436594 20451 solver.cpp:337] Iteration 15100, Testing net (#0)
I0808 23:27:29.958508 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 23:27:29.958559 20451 solver.cpp:404]     Test net output #1: loss = 1.00317 (* 1 = 1.00317 loss)
I0808 23:27:32.164476 20451 solver.cpp:228] Iteration 15100, loss = 0.437527
I0808 23:27:32.164662 20451 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0808 23:27:32.164682 20451 solver.cpp:244]     Train net output #1: loss = 0.437527 (* 1 = 0.437527 loss)
I0808 23:27:32.164697 20451 sgd_solver.cpp:106] Iteration 15100, lr = 0.00050147
I0808 23:27:54.446566 20451 solver.cpp:228] Iteration 15110, loss = 0.281267
I0808 23:27:54.446619 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 23:27:54.446633 20451 solver.cpp:244]     Train net output #1: loss = 0.281267 (* 1 = 0.281267 loss)
I0808 23:27:54.446645 20451 sgd_solver.cpp:106] Iteration 15110, lr = 0.00050132
I0808 23:28:16.753152 20451 solver.cpp:228] Iteration 15120, loss = 0.187609
I0808 23:28:16.753243 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:28:16.753259 20451 solver.cpp:244]     Train net output #1: loss = 0.187609 (* 1 = 0.187609 loss)
I0808 23:28:16.753273 20451 sgd_solver.cpp:106] Iteration 15120, lr = 0.00050117
I0808 23:28:39.054278 20451 solver.cpp:228] Iteration 15130, loss = 0.187671
I0808 23:28:39.054332 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:28:39.054347 20451 solver.cpp:244]     Train net output #1: loss = 0.187671 (* 1 = 0.187671 loss)
I0808 23:28:39.054359 20451 sgd_solver.cpp:106] Iteration 15130, lr = 0.000501021
I0808 23:29:01.357965 20451 solver.cpp:228] Iteration 15140, loss = 0.125078
I0808 23:29:01.358182 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:29:01.358198 20451 solver.cpp:244]     Train net output #1: loss = 0.125078 (* 1 = 0.125078 loss)
I0808 23:29:01.358214 20451 sgd_solver.cpp:106] Iteration 15140, lr = 0.000500871
I0808 23:29:23.652683 20451 solver.cpp:228] Iteration 15150, loss = 0.187541
I0808 23:29:23.652735 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:29:23.652750 20451 solver.cpp:244]     Train net output #1: loss = 0.187541 (* 1 = 0.187541 loss)
I0808 23:29:23.652762 20451 sgd_solver.cpp:106] Iteration 15150, lr = 0.000500722
I0808 23:29:45.961009 20451 solver.cpp:228] Iteration 15160, loss = 0.25004
I0808 23:29:45.961130 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:29:45.961151 20451 solver.cpp:244]     Train net output #1: loss = 0.25004 (* 1 = 0.25004 loss)
I0808 23:29:45.961165 20451 sgd_solver.cpp:106] Iteration 15160, lr = 0.000500573
I0808 23:30:08.272222 20451 solver.cpp:228] Iteration 15170, loss = 0.25015
I0808 23:30:08.272265 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:30:08.272294 20451 solver.cpp:244]     Train net output #1: loss = 0.25015 (* 1 = 0.25015 loss)
I0808 23:30:08.272310 20451 sgd_solver.cpp:106] Iteration 15170, lr = 0.000500423
I0808 23:30:30.576468 20451 solver.cpp:228] Iteration 15180, loss = 0.218835
I0808 23:30:30.576655 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:30:30.576675 20451 solver.cpp:244]     Train net output #1: loss = 0.218835 (* 1 = 0.218835 loss)
I0808 23:30:30.576690 20451 sgd_solver.cpp:106] Iteration 15180, lr = 0.000500274
I0808 23:30:52.886312 20451 solver.cpp:228] Iteration 15190, loss = 0.250067
I0808 23:30:52.886358 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:30:52.886378 20451 solver.cpp:244]     Train net output #1: loss = 0.250067 (* 1 = 0.250067 loss)
I0808 23:30:52.886391 20451 sgd_solver.cpp:106] Iteration 15190, lr = 0.000500125
I0808 23:31:12.964704 20451 solver.cpp:337] Iteration 15200, Testing net (#0)
I0808 23:31:21.490383 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0808 23:31:21.490427 20451 solver.cpp:404]     Test net output #1: loss = 0.966052 (* 1 = 0.966052 loss)
I0808 23:31:23.692811 20451 solver.cpp:228] Iteration 15200, loss = 0.187622
I0808 23:31:23.692857 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:31:23.692875 20451 solver.cpp:244]     Train net output #1: loss = 0.187622 (* 1 = 0.187622 loss)
I0808 23:31:23.692901 20451 sgd_solver.cpp:106] Iteration 15200, lr = 0.000499977
I0808 23:31:45.965425 20451 solver.cpp:228] Iteration 15210, loss = 0.0625374
I0808 23:31:45.965605 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 23:31:45.965623 20451 solver.cpp:244]     Train net output #1: loss = 0.0625375 (* 1 = 0.0625375 loss)
I0808 23:31:45.965639 20451 sgd_solver.cpp:106] Iteration 15210, lr = 0.000499828
I0808 23:32:08.282030 20451 solver.cpp:228] Iteration 15220, loss = 0.156277
I0808 23:32:08.282083 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:32:08.282099 20451 solver.cpp:244]     Train net output #1: loss = 0.156277 (* 1 = 0.156277 loss)
I0808 23:32:08.282110 20451 sgd_solver.cpp:106] Iteration 15220, lr = 0.000499679
I0808 23:32:30.599503 20451 solver.cpp:228] Iteration 15230, loss = 0.218837
I0808 23:32:30.599690 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:32:30.599705 20451 solver.cpp:244]     Train net output #1: loss = 0.218837 (* 1 = 0.218837 loss)
I0808 23:32:30.599719 20451 sgd_solver.cpp:106] Iteration 15230, lr = 0.000499531
I0808 23:32:52.913568 20451 solver.cpp:228] Iteration 15240, loss = 0.1875
I0808 23:32:52.913620 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:32:52.913635 20451 solver.cpp:244]     Train net output #1: loss = 0.1875 (* 1 = 0.1875 loss)
I0808 23:32:52.913646 20451 sgd_solver.cpp:106] Iteration 15240, lr = 0.000499382
I0808 23:33:15.233572 20451 solver.cpp:228] Iteration 15250, loss = 0.312674
I0808 23:33:15.233789 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 23:33:15.233805 20451 solver.cpp:244]     Train net output #1: loss = 0.312674 (* 1 = 0.312674 loss)
I0808 23:33:15.233819 20451 sgd_solver.cpp:106] Iteration 15250, lr = 0.000499234
I0808 23:33:37.548641 20451 solver.cpp:228] Iteration 15260, loss = 0.187565
I0808 23:33:37.548686 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:33:37.548701 20451 solver.cpp:244]     Train net output #1: loss = 0.187565 (* 1 = 0.187565 loss)
I0808 23:33:37.548713 20451 sgd_solver.cpp:106] Iteration 15260, lr = 0.000499086
I0808 23:33:59.856744 20451 solver.cpp:228] Iteration 15270, loss = 0.187653
I0808 23:33:59.856922 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:33:59.856937 20451 solver.cpp:244]     Train net output #1: loss = 0.187653 (* 1 = 0.187653 loss)
I0808 23:33:59.856950 20451 sgd_solver.cpp:106] Iteration 15270, lr = 0.000498937
I0808 23:34:22.160827 20451 solver.cpp:228] Iteration 15280, loss = 0.125046
I0808 23:34:22.160879 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:34:22.160893 20451 solver.cpp:244]     Train net output #1: loss = 0.125046 (* 1 = 0.125046 loss)
I0808 23:34:22.160907 20451 sgd_solver.cpp:106] Iteration 15280, lr = 0.000498789
I0808 23:34:44.461679 20451 solver.cpp:228] Iteration 15290, loss = 0.0937925
I0808 23:34:44.461856 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:34:44.461872 20451 solver.cpp:244]     Train net output #1: loss = 0.0937926 (* 1 = 0.0937926 loss)
I0808 23:34:44.461885 20451 sgd_solver.cpp:106] Iteration 15290, lr = 0.000498642
I0808 23:35:04.547765 20451 solver.cpp:337] Iteration 15300, Testing net (#0)
I0808 23:35:13.064609 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0808 23:35:13.064658 20451 solver.cpp:404]     Test net output #1: loss = 1.0317 (* 1 = 1.0317 loss)
I0808 23:35:15.267863 20451 solver.cpp:228] Iteration 15300, loss = 0.125081
I0808 23:35:15.268038 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:35:15.268054 20451 solver.cpp:244]     Train net output #1: loss = 0.125081 (* 1 = 0.125081 loss)
I0808 23:35:15.268065 20451 sgd_solver.cpp:106] Iteration 15300, lr = 0.000498494
I0808 23:35:37.557814 20451 solver.cpp:228] Iteration 15310, loss = 0.156372
I0808 23:35:37.557870 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:35:37.557888 20451 solver.cpp:244]     Train net output #1: loss = 0.156372 (* 1 = 0.156372 loss)
I0808 23:35:37.557904 20451 sgd_solver.cpp:106] Iteration 15310, lr = 0.000498346
I0808 23:35:59.863057 20451 solver.cpp:228] Iteration 15320, loss = 0.187913
I0808 23:35:59.863234 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:35:59.863250 20451 solver.cpp:244]     Train net output #1: loss = 0.187913 (* 1 = 0.187913 loss)
I0808 23:35:59.863261 20451 sgd_solver.cpp:106] Iteration 15320, lr = 0.000498198
I0808 23:36:22.176156 20451 solver.cpp:228] Iteration 15330, loss = 0.281566
I0808 23:36:22.176209 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:36:22.176223 20451 solver.cpp:244]     Train net output #1: loss = 0.281566 (* 1 = 0.281566 loss)
I0808 23:36:22.176235 20451 sgd_solver.cpp:106] Iteration 15330, lr = 0.000498051
I0808 23:36:44.482504 20451 solver.cpp:228] Iteration 15340, loss = 0.0938732
I0808 23:36:44.482679 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:36:44.482695 20451 solver.cpp:244]     Train net output #1: loss = 0.0938734 (* 1 = 0.0938734 loss)
I0808 23:36:44.482709 20451 sgd_solver.cpp:106] Iteration 15340, lr = 0.000497903
I0808 23:37:06.781204 20451 solver.cpp:228] Iteration 15350, loss = 0.281293
I0808 23:37:06.781258 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:37:06.781272 20451 solver.cpp:244]     Train net output #1: loss = 0.281294 (* 1 = 0.281294 loss)
I0808 23:37:06.781285 20451 sgd_solver.cpp:106] Iteration 15350, lr = 0.000497756
I0808 23:37:29.082180 20451 solver.cpp:228] Iteration 15360, loss = 0.125189
I0808 23:37:29.082401 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:37:29.082417 20451 solver.cpp:244]     Train net output #1: loss = 0.125189 (* 1 = 0.125189 loss)
I0808 23:37:29.082430 20451 sgd_solver.cpp:106] Iteration 15360, lr = 0.000497609
I0808 23:37:51.380272 20451 solver.cpp:228] Iteration 15370, loss = 0.250033
I0808 23:37:51.380323 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:37:51.380337 20451 solver.cpp:244]     Train net output #1: loss = 0.250033 (* 1 = 0.250033 loss)
I0808 23:37:51.380349 20451 sgd_solver.cpp:106] Iteration 15370, lr = 0.000497462
I0808 23:38:13.677552 20451 solver.cpp:228] Iteration 15380, loss = 0.312802
I0808 23:38:13.677655 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 23:38:13.677672 20451 solver.cpp:244]     Train net output #1: loss = 0.312802 (* 1 = 0.312802 loss)
I0808 23:38:13.677686 20451 sgd_solver.cpp:106] Iteration 15380, lr = 0.000497315
I0808 23:38:35.996532 20451 solver.cpp:228] Iteration 15390, loss = 0.156286
I0808 23:38:35.996584 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:38:35.996599 20451 solver.cpp:244]     Train net output #1: loss = 0.156286 (* 1 = 0.156286 loss)
I0808 23:38:35.996610 20451 sgd_solver.cpp:106] Iteration 15390, lr = 0.000497168
I0808 23:38:56.076197 20451 solver.cpp:337] Iteration 15400, Testing net (#0)
I0808 23:39:04.597240 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 23:39:04.597293 20451 solver.cpp:404]     Test net output #1: loss = 1.00368 (* 1 = 1.00368 loss)
I0808 23:39:06.802587 20451 solver.cpp:228] Iteration 15400, loss = 0.125102
I0808 23:39:06.802635 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:39:06.802649 20451 solver.cpp:244]     Train net output #1: loss = 0.125102 (* 1 = 0.125102 loss)
I0808 23:39:06.802661 20451 sgd_solver.cpp:106] Iteration 15400, lr = 0.000497021
I0808 23:39:29.085597 20451 solver.cpp:228] Iteration 15410, loss = 0.218868
I0808 23:39:29.085721 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:39:29.085736 20451 solver.cpp:244]     Train net output #1: loss = 0.218868 (* 1 = 0.218868 loss)
I0808 23:39:29.085748 20451 sgd_solver.cpp:106] Iteration 15410, lr = 0.000496874
I0808 23:39:51.390265 20451 solver.cpp:228] Iteration 15420, loss = 0.187585
I0808 23:39:51.390312 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:39:51.390327 20451 solver.cpp:244]     Train net output #1: loss = 0.187585 (* 1 = 0.187585 loss)
I0808 23:39:51.390341 20451 sgd_solver.cpp:106] Iteration 15420, lr = 0.000496728
I0808 23:40:13.693567 20451 solver.cpp:228] Iteration 15430, loss = 0.0937925
I0808 23:40:13.693681 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:40:13.693699 20451 solver.cpp:244]     Train net output #1: loss = 0.0937926 (* 1 = 0.0937926 loss)
I0808 23:40:13.693714 20451 sgd_solver.cpp:106] Iteration 15430, lr = 0.000496581
I0808 23:40:36.010893 20451 solver.cpp:228] Iteration 15440, loss = 0.125039
I0808 23:40:36.010946 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:40:36.010959 20451 solver.cpp:244]     Train net output #1: loss = 0.125039 (* 1 = 0.125039 loss)
I0808 23:40:36.010972 20451 sgd_solver.cpp:106] Iteration 15440, lr = 0.000496435
I0808 23:40:58.312136 20451 solver.cpp:228] Iteration 15450, loss = 0.156336
I0808 23:40:58.312377 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:40:58.312393 20451 solver.cpp:244]     Train net output #1: loss = 0.156336 (* 1 = 0.156336 loss)
I0808 23:40:58.312405 20451 sgd_solver.cpp:106] Iteration 15450, lr = 0.000496288
I0808 23:41:20.620196 20451 solver.cpp:228] Iteration 15460, loss = 0.0625118
I0808 23:41:20.620249 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 23:41:20.620265 20451 solver.cpp:244]     Train net output #1: loss = 0.062512 (* 1 = 0.062512 loss)
I0808 23:41:20.620276 20451 sgd_solver.cpp:106] Iteration 15460, lr = 0.000496142
I0808 23:41:42.936699 20451 solver.cpp:228] Iteration 15470, loss = 0.0625357
I0808 23:41:42.936914 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 23:41:42.936930 20451 solver.cpp:244]     Train net output #1: loss = 0.0625359 (* 1 = 0.0625359 loss)
I0808 23:41:42.936944 20451 sgd_solver.cpp:106] Iteration 15470, lr = 0.000495996
I0808 23:42:05.247056 20451 solver.cpp:228] Iteration 15480, loss = 0.156285
I0808 23:42:05.247102 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:42:05.247130 20451 solver.cpp:244]     Train net output #1: loss = 0.156285 (* 1 = 0.156285 loss)
I0808 23:42:05.247148 20451 sgd_solver.cpp:106] Iteration 15480, lr = 0.00049585
I0808 23:42:27.554270 20451 solver.cpp:228] Iteration 15490, loss = 0.0625209
I0808 23:42:27.554450 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 23:42:27.554466 20451 solver.cpp:244]     Train net output #1: loss = 0.062521 (* 1 = 0.062521 loss)
I0808 23:42:27.554479 20451 sgd_solver.cpp:106] Iteration 15490, lr = 0.000495704
I0808 23:42:47.643088 20451 solver.cpp:337] Iteration 15500, Testing net (#0)
I0808 23:42:56.161859 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0808 23:42:56.161909 20451 solver.cpp:404]     Test net output #1: loss = 0.984685 (* 1 = 0.984685 loss)
I0808 23:42:58.362422 20451 solver.cpp:228] Iteration 15500, loss = 0.18759
I0808 23:42:58.362598 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:42:58.362614 20451 solver.cpp:244]     Train net output #1: loss = 0.18759 (* 1 = 0.18759 loss)
I0808 23:42:58.362627 20451 sgd_solver.cpp:106] Iteration 15500, lr = 0.000495558
I0808 23:43:20.655911 20451 solver.cpp:228] Iteration 15510, loss = 0.156323
I0808 23:43:20.655962 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:43:20.655977 20451 solver.cpp:244]     Train net output #1: loss = 0.156324 (* 1 = 0.156324 loss)
I0808 23:43:20.655988 20451 sgd_solver.cpp:106] Iteration 15510, lr = 0.000495413
I0808 23:43:42.967175 20451 solver.cpp:228] Iteration 15520, loss = 0.12505
I0808 23:43:42.967360 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:43:42.967375 20451 solver.cpp:244]     Train net output #1: loss = 0.12505 (* 1 = 0.12505 loss)
I0808 23:43:42.967386 20451 sgd_solver.cpp:106] Iteration 15520, lr = 0.000495267
I0808 23:44:05.274989 20451 solver.cpp:228] Iteration 15530, loss = 0.125061
I0808 23:44:05.275043 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:44:05.275056 20451 solver.cpp:244]     Train net output #1: loss = 0.125061 (* 1 = 0.125061 loss)
I0808 23:44:05.275068 20451 sgd_solver.cpp:106] Iteration 15530, lr = 0.000495122
I0808 23:44:27.583330 20451 solver.cpp:228] Iteration 15540, loss = 0.218863
I0808 23:44:27.583503 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:44:27.583519 20451 solver.cpp:244]     Train net output #1: loss = 0.218863 (* 1 = 0.218863 loss)
I0808 23:44:27.583533 20451 sgd_solver.cpp:106] Iteration 15540, lr = 0.000494976
I0808 23:44:49.886113 20451 solver.cpp:228] Iteration 15550, loss = 0.125098
I0808 23:44:49.886168 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:44:49.886181 20451 solver.cpp:244]     Train net output #1: loss = 0.125098 (* 1 = 0.125098 loss)
I0808 23:44:49.886194 20451 sgd_solver.cpp:106] Iteration 15550, lr = 0.000494831
I0808 23:45:12.188786 20451 solver.cpp:228] Iteration 15560, loss = 0.34384
I0808 23:45:12.188961 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 23:45:12.188977 20451 solver.cpp:244]     Train net output #1: loss = 0.34384 (* 1 = 0.34384 loss)
I0808 23:45:12.188990 20451 sgd_solver.cpp:106] Iteration 15560, lr = 0.000494686
I0808 23:45:34.499387 20451 solver.cpp:228] Iteration 15570, loss = 0.250174
I0808 23:45:34.499440 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:45:34.499454 20451 solver.cpp:244]     Train net output #1: loss = 0.250174 (* 1 = 0.250174 loss)
I0808 23:45:34.499466 20451 sgd_solver.cpp:106] Iteration 15570, lr = 0.000494541
I0808 23:45:56.809293 20451 solver.cpp:228] Iteration 15580, loss = 0.156378
I0808 23:45:56.809556 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:45:56.809571 20451 solver.cpp:244]     Train net output #1: loss = 0.156378 (* 1 = 0.156378 loss)
I0808 23:45:56.809583 20451 sgd_solver.cpp:106] Iteration 15580, lr = 0.000494396
I0808 23:46:19.129969 20451 solver.cpp:228] Iteration 15590, loss = 0.219071
I0808 23:46:19.130023 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:46:19.130036 20451 solver.cpp:244]     Train net output #1: loss = 0.219072 (* 1 = 0.219072 loss)
I0808 23:46:19.130048 20451 sgd_solver.cpp:106] Iteration 15590, lr = 0.000494251
I0808 23:46:39.213106 20451 solver.cpp:337] Iteration 15600, Testing net (#0)
I0808 23:46:47.733948 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 23:46:47.734000 20451 solver.cpp:404]     Test net output #1: loss = 0.999915 (* 1 = 0.999915 loss)
I0808 23:46:49.935889 20451 solver.cpp:228] Iteration 15600, loss = 0.219234
I0808 23:46:49.935941 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:46:49.935956 20451 solver.cpp:244]     Train net output #1: loss = 0.219234 (* 1 = 0.219234 loss)
I0808 23:46:49.935967 20451 sgd_solver.cpp:106] Iteration 15600, lr = 0.000494106
I0808 23:47:12.220453 20451 solver.cpp:228] Iteration 15610, loss = 0.0937971
I0808 23:47:12.220621 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:47:12.220638 20451 solver.cpp:244]     Train net output #1: loss = 0.0937972 (* 1 = 0.0937972 loss)
I0808 23:47:12.220650 20451 sgd_solver.cpp:106] Iteration 15610, lr = 0.000493961
I0808 23:47:34.517206 20451 solver.cpp:228] Iteration 15620, loss = 0.25013
I0808 23:47:34.517258 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:47:34.517272 20451 solver.cpp:244]     Train net output #1: loss = 0.25013 (* 1 = 0.25013 loss)
I0808 23:47:34.517284 20451 sgd_solver.cpp:106] Iteration 15620, lr = 0.000493817
I0808 23:47:56.821027 20451 solver.cpp:228] Iteration 15630, loss = 0.187637
I0808 23:47:56.821221 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:47:56.821238 20451 solver.cpp:244]     Train net output #1: loss = 0.187637 (* 1 = 0.187637 loss)
I0808 23:47:56.821251 20451 sgd_solver.cpp:106] Iteration 15630, lr = 0.000493672
I0808 23:48:19.136029 20451 solver.cpp:228] Iteration 15640, loss = 0.218773
I0808 23:48:19.136081 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:48:19.136096 20451 solver.cpp:244]     Train net output #1: loss = 0.218773 (* 1 = 0.218773 loss)
I0808 23:48:19.136108 20451 sgd_solver.cpp:106] Iteration 15640, lr = 0.000493528
I0808 23:48:41.447759 20451 solver.cpp:228] Iteration 15650, loss = 0.250055
I0808 23:48:41.447937 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:48:41.447952 20451 solver.cpp:244]     Train net output #1: loss = 0.250055 (* 1 = 0.250055 loss)
I0808 23:48:41.447965 20451 sgd_solver.cpp:106] Iteration 15650, lr = 0.000493383
I0808 23:49:03.762648 20451 solver.cpp:228] Iteration 15660, loss = 0.12504
I0808 23:49:03.762703 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:49:03.762722 20451 solver.cpp:244]     Train net output #1: loss = 0.12504 (* 1 = 0.12504 loss)
I0808 23:49:03.762743 20451 sgd_solver.cpp:106] Iteration 15660, lr = 0.000493239
I0808 23:49:26.072011 20451 solver.cpp:228] Iteration 15670, loss = 0.125067
I0808 23:49:26.072227 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0808 23:49:26.072242 20451 solver.cpp:244]     Train net output #1: loss = 0.125067 (* 1 = 0.125067 loss)
I0808 23:49:26.072254 20451 sgd_solver.cpp:106] Iteration 15670, lr = 0.000493095
I0808 23:49:48.370167 20451 solver.cpp:228] Iteration 15680, loss = 0.218818
I0808 23:49:48.370220 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:49:48.370234 20451 solver.cpp:244]     Train net output #1: loss = 0.218818 (* 1 = 0.218818 loss)
I0808 23:49:48.370246 20451 sgd_solver.cpp:106] Iteration 15680, lr = 0.000492951
I0808 23:50:10.673336 20451 solver.cpp:228] Iteration 15690, loss = 0.187618
I0808 23:50:10.673517 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:50:10.673532 20451 solver.cpp:244]     Train net output #1: loss = 0.187618 (* 1 = 0.187618 loss)
I0808 23:50:10.673545 20451 sgd_solver.cpp:106] Iteration 15690, lr = 0.000492807
I0808 23:50:30.749451 20451 solver.cpp:337] Iteration 15700, Testing net (#0)
I0808 23:50:39.268574 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0808 23:50:39.268625 20451 solver.cpp:404]     Test net output #1: loss = 0.998471 (* 1 = 0.998471 loss)
I0808 23:50:41.472443 20451 solver.cpp:228] Iteration 15700, loss = 0.218824
I0808 23:50:41.472627 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0808 23:50:41.472647 20451 solver.cpp:244]     Train net output #1: loss = 0.218824 (* 1 = 0.218824 loss)
I0808 23:50:41.472662 20451 sgd_solver.cpp:106] Iteration 15700, lr = 0.000492663
I0808 23:51:03.759165 20451 solver.cpp:228] Iteration 15710, loss = 0.250054
I0808 23:51:03.759214 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:51:03.759228 20451 solver.cpp:244]     Train net output #1: loss = 0.250054 (* 1 = 0.250054 loss)
I0808 23:51:03.759240 20451 sgd_solver.cpp:106] Iteration 15710, lr = 0.00049252
I0808 23:51:26.067420 20451 solver.cpp:228] Iteration 15720, loss = 0.156265
I0808 23:51:26.067595 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:51:26.067610 20451 solver.cpp:244]     Train net output #1: loss = 0.156265 (* 1 = 0.156265 loss)
I0808 23:51:26.067623 20451 sgd_solver.cpp:106] Iteration 15720, lr = 0.000492376
I0808 23:51:48.373642 20451 solver.cpp:228] Iteration 15730, loss = 0.0625474
I0808 23:51:48.373697 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0808 23:51:48.373711 20451 solver.cpp:244]     Train net output #1: loss = 0.0625475 (* 1 = 0.0625475 loss)
I0808 23:51:48.373724 20451 sgd_solver.cpp:106] Iteration 15730, lr = 0.000492232
I0808 23:52:10.679433 20451 solver.cpp:228] Iteration 15740, loss = 0.187569
I0808 23:52:10.679616 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:52:10.679632 20451 solver.cpp:244]     Train net output #1: loss = 0.187569 (* 1 = 0.187569 loss)
I0808 23:52:10.679646 20451 sgd_solver.cpp:106] Iteration 15740, lr = 0.000492089
I0808 23:52:32.976562 20451 solver.cpp:228] Iteration 15750, loss = 0.0938225
I0808 23:52:32.976613 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:52:32.976627 20451 solver.cpp:244]     Train net output #1: loss = 0.0938226 (* 1 = 0.0938226 loss)
I0808 23:52:32.976639 20451 sgd_solver.cpp:106] Iteration 15750, lr = 0.000491946
I0808 23:52:55.279505 20451 solver.cpp:228] Iteration 15760, loss = 0.156321
I0808 23:52:55.279685 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:52:55.279701 20451 solver.cpp:244]     Train net output #1: loss = 0.156321 (* 1 = 0.156321 loss)
I0808 23:52:55.279714 20451 sgd_solver.cpp:106] Iteration 15760, lr = 0.000491802
I0808 23:53:17.592926 20451 solver.cpp:228] Iteration 15770, loss = 0.250154
I0808 23:53:17.592969 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:53:17.592988 20451 solver.cpp:244]     Train net output #1: loss = 0.250154 (* 1 = 0.250154 loss)
I0808 23:53:17.593011 20451 sgd_solver.cpp:106] Iteration 15770, lr = 0.000491659
I0808 23:53:39.902645 20451 solver.cpp:228] Iteration 15780, loss = 0.093776
I0808 23:53:39.902858 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:53:39.902875 20451 solver.cpp:244]     Train net output #1: loss = 0.0937761 (* 1 = 0.0937761 loss)
I0808 23:53:39.902887 20451 sgd_solver.cpp:106] Iteration 15780, lr = 0.000491516
I0808 23:54:02.226829 20451 solver.cpp:228] Iteration 15790, loss = 0.250117
I0808 23:54:02.226881 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:54:02.226894 20451 solver.cpp:244]     Train net output #1: loss = 0.250117 (* 1 = 0.250117 loss)
I0808 23:54:02.226907 20451 sgd_solver.cpp:106] Iteration 15790, lr = 0.000491373
I0808 23:54:22.309631 20451 solver.cpp:337] Iteration 15800, Testing net (#0)
I0808 23:54:30.837160 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0808 23:54:30.837211 20451 solver.cpp:404]     Test net output #1: loss = 1.0081 (* 1 = 1.0081 loss)
I0808 23:54:33.043311 20451 solver.cpp:228] Iteration 15800, loss = 0.250126
I0808 23:54:33.043361 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:54:33.043375 20451 solver.cpp:244]     Train net output #1: loss = 0.250126 (* 1 = 0.250126 loss)
I0808 23:54:33.043388 20451 sgd_solver.cpp:106] Iteration 15800, lr = 0.00049123
I0808 23:54:55.325238 20451 solver.cpp:228] Iteration 15810, loss = 0.218863
I0808 23:54:55.325418 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:54:55.325434 20451 solver.cpp:244]     Train net output #1: loss = 0.218864 (* 1 = 0.218864 loss)
I0808 23:54:55.325446 20451 sgd_solver.cpp:106] Iteration 15810, lr = 0.000491088
I0808 23:55:17.629259 20451 solver.cpp:228] Iteration 15820, loss = 0.312616
I0808 23:55:17.629314 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0808 23:55:17.629331 20451 solver.cpp:244]     Train net output #1: loss = 0.312616 (* 1 = 0.312616 loss)
I0808 23:55:17.629345 20451 sgd_solver.cpp:106] Iteration 15820, lr = 0.000490945
I0808 23:55:39.930227 20451 solver.cpp:228] Iteration 15830, loss = 0.187665
I0808 23:55:39.930413 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:55:39.930428 20451 solver.cpp:244]     Train net output #1: loss = 0.187665 (* 1 = 0.187665 loss)
I0808 23:55:39.930440 20451 sgd_solver.cpp:106] Iteration 15830, lr = 0.000490802
I0808 23:56:02.242677 20451 solver.cpp:228] Iteration 15840, loss = 0.218768
I0808 23:56:02.242727 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:56:02.242740 20451 solver.cpp:244]     Train net output #1: loss = 0.218768 (* 1 = 0.218768 loss)
I0808 23:56:02.242753 20451 sgd_solver.cpp:106] Iteration 15840, lr = 0.00049066
I0808 23:56:24.546721 20451 solver.cpp:228] Iteration 15850, loss = 0.344112
I0808 23:56:24.546895 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 23:56:24.546910 20451 solver.cpp:244]     Train net output #1: loss = 0.344112 (* 1 = 0.344112 loss)
I0808 23:56:24.546922 20451 sgd_solver.cpp:106] Iteration 15850, lr = 0.000490518
I0808 23:56:46.836084 20451 solver.cpp:228] Iteration 15860, loss = 0.156325
I0808 23:56:46.836138 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:56:46.836156 20451 solver.cpp:244]     Train net output #1: loss = 0.156325 (* 1 = 0.156325 loss)
I0808 23:56:46.836171 20451 sgd_solver.cpp:106] Iteration 15860, lr = 0.000490375
I0808 23:57:09.141844 20451 solver.cpp:228] Iteration 15870, loss = 0.156347
I0808 23:57:09.142032 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:57:09.142051 20451 solver.cpp:244]     Train net output #1: loss = 0.156348 (* 1 = 0.156348 loss)
I0808 23:57:09.142066 20451 sgd_solver.cpp:106] Iteration 15870, lr = 0.000490233
I0808 23:57:31.441154 20451 solver.cpp:228] Iteration 15880, loss = 0.187542
I0808 23:57:31.441206 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0808 23:57:31.441220 20451 solver.cpp:244]     Train net output #1: loss = 0.187542 (* 1 = 0.187542 loss)
I0808 23:57:31.441232 20451 sgd_solver.cpp:106] Iteration 15880, lr = 0.000490091
I0808 23:57:53.746101 20451 solver.cpp:228] Iteration 15890, loss = 0.218936
I0808 23:57:53.746306 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0808 23:57:53.746323 20451 solver.cpp:244]     Train net output #1: loss = 0.218936 (* 1 = 0.218936 loss)
I0808 23:57:53.746336 20451 sgd_solver.cpp:106] Iteration 15890, lr = 0.000489949
I0808 23:58:13.826913 20451 solver.cpp:337] Iteration 15900, Testing net (#0)
I0808 23:58:22.348961 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0808 23:58:22.349014 20451 solver.cpp:404]     Test net output #1: loss = 1.0033 (* 1 = 1.0033 loss)
I0808 23:58:24.551273 20451 solver.cpp:228] Iteration 15900, loss = 0.0937739
I0808 23:58:24.551453 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0808 23:58:24.551468 20451 solver.cpp:244]     Train net output #1: loss = 0.093774 (* 1 = 0.093774 loss)
I0808 23:58:24.551481 20451 sgd_solver.cpp:106] Iteration 15900, lr = 0.000489807
I0808 23:58:46.832237 20451 solver.cpp:228] Iteration 15910, loss = 0.343954
I0808 23:58:46.832288 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0808 23:58:46.832306 20451 solver.cpp:244]     Train net output #1: loss = 0.343955 (* 1 = 0.343955 loss)
I0808 23:58:46.832324 20451 sgd_solver.cpp:106] Iteration 15910, lr = 0.000489665
I0808 23:59:09.137693 20451 solver.cpp:228] Iteration 15920, loss = 0.18758
I0808 23:59:09.137876 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0808 23:59:09.137895 20451 solver.cpp:244]     Train net output #1: loss = 0.18758 (* 1 = 0.18758 loss)
I0808 23:59:09.137910 20451 sgd_solver.cpp:106] Iteration 15920, lr = 0.000489524
I0808 23:59:31.440836 20451 solver.cpp:228] Iteration 15930, loss = 0.281481
I0808 23:59:31.440884 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0808 23:59:31.440903 20451 solver.cpp:244]     Train net output #1: loss = 0.281481 (* 1 = 0.281481 loss)
I0808 23:59:31.440918 20451 sgd_solver.cpp:106] Iteration 15930, lr = 0.000489382
I0808 23:59:53.745096 20451 solver.cpp:228] Iteration 15940, loss = 0.250108
I0808 23:59:53.745278 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0808 23:59:53.745297 20451 solver.cpp:244]     Train net output #1: loss = 0.250108 (* 1 = 0.250108 loss)
I0808 23:59:53.745313 20451 sgd_solver.cpp:106] Iteration 15940, lr = 0.000489241
I0809 00:00:16.052130 20451 solver.cpp:228] Iteration 15950, loss = 0.250147
I0809 00:00:16.052183 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:00:16.052197 20451 solver.cpp:244]     Train net output #1: loss = 0.250147 (* 1 = 0.250147 loss)
I0809 00:00:16.052211 20451 sgd_solver.cpp:106] Iteration 15950, lr = 0.000489099
I0809 00:00:38.371137 20451 solver.cpp:228] Iteration 15960, loss = 0.218808
I0809 00:00:38.371318 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:00:38.371335 20451 solver.cpp:244]     Train net output #1: loss = 0.218808 (* 1 = 0.218808 loss)
I0809 00:00:38.371346 20451 sgd_solver.cpp:106] Iteration 15960, lr = 0.000488958
I0809 00:01:00.672502 20451 solver.cpp:228] Iteration 15970, loss = 0.0938206
I0809 00:01:00.672555 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:01:00.672570 20451 solver.cpp:244]     Train net output #1: loss = 0.0938207 (* 1 = 0.0938207 loss)
I0809 00:01:00.672582 20451 sgd_solver.cpp:106] Iteration 15970, lr = 0.000488817
I0809 00:01:22.980811 20451 solver.cpp:228] Iteration 15980, loss = 0.187516
I0809 00:01:22.980907 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:01:22.980927 20451 solver.cpp:244]     Train net output #1: loss = 0.187516 (* 1 = 0.187516 loss)
I0809 00:01:22.980942 20451 sgd_solver.cpp:106] Iteration 15980, lr = 0.000488676
I0809 00:01:45.299120 20451 solver.cpp:228] Iteration 15990, loss = 0.218866
I0809 00:01:45.299166 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:01:45.299185 20451 solver.cpp:244]     Train net output #1: loss = 0.218866 (* 1 = 0.218866 loss)
I0809 00:01:45.299201 20451 sgd_solver.cpp:106] Iteration 15990, lr = 0.000488535
I0809 00:02:05.377050 20451 solver.cpp:337] Iteration 16000, Testing net (#0)
I0809 00:02:13.900225 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0809 00:02:13.900272 20451 solver.cpp:404]     Test net output #1: loss = 0.961085 (* 1 = 0.961085 loss)
I0809 00:02:16.100292 20451 solver.cpp:228] Iteration 16000, loss = 0.187541
I0809 00:02:16.100347 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:02:16.100360 20451 solver.cpp:244]     Train net output #1: loss = 0.187542 (* 1 = 0.187542 loss)
I0809 00:02:16.100373 20451 sgd_solver.cpp:106] Iteration 16000, lr = 0.000488394
I0809 00:02:38.375041 20451 solver.cpp:228] Iteration 16010, loss = 0.0937948
I0809 00:02:38.375232 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:02:38.375248 20451 solver.cpp:244]     Train net output #1: loss = 0.0937949 (* 1 = 0.0937949 loss)
I0809 00:02:38.375262 20451 sgd_solver.cpp:106] Iteration 16010, lr = 0.000488253
I0809 00:03:00.684870 20451 solver.cpp:228] Iteration 16020, loss = 0.218803
I0809 00:03:00.684923 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:03:00.684937 20451 solver.cpp:244]     Train net output #1: loss = 0.218803 (* 1 = 0.218803 loss)
I0809 00:03:00.684949 20451 sgd_solver.cpp:106] Iteration 16020, lr = 0.000488112
I0809 00:03:22.990159 20451 solver.cpp:228] Iteration 16030, loss = 0.0312598
I0809 00:03:22.990253 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 00:03:22.990268 20451 solver.cpp:244]     Train net output #1: loss = 0.0312599 (* 1 = 0.0312599 loss)
I0809 00:03:22.990281 20451 sgd_solver.cpp:106] Iteration 16030, lr = 0.000487971
I0809 00:03:45.306471 20451 solver.cpp:228] Iteration 16040, loss = 0.281308
I0809 00:03:45.306522 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 00:03:45.306536 20451 solver.cpp:244]     Train net output #1: loss = 0.281308 (* 1 = 0.281308 loss)
I0809 00:03:45.306548 20451 sgd_solver.cpp:106] Iteration 16040, lr = 0.000487831
I0809 00:04:07.616257 20451 solver.cpp:228] Iteration 16050, loss = 0.187564
I0809 00:04:07.616432 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:04:07.616447 20451 solver.cpp:244]     Train net output #1: loss = 0.187564 (* 1 = 0.187564 loss)
I0809 00:04:07.616459 20451 sgd_solver.cpp:106] Iteration 16050, lr = 0.00048769
I0809 00:04:29.928021 20451 solver.cpp:228] Iteration 16060, loss = 0.156454
I0809 00:04:29.928073 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:04:29.928087 20451 solver.cpp:244]     Train net output #1: loss = 0.156454 (* 1 = 0.156454 loss)
I0809 00:04:29.928099 20451 sgd_solver.cpp:106] Iteration 16060, lr = 0.00048755
I0809 00:04:52.226303 20451 solver.cpp:228] Iteration 16070, loss = 0.125195
I0809 00:04:52.226481 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:04:52.226496 20451 solver.cpp:244]     Train net output #1: loss = 0.125195 (* 1 = 0.125195 loss)
I0809 00:04:52.226508 20451 sgd_solver.cpp:106] Iteration 16070, lr = 0.00048741
I0809 00:05:14.530627 20451 solver.cpp:228] Iteration 16080, loss = 0.187502
I0809 00:05:14.530680 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:05:14.530694 20451 solver.cpp:244]     Train net output #1: loss = 0.187502 (* 1 = 0.187502 loss)
I0809 00:05:14.530706 20451 sgd_solver.cpp:106] Iteration 16080, lr = 0.00048727
I0809 00:05:36.836866 20451 solver.cpp:228] Iteration 16090, loss = 0.250076
I0809 00:05:36.837045 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:05:36.837061 20451 solver.cpp:244]     Train net output #1: loss = 0.250076 (* 1 = 0.250076 loss)
I0809 00:05:36.837074 20451 sgd_solver.cpp:106] Iteration 16090, lr = 0.00048713
I0809 00:05:56.921902 20451 solver.cpp:337] Iteration 16100, Testing net (#0)
I0809 00:06:05.454206 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 00:06:05.454258 20451 solver.cpp:404]     Test net output #1: loss = 0.993804 (* 1 = 0.993804 loss)
I0809 00:06:07.658159 20451 solver.cpp:228] Iteration 16100, loss = 0.0626466
I0809 00:06:07.658357 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:06:07.658373 20451 solver.cpp:244]     Train net output #1: loss = 0.0626467 (* 1 = 0.0626467 loss)
I0809 00:06:07.658386 20451 sgd_solver.cpp:106] Iteration 16100, lr = 0.00048699
I0809 00:06:29.951114 20451 solver.cpp:228] Iteration 16110, loss = 0.281421
I0809 00:06:29.951169 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 00:06:29.951182 20451 solver.cpp:244]     Train net output #1: loss = 0.281421 (* 1 = 0.281421 loss)
I0809 00:06:29.951195 20451 sgd_solver.cpp:106] Iteration 16110, lr = 0.00048685
I0809 00:06:52.261857 20451 solver.cpp:228] Iteration 16120, loss = 0.0937761
I0809 00:06:52.262033 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:06:52.262050 20451 solver.cpp:244]     Train net output #1: loss = 0.0937762 (* 1 = 0.0937762 loss)
I0809 00:06:52.262063 20451 sgd_solver.cpp:106] Iteration 16120, lr = 0.00048671
I0809 00:07:14.578503 20451 solver.cpp:228] Iteration 16130, loss = 0.125016
I0809 00:07:14.578555 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:07:14.578568 20451 solver.cpp:244]     Train net output #1: loss = 0.125016 (* 1 = 0.125016 loss)
I0809 00:07:14.578582 20451 sgd_solver.cpp:106] Iteration 16130, lr = 0.00048657
I0809 00:07:36.883021 20451 solver.cpp:228] Iteration 16140, loss = 0.250056
I0809 00:07:36.883213 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:07:36.883229 20451 solver.cpp:244]     Train net output #1: loss = 0.250056 (* 1 = 0.250056 loss)
I0809 00:07:36.883241 20451 sgd_solver.cpp:106] Iteration 16140, lr = 0.000486431
I0809 00:07:59.179601 20451 solver.cpp:228] Iteration 16150, loss = 0.125051
I0809 00:07:59.179656 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:07:59.179669 20451 solver.cpp:244]     Train net output #1: loss = 0.125051 (* 1 = 0.125051 loss)
I0809 00:07:59.179682 20451 sgd_solver.cpp:106] Iteration 16150, lr = 0.000486291
I0809 00:08:21.491027 20451 solver.cpp:228] Iteration 16160, loss = 0.187676
I0809 00:08:21.491204 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:08:21.491219 20451 solver.cpp:244]     Train net output #1: loss = 0.187676 (* 1 = 0.187676 loss)
I0809 00:08:21.491232 20451 sgd_solver.cpp:106] Iteration 16160, lr = 0.000486152
I0809 00:08:43.794510 20451 solver.cpp:228] Iteration 16170, loss = 0.218825
I0809 00:08:43.794559 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:08:43.794574 20451 solver.cpp:244]     Train net output #1: loss = 0.218825 (* 1 = 0.218825 loss)
I0809 00:08:43.794589 20451 sgd_solver.cpp:106] Iteration 16170, lr = 0.000486012
I0809 00:09:06.119261 20451 solver.cpp:228] Iteration 16180, loss = 0.250122
I0809 00:09:06.119451 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:09:06.119467 20451 solver.cpp:244]     Train net output #1: loss = 0.250122 (* 1 = 0.250122 loss)
I0809 00:09:06.119478 20451 sgd_solver.cpp:106] Iteration 16180, lr = 0.000485873
I0809 00:09:28.426029 20451 solver.cpp:228] Iteration 16190, loss = 0.187523
I0809 00:09:28.426081 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:09:28.426095 20451 solver.cpp:244]     Train net output #1: loss = 0.187523 (* 1 = 0.187523 loss)
I0809 00:09:28.426107 20451 sgd_solver.cpp:106] Iteration 16190, lr = 0.000485734
I0809 00:09:48.515162 20451 solver.cpp:337] Iteration 16200, Testing net (#0)
I0809 00:09:57.038136 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 00:09:57.038187 20451 solver.cpp:404]     Test net output #1: loss = 0.998792 (* 1 = 0.998792 loss)
I0809 00:09:59.239974 20451 solver.cpp:228] Iteration 16200, loss = 0.312663
I0809 00:09:59.240031 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 00:09:59.240046 20451 solver.cpp:244]     Train net output #1: loss = 0.312663 (* 1 = 0.312663 loss)
I0809 00:09:59.240057 20451 sgd_solver.cpp:106] Iteration 16200, lr = 0.000485595
I0809 00:10:21.528724 20451 solver.cpp:228] Iteration 16210, loss = 0.312519
I0809 00:10:21.528941 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 00:10:21.528957 20451 solver.cpp:244]     Train net output #1: loss = 0.312519 (* 1 = 0.312519 loss)
I0809 00:10:21.528970 20451 sgd_solver.cpp:106] Iteration 16210, lr = 0.000485456
I0809 00:10:43.847550 20451 solver.cpp:228] Iteration 16220, loss = 0.125272
I0809 00:10:43.847597 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:10:43.847616 20451 solver.cpp:244]     Train net output #1: loss = 0.125272 (* 1 = 0.125272 loss)
I0809 00:10:43.847631 20451 sgd_solver.cpp:106] Iteration 16220, lr = 0.000485317
I0809 00:11:06.163620 20451 solver.cpp:228] Iteration 16230, loss = 0.156306
I0809 00:11:06.163735 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:11:06.163754 20451 solver.cpp:244]     Train net output #1: loss = 0.156306 (* 1 = 0.156306 loss)
I0809 00:11:06.163770 20451 sgd_solver.cpp:106] Iteration 16230, lr = 0.000485178
I0809 00:11:28.478338 20451 solver.cpp:228] Iteration 16240, loss = 0.187884
I0809 00:11:28.478392 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:11:28.478406 20451 solver.cpp:244]     Train net output #1: loss = 0.187884 (* 1 = 0.187884 loss)
I0809 00:11:28.478418 20451 sgd_solver.cpp:106] Iteration 16240, lr = 0.00048504
I0809 00:11:50.799084 20451 solver.cpp:228] Iteration 16250, loss = 0.218961
I0809 00:11:50.799259 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:11:50.799278 20451 solver.cpp:244]     Train net output #1: loss = 0.218961 (* 1 = 0.218961 loss)
I0809 00:11:50.799291 20451 sgd_solver.cpp:106] Iteration 16250, lr = 0.000484901
I0809 00:12:13.118619 20451 solver.cpp:228] Iteration 16260, loss = 0.125217
I0809 00:12:13.118670 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:12:13.118683 20451 solver.cpp:244]     Train net output #1: loss = 0.125217 (* 1 = 0.125217 loss)
I0809 00:12:13.118695 20451 sgd_solver.cpp:106] Iteration 16260, lr = 0.000484762
I0809 00:12:35.440181 20451 solver.cpp:228] Iteration 16270, loss = 0.0938401
I0809 00:12:35.440357 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:12:35.440372 20451 solver.cpp:244]     Train net output #1: loss = 0.0938402 (* 1 = 0.0938402 loss)
I0809 00:12:35.440385 20451 sgd_solver.cpp:106] Iteration 16270, lr = 0.000484624
I0809 00:12:57.755291 20451 solver.cpp:228] Iteration 16280, loss = 0.219149
I0809 00:12:57.755347 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:12:57.755359 20451 solver.cpp:244]     Train net output #1: loss = 0.219149 (* 1 = 0.219149 loss)
I0809 00:12:57.755373 20451 sgd_solver.cpp:106] Iteration 16280, lr = 0.000484486
I0809 00:13:20.072301 20451 solver.cpp:228] Iteration 16290, loss = 0.219082
I0809 00:13:20.072479 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:13:20.072494 20451 solver.cpp:244]     Train net output #1: loss = 0.219082 (* 1 = 0.219082 loss)
I0809 00:13:20.072507 20451 sgd_solver.cpp:106] Iteration 16290, lr = 0.000484348
I0809 00:13:40.161871 20451 solver.cpp:337] Iteration 16300, Testing net (#0)
I0809 00:13:48.688262 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0809 00:13:48.688313 20451 solver.cpp:404]     Test net output #1: loss = 0.989752 (* 1 = 0.989752 loss)
I0809 00:13:50.892171 20451 solver.cpp:228] Iteration 16300, loss = 0.0938471
I0809 00:13:50.892350 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:13:50.892365 20451 solver.cpp:244]     Train net output #1: loss = 0.0938472 (* 1 = 0.0938472 loss)
I0809 00:13:50.892379 20451 sgd_solver.cpp:106] Iteration 16300, lr = 0.000484209
I0809 00:14:13.185062 20451 solver.cpp:228] Iteration 16310, loss = 0.250622
I0809 00:14:13.185113 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:14:13.185127 20451 solver.cpp:244]     Train net output #1: loss = 0.250622 (* 1 = 0.250622 loss)
I0809 00:14:13.185139 20451 sgd_solver.cpp:106] Iteration 16310, lr = 0.000484071
I0809 00:14:35.504699 20451 solver.cpp:228] Iteration 16320, loss = 0.218844
I0809 00:14:35.504919 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:14:35.504935 20451 solver.cpp:244]     Train net output #1: loss = 0.218844 (* 1 = 0.218844 loss)
I0809 00:14:35.504946 20451 sgd_solver.cpp:106] Iteration 16320, lr = 0.000483933
I0809 00:14:57.815682 20451 solver.cpp:228] Iteration 16330, loss = 0.250335
I0809 00:14:57.815733 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:14:57.815747 20451 solver.cpp:244]     Train net output #1: loss = 0.250335 (* 1 = 0.250335 loss)
I0809 00:14:57.815759 20451 sgd_solver.cpp:106] Iteration 16330, lr = 0.000483796
I0809 00:15:20.134847 20451 solver.cpp:228] Iteration 16340, loss = 0.156269
I0809 00:15:20.135032 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:15:20.135047 20451 solver.cpp:244]     Train net output #1: loss = 0.15627 (* 1 = 0.15627 loss)
I0809 00:15:20.135061 20451 sgd_solver.cpp:106] Iteration 16340, lr = 0.000483658
I0809 00:15:42.449005 20451 solver.cpp:228] Iteration 16350, loss = 0.250438
I0809 00:15:42.449059 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:15:42.449072 20451 solver.cpp:244]     Train net output #1: loss = 0.250438 (* 1 = 0.250438 loss)
I0809 00:15:42.449084 20451 sgd_solver.cpp:106] Iteration 16350, lr = 0.00048352
I0809 00:16:04.761659 20451 solver.cpp:228] Iteration 16360, loss = 0.125056
I0809 00:16:04.761762 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:16:04.761782 20451 solver.cpp:244]     Train net output #1: loss = 0.125056 (* 1 = 0.125056 loss)
I0809 00:16:04.761798 20451 sgd_solver.cpp:106] Iteration 16360, lr = 0.000483383
I0809 00:16:27.072144 20451 solver.cpp:228] Iteration 16370, loss = 0.250486
I0809 00:16:27.072187 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:16:27.072206 20451 solver.cpp:244]     Train net output #1: loss = 0.250486 (* 1 = 0.250486 loss)
I0809 00:16:27.072221 20451 sgd_solver.cpp:106] Iteration 16370, lr = 0.000483245
I0809 00:16:49.386894 20451 solver.cpp:228] Iteration 16380, loss = 0.187628
I0809 00:16:49.387148 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:16:49.387212 20451 solver.cpp:244]     Train net output #1: loss = 0.187628 (* 1 = 0.187628 loss)
I0809 00:16:49.387244 20451 sgd_solver.cpp:106] Iteration 16380, lr = 0.000483108
I0809 00:17:11.697149 20451 solver.cpp:228] Iteration 16390, loss = 0.250418
I0809 00:17:11.697201 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:17:11.697214 20451 solver.cpp:244]     Train net output #1: loss = 0.250418 (* 1 = 0.250418 loss)
I0809 00:17:11.697227 20451 sgd_solver.cpp:106] Iteration 16390, lr = 0.00048297
I0809 00:17:31.771948 20451 solver.cpp:337] Iteration 16400, Testing net (#0)
I0809 00:17:40.297612 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0809 00:17:40.297654 20451 solver.cpp:404]     Test net output #1: loss = 1.03625 (* 1 = 1.03625 loss)
I0809 00:17:42.503880 20451 solver.cpp:228] Iteration 16400, loss = 0.15632
I0809 00:17:42.503932 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:17:42.503947 20451 solver.cpp:244]     Train net output #1: loss = 0.156321 (* 1 = 0.156321 loss)
I0809 00:17:42.503958 20451 sgd_solver.cpp:106] Iteration 16400, lr = 0.000482833
I0809 00:18:04.787395 20451 solver.cpp:228] Iteration 16410, loss = 0.25004
I0809 00:18:04.787542 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:18:04.787559 20451 solver.cpp:244]     Train net output #1: loss = 0.250041 (* 1 = 0.250041 loss)
I0809 00:18:04.787575 20451 sgd_solver.cpp:106] Iteration 16410, lr = 0.000482696
I0809 00:18:27.093418 20451 solver.cpp:228] Iteration 16420, loss = 0.34395
I0809 00:18:27.093471 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 00:18:27.093484 20451 solver.cpp:244]     Train net output #1: loss = 0.34395 (* 1 = 0.34395 loss)
I0809 00:18:27.093497 20451 sgd_solver.cpp:106] Iteration 16420, lr = 0.000482559
I0809 00:18:49.398545 20451 solver.cpp:228] Iteration 16430, loss = 0.218793
I0809 00:18:49.398763 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:18:49.398779 20451 solver.cpp:244]     Train net output #1: loss = 0.218794 (* 1 = 0.218794 loss)
I0809 00:18:49.398792 20451 sgd_solver.cpp:106] Iteration 16430, lr = 0.000482422
I0809 00:19:11.713317 20451 solver.cpp:228] Iteration 16440, loss = 0.125052
I0809 00:19:11.713369 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:19:11.713383 20451 solver.cpp:244]     Train net output #1: loss = 0.125052 (* 1 = 0.125052 loss)
I0809 00:19:11.713395 20451 sgd_solver.cpp:106] Iteration 16440, lr = 0.000482285
I0809 00:19:34.023685 20451 solver.cpp:228] Iteration 16450, loss = 0.0938483
I0809 00:19:34.023869 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:19:34.023885 20451 solver.cpp:244]     Train net output #1: loss = 0.0938484 (* 1 = 0.0938484 loss)
I0809 00:19:34.023896 20451 sgd_solver.cpp:106] Iteration 16450, lr = 0.000482148
I0809 00:19:56.330462 20451 solver.cpp:228] Iteration 16460, loss = 0.125242
I0809 00:19:56.330513 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:19:56.330528 20451 solver.cpp:244]     Train net output #1: loss = 0.125242 (* 1 = 0.125242 loss)
I0809 00:19:56.330541 20451 sgd_solver.cpp:106] Iteration 16460, lr = 0.000482012
I0809 00:20:18.650723 20451 solver.cpp:228] Iteration 16470, loss = 0.187514
I0809 00:20:18.650840 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:20:18.650856 20451 solver.cpp:244]     Train net output #1: loss = 0.187514 (* 1 = 0.187514 loss)
I0809 00:20:18.650867 20451 sgd_solver.cpp:106] Iteration 16470, lr = 0.000481875
I0809 00:20:40.964176 20451 solver.cpp:228] Iteration 16480, loss = 0.21899
I0809 00:20:40.964220 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:20:40.964237 20451 solver.cpp:244]     Train net output #1: loss = 0.21899 (* 1 = 0.21899 loss)
I0809 00:20:40.964251 20451 sgd_solver.cpp:106] Iteration 16480, lr = 0.000481739
I0809 00:21:03.276779 20451 solver.cpp:228] Iteration 16490, loss = 0.0938408
I0809 00:21:03.276954 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:21:03.276969 20451 solver.cpp:244]     Train net output #1: loss = 0.0938409 (* 1 = 0.0938409 loss)
I0809 00:21:03.276983 20451 sgd_solver.cpp:106] Iteration 16490, lr = 0.000481602
I0809 00:21:23.362335 20451 solver.cpp:337] Iteration 16500, Testing net (#0)
I0809 00:21:31.888262 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 00:21:31.888309 20451 solver.cpp:404]     Test net output #1: loss = 0.985694 (* 1 = 0.985694 loss)
I0809 00:21:34.091017 20451 solver.cpp:228] Iteration 16500, loss = 0.156562
I0809 00:21:34.091125 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:21:34.091143 20451 solver.cpp:244]     Train net output #1: loss = 0.156562 (* 1 = 0.156562 loss)
I0809 00:21:34.091158 20451 sgd_solver.cpp:106] Iteration 16500, lr = 0.000481466
I0809 00:21:56.369747 20451 solver.cpp:228] Iteration 16510, loss = 0.0943332
I0809 00:21:56.369799 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:21:56.369817 20451 solver.cpp:244]     Train net output #1: loss = 0.0943333 (* 1 = 0.0943333 loss)
I0809 00:21:56.369833 20451 sgd_solver.cpp:106] Iteration 16510, lr = 0.00048133
I0809 00:22:18.675216 20451 solver.cpp:228] Iteration 16520, loss = 0.187723
I0809 00:22:18.675405 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:22:18.675420 20451 solver.cpp:244]     Train net output #1: loss = 0.187723 (* 1 = 0.187723 loss)
I0809 00:22:18.675431 20451 sgd_solver.cpp:106] Iteration 16520, lr = 0.000481194
I0809 00:22:40.993041 20451 solver.cpp:228] Iteration 16530, loss = 0.156386
I0809 00:22:40.993086 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:22:40.993103 20451 solver.cpp:244]     Train net output #1: loss = 0.156386 (* 1 = 0.156386 loss)
I0809 00:22:40.993114 20451 sgd_solver.cpp:106] Iteration 16530, lr = 0.000481058
I0809 00:23:03.301040 20451 solver.cpp:228] Iteration 16540, loss = 0.219101
I0809 00:23:03.301242 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:23:03.301259 20451 solver.cpp:244]     Train net output #1: loss = 0.219101 (* 1 = 0.219101 loss)
I0809 00:23:03.301271 20451 sgd_solver.cpp:106] Iteration 16540, lr = 0.000480922
I0809 00:23:25.607964 20451 solver.cpp:228] Iteration 16550, loss = 0.312625
I0809 00:23:25.608011 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 00:23:25.608031 20451 solver.cpp:244]     Train net output #1: loss = 0.312625 (* 1 = 0.312625 loss)
I0809 00:23:25.608045 20451 sgd_solver.cpp:106] Iteration 16550, lr = 0.000480786
I0809 00:23:47.922775 20451 solver.cpp:228] Iteration 16560, loss = 0.1252
I0809 00:23:47.923022 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:23:47.923040 20451 solver.cpp:244]     Train net output #1: loss = 0.1252 (* 1 = 0.1252 loss)
I0809 00:23:47.923055 20451 sgd_solver.cpp:106] Iteration 16560, lr = 0.00048065
I0809 00:24:10.246044 20451 solver.cpp:228] Iteration 16570, loss = 0.218775
I0809 00:24:10.246098 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:24:10.246111 20451 solver.cpp:244]     Train net output #1: loss = 0.218775 (* 1 = 0.218775 loss)
I0809 00:24:10.246124 20451 sgd_solver.cpp:106] Iteration 16570, lr = 0.000480514
I0809 00:24:32.557672 20451 solver.cpp:228] Iteration 16580, loss = 0.187848
I0809 00:24:32.557884 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:24:32.557900 20451 solver.cpp:244]     Train net output #1: loss = 0.187848 (* 1 = 0.187848 loss)
I0809 00:24:32.557914 20451 sgd_solver.cpp:106] Iteration 16580, lr = 0.000480379
I0809 00:24:54.861826 20451 solver.cpp:228] Iteration 16590, loss = 0.156498
I0809 00:24:54.861878 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:24:54.861892 20451 solver.cpp:244]     Train net output #1: loss = 0.156498 (* 1 = 0.156498 loss)
I0809 00:24:54.861904 20451 sgd_solver.cpp:106] Iteration 16590, lr = 0.000480243
I0809 00:25:14.945086 20451 solver.cpp:337] Iteration 16600, Testing net (#0)
I0809 00:25:23.465908 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0809 00:25:23.465963 20451 solver.cpp:404]     Test net output #1: loss = 0.971656 (* 1 = 0.971656 loss)
I0809 00:25:25.669909 20451 solver.cpp:228] Iteration 16600, loss = 0.187888
I0809 00:25:25.669960 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:25:25.669973 20451 solver.cpp:244]     Train net output #1: loss = 0.187888 (* 1 = 0.187888 loss)
I0809 00:25:25.669986 20451 sgd_solver.cpp:106] Iteration 16600, lr = 0.000480108
I0809 00:25:47.947778 20451 solver.cpp:228] Iteration 16610, loss = 0.218792
I0809 00:25:47.947881 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:25:47.947896 20451 solver.cpp:244]     Train net output #1: loss = 0.218792 (* 1 = 0.218792 loss)
I0809 00:25:47.947909 20451 sgd_solver.cpp:106] Iteration 16610, lr = 0.000479973
I0809 00:26:10.260922 20451 solver.cpp:228] Iteration 16620, loss = 0.250168
I0809 00:26:10.260973 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:26:10.260987 20451 solver.cpp:244]     Train net output #1: loss = 0.250168 (* 1 = 0.250168 loss)
I0809 00:26:10.260998 20451 sgd_solver.cpp:106] Iteration 16620, lr = 0.000479837
I0809 00:26:32.570950 20451 solver.cpp:228] Iteration 16630, loss = 0.0937647
I0809 00:26:32.571141 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:26:32.571158 20451 solver.cpp:244]     Train net output #1: loss = 0.0937648 (* 1 = 0.0937648 loss)
I0809 00:26:32.571171 20451 sgd_solver.cpp:106] Iteration 16630, lr = 0.000479702
I0809 00:26:54.867468 20451 solver.cpp:228] Iteration 16640, loss = 0.187627
I0809 00:26:54.867521 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:26:54.867533 20451 solver.cpp:244]     Train net output #1: loss = 0.187627 (* 1 = 0.187627 loss)
I0809 00:26:54.867545 20451 sgd_solver.cpp:106] Iteration 16640, lr = 0.000479567
I0809 00:27:17.173966 20451 solver.cpp:228] Iteration 16650, loss = 0.156346
I0809 00:27:17.174188 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:27:17.174204 20451 solver.cpp:244]     Train net output #1: loss = 0.156346 (* 1 = 0.156346 loss)
I0809 00:27:17.174216 20451 sgd_solver.cpp:106] Iteration 16650, lr = 0.000479432
I0809 00:27:39.481709 20451 solver.cpp:228] Iteration 16660, loss = 0.187772
I0809 00:27:39.481761 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:27:39.481775 20451 solver.cpp:244]     Train net output #1: loss = 0.187772 (* 1 = 0.187772 loss)
I0809 00:27:39.481787 20451 sgd_solver.cpp:106] Iteration 16660, lr = 0.000479297
I0809 00:28:01.790691 20451 solver.cpp:228] Iteration 16670, loss = 0.250052
I0809 00:28:01.790884 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:28:01.790917 20451 solver.cpp:244]     Train net output #1: loss = 0.250052 (* 1 = 0.250052 loss)
I0809 00:28:01.790942 20451 sgd_solver.cpp:106] Iteration 16670, lr = 0.000479162
I0809 00:28:24.101809 20451 solver.cpp:228] Iteration 16680, loss = 0.218854
I0809 00:28:24.101855 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:28:24.101873 20451 solver.cpp:244]     Train net output #1: loss = 0.218855 (* 1 = 0.218855 loss)
I0809 00:28:24.101898 20451 sgd_solver.cpp:106] Iteration 16680, lr = 0.000479028
I0809 00:28:46.416067 20451 solver.cpp:228] Iteration 16690, loss = 0.343888
I0809 00:28:46.416319 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 00:28:46.416393 20451 solver.cpp:244]     Train net output #1: loss = 0.343889 (* 1 = 0.343889 loss)
I0809 00:28:46.416431 20451 sgd_solver.cpp:106] Iteration 16690, lr = 0.000478893
I0809 00:29:06.501826 20451 solver.cpp:337] Iteration 16700, Testing net (#0)
I0809 00:29:15.022585 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 00:29:15.022639 20451 solver.cpp:404]     Test net output #1: loss = 1.00808 (* 1 = 1.00808 loss)
I0809 00:29:17.227669 20451 solver.cpp:228] Iteration 16700, loss = 0.218835
I0809 00:29:17.227851 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:29:17.227867 20451 solver.cpp:244]     Train net output #1: loss = 0.218835 (* 1 = 0.218835 loss)
I0809 00:29:17.227880 20451 sgd_solver.cpp:106] Iteration 16700, lr = 0.000478759
I0809 00:29:39.503008 20451 solver.cpp:228] Iteration 16710, loss = 0.187599
I0809 00:29:39.503062 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:29:39.503075 20451 solver.cpp:244]     Train net output #1: loss = 0.187599 (* 1 = 0.187599 loss)
I0809 00:29:39.503088 20451 sgd_solver.cpp:106] Iteration 16710, lr = 0.000478624
I0809 00:30:01.814501 20451 solver.cpp:228] Iteration 16720, loss = 0.156306
I0809 00:30:01.814597 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:30:01.814613 20451 solver.cpp:244]     Train net output #1: loss = 0.156306 (* 1 = 0.156306 loss)
I0809 00:30:01.814627 20451 sgd_solver.cpp:106] Iteration 16720, lr = 0.00047849
I0809 00:30:24.127483 20451 solver.cpp:228] Iteration 16730, loss = 0.187594
I0809 00:30:24.127537 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:30:24.127552 20451 solver.cpp:244]     Train net output #1: loss = 0.187595 (* 1 = 0.187595 loss)
I0809 00:30:24.127563 20451 sgd_solver.cpp:106] Iteration 16730, lr = 0.000478356
I0809 00:30:46.438338 20451 solver.cpp:228] Iteration 16740, loss = 0.156632
I0809 00:30:46.438519 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:30:46.438534 20451 solver.cpp:244]     Train net output #1: loss = 0.156632 (* 1 = 0.156632 loss)
I0809 00:30:46.438546 20451 sgd_solver.cpp:106] Iteration 16740, lr = 0.000478221
I0809 00:31:08.740072 20451 solver.cpp:228] Iteration 16750, loss = 0.281955
I0809 00:31:08.740120 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 00:31:08.740135 20451 solver.cpp:244]     Train net output #1: loss = 0.281955 (* 1 = 0.281955 loss)
I0809 00:31:08.740149 20451 sgd_solver.cpp:106] Iteration 16750, lr = 0.000478087
I0809 00:31:31.048420 20451 solver.cpp:228] Iteration 16760, loss = 0.218898
I0809 00:31:31.048568 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:31:31.048584 20451 solver.cpp:244]     Train net output #1: loss = 0.218898 (* 1 = 0.218898 loss)
I0809 00:31:31.048598 20451 sgd_solver.cpp:106] Iteration 16760, lr = 0.000477953
I0809 00:31:53.355159 20451 solver.cpp:228] Iteration 16770, loss = 0.218864
I0809 00:31:53.355212 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:31:53.355227 20451 solver.cpp:244]     Train net output #1: loss = 0.218864 (* 1 = 0.218864 loss)
I0809 00:31:53.355239 20451 sgd_solver.cpp:106] Iteration 16770, lr = 0.000477819
I0809 00:32:15.664832 20451 solver.cpp:228] Iteration 16780, loss = 0.343784
I0809 00:32:15.665009 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 00:32:15.665024 20451 solver.cpp:244]     Train net output #1: loss = 0.343784 (* 1 = 0.343784 loss)
I0809 00:32:15.665035 20451 sgd_solver.cpp:106] Iteration 16780, lr = 0.000477686
I0809 00:32:37.983901 20451 solver.cpp:228] Iteration 16790, loss = 0.218898
I0809 00:32:37.983945 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:32:37.983963 20451 solver.cpp:244]     Train net output #1: loss = 0.218898 (* 1 = 0.218898 loss)
I0809 00:32:37.983978 20451 sgd_solver.cpp:106] Iteration 16790, lr = 0.000477552
I0809 00:32:58.063736 20451 solver.cpp:337] Iteration 16800, Testing net (#0)
I0809 00:33:06.587050 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0809 00:33:06.587102 20451 solver.cpp:404]     Test net output #1: loss = 1.01284 (* 1 = 1.01284 loss)
I0809 00:33:08.791504 20451 solver.cpp:228] Iteration 16800, loss = 0.187603
I0809 00:33:08.791553 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:33:08.791566 20451 solver.cpp:244]     Train net output #1: loss = 0.187603 (* 1 = 0.187603 loss)
I0809 00:33:08.791579 20451 sgd_solver.cpp:106] Iteration 16800, lr = 0.000477418
I0809 00:33:31.078126 20451 solver.cpp:228] Iteration 16810, loss = 0.250061
I0809 00:33:31.078234 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:33:31.078250 20451 solver.cpp:244]     Train net output #1: loss = 0.250062 (* 1 = 0.250062 loss)
I0809 00:33:31.078263 20451 sgd_solver.cpp:106] Iteration 16810, lr = 0.000477285
I0809 00:33:53.390394 20451 solver.cpp:228] Iteration 16820, loss = 0.187629
I0809 00:33:53.390444 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:33:53.390460 20451 solver.cpp:244]     Train net output #1: loss = 0.187629 (* 1 = 0.187629 loss)
I0809 00:33:53.390471 20451 sgd_solver.cpp:106] Iteration 16820, lr = 0.000477151
I0809 00:34:15.709619 20451 solver.cpp:228] Iteration 16830, loss = 0.218852
I0809 00:34:15.709801 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:34:15.709817 20451 solver.cpp:244]     Train net output #1: loss = 0.218852 (* 1 = 0.218852 loss)
I0809 00:34:15.709830 20451 sgd_solver.cpp:106] Iteration 16830, lr = 0.000477018
I0809 00:34:38.015053 20451 solver.cpp:228] Iteration 16840, loss = 0.156298
I0809 00:34:38.015105 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:34:38.015118 20451 solver.cpp:244]     Train net output #1: loss = 0.156298 (* 1 = 0.156298 loss)
I0809 00:34:38.015130 20451 sgd_solver.cpp:106] Iteration 16840, lr = 0.000476884
I0809 00:35:00.320390 20451 solver.cpp:228] Iteration 16850, loss = 0.312689
I0809 00:35:00.320603 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 00:35:00.320619 20451 solver.cpp:244]     Train net output #1: loss = 0.312689 (* 1 = 0.312689 loss)
I0809 00:35:00.320632 20451 sgd_solver.cpp:106] Iteration 16850, lr = 0.000476751
I0809 00:35:22.628260 20451 solver.cpp:228] Iteration 16860, loss = 0.250151
I0809 00:35:22.628306 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:35:22.628335 20451 solver.cpp:244]     Train net output #1: loss = 0.250151 (* 1 = 0.250151 loss)
I0809 00:35:22.628350 20451 sgd_solver.cpp:106] Iteration 16860, lr = 0.000476618
I0809 00:35:44.939107 20451 solver.cpp:228] Iteration 16870, loss = 0.0938364
I0809 00:35:44.939294 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:35:44.939314 20451 solver.cpp:244]     Train net output #1: loss = 0.0938366 (* 1 = 0.0938366 loss)
I0809 00:35:44.939332 20451 sgd_solver.cpp:106] Iteration 16870, lr = 0.000476485
I0809 00:36:07.247768 20451 solver.cpp:228] Iteration 16880, loss = 0.125263
I0809 00:36:07.247812 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:36:07.247839 20451 solver.cpp:244]     Train net output #1: loss = 0.125263 (* 1 = 0.125263 loss)
I0809 00:36:07.247855 20451 sgd_solver.cpp:106] Iteration 16880, lr = 0.000476352
I0809 00:36:29.552067 20451 solver.cpp:228] Iteration 16890, loss = 0.125562
I0809 00:36:29.552184 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:36:29.552199 20451 solver.cpp:244]     Train net output #1: loss = 0.125562 (* 1 = 0.125562 loss)
I0809 00:36:29.552211 20451 sgd_solver.cpp:106] Iteration 16890, lr = 0.000476219
I0809 00:36:49.636914 20451 solver.cpp:337] Iteration 16900, Testing net (#0)
I0809 00:36:58.167719 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 00:36:58.167762 20451 solver.cpp:404]     Test net output #1: loss = 0.985174 (* 1 = 0.985174 loss)
I0809 00:37:00.377840 20451 solver.cpp:228] Iteration 16900, loss = 0.250301
I0809 00:37:00.378021 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:37:00.378036 20451 solver.cpp:244]     Train net output #1: loss = 0.250301 (* 1 = 0.250301 loss)
I0809 00:37:00.378047 20451 sgd_solver.cpp:106] Iteration 16900, lr = 0.000476086
I0809 00:37:22.658304 20451 solver.cpp:228] Iteration 16910, loss = 0.125008
I0809 00:37:22.658356 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:37:22.658370 20451 solver.cpp:244]     Train net output #1: loss = 0.125008 (* 1 = 0.125008 loss)
I0809 00:37:22.658382 20451 sgd_solver.cpp:106] Iteration 16910, lr = 0.000475954
I0809 00:37:44.958377 20451 solver.cpp:228] Iteration 16920, loss = 0.0938139
I0809 00:37:44.958564 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:37:44.958580 20451 solver.cpp:244]     Train net output #1: loss = 0.0938141 (* 1 = 0.0938141 loss)
I0809 00:37:44.958593 20451 sgd_solver.cpp:106] Iteration 16920, lr = 0.000475821
I0809 00:38:07.262624 20451 solver.cpp:228] Iteration 16930, loss = 0.219043
I0809 00:38:07.262676 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:38:07.262689 20451 solver.cpp:244]     Train net output #1: loss = 0.219043 (* 1 = 0.219043 loss)
I0809 00:38:07.262701 20451 sgd_solver.cpp:106] Iteration 16930, lr = 0.000475689
I0809 00:38:29.567911 20451 solver.cpp:228] Iteration 16940, loss = 0.344013
I0809 00:38:29.568080 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 00:38:29.568095 20451 solver.cpp:244]     Train net output #1: loss = 0.344013 (* 1 = 0.344013 loss)
I0809 00:38:29.568109 20451 sgd_solver.cpp:106] Iteration 16940, lr = 0.000475556
I0809 00:38:51.882230 20451 solver.cpp:228] Iteration 16950, loss = 0.250084
I0809 00:38:51.882284 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:38:51.882299 20451 solver.cpp:244]     Train net output #1: loss = 0.250084 (* 1 = 0.250084 loss)
I0809 00:38:51.882311 20451 sgd_solver.cpp:106] Iteration 16950, lr = 0.000475424
I0809 00:39:14.197726 20451 solver.cpp:228] Iteration 16960, loss = 0.187616
I0809 00:39:14.197952 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:39:14.197994 20451 solver.cpp:244]     Train net output #1: loss = 0.187616 (* 1 = 0.187616 loss)
I0809 00:39:14.198015 20451 sgd_solver.cpp:106] Iteration 16960, lr = 0.000475292
I0809 00:39:36.508852 20451 solver.cpp:228] Iteration 16970, loss = 0.187557
I0809 00:39:36.508904 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:39:36.508919 20451 solver.cpp:244]     Train net output #1: loss = 0.187557 (* 1 = 0.187557 loss)
I0809 00:39:36.508931 20451 sgd_solver.cpp:106] Iteration 16970, lr = 0.000475159
I0809 00:39:58.815701 20451 solver.cpp:228] Iteration 16980, loss = 0.156303
I0809 00:39:58.815855 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:39:58.815871 20451 solver.cpp:244]     Train net output #1: loss = 0.156303 (* 1 = 0.156303 loss)
I0809 00:39:58.815886 20451 sgd_solver.cpp:106] Iteration 16980, lr = 0.000475027
I0809 00:40:21.126832 20451 solver.cpp:228] Iteration 16990, loss = 0.0938032
I0809 00:40:21.126893 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:40:21.126907 20451 solver.cpp:244]     Train net output #1: loss = 0.0938033 (* 1 = 0.0938033 loss)
I0809 00:40:21.126920 20451 sgd_solver.cpp:106] Iteration 16990, lr = 0.000474895
I0809 00:40:41.210512 20451 solver.cpp:337] Iteration 17000, Testing net (#0)
I0809 00:40:49.728714 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 00:40:49.728767 20451 solver.cpp:404]     Test net output #1: loss = 1.00326 (* 1 = 1.00326 loss)
I0809 00:40:51.930956 20451 solver.cpp:228] Iteration 17000, loss = 0.218793
I0809 00:40:51.931006 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:40:51.931025 20451 solver.cpp:244]     Train net output #1: loss = 0.218793 (* 1 = 0.218793 loss)
I0809 00:40:51.931041 20451 sgd_solver.cpp:106] Iteration 17000, lr = 0.000474763
I0809 00:41:14.225154 20451 solver.cpp:228] Iteration 17010, loss = 0.218806
I0809 00:41:14.225250 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:41:14.225270 20451 solver.cpp:244]     Train net output #1: loss = 0.218806 (* 1 = 0.218806 loss)
I0809 00:41:14.225284 20451 sgd_solver.cpp:106] Iteration 17010, lr = 0.000474632
I0809 00:41:36.535061 20451 solver.cpp:228] Iteration 17020, loss = -1.19209e-07
I0809 00:41:36.535115 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:41:36.535128 20451 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0809 00:41:36.535140 20451 sgd_solver.cpp:106] Iteration 17020, lr = 0.0004745
I0809 00:41:58.843747 20451 solver.cpp:228] Iteration 17030, loss = 0.0312612
I0809 00:41:58.843850 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 00:41:58.843869 20451 solver.cpp:244]     Train net output #1: loss = 0.0312613 (* 1 = 0.0312613 loss)
I0809 00:41:58.843885 20451 sgd_solver.cpp:106] Iteration 17030, lr = 0.000474368
I0809 00:42:21.156246 20451 solver.cpp:228] Iteration 17040, loss = 0.187614
I0809 00:42:21.156297 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:42:21.156311 20451 solver.cpp:244]     Train net output #1: loss = 0.187614 (* 1 = 0.187614 loss)
I0809 00:42:21.156324 20451 sgd_solver.cpp:106] Iteration 17040, lr = 0.000474237
I0809 00:42:43.457455 20451 solver.cpp:228] Iteration 17050, loss = 0.156325
I0809 00:42:43.457633 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:42:43.457650 20451 solver.cpp:244]     Train net output #1: loss = 0.156325 (* 1 = 0.156325 loss)
I0809 00:42:43.457666 20451 sgd_solver.cpp:106] Iteration 17050, lr = 0.000474105
I0809 00:43:05.767133 20451 solver.cpp:228] Iteration 17060, loss = 0.218852
I0809 00:43:05.767184 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:43:05.767202 20451 solver.cpp:244]     Train net output #1: loss = 0.218852 (* 1 = 0.218852 loss)
I0809 00:43:05.767217 20451 sgd_solver.cpp:106] Iteration 17060, lr = 0.000473974
I0809 00:43:28.078956 20451 solver.cpp:228] Iteration 17070, loss = 0.093822
I0809 00:43:28.079202 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:43:28.079222 20451 solver.cpp:244]     Train net output #1: loss = 0.0938221 (* 1 = 0.0938221 loss)
I0809 00:43:28.079237 20451 sgd_solver.cpp:106] Iteration 17070, lr = 0.000473842
I0809 00:43:50.390348 20451 solver.cpp:228] Iteration 17080, loss = 0.0625453
I0809 00:43:50.390400 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 00:43:50.390415 20451 solver.cpp:244]     Train net output #1: loss = 0.0625454 (* 1 = 0.0625454 loss)
I0809 00:43:50.390427 20451 sgd_solver.cpp:106] Iteration 17080, lr = 0.000473711
I0809 00:44:12.702924 20451 solver.cpp:228] Iteration 17090, loss = 0.218831
I0809 00:44:12.703102 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:44:12.703122 20451 solver.cpp:244]     Train net output #1: loss = 0.218831 (* 1 = 0.218831 loss)
I0809 00:44:12.703138 20451 sgd_solver.cpp:106] Iteration 17090, lr = 0.00047358
I0809 00:44:32.789427 20451 solver.cpp:337] Iteration 17100, Testing net (#0)
I0809 00:44:41.303812 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 00:44:41.303865 20451 solver.cpp:404]     Test net output #1: loss = 0.97549 (* 1 = 0.97549 loss)
I0809 00:44:43.507992 20451 solver.cpp:228] Iteration 17100, loss = 0.218913
I0809 00:44:43.508167 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:44:43.508183 20451 solver.cpp:244]     Train net output #1: loss = 0.218913 (* 1 = 0.218913 loss)
I0809 00:44:43.508195 20451 sgd_solver.cpp:106] Iteration 17100, lr = 0.000473449
I0809 00:45:05.794762 20451 solver.cpp:228] Iteration 17110, loss = 0.187511
I0809 00:45:05.794813 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:45:05.794827 20451 solver.cpp:244]     Train net output #1: loss = 0.187511 (* 1 = 0.187511 loss)
I0809 00:45:05.794839 20451 sgd_solver.cpp:106] Iteration 17110, lr = 0.000473318
I0809 00:45:28.102985 20451 solver.cpp:228] Iteration 17120, loss = 0.250514
I0809 00:45:28.103158 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:45:28.103173 20451 solver.cpp:244]     Train net output #1: loss = 0.250514 (* 1 = 0.250514 loss)
I0809 00:45:28.103186 20451 sgd_solver.cpp:106] Iteration 17120, lr = 0.000473187
I0809 00:45:50.412482 20451 solver.cpp:228] Iteration 17130, loss = 0.125008
I0809 00:45:50.412536 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:45:50.412550 20451 solver.cpp:244]     Train net output #1: loss = 0.125008 (* 1 = 0.125008 loss)
I0809 00:45:50.412562 20451 sgd_solver.cpp:106] Iteration 17130, lr = 0.000473056
I0809 00:46:12.738924 20451 solver.cpp:228] Iteration 17140, loss = 0.25048
I0809 00:46:12.739079 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:46:12.739095 20451 solver.cpp:244]     Train net output #1: loss = 0.25048 (* 1 = 0.25048 loss)
I0809 00:46:12.739109 20451 sgd_solver.cpp:106] Iteration 17140, lr = 0.000472925
I0809 00:46:35.060453 20451 solver.cpp:228] Iteration 17150, loss = 0.187602
I0809 00:46:35.060494 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:46:35.060509 20451 solver.cpp:244]     Train net output #1: loss = 0.187603 (* 1 = 0.187603 loss)
I0809 00:46:35.060523 20451 sgd_solver.cpp:106] Iteration 17150, lr = 0.000472795
I0809 00:46:57.362136 20451 solver.cpp:228] Iteration 17160, loss = 0.125211
I0809 00:46:57.362231 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:46:57.362247 20451 solver.cpp:244]     Train net output #1: loss = 0.125211 (* 1 = 0.125211 loss)
I0809 00:46:57.362260 20451 sgd_solver.cpp:106] Iteration 17160, lr = 0.000472664
I0809 00:47:19.672937 20451 solver.cpp:228] Iteration 17170, loss = 0.187525
I0809 00:47:19.672988 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:47:19.673002 20451 solver.cpp:244]     Train net output #1: loss = 0.187525 (* 1 = 0.187525 loss)
I0809 00:47:19.673014 20451 sgd_solver.cpp:106] Iteration 17170, lr = 0.000472534
I0809 00:47:41.982436 20451 solver.cpp:228] Iteration 17180, loss = 0.28169
I0809 00:47:41.982573 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 00:47:41.982592 20451 solver.cpp:244]     Train net output #1: loss = 0.28169 (* 1 = 0.28169 loss)
I0809 00:47:41.982606 20451 sgd_solver.cpp:106] Iteration 17180, lr = 0.000472403
I0809 00:48:04.283077 20451 solver.cpp:228] Iteration 17190, loss = 0.187534
I0809 00:48:04.283126 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:48:04.283140 20451 solver.cpp:244]     Train net output #1: loss = 0.187534 (* 1 = 0.187534 loss)
I0809 00:48:04.283152 20451 sgd_solver.cpp:106] Iteration 17190, lr = 0.000472273
I0809 00:48:24.366282 20451 solver.cpp:337] Iteration 17200, Testing net (#0)
I0809 00:48:32.890578 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0809 00:48:32.890631 20451 solver.cpp:404]     Test net output #1: loss = 1.01728 (* 1 = 1.01728 loss)
I0809 00:48:35.095758 20451 solver.cpp:228] Iteration 17200, loss = 0.250206
I0809 00:48:35.095808 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:48:35.095823 20451 solver.cpp:244]     Train net output #1: loss = 0.250206 (* 1 = 0.250206 loss)
I0809 00:48:35.095835 20451 sgd_solver.cpp:106] Iteration 17200, lr = 0.000472143
I0809 00:48:57.386819 20451 solver.cpp:228] Iteration 17210, loss = 0.125053
I0809 00:48:57.386997 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:48:57.387013 20451 solver.cpp:244]     Train net output #1: loss = 0.125053 (* 1 = 0.125053 loss)
I0809 00:48:57.387025 20451 sgd_solver.cpp:106] Iteration 17210, lr = 0.000472013
I0809 00:49:19.696928 20451 solver.cpp:228] Iteration 17220, loss = 0.250107
I0809 00:49:19.696974 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 00:49:19.696992 20451 solver.cpp:244]     Train net output #1: loss = 0.250107 (* 1 = 0.250107 loss)
I0809 00:49:19.697007 20451 sgd_solver.cpp:106] Iteration 17220, lr = 0.000471883
I0809 00:49:41.996394 20451 solver.cpp:228] Iteration 17230, loss = 0.125213
I0809 00:49:41.996496 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:49:41.996511 20451 solver.cpp:244]     Train net output #1: loss = 0.125214 (* 1 = 0.125214 loss)
I0809 00:49:41.996526 20451 sgd_solver.cpp:106] Iteration 17230, lr = 0.000471753
I0809 00:50:04.304610 20451 solver.cpp:228] Iteration 17240, loss = 0.156334
I0809 00:50:04.304661 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:50:04.304675 20451 solver.cpp:244]     Train net output #1: loss = 0.156334 (* 1 = 0.156334 loss)
I0809 00:50:04.304687 20451 sgd_solver.cpp:106] Iteration 17240, lr = 0.000471623
I0809 00:50:26.627343 20451 solver.cpp:228] Iteration 17250, loss = 0.250065
I0809 00:50:26.627523 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 00:50:26.627538 20451 solver.cpp:244]     Train net output #1: loss = 0.250065 (* 1 = 0.250065 loss)
I0809 00:50:26.627552 20451 sgd_solver.cpp:106] Iteration 17250, lr = 0.000471493
I0809 00:50:48.937858 20451 solver.cpp:228] Iteration 17260, loss = 0.125079
I0809 00:50:48.937911 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:50:48.937924 20451 solver.cpp:244]     Train net output #1: loss = 0.125079 (* 1 = 0.125079 loss)
I0809 00:50:48.937937 20451 sgd_solver.cpp:106] Iteration 17260, lr = 0.000471363
I0809 00:51:11.246135 20451 solver.cpp:228] Iteration 17270, loss = 0.156285
I0809 00:51:11.246311 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:51:11.246327 20451 solver.cpp:244]     Train net output #1: loss = 0.156285 (* 1 = 0.156285 loss)
I0809 00:51:11.246340 20451 sgd_solver.cpp:106] Iteration 17270, lr = 0.000471234
I0809 00:51:33.554536 20451 solver.cpp:228] Iteration 17280, loss = 0.0937817
I0809 00:51:33.554589 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:51:33.554602 20451 solver.cpp:244]     Train net output #1: loss = 0.0937818 (* 1 = 0.0937818 loss)
I0809 00:51:33.554615 20451 sgd_solver.cpp:106] Iteration 17280, lr = 0.000471104
I0809 00:51:55.859063 20451 solver.cpp:228] Iteration 17290, loss = 0.125016
I0809 00:51:55.859210 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:51:55.859225 20451 solver.cpp:244]     Train net output #1: loss = 0.125016 (* 1 = 0.125016 loss)
I0809 00:51:55.859239 20451 sgd_solver.cpp:106] Iteration 17290, lr = 0.000470974
I0809 00:52:15.936142 20451 solver.cpp:337] Iteration 17300, Testing net (#0)
I0809 00:52:24.463009 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 00:52:24.463063 20451 solver.cpp:404]     Test net output #1: loss = 1.00352 (* 1 = 1.00352 loss)
I0809 00:52:26.664971 20451 solver.cpp:228] Iteration 17300, loss = 0.187609
I0809 00:52:26.665154 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:52:26.665170 20451 solver.cpp:244]     Train net output #1: loss = 0.187609 (* 1 = 0.187609 loss)
I0809 00:52:26.665184 20451 sgd_solver.cpp:106] Iteration 17300, lr = 0.000470845
I0809 00:52:48.947646 20451 solver.cpp:228] Iteration 17310, loss = 0.125101
I0809 00:52:48.947697 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:52:48.947712 20451 solver.cpp:244]     Train net output #1: loss = 0.125101 (* 1 = 0.125101 loss)
I0809 00:52:48.947726 20451 sgd_solver.cpp:106] Iteration 17310, lr = 0.000470716
I0809 00:53:11.261823 20451 solver.cpp:228] Iteration 17320, loss = 0.0625082
I0809 00:53:11.261998 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 00:53:11.262013 20451 solver.cpp:244]     Train net output #1: loss = 0.0625083 (* 1 = 0.0625083 loss)
I0809 00:53:11.262027 20451 sgd_solver.cpp:106] Iteration 17320, lr = 0.000470587
I0809 00:53:33.569936 20451 solver.cpp:228] Iteration 17330, loss = 0.0938104
I0809 00:53:33.569990 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:53:33.570004 20451 solver.cpp:244]     Train net output #1: loss = 0.0938105 (* 1 = 0.0938105 loss)
I0809 00:53:33.570016 20451 sgd_solver.cpp:106] Iteration 17330, lr = 0.000470457
I0809 00:53:55.887781 20451 solver.cpp:228] Iteration 17340, loss = 0.156278
I0809 00:53:55.887959 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:53:55.887975 20451 solver.cpp:244]     Train net output #1: loss = 0.156278 (* 1 = 0.156278 loss)
I0809 00:53:55.887987 20451 sgd_solver.cpp:106] Iteration 17340, lr = 0.000470328
I0809 00:54:18.198107 20451 solver.cpp:228] Iteration 17350, loss = 0.156339
I0809 00:54:18.198158 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:54:18.198173 20451 solver.cpp:244]     Train net output #1: loss = 0.156339 (* 1 = 0.156339 loss)
I0809 00:54:18.198184 20451 sgd_solver.cpp:106] Iteration 17350, lr = 0.000470199
I0809 00:54:40.507778 20451 solver.cpp:228] Iteration 17360, loss = 0.094106
I0809 00:54:40.507977 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 00:54:40.507993 20451 solver.cpp:244]     Train net output #1: loss = 0.0941061 (* 1 = 0.0941061 loss)
I0809 00:54:40.508007 20451 sgd_solver.cpp:106] Iteration 17360, lr = 0.00047007
I0809 00:55:02.830128 20451 solver.cpp:228] Iteration 17370, loss = 0.0937512
I0809 00:55:02.830180 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 00:55:02.830194 20451 solver.cpp:244]     Train net output #1: loss = 0.0937513 (* 1 = 0.0937513 loss)
I0809 00:55:02.830206 20451 sgd_solver.cpp:106] Iteration 17370, lr = 0.000469942
I0809 00:55:25.141289 20451 solver.cpp:228] Iteration 17380, loss = 0.156323
I0809 00:55:25.141420 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 00:55:25.141435 20451 solver.cpp:244]     Train net output #1: loss = 0.156324 (* 1 = 0.156324 loss)
I0809 00:55:25.141448 20451 sgd_solver.cpp:106] Iteration 17380, lr = 0.000469813
I0809 00:55:47.460732 20451 solver.cpp:228] Iteration 17390, loss = 0.187506
I0809 00:55:47.460783 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:55:47.460798 20451 solver.cpp:244]     Train net output #1: loss = 0.187506 (* 1 = 0.187506 loss)
I0809 00:55:47.460809 20451 sgd_solver.cpp:106] Iteration 17390, lr = 0.000469684
I0809 00:56:07.548619 20451 solver.cpp:337] Iteration 17400, Testing net (#0)
I0809 00:56:16.077028 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 00:56:16.077080 20451 solver.cpp:404]     Test net output #1: loss = 0.976415 (* 1 = 0.976415 loss)
I0809 00:56:18.281694 20451 solver.cpp:228] Iteration 17400, loss = 0.0939531
I0809 00:56:18.281738 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:56:18.281754 20451 solver.cpp:244]     Train net output #1: loss = 0.0939532 (* 1 = 0.0939532 loss)
I0809 00:56:18.281767 20451 sgd_solver.cpp:106] Iteration 17400, lr = 0.000469556
I0809 00:56:40.578577 20451 solver.cpp:228] Iteration 17410, loss = 0.187669
I0809 00:56:40.578753 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 00:56:40.578768 20451 solver.cpp:244]     Train net output #1: loss = 0.187669 (* 1 = 0.187669 loss)
I0809 00:56:40.578780 20451 sgd_solver.cpp:106] Iteration 17410, lr = 0.000469427
I0809 00:57:02.892938 20451 solver.cpp:228] Iteration 17420, loss = 0.219062
I0809 00:57:02.892990 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:57:02.893004 20451 solver.cpp:244]     Train net output #1: loss = 0.219062 (* 1 = 0.219062 loss)
I0809 00:57:02.893016 20451 sgd_solver.cpp:106] Iteration 17420, lr = 0.000469299
I0809 00:57:25.204443 20451 solver.cpp:228] Iteration 17430, loss = 0.281391
I0809 00:57:25.204628 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 00:57:25.204643 20451 solver.cpp:244]     Train net output #1: loss = 0.281391 (* 1 = 0.281391 loss)
I0809 00:57:25.204655 20451 sgd_solver.cpp:106] Iteration 17430, lr = 0.00046917
I0809 00:57:47.509426 20451 solver.cpp:228] Iteration 17440, loss = 0.125024
I0809 00:57:47.509481 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:57:47.509495 20451 solver.cpp:244]     Train net output #1: loss = 0.125024 (* 1 = 0.125024 loss)
I0809 00:57:47.509507 20451 sgd_solver.cpp:106] Iteration 17440, lr = 0.000469042
I0809 00:58:09.815017 20451 solver.cpp:228] Iteration 17450, loss = 0.125026
I0809 00:58:09.815191 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:58:09.815206 20451 solver.cpp:244]     Train net output #1: loss = 0.125026 (* 1 = 0.125026 loss)
I0809 00:58:09.815218 20451 sgd_solver.cpp:106] Iteration 17450, lr = 0.000468914
I0809 00:58:32.126791 20451 solver.cpp:228] Iteration 17460, loss = 0.218824
I0809 00:58:32.126844 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 00:58:32.126858 20451 solver.cpp:244]     Train net output #1: loss = 0.218824 (* 1 = 0.218824 loss)
I0809 00:58:32.126870 20451 sgd_solver.cpp:106] Iteration 17460, lr = 0.000468786
I0809 00:58:54.423327 20451 solver.cpp:228] Iteration 17470, loss = 0.281357
I0809 00:58:54.423506 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 00:58:54.423522 20451 solver.cpp:244]     Train net output #1: loss = 0.281358 (* 1 = 0.281358 loss)
I0809 00:58:54.423534 20451 sgd_solver.cpp:106] Iteration 17470, lr = 0.000468658
I0809 00:59:16.735481 20451 solver.cpp:228] Iteration 17480, loss = 0.125096
I0809 00:59:16.735527 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 00:59:16.735546 20451 solver.cpp:244]     Train net output #1: loss = 0.125096 (* 1 = 0.125096 loss)
I0809 00:59:16.735561 20451 sgd_solver.cpp:106] Iteration 17480, lr = 0.00046853
I0809 00:59:39.044507 20451 solver.cpp:228] Iteration 17490, loss = 0.093766
I0809 00:59:39.044667 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 00:59:39.044690 20451 solver.cpp:244]     Train net output #1: loss = 0.0937661 (* 1 = 0.0937661 loss)
I0809 00:59:39.044708 20451 sgd_solver.cpp:106] Iteration 17490, lr = 0.000468402
I0809 00:59:59.135833 20451 solver.cpp:337] Iteration 17500, Testing net (#0)
I0809 01:00:07.658664 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 01:00:07.658707 20451 solver.cpp:404]     Test net output #1: loss = 0.994296 (* 1 = 0.994296 loss)
I0809 01:00:09.864296 20451 solver.cpp:228] Iteration 17500, loss = 0.125102
I0809 01:00:09.864508 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:00:09.864523 20451 solver.cpp:244]     Train net output #1: loss = 0.125102 (* 1 = 0.125102 loss)
I0809 01:00:09.864537 20451 sgd_solver.cpp:106] Iteration 17500, lr = 0.000468274
I0809 01:00:32.143009 20451 solver.cpp:228] Iteration 17510, loss = 0.218828
I0809 01:00:32.143059 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:00:32.143074 20451 solver.cpp:244]     Train net output #1: loss = 0.218828 (* 1 = 0.218828 loss)
I0809 01:00:32.143086 20451 sgd_solver.cpp:106] Iteration 17510, lr = 0.000468147
I0809 01:00:54.447886 20451 solver.cpp:228] Iteration 17520, loss = 0.125069
I0809 01:00:54.448068 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:00:54.448084 20451 solver.cpp:244]     Train net output #1: loss = 0.125069 (* 1 = 0.125069 loss)
I0809 01:00:54.448096 20451 sgd_solver.cpp:106] Iteration 17520, lr = 0.000468019
I0809 01:01:16.761230 20451 solver.cpp:228] Iteration 17530, loss = 0.156292
I0809 01:01:16.761277 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:01:16.761293 20451 solver.cpp:244]     Train net output #1: loss = 0.156292 (* 1 = 0.156292 loss)
I0809 01:01:16.761307 20451 sgd_solver.cpp:106] Iteration 17530, lr = 0.000467892
I0809 01:01:39.061547 20451 solver.cpp:228] Iteration 17540, loss = 0.15638
I0809 01:01:39.061658 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:01:39.061677 20451 solver.cpp:244]     Train net output #1: loss = 0.15638 (* 1 = 0.15638 loss)
I0809 01:01:39.061692 20451 sgd_solver.cpp:106] Iteration 17540, lr = 0.000467764
I0809 01:02:01.370651 20451 solver.cpp:228] Iteration 17550, loss = 0.156314
I0809 01:02:01.370695 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:02:01.370712 20451 solver.cpp:244]     Train net output #1: loss = 0.156314 (* 1 = 0.156314 loss)
I0809 01:02:01.370726 20451 sgd_solver.cpp:106] Iteration 17550, lr = 0.000467637
I0809 01:02:23.680762 20451 solver.cpp:228] Iteration 17560, loss = 0.250184
I0809 01:02:23.680939 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:02:23.680954 20451 solver.cpp:244]     Train net output #1: loss = 0.250184 (* 1 = 0.250184 loss)
I0809 01:02:23.680968 20451 sgd_solver.cpp:106] Iteration 17560, lr = 0.00046751
I0809 01:02:45.986634 20451 solver.cpp:228] Iteration 17570, loss = 0.21878
I0809 01:02:45.986677 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:02:45.986696 20451 solver.cpp:244]     Train net output #1: loss = 0.21878 (* 1 = 0.21878 loss)
I0809 01:02:45.986707 20451 sgd_solver.cpp:106] Iteration 17570, lr = 0.000467383
I0809 01:03:08.303484 20451 solver.cpp:228] Iteration 17580, loss = 0.156291
I0809 01:03:08.303664 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:03:08.303679 20451 solver.cpp:244]     Train net output #1: loss = 0.156291 (* 1 = 0.156291 loss)
I0809 01:03:08.303691 20451 sgd_solver.cpp:106] Iteration 17580, lr = 0.000467255
I0809 01:03:30.611069 20451 solver.cpp:228] Iteration 17590, loss = 0.218755
I0809 01:03:30.611125 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:03:30.611140 20451 solver.cpp:244]     Train net output #1: loss = 0.218755 (* 1 = 0.218755 loss)
I0809 01:03:30.611151 20451 sgd_solver.cpp:106] Iteration 17590, lr = 0.000467128
I0809 01:03:50.692595 20451 solver.cpp:337] Iteration 17600, Testing net (#0)
I0809 01:03:59.214331 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 01:03:59.214383 20451 solver.cpp:404]     Test net output #1: loss = 1.00318 (* 1 = 1.00318 loss)
I0809 01:04:01.417932 20451 solver.cpp:228] Iteration 17600, loss = 0.25005
I0809 01:04:01.417981 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:04:01.417994 20451 solver.cpp:244]     Train net output #1: loss = 0.25005 (* 1 = 0.25005 loss)
I0809 01:04:01.418007 20451 sgd_solver.cpp:106] Iteration 17600, lr = 0.000467001
I0809 01:04:23.701015 20451 solver.cpp:228] Iteration 17610, loss = 0.125075
I0809 01:04:23.701220 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:04:23.701236 20451 solver.cpp:244]     Train net output #1: loss = 0.125075 (* 1 = 0.125075 loss)
I0809 01:04:23.701248 20451 sgd_solver.cpp:106] Iteration 17610, lr = 0.000466875
I0809 01:04:46.010668 20451 solver.cpp:228] Iteration 17620, loss = 0.218887
I0809 01:04:46.010721 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:04:46.010735 20451 solver.cpp:244]     Train net output #1: loss = 0.218887 (* 1 = 0.218887 loss)
I0809 01:04:46.010748 20451 sgd_solver.cpp:106] Iteration 17620, lr = 0.000466748
I0809 01:05:08.318262 20451 solver.cpp:228] Iteration 17630, loss = 0.156308
I0809 01:05:08.318446 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:05:08.318462 20451 solver.cpp:244]     Train net output #1: loss = 0.156308 (* 1 = 0.156308 loss)
I0809 01:05:08.318475 20451 sgd_solver.cpp:106] Iteration 17630, lr = 0.000466621
I0809 01:05:30.634640 20451 solver.cpp:228] Iteration 17640, loss = 0.187567
I0809 01:05:30.634703 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:05:30.634718 20451 solver.cpp:244]     Train net output #1: loss = 0.187567 (* 1 = 0.187567 loss)
I0809 01:05:30.634730 20451 sgd_solver.cpp:106] Iteration 17640, lr = 0.000466494
I0809 01:05:52.949635 20451 solver.cpp:228] Iteration 17650, loss = 0.156347
I0809 01:05:52.949807 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:05:52.949823 20451 solver.cpp:244]     Train net output #1: loss = 0.156347 (* 1 = 0.156347 loss)
I0809 01:05:52.949836 20451 sgd_solver.cpp:106] Iteration 17650, lr = 0.000466368
I0809 01:06:15.263445 20451 solver.cpp:228] Iteration 17660, loss = 0.218828
I0809 01:06:15.263497 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:06:15.263511 20451 solver.cpp:244]     Train net output #1: loss = 0.218828 (* 1 = 0.218828 loss)
I0809 01:06:15.263523 20451 sgd_solver.cpp:106] Iteration 17660, lr = 0.000466241
I0809 01:06:37.564460 20451 solver.cpp:228] Iteration 17670, loss = 0.156335
I0809 01:06:37.564640 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:06:37.564654 20451 solver.cpp:244]     Train net output #1: loss = 0.156335 (* 1 = 0.156335 loss)
I0809 01:06:37.564666 20451 sgd_solver.cpp:106] Iteration 17670, lr = 0.000466115
I0809 01:06:59.864553 20451 solver.cpp:228] Iteration 17680, loss = 0.218857
I0809 01:06:59.864609 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:06:59.864626 20451 solver.cpp:244]     Train net output #1: loss = 0.218857 (* 1 = 0.218857 loss)
I0809 01:06:59.864639 20451 sgd_solver.cpp:106] Iteration 17680, lr = 0.000465989
I0809 01:07:22.182327 20451 solver.cpp:228] Iteration 17690, loss = 0.218819
I0809 01:07:22.182433 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:07:22.182448 20451 solver.cpp:244]     Train net output #1: loss = 0.218819 (* 1 = 0.218819 loss)
I0809 01:07:22.182461 20451 sgd_solver.cpp:106] Iteration 17690, lr = 0.000465863
I0809 01:07:42.264014 20451 solver.cpp:337] Iteration 17700, Testing net (#0)
I0809 01:07:50.784168 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0809 01:07:50.784219 20451 solver.cpp:404]     Test net output #1: loss = 0.965875 (* 1 = 0.965875 loss)
I0809 01:07:52.990586 20451 solver.cpp:228] Iteration 17700, loss = 0.0937856
I0809 01:07:52.990774 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:07:52.990790 20451 solver.cpp:244]     Train net output #1: loss = 0.0937857 (* 1 = 0.0937857 loss)
I0809 01:07:52.990803 20451 sgd_solver.cpp:106] Iteration 17700, lr = 0.000465736
I0809 01:08:15.286108 20451 solver.cpp:228] Iteration 17710, loss = 0.187618
I0809 01:08:15.286161 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:08:15.286175 20451 solver.cpp:244]     Train net output #1: loss = 0.187618 (* 1 = 0.187618 loss)
I0809 01:08:15.286187 20451 sgd_solver.cpp:106] Iteration 17710, lr = 0.00046561
I0809 01:08:37.598471 20451 solver.cpp:228] Iteration 17720, loss = 0.281332
I0809 01:08:37.598654 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 01:08:37.598670 20451 solver.cpp:244]     Train net output #1: loss = 0.281332 (* 1 = 0.281332 loss)
I0809 01:08:37.598682 20451 sgd_solver.cpp:106] Iteration 17720, lr = 0.000465484
I0809 01:08:59.911080 20451 solver.cpp:228] Iteration 17730, loss = 0.250162
I0809 01:08:59.911134 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:08:59.911154 20451 solver.cpp:244]     Train net output #1: loss = 0.250162 (* 1 = 0.250162 loss)
I0809 01:08:59.911170 20451 sgd_solver.cpp:106] Iteration 17730, lr = 0.000465358
I0809 01:09:22.220530 20451 solver.cpp:228] Iteration 17740, loss = 0.093775
I0809 01:09:22.220638 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:09:22.220655 20451 solver.cpp:244]     Train net output #1: loss = 0.0937751 (* 1 = 0.0937751 loss)
I0809 01:09:22.220671 20451 sgd_solver.cpp:106] Iteration 17740, lr = 0.000465233
I0809 01:09:44.532241 20451 solver.cpp:228] Iteration 17750, loss = 0.218805
I0809 01:09:44.532289 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:09:44.532308 20451 solver.cpp:244]     Train net output #1: loss = 0.218805 (* 1 = 0.218805 loss)
I0809 01:09:44.532335 20451 sgd_solver.cpp:106] Iteration 17750, lr = 0.000465107
I0809 01:10:06.845582 20451 solver.cpp:228] Iteration 17760, loss = 0.125039
I0809 01:10:06.845760 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:10:06.845778 20451 solver.cpp:244]     Train net output #1: loss = 0.125039 (* 1 = 0.125039 loss)
I0809 01:10:06.845794 20451 sgd_solver.cpp:106] Iteration 17760, lr = 0.000464981
I0809 01:10:29.164804 20451 solver.cpp:228] Iteration 17770, loss = 0.18757
I0809 01:10:29.164849 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:10:29.164867 20451 solver.cpp:244]     Train net output #1: loss = 0.18757 (* 1 = 0.18757 loss)
I0809 01:10:29.164882 20451 sgd_solver.cpp:106] Iteration 17770, lr = 0.000464856
I0809 01:10:51.479012 20451 solver.cpp:228] Iteration 17780, loss = 0.125037
I0809 01:10:51.479190 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:10:51.479205 20451 solver.cpp:244]     Train net output #1: loss = 0.125037 (* 1 = 0.125037 loss)
I0809 01:10:51.479218 20451 sgd_solver.cpp:106] Iteration 17780, lr = 0.00046473
I0809 01:11:13.797432 20451 solver.cpp:228] Iteration 17790, loss = 0.125037
I0809 01:11:13.797492 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:11:13.797508 20451 solver.cpp:244]     Train net output #1: loss = 0.125037 (* 1 = 0.125037 loss)
I0809 01:11:13.797523 20451 sgd_solver.cpp:106] Iteration 17790, lr = 0.000464605
I0809 01:11:33.879227 20451 solver.cpp:337] Iteration 17800, Testing net (#0)
I0809 01:11:42.404551 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0809 01:11:42.404602 20451 solver.cpp:404]     Test net output #1: loss = 1.03148 (* 1 = 1.03148 loss)
I0809 01:11:44.607331 20451 solver.cpp:228] Iteration 17800, loss = 0.250082
I0809 01:11:44.607383 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:11:44.607398 20451 solver.cpp:244]     Train net output #1: loss = 0.250082 (* 1 = 0.250082 loss)
I0809 01:11:44.607409 20451 sgd_solver.cpp:106] Iteration 17800, lr = 0.000464479
I0809 01:12:06.898959 20451 solver.cpp:228] Iteration 17810, loss = 0.156312
I0809 01:12:06.899122 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:12:06.899137 20451 solver.cpp:244]     Train net output #1: loss = 0.156312 (* 1 = 0.156312 loss)
I0809 01:12:06.899150 20451 sgd_solver.cpp:106] Iteration 17810, lr = 0.000464354
I0809 01:12:29.203212 20451 solver.cpp:228] Iteration 17820, loss = 0.250069
I0809 01:12:29.203263 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:12:29.203285 20451 solver.cpp:244]     Train net output #1: loss = 0.250069 (* 1 = 0.250069 loss)
I0809 01:12:29.203297 20451 sgd_solver.cpp:106] Iteration 17820, lr = 0.000464229
I0809 01:12:51.507050 20451 solver.cpp:228] Iteration 17830, loss = 0.125098
I0809 01:12:51.507264 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:12:51.507283 20451 solver.cpp:244]     Train net output #1: loss = 0.125098 (* 1 = 0.125098 loss)
I0809 01:12:51.507295 20451 sgd_solver.cpp:106] Iteration 17830, lr = 0.000464104
I0809 01:13:13.810286 20451 solver.cpp:228] Iteration 17840, loss = 0.156403
I0809 01:13:13.810333 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:13:13.810348 20451 solver.cpp:244]     Train net output #1: loss = 0.156403 (* 1 = 0.156403 loss)
I0809 01:13:13.810360 20451 sgd_solver.cpp:106] Iteration 17840, lr = 0.000463979
I0809 01:13:36.114696 20451 solver.cpp:228] Iteration 17850, loss = 0.187547
I0809 01:13:36.114871 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:13:36.114887 20451 solver.cpp:244]     Train net output #1: loss = 0.187547 (* 1 = 0.187547 loss)
I0809 01:13:36.114900 20451 sgd_solver.cpp:106] Iteration 17850, lr = 0.000463854
I0809 01:13:58.420054 20451 solver.cpp:228] Iteration 17860, loss = 0.250216
I0809 01:13:58.420105 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:13:58.420120 20451 solver.cpp:244]     Train net output #1: loss = 0.250216 (* 1 = 0.250216 loss)
I0809 01:13:58.420131 20451 sgd_solver.cpp:106] Iteration 17860, lr = 0.000463729
I0809 01:14:20.736246 20451 solver.cpp:228] Iteration 17870, loss = 0.218769
I0809 01:14:20.736351 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:14:20.736367 20451 solver.cpp:244]     Train net output #1: loss = 0.218769 (* 1 = 0.218769 loss)
I0809 01:14:20.736380 20451 sgd_solver.cpp:106] Iteration 17870, lr = 0.000463604
I0809 01:14:43.035362 20451 solver.cpp:228] Iteration 17880, loss = 0.250017
I0809 01:14:43.035405 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:14:43.035423 20451 solver.cpp:244]     Train net output #1: loss = 0.250017 (* 1 = 0.250017 loss)
I0809 01:14:43.035435 20451 sgd_solver.cpp:106] Iteration 17880, lr = 0.000463479
I0809 01:15:05.345052 20451 solver.cpp:228] Iteration 17890, loss = 0.125065
I0809 01:15:05.345238 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:15:05.345254 20451 solver.cpp:244]     Train net output #1: loss = 0.125065 (* 1 = 0.125065 loss)
I0809 01:15:05.345268 20451 sgd_solver.cpp:106] Iteration 17890, lr = 0.000463355
I0809 01:15:25.429029 20451 solver.cpp:337] Iteration 17900, Testing net (#0)
I0809 01:15:33.946954 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 01:15:33.947005 20451 solver.cpp:404]     Test net output #1: loss = 1.00356 (* 1 = 1.00356 loss)
I0809 01:15:36.150851 20451 solver.cpp:228] Iteration 17900, loss = 0.250162
I0809 01:15:36.151042 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:15:36.151059 20451 solver.cpp:244]     Train net output #1: loss = 0.250162 (* 1 = 0.250162 loss)
I0809 01:15:36.151072 20451 sgd_solver.cpp:106] Iteration 17900, lr = 0.00046323
I0809 01:15:58.425851 20451 solver.cpp:228] Iteration 17910, loss = 0.187575
I0809 01:15:58.425902 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:15:58.425917 20451 solver.cpp:244]     Train net output #1: loss = 0.187575 (* 1 = 0.187575 loss)
I0809 01:15:58.425930 20451 sgd_solver.cpp:106] Iteration 17910, lr = 0.000463106
I0809 01:16:20.737503 20451 solver.cpp:228] Iteration 17920, loss = 0.281468
I0809 01:16:20.737686 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 01:16:20.737704 20451 solver.cpp:244]     Train net output #1: loss = 0.281468 (* 1 = 0.281468 loss)
I0809 01:16:20.737720 20451 sgd_solver.cpp:106] Iteration 17920, lr = 0.000462981
I0809 01:16:43.047929 20451 solver.cpp:228] Iteration 17930, loss = 0.25001
I0809 01:16:43.047981 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:16:43.047994 20451 solver.cpp:244]     Train net output #1: loss = 0.25001 (* 1 = 0.25001 loss)
I0809 01:16:43.048007 20451 sgd_solver.cpp:106] Iteration 17930, lr = 0.000462857
I0809 01:17:05.362534 20451 solver.cpp:228] Iteration 17940, loss = 0.187576
I0809 01:17:05.362741 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 01:17:05.362757 20451 solver.cpp:244]     Train net output #1: loss = 0.187576 (* 1 = 0.187576 loss)
I0809 01:17:05.362771 20451 sgd_solver.cpp:106] Iteration 17940, lr = 0.000462733
I0809 01:17:27.670682 20451 solver.cpp:228] Iteration 17950, loss = 0.343867
I0809 01:17:27.670734 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 01:17:27.670747 20451 solver.cpp:244]     Train net output #1: loss = 0.343867 (* 1 = 0.343867 loss)
I0809 01:17:27.670759 20451 sgd_solver.cpp:106] Iteration 17950, lr = 0.000462609
I0809 01:17:49.985920 20451 solver.cpp:228] Iteration 17960, loss = 0.125029
I0809 01:17:49.986029 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:17:49.986052 20451 solver.cpp:244]     Train net output #1: loss = 0.12503 (* 1 = 0.12503 loss)
I0809 01:17:49.986066 20451 sgd_solver.cpp:106] Iteration 17960, lr = 0.000462484
I0809 01:18:12.302284 20451 solver.cpp:228] Iteration 17970, loss = 0.125037
I0809 01:18:12.302337 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:18:12.302350 20451 solver.cpp:244]     Train net output #1: loss = 0.125037 (* 1 = 0.125037 loss)
I0809 01:18:12.302362 20451 sgd_solver.cpp:106] Iteration 17970, lr = 0.00046236
I0809 01:18:34.608690 20451 solver.cpp:228] Iteration 17980, loss = 0.187576
I0809 01:18:34.608871 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:18:34.608886 20451 solver.cpp:244]     Train net output #1: loss = 0.187576 (* 1 = 0.187576 loss)
I0809 01:18:34.608898 20451 sgd_solver.cpp:106] Iteration 17980, lr = 0.000462237
I0809 01:18:56.919975 20451 solver.cpp:228] Iteration 17990, loss = 0.125017
I0809 01:18:56.920029 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:18:56.920044 20451 solver.cpp:244]     Train net output #1: loss = 0.125017 (* 1 = 0.125017 loss)
I0809 01:18:56.920058 20451 sgd_solver.cpp:106] Iteration 17990, lr = 0.000462113
I0809 01:19:17.004405 20451 solver.cpp:337] Iteration 18000, Testing net (#0)
I0809 01:19:25.531615 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 01:19:25.531667 20451 solver.cpp:404]     Test net output #1: loss = 0.984696 (* 1 = 0.984696 loss)
I0809 01:19:27.736281 20451 solver.cpp:228] Iteration 18000, loss = 0.0938005
I0809 01:19:27.736333 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:19:27.736347 20451 solver.cpp:244]     Train net output #1: loss = 0.0938006 (* 1 = 0.0938006 loss)
I0809 01:19:27.736359 20451 sgd_solver.cpp:106] Iteration 18000, lr = 0.000461989
I0809 01:19:50.023303 20451 solver.cpp:228] Iteration 18010, loss = 0.0937833
I0809 01:19:50.023469 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:19:50.023485 20451 solver.cpp:244]     Train net output #1: loss = 0.0937834 (* 1 = 0.0937834 loss)
I0809 01:19:50.023499 20451 sgd_solver.cpp:106] Iteration 18010, lr = 0.000461865
I0809 01:20:12.339622 20451 solver.cpp:228] Iteration 18020, loss = 0.156358
I0809 01:20:12.339675 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:20:12.339689 20451 solver.cpp:244]     Train net output #1: loss = 0.156358 (* 1 = 0.156358 loss)
I0809 01:20:12.339702 20451 sgd_solver.cpp:106] Iteration 18020, lr = 0.000461741
I0809 01:20:34.644666 20451 solver.cpp:228] Iteration 18030, loss = 0.25009
I0809 01:20:34.644830 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:20:34.644846 20451 solver.cpp:244]     Train net output #1: loss = 0.250091 (* 1 = 0.250091 loss)
I0809 01:20:34.644860 20451 sgd_solver.cpp:106] Iteration 18030, lr = 0.000461618
I0809 01:20:56.959806 20451 solver.cpp:228] Iteration 18040, loss = 0.125079
I0809 01:20:56.959861 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:20:56.959875 20451 solver.cpp:244]     Train net output #1: loss = 0.12508 (* 1 = 0.12508 loss)
I0809 01:20:56.959888 20451 sgd_solver.cpp:106] Iteration 18040, lr = 0.000461494
I0809 01:21:19.265374 20451 solver.cpp:228] Iteration 18050, loss = 0.125006
I0809 01:21:19.265591 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:21:19.265607 20451 solver.cpp:244]     Train net output #1: loss = 0.125006 (* 1 = 0.125006 loss)
I0809 01:21:19.265640 20451 sgd_solver.cpp:106] Iteration 18050, lr = 0.000461371
I0809 01:21:41.576522 20451 solver.cpp:228] Iteration 18060, loss = 0.218783
I0809 01:21:41.576567 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:21:41.576583 20451 solver.cpp:244]     Train net output #1: loss = 0.218783 (* 1 = 0.218783 loss)
I0809 01:21:41.576596 20451 sgd_solver.cpp:106] Iteration 18060, lr = 0.000461248
I0809 01:22:03.892735 20451 solver.cpp:228] Iteration 18070, loss = 0.187625
I0809 01:22:03.892916 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:22:03.892931 20451 solver.cpp:244]     Train net output #1: loss = 0.187626 (* 1 = 0.187626 loss)
I0809 01:22:03.892945 20451 sgd_solver.cpp:106] Iteration 18070, lr = 0.000461125
I0809 01:22:26.192466 20451 solver.cpp:228] Iteration 18080, loss = 0.0625176
I0809 01:22:26.192513 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 01:22:26.192533 20451 solver.cpp:244]     Train net output #1: loss = 0.0625177 (* 1 = 0.0625177 loss)
I0809 01:22:26.192548 20451 sgd_solver.cpp:106] Iteration 18080, lr = 0.000461001
I0809 01:22:48.497723 20451 solver.cpp:228] Iteration 18090, loss = 0.187751
I0809 01:22:48.497913 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:22:48.497930 20451 solver.cpp:244]     Train net output #1: loss = 0.187751 (* 1 = 0.187751 loss)
I0809 01:22:48.497942 20451 sgd_solver.cpp:106] Iteration 18090, lr = 0.000460878
I0809 01:23:08.580778 20451 solver.cpp:337] Iteration 18100, Testing net (#0)
I0809 01:23:17.092569 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 01:23:17.092622 20451 solver.cpp:404]     Test net output #1: loss = 0.998478 (* 1 = 0.998478 loss)
I0809 01:23:19.294162 20451 solver.cpp:228] Iteration 18100, loss = 0.0625032
I0809 01:23:19.294340 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 01:23:19.294355 20451 solver.cpp:244]     Train net output #1: loss = 0.0625034 (* 1 = 0.0625034 loss)
I0809 01:23:19.294368 20451 sgd_solver.cpp:106] Iteration 18100, lr = 0.000460755
I0809 01:23:41.581303 20451 solver.cpp:228] Iteration 18110, loss = 0.218924
I0809 01:23:41.581356 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:23:41.581369 20451 solver.cpp:244]     Train net output #1: loss = 0.218924 (* 1 = 0.218924 loss)
I0809 01:23:41.581382 20451 sgd_solver.cpp:106] Iteration 18110, lr = 0.000460632
I0809 01:24:03.893322 20451 solver.cpp:228] Iteration 18120, loss = 0.0625325
I0809 01:24:03.893504 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 01:24:03.893520 20451 solver.cpp:244]     Train net output #1: loss = 0.0625326 (* 1 = 0.0625326 loss)
I0809 01:24:03.893533 20451 sgd_solver.cpp:106] Iteration 18120, lr = 0.000460509
I0809 01:24:26.203369 20451 solver.cpp:228] Iteration 18130, loss = 0.218813
I0809 01:24:26.203421 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:24:26.203435 20451 solver.cpp:244]     Train net output #1: loss = 0.218813 (* 1 = 0.218813 loss)
I0809 01:24:26.203447 20451 sgd_solver.cpp:106] Iteration 18130, lr = 0.000460387
I0809 01:24:48.519093 20451 solver.cpp:228] Iteration 18140, loss = 0.218796
I0809 01:24:48.519315 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:24:48.519331 20451 solver.cpp:244]     Train net output #1: loss = 0.218796 (* 1 = 0.218796 loss)
I0809 01:24:48.519345 20451 sgd_solver.cpp:106] Iteration 18140, lr = 0.000460264
I0809 01:25:10.838387 20451 solver.cpp:228] Iteration 18150, loss = 0.156274
I0809 01:25:10.838438 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 01:25:10.838457 20451 solver.cpp:244]     Train net output #1: loss = 0.156274 (* 1 = 0.156274 loss)
I0809 01:25:10.838474 20451 sgd_solver.cpp:106] Iteration 18150, lr = 0.000460141
I0809 01:25:33.151185 20451 solver.cpp:228] Iteration 18160, loss = 0.187554
I0809 01:25:33.151309 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 01:25:33.151329 20451 solver.cpp:244]     Train net output #1: loss = 0.187554 (* 1 = 0.187554 loss)
I0809 01:25:33.151343 20451 sgd_solver.cpp:106] Iteration 18160, lr = 0.000460019
I0809 01:25:55.457517 20451 solver.cpp:228] Iteration 18170, loss = 0.187545
I0809 01:25:55.457571 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:25:55.457583 20451 solver.cpp:244]     Train net output #1: loss = 0.187545 (* 1 = 0.187545 loss)
I0809 01:25:55.457595 20451 sgd_solver.cpp:106] Iteration 18170, lr = 0.000459896
I0809 01:26:17.771901 20451 solver.cpp:228] Iteration 18180, loss = 0.218792
I0809 01:26:17.772007 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:26:17.772022 20451 solver.cpp:244]     Train net output #1: loss = 0.218792 (* 1 = 0.218792 loss)
I0809 01:26:17.772035 20451 sgd_solver.cpp:106] Iteration 18180, lr = 0.000459774
I0809 01:26:40.086979 20451 solver.cpp:228] Iteration 18190, loss = 0.250082
I0809 01:26:40.087033 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 01:26:40.087049 20451 solver.cpp:244]     Train net output #1: loss = 0.250083 (* 1 = 0.250083 loss)
I0809 01:26:40.087060 20451 sgd_solver.cpp:106] Iteration 18190, lr = 0.000459652
I0809 01:27:00.170392 20451 solver.cpp:337] Iteration 18200, Testing net (#0)
I0809 01:27:08.697685 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 01:27:08.697731 20451 solver.cpp:404]     Test net output #1: loss = 0.998593 (* 1 = 0.998593 loss)
I0809 01:27:10.903339 20451 solver.cpp:228] Iteration 18200, loss = 0.156285
I0809 01:27:10.903388 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:27:10.903408 20451 solver.cpp:244]     Train net output #1: loss = 0.156285 (* 1 = 0.156285 loss)
I0809 01:27:10.903422 20451 sgd_solver.cpp:106] Iteration 18200, lr = 0.000459529
I0809 01:27:33.186776 20451 solver.cpp:228] Iteration 18210, loss = 0.250135
I0809 01:27:33.186892 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:27:33.186911 20451 solver.cpp:244]     Train net output #1: loss = 0.250136 (* 1 = 0.250136 loss)
I0809 01:27:33.186928 20451 sgd_solver.cpp:106] Iteration 18210, lr = 0.000459407
I0809 01:27:55.499790 20451 solver.cpp:228] Iteration 18220, loss = 0.218848
I0809 01:27:55.499837 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:27:55.499852 20451 solver.cpp:244]     Train net output #1: loss = 0.218848 (* 1 = 0.218848 loss)
I0809 01:27:55.499866 20451 sgd_solver.cpp:106] Iteration 18220, lr = 0.000459285
I0809 01:28:17.823900 20451 solver.cpp:228] Iteration 18230, loss = 0.281373
I0809 01:28:17.824069 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 01:28:17.824084 20451 solver.cpp:244]     Train net output #1: loss = 0.281373 (* 1 = 0.281373 loss)
I0809 01:28:17.824097 20451 sgd_solver.cpp:106] Iteration 18230, lr = 0.000459163
I0809 01:28:40.137681 20451 solver.cpp:228] Iteration 18240, loss = 0.187599
I0809 01:28:40.137732 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:28:40.137747 20451 solver.cpp:244]     Train net output #1: loss = 0.187599 (* 1 = 0.187599 loss)
I0809 01:28:40.137758 20451 sgd_solver.cpp:106] Iteration 18240, lr = 0.000459041
I0809 01:29:02.457808 20451 solver.cpp:228] Iteration 18250, loss = 0.125066
I0809 01:29:02.457947 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:29:02.457962 20451 solver.cpp:244]     Train net output #1: loss = 0.125066 (* 1 = 0.125066 loss)
I0809 01:29:02.457975 20451 sgd_solver.cpp:106] Iteration 18250, lr = 0.000458919
I0809 01:29:24.772348 20451 solver.cpp:228] Iteration 18260, loss = 0.28154
I0809 01:29:24.772403 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 01:29:24.772416 20451 solver.cpp:244]     Train net output #1: loss = 0.28154 (* 1 = 0.28154 loss)
I0809 01:29:24.772429 20451 sgd_solver.cpp:106] Iteration 18260, lr = 0.000458797
I0809 01:29:47.092370 20451 solver.cpp:228] Iteration 18270, loss = 0.375482
I0809 01:29:47.092547 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0809 01:29:47.092563 20451 solver.cpp:244]     Train net output #1: loss = 0.375482 (* 1 = 0.375482 loss)
I0809 01:29:47.092576 20451 sgd_solver.cpp:106] Iteration 18270, lr = 0.000458676
I0809 01:30:09.404062 20451 solver.cpp:228] Iteration 18280, loss = 0.156272
I0809 01:30:09.404114 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:30:09.404127 20451 solver.cpp:244]     Train net output #1: loss = 0.156272 (* 1 = 0.156272 loss)
I0809 01:30:09.404140 20451 sgd_solver.cpp:106] Iteration 18280, lr = 0.000458554
I0809 01:30:31.722139 20451 solver.cpp:228] Iteration 18290, loss = 0.312645
I0809 01:30:31.722239 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 01:30:31.722257 20451 solver.cpp:244]     Train net output #1: loss = 0.312645 (* 1 = 0.312645 loss)
I0809 01:30:31.722272 20451 sgd_solver.cpp:106] Iteration 18290, lr = 0.000458432
I0809 01:30:51.819862 20451 solver.cpp:337] Iteration 18300, Testing net (#0)
I0809 01:31:00.350642 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 01:31:00.350692 20451 solver.cpp:404]     Test net output #1: loss = 1.00897 (* 1 = 1.00897 loss)
I0809 01:31:02.553402 20451 solver.cpp:228] Iteration 18300, loss = 0.250428
I0809 01:31:02.553565 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:31:02.553578 20451 solver.cpp:244]     Train net output #1: loss = 0.250428 (* 1 = 0.250428 loss)
I0809 01:31:02.553591 20451 sgd_solver.cpp:106] Iteration 18300, lr = 0.000458311
I0809 01:31:24.843634 20451 solver.cpp:228] Iteration 18310, loss = 0.156382
I0809 01:31:24.843685 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:31:24.843698 20451 solver.cpp:244]     Train net output #1: loss = 0.156382 (* 1 = 0.156382 loss)
I0809 01:31:24.843710 20451 sgd_solver.cpp:106] Iteration 18310, lr = 0.000458189
I0809 01:31:47.156045 20451 solver.cpp:228] Iteration 18320, loss = 0.125162
I0809 01:31:47.156234 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:31:47.156250 20451 solver.cpp:244]     Train net output #1: loss = 0.125162 (* 1 = 0.125162 loss)
I0809 01:31:47.156262 20451 sgd_solver.cpp:106] Iteration 18320, lr = 0.000458068
I0809 01:32:09.473806 20451 solver.cpp:228] Iteration 18330, loss = 0.125169
I0809 01:32:09.473860 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:32:09.473873 20451 solver.cpp:244]     Train net output #1: loss = 0.12517 (* 1 = 0.12517 loss)
I0809 01:32:09.473886 20451 sgd_solver.cpp:106] Iteration 18330, lr = 0.000457947
I0809 01:32:31.788524 20451 solver.cpp:228] Iteration 18340, loss = 0.187536
I0809 01:32:31.788625 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:32:31.788641 20451 solver.cpp:244]     Train net output #1: loss = 0.187536 (* 1 = 0.187536 loss)
I0809 01:32:31.788655 20451 sgd_solver.cpp:106] Iteration 18340, lr = 0.000457826
I0809 01:32:54.107805 20451 solver.cpp:228] Iteration 18350, loss = 0.12508
I0809 01:32:54.107851 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:32:54.107867 20451 solver.cpp:244]     Train net output #1: loss = 0.12508 (* 1 = 0.12508 loss)
I0809 01:32:54.107880 20451 sgd_solver.cpp:106] Iteration 18350, lr = 0.000457705
I0809 01:33:16.421149 20451 solver.cpp:228] Iteration 18360, loss = 0.218821
I0809 01:33:16.421370 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:33:16.421385 20451 solver.cpp:244]     Train net output #1: loss = 0.218821 (* 1 = 0.218821 loss)
I0809 01:33:16.421397 20451 sgd_solver.cpp:106] Iteration 18360, lr = 0.000457583
I0809 01:33:38.734774 20451 solver.cpp:228] Iteration 18370, loss = 0.156355
I0809 01:33:38.734827 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:33:38.734840 20451 solver.cpp:244]     Train net output #1: loss = 0.156356 (* 1 = 0.156356 loss)
I0809 01:33:38.734853 20451 sgd_solver.cpp:106] Iteration 18370, lr = 0.000457463
I0809 01:34:01.048069 20451 solver.cpp:228] Iteration 18380, loss = 0.156282
I0809 01:34:01.048246 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:34:01.048264 20451 solver.cpp:244]     Train net output #1: loss = 0.156283 (* 1 = 0.156283 loss)
I0809 01:34:01.048277 20451 sgd_solver.cpp:106] Iteration 18380, lr = 0.000457342
I0809 01:34:23.367655 20451 solver.cpp:228] Iteration 18390, loss = 0.250023
I0809 01:34:23.367707 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:34:23.367722 20451 solver.cpp:244]     Train net output #1: loss = 0.250023 (* 1 = 0.250023 loss)
I0809 01:34:23.367733 20451 sgd_solver.cpp:106] Iteration 18390, lr = 0.000457221
I0809 01:34:43.455799 20451 solver.cpp:337] Iteration 18400, Testing net (#0)
I0809 01:34:51.983100 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 01:34:51.983144 20451 solver.cpp:404]     Test net output #1: loss = 1.0034 (* 1 = 1.0034 loss)
I0809 01:34:54.187052 20451 solver.cpp:228] Iteration 18400, loss = 0.156312
I0809 01:34:54.187103 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:34:54.187117 20451 solver.cpp:244]     Train net output #1: loss = 0.156312 (* 1 = 0.156312 loss)
I0809 01:34:54.187130 20451 sgd_solver.cpp:106] Iteration 18400, lr = 0.0004571
I0809 01:35:16.478741 20451 solver.cpp:228] Iteration 18410, loss = 0.125054
I0809 01:35:16.478915 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:35:16.478931 20451 solver.cpp:244]     Train net output #1: loss = 0.125054 (* 1 = 0.125054 loss)
I0809 01:35:16.478945 20451 sgd_solver.cpp:106] Iteration 18410, lr = 0.000456979
I0809 01:35:38.799618 20451 solver.cpp:228] Iteration 18420, loss = 0.218848
I0809 01:35:38.799662 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:35:38.799679 20451 solver.cpp:244]     Train net output #1: loss = 0.218848 (* 1 = 0.218848 loss)
I0809 01:35:38.799691 20451 sgd_solver.cpp:106] Iteration 18420, lr = 0.000456859
I0809 01:36:01.115784 20451 solver.cpp:228] Iteration 18430, loss = 0.28137
I0809 01:36:01.115962 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 01:36:01.115977 20451 solver.cpp:244]     Train net output #1: loss = 0.28137 (* 1 = 0.28137 loss)
I0809 01:36:01.115988 20451 sgd_solver.cpp:106] Iteration 18430, lr = 0.000456738
I0809 01:36:23.438766 20451 solver.cpp:228] Iteration 18440, loss = 0.250084
I0809 01:36:23.438818 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:36:23.438832 20451 solver.cpp:244]     Train net output #1: loss = 0.250084 (* 1 = 0.250084 loss)
I0809 01:36:23.438844 20451 sgd_solver.cpp:106] Iteration 18440, lr = 0.000456618
I0809 01:36:45.743753 20451 solver.cpp:228] Iteration 18450, loss = 0.0937991
I0809 01:36:45.743932 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:36:45.743947 20451 solver.cpp:244]     Train net output #1: loss = 0.0937992 (* 1 = 0.0937992 loss)
I0809 01:36:45.743959 20451 sgd_solver.cpp:106] Iteration 18450, lr = 0.000456497
I0809 01:37:08.065709 20451 solver.cpp:228] Iteration 18460, loss = 0.093782
I0809 01:37:08.065753 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:37:08.065770 20451 solver.cpp:244]     Train net output #1: loss = 0.0937822 (* 1 = 0.0937822 loss)
I0809 01:37:08.065796 20451 sgd_solver.cpp:106] Iteration 18460, lr = 0.000456377
I0809 01:37:30.375752 20451 solver.cpp:228] Iteration 18470, loss = 0.125333
I0809 01:37:30.375954 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 01:37:30.375974 20451 solver.cpp:244]     Train net output #1: loss = 0.125333 (* 1 = 0.125333 loss)
I0809 01:37:30.375990 20451 sgd_solver.cpp:106] Iteration 18470, lr = 0.000456257
I0809 01:37:52.689440 20451 solver.cpp:228] Iteration 18480, loss = 0.250056
I0809 01:37:52.689487 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:37:52.689507 20451 solver.cpp:244]     Train net output #1: loss = 0.250056 (* 1 = 0.250056 loss)
I0809 01:37:52.689520 20451 sgd_solver.cpp:106] Iteration 18480, lr = 0.000456137
I0809 01:38:15.009227 20451 solver.cpp:228] Iteration 18490, loss = 0.156257
I0809 01:38:15.009409 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:38:15.009424 20451 solver.cpp:244]     Train net output #1: loss = 0.156257 (* 1 = 0.156257 loss)
I0809 01:38:15.009436 20451 sgd_solver.cpp:106] Iteration 18490, lr = 0.000456017
I0809 01:38:35.104985 20451 solver.cpp:337] Iteration 18500, Testing net (#0)
I0809 01:38:43.635792 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0809 01:38:43.635843 20451 solver.cpp:404]     Test net output #1: loss = 0.961166 (* 1 = 0.961166 loss)
I0809 01:38:45.837590 20451 solver.cpp:228] Iteration 18500, loss = 0.218826
I0809 01:38:45.837771 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:38:45.837791 20451 solver.cpp:244]     Train net output #1: loss = 0.218827 (* 1 = 0.218827 loss)
I0809 01:38:45.837805 20451 sgd_solver.cpp:106] Iteration 18500, lr = 0.000455897
I0809 01:39:08.128751 20451 solver.cpp:228] Iteration 18510, loss = 0.125003
I0809 01:39:08.128804 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:39:08.128824 20451 solver.cpp:244]     Train net output #1: loss = 0.125003 (* 1 = 0.125003 loss)
I0809 01:39:08.128840 20451 sgd_solver.cpp:106] Iteration 18510, lr = 0.000455777
I0809 01:39:30.448612 20451 solver.cpp:228] Iteration 18520, loss = 0.156354
I0809 01:39:30.448801 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:39:30.448822 20451 solver.cpp:244]     Train net output #1: loss = 0.156354 (* 1 = 0.156354 loss)
I0809 01:39:30.448837 20451 sgd_solver.cpp:106] Iteration 18520, lr = 0.000455657
I0809 01:39:52.766806 20451 solver.cpp:228] Iteration 18530, loss = 0.125085
I0809 01:39:52.766855 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:39:52.766875 20451 solver.cpp:244]     Train net output #1: loss = 0.125085 (* 1 = 0.125085 loss)
I0809 01:39:52.766893 20451 sgd_solver.cpp:106] Iteration 18530, lr = 0.000455537
I0809 01:40:15.095129 20451 solver.cpp:228] Iteration 18540, loss = 0.125051
I0809 01:40:15.095230 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:40:15.095247 20451 solver.cpp:244]     Train net output #1: loss = 0.125051 (* 1 = 0.125051 loss)
I0809 01:40:15.095259 20451 sgd_solver.cpp:106] Iteration 18540, lr = 0.000455417
I0809 01:40:37.412245 20451 solver.cpp:228] Iteration 18550, loss = 0.187789
I0809 01:40:37.412295 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:40:37.412309 20451 solver.cpp:244]     Train net output #1: loss = 0.187789 (* 1 = 0.187789 loss)
I0809 01:40:37.412322 20451 sgd_solver.cpp:106] Iteration 18550, lr = 0.000455298
I0809 01:40:59.722364 20451 solver.cpp:228] Iteration 18560, loss = 0.18754
I0809 01:40:59.722535 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:40:59.722550 20451 solver.cpp:244]     Train net output #1: loss = 0.18754 (* 1 = 0.18754 loss)
I0809 01:40:59.722563 20451 sgd_solver.cpp:106] Iteration 18560, lr = 0.000455178
I0809 01:41:22.034698 20451 solver.cpp:228] Iteration 18570, loss = 0.250182
I0809 01:41:22.034750 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:41:22.034765 20451 solver.cpp:244]     Train net output #1: loss = 0.250182 (* 1 = 0.250182 loss)
I0809 01:41:22.034776 20451 sgd_solver.cpp:106] Iteration 18570, lr = 0.000455059
I0809 01:41:44.342516 20451 solver.cpp:228] Iteration 18580, loss = 0.187525
I0809 01:41:44.342736 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:41:44.342751 20451 solver.cpp:244]     Train net output #1: loss = 0.187525 (* 1 = 0.187525 loss)
I0809 01:41:44.342763 20451 sgd_solver.cpp:106] Iteration 18580, lr = 0.000454939
I0809 01:42:06.659301 20451 solver.cpp:228] Iteration 18590, loss = 0.187575
I0809 01:42:06.659356 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:42:06.659371 20451 solver.cpp:244]     Train net output #1: loss = 0.187575 (* 1 = 0.187575 loss)
I0809 01:42:06.659384 20451 sgd_solver.cpp:106] Iteration 18590, lr = 0.00045482
I0809 01:42:26.747447 20451 solver.cpp:337] Iteration 18600, Testing net (#0)
I0809 01:42:35.277482 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 01:42:35.277526 20451 solver.cpp:404]     Test net output #1: loss = 0.994225 (* 1 = 0.994225 loss)
I0809 01:42:37.481211 20451 solver.cpp:228] Iteration 18600, loss = 0.218906
I0809 01:42:37.481257 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:42:37.481276 20451 solver.cpp:244]     Train net output #1: loss = 0.218906 (* 1 = 0.218906 loss)
I0809 01:42:37.481292 20451 sgd_solver.cpp:106] Iteration 18600, lr = 0.000454701
I0809 01:42:59.780352 20451 solver.cpp:228] Iteration 18610, loss = 0.125073
I0809 01:42:59.780531 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:42:59.780550 20451 solver.cpp:244]     Train net output #1: loss = 0.125073 (* 1 = 0.125073 loss)
I0809 01:42:59.780566 20451 sgd_solver.cpp:106] Iteration 18610, lr = 0.000454581
I0809 01:43:22.101147 20451 solver.cpp:228] Iteration 18620, loss = 0.250103
I0809 01:43:22.101192 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 01:43:22.101210 20451 solver.cpp:244]     Train net output #1: loss = 0.250103 (* 1 = 0.250103 loss)
I0809 01:43:22.101227 20451 sgd_solver.cpp:106] Iteration 18620, lr = 0.000454462
I0809 01:43:44.420104 20451 solver.cpp:228] Iteration 18630, loss = 0.187574
I0809 01:43:44.420291 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:43:44.420310 20451 solver.cpp:244]     Train net output #1: loss = 0.187574 (* 1 = 0.187574 loss)
I0809 01:43:44.420326 20451 sgd_solver.cpp:106] Iteration 18630, lr = 0.000454343
I0809 01:44:06.739132 20451 solver.cpp:228] Iteration 18640, loss = 0.0627093
I0809 01:44:06.739187 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 01:44:06.739200 20451 solver.cpp:244]     Train net output #1: loss = 0.0627094 (* 1 = 0.0627094 loss)
I0809 01:44:06.739212 20451 sgd_solver.cpp:106] Iteration 18640, lr = 0.000454224
I0809 01:44:29.048547 20451 solver.cpp:228] Iteration 18650, loss = 0.250079
I0809 01:44:29.048655 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:44:29.048674 20451 solver.cpp:244]     Train net output #1: loss = 0.250079 (* 1 = 0.250079 loss)
I0809 01:44:29.048689 20451 sgd_solver.cpp:106] Iteration 18650, lr = 0.000454105
I0809 01:44:51.359809 20451 solver.cpp:228] Iteration 18660, loss = 0.125019
I0809 01:44:51.359863 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:44:51.359876 20451 solver.cpp:244]     Train net output #1: loss = 0.125019 (* 1 = 0.125019 loss)
I0809 01:44:51.359887 20451 sgd_solver.cpp:106] Iteration 18660, lr = 0.000453986
I0809 01:45:13.662732 20451 solver.cpp:228] Iteration 18670, loss = 0.125101
I0809 01:45:13.662904 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:45:13.662919 20451 solver.cpp:244]     Train net output #1: loss = 0.125101 (* 1 = 0.125101 loss)
I0809 01:45:13.662931 20451 sgd_solver.cpp:106] Iteration 18670, lr = 0.000453868
I0809 01:45:35.974117 20451 solver.cpp:228] Iteration 18680, loss = 0.125042
I0809 01:45:35.974160 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 01:45:35.974175 20451 solver.cpp:244]     Train net output #1: loss = 0.125042 (* 1 = 0.125042 loss)
I0809 01:45:35.974187 20451 sgd_solver.cpp:106] Iteration 18680, lr = 0.000453749
I0809 01:45:58.278825 20451 solver.cpp:228] Iteration 18690, loss = 0.0937851
I0809 01:45:58.279018 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:45:58.279033 20451 solver.cpp:244]     Train net output #1: loss = 0.0937852 (* 1 = 0.0937852 loss)
I0809 01:45:58.279045 20451 sgd_solver.cpp:106] Iteration 18690, lr = 0.00045363
I0809 01:46:18.365696 20451 solver.cpp:337] Iteration 18700, Testing net (#0)
I0809 01:46:26.894114 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 01:46:26.894165 20451 solver.cpp:404]     Test net output #1: loss = 0.998694 (* 1 = 0.998694 loss)
I0809 01:46:29.100612 20451 solver.cpp:228] Iteration 18700, loss = 0.0937877
I0809 01:46:29.100786 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:46:29.100801 20451 solver.cpp:244]     Train net output #1: loss = 0.0937879 (* 1 = 0.0937879 loss)
I0809 01:46:29.100814 20451 sgd_solver.cpp:106] Iteration 18700, lr = 0.000453512
I0809 01:46:51.391522 20451 solver.cpp:228] Iteration 18710, loss = 0.250109
I0809 01:46:51.391574 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:46:51.391588 20451 solver.cpp:244]     Train net output #1: loss = 0.250109 (* 1 = 0.250109 loss)
I0809 01:46:51.391600 20451 sgd_solver.cpp:106] Iteration 18710, lr = 0.000453393
I0809 01:47:13.704056 20451 solver.cpp:228] Iteration 18720, loss = 0.0312655
I0809 01:47:13.704154 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 01:47:13.704174 20451 solver.cpp:244]     Train net output #1: loss = 0.0312656 (* 1 = 0.0312656 loss)
I0809 01:47:13.704190 20451 sgd_solver.cpp:106] Iteration 18720, lr = 0.000453275
I0809 01:47:36.009021 20451 solver.cpp:228] Iteration 18730, loss = 0.156357
I0809 01:47:36.009068 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:47:36.009094 20451 solver.cpp:244]     Train net output #1: loss = 0.156357 (* 1 = 0.156357 loss)
I0809 01:47:36.009109 20451 sgd_solver.cpp:106] Iteration 18730, lr = 0.000453157
I0809 01:47:58.321173 20451 solver.cpp:228] Iteration 18740, loss = 0.250116
I0809 01:47:58.321391 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 01:47:58.321455 20451 solver.cpp:244]     Train net output #1: loss = 0.250116 (* 1 = 0.250116 loss)
I0809 01:47:58.321490 20451 sgd_solver.cpp:106] Iteration 18740, lr = 0.000453038
I0809 01:48:20.643254 20451 solver.cpp:228] Iteration 18750, loss = 0.0625254
I0809 01:48:20.643301 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 01:48:20.643329 20451 solver.cpp:244]     Train net output #1: loss = 0.0625255 (* 1 = 0.0625255 loss)
I0809 01:48:20.643344 20451 sgd_solver.cpp:106] Iteration 18750, lr = 0.00045292
I0809 01:48:42.958680 20451 solver.cpp:228] Iteration 18760, loss = 0.156305
I0809 01:48:42.958864 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:48:42.958880 20451 solver.cpp:244]     Train net output #1: loss = 0.156306 (* 1 = 0.156306 loss)
I0809 01:48:42.958892 20451 sgd_solver.cpp:106] Iteration 18760, lr = 0.000452802
I0809 01:49:05.274986 20451 solver.cpp:228] Iteration 18770, loss = 0.187553
I0809 01:49:05.275039 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:49:05.275053 20451 solver.cpp:244]     Train net output #1: loss = 0.187553 (* 1 = 0.187553 loss)
I0809 01:49:05.275065 20451 sgd_solver.cpp:106] Iteration 18770, lr = 0.000452684
I0809 01:49:27.582528 20451 solver.cpp:228] Iteration 18780, loss = 0.0625039
I0809 01:49:27.582762 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 01:49:27.582777 20451 solver.cpp:244]     Train net output #1: loss = 0.0625041 (* 1 = 0.0625041 loss)
I0809 01:49:27.582789 20451 sgd_solver.cpp:106] Iteration 18780, lr = 0.000452566
I0809 01:49:49.894928 20451 solver.cpp:228] Iteration 18790, loss = 0.187684
I0809 01:49:49.894981 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:49:49.894995 20451 solver.cpp:244]     Train net output #1: loss = 0.187684 (* 1 = 0.187684 loss)
I0809 01:49:49.895007 20451 sgd_solver.cpp:106] Iteration 18790, lr = 0.000452448
I0809 01:50:09.986835 20451 solver.cpp:337] Iteration 18800, Testing net (#0)
I0809 01:50:18.514909 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0809 01:50:18.514971 20451 solver.cpp:404]     Test net output #1: loss = 0.989611 (* 1 = 0.989611 loss)
I0809 01:50:20.721971 20451 solver.cpp:228] Iteration 18800, loss = 0.0938268
I0809 01:50:20.722021 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:50:20.722036 20451 solver.cpp:244]     Train net output #1: loss = 0.093827 (* 1 = 0.093827 loss)
I0809 01:50:20.722048 20451 sgd_solver.cpp:106] Iteration 18800, lr = 0.00045233
I0809 01:50:43.013592 20451 solver.cpp:228] Iteration 18810, loss = 0.156478
I0809 01:50:43.013767 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:50:43.013782 20451 solver.cpp:244]     Train net output #1: loss = 0.156479 (* 1 = 0.156479 loss)
I0809 01:50:43.013795 20451 sgd_solver.cpp:106] Iteration 18810, lr = 0.000452213
I0809 01:51:05.324594 20451 solver.cpp:228] Iteration 18820, loss = 0.187532
I0809 01:51:05.324637 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:51:05.324652 20451 solver.cpp:244]     Train net output #1: loss = 0.187532 (* 1 = 0.187532 loss)
I0809 01:51:05.324666 20451 sgd_solver.cpp:106] Iteration 18820, lr = 0.000452095
I0809 01:51:27.638350 20451 solver.cpp:228] Iteration 18830, loss = 0.156408
I0809 01:51:27.638525 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:51:27.638540 20451 solver.cpp:244]     Train net output #1: loss = 0.156408 (* 1 = 0.156408 loss)
I0809 01:51:27.638552 20451 sgd_solver.cpp:106] Iteration 18830, lr = 0.000451977
I0809 01:51:49.955548 20451 solver.cpp:228] Iteration 18840, loss = 0.0937746
I0809 01:51:49.955590 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:51:49.955605 20451 solver.cpp:244]     Train net output #1: loss = 0.0937748 (* 1 = 0.0937748 loss)
I0809 01:51:49.955617 20451 sgd_solver.cpp:106] Iteration 18840, lr = 0.00045186
I0809 01:52:12.269251 20451 solver.cpp:228] Iteration 18850, loss = 0.218784
I0809 01:52:12.269433 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:52:12.269448 20451 solver.cpp:244]     Train net output #1: loss = 0.218784 (* 1 = 0.218784 loss)
I0809 01:52:12.269459 20451 sgd_solver.cpp:106] Iteration 18850, lr = 0.000451742
I0809 01:52:34.576869 20451 solver.cpp:228] Iteration 18860, loss = 0.31254
I0809 01:52:34.576922 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 01:52:34.576936 20451 solver.cpp:244]     Train net output #1: loss = 0.31254 (* 1 = 0.31254 loss)
I0809 01:52:34.576947 20451 sgd_solver.cpp:106] Iteration 18860, lr = 0.000451625
I0809 01:52:56.887629 20451 solver.cpp:228] Iteration 18870, loss = 0.0312581
I0809 01:52:56.887809 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 01:52:56.887825 20451 solver.cpp:244]     Train net output #1: loss = 0.0312583 (* 1 = 0.0312583 loss)
I0809 01:52:56.887837 20451 sgd_solver.cpp:106] Iteration 18870, lr = 0.000451507
I0809 01:53:19.198725 20451 solver.cpp:228] Iteration 18880, loss = 0.062575
I0809 01:53:19.198770 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 01:53:19.198788 20451 solver.cpp:244]     Train net output #1: loss = 0.0625752 (* 1 = 0.0625752 loss)
I0809 01:53:19.198803 20451 sgd_solver.cpp:106] Iteration 18880, lr = 0.00045139
I0809 01:53:41.516100 20451 solver.cpp:228] Iteration 18890, loss = 0.219287
I0809 01:53:41.516290 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:53:41.516305 20451 solver.cpp:244]     Train net output #1: loss = 0.219287 (* 1 = 0.219287 loss)
I0809 01:53:41.516317 20451 sgd_solver.cpp:106] Iteration 18890, lr = 0.000451273
I0809 01:54:01.598625 20451 solver.cpp:337] Iteration 18900, Testing net (#0)
I0809 01:54:10.121219 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0809 01:54:10.121273 20451 solver.cpp:404]     Test net output #1: loss = 1.03624 (* 1 = 1.03624 loss)
I0809 01:54:12.324616 20451 solver.cpp:228] Iteration 18900, loss = 0.0937933
I0809 01:54:12.324836 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:54:12.324853 20451 solver.cpp:244]     Train net output #1: loss = 0.0937935 (* 1 = 0.0937935 loss)
I0809 01:54:12.324865 20451 sgd_solver.cpp:106] Iteration 18900, lr = 0.000451156
I0809 01:54:34.609336 20451 solver.cpp:228] Iteration 18910, loss = 0.031251
I0809 01:54:34.609390 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 01:54:34.609403 20451 solver.cpp:244]     Train net output #1: loss = 0.0312512 (* 1 = 0.0312512 loss)
I0809 01:54:34.609416 20451 sgd_solver.cpp:106] Iteration 18910, lr = 0.000451039
I0809 01:54:56.922698 20451 solver.cpp:228] Iteration 18920, loss = 0.187599
I0809 01:54:56.922881 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:54:56.922897 20451 solver.cpp:244]     Train net output #1: loss = 0.187599 (* 1 = 0.187599 loss)
I0809 01:54:56.922910 20451 sgd_solver.cpp:106] Iteration 18920, lr = 0.000450922
I0809 01:55:19.233049 20451 solver.cpp:228] Iteration 18930, loss = 0.0937697
I0809 01:55:19.233103 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:55:19.233124 20451 solver.cpp:244]     Train net output #1: loss = 0.0937699 (* 1 = 0.0937699 loss)
I0809 01:55:19.233139 20451 sgd_solver.cpp:106] Iteration 18930, lr = 0.000450805
I0809 01:55:41.547904 20451 solver.cpp:228] Iteration 18940, loss = 0.0937664
I0809 01:55:41.548084 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:55:41.548099 20451 solver.cpp:244]     Train net output #1: loss = 0.0937666 (* 1 = 0.0937666 loss)
I0809 01:55:41.548111 20451 sgd_solver.cpp:106] Iteration 18940, lr = 0.000450688
I0809 01:56:03.868044 20451 solver.cpp:228] Iteration 18950, loss = 0.15631
I0809 01:56:03.868098 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:56:03.868113 20451 solver.cpp:244]     Train net output #1: loss = 0.15631 (* 1 = 0.15631 loss)
I0809 01:56:03.868124 20451 sgd_solver.cpp:106] Iteration 18950, lr = 0.000450571
I0809 01:56:26.184293 20451 solver.cpp:228] Iteration 18960, loss = 0.0937979
I0809 01:56:26.184394 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:56:26.184412 20451 solver.cpp:244]     Train net output #1: loss = 0.0937981 (* 1 = 0.0937981 loss)
I0809 01:56:26.184424 20451 sgd_solver.cpp:106] Iteration 18960, lr = 0.000450455
I0809 01:56:48.496932 20451 solver.cpp:228] Iteration 18970, loss = 0.218899
I0809 01:56:48.496986 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 01:56:48.497000 20451 solver.cpp:244]     Train net output #1: loss = 0.2189 (* 1 = 0.2189 loss)
I0809 01:56:48.497014 20451 sgd_solver.cpp:106] Iteration 18970, lr = 0.000450338
I0809 01:57:10.808156 20451 solver.cpp:228] Iteration 18980, loss = 0.093782
I0809 01:57:10.808337 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 01:57:10.808354 20451 solver.cpp:244]     Train net output #1: loss = 0.0937821 (* 1 = 0.0937821 loss)
I0809 01:57:10.808369 20451 sgd_solver.cpp:106] Iteration 18980, lr = 0.000450222
I0809 01:57:33.117904 20451 solver.cpp:228] Iteration 18990, loss = 0.0625319
I0809 01:57:33.117954 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 01:57:33.117967 20451 solver.cpp:244]     Train net output #1: loss = 0.062532 (* 1 = 0.062532 loss)
I0809 01:57:33.117980 20451 sgd_solver.cpp:106] Iteration 18990, lr = 0.000450105
I0809 01:57:53.206814 20451 solver.cpp:337] Iteration 19000, Testing net (#0)
I0809 01:58:01.727416 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 01:58:01.727461 20451 solver.cpp:404]     Test net output #1: loss = 0.984587 (* 1 = 0.984587 loss)
I0809 01:58:03.932632 20451 solver.cpp:228] Iteration 19000, loss = 0.187559
I0809 01:58:03.932690 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:58:03.932709 20451 solver.cpp:244]     Train net output #1: loss = 0.187559 (* 1 = 0.187559 loss)
I0809 01:58:03.932724 20451 sgd_solver.cpp:106] Iteration 19000, lr = 0.000449989
I0809 01:58:26.223503 20451 solver.cpp:228] Iteration 19010, loss = 0.187598
I0809 01:58:26.223719 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:58:26.223734 20451 solver.cpp:244]     Train net output #1: loss = 0.187599 (* 1 = 0.187599 loss)
I0809 01:58:26.223747 20451 sgd_solver.cpp:106] Iteration 19010, lr = 0.000449872
I0809 01:58:48.532209 20451 solver.cpp:228] Iteration 19020, loss = 0.187594
I0809 01:58:48.532263 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:58:48.532276 20451 solver.cpp:244]     Train net output #1: loss = 0.187594 (* 1 = 0.187594 loss)
I0809 01:58:48.532289 20451 sgd_solver.cpp:106] Iteration 19020, lr = 0.000449756
I0809 01:59:10.855562 20451 solver.cpp:228] Iteration 19030, loss = 0.187524
I0809 01:59:10.855669 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 01:59:10.855685 20451 solver.cpp:244]     Train net output #1: loss = 0.187524 (* 1 = 0.187524 loss)
I0809 01:59:10.855698 20451 sgd_solver.cpp:106] Iteration 19030, lr = 0.00044964
I0809 01:59:33.171134 20451 solver.cpp:228] Iteration 19040, loss = 0.0938909
I0809 01:59:33.171186 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 01:59:33.171201 20451 solver.cpp:244]     Train net output #1: loss = 0.0938911 (* 1 = 0.0938911 loss)
I0809 01:59:33.171213 20451 sgd_solver.cpp:106] Iteration 19040, lr = 0.000449524
I0809 01:59:55.483757 20451 solver.cpp:228] Iteration 19050, loss = 0.156254
I0809 01:59:55.483928 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 01:59:55.483943 20451 solver.cpp:244]     Train net output #1: loss = 0.156254 (* 1 = 0.156254 loss)
I0809 01:59:55.483955 20451 sgd_solver.cpp:106] Iteration 19050, lr = 0.000449408
I0809 02:00:17.806875 20451 solver.cpp:228] Iteration 19060, loss = 0.156567
I0809 02:00:17.806921 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:00:17.806937 20451 solver.cpp:244]     Train net output #1: loss = 0.156567 (* 1 = 0.156567 loss)
I0809 02:00:17.806951 20451 sgd_solver.cpp:106] Iteration 19060, lr = 0.000449292
I0809 02:00:40.124043 20451 solver.cpp:228] Iteration 19070, loss = 0.125086
I0809 02:00:40.124228 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:00:40.124243 20451 solver.cpp:244]     Train net output #1: loss = 0.125086 (* 1 = 0.125086 loss)
I0809 02:00:40.124255 20451 sgd_solver.cpp:106] Iteration 19070, lr = 0.000449176
I0809 02:01:02.440887 20451 solver.cpp:228] Iteration 19080, loss = 0.125192
I0809 02:01:02.440937 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:01:02.440950 20451 solver.cpp:244]     Train net output #1: loss = 0.125192 (* 1 = 0.125192 loss)
I0809 02:01:02.440963 20451 sgd_solver.cpp:106] Iteration 19080, lr = 0.00044906
I0809 02:01:24.762935 20451 solver.cpp:228] Iteration 19090, loss = 0.156385
I0809 02:01:24.763103 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:01:24.763118 20451 solver.cpp:244]     Train net output #1: loss = 0.156385 (* 1 = 0.156385 loss)
I0809 02:01:24.763130 20451 sgd_solver.cpp:106] Iteration 19090, lr = 0.000448944
I0809 02:01:44.849664 20451 solver.cpp:337] Iteration 19100, Testing net (#0)
I0809 02:01:53.389423 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0809 02:01:53.389479 20451 solver.cpp:404]     Test net output #1: loss = 0.970977 (* 1 = 0.970977 loss)
I0809 02:01:55.593382 20451 solver.cpp:228] Iteration 19100, loss = 0.125127
I0809 02:01:55.593475 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:01:55.593490 20451 solver.cpp:244]     Train net output #1: loss = 0.125127 (* 1 = 0.125127 loss)
I0809 02:01:55.593502 20451 sgd_solver.cpp:106] Iteration 19100, lr = 0.000448828
I0809 02:02:17.894222 20451 solver.cpp:228] Iteration 19110, loss = 0.0937989
I0809 02:02:17.894273 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:02:17.894286 20451 solver.cpp:244]     Train net output #1: loss = 0.0937991 (* 1 = 0.0937991 loss)
I0809 02:02:17.894299 20451 sgd_solver.cpp:106] Iteration 19110, lr = 0.000448713
I0809 02:02:40.209537 20451 solver.cpp:228] Iteration 19120, loss = 0.250047
I0809 02:02:40.209682 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:02:40.209699 20451 solver.cpp:244]     Train net output #1: loss = 0.250048 (* 1 = 0.250048 loss)
I0809 02:02:40.209712 20451 sgd_solver.cpp:106] Iteration 19120, lr = 0.000448597
I0809 02:03:02.527911 20451 solver.cpp:228] Iteration 19130, loss = 0.125063
I0809 02:03:02.527954 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:03:02.527969 20451 solver.cpp:244]     Train net output #1: loss = 0.125064 (* 1 = 0.125064 loss)
I0809 02:03:02.527981 20451 sgd_solver.cpp:106] Iteration 19130, lr = 0.000448482
I0809 02:03:24.837424 20451 solver.cpp:228] Iteration 19140, loss = 0.12507
I0809 02:03:24.837611 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:03:24.837630 20451 solver.cpp:244]     Train net output #1: loss = 0.125071 (* 1 = 0.125071 loss)
I0809 02:03:24.837644 20451 sgd_solver.cpp:106] Iteration 19140, lr = 0.000448366
I0809 02:03:47.146282 20451 solver.cpp:228] Iteration 19150, loss = 0.312648
I0809 02:03:47.146327 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 02:03:47.146342 20451 solver.cpp:244]     Train net output #1: loss = 0.312648 (* 1 = 0.312648 loss)
I0809 02:03:47.146354 20451 sgd_solver.cpp:106] Iteration 19150, lr = 0.000448251
I0809 02:04:09.450824 20451 solver.cpp:228] Iteration 19160, loss = 0.187571
I0809 02:04:09.450999 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:04:09.451015 20451 solver.cpp:244]     Train net output #1: loss = 0.187571 (* 1 = 0.187571 loss)
I0809 02:04:09.451027 20451 sgd_solver.cpp:106] Iteration 19160, lr = 0.000448136
I0809 02:04:31.765707 20451 solver.cpp:228] Iteration 19170, loss = 0.0939789
I0809 02:04:31.765756 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:04:31.765775 20451 solver.cpp:244]     Train net output #1: loss = 0.0939791 (* 1 = 0.0939791 loss)
I0809 02:04:31.765790 20451 sgd_solver.cpp:106] Iteration 19170, lr = 0.00044802
I0809 02:04:54.061842 20451 solver.cpp:228] Iteration 19180, loss = 0.156305
I0809 02:04:54.061938 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:04:54.061956 20451 solver.cpp:244]     Train net output #1: loss = 0.156305 (* 1 = 0.156305 loss)
I0809 02:04:54.061972 20451 sgd_solver.cpp:106] Iteration 19180, lr = 0.000447905
I0809 02:05:16.370425 20451 solver.cpp:228] Iteration 19190, loss = 0.125017
I0809 02:05:16.370481 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:05:16.370494 20451 solver.cpp:244]     Train net output #1: loss = 0.125017 (* 1 = 0.125017 loss)
I0809 02:05:16.370507 20451 sgd_solver.cpp:106] Iteration 19190, lr = 0.00044779
I0809 02:05:36.461045 20451 solver.cpp:337] Iteration 19200, Testing net (#0)
I0809 02:05:44.983839 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 02:05:44.983886 20451 solver.cpp:404]     Test net output #1: loss = 1.00793 (* 1 = 1.00793 loss)
I0809 02:05:47.189764 20451 solver.cpp:228] Iteration 19200, loss = 0.25004
I0809 02:05:47.189816 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:05:47.189831 20451 solver.cpp:244]     Train net output #1: loss = 0.25004 (* 1 = 0.25004 loss)
I0809 02:05:47.189843 20451 sgd_solver.cpp:106] Iteration 19200, lr = 0.000447675
I0809 02:06:09.481076 20451 solver.cpp:228] Iteration 19210, loss = 0.125221
I0809 02:06:09.481259 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:06:09.481274 20451 solver.cpp:244]     Train net output #1: loss = 0.125222 (* 1 = 0.125222 loss)
I0809 02:06:09.481288 20451 sgd_solver.cpp:106] Iteration 19210, lr = 0.00044756
I0809 02:06:31.796726 20451 solver.cpp:228] Iteration 19220, loss = 0.156294
I0809 02:06:31.796773 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 02:06:31.796789 20451 solver.cpp:244]     Train net output #1: loss = 0.156294 (* 1 = 0.156294 loss)
I0809 02:06:31.796802 20451 sgd_solver.cpp:106] Iteration 19220, lr = 0.000447445
I0809 02:06:54.116350 20451 solver.cpp:228] Iteration 19230, loss = 0.218809
I0809 02:06:54.116562 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:06:54.116580 20451 solver.cpp:244]     Train net output #1: loss = 0.218809 (* 1 = 0.218809 loss)
I0809 02:06:54.116591 20451 sgd_solver.cpp:106] Iteration 19230, lr = 0.00044733
I0809 02:07:16.435884 20451 solver.cpp:228] Iteration 19240, loss = 0.156285
I0809 02:07:16.435936 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:07:16.435950 20451 solver.cpp:244]     Train net output #1: loss = 0.156285 (* 1 = 0.156285 loss)
I0809 02:07:16.435961 20451 sgd_solver.cpp:106] Iteration 19240, lr = 0.000447216
I0809 02:07:38.749958 20451 solver.cpp:228] Iteration 19250, loss = 0.125019
I0809 02:07:38.750150 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:07:38.750165 20451 solver.cpp:244]     Train net output #1: loss = 0.125019 (* 1 = 0.125019 loss)
I0809 02:07:38.750180 20451 sgd_solver.cpp:106] Iteration 19250, lr = 0.000447101
I0809 02:08:01.067626 20451 solver.cpp:228] Iteration 19260, loss = 0.125049
I0809 02:08:01.067680 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:08:01.067694 20451 solver.cpp:244]     Train net output #1: loss = 0.125049 (* 1 = 0.125049 loss)
I0809 02:08:01.067706 20451 sgd_solver.cpp:106] Iteration 19260, lr = 0.000446986
I0809 02:08:23.377956 20451 solver.cpp:228] Iteration 19270, loss = 0.250093
I0809 02:08:23.378134 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:08:23.378149 20451 solver.cpp:244]     Train net output #1: loss = 0.250093 (* 1 = 0.250093 loss)
I0809 02:08:23.378161 20451 sgd_solver.cpp:106] Iteration 19270, lr = 0.000446872
I0809 02:08:45.687342 20451 solver.cpp:228] Iteration 19280, loss = 0.250092
I0809 02:08:45.687393 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:08:45.687407 20451 solver.cpp:244]     Train net output #1: loss = 0.250092 (* 1 = 0.250092 loss)
I0809 02:08:45.687419 20451 sgd_solver.cpp:106] Iteration 19280, lr = 0.000446757
I0809 02:09:08.017907 20451 solver.cpp:228] Iteration 19290, loss = 0.0937853
I0809 02:09:08.018010 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:09:08.018026 20451 solver.cpp:244]     Train net output #1: loss = 0.0937855 (* 1 = 0.0937855 loss)
I0809 02:09:08.018039 20451 sgd_solver.cpp:106] Iteration 19290, lr = 0.000446643
I0809 02:09:28.099525 20451 solver.cpp:337] Iteration 19300, Testing net (#0)
I0809 02:09:36.626142 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0809 02:09:36.626194 20451 solver.cpp:404]     Test net output #1: loss = 1.01263 (* 1 = 1.01263 loss)
I0809 02:09:38.831689 20451 solver.cpp:228] Iteration 19300, loss = 0.0625115
I0809 02:09:38.831876 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 02:09:38.831897 20451 solver.cpp:244]     Train net output #1: loss = 0.0625117 (* 1 = 0.0625117 loss)
I0809 02:09:38.831912 20451 sgd_solver.cpp:106] Iteration 19300, lr = 0.000446529
I0809 02:10:01.125054 20451 solver.cpp:228] Iteration 19310, loss = 0.187509
I0809 02:10:01.125097 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:10:01.125116 20451 solver.cpp:244]     Train net output #1: loss = 0.187509 (* 1 = 0.187509 loss)
I0809 02:10:01.125141 20451 sgd_solver.cpp:106] Iteration 19310, lr = 0.000446414
I0809 02:10:23.438343 20451 solver.cpp:228] Iteration 19320, loss = 0.000230819
I0809 02:10:23.438522 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:10:23.438537 20451 solver.cpp:244]     Train net output #1: loss = 0.000230991 (* 1 = 0.000230991 loss)
I0809 02:10:23.438549 20451 sgd_solver.cpp:106] Iteration 19320, lr = 0.0004463
I0809 02:10:45.747910 20451 solver.cpp:228] Iteration 19330, loss = 0.312616
I0809 02:10:45.747961 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 02:10:45.747975 20451 solver.cpp:244]     Train net output #1: loss = 0.312617 (* 1 = 0.312617 loss)
I0809 02:10:45.747987 20451 sgd_solver.cpp:106] Iteration 19330, lr = 0.000446186
I0809 02:11:08.072723 20451 solver.cpp:228] Iteration 19340, loss = 0.219114
I0809 02:11:08.072932 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:11:08.072949 20451 solver.cpp:244]     Train net output #1: loss = 0.219115 (* 1 = 0.219115 loss)
I0809 02:11:08.072962 20451 sgd_solver.cpp:106] Iteration 19340, lr = 0.000446072
I0809 02:11:30.385125 20451 solver.cpp:228] Iteration 19350, loss = 0.0937735
I0809 02:11:30.385176 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:11:30.385191 20451 solver.cpp:244]     Train net output #1: loss = 0.0937737 (* 1 = 0.0937737 loss)
I0809 02:11:30.385203 20451 sgd_solver.cpp:106] Iteration 19350, lr = 0.000445958
I0809 02:11:52.712795 20451 solver.cpp:228] Iteration 19360, loss = 0.187446
I0809 02:11:52.712878 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:11:52.712896 20451 solver.cpp:244]     Train net output #1: loss = 0.187446 (* 1 = 0.187446 loss)
I0809 02:11:52.712910 20451 sgd_solver.cpp:106] Iteration 19360, lr = 0.000445844
I0809 02:12:15.038344 20451 solver.cpp:228] Iteration 19370, loss = 0.218879
I0809 02:12:15.038390 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:12:15.038416 20451 solver.cpp:244]     Train net output #1: loss = 0.218879 (* 1 = 0.218879 loss)
I0809 02:12:15.038432 20451 sgd_solver.cpp:106] Iteration 19370, lr = 0.00044573
I0809 02:12:37.345916 20451 solver.cpp:228] Iteration 19380, loss = 0.312543
I0809 02:12:37.346094 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 02:12:37.346109 20451 solver.cpp:244]     Train net output #1: loss = 0.312543 (* 1 = 0.312543 loss)
I0809 02:12:37.346122 20451 sgd_solver.cpp:106] Iteration 19380, lr = 0.000445616
I0809 02:12:59.657778 20451 solver.cpp:228] Iteration 19390, loss = 0.187634
I0809 02:12:59.657830 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:12:59.657845 20451 solver.cpp:244]     Train net output #1: loss = 0.187634 (* 1 = 0.187634 loss)
I0809 02:12:59.657857 20451 sgd_solver.cpp:106] Iteration 19390, lr = 0.000445503
I0809 02:13:19.741593 20451 solver.cpp:337] Iteration 19400, Testing net (#0)
I0809 02:13:28.266039 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 02:13:28.266085 20451 solver.cpp:404]     Test net output #1: loss = 0.984583 (* 1 = 0.984583 loss)
I0809 02:13:30.472591 20451 solver.cpp:228] Iteration 19400, loss = 0.218818
I0809 02:13:30.472640 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:13:30.472656 20451 solver.cpp:244]     Train net output #1: loss = 0.218818 (* 1 = 0.218818 loss)
I0809 02:13:30.472668 20451 sgd_solver.cpp:106] Iteration 19400, lr = 0.000445389
I0809 02:13:52.768288 20451 solver.cpp:228] Iteration 19410, loss = 0.0937561
I0809 02:13:52.768385 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:13:52.768401 20451 solver.cpp:244]     Train net output #1: loss = 0.0937563 (* 1 = 0.0937563 loss)
I0809 02:13:52.768415 20451 sgd_solver.cpp:106] Iteration 19410, lr = 0.000445275
I0809 02:14:15.093284 20451 solver.cpp:228] Iteration 19420, loss = 0.218851
I0809 02:14:15.093332 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:14:15.093350 20451 solver.cpp:244]     Train net output #1: loss = 0.218851 (* 1 = 0.218851 loss)
I0809 02:14:15.093365 20451 sgd_solver.cpp:106] Iteration 19420, lr = 0.000445162
I0809 02:14:37.419380 20451 solver.cpp:228] Iteration 19430, loss = 0.125037
I0809 02:14:37.419590 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:14:37.419610 20451 solver.cpp:244]     Train net output #1: loss = 0.125037 (* 1 = 0.125037 loss)
I0809 02:14:37.419625 20451 sgd_solver.cpp:106] Iteration 19430, lr = 0.000445048
I0809 02:14:59.738862 20451 solver.cpp:228] Iteration 19440, loss = 0.156358
I0809 02:14:59.738921 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:14:59.738935 20451 solver.cpp:244]     Train net output #1: loss = 0.156358 (* 1 = 0.156358 loss)
I0809 02:14:59.738948 20451 sgd_solver.cpp:106] Iteration 19440, lr = 0.000444935
I0809 02:15:22.058413 20451 solver.cpp:228] Iteration 19450, loss = 0.187595
I0809 02:15:22.058609 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:15:22.058627 20451 solver.cpp:244]     Train net output #1: loss = 0.187595 (* 1 = 0.187595 loss)
I0809 02:15:22.058641 20451 sgd_solver.cpp:106] Iteration 19450, lr = 0.000444822
I0809 02:15:44.377291 20451 solver.cpp:228] Iteration 19460, loss = 0.156341
I0809 02:15:44.377343 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:15:44.377357 20451 solver.cpp:244]     Train net output #1: loss = 0.156341 (* 1 = 0.156341 loss)
I0809 02:15:44.377369 20451 sgd_solver.cpp:106] Iteration 19460, lr = 0.000444709
I0809 02:16:06.695631 20451 solver.cpp:228] Iteration 19470, loss = 0.187519
I0809 02:16:06.695814 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:16:06.695830 20451 solver.cpp:244]     Train net output #1: loss = 0.187519 (* 1 = 0.187519 loss)
I0809 02:16:06.695843 20451 sgd_solver.cpp:106] Iteration 19470, lr = 0.000444595
I0809 02:16:29.004051 20451 solver.cpp:228] Iteration 19480, loss = 0.125067
I0809 02:16:29.004094 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:16:29.004113 20451 solver.cpp:244]     Train net output #1: loss = 0.125067 (* 1 = 0.125067 loss)
I0809 02:16:29.004128 20451 sgd_solver.cpp:106] Iteration 19480, lr = 0.000444482
I0809 02:16:51.311002 20451 solver.cpp:228] Iteration 19490, loss = 0.125017
I0809 02:16:51.311110 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:16:51.311126 20451 solver.cpp:244]     Train net output #1: loss = 0.125017 (* 1 = 0.125017 loss)
I0809 02:16:51.311138 20451 sgd_solver.cpp:106] Iteration 19490, lr = 0.000444369
I0809 02:17:11.386015 20451 solver.cpp:337] Iteration 19500, Testing net (#0)
I0809 02:17:19.908777 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 02:17:19.908830 20451 solver.cpp:404]     Test net output #1: loss = 1.00329 (* 1 = 1.00329 loss)
I0809 02:17:22.113270 20451 solver.cpp:228] Iteration 19500, loss = 0.12503
I0809 02:17:22.113361 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:17:22.113379 20451 solver.cpp:244]     Train net output #1: loss = 0.125031 (* 1 = 0.125031 loss)
I0809 02:17:22.113390 20451 sgd_solver.cpp:106] Iteration 19500, lr = 0.000444256
I0809 02:17:44.415343 20451 solver.cpp:228] Iteration 19510, loss = 0.218818
I0809 02:17:44.415395 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:17:44.415408 20451 solver.cpp:244]     Train net output #1: loss = 0.218818 (* 1 = 0.218818 loss)
I0809 02:17:44.415421 20451 sgd_solver.cpp:106] Iteration 19510, lr = 0.000444143
I0809 02:18:06.728768 20451 solver.cpp:228] Iteration 19520, loss = 0.187576
I0809 02:18:06.728945 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:18:06.728960 20451 solver.cpp:244]     Train net output #1: loss = 0.187576 (* 1 = 0.187576 loss)
I0809 02:18:06.728972 20451 sgd_solver.cpp:106] Iteration 19520, lr = 0.00044403
I0809 02:18:29.041525 20451 solver.cpp:228] Iteration 19530, loss = 0.125054
I0809 02:18:29.041569 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:18:29.041587 20451 solver.cpp:244]     Train net output #1: loss = 0.125054 (* 1 = 0.125054 loss)
I0809 02:18:29.041600 20451 sgd_solver.cpp:106] Iteration 19530, lr = 0.000443918
I0809 02:18:51.345157 20451 solver.cpp:228] Iteration 19540, loss = 0.187569
I0809 02:18:51.345382 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:18:51.345398 20451 solver.cpp:244]     Train net output #1: loss = 0.187569 (* 1 = 0.187569 loss)
I0809 02:18:51.345413 20451 sgd_solver.cpp:106] Iteration 19540, lr = 0.000443805
I0809 02:19:13.644598 20451 solver.cpp:228] Iteration 19550, loss = 0.156293
I0809 02:19:13.644639 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:19:13.644654 20451 solver.cpp:244]     Train net output #1: loss = 0.156293 (* 1 = 0.156293 loss)
I0809 02:19:13.644665 20451 sgd_solver.cpp:106] Iteration 19550, lr = 0.000443692
I0809 02:19:35.950142 20451 solver.cpp:228] Iteration 19560, loss = 0.0937886
I0809 02:19:35.950255 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:19:35.950271 20451 solver.cpp:244]     Train net output #1: loss = 0.0937888 (* 1 = 0.0937888 loss)
I0809 02:19:35.950284 20451 sgd_solver.cpp:106] Iteration 19560, lr = 0.00044358
I0809 02:19:58.258491 20451 solver.cpp:228] Iteration 19570, loss = 0.156439
I0809 02:19:58.258608 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:19:58.258648 20451 solver.cpp:244]     Train net output #1: loss = 0.156439 (* 1 = 0.156439 loss)
I0809 02:19:58.258682 20451 sgd_solver.cpp:106] Iteration 19570, lr = 0.000443467
I0809 02:20:20.577939 20451 solver.cpp:228] Iteration 19580, loss = 0.281407
I0809 02:20:20.578119 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 02:20:20.578133 20451 solver.cpp:244]     Train net output #1: loss = 0.281408 (* 1 = 0.281408 loss)
I0809 02:20:20.578145 20451 sgd_solver.cpp:106] Iteration 19580, lr = 0.000443355
I0809 02:20:42.896849 20451 solver.cpp:228] Iteration 19590, loss = 0.156277
I0809 02:20:42.896901 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:20:42.896915 20451 solver.cpp:244]     Train net output #1: loss = 0.156278 (* 1 = 0.156278 loss)
I0809 02:20:42.896927 20451 sgd_solver.cpp:106] Iteration 19590, lr = 0.000443242
I0809 02:21:02.993705 20451 solver.cpp:337] Iteration 19600, Testing net (#0)
I0809 02:21:11.517416 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 02:21:11.517467 20451 solver.cpp:404]     Test net output #1: loss = 0.975209 (* 1 = 0.975209 loss)
I0809 02:21:13.722200 20451 solver.cpp:228] Iteration 19600, loss = 0.187559
I0809 02:21:13.722251 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:21:13.722271 20451 solver.cpp:244]     Train net output #1: loss = 0.18756 (* 1 = 0.18756 loss)
I0809 02:21:13.722287 20451 sgd_solver.cpp:106] Iteration 19600, lr = 0.00044313
I0809 02:21:36.004314 20451 solver.cpp:228] Iteration 19610, loss = 0.187626
I0809 02:21:36.004421 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:21:36.004436 20451 solver.cpp:244]     Train net output #1: loss = 0.187626 (* 1 = 0.187626 loss)
I0809 02:21:36.004449 20451 sgd_solver.cpp:106] Iteration 19610, lr = 0.000443018
I0809 02:21:58.306746 20451 solver.cpp:228] Iteration 19620, loss = 0.250043
I0809 02:21:58.306800 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:21:58.306818 20451 solver.cpp:244]     Train net output #1: loss = 0.250043 (* 1 = 0.250043 loss)
I0809 02:21:58.306833 20451 sgd_solver.cpp:106] Iteration 19620, lr = 0.000442906
I0809 02:22:20.611443 20451 solver.cpp:228] Iteration 19630, loss = 0.250158
I0809 02:22:20.611623 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:22:20.611637 20451 solver.cpp:244]     Train net output #1: loss = 0.250159 (* 1 = 0.250159 loss)
I0809 02:22:20.611650 20451 sgd_solver.cpp:106] Iteration 19630, lr = 0.000442794
I0809 02:22:42.928671 20451 solver.cpp:228] Iteration 19640, loss = 0.125001
I0809 02:22:42.928725 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:22:42.928737 20451 solver.cpp:244]     Train net output #1: loss = 0.125001 (* 1 = 0.125001 loss)
I0809 02:22:42.928750 20451 sgd_solver.cpp:106] Iteration 19640, lr = 0.000442682
I0809 02:23:05.247545 20451 solver.cpp:228] Iteration 19650, loss = 0.125022
I0809 02:23:05.247678 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:23:05.247694 20451 solver.cpp:244]     Train net output #1: loss = 0.125022 (* 1 = 0.125022 loss)
I0809 02:23:05.247707 20451 sgd_solver.cpp:106] Iteration 19650, lr = 0.00044257
I0809 02:23:27.563434 20451 solver.cpp:228] Iteration 19660, loss = 0.187528
I0809 02:23:27.563485 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:23:27.563499 20451 solver.cpp:244]     Train net output #1: loss = 0.187528 (* 1 = 0.187528 loss)
I0809 02:23:27.563511 20451 sgd_solver.cpp:106] Iteration 19660, lr = 0.000442458
I0809 02:23:49.875277 20451 solver.cpp:228] Iteration 19670, loss = 0.125031
I0809 02:23:49.875457 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:23:49.875471 20451 solver.cpp:244]     Train net output #1: loss = 0.125031 (* 1 = 0.125031 loss)
I0809 02:23:49.875484 20451 sgd_solver.cpp:106] Iteration 19670, lr = 0.000442346
I0809 02:24:12.191385 20451 solver.cpp:228] Iteration 19680, loss = 0.187543
I0809 02:24:12.191438 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:24:12.191452 20451 solver.cpp:244]     Train net output #1: loss = 0.187543 (* 1 = 0.187543 loss)
I0809 02:24:12.191465 20451 sgd_solver.cpp:106] Iteration 19680, lr = 0.000442234
I0809 02:24:34.507756 20451 solver.cpp:228] Iteration 19690, loss = 0.218828
I0809 02:24:34.507939 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:24:34.507954 20451 solver.cpp:244]     Train net output #1: loss = 0.218828 (* 1 = 0.218828 loss)
I0809 02:24:34.507966 20451 sgd_solver.cpp:106] Iteration 19690, lr = 0.000442122
I0809 02:24:54.586458 20451 solver.cpp:337] Iteration 19700, Testing net (#0)
I0809 02:25:03.116015 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0809 02:25:03.116078 20451 solver.cpp:404]     Test net output #1: loss = 1.01741 (* 1 = 1.01741 loss)
I0809 02:25:05.321032 20451 solver.cpp:228] Iteration 19700, loss = 0.18756
I0809 02:25:05.321208 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:25:05.321223 20451 solver.cpp:244]     Train net output #1: loss = 0.18756 (* 1 = 0.18756 loss)
I0809 02:25:05.321236 20451 sgd_solver.cpp:106] Iteration 19700, lr = 0.000442011
I0809 02:25:27.611752 20451 solver.cpp:228] Iteration 19710, loss = 0.125051
I0809 02:25:27.611802 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:25:27.611816 20451 solver.cpp:244]     Train net output #1: loss = 0.125051 (* 1 = 0.125051 loss)
I0809 02:25:27.611829 20451 sgd_solver.cpp:106] Iteration 19710, lr = 0.000441899
I0809 02:25:49.921758 20451 solver.cpp:228] Iteration 19720, loss = 0.281327
I0809 02:25:49.921874 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 02:25:49.921890 20451 solver.cpp:244]     Train net output #1: loss = 0.281327 (* 1 = 0.281327 loss)
I0809 02:25:49.921905 20451 sgd_solver.cpp:106] Iteration 19720, lr = 0.000441787
I0809 02:26:12.232771 20451 solver.cpp:228] Iteration 19730, loss = 0.0938046
I0809 02:26:12.232822 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:26:12.232836 20451 solver.cpp:244]     Train net output #1: loss = 0.0938048 (* 1 = 0.0938048 loss)
I0809 02:26:12.232849 20451 sgd_solver.cpp:106] Iteration 19730, lr = 0.000441676
I0809 02:26:34.532636 20451 solver.cpp:228] Iteration 19740, loss = 0.21888
I0809 02:26:34.532812 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:26:34.532827 20451 solver.cpp:244]     Train net output #1: loss = 0.21888 (* 1 = 0.21888 loss)
I0809 02:26:34.532840 20451 sgd_solver.cpp:106] Iteration 19740, lr = 0.000441565
I0809 02:26:56.847898 20451 solver.cpp:228] Iteration 19750, loss = 0.187586
I0809 02:26:56.847949 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:26:56.847962 20451 solver.cpp:244]     Train net output #1: loss = 0.187586 (* 1 = 0.187586 loss)
I0809 02:26:56.847975 20451 sgd_solver.cpp:106] Iteration 19750, lr = 0.000441453
I0809 02:27:19.155287 20451 solver.cpp:228] Iteration 19760, loss = 0.1877
I0809 02:27:19.155501 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:27:19.155517 20451 solver.cpp:244]     Train net output #1: loss = 0.1877 (* 1 = 0.1877 loss)
I0809 02:27:19.155529 20451 sgd_solver.cpp:106] Iteration 19760, lr = 0.000441342
I0809 02:27:41.464944 20451 solver.cpp:228] Iteration 19770, loss = 0.0938791
I0809 02:27:41.464994 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:27:41.465008 20451 solver.cpp:244]     Train net output #1: loss = 0.0938792 (* 1 = 0.0938792 loss)
I0809 02:27:41.465021 20451 sgd_solver.cpp:106] Iteration 19770, lr = 0.000441231
I0809 02:28:03.781988 20451 solver.cpp:228] Iteration 19780, loss = 0.125104
I0809 02:28:03.782227 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:28:03.782241 20451 solver.cpp:244]     Train net output #1: loss = 0.125105 (* 1 = 0.125105 loss)
I0809 02:28:03.782253 20451 sgd_solver.cpp:106] Iteration 19780, lr = 0.00044112
I0809 02:28:26.091027 20451 solver.cpp:228] Iteration 19790, loss = 0.0938823
I0809 02:28:26.091079 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:28:26.091094 20451 solver.cpp:244]     Train net output #1: loss = 0.0938825 (* 1 = 0.0938825 loss)
I0809 02:28:26.091105 20451 sgd_solver.cpp:106] Iteration 19790, lr = 0.000441009
I0809 02:28:46.168709 20451 solver.cpp:337] Iteration 19800, Testing net (#0)
I0809 02:28:54.697222 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 02:28:54.697273 20451 solver.cpp:404]     Test net output #1: loss = 1.00323 (* 1 = 1.00323 loss)
I0809 02:28:56.903120 20451 solver.cpp:228] Iteration 19800, loss = 0.156273
I0809 02:28:56.903165 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:28:56.903183 20451 solver.cpp:244]     Train net output #1: loss = 0.156273 (* 1 = 0.156273 loss)
I0809 02:28:56.903199 20451 sgd_solver.cpp:106] Iteration 19800, lr = 0.000440898
I0809 02:29:19.186738 20451 solver.cpp:228] Iteration 19810, loss = 0.093845
I0809 02:29:19.186915 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:29:19.186931 20451 solver.cpp:244]     Train net output #1: loss = 0.0938452 (* 1 = 0.0938452 loss)
I0809 02:29:19.186945 20451 sgd_solver.cpp:106] Iteration 19810, lr = 0.000440787
I0809 02:29:41.487426 20451 solver.cpp:228] Iteration 19820, loss = 0.250041
I0809 02:29:41.487478 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:29:41.487490 20451 solver.cpp:244]     Train net output #1: loss = 0.250041 (* 1 = 0.250041 loss)
I0809 02:29:41.487503 20451 sgd_solver.cpp:106] Iteration 19820, lr = 0.000440676
I0809 02:30:03.803295 20451 solver.cpp:228] Iteration 19830, loss = 0.187694
I0809 02:30:03.803465 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:30:03.803480 20451 solver.cpp:244]     Train net output #1: loss = 0.187695 (* 1 = 0.187695 loss)
I0809 02:30:03.803493 20451 sgd_solver.cpp:106] Iteration 19830, lr = 0.000440565
I0809 02:30:26.112576 20451 solver.cpp:228] Iteration 19840, loss = 0.156254
I0809 02:30:26.112628 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:30:26.112643 20451 solver.cpp:244]     Train net output #1: loss = 0.156254 (* 1 = 0.156254 loss)
I0809 02:30:26.112655 20451 sgd_solver.cpp:106] Iteration 19840, lr = 0.000440454
I0809 02:30:48.431036 20451 solver.cpp:228] Iteration 19850, loss = 0.187537
I0809 02:30:48.431213 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:30:48.431228 20451 solver.cpp:244]     Train net output #1: loss = 0.187537 (* 1 = 0.187537 loss)
I0809 02:30:48.431241 20451 sgd_solver.cpp:106] Iteration 19850, lr = 0.000440344
I0809 02:31:10.734940 20451 solver.cpp:228] Iteration 19860, loss = 0.156273
I0809 02:31:10.734988 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:31:10.735008 20451 solver.cpp:244]     Train net output #1: loss = 0.156273 (* 1 = 0.156273 loss)
I0809 02:31:10.735025 20451 sgd_solver.cpp:106] Iteration 19860, lr = 0.000440233
I0809 02:31:33.039575 20451 solver.cpp:228] Iteration 19870, loss = 0.218884
I0809 02:31:33.039774 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:31:33.039789 20451 solver.cpp:244]     Train net output #1: loss = 0.218884 (* 1 = 0.218884 loss)
I0809 02:31:33.039803 20451 sgd_solver.cpp:106] Iteration 19870, lr = 0.000440123
I0809 02:31:55.347242 20451 solver.cpp:228] Iteration 19880, loss = 0.219015
I0809 02:31:55.347296 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:31:55.347309 20451 solver.cpp:244]     Train net output #1: loss = 0.219015 (* 1 = 0.219015 loss)
I0809 02:31:55.347321 20451 sgd_solver.cpp:106] Iteration 19880, lr = 0.000440012
I0809 02:32:17.656925 20451 solver.cpp:228] Iteration 19890, loss = 0.187849
I0809 02:32:17.657119 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:32:17.657191 20451 solver.cpp:244]     Train net output #1: loss = 0.187849 (* 1 = 0.187849 loss)
I0809 02:32:17.657227 20451 sgd_solver.cpp:106] Iteration 19890, lr = 0.000439902
I0809 02:32:37.746304 20451 solver.cpp:337] Iteration 19900, Testing net (#0)
I0809 02:32:46.269129 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 02:32:46.269178 20451 solver.cpp:404]     Test net output #1: loss = 0.975215 (* 1 = 0.975215 loss)
I0809 02:32:48.474699 20451 solver.cpp:228] Iteration 19900, loss = 0.125041
I0809 02:32:48.474865 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:32:48.474879 20451 solver.cpp:244]     Train net output #1: loss = 0.125041 (* 1 = 0.125041 loss)
I0809 02:32:48.474892 20451 sgd_solver.cpp:106] Iteration 19900, lr = 0.000439791
I0809 02:33:10.763559 20451 solver.cpp:228] Iteration 19910, loss = 0.0938907
I0809 02:33:10.763624 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:33:10.763640 20451 solver.cpp:244]     Train net output #1: loss = 0.0938908 (* 1 = 0.0938908 loss)
I0809 02:33:10.763653 20451 sgd_solver.cpp:106] Iteration 19910, lr = 0.000439681
I0809 02:33:33.087256 20451 solver.cpp:228] Iteration 19920, loss = 0.125056
I0809 02:33:33.087441 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:33:33.087456 20451 solver.cpp:244]     Train net output #1: loss = 0.125056 (* 1 = 0.125056 loss)
I0809 02:33:33.087468 20451 sgd_solver.cpp:106] Iteration 19920, lr = 0.000439571
I0809 02:33:55.407632 20451 solver.cpp:228] Iteration 19930, loss = 0.156556
I0809 02:33:55.407683 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:33:55.407697 20451 solver.cpp:244]     Train net output #1: loss = 0.156557 (* 1 = 0.156557 loss)
I0809 02:33:55.407709 20451 sgd_solver.cpp:106] Iteration 19930, lr = 0.000439461
I0809 02:34:17.720772 20451 solver.cpp:228] Iteration 19940, loss = 0.281693
I0809 02:34:17.720952 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 02:34:17.720966 20451 solver.cpp:244]     Train net output #1: loss = 0.281693 (* 1 = 0.281693 loss)
I0809 02:34:17.720978 20451 sgd_solver.cpp:106] Iteration 19940, lr = 0.000439351
I0809 02:34:40.047648 20451 solver.cpp:228] Iteration 19950, loss = 0.156373
I0809 02:34:40.047700 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:34:40.047719 20451 solver.cpp:244]     Train net output #1: loss = 0.156373 (* 1 = 0.156373 loss)
I0809 02:34:40.047732 20451 sgd_solver.cpp:106] Iteration 19950, lr = 0.000439241
I0809 02:35:02.369639 20451 solver.cpp:228] Iteration 19960, loss = 0.156502
I0809 02:35:02.369815 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:35:02.369833 20451 solver.cpp:244]     Train net output #1: loss = 0.156502 (* 1 = 0.156502 loss)
I0809 02:35:02.369849 20451 sgd_solver.cpp:106] Iteration 19960, lr = 0.000439131
I0809 02:35:24.681746 20451 solver.cpp:228] Iteration 19970, loss = 0.125256
I0809 02:35:24.681798 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:35:24.681813 20451 solver.cpp:244]     Train net output #1: loss = 0.125256 (* 1 = 0.125256 loss)
I0809 02:35:24.681824 20451 sgd_solver.cpp:106] Iteration 19970, lr = 0.000439021
I0809 02:35:46.992144 20451 solver.cpp:228] Iteration 19980, loss = 0.15646
I0809 02:35:46.992274 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:35:46.992290 20451 solver.cpp:244]     Train net output #1: loss = 0.15646 (* 1 = 0.15646 loss)
I0809 02:35:46.992303 20451 sgd_solver.cpp:106] Iteration 19980, lr = 0.000438911
I0809 02:36:09.300734 20451 solver.cpp:228] Iteration 19990, loss = 0.218789
I0809 02:36:09.300791 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:36:09.300811 20451 solver.cpp:244]     Train net output #1: loss = 0.218789 (* 1 = 0.218789 loss)
I0809 02:36:09.300827 20451 sgd_solver.cpp:106] Iteration 19990, lr = 0.000438801
I0809 02:36:29.394757 20451 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_20000.caffemodel
I0809 02:36:29.588686 20451 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_20000.solverstate
I0809 02:36:29.591296 20451 solver.cpp:337] Iteration 20000, Testing net (#0)
I0809 02:36:38.101131 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 02:36:38.101176 20451 solver.cpp:404]     Test net output #1: loss = 0.994035 (* 1 = 0.994035 loss)
I0809 02:36:40.302952 20451 solver.cpp:228] Iteration 20000, loss = 0.09379
I0809 02:36:40.302995 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:36:40.303014 20451 solver.cpp:244]     Train net output #1: loss = 0.0937901 (* 1 = 0.0937901 loss)
I0809 02:36:40.303038 20451 sgd_solver.cpp:106] Iteration 20000, lr = 0.000438691
I0809 02:37:02.617422 20451 solver.cpp:228] Iteration 20010, loss = 0.250109
I0809 02:37:02.617595 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:37:02.617611 20451 solver.cpp:244]     Train net output #1: loss = 0.250109 (* 1 = 0.250109 loss)
I0809 02:37:02.617624 20451 sgd_solver.cpp:106] Iteration 20010, lr = 0.000438582
I0809 02:37:24.935681 20451 solver.cpp:228] Iteration 20020, loss = 0.250152
I0809 02:37:24.935729 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:37:24.935748 20451 solver.cpp:244]     Train net output #1: loss = 0.250152 (* 1 = 0.250152 loss)
I0809 02:37:24.935762 20451 sgd_solver.cpp:106] Iteration 20020, lr = 0.000438472
I0809 02:37:47.256866 20451 solver.cpp:228] Iteration 20030, loss = 0.0937887
I0809 02:37:47.256975 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:37:47.256990 20451 solver.cpp:244]     Train net output #1: loss = 0.0937888 (* 1 = 0.0937888 loss)
I0809 02:37:47.257004 20451 sgd_solver.cpp:106] Iteration 20030, lr = 0.000438363
I0809 02:38:09.576665 20451 solver.cpp:228] Iteration 20040, loss = 0.12504
I0809 02:38:09.576709 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:38:09.576722 20451 solver.cpp:244]     Train net output #1: loss = 0.125041 (* 1 = 0.125041 loss)
I0809 02:38:09.576735 20451 sgd_solver.cpp:106] Iteration 20040, lr = 0.000438253
I0809 02:38:31.898900 20451 solver.cpp:228] Iteration 20050, loss = 0.0312617
I0809 02:38:31.899075 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 02:38:31.899091 20451 solver.cpp:244]     Train net output #1: loss = 0.0312619 (* 1 = 0.0312619 loss)
I0809 02:38:31.899103 20451 sgd_solver.cpp:106] Iteration 20050, lr = 0.000438144
I0809 02:38:54.223676 20451 solver.cpp:228] Iteration 20060, loss = 0.18759
I0809 02:38:54.223737 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:38:54.223752 20451 solver.cpp:244]     Train net output #1: loss = 0.18759 (* 1 = 0.18759 loss)
I0809 02:38:54.223763 20451 sgd_solver.cpp:106] Iteration 20060, lr = 0.000438034
I0809 02:39:16.539113 20451 solver.cpp:228] Iteration 20070, loss = 0.312562
I0809 02:39:16.539288 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 02:39:16.539304 20451 solver.cpp:244]     Train net output #1: loss = 0.312562 (* 1 = 0.312562 loss)
I0809 02:39:16.539316 20451 sgd_solver.cpp:106] Iteration 20070, lr = 0.000437925
I0809 02:39:38.861248 20451 solver.cpp:228] Iteration 20080, loss = 0.218818
I0809 02:39:38.861299 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:39:38.861315 20451 solver.cpp:244]     Train net output #1: loss = 0.218818 (* 1 = 0.218818 loss)
I0809 02:39:38.861326 20451 sgd_solver.cpp:106] Iteration 20080, lr = 0.000437816
I0809 02:40:01.178140 20451 solver.cpp:228] Iteration 20090, loss = 0.156317
I0809 02:40:01.178355 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:40:01.178371 20451 solver.cpp:244]     Train net output #1: loss = 0.156317 (* 1 = 0.156317 loss)
I0809 02:40:01.178383 20451 sgd_solver.cpp:106] Iteration 20090, lr = 0.000437707
I0809 02:40:21.277246 20451 solver.cpp:337] Iteration 20100, Testing net (#0)
I0809 02:40:29.809214 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 02:40:29.809265 20451 solver.cpp:404]     Test net output #1: loss = 1.00342 (* 1 = 1.00342 loss)
I0809 02:40:32.015404 20451 solver.cpp:228] Iteration 20100, loss = 0.25011
I0809 02:40:32.015558 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:40:32.015637 20451 solver.cpp:244]     Train net output #1: loss = 0.250111 (* 1 = 0.250111 loss)
I0809 02:40:32.015674 20451 sgd_solver.cpp:106] Iteration 20100, lr = 0.000437598
I0809 02:40:54.305868 20451 solver.cpp:228] Iteration 20110, loss = 0.18755
I0809 02:40:54.305922 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:40:54.305935 20451 solver.cpp:244]     Train net output #1: loss = 0.187551 (* 1 = 0.187551 loss)
I0809 02:40:54.305948 20451 sgd_solver.cpp:106] Iteration 20110, lr = 0.000437489
I0809 02:41:16.623517 20451 solver.cpp:228] Iteration 20120, loss = 0.25007
I0809 02:41:16.623703 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:41:16.623721 20451 solver.cpp:244]     Train net output #1: loss = 0.25007 (* 1 = 0.25007 loss)
I0809 02:41:16.623736 20451 sgd_solver.cpp:106] Iteration 20120, lr = 0.00043738
I0809 02:41:38.938308 20451 solver.cpp:228] Iteration 20130, loss = 0.156296
I0809 02:41:38.938360 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:41:38.938374 20451 solver.cpp:244]     Train net output #1: loss = 0.156296 (* 1 = 0.156296 loss)
I0809 02:41:38.938386 20451 sgd_solver.cpp:106] Iteration 20130, lr = 0.000437271
I0809 02:42:01.264312 20451 solver.cpp:228] Iteration 20140, loss = 0.0937792
I0809 02:42:01.264489 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:42:01.264505 20451 solver.cpp:244]     Train net output #1: loss = 0.0937793 (* 1 = 0.0937793 loss)
I0809 02:42:01.264518 20451 sgd_solver.cpp:106] Iteration 20140, lr = 0.000437162
I0809 02:42:23.591131 20451 solver.cpp:228] Iteration 20150, loss = 0.281343
I0809 02:42:23.591179 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 02:42:23.591193 20451 solver.cpp:244]     Train net output #1: loss = 0.281343 (* 1 = 0.281343 loss)
I0809 02:42:23.591205 20451 sgd_solver.cpp:106] Iteration 20150, lr = 0.000437053
I0809 02:42:45.910775 20451 solver.cpp:228] Iteration 20160, loss = 0.0625354
I0809 02:42:45.910953 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 02:42:45.910969 20451 solver.cpp:244]     Train net output #1: loss = 0.0625355 (* 1 = 0.0625355 loss)
I0809 02:42:45.910980 20451 sgd_solver.cpp:106] Iteration 20160, lr = 0.000436945
I0809 02:43:08.228513 20451 solver.cpp:228] Iteration 20170, loss = 0.218829
I0809 02:43:08.228564 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:43:08.228579 20451 solver.cpp:244]     Train net output #1: loss = 0.218829 (* 1 = 0.218829 loss)
I0809 02:43:08.228590 20451 sgd_solver.cpp:106] Iteration 20170, lr = 0.000436836
I0809 02:43:30.542814 20451 solver.cpp:228] Iteration 20180, loss = 0.156299
I0809 02:43:30.542973 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:43:30.542992 20451 solver.cpp:244]     Train net output #1: loss = 0.1563 (* 1 = 0.1563 loss)
I0809 02:43:30.543009 20451 sgd_solver.cpp:106] Iteration 20180, lr = 0.000436728
I0809 02:43:52.860658 20451 solver.cpp:228] Iteration 20190, loss = 0.0625318
I0809 02:43:52.860709 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 02:43:52.860729 20451 solver.cpp:244]     Train net output #1: loss = 0.0625319 (* 1 = 0.0625319 loss)
I0809 02:43:52.860745 20451 sgd_solver.cpp:106] Iteration 20190, lr = 0.000436619
I0809 02:44:12.954926 20451 solver.cpp:337] Iteration 20200, Testing net (#0)
I0809 02:44:21.480442 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0809 02:44:21.480492 20451 solver.cpp:404]     Test net output #1: loss = 0.965876 (* 1 = 0.965876 loss)
I0809 02:44:23.683169 20451 solver.cpp:228] Iteration 20200, loss = 0.250095
I0809 02:44:23.683219 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:44:23.683233 20451 solver.cpp:244]     Train net output #1: loss = 0.250095 (* 1 = 0.250095 loss)
I0809 02:44:23.683245 20451 sgd_solver.cpp:106] Iteration 20200, lr = 0.000436511
I0809 02:44:45.970490 20451 solver.cpp:228] Iteration 20210, loss = 0.156301
I0809 02:44:45.970664 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:44:45.970679 20451 solver.cpp:244]     Train net output #1: loss = 0.156301 (* 1 = 0.156301 loss)
I0809 02:44:45.970691 20451 sgd_solver.cpp:106] Iteration 20210, lr = 0.000436402
I0809 02:45:08.287258 20451 solver.cpp:228] Iteration 20220, loss = 0.156312
I0809 02:45:08.287317 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:45:08.287331 20451 solver.cpp:244]     Train net output #1: loss = 0.156312 (* 1 = 0.156312 loss)
I0809 02:45:08.287343 20451 sgd_solver.cpp:106] Iteration 20220, lr = 0.000436294
I0809 02:45:30.597185 20451 solver.cpp:228] Iteration 20230, loss = 0.0937969
I0809 02:45:30.597376 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:45:30.597396 20451 solver.cpp:244]     Train net output #1: loss = 0.093797 (* 1 = 0.093797 loss)
I0809 02:45:30.597412 20451 sgd_solver.cpp:106] Iteration 20230, lr = 0.000436186
I0809 02:45:52.908215 20451 solver.cpp:228] Iteration 20240, loss = 0.218893
I0809 02:45:52.908259 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:45:52.908275 20451 solver.cpp:244]     Train net output #1: loss = 0.218893 (* 1 = 0.218893 loss)
I0809 02:45:52.908288 20451 sgd_solver.cpp:106] Iteration 20240, lr = 0.000436078
I0809 02:46:15.233836 20451 solver.cpp:228] Iteration 20250, loss = 0.187525
I0809 02:46:15.234007 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:46:15.234022 20451 solver.cpp:244]     Train net output #1: loss = 0.187525 (* 1 = 0.187525 loss)
I0809 02:46:15.234035 20451 sgd_solver.cpp:106] Iteration 20250, lr = 0.000435969
I0809 02:46:37.551156 20451 solver.cpp:228] Iteration 20260, loss = 0.25016
I0809 02:46:37.551209 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:46:37.551223 20451 solver.cpp:244]     Train net output #1: loss = 0.25016 (* 1 = 0.25016 loss)
I0809 02:46:37.551235 20451 sgd_solver.cpp:106] Iteration 20260, lr = 0.000435861
I0809 02:46:59.862988 20451 solver.cpp:228] Iteration 20270, loss = 0.156283
I0809 02:46:59.863158 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:46:59.863173 20451 solver.cpp:244]     Train net output #1: loss = 0.156283 (* 1 = 0.156283 loss)
I0809 02:46:59.863185 20451 sgd_solver.cpp:106] Iteration 20270, lr = 0.000435753
I0809 02:47:22.177795 20451 solver.cpp:228] Iteration 20280, loss = 0.125043
I0809 02:47:22.177848 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:47:22.177863 20451 solver.cpp:244]     Train net output #1: loss = 0.125043 (* 1 = 0.125043 loss)
I0809 02:47:22.177875 20451 sgd_solver.cpp:106] Iteration 20280, lr = 0.000435645
I0809 02:47:44.488309 20451 solver.cpp:228] Iteration 20290, loss = 0.218837
I0809 02:47:44.488535 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:47:44.488551 20451 solver.cpp:244]     Train net output #1: loss = 0.218837 (* 1 = 0.218837 loss)
I0809 02:47:44.488564 20451 sgd_solver.cpp:106] Iteration 20290, lr = 0.000435538
I0809 02:48:04.586875 20451 solver.cpp:337] Iteration 20300, Testing net (#0)
I0809 02:48:13.108168 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0809 02:48:13.108220 20451 solver.cpp:404]     Test net output #1: loss = 1.0313 (* 1 = 1.0313 loss)
I0809 02:48:15.312666 20451 solver.cpp:228] Iteration 20300, loss = 0.218766
I0809 02:48:15.312840 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:48:15.312855 20451 solver.cpp:244]     Train net output #1: loss = 0.218766 (* 1 = 0.218766 loss)
I0809 02:48:15.312867 20451 sgd_solver.cpp:106] Iteration 20300, lr = 0.00043543
I0809 02:48:37.613054 20451 solver.cpp:228] Iteration 20310, loss = 0.312531
I0809 02:48:37.613106 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 02:48:37.613119 20451 solver.cpp:244]     Train net output #1: loss = 0.312531 (* 1 = 0.312531 loss)
I0809 02:48:37.613131 20451 sgd_solver.cpp:106] Iteration 20310, lr = 0.000435322
I0809 02:48:59.936751 20451 solver.cpp:228] Iteration 20320, loss = 0.250045
I0809 02:48:59.936933 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:48:59.936946 20451 solver.cpp:244]     Train net output #1: loss = 0.250045 (* 1 = 0.250045 loss)
I0809 02:48:59.936959 20451 sgd_solver.cpp:106] Iteration 20320, lr = 0.000435214
I0809 02:49:22.246675 20451 solver.cpp:228] Iteration 20330, loss = 0.187528
I0809 02:49:22.246727 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:49:22.246742 20451 solver.cpp:244]     Train net output #1: loss = 0.187528 (* 1 = 0.187528 loss)
I0809 02:49:22.246754 20451 sgd_solver.cpp:106] Iteration 20330, lr = 0.000435107
I0809 02:49:44.562206 20451 solver.cpp:228] Iteration 20340, loss = 0.250144
I0809 02:49:44.562393 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 02:49:44.562408 20451 solver.cpp:244]     Train net output #1: loss = 0.250144 (* 1 = 0.250144 loss)
I0809 02:49:44.562422 20451 sgd_solver.cpp:106] Iteration 20340, lr = 0.000434999
I0809 02:50:06.876657 20451 solver.cpp:228] Iteration 20350, loss = 0.281317
I0809 02:50:06.876709 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 02:50:06.876724 20451 solver.cpp:244]     Train net output #1: loss = 0.281317 (* 1 = 0.281317 loss)
I0809 02:50:06.876736 20451 sgd_solver.cpp:106] Iteration 20350, lr = 0.000434892
I0809 02:50:29.190951 20451 solver.cpp:228] Iteration 20360, loss = 0.312665
I0809 02:50:29.191134 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 02:50:29.191149 20451 solver.cpp:244]     Train net output #1: loss = 0.312665 (* 1 = 0.312665 loss)
I0809 02:50:29.191161 20451 sgd_solver.cpp:106] Iteration 20360, lr = 0.000434784
I0809 02:50:51.514755 20451 solver.cpp:228] Iteration 20370, loss = 0.312528
I0809 02:50:51.514807 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 02:50:51.514822 20451 solver.cpp:244]     Train net output #1: loss = 0.312528 (* 1 = 0.312528 loss)
I0809 02:50:51.514834 20451 sgd_solver.cpp:106] Iteration 20370, lr = 0.000434677
I0809 02:51:13.831531 20451 solver.cpp:228] Iteration 20380, loss = 0.031262
I0809 02:51:13.831636 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 02:51:13.831658 20451 solver.cpp:244]     Train net output #1: loss = 0.0312621 (* 1 = 0.0312621 loss)
I0809 02:51:13.831675 20451 sgd_solver.cpp:106] Iteration 20380, lr = 0.000434569
I0809 02:51:36.154409 20451 solver.cpp:228] Iteration 20390, loss = 0.250034
I0809 02:51:36.154451 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:51:36.154469 20451 solver.cpp:244]     Train net output #1: loss = 0.250034 (* 1 = 0.250034 loss)
I0809 02:51:36.154484 20451 sgd_solver.cpp:106] Iteration 20390, lr = 0.000434462
I0809 02:51:56.254225 20451 solver.cpp:337] Iteration 20400, Testing net (#0)
I0809 02:52:04.783200 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 02:52:04.783251 20451 solver.cpp:404]     Test net output #1: loss = 1.00345 (* 1 = 1.00345 loss)
I0809 02:52:06.985759 20451 solver.cpp:228] Iteration 20400, loss = 0.281383
I0809 02:52:06.985805 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 02:52:06.985824 20451 solver.cpp:244]     Train net output #1: loss = 0.281383 (* 1 = 0.281383 loss)
I0809 02:52:06.985838 20451 sgd_solver.cpp:106] Iteration 20400, lr = 0.000434355
I0809 02:52:29.278033 20451 solver.cpp:228] Iteration 20410, loss = 0.218796
I0809 02:52:29.278208 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:52:29.278224 20451 solver.cpp:244]     Train net output #1: loss = 0.218796 (* 1 = 0.218796 loss)
I0809 02:52:29.278237 20451 sgd_solver.cpp:106] Iteration 20410, lr = 0.000434248
I0809 02:52:51.593626 20451 solver.cpp:228] Iteration 20420, loss = 0.312744
I0809 02:52:51.593678 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 02:52:51.593693 20451 solver.cpp:244]     Train net output #1: loss = 0.312744 (* 1 = 0.312744 loss)
I0809 02:52:51.593704 20451 sgd_solver.cpp:106] Iteration 20420, lr = 0.000434141
I0809 02:53:13.925844 20451 solver.cpp:228] Iteration 20430, loss = 0.125102
I0809 02:53:13.926023 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:53:13.926041 20451 solver.cpp:244]     Train net output #1: loss = 0.125102 (* 1 = 0.125102 loss)
I0809 02:53:13.926056 20451 sgd_solver.cpp:106] Iteration 20430, lr = 0.000434034
I0809 02:53:36.252849 20451 solver.cpp:228] Iteration 20440, loss = 0.0938974
I0809 02:53:36.252893 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:53:36.252918 20451 solver.cpp:244]     Train net output #1: loss = 0.0938976 (* 1 = 0.0938976 loss)
I0809 02:53:36.252934 20451 sgd_solver.cpp:106] Iteration 20440, lr = 0.000433927
I0809 02:53:58.578439 20451 solver.cpp:228] Iteration 20450, loss = 0.12502
I0809 02:53:58.578615 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:53:58.578631 20451 solver.cpp:244]     Train net output #1: loss = 0.125021 (* 1 = 0.125021 loss)
I0809 02:53:58.578644 20451 sgd_solver.cpp:106] Iteration 20450, lr = 0.00043382
I0809 02:54:20.904788 20451 solver.cpp:228] Iteration 20460, loss = 0.218875
I0809 02:54:20.904839 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:54:20.904852 20451 solver.cpp:244]     Train net output #1: loss = 0.218875 (* 1 = 0.218875 loss)
I0809 02:54:20.904865 20451 sgd_solver.cpp:106] Iteration 20460, lr = 0.000433713
I0809 02:54:43.228410 20451 solver.cpp:228] Iteration 20470, loss = 0.218789
I0809 02:54:43.228587 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:54:43.228603 20451 solver.cpp:244]     Train net output #1: loss = 0.218789 (* 1 = 0.218789 loss)
I0809 02:54:43.228616 20451 sgd_solver.cpp:106] Iteration 20470, lr = 0.000433606
I0809 02:55:05.545475 20451 solver.cpp:228] Iteration 20480, loss = 0.187619
I0809 02:55:05.545529 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:55:05.545543 20451 solver.cpp:244]     Train net output #1: loss = 0.187619 (* 1 = 0.187619 loss)
I0809 02:55:05.545557 20451 sgd_solver.cpp:106] Iteration 20480, lr = 0.0004335
I0809 02:55:27.863582 20451 solver.cpp:228] Iteration 20490, loss = 0.187548
I0809 02:55:27.863823 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:55:27.863842 20451 solver.cpp:244]     Train net output #1: loss = 0.187548 (* 1 = 0.187548 loss)
I0809 02:55:27.863857 20451 sgd_solver.cpp:106] Iteration 20490, lr = 0.000433393
I0809 02:55:47.963204 20451 solver.cpp:337] Iteration 20500, Testing net (#0)
I0809 02:55:56.489420 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 02:55:56.489466 20451 solver.cpp:404]     Test net output #1: loss = 0.984646 (* 1 = 0.984646 loss)
I0809 02:55:58.694059 20451 solver.cpp:228] Iteration 20500, loss = 0.187576
I0809 02:55:58.694186 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:55:58.694208 20451 solver.cpp:244]     Train net output #1: loss = 0.187576 (* 1 = 0.187576 loss)
I0809 02:55:58.694222 20451 sgd_solver.cpp:106] Iteration 20500, lr = 0.000433286
I0809 02:56:21.005497 20451 solver.cpp:228] Iteration 20510, loss = 0.218839
I0809 02:56:21.005542 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:56:21.005560 20451 solver.cpp:244]     Train net output #1: loss = 0.218839 (* 1 = 0.218839 loss)
I0809 02:56:21.005574 20451 sgd_solver.cpp:106] Iteration 20510, lr = 0.00043318
I0809 02:56:43.318413 20451 solver.cpp:228] Iteration 20520, loss = 0.156373
I0809 02:56:43.318593 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 02:56:43.318611 20451 solver.cpp:244]     Train net output #1: loss = 0.156373 (* 1 = 0.156373 loss)
I0809 02:56:43.318626 20451 sgd_solver.cpp:106] Iteration 20520, lr = 0.000433073
I0809 02:57:05.634747 20451 solver.cpp:228] Iteration 20530, loss = 0.093817
I0809 02:57:05.634799 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 02:57:05.634819 20451 solver.cpp:244]     Train net output #1: loss = 0.0938171 (* 1 = 0.0938171 loss)
I0809 02:57:05.634834 20451 sgd_solver.cpp:106] Iteration 20530, lr = 0.000432967
I0809 02:57:27.947477 20451 solver.cpp:228] Iteration 20540, loss = 0.219018
I0809 02:57:27.947659 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:57:27.947679 20451 solver.cpp:244]     Train net output #1: loss = 0.219018 (* 1 = 0.219018 loss)
I0809 02:57:27.947695 20451 sgd_solver.cpp:106] Iteration 20540, lr = 0.000432861
I0809 02:57:50.275123 20451 solver.cpp:228] Iteration 20550, loss = 0.12516
I0809 02:57:50.275177 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:57:50.275190 20451 solver.cpp:244]     Train net output #1: loss = 0.12516 (* 1 = 0.12516 loss)
I0809 02:57:50.275202 20451 sgd_solver.cpp:106] Iteration 20550, lr = 0.000432755
I0809 02:58:12.597548 20451 solver.cpp:228] Iteration 20560, loss = 0.219153
I0809 02:58:12.597708 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 02:58:12.597723 20451 solver.cpp:244]     Train net output #1: loss = 0.219153 (* 1 = 0.219153 loss)
I0809 02:58:12.597735 20451 sgd_solver.cpp:106] Iteration 20560, lr = 0.000432648
I0809 02:58:34.907536 20451 solver.cpp:228] Iteration 20570, loss = 0.125011
I0809 02:58:34.907588 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 02:58:34.907601 20451 solver.cpp:244]     Train net output #1: loss = 0.125011 (* 1 = 0.125011 loss)
I0809 02:58:34.907613 20451 sgd_solver.cpp:106] Iteration 20570, lr = 0.000432542
I0809 02:58:57.226022 20451 solver.cpp:228] Iteration 20580, loss = 0.187666
I0809 02:58:57.226200 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 02:58:57.226217 20451 solver.cpp:244]     Train net output #1: loss = 0.187666 (* 1 = 0.187666 loss)
I0809 02:58:57.226228 20451 sgd_solver.cpp:106] Iteration 20580, lr = 0.000432436
I0809 02:59:19.547839 20451 solver.cpp:228] Iteration 20590, loss = 0.312575
I0809 02:59:19.547893 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 02:59:19.547906 20451 solver.cpp:244]     Train net output #1: loss = 0.312575 (* 1 = 0.312575 loss)
I0809 02:59:19.547919 20451 sgd_solver.cpp:106] Iteration 20590, lr = 0.00043233
I0809 02:59:39.637706 20451 solver.cpp:337] Iteration 20600, Testing net (#0)
I0809 02:59:48.156466 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 02:59:48.156517 20451 solver.cpp:404]     Test net output #1: loss = 0.998798 (* 1 = 0.998798 loss)
I0809 02:59:50.359062 20451 solver.cpp:228] Iteration 20600, loss = 0.250135
I0809 02:59:50.359123 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 02:59:50.359138 20451 solver.cpp:244]     Train net output #1: loss = 0.250135 (* 1 = 0.250135 loss)
I0809 02:59:50.359149 20451 sgd_solver.cpp:106] Iteration 20600, lr = 0.000432224
I0809 03:00:12.639073 20451 solver.cpp:228] Iteration 20610, loss = 0.1876
I0809 03:00:12.639269 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:00:12.639288 20451 solver.cpp:244]     Train net output #1: loss = 0.1876 (* 1 = 0.1876 loss)
I0809 03:00:12.639302 20451 sgd_solver.cpp:106] Iteration 20610, lr = 0.000432118
I0809 03:00:34.953104 20451 solver.cpp:228] Iteration 20620, loss = 0.281312
I0809 03:00:34.953157 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:00:34.953171 20451 solver.cpp:244]     Train net output #1: loss = 0.281312 (* 1 = 0.281312 loss)
I0809 03:00:34.953183 20451 sgd_solver.cpp:106] Iteration 20620, lr = 0.000432012
I0809 03:00:57.264576 20451 solver.cpp:228] Iteration 20630, loss = 0.21885
I0809 03:00:57.264760 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:00:57.264775 20451 solver.cpp:244]     Train net output #1: loss = 0.21885 (* 1 = 0.21885 loss)
I0809 03:00:57.264788 20451 sgd_solver.cpp:106] Iteration 20630, lr = 0.000431907
I0809 03:01:19.583034 20451 solver.cpp:228] Iteration 20640, loss = 0.312622
I0809 03:01:19.583086 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 03:01:19.583101 20451 solver.cpp:244]     Train net output #1: loss = 0.312622 (* 1 = 0.312622 loss)
I0809 03:01:19.583112 20451 sgd_solver.cpp:106] Iteration 20640, lr = 0.000431801
I0809 03:01:41.897562 20451 solver.cpp:228] Iteration 20650, loss = 0.125043
I0809 03:01:41.897672 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:01:41.897691 20451 solver.cpp:244]     Train net output #1: loss = 0.125043 (* 1 = 0.125043 loss)
I0809 03:01:41.897706 20451 sgd_solver.cpp:106] Iteration 20650, lr = 0.000431695
I0809 03:02:04.214429 20451 solver.cpp:228] Iteration 20660, loss = 0.125065
I0809 03:02:04.214480 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:02:04.214495 20451 solver.cpp:244]     Train net output #1: loss = 0.125065 (* 1 = 0.125065 loss)
I0809 03:02:04.214506 20451 sgd_solver.cpp:106] Iteration 20660, lr = 0.00043159
I0809 03:02:26.533464 20451 solver.cpp:228] Iteration 20670, loss = 0.0937866
I0809 03:02:26.533646 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:02:26.533661 20451 solver.cpp:244]     Train net output #1: loss = 0.0937867 (* 1 = 0.0937867 loss)
I0809 03:02:26.533674 20451 sgd_solver.cpp:106] Iteration 20670, lr = 0.000431484
I0809 03:02:48.846043 20451 solver.cpp:228] Iteration 20680, loss = 0.312956
I0809 03:02:48.846096 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 03:02:48.846109 20451 solver.cpp:244]     Train net output #1: loss = 0.312956 (* 1 = 0.312956 loss)
I0809 03:02:48.846122 20451 sgd_solver.cpp:106] Iteration 20680, lr = 0.000431379
I0809 03:03:11.166342 20451 solver.cpp:228] Iteration 20690, loss = 0.125009
I0809 03:03:11.166512 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:03:11.166527 20451 solver.cpp:244]     Train net output #1: loss = 0.125009 (* 1 = 0.125009 loss)
I0809 03:03:11.166539 20451 sgd_solver.cpp:106] Iteration 20690, lr = 0.000431273
I0809 03:03:31.251849 20451 solver.cpp:337] Iteration 20700, Testing net (#0)
I0809 03:03:39.776047 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 03:03:39.776099 20451 solver.cpp:404]     Test net output #1: loss = 0.998644 (* 1 = 0.998644 loss)
I0809 03:03:41.979661 20451 solver.cpp:228] Iteration 20700, loss = 0.156298
I0809 03:03:41.979753 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:03:41.979768 20451 solver.cpp:244]     Train net output #1: loss = 0.156298 (* 1 = 0.156298 loss)
I0809 03:03:41.979781 20451 sgd_solver.cpp:106] Iteration 20700, lr = 0.000431168
I0809 03:04:04.278537 20451 solver.cpp:228] Iteration 20710, loss = 0.250013
I0809 03:04:04.278589 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:04:04.278604 20451 solver.cpp:244]     Train net output #1: loss = 0.250013 (* 1 = 0.250013 loss)
I0809 03:04:04.278615 20451 sgd_solver.cpp:106] Iteration 20710, lr = 0.000431062
I0809 03:04:26.597226 20451 solver.cpp:228] Iteration 20720, loss = 0.250083
I0809 03:04:26.597440 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:04:26.597455 20451 solver.cpp:244]     Train net output #1: loss = 0.250083 (* 1 = 0.250083 loss)
I0809 03:04:26.597467 20451 sgd_solver.cpp:106] Iteration 20720, lr = 0.000430957
I0809 03:04:48.915695 20451 solver.cpp:228] Iteration 20730, loss = 0.125242
I0809 03:04:48.915747 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:04:48.915762 20451 solver.cpp:244]     Train net output #1: loss = 0.125242 (* 1 = 0.125242 loss)
I0809 03:04:48.915774 20451 sgd_solver.cpp:106] Iteration 20730, lr = 0.000430852
I0809 03:05:11.226785 20451 solver.cpp:228] Iteration 20740, loss = 0.0939524
I0809 03:05:11.226963 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:05:11.226979 20451 solver.cpp:244]     Train net output #1: loss = 0.0939525 (* 1 = 0.0939525 loss)
I0809 03:05:11.226991 20451 sgd_solver.cpp:106] Iteration 20740, lr = 0.000430747
I0809 03:05:33.544406 20451 solver.cpp:228] Iteration 20750, loss = 0.125026
I0809 03:05:33.544453 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:05:33.544469 20451 solver.cpp:244]     Train net output #1: loss = 0.125026 (* 1 = 0.125026 loss)
I0809 03:05:33.544481 20451 sgd_solver.cpp:106] Iteration 20750, lr = 0.000430642
I0809 03:05:55.850138 20451 solver.cpp:228] Iteration 20760, loss = 0.25006
I0809 03:05:55.850247 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:05:55.850267 20451 solver.cpp:244]     Train net output #1: loss = 0.25006 (* 1 = 0.25006 loss)
I0809 03:05:55.850283 20451 sgd_solver.cpp:106] Iteration 20760, lr = 0.000430537
I0809 03:06:18.173987 20451 solver.cpp:228] Iteration 20770, loss = 0.125049
I0809 03:06:18.174031 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:06:18.174046 20451 solver.cpp:244]     Train net output #1: loss = 0.125049 (* 1 = 0.125049 loss)
I0809 03:06:18.174057 20451 sgd_solver.cpp:106] Iteration 20770, lr = 0.000430432
I0809 03:06:40.503612 20451 solver.cpp:228] Iteration 20780, loss = 0.12504
I0809 03:06:40.503794 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:06:40.503814 20451 solver.cpp:244]     Train net output #1: loss = 0.12504 (* 1 = 0.12504 loss)
I0809 03:06:40.503829 20451 sgd_solver.cpp:106] Iteration 20780, lr = 0.000430327
I0809 03:07:02.819814 20451 solver.cpp:228] Iteration 20790, loss = 0.0312593
I0809 03:07:02.819865 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 03:07:02.819880 20451 solver.cpp:244]     Train net output #1: loss = 0.0312593 (* 1 = 0.0312593 loss)
I0809 03:07:02.819892 20451 sgd_solver.cpp:106] Iteration 20790, lr = 0.000430222
I0809 03:07:22.913529 20451 solver.cpp:337] Iteration 20800, Testing net (#0)
I0809 03:07:31.434965 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 03:07:31.435019 20451 solver.cpp:404]     Test net output #1: loss = 1.00802 (* 1 = 1.00802 loss)
I0809 03:07:33.637593 20451 solver.cpp:228] Iteration 20800, loss = 0.0625188
I0809 03:07:33.637644 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 03:07:33.637658 20451 solver.cpp:244]     Train net output #1: loss = 0.0625189 (* 1 = 0.0625189 loss)
I0809 03:07:33.637670 20451 sgd_solver.cpp:106] Iteration 20800, lr = 0.000430117
I0809 03:07:55.929841 20451 solver.cpp:228] Iteration 20810, loss = 0.218888
I0809 03:07:55.929936 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:07:55.929951 20451 solver.cpp:244]     Train net output #1: loss = 0.218888 (* 1 = 0.218888 loss)
I0809 03:07:55.929965 20451 sgd_solver.cpp:106] Iteration 20810, lr = 0.000430013
I0809 03:08:18.239979 20451 solver.cpp:228] Iteration 20820, loss = 0.031471
I0809 03:08:18.240034 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:08:18.240048 20451 solver.cpp:244]     Train net output #1: loss = 0.031471 (* 1 = 0.031471 loss)
I0809 03:08:18.240061 20451 sgd_solver.cpp:106] Iteration 20820, lr = 0.000429908
I0809 03:08:40.552687 20451 solver.cpp:228] Iteration 20830, loss = 0.218801
I0809 03:08:40.552903 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:08:40.552919 20451 solver.cpp:244]     Train net output #1: loss = 0.218801 (* 1 = 0.218801 loss)
I0809 03:08:40.552933 20451 sgd_solver.cpp:106] Iteration 20830, lr = 0.000429803
I0809 03:09:02.872252 20451 solver.cpp:228] Iteration 20840, loss = 0.093944
I0809 03:09:02.872294 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:09:02.872309 20451 solver.cpp:244]     Train net output #1: loss = 0.0939441 (* 1 = 0.0939441 loss)
I0809 03:09:02.872321 20451 sgd_solver.cpp:106] Iteration 20840, lr = 0.000429699
I0809 03:09:25.180413 20451 solver.cpp:228] Iteration 20850, loss = 0.0938775
I0809 03:09:25.180538 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:09:25.180557 20451 solver.cpp:244]     Train net output #1: loss = 0.0938776 (* 1 = 0.0938776 loss)
I0809 03:09:25.180574 20451 sgd_solver.cpp:106] Iteration 20850, lr = 0.000429594
I0809 03:09:47.501689 20451 solver.cpp:228] Iteration 20860, loss = 0.156376
I0809 03:09:47.501734 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:09:47.501752 20451 solver.cpp:244]     Train net output #1: loss = 0.156376 (* 1 = 0.156376 loss)
I0809 03:09:47.501768 20451 sgd_solver.cpp:106] Iteration 20860, lr = 0.00042949
I0809 03:10:09.825055 20451 solver.cpp:228] Iteration 20870, loss = 0.219183
I0809 03:10:09.825239 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:10:09.825258 20451 solver.cpp:244]     Train net output #1: loss = 0.219183 (* 1 = 0.219183 loss)
I0809 03:10:09.825273 20451 sgd_solver.cpp:106] Iteration 20870, lr = 0.000429386
I0809 03:10:32.144847 20451 solver.cpp:228] Iteration 20880, loss = 0.156316
I0809 03:10:32.144901 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:10:32.144914 20451 solver.cpp:244]     Train net output #1: loss = 0.156317 (* 1 = 0.156317 loss)
I0809 03:10:32.144927 20451 sgd_solver.cpp:106] Iteration 20880, lr = 0.000429281
I0809 03:10:54.453621 20451 solver.cpp:228] Iteration 20890, loss = 0.156304
I0809 03:10:54.453724 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:10:54.453739 20451 solver.cpp:244]     Train net output #1: loss = 0.156304 (* 1 = 0.156304 loss)
I0809 03:10:54.453752 20451 sgd_solver.cpp:106] Iteration 20890, lr = 0.000429177
I0809 03:11:14.547808 20451 solver.cpp:337] Iteration 20900, Testing net (#0)
I0809 03:11:23.065798 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 03:11:23.065837 20451 solver.cpp:404]     Test net output #1: loss = 1.00326 (* 1 = 1.00326 loss)
I0809 03:11:25.267659 20451 solver.cpp:228] Iteration 20900, loss = 0.25005
I0809 03:11:25.267904 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:11:25.268046 20451 solver.cpp:244]     Train net output #1: loss = 0.250051 (* 1 = 0.250051 loss)
I0809 03:11:25.268090 20451 sgd_solver.cpp:106] Iteration 20900, lr = 0.000429073
I0809 03:11:47.567235 20451 solver.cpp:228] Iteration 20910, loss = 0.0937668
I0809 03:11:47.567282 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:11:47.567298 20451 solver.cpp:244]     Train net output #1: loss = 0.0937669 (* 1 = 0.0937669 loss)
I0809 03:11:47.567312 20451 sgd_solver.cpp:106] Iteration 20910, lr = 0.000428969
I0809 03:12:09.881108 20451 solver.cpp:228] Iteration 20920, loss = 0.0625471
I0809 03:12:09.881358 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 03:12:09.881378 20451 solver.cpp:244]     Train net output #1: loss = 0.0625472 (* 1 = 0.0625472 loss)
I0809 03:12:09.881394 20451 sgd_solver.cpp:106] Iteration 20920, lr = 0.000428865
I0809 03:12:32.188508 20451 solver.cpp:228] Iteration 20930, loss = 0.156289
I0809 03:12:32.188560 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:12:32.188573 20451 solver.cpp:244]     Train net output #1: loss = 0.156289 (* 1 = 0.156289 loss)
I0809 03:12:32.188585 20451 sgd_solver.cpp:106] Iteration 20930, lr = 0.000428761
I0809 03:12:54.507588 20451 solver.cpp:228] Iteration 20940, loss = 0.250073
I0809 03:12:54.507980 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:12:54.507995 20451 solver.cpp:244]     Train net output #1: loss = 0.250073 (* 1 = 0.250073 loss)
I0809 03:12:54.508008 20451 sgd_solver.cpp:106] Iteration 20940, lr = 0.000428657
I0809 03:13:16.826413 20451 solver.cpp:228] Iteration 20950, loss = 0.250115
I0809 03:13:16.826472 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:13:16.826488 20451 solver.cpp:244]     Train net output #1: loss = 0.250115 (* 1 = 0.250115 loss)
I0809 03:13:16.826501 20451 sgd_solver.cpp:106] Iteration 20950, lr = 0.000428553
I0809 03:13:39.136669 20451 solver.cpp:228] Iteration 20960, loss = 0.28131
I0809 03:13:39.136853 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:13:39.136869 20451 solver.cpp:244]     Train net output #1: loss = 0.28131 (* 1 = 0.28131 loss)
I0809 03:13:39.136883 20451 sgd_solver.cpp:106] Iteration 20960, lr = 0.000428449
I0809 03:14:01.448709 20451 solver.cpp:228] Iteration 20970, loss = 0.156315
I0809 03:14:01.448753 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:14:01.448771 20451 solver.cpp:244]     Train net output #1: loss = 0.156315 (* 1 = 0.156315 loss)
I0809 03:14:01.448783 20451 sgd_solver.cpp:106] Iteration 20970, lr = 0.000428345
I0809 03:14:23.763957 20451 solver.cpp:228] Iteration 20980, loss = 0.187535
I0809 03:14:23.764062 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:14:23.764077 20451 solver.cpp:244]     Train net output #1: loss = 0.187535 (* 1 = 0.187535 loss)
I0809 03:14:23.764091 20451 sgd_solver.cpp:106] Iteration 20980, lr = 0.000428242
I0809 03:14:46.082906 20451 solver.cpp:228] Iteration 20990, loss = 0.187539
I0809 03:14:46.082959 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:14:46.082974 20451 solver.cpp:244]     Train net output #1: loss = 0.187539 (* 1 = 0.187539 loss)
I0809 03:14:46.082986 20451 sgd_solver.cpp:106] Iteration 20990, lr = 0.000428138
I0809 03:15:06.170958 20451 solver.cpp:337] Iteration 21000, Testing net (#0)
I0809 03:15:14.692389 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0809 03:15:14.692440 20451 solver.cpp:404]     Test net output #1: loss = 0.961521 (* 1 = 0.961521 loss)
I0809 03:15:16.897095 20451 solver.cpp:228] Iteration 21000, loss = 0.156392
I0809 03:15:16.897150 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:15:16.897163 20451 solver.cpp:244]     Train net output #1: loss = 0.156392 (* 1 = 0.156392 loss)
I0809 03:15:16.897176 20451 sgd_solver.cpp:106] Iteration 21000, lr = 0.000428034
I0809 03:15:39.190453 20451 solver.cpp:228] Iteration 21010, loss = 0.156283
I0809 03:15:39.190634 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:15:39.190649 20451 solver.cpp:244]     Train net output #1: loss = 0.156284 (* 1 = 0.156284 loss)
I0809 03:15:39.190662 20451 sgd_solver.cpp:106] Iteration 21010, lr = 0.000427931
I0809 03:16:01.506217 20451 solver.cpp:228] Iteration 21020, loss = 0.187608
I0809 03:16:01.506268 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:16:01.506281 20451 solver.cpp:244]     Train net output #1: loss = 0.187608 (* 1 = 0.187608 loss)
I0809 03:16:01.506292 20451 sgd_solver.cpp:106] Iteration 21020, lr = 0.000427827
I0809 03:16:23.828114 20451 solver.cpp:228] Iteration 21030, loss = 0.218824
I0809 03:16:23.828292 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:16:23.828307 20451 solver.cpp:244]     Train net output #1: loss = 0.218824 (* 1 = 0.218824 loss)
I0809 03:16:23.828320 20451 sgd_solver.cpp:106] Iteration 21030, lr = 0.000427724
I0809 03:16:46.148879 20451 solver.cpp:228] Iteration 21040, loss = 0.156353
I0809 03:16:46.148931 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:16:46.148944 20451 solver.cpp:244]     Train net output #1: loss = 0.156353 (* 1 = 0.156353 loss)
I0809 03:16:46.148955 20451 sgd_solver.cpp:106] Iteration 21040, lr = 0.000427621
I0809 03:17:08.464962 20451 solver.cpp:228] Iteration 21050, loss = 0.281404
I0809 03:17:08.465184 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:17:08.465204 20451 solver.cpp:244]     Train net output #1: loss = 0.281404 (* 1 = 0.281404 loss)
I0809 03:17:08.465220 20451 sgd_solver.cpp:106] Iteration 21050, lr = 0.000427517
I0809 03:17:30.773612 20451 solver.cpp:228] Iteration 21060, loss = 0.125019
I0809 03:17:30.773664 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:17:30.773677 20451 solver.cpp:244]     Train net output #1: loss = 0.125019 (* 1 = 0.125019 loss)
I0809 03:17:30.773689 20451 sgd_solver.cpp:106] Iteration 21060, lr = 0.000427414
I0809 03:17:53.086439 20451 solver.cpp:228] Iteration 21070, loss = 0.0937892
I0809 03:17:53.086614 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:17:53.086630 20451 solver.cpp:244]     Train net output #1: loss = 0.0937894 (* 1 = 0.0937894 loss)
I0809 03:17:53.086643 20451 sgd_solver.cpp:106] Iteration 21070, lr = 0.000427311
I0809 03:18:15.406913 20451 solver.cpp:228] Iteration 21080, loss = 0.125026
I0809 03:18:15.406965 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:18:15.406978 20451 solver.cpp:244]     Train net output #1: loss = 0.125026 (* 1 = 0.125026 loss)
I0809 03:18:15.406991 20451 sgd_solver.cpp:106] Iteration 21080, lr = 0.000427208
I0809 03:18:37.721092 20451 solver.cpp:228] Iteration 21090, loss = 0.125087
I0809 03:18:37.721192 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:18:37.721211 20451 solver.cpp:244]     Train net output #1: loss = 0.125087 (* 1 = 0.125087 loss)
I0809 03:18:37.721225 20451 sgd_solver.cpp:106] Iteration 21090, lr = 0.000427105
I0809 03:18:57.804057 20451 solver.cpp:337] Iteration 21100, Testing net (#0)
I0809 03:19:06.333747 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 03:19:06.333798 20451 solver.cpp:404]     Test net output #1: loss = 0.994239 (* 1 = 0.994239 loss)
I0809 03:19:08.534216 20451 solver.cpp:228] Iteration 21100, loss = 0.187637
I0809 03:19:08.534394 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:19:08.534410 20451 solver.cpp:244]     Train net output #1: loss = 0.187637 (* 1 = 0.187637 loss)
I0809 03:19:08.534423 20451 sgd_solver.cpp:106] Iteration 21100, lr = 0.000427002
I0809 03:19:30.831387 20451 solver.cpp:228] Iteration 21110, loss = 0.218984
I0809 03:19:30.831439 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:19:30.831451 20451 solver.cpp:244]     Train net output #1: loss = 0.218984 (* 1 = 0.218984 loss)
I0809 03:19:30.831465 20451 sgd_solver.cpp:106] Iteration 21110, lr = 0.000426899
I0809 03:19:53.151350 20451 solver.cpp:228] Iteration 21120, loss = 0.187708
I0809 03:19:53.151526 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:19:53.151543 20451 solver.cpp:244]     Train net output #1: loss = 0.187708 (* 1 = 0.187708 loss)
I0809 03:19:53.151556 20451 sgd_solver.cpp:106] Iteration 21120, lr = 0.000426796
I0809 03:20:15.467464 20451 solver.cpp:228] Iteration 21130, loss = 0.093825
I0809 03:20:15.467507 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:20:15.467522 20451 solver.cpp:244]     Train net output #1: loss = 0.0938251 (* 1 = 0.0938251 loss)
I0809 03:20:15.467535 20451 sgd_solver.cpp:106] Iteration 21130, lr = 0.000426693
I0809 03:20:37.775740 20451 solver.cpp:228] Iteration 21140, loss = 0.281539
I0809 03:20:37.775840 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:20:37.775856 20451 solver.cpp:244]     Train net output #1: loss = 0.281539 (* 1 = 0.281539 loss)
I0809 03:20:37.775869 20451 sgd_solver.cpp:106] Iteration 21140, lr = 0.00042659
I0809 03:21:00.106081 20451 solver.cpp:228] Iteration 21150, loss = 0.218917
I0809 03:21:00.106132 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:21:00.106145 20451 solver.cpp:244]     Train net output #1: loss = 0.218917 (* 1 = 0.218917 loss)
I0809 03:21:00.106158 20451 sgd_solver.cpp:106] Iteration 21150, lr = 0.000426488
I0809 03:21:22.421933 20451 solver.cpp:228] Iteration 21160, loss = 0.281285
I0809 03:21:22.422144 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:21:22.422160 20451 solver.cpp:244]     Train net output #1: loss = 0.281285 (* 1 = 0.281285 loss)
I0809 03:21:22.422173 20451 sgd_solver.cpp:106] Iteration 21160, lr = 0.000426385
I0809 03:21:44.722450 20451 solver.cpp:228] Iteration 21170, loss = 0.187611
I0809 03:21:44.722504 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:21:44.722518 20451 solver.cpp:244]     Train net output #1: loss = 0.187611 (* 1 = 0.187611 loss)
I0809 03:21:44.722532 20451 sgd_solver.cpp:106] Iteration 21170, lr = 0.000426282
I0809 03:22:07.041978 20451 solver.cpp:228] Iteration 21180, loss = 0.15632
I0809 03:22:07.042143 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:22:07.042160 20451 solver.cpp:244]     Train net output #1: loss = 0.15632 (* 1 = 0.15632 loss)
I0809 03:22:07.042171 20451 sgd_solver.cpp:106] Iteration 21180, lr = 0.00042618
I0809 03:22:29.363466 20451 solver.cpp:228] Iteration 21190, loss = 0.12503
I0809 03:22:29.363517 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:22:29.363530 20451 solver.cpp:244]     Train net output #1: loss = 0.12503 (* 1 = 0.12503 loss)
I0809 03:22:29.363543 20451 sgd_solver.cpp:106] Iteration 21190, lr = 0.000426077
I0809 03:22:49.461781 20451 solver.cpp:337] Iteration 21200, Testing net (#0)
I0809 03:22:57.988890 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 03:22:57.988935 20451 solver.cpp:404]     Test net output #1: loss = 0.998458 (* 1 = 0.998458 loss)
I0809 03:23:00.197693 20451 solver.cpp:228] Iteration 21200, loss = 0.312539
I0809 03:23:00.197736 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:23:00.197749 20451 solver.cpp:244]     Train net output #1: loss = 0.312539 (* 1 = 0.312539 loss)
I0809 03:23:00.197762 20451 sgd_solver.cpp:106] Iteration 21200, lr = 0.000425975
I0809 03:23:22.489998 20451 solver.cpp:228] Iteration 21210, loss = 0.250266
I0809 03:23:22.490178 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:23:22.490192 20451 solver.cpp:244]     Train net output #1: loss = 0.250266 (* 1 = 0.250266 loss)
I0809 03:23:22.490205 20451 sgd_solver.cpp:106] Iteration 21210, lr = 0.000425873
I0809 03:23:44.808776 20451 solver.cpp:228] Iteration 21220, loss = 0.156298
I0809 03:23:44.808828 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:23:44.808842 20451 solver.cpp:244]     Train net output #1: loss = 0.156298 (* 1 = 0.156298 loss)
I0809 03:23:44.808854 20451 sgd_solver.cpp:106] Iteration 21220, lr = 0.00042577
I0809 03:24:07.133798 20451 solver.cpp:228] Iteration 21230, loss = 0.125084
I0809 03:24:07.133909 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:24:07.133925 20451 solver.cpp:244]     Train net output #1: loss = 0.125084 (* 1 = 0.125084 loss)
I0809 03:24:07.133940 20451 sgd_solver.cpp:106] Iteration 21230, lr = 0.000425668
I0809 03:24:29.445482 20451 solver.cpp:228] Iteration 21240, loss = 0.281353
I0809 03:24:29.445533 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:24:29.445546 20451 solver.cpp:244]     Train net output #1: loss = 0.281353 (* 1 = 0.281353 loss)
I0809 03:24:29.445559 20451 sgd_solver.cpp:106] Iteration 21240, lr = 0.000425566
I0809 03:24:51.760198 20451 solver.cpp:228] Iteration 21250, loss = 0.156354
I0809 03:24:51.760375 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:24:51.760390 20451 solver.cpp:244]     Train net output #1: loss = 0.156354 (* 1 = 0.156354 loss)
I0809 03:24:51.760403 20451 sgd_solver.cpp:106] Iteration 21250, lr = 0.000425464
I0809 03:25:14.069373 20451 solver.cpp:228] Iteration 21260, loss = 0.187577
I0809 03:25:14.069425 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:25:14.069439 20451 solver.cpp:244]     Train net output #1: loss = 0.187578 (* 1 = 0.187578 loss)
I0809 03:25:14.069453 20451 sgd_solver.cpp:106] Iteration 21260, lr = 0.000425362
I0809 03:25:36.376209 20451 solver.cpp:228] Iteration 21270, loss = 0.0312578
I0809 03:25:36.376415 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 03:25:36.376430 20451 solver.cpp:244]     Train net output #1: loss = 0.0312579 (* 1 = 0.0312579 loss)
I0809 03:25:36.376443 20451 sgd_solver.cpp:106] Iteration 21270, lr = 0.00042526
I0809 03:25:58.678601 20451 solver.cpp:228] Iteration 21280, loss = 0.125024
I0809 03:25:58.678653 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:25:58.678666 20451 solver.cpp:244]     Train net output #1: loss = 0.125024 (* 1 = 0.125024 loss)
I0809 03:25:58.678678 20451 sgd_solver.cpp:106] Iteration 21280, lr = 0.000425158
I0809 03:26:20.985474 20451 solver.cpp:228] Iteration 21290, loss = 0.156265
I0809 03:26:20.985625 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:26:20.985646 20451 solver.cpp:244]     Train net output #1: loss = 0.156265 (* 1 = 0.156265 loss)
I0809 03:26:20.985661 20451 sgd_solver.cpp:106] Iteration 21290, lr = 0.000425056
I0809 03:26:41.058631 20451 solver.cpp:337] Iteration 21300, Testing net (#0)
I0809 03:26:49.575058 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0809 03:26:49.575111 20451 solver.cpp:404]     Test net output #1: loss = 0.989145 (* 1 = 0.989145 loss)
I0809 03:26:51.780653 20451 solver.cpp:228] Iteration 21300, loss = 0.156457
I0809 03:26:51.780827 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:26:51.780843 20451 solver.cpp:244]     Train net output #1: loss = 0.156457 (* 1 = 0.156457 loss)
I0809 03:26:51.780856 20451 sgd_solver.cpp:106] Iteration 21300, lr = 0.000424954
I0809 03:27:14.074688 20451 solver.cpp:228] Iteration 21310, loss = 0.187564
I0809 03:27:14.074739 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:27:14.074753 20451 solver.cpp:244]     Train net output #1: loss = 0.187564 (* 1 = 0.187564 loss)
I0809 03:27:14.074765 20451 sgd_solver.cpp:106] Iteration 21310, lr = 0.000424852
I0809 03:27:36.385944 20451 solver.cpp:228] Iteration 21320, loss = 0.125047
I0809 03:27:36.386123 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:27:36.386139 20451 solver.cpp:244]     Train net output #1: loss = 0.125047 (* 1 = 0.125047 loss)
I0809 03:27:36.386152 20451 sgd_solver.cpp:106] Iteration 21320, lr = 0.00042475
I0809 03:27:58.696274 20451 solver.cpp:228] Iteration 21330, loss = 0.218976
I0809 03:27:58.696319 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:27:58.696337 20451 solver.cpp:244]     Train net output #1: loss = 0.218976 (* 1 = 0.218976 loss)
I0809 03:27:58.696352 20451 sgd_solver.cpp:106] Iteration 21330, lr = 0.000424649
I0809 03:28:21.006510 20451 solver.cpp:228] Iteration 21340, loss = 0.125087
I0809 03:28:21.006687 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:28:21.006705 20451 solver.cpp:244]     Train net output #1: loss = 0.125087 (* 1 = 0.125087 loss)
I0809 03:28:21.006721 20451 sgd_solver.cpp:106] Iteration 21340, lr = 0.000424547
I0809 03:28:43.317818 20451 solver.cpp:228] Iteration 21350, loss = 0.281304
I0809 03:28:43.317873 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:28:43.317888 20451 solver.cpp:244]     Train net output #1: loss = 0.281304 (* 1 = 0.281304 loss)
I0809 03:28:43.317899 20451 sgd_solver.cpp:106] Iteration 21350, lr = 0.000424445
I0809 03:29:05.629637 20451 solver.cpp:228] Iteration 21360, loss = 0.187613
I0809 03:29:05.629742 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:29:05.629760 20451 solver.cpp:244]     Train net output #1: loss = 0.187613 (* 1 = 0.187613 loss)
I0809 03:29:05.629776 20451 sgd_solver.cpp:106] Iteration 21360, lr = 0.000424344
I0809 03:29:27.936172 20451 solver.cpp:228] Iteration 21370, loss = 0.156267
I0809 03:29:27.936220 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:29:27.936234 20451 solver.cpp:244]     Train net output #1: loss = 0.156267 (* 1 = 0.156267 loss)
I0809 03:29:27.936246 20451 sgd_solver.cpp:106] Iteration 21370, lr = 0.000424242
I0809 03:29:50.245175 20451 solver.cpp:228] Iteration 21380, loss = 2.68221e-07
I0809 03:29:50.245368 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:29:50.245412 20451 solver.cpp:244]     Train net output #1: loss = 3.42727e-07 (* 1 = 3.42727e-07 loss)
I0809 03:29:50.245450 20451 sgd_solver.cpp:106] Iteration 21380, lr = 0.000424141
I0809 03:30:12.556686 20451 solver.cpp:228] Iteration 21390, loss = 0.12501
I0809 03:30:12.556728 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:30:12.556746 20451 solver.cpp:244]     Train net output #1: loss = 0.12501 (* 1 = 0.12501 loss)
I0809 03:30:12.556761 20451 sgd_solver.cpp:106] Iteration 21390, lr = 0.00042404
I0809 03:30:32.648659 20451 solver.cpp:337] Iteration 21400, Testing net (#0)
I0809 03:30:41.176215 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0809 03:30:41.176306 20451 solver.cpp:404]     Test net output #1: loss = 1.03609 (* 1 = 1.03609 loss)
I0809 03:30:43.377825 20451 solver.cpp:228] Iteration 21400, loss = 0.15628
I0809 03:30:43.377869 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:30:43.377888 20451 solver.cpp:244]     Train net output #1: loss = 0.15628 (* 1 = 0.15628 loss)
I0809 03:30:43.377913 20451 sgd_solver.cpp:106] Iteration 21400, lr = 0.000423938
I0809 03:31:05.670723 20451 solver.cpp:228] Iteration 21410, loss = 0.187554
I0809 03:31:05.670904 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:31:05.670919 20451 solver.cpp:244]     Train net output #1: loss = 0.187554 (* 1 = 0.187554 loss)
I0809 03:31:05.670933 20451 sgd_solver.cpp:106] Iteration 21410, lr = 0.000423837
I0809 03:31:27.985518 20451 solver.cpp:228] Iteration 21420, loss = 0.125012
I0809 03:31:27.985563 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:31:27.985577 20451 solver.cpp:244]     Train net output #1: loss = 0.125012 (* 1 = 0.125012 loss)
I0809 03:31:27.985589 20451 sgd_solver.cpp:106] Iteration 21420, lr = 0.000423736
I0809 03:31:50.299149 20451 solver.cpp:228] Iteration 21430, loss = 0.281286
I0809 03:31:50.299388 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:31:50.299465 20451 solver.cpp:244]     Train net output #1: loss = 0.281286 (* 1 = 0.281286 loss)
I0809 03:31:50.299504 20451 sgd_solver.cpp:106] Iteration 21430, lr = 0.000423635
I0809 03:32:12.610201 20451 solver.cpp:228] Iteration 21440, loss = 0.156293
I0809 03:32:12.610251 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:32:12.610265 20451 solver.cpp:244]     Train net output #1: loss = 0.156293 (* 1 = 0.156293 loss)
I0809 03:32:12.610277 20451 sgd_solver.cpp:106] Iteration 21440, lr = 0.000423534
I0809 03:32:34.926542 20451 solver.cpp:228] Iteration 21450, loss = 0.0937649
I0809 03:32:34.926723 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:32:34.926738 20451 solver.cpp:244]     Train net output #1: loss = 0.093765 (* 1 = 0.093765 loss)
I0809 03:32:34.926751 20451 sgd_solver.cpp:106] Iteration 21450, lr = 0.000423433
I0809 03:32:57.251588 20451 solver.cpp:228] Iteration 21460, loss = 0.250051
I0809 03:32:57.251641 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:32:57.251654 20451 solver.cpp:244]     Train net output #1: loss = 0.250051 (* 1 = 0.250051 loss)
I0809 03:32:57.251667 20451 sgd_solver.cpp:106] Iteration 21460, lr = 0.000423332
I0809 03:33:19.562007 20451 solver.cpp:228] Iteration 21470, loss = 0.219066
I0809 03:33:19.562183 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:33:19.562198 20451 solver.cpp:244]     Train net output #1: loss = 0.219066 (* 1 = 0.219066 loss)
I0809 03:33:19.562211 20451 sgd_solver.cpp:106] Iteration 21470, lr = 0.000423231
I0809 03:33:41.873239 20451 solver.cpp:228] Iteration 21480, loss = 0.250253
I0809 03:33:41.873291 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:33:41.873303 20451 solver.cpp:244]     Train net output #1: loss = 0.250253 (* 1 = 0.250253 loss)
I0809 03:33:41.873317 20451 sgd_solver.cpp:106] Iteration 21480, lr = 0.00042313
I0809 03:34:04.190866 20451 solver.cpp:228] Iteration 21490, loss = 0.09389
I0809 03:34:04.191155 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:34:04.191198 20451 solver.cpp:244]     Train net output #1: loss = 0.0938901 (* 1 = 0.0938901 loss)
I0809 03:34:04.191215 20451 sgd_solver.cpp:106] Iteration 21490, lr = 0.000423029
I0809 03:34:24.284937 20451 solver.cpp:337] Iteration 21500, Testing net (#0)
I0809 03:34:32.807355 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 03:34:32.807405 20451 solver.cpp:404]     Test net output #1: loss = 0.984542 (* 1 = 0.984542 loss)
I0809 03:34:35.013305 20451 solver.cpp:228] Iteration 21500, loss = 0.125429
I0809 03:34:35.013489 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:34:35.013504 20451 solver.cpp:244]     Train net output #1: loss = 0.125429 (* 1 = 0.125429 loss)
I0809 03:34:35.013516 20451 sgd_solver.cpp:106] Iteration 21500, lr = 0.000422929
I0809 03:34:57.308576 20451 solver.cpp:228] Iteration 21510, loss = 0.219028
I0809 03:34:57.308627 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:34:57.308641 20451 solver.cpp:244]     Train net output #1: loss = 0.219028 (* 1 = 0.219028 loss)
I0809 03:34:57.308653 20451 sgd_solver.cpp:106] Iteration 21510, lr = 0.000422828
I0809 03:35:19.615016 20451 solver.cpp:228] Iteration 21520, loss = 0.125057
I0809 03:35:19.615196 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:35:19.615212 20451 solver.cpp:244]     Train net output #1: loss = 0.125057 (* 1 = 0.125057 loss)
I0809 03:35:19.615226 20451 sgd_solver.cpp:106] Iteration 21520, lr = 0.000422727
I0809 03:35:41.920552 20451 solver.cpp:228] Iteration 21530, loss = 0.187763
I0809 03:35:41.920606 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:35:41.920620 20451 solver.cpp:244]     Train net output #1: loss = 0.187763 (* 1 = 0.187763 loss)
I0809 03:35:41.920634 20451 sgd_solver.cpp:106] Iteration 21530, lr = 0.000422627
I0809 03:36:04.228128 20451 solver.cpp:228] Iteration 21540, loss = 0.250032
I0809 03:36:04.228308 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:36:04.228324 20451 solver.cpp:244]     Train net output #1: loss = 0.250032 (* 1 = 0.250032 loss)
I0809 03:36:04.228338 20451 sgd_solver.cpp:106] Iteration 21540, lr = 0.000422526
I0809 03:36:26.543334 20451 solver.cpp:228] Iteration 21550, loss = 0.156383
I0809 03:36:26.543385 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:36:26.543400 20451 solver.cpp:244]     Train net output #1: loss = 0.156383 (* 1 = 0.156383 loss)
I0809 03:36:26.543411 20451 sgd_solver.cpp:106] Iteration 21550, lr = 0.000422426
I0809 03:36:48.858474 20451 solver.cpp:228] Iteration 21560, loss = 0.281277
I0809 03:36:48.858654 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:36:48.858670 20451 solver.cpp:244]     Train net output #1: loss = 0.281277 (* 1 = 0.281277 loss)
I0809 03:36:48.858682 20451 sgd_solver.cpp:106] Iteration 21560, lr = 0.000422325
I0809 03:37:11.169056 20451 solver.cpp:228] Iteration 21570, loss = 0.281548
I0809 03:37:11.169108 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:37:11.169122 20451 solver.cpp:244]     Train net output #1: loss = 0.281548 (* 1 = 0.281548 loss)
I0809 03:37:11.169134 20451 sgd_solver.cpp:106] Iteration 21570, lr = 0.000422225
I0809 03:37:33.486951 20451 solver.cpp:228] Iteration 21580, loss = 0.312572
I0809 03:37:33.487176 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 03:37:33.487217 20451 solver.cpp:244]     Train net output #1: loss = 0.312572 (* 1 = 0.312572 loss)
I0809 03:37:33.487233 20451 sgd_solver.cpp:106] Iteration 21580, lr = 0.000422125
I0809 03:37:55.803764 20451 solver.cpp:228] Iteration 21590, loss = 0.187552
I0809 03:37:55.803819 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:37:55.803838 20451 solver.cpp:244]     Train net output #1: loss = 0.187552 (* 1 = 0.187552 loss)
I0809 03:37:55.803853 20451 sgd_solver.cpp:106] Iteration 21590, lr = 0.000422025
I0809 03:38:15.892608 20451 solver.cpp:337] Iteration 21600, Testing net (#0)
I0809 03:38:24.416842 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0809 03:38:24.416893 20451 solver.cpp:404]     Test net output #1: loss = 0.970472 (* 1 = 0.970472 loss)
I0809 03:38:26.620919 20451 solver.cpp:228] Iteration 21600, loss = 0.187545
I0809 03:38:26.620961 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:38:26.620976 20451 solver.cpp:244]     Train net output #1: loss = 0.187545 (* 1 = 0.187545 loss)
I0809 03:38:26.620990 20451 sgd_solver.cpp:106] Iteration 21600, lr = 0.000421924
I0809 03:38:48.915859 20451 solver.cpp:228] Iteration 21610, loss = 0.156284
I0809 03:38:48.916041 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:38:48.916056 20451 solver.cpp:244]     Train net output #1: loss = 0.156285 (* 1 = 0.156285 loss)
I0809 03:38:48.916069 20451 sgd_solver.cpp:106] Iteration 21610, lr = 0.000421824
I0809 03:39:11.235677 20451 solver.cpp:228] Iteration 21620, loss = 0.156272
I0809 03:39:11.235723 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:39:11.235750 20451 solver.cpp:244]     Train net output #1: loss = 0.156272 (* 1 = 0.156272 loss)
I0809 03:39:11.235766 20451 sgd_solver.cpp:106] Iteration 21620, lr = 0.000421724
I0809 03:39:33.551972 20451 solver.cpp:228] Iteration 21630, loss = 0.0937729
I0809 03:39:33.552150 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:39:33.552167 20451 solver.cpp:244]     Train net output #1: loss = 0.0937729 (* 1 = 0.0937729 loss)
I0809 03:39:33.552182 20451 sgd_solver.cpp:106] Iteration 21630, lr = 0.000421624
I0809 03:39:55.865316 20451 solver.cpp:228] Iteration 21640, loss = 0.125028
I0809 03:39:55.865370 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:39:55.865384 20451 solver.cpp:244]     Train net output #1: loss = 0.125028 (* 1 = 0.125028 loss)
I0809 03:39:55.865396 20451 sgd_solver.cpp:106] Iteration 21640, lr = 0.000421524
I0809 03:40:18.184384 20451 solver.cpp:228] Iteration 21650, loss = 0.218838
I0809 03:40:18.184568 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:40:18.184583 20451 solver.cpp:244]     Train net output #1: loss = 0.218838 (* 1 = 0.218838 loss)
I0809 03:40:18.184597 20451 sgd_solver.cpp:106] Iteration 21650, lr = 0.000421424
I0809 03:40:40.496338 20451 solver.cpp:228] Iteration 21660, loss = 0.281338
I0809 03:40:40.496387 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:40:40.496407 20451 solver.cpp:244]     Train net output #1: loss = 0.281338 (* 1 = 0.281338 loss)
I0809 03:40:40.496423 20451 sgd_solver.cpp:106] Iteration 21660, lr = 0.000421325
I0809 03:41:02.815155 20451 solver.cpp:228] Iteration 21670, loss = 0.0937833
I0809 03:41:02.815335 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:41:02.815354 20451 solver.cpp:244]     Train net output #1: loss = 0.0937834 (* 1 = 0.0937834 loss)
I0809 03:41:02.815369 20451 sgd_solver.cpp:106] Iteration 21670, lr = 0.000421225
I0809 03:41:25.129070 20451 solver.cpp:228] Iteration 21680, loss = 0.187595
I0809 03:41:25.129113 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:41:25.129130 20451 solver.cpp:244]     Train net output #1: loss = 0.187596 (* 1 = 0.187596 loss)
I0809 03:41:25.129156 20451 sgd_solver.cpp:106] Iteration 21680, lr = 0.000421125
I0809 03:41:47.453289 20451 solver.cpp:228] Iteration 21690, loss = 0.187562
I0809 03:41:47.453510 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:41:47.453526 20451 solver.cpp:244]     Train net output #1: loss = 0.187562 (* 1 = 0.187562 loss)
I0809 03:41:47.453539 20451 sgd_solver.cpp:106] Iteration 21690, lr = 0.000421025
I0809 03:42:07.541371 20451 solver.cpp:337] Iteration 21700, Testing net (#0)
I0809 03:42:16.081454 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 03:42:16.081506 20451 solver.cpp:404]     Test net output #1: loss = 1.00803 (* 1 = 1.00803 loss)
I0809 03:42:18.285262 20451 solver.cpp:228] Iteration 21700, loss = 0.125041
I0809 03:42:18.285449 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:42:18.285465 20451 solver.cpp:244]     Train net output #1: loss = 0.125041 (* 1 = 0.125041 loss)
I0809 03:42:18.285476 20451 sgd_solver.cpp:106] Iteration 21700, lr = 0.000420926
I0809 03:42:40.569453 20451 solver.cpp:228] Iteration 21710, loss = 0.125105
I0809 03:42:40.569504 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:42:40.569517 20451 solver.cpp:244]     Train net output #1: loss = 0.125105 (* 1 = 0.125105 loss)
I0809 03:42:40.569530 20451 sgd_solver.cpp:106] Iteration 21710, lr = 0.000420826
I0809 03:43:02.884603 20451 solver.cpp:228] Iteration 21720, loss = 0.218807
I0809 03:43:02.884779 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:43:02.884794 20451 solver.cpp:244]     Train net output #1: loss = 0.218807 (* 1 = 0.218807 loss)
I0809 03:43:02.884807 20451 sgd_solver.cpp:106] Iteration 21720, lr = 0.000420727
I0809 03:43:25.202214 20451 solver.cpp:228] Iteration 21730, loss = 0.250115
I0809 03:43:25.202257 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:43:25.202272 20451 solver.cpp:244]     Train net output #1: loss = 0.250115 (* 1 = 0.250115 loss)
I0809 03:43:25.202286 20451 sgd_solver.cpp:106] Iteration 21730, lr = 0.000420627
I0809 03:43:47.521507 20451 solver.cpp:228] Iteration 21740, loss = 0.187565
I0809 03:43:47.521608 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:43:47.521625 20451 solver.cpp:244]     Train net output #1: loss = 0.187565 (* 1 = 0.187565 loss)
I0809 03:43:47.521637 20451 sgd_solver.cpp:106] Iteration 21740, lr = 0.000420528
I0809 03:44:09.841588 20451 solver.cpp:228] Iteration 21750, loss = 0.281342
I0809 03:44:09.841641 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:44:09.841655 20451 solver.cpp:244]     Train net output #1: loss = 0.281342 (* 1 = 0.281342 loss)
I0809 03:44:09.841667 20451 sgd_solver.cpp:106] Iteration 21750, lr = 0.000420429
I0809 03:44:32.159092 20451 solver.cpp:228] Iteration 21760, loss = 0.156295
I0809 03:44:32.159277 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:44:32.159293 20451 solver.cpp:244]     Train net output #1: loss = 0.156295 (* 1 = 0.156295 loss)
I0809 03:44:32.159306 20451 sgd_solver.cpp:106] Iteration 21760, lr = 0.000420329
I0809 03:44:54.472767 20451 solver.cpp:228] Iteration 21770, loss = 0.18753
I0809 03:44:54.472820 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:44:54.472833 20451 solver.cpp:244]     Train net output #1: loss = 0.18753 (* 1 = 0.18753 loss)
I0809 03:44:54.472846 20451 sgd_solver.cpp:106] Iteration 21770, lr = 0.00042023
I0809 03:45:16.790406 20451 solver.cpp:228] Iteration 21780, loss = 0.218768
I0809 03:45:16.790611 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:45:16.790653 20451 solver.cpp:244]     Train net output #1: loss = 0.218768 (* 1 = 0.218768 loss)
I0809 03:45:16.790690 20451 sgd_solver.cpp:106] Iteration 21780, lr = 0.000420131
I0809 03:45:39.107725 20451 solver.cpp:228] Iteration 21790, loss = 0.187526
I0809 03:45:39.107779 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:45:39.107792 20451 solver.cpp:244]     Train net output #1: loss = 0.187526 (* 1 = 0.187526 loss)
I0809 03:45:39.107805 20451 sgd_solver.cpp:106] Iteration 21790, lr = 0.000420032
I0809 03:45:59.198765 20451 solver.cpp:337] Iteration 21800, Testing net (#0)
I0809 03:46:07.722506 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0809 03:46:07.722551 20451 solver.cpp:404]     Test net output #1: loss = 1.01258 (* 1 = 1.01258 loss)
I0809 03:46:09.927809 20451 solver.cpp:228] Iteration 21800, loss = 0.187708
I0809 03:46:09.927867 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:46:09.927881 20451 solver.cpp:244]     Train net output #1: loss = 0.187708 (* 1 = 0.187708 loss)
I0809 03:46:09.927894 20451 sgd_solver.cpp:106] Iteration 21800, lr = 0.000419933
I0809 03:46:32.222673 20451 solver.cpp:228] Iteration 21810, loss = 0.0937579
I0809 03:46:32.222846 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:46:32.222863 20451 solver.cpp:244]     Train net output #1: loss = 0.093758 (* 1 = 0.093758 loss)
I0809 03:46:32.222877 20451 sgd_solver.cpp:106] Iteration 21810, lr = 0.000419834
I0809 03:46:54.537077 20451 solver.cpp:228] Iteration 21820, loss = 0.0937776
I0809 03:46:54.537118 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:46:54.537133 20451 solver.cpp:244]     Train net output #1: loss = 0.0937777 (* 1 = 0.0937777 loss)
I0809 03:46:54.537147 20451 sgd_solver.cpp:106] Iteration 21820, lr = 0.000419735
I0809 03:47:16.854065 20451 solver.cpp:228] Iteration 21830, loss = 0.125234
I0809 03:47:16.854254 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:47:16.854269 20451 solver.cpp:244]     Train net output #1: loss = 0.125234 (* 1 = 0.125234 loss)
I0809 03:47:16.854281 20451 sgd_solver.cpp:106] Iteration 21830, lr = 0.000419636
I0809 03:47:39.163470 20451 solver.cpp:228] Iteration 21840, loss = 0.125021
I0809 03:47:39.163522 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:47:39.163537 20451 solver.cpp:244]     Train net output #1: loss = 0.125021 (* 1 = 0.125021 loss)
I0809 03:47:39.163547 20451 sgd_solver.cpp:106] Iteration 21840, lr = 0.000419537
I0809 03:48:01.477138 20451 solver.cpp:228] Iteration 21850, loss = 0.187652
I0809 03:48:01.477233 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:48:01.477249 20451 solver.cpp:244]     Train net output #1: loss = 0.187652 (* 1 = 0.187652 loss)
I0809 03:48:01.477262 20451 sgd_solver.cpp:106] Iteration 21850, lr = 0.000419438
I0809 03:48:23.800966 20451 solver.cpp:228] Iteration 21860, loss = 0.156268
I0809 03:48:23.801017 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:48:23.801031 20451 solver.cpp:244]     Train net output #1: loss = 0.156268 (* 1 = 0.156268 loss)
I0809 03:48:23.801043 20451 sgd_solver.cpp:106] Iteration 21860, lr = 0.000419339
I0809 03:48:46.112599 20451 solver.cpp:228] Iteration 21870, loss = 0.187554
I0809 03:48:46.112776 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:48:46.112792 20451 solver.cpp:244]     Train net output #1: loss = 0.187554 (* 1 = 0.187554 loss)
I0809 03:48:46.112803 20451 sgd_solver.cpp:106] Iteration 21870, lr = 0.000419241
I0809 03:49:08.432543 20451 solver.cpp:228] Iteration 21880, loss = 0.156364
I0809 03:49:08.432593 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:49:08.432607 20451 solver.cpp:244]     Train net output #1: loss = 0.156364 (* 1 = 0.156364 loss)
I0809 03:49:08.432620 20451 sgd_solver.cpp:106] Iteration 21880, lr = 0.000419142
I0809 03:49:30.737396 20451 solver.cpp:228] Iteration 21890, loss = 0.18752
I0809 03:49:30.737573 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:49:30.737588 20451 solver.cpp:244]     Train net output #1: loss = 0.18752 (* 1 = 0.18752 loss)
I0809 03:49:30.737601 20451 sgd_solver.cpp:106] Iteration 21890, lr = 0.000419044
I0809 03:49:50.828583 20451 solver.cpp:337] Iteration 21900, Testing net (#0)
I0809 03:49:59.357728 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 03:49:59.357771 20451 solver.cpp:404]     Test net output #1: loss = 0.984415 (* 1 = 0.984415 loss)
I0809 03:50:01.561820 20451 solver.cpp:228] Iteration 21900, loss = 0.281343
I0809 03:50:01.563024 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 03:50:01.563043 20451 solver.cpp:244]     Train net output #1: loss = 0.281343 (* 1 = 0.281343 loss)
I0809 03:50:01.563056 20451 sgd_solver.cpp:106] Iteration 21900, lr = 0.000418945
I0809 03:50:23.855531 20451 solver.cpp:228] Iteration 21910, loss = 0.343925
I0809 03:50:23.855573 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 03:50:23.855589 20451 solver.cpp:244]     Train net output #1: loss = 0.343925 (* 1 = 0.343925 loss)
I0809 03:50:23.855602 20451 sgd_solver.cpp:106] Iteration 21910, lr = 0.000418847
I0809 03:50:46.170111 20451 solver.cpp:228] Iteration 21920, loss = 0.0937586
I0809 03:50:46.170291 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:50:46.170306 20451 solver.cpp:244]     Train net output #1: loss = 0.0937588 (* 1 = 0.0937588 loss)
I0809 03:50:46.170320 20451 sgd_solver.cpp:106] Iteration 21920, lr = 0.000418748
I0809 03:51:08.492215 20451 solver.cpp:228] Iteration 21930, loss = 0.125009
I0809 03:51:08.492267 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:51:08.492282 20451 solver.cpp:244]     Train net output #1: loss = 0.125009 (* 1 = 0.125009 loss)
I0809 03:51:08.492295 20451 sgd_solver.cpp:106] Iteration 21930, lr = 0.00041865
I0809 03:51:30.812773 20451 solver.cpp:228] Iteration 21940, loss = 0.0937682
I0809 03:51:30.812950 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:51:30.812966 20451 solver.cpp:244]     Train net output #1: loss = 0.0937683 (* 1 = 0.0937683 loss)
I0809 03:51:30.812979 20451 sgd_solver.cpp:106] Iteration 21940, lr = 0.000418551
I0809 03:51:53.130080 20451 solver.cpp:228] Iteration 21950, loss = 0.156349
I0809 03:51:53.130131 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:51:53.130146 20451 solver.cpp:244]     Train net output #1: loss = 0.15635 (* 1 = 0.15635 loss)
I0809 03:51:53.130157 20451 sgd_solver.cpp:106] Iteration 21950, lr = 0.000418453
I0809 03:52:15.446450 20451 solver.cpp:228] Iteration 21960, loss = 0.15632
I0809 03:52:15.446627 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:52:15.446641 20451 solver.cpp:244]     Train net output #1: loss = 0.156321 (* 1 = 0.156321 loss)
I0809 03:52:15.446653 20451 sgd_solver.cpp:106] Iteration 21960, lr = 0.000418355
I0809 03:52:37.766352 20451 solver.cpp:228] Iteration 21970, loss = 0.187527
I0809 03:52:37.766397 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:52:37.766413 20451 solver.cpp:244]     Train net output #1: loss = 0.187528 (* 1 = 0.187528 loss)
I0809 03:52:37.766427 20451 sgd_solver.cpp:106] Iteration 21970, lr = 0.000418257
I0809 03:53:00.078261 20451 solver.cpp:228] Iteration 21980, loss = 0.125058
I0809 03:53:00.078440 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:53:00.078456 20451 solver.cpp:244]     Train net output #1: loss = 0.125058 (* 1 = 0.125058 loss)
I0809 03:53:00.078469 20451 sgd_solver.cpp:106] Iteration 21980, lr = 0.000418159
I0809 03:53:22.405947 20451 solver.cpp:228] Iteration 21990, loss = 0.125056
I0809 03:53:22.406002 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:53:22.406016 20451 solver.cpp:244]     Train net output #1: loss = 0.125056 (* 1 = 0.125056 loss)
I0809 03:53:22.406029 20451 sgd_solver.cpp:106] Iteration 21990, lr = 0.000418061
I0809 03:53:42.501823 20451 solver.cpp:337] Iteration 22000, Testing net (#0)
I0809 03:53:51.022671 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 03:53:51.022723 20451 solver.cpp:404]     Test net output #1: loss = 1.00346 (* 1 = 1.00346 loss)
I0809 03:53:53.228415 20451 solver.cpp:228] Iteration 22000, loss = 0.0312653
I0809 03:53:53.228466 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 03:53:53.228480 20451 solver.cpp:244]     Train net output #1: loss = 0.0312655 (* 1 = 0.0312655 loss)
I0809 03:53:53.228493 20451 sgd_solver.cpp:106] Iteration 22000, lr = 0.000417963
I0809 03:54:15.521214 20451 solver.cpp:228] Iteration 22010, loss = 0.250069
I0809 03:54:15.521432 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:54:15.521447 20451 solver.cpp:244]     Train net output #1: loss = 0.250069 (* 1 = 0.250069 loss)
I0809 03:54:15.521461 20451 sgd_solver.cpp:106] Iteration 22010, lr = 0.000417865
I0809 03:54:37.848111 20451 solver.cpp:228] Iteration 22020, loss = 0.250092
I0809 03:54:37.848163 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:54:37.848178 20451 solver.cpp:244]     Train net output #1: loss = 0.250092 (* 1 = 0.250092 loss)
I0809 03:54:37.848191 20451 sgd_solver.cpp:106] Iteration 22020, lr = 0.000417767
I0809 03:55:00.167237 20451 solver.cpp:228] Iteration 22030, loss = 0.281357
I0809 03:55:00.167412 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 03:55:00.167428 20451 solver.cpp:244]     Train net output #1: loss = 0.281357 (* 1 = 0.281357 loss)
I0809 03:55:00.167439 20451 sgd_solver.cpp:106] Iteration 22030, lr = 0.000417669
I0809 03:55:22.485539 20451 solver.cpp:228] Iteration 22040, loss = 0.125064
I0809 03:55:22.485590 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 03:55:22.485605 20451 solver.cpp:244]     Train net output #1: loss = 0.125064 (* 1 = 0.125064 loss)
I0809 03:55:22.485616 20451 sgd_solver.cpp:106] Iteration 22040, lr = 0.000417571
I0809 03:55:44.808481 20451 solver.cpp:228] Iteration 22050, loss = 0.21885
I0809 03:55:44.808666 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:55:44.808682 20451 solver.cpp:244]     Train net output #1: loss = 0.21885 (* 1 = 0.21885 loss)
I0809 03:55:44.808696 20451 sgd_solver.cpp:106] Iteration 22050, lr = 0.000417474
I0809 03:56:07.125020 20451 solver.cpp:228] Iteration 22060, loss = 0.218781
I0809 03:56:07.125073 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 03:56:07.125087 20451 solver.cpp:244]     Train net output #1: loss = 0.218781 (* 1 = 0.218781 loss)
I0809 03:56:07.125099 20451 sgd_solver.cpp:106] Iteration 22060, lr = 0.000417376
I0809 03:56:29.448321 20451 solver.cpp:228] Iteration 22070, loss = 0.156319
I0809 03:56:29.448498 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 03:56:29.448513 20451 solver.cpp:244]     Train net output #1: loss = 0.156319 (* 1 = 0.156319 loss)
I0809 03:56:29.448526 20451 sgd_solver.cpp:106] Iteration 22070, lr = 0.000417278
I0809 03:56:51.758517 20451 solver.cpp:228] Iteration 22080, loss = 0.250113
I0809 03:56:51.758566 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:56:51.758580 20451 solver.cpp:244]     Train net output #1: loss = 0.250113 (* 1 = 0.250113 loss)
I0809 03:56:51.758592 20451 sgd_solver.cpp:106] Iteration 22080, lr = 0.000417181
I0809 03:57:14.077390 20451 solver.cpp:228] Iteration 22090, loss = 0.18756
I0809 03:57:14.077566 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:57:14.077582 20451 solver.cpp:244]     Train net output #1: loss = 0.18756 (* 1 = 0.18756 loss)
I0809 03:57:14.077594 20451 sgd_solver.cpp:106] Iteration 22090, lr = 0.000417083
I0809 03:57:34.164222 20451 solver.cpp:337] Iteration 22100, Testing net (#0)
I0809 03:57:42.689985 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 03:57:42.690032 20451 solver.cpp:404]     Test net output #1: loss = 0.975151 (* 1 = 0.975151 loss)
I0809 03:57:44.894460 20451 solver.cpp:228] Iteration 22100, loss = 0.250057
I0809 03:57:44.894634 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 03:57:44.894652 20451 solver.cpp:244]     Train net output #1: loss = 0.250057 (* 1 = 0.250057 loss)
I0809 03:57:44.894667 20451 sgd_solver.cpp:106] Iteration 22100, lr = 0.000416986
I0809 03:58:07.191874 20451 solver.cpp:228] Iteration 22110, loss = 0.187572
I0809 03:58:07.191917 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:58:07.191934 20451 solver.cpp:244]     Train net output #1: loss = 0.187572 (* 1 = 0.187572 loss)
I0809 03:58:07.191961 20451 sgd_solver.cpp:106] Iteration 22110, lr = 0.000416888
I0809 03:58:29.506614 20451 solver.cpp:228] Iteration 22120, loss = 0.0937694
I0809 03:58:29.506827 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:58:29.506849 20451 solver.cpp:244]     Train net output #1: loss = 0.0937695 (* 1 = 0.0937695 loss)
I0809 03:58:29.506863 20451 sgd_solver.cpp:106] Iteration 22120, lr = 0.000416791
I0809 03:58:51.824476 20451 solver.cpp:228] Iteration 22130, loss = 0.187629
I0809 03:58:51.824532 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:58:51.824545 20451 solver.cpp:244]     Train net output #1: loss = 0.187629 (* 1 = 0.187629 loss)
I0809 03:58:51.824558 20451 sgd_solver.cpp:106] Iteration 22130, lr = 0.000416694
I0809 03:59:14.136874 20451 solver.cpp:228] Iteration 22140, loss = 0.0937676
I0809 03:59:14.137053 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:59:14.137068 20451 solver.cpp:244]     Train net output #1: loss = 0.0937677 (* 1 = 0.0937677 loss)
I0809 03:59:14.137081 20451 sgd_solver.cpp:106] Iteration 22140, lr = 0.000416597
I0809 03:59:36.454699 20451 solver.cpp:228] Iteration 22150, loss = 0.187552
I0809 03:59:36.454749 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 03:59:36.454762 20451 solver.cpp:244]     Train net output #1: loss = 0.187552 (* 1 = 0.187552 loss)
I0809 03:59:36.454774 20451 sgd_solver.cpp:106] Iteration 22150, lr = 0.000416499
I0809 03:59:58.774348 20451 solver.cpp:228] Iteration 22160, loss = 0.0937607
I0809 03:59:58.774442 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 03:59:58.774458 20451 solver.cpp:244]     Train net output #1: loss = 0.0937608 (* 1 = 0.0937608 loss)
I0809 03:59:58.774473 20451 sgd_solver.cpp:106] Iteration 22160, lr = 0.000416402
I0809 04:00:21.103549 20451 solver.cpp:228] Iteration 22170, loss = 0.0939221
I0809 04:00:21.103600 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:00:21.103615 20451 solver.cpp:244]     Train net output #1: loss = 0.0939222 (* 1 = 0.0939222 loss)
I0809 04:00:21.103627 20451 sgd_solver.cpp:106] Iteration 22170, lr = 0.000416305
I0809 04:00:43.434026 20451 solver.cpp:228] Iteration 22180, loss = 0.250065
I0809 04:00:43.434208 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 04:00:43.434222 20451 solver.cpp:244]     Train net output #1: loss = 0.250065 (* 1 = 0.250065 loss)
I0809 04:00:43.434234 20451 sgd_solver.cpp:106] Iteration 22180, lr = 0.000416208
I0809 04:01:05.756429 20451 solver.cpp:228] Iteration 22190, loss = 0.281348
I0809 04:01:05.756481 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:01:05.756495 20451 solver.cpp:244]     Train net output #1: loss = 0.281348 (* 1 = 0.281348 loss)
I0809 04:01:05.756507 20451 sgd_solver.cpp:106] Iteration 22190, lr = 0.000416111
I0809 04:01:25.845412 20451 solver.cpp:337] Iteration 22200, Testing net (#0)
I0809 04:01:34.370781 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0809 04:01:34.370833 20451 solver.cpp:404]     Test net output #1: loss = 1.01728 (* 1 = 1.01728 loss)
I0809 04:01:36.579228 20451 solver.cpp:228] Iteration 22200, loss = 0.218779
I0809 04:01:36.579283 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:01:36.579298 20451 solver.cpp:244]     Train net output #1: loss = 0.218779 (* 1 = 0.218779 loss)
I0809 04:01:36.579309 20451 sgd_solver.cpp:106] Iteration 22200, lr = 0.000416014
I0809 04:01:58.873656 20451 solver.cpp:228] Iteration 22210, loss = 0.250124
I0809 04:01:58.873769 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 04:01:58.873788 20451 solver.cpp:244]     Train net output #1: loss = 0.250125 (* 1 = 0.250125 loss)
I0809 04:01:58.873805 20451 sgd_solver.cpp:106] Iteration 22210, lr = 0.000415917
I0809 04:02:21.200580 20451 solver.cpp:228] Iteration 22220, loss = 0.156312
I0809 04:02:21.200623 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:02:21.200641 20451 solver.cpp:244]     Train net output #1: loss = 0.156312 (* 1 = 0.156312 loss)
I0809 04:02:21.200656 20451 sgd_solver.cpp:106] Iteration 22220, lr = 0.00041582
I0809 04:02:43.518051 20451 solver.cpp:228] Iteration 22230, loss = 0.28144
I0809 04:02:43.518272 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:02:43.518288 20451 solver.cpp:244]     Train net output #1: loss = 0.28144 (* 1 = 0.28144 loss)
I0809 04:02:43.518301 20451 sgd_solver.cpp:106] Iteration 22230, lr = 0.000415724
I0809 04:03:05.850765 20451 solver.cpp:228] Iteration 22240, loss = 0.156477
I0809 04:03:05.850811 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:03:05.850826 20451 solver.cpp:244]     Train net output #1: loss = 0.156477 (* 1 = 0.156477 loss)
I0809 04:03:05.850837 20451 sgd_solver.cpp:106] Iteration 22240, lr = 0.000415627
I0809 04:03:28.177923 20451 solver.cpp:228] Iteration 22250, loss = 0.187822
I0809 04:03:28.178099 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:03:28.178115 20451 solver.cpp:244]     Train net output #1: loss = 0.187822 (* 1 = 0.187822 loss)
I0809 04:03:28.178128 20451 sgd_solver.cpp:106] Iteration 22250, lr = 0.00041553
I0809 04:03:50.497831 20451 solver.cpp:228] Iteration 22260, loss = 0.312511
I0809 04:03:50.497874 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 04:03:50.497889 20451 solver.cpp:244]     Train net output #1: loss = 0.312511 (* 1 = 0.312511 loss)
I0809 04:03:50.497901 20451 sgd_solver.cpp:106] Iteration 22260, lr = 0.000415434
I0809 04:04:12.817921 20451 solver.cpp:228] Iteration 22270, loss = 0.18762
I0809 04:04:12.818106 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:04:12.818122 20451 solver.cpp:244]     Train net output #1: loss = 0.187621 (* 1 = 0.187621 loss)
I0809 04:04:12.818135 20451 sgd_solver.cpp:106] Iteration 22270, lr = 0.000415337
I0809 04:04:35.144237 20451 solver.cpp:228] Iteration 22280, loss = 0.156259
I0809 04:04:35.144289 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:04:35.144302 20451 solver.cpp:244]     Train net output #1: loss = 0.15626 (* 1 = 0.15626 loss)
I0809 04:04:35.144315 20451 sgd_solver.cpp:106] Iteration 22280, lr = 0.000415241
I0809 04:04:57.460440 20451 solver.cpp:228] Iteration 22290, loss = 0.125022
I0809 04:04:57.460618 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:04:57.460634 20451 solver.cpp:244]     Train net output #1: loss = 0.125022 (* 1 = 0.125022 loss)
I0809 04:04:57.460647 20451 sgd_solver.cpp:106] Iteration 22290, lr = 0.000415144
I0809 04:05:17.556179 20451 solver.cpp:337] Iteration 22300, Testing net (#0)
I0809 04:05:26.089385 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 04:05:26.089427 20451 solver.cpp:404]     Test net output #1: loss = 1.00321 (* 1 = 1.00321 loss)
I0809 04:05:28.293365 20451 solver.cpp:228] Iteration 22300, loss = 0.0937618
I0809 04:05:28.293541 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:05:28.293556 20451 solver.cpp:244]     Train net output #1: loss = 0.0937619 (* 1 = 0.0937619 loss)
I0809 04:05:28.293568 20451 sgd_solver.cpp:106] Iteration 22300, lr = 0.000415048
I0809 04:05:50.596191 20451 solver.cpp:228] Iteration 22310, loss = 0.250047
I0809 04:05:50.596243 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 04:05:50.596257 20451 solver.cpp:244]     Train net output #1: loss = 0.250047 (* 1 = 0.250047 loss)
I0809 04:05:50.596269 20451 sgd_solver.cpp:106] Iteration 22310, lr = 0.000414951
I0809 04:06:12.923607 20451 solver.cpp:228] Iteration 22320, loss = 0.125009
I0809 04:06:12.923717 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:06:12.923737 20451 solver.cpp:244]     Train net output #1: loss = 0.125009 (* 1 = 0.125009 loss)
I0809 04:06:12.923750 20451 sgd_solver.cpp:106] Iteration 22320, lr = 0.000414855
I0809 04:06:35.244179 20451 solver.cpp:228] Iteration 22330, loss = 0.218754
I0809 04:06:35.244232 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:06:35.244246 20451 solver.cpp:244]     Train net output #1: loss = 0.218754 (* 1 = 0.218754 loss)
I0809 04:06:35.244258 20451 sgd_solver.cpp:106] Iteration 22330, lr = 0.000414759
I0809 04:06:57.563217 20451 solver.cpp:228] Iteration 22340, loss = 0.218828
I0809 04:06:57.563433 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:06:57.563448 20451 solver.cpp:244]     Train net output #1: loss = 0.218828 (* 1 = 0.218828 loss)
I0809 04:06:57.563462 20451 sgd_solver.cpp:106] Iteration 22340, lr = 0.000414663
I0809 04:07:19.886364 20451 solver.cpp:228] Iteration 22350, loss = 0.281355
I0809 04:07:19.886420 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:07:19.886433 20451 solver.cpp:244]     Train net output #1: loss = 0.281355 (* 1 = 0.281355 loss)
I0809 04:07:19.886445 20451 sgd_solver.cpp:106] Iteration 22350, lr = 0.000414567
I0809 04:07:42.194597 20451 solver.cpp:228] Iteration 22360, loss = 0.0625279
I0809 04:07:42.194701 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 04:07:42.194716 20451 solver.cpp:244]     Train net output #1: loss = 0.062528 (* 1 = 0.062528 loss)
I0809 04:07:42.194730 20451 sgd_solver.cpp:106] Iteration 22360, lr = 0.000414471
I0809 04:08:04.508858 20451 solver.cpp:228] Iteration 22370, loss = 0.281376
I0809 04:08:04.508911 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:08:04.508924 20451 solver.cpp:244]     Train net output #1: loss = 0.281376 (* 1 = 0.281376 loss)
I0809 04:08:04.508936 20451 sgd_solver.cpp:106] Iteration 22370, lr = 0.000414374
I0809 04:08:26.835114 20451 solver.cpp:228] Iteration 22380, loss = 0.156425
I0809 04:08:26.835237 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:08:26.835256 20451 solver.cpp:244]     Train net output #1: loss = 0.156426 (* 1 = 0.156426 loss)
I0809 04:08:26.835276 20451 sgd_solver.cpp:106] Iteration 22380, lr = 0.000414279
I0809 04:08:49.157033 20451 solver.cpp:228] Iteration 22390, loss = 0.187577
I0809 04:08:49.157075 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:08:49.157094 20451 solver.cpp:244]     Train net output #1: loss = 0.187577 (* 1 = 0.187577 loss)
I0809 04:08:49.157109 20451 sgd_solver.cpp:106] Iteration 22390, lr = 0.000414183
I0809 04:09:09.248884 20451 solver.cpp:337] Iteration 22400, Testing net (#0)
I0809 04:09:17.774276 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 04:09:17.774327 20451 solver.cpp:404]     Test net output #1: loss = 0.975083 (* 1 = 0.975083 loss)
I0809 04:09:19.976362 20451 solver.cpp:228] Iteration 22400, loss = 0.343792
I0809 04:09:19.976418 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 04:09:19.976433 20451 solver.cpp:244]     Train net output #1: loss = 0.343792 (* 1 = 0.343792 loss)
I0809 04:09:19.976445 20451 sgd_solver.cpp:106] Iteration 22400, lr = 0.000414087
I0809 04:09:42.270141 20451 solver.cpp:228] Iteration 22410, loss = 0.0625363
I0809 04:09:42.270329 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 04:09:42.270349 20451 solver.cpp:244]     Train net output #1: loss = 0.0625365 (* 1 = 0.0625365 loss)
I0809 04:09:42.270364 20451 sgd_solver.cpp:106] Iteration 22410, lr = 0.000413991
I0809 04:10:04.584383 20451 solver.cpp:228] Iteration 22420, loss = 0.250033
I0809 04:10:04.584434 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 04:10:04.584448 20451 solver.cpp:244]     Train net output #1: loss = 0.250033 (* 1 = 0.250033 loss)
I0809 04:10:04.584460 20451 sgd_solver.cpp:106] Iteration 22420, lr = 0.000413895
I0809 04:10:26.887356 20451 solver.cpp:228] Iteration 22430, loss = 0.0938093
I0809 04:10:26.887459 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:10:26.887480 20451 solver.cpp:244]     Train net output #1: loss = 0.0938095 (* 1 = 0.0938095 loss)
I0809 04:10:26.887495 20451 sgd_solver.cpp:106] Iteration 22430, lr = 0.000413799
I0809 04:10:49.201017 20451 solver.cpp:228] Iteration 22440, loss = 0.0625102
I0809 04:10:49.201066 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 04:10:49.201081 20451 solver.cpp:244]     Train net output #1: loss = 0.0625104 (* 1 = 0.0625104 loss)
I0809 04:10:49.201094 20451 sgd_solver.cpp:106] Iteration 22440, lr = 0.000413704
I0809 04:11:11.513890 20451 solver.cpp:228] Iteration 22450, loss = 0.156326
I0809 04:11:11.514039 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:11:11.514053 20451 solver.cpp:244]     Train net output #1: loss = 0.156326 (* 1 = 0.156326 loss)
I0809 04:11:11.514066 20451 sgd_solver.cpp:106] Iteration 22450, lr = 0.000413608
I0809 04:11:33.823885 20451 solver.cpp:228] Iteration 22460, loss = 0.250174
I0809 04:11:33.823936 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 04:11:33.823951 20451 solver.cpp:244]     Train net output #1: loss = 0.250174 (* 1 = 0.250174 loss)
I0809 04:11:33.823962 20451 sgd_solver.cpp:106] Iteration 22460, lr = 0.000413512
I0809 04:11:56.134033 20451 solver.cpp:228] Iteration 22470, loss = 0.156386
I0809 04:11:56.134212 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:11:56.134227 20451 solver.cpp:244]     Train net output #1: loss = 0.156386 (* 1 = 0.156386 loss)
I0809 04:11:56.134240 20451 sgd_solver.cpp:106] Iteration 22470, lr = 0.000413417
I0809 04:12:18.455747 20451 solver.cpp:228] Iteration 22480, loss = 0.219106
I0809 04:12:18.455802 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:12:18.455816 20451 solver.cpp:244]     Train net output #1: loss = 0.219106 (* 1 = 0.219106 loss)
I0809 04:12:18.455828 20451 sgd_solver.cpp:106] Iteration 22480, lr = 0.000413322
I0809 04:12:40.772735 20451 solver.cpp:228] Iteration 22490, loss = 0.0940282
I0809 04:12:40.772840 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:12:40.772861 20451 solver.cpp:244]     Train net output #1: loss = 0.0940283 (* 1 = 0.0940283 loss)
I0809 04:12:40.772876 20451 sgd_solver.cpp:106] Iteration 22490, lr = 0.000413226
I0809 04:13:00.862989 20451 solver.cpp:337] Iteration 22500, Testing net (#0)
I0809 04:13:09.388854 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 04:13:09.388906 20451 solver.cpp:404]     Test net output #1: loss = 0.994667 (* 1 = 0.994667 loss)
I0809 04:13:11.596089 20451 solver.cpp:228] Iteration 22500, loss = 0.281728
I0809 04:13:11.596266 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:13:11.596282 20451 solver.cpp:244]     Train net output #1: loss = 0.281728 (* 1 = 0.281728 loss)
I0809 04:13:11.596294 20451 sgd_solver.cpp:106] Iteration 22500, lr = 0.000413131
I0809 04:13:33.882120 20451 solver.cpp:228] Iteration 22510, loss = 0.187528
I0809 04:13:33.882171 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:13:33.882185 20451 solver.cpp:244]     Train net output #1: loss = 0.187528 (* 1 = 0.187528 loss)
I0809 04:13:33.882197 20451 sgd_solver.cpp:106] Iteration 22510, lr = 0.000413035
I0809 04:13:56.187389 20451 solver.cpp:228] Iteration 22520, loss = 0.156346
I0809 04:13:56.187572 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:13:56.187587 20451 solver.cpp:244]     Train net output #1: loss = 0.156347 (* 1 = 0.156347 loss)
I0809 04:13:56.187599 20451 sgd_solver.cpp:106] Iteration 22520, lr = 0.00041294
I0809 04:14:18.500236 20451 solver.cpp:228] Iteration 22530, loss = 0.250093
I0809 04:14:18.500286 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:14:18.500303 20451 solver.cpp:244]     Train net output #1: loss = 0.250093 (* 1 = 0.250093 loss)
I0809 04:14:18.500319 20451 sgd_solver.cpp:106] Iteration 22530, lr = 0.000412845
I0809 04:14:40.805826 20451 solver.cpp:228] Iteration 22540, loss = 0.156249
I0809 04:14:40.805924 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:14:40.805943 20451 solver.cpp:244]     Train net output #1: loss = 0.156249 (* 1 = 0.156249 loss)
I0809 04:14:40.805959 20451 sgd_solver.cpp:106] Iteration 22540, lr = 0.00041275
I0809 04:15:03.119133 20451 solver.cpp:228] Iteration 22550, loss = 0.218914
I0809 04:15:03.119194 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:15:03.119207 20451 solver.cpp:244]     Train net output #1: loss = 0.218914 (* 1 = 0.218914 loss)
I0809 04:15:03.119220 20451 sgd_solver.cpp:106] Iteration 22550, lr = 0.000412655
I0809 04:15:25.426738 20451 solver.cpp:228] Iteration 22560, loss = 0.125024
I0809 04:15:25.426934 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:15:25.426949 20451 solver.cpp:244]     Train net output #1: loss = 0.125024 (* 1 = 0.125024 loss)
I0809 04:15:25.426962 20451 sgd_solver.cpp:106] Iteration 22560, lr = 0.00041256
I0809 04:15:47.739967 20451 solver.cpp:228] Iteration 22570, loss = 0.281304
I0809 04:15:47.740018 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:15:47.740032 20451 solver.cpp:244]     Train net output #1: loss = 0.281305 (* 1 = 0.281305 loss)
I0809 04:15:47.740044 20451 sgd_solver.cpp:106] Iteration 22570, lr = 0.000412465
I0809 04:16:10.055542 20451 solver.cpp:228] Iteration 22580, loss = 0.187562
I0809 04:16:10.055724 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:16:10.055739 20451 solver.cpp:244]     Train net output #1: loss = 0.187562 (* 1 = 0.187562 loss)
I0809 04:16:10.055752 20451 sgd_solver.cpp:106] Iteration 22580, lr = 0.00041237
I0809 04:16:32.367722 20451 solver.cpp:228] Iteration 22590, loss = 0.0626704
I0809 04:16:32.367774 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:16:32.367789 20451 solver.cpp:244]     Train net output #1: loss = 0.0626705 (* 1 = 0.0626705 loss)
I0809 04:16:32.367800 20451 sgd_solver.cpp:106] Iteration 22590, lr = 0.000412275
I0809 04:16:52.441241 20451 solver.cpp:337] Iteration 22600, Testing net (#0)
I0809 04:17:00.972626 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 04:17:00.972679 20451 solver.cpp:404]     Test net output #1: loss = 1.00317 (* 1 = 1.00317 loss)
I0809 04:17:03.176443 20451 solver.cpp:228] Iteration 22600, loss = 0.312521
I0809 04:17:03.176493 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 04:17:03.176509 20451 solver.cpp:244]     Train net output #1: loss = 0.312521 (* 1 = 0.312521 loss)
I0809 04:17:03.176524 20451 sgd_solver.cpp:106] Iteration 22600, lr = 0.00041218
I0809 04:17:25.457408 20451 solver.cpp:228] Iteration 22610, loss = 0.0937717
I0809 04:17:25.457587 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:17:25.457602 20451 solver.cpp:244]     Train net output #1: loss = 0.0937718 (* 1 = 0.0937718 loss)
I0809 04:17:25.457615 20451 sgd_solver.cpp:106] Iteration 22610, lr = 0.000412085
I0809 04:17:47.771607 20451 solver.cpp:228] Iteration 22620, loss = 0.187586
I0809 04:17:47.771659 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:17:47.771673 20451 solver.cpp:244]     Train net output #1: loss = 0.187587 (* 1 = 0.187587 loss)
I0809 04:17:47.771685 20451 sgd_solver.cpp:106] Iteration 22620, lr = 0.00041199
I0809 04:18:10.087806 20451 solver.cpp:228] Iteration 22630, loss = 0.187604
I0809 04:18:10.087982 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:18:10.087997 20451 solver.cpp:244]     Train net output #1: loss = 0.187604 (* 1 = 0.187604 loss)
I0809 04:18:10.088011 20451 sgd_solver.cpp:106] Iteration 22630, lr = 0.000411896
I0809 04:18:32.392890 20451 solver.cpp:228] Iteration 22640, loss = 0.281356
I0809 04:18:32.392943 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:18:32.392957 20451 solver.cpp:244]     Train net output #1: loss = 0.281356 (* 1 = 0.281356 loss)
I0809 04:18:32.392971 20451 sgd_solver.cpp:106] Iteration 22640, lr = 0.000411801
I0809 04:18:54.700405 20451 solver.cpp:228] Iteration 22650, loss = 0.250113
I0809 04:18:54.700588 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 04:18:54.700603 20451 solver.cpp:244]     Train net output #1: loss = 0.250113 (* 1 = 0.250113 loss)
I0809 04:18:54.700615 20451 sgd_solver.cpp:106] Iteration 22650, lr = 0.000411706
I0809 04:19:17.002612 20451 solver.cpp:228] Iteration 22660, loss = 0.0937997
I0809 04:19:17.002665 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:19:17.002679 20451 solver.cpp:244]     Train net output #1: loss = 0.0937999 (* 1 = 0.0937999 loss)
I0809 04:19:17.002691 20451 sgd_solver.cpp:106] Iteration 22660, lr = 0.000411612
I0809 04:19:39.317422 20451 solver.cpp:228] Iteration 22670, loss = 0.187513
I0809 04:19:39.317575 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:19:39.317595 20451 solver.cpp:244]     Train net output #1: loss = 0.187513 (* 1 = 0.187513 loss)
I0809 04:19:39.317608 20451 sgd_solver.cpp:106] Iteration 22670, lr = 0.000411517
I0809 04:20:01.629523 20451 solver.cpp:228] Iteration 22680, loss = 0.187591
I0809 04:20:01.629575 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:20:01.629588 20451 solver.cpp:244]     Train net output #1: loss = 0.187591 (* 1 = 0.187591 loss)
I0809 04:20:01.629601 20451 sgd_solver.cpp:106] Iteration 22680, lr = 0.000411423
I0809 04:20:23.943672 20451 solver.cpp:228] Iteration 22690, loss = 0.0937962
I0809 04:20:23.943786 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:20:23.943801 20451 solver.cpp:244]     Train net output #1: loss = 0.0937964 (* 1 = 0.0937964 loss)
I0809 04:20:23.943814 20451 sgd_solver.cpp:106] Iteration 22690, lr = 0.000411329
I0809 04:20:44.024395 20451 solver.cpp:337] Iteration 22700, Testing net (#0)
I0809 04:20:52.547150 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0809 04:20:52.547201 20451 solver.cpp:404]     Test net output #1: loss = 0.965664 (* 1 = 0.965664 loss)
I0809 04:20:54.750404 20451 solver.cpp:228] Iteration 22700, loss = 0.0938473
I0809 04:20:54.750494 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:20:54.750510 20451 solver.cpp:244]     Train net output #1: loss = 0.0938475 (* 1 = 0.0938475 loss)
I0809 04:20:54.750524 20451 sgd_solver.cpp:106] Iteration 22700, lr = 0.000411234
I0809 04:21:17.020530 20451 solver.cpp:228] Iteration 22710, loss = 0.218802
I0809 04:21:17.020584 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:21:17.020598 20451 solver.cpp:244]     Train net output #1: loss = 0.218802 (* 1 = 0.218802 loss)
I0809 04:21:17.020611 20451 sgd_solver.cpp:106] Iteration 22710, lr = 0.00041114
I0809 04:21:39.324775 20451 solver.cpp:228] Iteration 22720, loss = 0.156303
I0809 04:21:39.324959 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:21:39.324973 20451 solver.cpp:244]     Train net output #1: loss = 0.156303 (* 1 = 0.156303 loss)
I0809 04:21:39.324986 20451 sgd_solver.cpp:106] Iteration 22720, lr = 0.000411046
I0809 04:22:01.634068 20451 solver.cpp:228] Iteration 22730, loss = 0.187546
I0809 04:22:01.634125 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:22:01.634140 20451 solver.cpp:244]     Train net output #1: loss = 0.187547 (* 1 = 0.187547 loss)
I0809 04:22:01.634151 20451 sgd_solver.cpp:106] Iteration 22730, lr = 0.000410951
I0809 04:22:23.950521 20451 solver.cpp:228] Iteration 22740, loss = 0.281423
I0809 04:22:23.950700 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:22:23.950716 20451 solver.cpp:244]     Train net output #1: loss = 0.281423 (* 1 = 0.281423 loss)
I0809 04:22:23.950728 20451 sgd_solver.cpp:106] Iteration 22740, lr = 0.000410857
I0809 04:22:46.253501 20451 solver.cpp:228] Iteration 22750, loss = 0.156383
I0809 04:22:46.253553 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:22:46.253567 20451 solver.cpp:244]     Train net output #1: loss = 0.156383 (* 1 = 0.156383 loss)
I0809 04:22:46.253578 20451 sgd_solver.cpp:106] Iteration 22750, lr = 0.000410763
I0809 04:23:08.559348 20451 solver.cpp:228] Iteration 22760, loss = 0.0312815
I0809 04:23:08.559458 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 04:23:08.559476 20451 solver.cpp:244]     Train net output #1: loss = 0.0312817 (* 1 = 0.0312817 loss)
I0809 04:23:08.559492 20451 sgd_solver.cpp:106] Iteration 22760, lr = 0.000410669
I0809 04:23:30.864074 20451 solver.cpp:228] Iteration 22770, loss = 0.187691
I0809 04:23:30.864117 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:23:30.864143 20451 solver.cpp:244]     Train net output #1: loss = 0.187691 (* 1 = 0.187691 loss)
I0809 04:23:30.864159 20451 sgd_solver.cpp:106] Iteration 22770, lr = 0.000410575
I0809 04:23:53.165679 20451 solver.cpp:228] Iteration 22780, loss = 0.218878
I0809 04:23:53.165884 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:23:53.165904 20451 solver.cpp:244]     Train net output #1: loss = 0.218878 (* 1 = 0.218878 loss)
I0809 04:23:53.165917 20451 sgd_solver.cpp:106] Iteration 22780, lr = 0.000410481
I0809 04:24:15.476683 20451 solver.cpp:228] Iteration 22790, loss = 0.187809
I0809 04:24:15.476734 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:24:15.476748 20451 solver.cpp:244]     Train net output #1: loss = 0.187809 (* 1 = 0.187809 loss)
I0809 04:24:15.476760 20451 sgd_solver.cpp:106] Iteration 22790, lr = 0.000410387
I0809 04:24:35.555146 20451 solver.cpp:337] Iteration 22800, Testing net (#0)
I0809 04:24:44.074291 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0809 04:24:44.074337 20451 solver.cpp:404]     Test net output #1: loss = 1.03194 (* 1 = 1.03194 loss)
I0809 04:24:46.276666 20451 solver.cpp:228] Iteration 22800, loss = 0.0625621
I0809 04:24:46.276708 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 04:24:46.276726 20451 solver.cpp:244]     Train net output #1: loss = 0.0625623 (* 1 = 0.0625623 loss)
I0809 04:24:46.276752 20451 sgd_solver.cpp:106] Iteration 22800, lr = 0.000410293
I0809 04:25:08.565014 20451 solver.cpp:228] Iteration 22810, loss = 0.125138
I0809 04:25:08.565194 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:25:08.565209 20451 solver.cpp:244]     Train net output #1: loss = 0.125138 (* 1 = 0.125138 loss)
I0809 04:25:08.565222 20451 sgd_solver.cpp:106] Iteration 22810, lr = 0.0004102
I0809 04:25:30.875196 20451 solver.cpp:228] Iteration 22820, loss = 0.219064
I0809 04:25:30.875236 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:25:30.875252 20451 solver.cpp:244]     Train net output #1: loss = 0.219064 (* 1 = 0.219064 loss)
I0809 04:25:30.875263 20451 sgd_solver.cpp:106] Iteration 22820, lr = 0.000410106
I0809 04:25:53.191715 20451 solver.cpp:228] Iteration 22830, loss = 0.281287
I0809 04:25:53.191900 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 04:25:53.191918 20451 solver.cpp:244]     Train net output #1: loss = 0.281287 (* 1 = 0.281287 loss)
I0809 04:25:53.191934 20451 sgd_solver.cpp:106] Iteration 22830, lr = 0.000410012
I0809 04:26:15.506827 20451 solver.cpp:228] Iteration 22840, loss = 0.281424
I0809 04:26:15.506871 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:26:15.506901 20451 solver.cpp:244]     Train net output #1: loss = 0.281424 (* 1 = 0.281424 loss)
I0809 04:26:15.506917 20451 sgd_solver.cpp:106] Iteration 22840, lr = 0.000409919
I0809 04:26:37.811013 20451 solver.cpp:228] Iteration 22850, loss = 0.125029
I0809 04:26:37.811139 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:26:37.811157 20451 solver.cpp:244]     Train net output #1: loss = 0.125029 (* 1 = 0.125029 loss)
I0809 04:26:37.811172 20451 sgd_solver.cpp:106] Iteration 22850, lr = 0.000409825
I0809 04:27:00.124610 20451 solver.cpp:228] Iteration 22860, loss = 0.218858
I0809 04:27:00.124660 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:27:00.124678 20451 solver.cpp:244]     Train net output #1: loss = 0.218859 (* 1 = 0.218859 loss)
I0809 04:27:00.124694 20451 sgd_solver.cpp:106] Iteration 22860, lr = 0.000409731
I0809 04:27:22.441725 20451 solver.cpp:228] Iteration 22870, loss = 0.187566
I0809 04:27:22.441862 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:27:22.441877 20451 solver.cpp:244]     Train net output #1: loss = 0.187566 (* 1 = 0.187566 loss)
I0809 04:27:22.441890 20451 sgd_solver.cpp:106] Iteration 22870, lr = 0.000409638
I0809 04:27:44.753253 20451 solver.cpp:228] Iteration 22880, loss = 0.218854
I0809 04:27:44.753304 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:27:44.753319 20451 solver.cpp:244]     Train net output #1: loss = 0.218854 (* 1 = 0.218854 loss)
I0809 04:27:44.753331 20451 sgd_solver.cpp:106] Iteration 22880, lr = 0.000409545
I0809 04:28:07.068796 20451 solver.cpp:228] Iteration 22890, loss = 0.187553
I0809 04:28:07.068980 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:28:07.069002 20451 solver.cpp:244]     Train net output #1: loss = 0.187553 (* 1 = 0.187553 loss)
I0809 04:28:07.069018 20451 sgd_solver.cpp:106] Iteration 22890, lr = 0.000409451
I0809 04:28:27.160980 20451 solver.cpp:337] Iteration 22900, Testing net (#0)
I0809 04:28:35.693598 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 04:28:35.693644 20451 solver.cpp:404]     Test net output #1: loss = 1.00342 (* 1 = 1.00342 loss)
I0809 04:28:37.899833 20451 solver.cpp:228] Iteration 22900, loss = 0.218846
I0809 04:28:37.899945 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:28:37.899965 20451 solver.cpp:244]     Train net output #1: loss = 0.218846 (* 1 = 0.218846 loss)
I0809 04:28:37.899981 20451 sgd_solver.cpp:106] Iteration 22900, lr = 0.000409358
I0809 04:29:00.183609 20451 solver.cpp:228] Iteration 22910, loss = 0.281408
I0809 04:29:00.183651 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:29:00.183666 20451 solver.cpp:244]     Train net output #1: loss = 0.281408 (* 1 = 0.281408 loss)
I0809 04:29:00.183679 20451 sgd_solver.cpp:106] Iteration 22910, lr = 0.000409265
I0809 04:29:22.495842 20451 solver.cpp:228] Iteration 22920, loss = 0.125031
I0809 04:29:22.496024 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:29:22.496039 20451 solver.cpp:244]     Train net output #1: loss = 0.125031 (* 1 = 0.125031 loss)
I0809 04:29:22.496052 20451 sgd_solver.cpp:106] Iteration 22920, lr = 0.000409171
I0809 04:29:44.809193 20451 solver.cpp:228] Iteration 22930, loss = 0.0938085
I0809 04:29:44.809247 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:29:44.809262 20451 solver.cpp:244]     Train net output #1: loss = 0.0938088 (* 1 = 0.0938088 loss)
I0809 04:29:44.809273 20451 sgd_solver.cpp:106] Iteration 22930, lr = 0.000409078
I0809 04:30:07.127861 20451 solver.cpp:228] Iteration 22940, loss = 0.0625228
I0809 04:30:07.128038 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 04:30:07.128053 20451 solver.cpp:244]     Train net output #1: loss = 0.062523 (* 1 = 0.062523 loss)
I0809 04:30:07.128067 20451 sgd_solver.cpp:106] Iteration 22940, lr = 0.000408985
I0809 04:30:29.443572 20451 solver.cpp:228] Iteration 22950, loss = 0.156274
I0809 04:30:29.443625 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:30:29.443639 20451 solver.cpp:244]     Train net output #1: loss = 0.156274 (* 1 = 0.156274 loss)
I0809 04:30:29.443651 20451 sgd_solver.cpp:106] Iteration 22950, lr = 0.000408892
I0809 04:30:51.759393 20451 solver.cpp:228] Iteration 22960, loss = 0.0937553
I0809 04:30:51.759563 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:30:51.759578 20451 solver.cpp:244]     Train net output #1: loss = 0.0937555 (* 1 = 0.0937555 loss)
I0809 04:30:51.759591 20451 sgd_solver.cpp:106] Iteration 22960, lr = 0.000408799
I0809 04:31:14.088186 20451 solver.cpp:228] Iteration 22970, loss = 0.156307
I0809 04:31:14.088228 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:31:14.088246 20451 solver.cpp:244]     Train net output #1: loss = 0.156308 (* 1 = 0.156308 loss)
I0809 04:31:14.088259 20451 sgd_solver.cpp:106] Iteration 22970, lr = 0.000408706
I0809 04:31:36.400387 20451 solver.cpp:228] Iteration 22980, loss = 0.18753
I0809 04:31:36.400605 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:31:36.400621 20451 solver.cpp:244]     Train net output #1: loss = 0.18753 (* 1 = 0.18753 loss)
I0809 04:31:36.400634 20451 sgd_solver.cpp:106] Iteration 22980, lr = 0.000408613
I0809 04:31:58.711148 20451 solver.cpp:228] Iteration 22990, loss = 0.0937794
I0809 04:31:58.711192 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:31:58.711208 20451 solver.cpp:244]     Train net output #1: loss = 0.0937796 (* 1 = 0.0937796 loss)
I0809 04:31:58.711221 20451 sgd_solver.cpp:106] Iteration 22990, lr = 0.00040852
I0809 04:32:18.807062 20451 solver.cpp:337] Iteration 23000, Testing net (#0)
I0809 04:32:27.332268 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 04:32:27.332320 20451 solver.cpp:404]     Test net output #1: loss = 0.984397 (* 1 = 0.984397 loss)
I0809 04:32:29.534965 20451 solver.cpp:228] Iteration 23000, loss = 0.312511
I0809 04:32:29.535017 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 04:32:29.535030 20451 solver.cpp:244]     Train net output #1: loss = 0.312511 (* 1 = 0.312511 loss)
I0809 04:32:29.535043 20451 sgd_solver.cpp:106] Iteration 23000, lr = 0.000408427
I0809 04:32:51.830777 20451 solver.cpp:228] Iteration 23010, loss = 0.218758
I0809 04:32:51.830955 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:32:51.830971 20451 solver.cpp:244]     Train net output #1: loss = 0.218759 (* 1 = 0.218759 loss)
I0809 04:32:51.830984 20451 sgd_solver.cpp:106] Iteration 23010, lr = 0.000408334
I0809 04:33:14.149591 20451 solver.cpp:228] Iteration 23020, loss = 0.218761
I0809 04:33:14.149644 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:33:14.149658 20451 solver.cpp:244]     Train net output #1: loss = 0.218761 (* 1 = 0.218761 loss)
I0809 04:33:14.149670 20451 sgd_solver.cpp:106] Iteration 23020, lr = 0.000408242
I0809 04:33:36.462746 20451 solver.cpp:228] Iteration 23030, loss = 0.156294
I0809 04:33:36.462931 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:33:36.462946 20451 solver.cpp:244]     Train net output #1: loss = 0.156294 (* 1 = 0.156294 loss)
I0809 04:33:36.462960 20451 sgd_solver.cpp:106] Iteration 23030, lr = 0.000408149
I0809 04:33:58.766754 20451 solver.cpp:228] Iteration 23040, loss = 0.156288
I0809 04:33:58.766804 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:33:58.766824 20451 solver.cpp:244]     Train net output #1: loss = 0.156288 (* 1 = 0.156288 loss)
I0809 04:33:58.766839 20451 sgd_solver.cpp:106] Iteration 23040, lr = 0.000408056
I0809 04:34:21.077888 20451 solver.cpp:228] Iteration 23050, loss = 0.218829
I0809 04:34:21.077987 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:34:21.078002 20451 solver.cpp:244]     Train net output #1: loss = 0.218829 (* 1 = 0.218829 loss)
I0809 04:34:21.078016 20451 sgd_solver.cpp:106] Iteration 23050, lr = 0.000407964
I0809 04:34:43.402612 20451 solver.cpp:228] Iteration 23060, loss = 0.187635
I0809 04:34:43.402663 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:34:43.402678 20451 solver.cpp:244]     Train net output #1: loss = 0.187635 (* 1 = 0.187635 loss)
I0809 04:34:43.402689 20451 sgd_solver.cpp:106] Iteration 23060, lr = 0.000407871
I0809 04:35:05.714381 20451 solver.cpp:228] Iteration 23070, loss = 0.187591
I0809 04:35:05.714560 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:35:05.714576 20451 solver.cpp:244]     Train net output #1: loss = 0.187592 (* 1 = 0.187592 loss)
I0809 04:35:05.714588 20451 sgd_solver.cpp:106] Iteration 23070, lr = 0.000407779
I0809 04:35:28.027732 20451 solver.cpp:228] Iteration 23080, loss = 0.156297
I0809 04:35:28.027787 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:35:28.027801 20451 solver.cpp:244]     Train net output #1: loss = 0.156297 (* 1 = 0.156297 loss)
I0809 04:35:28.027813 20451 sgd_solver.cpp:106] Iteration 23080, lr = 0.000407686
I0809 04:35:50.338434 20451 solver.cpp:228] Iteration 23090, loss = 0.0937765
I0809 04:35:50.338654 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:35:50.338668 20451 solver.cpp:244]     Train net output #1: loss = 0.0937767 (* 1 = 0.0937767 loss)
I0809 04:35:50.338681 20451 sgd_solver.cpp:106] Iteration 23090, lr = 0.000407594
I0809 04:36:10.415391 20451 solver.cpp:337] Iteration 23100, Testing net (#0)
I0809 04:36:18.943138 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 04:36:18.943191 20451 solver.cpp:404]     Test net output #1: loss = 0.998683 (* 1 = 0.998683 loss)
I0809 04:36:21.147519 20451 solver.cpp:228] Iteration 23100, loss = 0.125045
I0809 04:36:21.147701 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:36:21.147717 20451 solver.cpp:244]     Train net output #1: loss = 0.125045 (* 1 = 0.125045 loss)
I0809 04:36:21.147729 20451 sgd_solver.cpp:106] Iteration 23100, lr = 0.000407501
I0809 04:36:43.434139 20451 solver.cpp:228] Iteration 23110, loss = 0.343889
I0809 04:36:43.434192 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 04:36:43.434207 20451 solver.cpp:244]     Train net output #1: loss = 0.343889 (* 1 = 0.343889 loss)
I0809 04:36:43.434219 20451 sgd_solver.cpp:106] Iteration 23110, lr = 0.000407409
I0809 04:37:05.740990 20451 solver.cpp:228] Iteration 23120, loss = 0.218812
I0809 04:37:05.741173 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:37:05.741188 20451 solver.cpp:244]     Train net output #1: loss = 0.218812 (* 1 = 0.218812 loss)
I0809 04:37:05.741200 20451 sgd_solver.cpp:106] Iteration 23120, lr = 0.000407317
I0809 04:37:28.049190 20451 solver.cpp:228] Iteration 23130, loss = 0.156261
I0809 04:37:28.049242 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:37:28.049257 20451 solver.cpp:244]     Train net output #1: loss = 0.156261 (* 1 = 0.156261 loss)
I0809 04:37:28.049268 20451 sgd_solver.cpp:106] Iteration 23130, lr = 0.000407225
I0809 04:37:50.365391 20451 solver.cpp:228] Iteration 23140, loss = 0.187603
I0809 04:37:50.365569 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:37:50.365586 20451 solver.cpp:244]     Train net output #1: loss = 0.187603 (* 1 = 0.187603 loss)
I0809 04:37:50.365597 20451 sgd_solver.cpp:106] Iteration 23140, lr = 0.000407132
I0809 04:38:12.670032 20451 solver.cpp:228] Iteration 23150, loss = 0.18777
I0809 04:38:12.670083 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:38:12.670097 20451 solver.cpp:244]     Train net output #1: loss = 0.187771 (* 1 = 0.187771 loss)
I0809 04:38:12.670109 20451 sgd_solver.cpp:106] Iteration 23150, lr = 0.00040704
I0809 04:38:34.990175 20451 solver.cpp:228] Iteration 23160, loss = 0.0938651
I0809 04:38:34.990278 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:38:34.990293 20451 solver.cpp:244]     Train net output #1: loss = 0.0938653 (* 1 = 0.0938653 loss)
I0809 04:38:34.990306 20451 sgd_solver.cpp:106] Iteration 23160, lr = 0.000406948
I0809 04:38:57.304752 20451 solver.cpp:228] Iteration 23170, loss = 0.125075
I0809 04:38:57.304805 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:38:57.304819 20451 solver.cpp:244]     Train net output #1: loss = 0.125075 (* 1 = 0.125075 loss)
I0809 04:38:57.304831 20451 sgd_solver.cpp:106] Iteration 23170, lr = 0.000406856
I0809 04:39:19.609182 20451 solver.cpp:228] Iteration 23180, loss = 0.156441
I0809 04:39:19.609367 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:39:19.609382 20451 solver.cpp:244]     Train net output #1: loss = 0.156441 (* 1 = 0.156441 loss)
I0809 04:39:19.609395 20451 sgd_solver.cpp:106] Iteration 23180, lr = 0.000406764
I0809 04:39:41.922894 20451 solver.cpp:228] Iteration 23190, loss = 0.18754
I0809 04:39:41.922946 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:39:41.922960 20451 solver.cpp:244]     Train net output #1: loss = 0.18754 (* 1 = 0.18754 loss)
I0809 04:39:41.922972 20451 sgd_solver.cpp:106] Iteration 23190, lr = 0.000406672
I0809 04:40:02.016538 20451 solver.cpp:337] Iteration 23200, Testing net (#0)
I0809 04:40:10.541266 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 04:40:10.541317 20451 solver.cpp:404]     Test net output #1: loss = 0.998834 (* 1 = 0.998834 loss)
I0809 04:40:12.748306 20451 solver.cpp:228] Iteration 23200, loss = 0.125074
I0809 04:40:12.748344 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:40:12.748358 20451 solver.cpp:244]     Train net output #1: loss = 0.125074 (* 1 = 0.125074 loss)
I0809 04:40:12.748371 20451 sgd_solver.cpp:106] Iteration 23200, lr = 0.00040658
I0809 04:40:35.041371 20451 solver.cpp:228] Iteration 23210, loss = 0.0937724
I0809 04:40:35.041559 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:40:35.041579 20451 solver.cpp:244]     Train net output #1: loss = 0.0937726 (* 1 = 0.0937726 loss)
I0809 04:40:35.041594 20451 sgd_solver.cpp:106] Iteration 23210, lr = 0.000406489
I0809 04:40:57.353451 20451 solver.cpp:228] Iteration 23220, loss = 0.0938682
I0809 04:40:57.353494 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:40:57.353510 20451 solver.cpp:244]     Train net output #1: loss = 0.0938684 (* 1 = 0.0938684 loss)
I0809 04:40:57.353523 20451 sgd_solver.cpp:106] Iteration 23220, lr = 0.000406397
I0809 04:41:19.670979 20451 solver.cpp:228] Iteration 23230, loss = 0.062502
I0809 04:41:19.671082 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:41:19.671100 20451 solver.cpp:244]     Train net output #1: loss = 0.0625022 (* 1 = 0.0625022 loss)
I0809 04:41:19.671114 20451 sgd_solver.cpp:106] Iteration 23230, lr = 0.000406305
I0809 04:41:41.976148 20451 solver.cpp:228] Iteration 23240, loss = 0.0937531
I0809 04:41:41.976200 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:41:41.976215 20451 solver.cpp:244]     Train net output #1: loss = 0.0937533 (* 1 = 0.0937533 loss)
I0809 04:41:41.976227 20451 sgd_solver.cpp:106] Iteration 23240, lr = 0.000406213
I0809 04:42:04.304376 20451 solver.cpp:228] Iteration 23250, loss = 0.218782
I0809 04:42:04.304566 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:42:04.304581 20451 solver.cpp:244]     Train net output #1: loss = 0.218783 (* 1 = 0.218783 loss)
I0809 04:42:04.304594 20451 sgd_solver.cpp:106] Iteration 23250, lr = 0.000406122
I0809 04:42:26.625187 20451 solver.cpp:228] Iteration 23260, loss = 0.0937612
I0809 04:42:26.625239 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:42:26.625253 20451 solver.cpp:244]     Train net output #1: loss = 0.0937614 (* 1 = 0.0937614 loss)
I0809 04:42:26.625265 20451 sgd_solver.cpp:106] Iteration 23260, lr = 0.00040603
I0809 04:42:48.953258 20451 solver.cpp:228] Iteration 23270, loss = 0.281306
I0809 04:42:48.953429 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:42:48.953444 20451 solver.cpp:244]     Train net output #1: loss = 0.281306 (* 1 = 0.281306 loss)
I0809 04:42:48.953456 20451 sgd_solver.cpp:106] Iteration 23270, lr = 0.000405939
I0809 04:43:11.280097 20451 solver.cpp:228] Iteration 23280, loss = 0.156299
I0809 04:43:11.280153 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:43:11.280166 20451 solver.cpp:244]     Train net output #1: loss = 0.1563 (* 1 = 0.1563 loss)
I0809 04:43:11.280179 20451 sgd_solver.cpp:106] Iteration 23280, lr = 0.000405847
I0809 04:43:33.603073 20451 solver.cpp:228] Iteration 23290, loss = 0.125022
I0809 04:43:33.603245 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:43:33.603260 20451 solver.cpp:244]     Train net output #1: loss = 0.125023 (* 1 = 0.125023 loss)
I0809 04:43:33.603276 20451 sgd_solver.cpp:106] Iteration 23290, lr = 0.000405756
I0809 04:43:53.696542 20451 solver.cpp:337] Iteration 23300, Testing net (#0)
I0809 04:44:02.230166 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 04:44:02.230216 20451 solver.cpp:404]     Test net output #1: loss = 1.00815 (* 1 = 1.00815 loss)
I0809 04:44:04.432039 20451 solver.cpp:228] Iteration 23300, loss = 0.156329
I0809 04:44:04.432184 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:44:04.432199 20451 solver.cpp:244]     Train net output #1: loss = 0.156329 (* 1 = 0.156329 loss)
I0809 04:44:04.432212 20451 sgd_solver.cpp:106] Iteration 23300, lr = 0.000405664
I0809 04:44:26.723755 20451 solver.cpp:228] Iteration 23310, loss = 0.15627
I0809 04:44:26.723808 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:44:26.723820 20451 solver.cpp:244]     Train net output #1: loss = 0.156271 (* 1 = 0.156271 loss)
I0809 04:44:26.723834 20451 sgd_solver.cpp:106] Iteration 23310, lr = 0.000405573
I0809 04:44:49.032598 20451 solver.cpp:228] Iteration 23320, loss = 0.31265
I0809 04:44:49.032780 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 04:44:49.032795 20451 solver.cpp:244]     Train net output #1: loss = 0.31265 (* 1 = 0.31265 loss)
I0809 04:44:49.032807 20451 sgd_solver.cpp:106] Iteration 23320, lr = 0.000405482
I0809 04:45:11.345468 20451 solver.cpp:228] Iteration 23330, loss = 0.156302
I0809 04:45:11.345518 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:45:11.345531 20451 solver.cpp:244]     Train net output #1: loss = 0.156302 (* 1 = 0.156302 loss)
I0809 04:45:11.345544 20451 sgd_solver.cpp:106] Iteration 23330, lr = 0.00040539
I0809 04:45:33.652303 20451 solver.cpp:228] Iteration 23340, loss = 0.187568
I0809 04:45:33.652482 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:45:33.652498 20451 solver.cpp:244]     Train net output #1: loss = 0.187568 (* 1 = 0.187568 loss)
I0809 04:45:33.652509 20451 sgd_solver.cpp:106] Iteration 23340, lr = 0.000405299
I0809 04:45:55.968427 20451 solver.cpp:228] Iteration 23350, loss = 0.125072
I0809 04:45:55.968475 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:45:55.968489 20451 solver.cpp:244]     Train net output #1: loss = 0.125072 (* 1 = 0.125072 loss)
I0809 04:45:55.968502 20451 sgd_solver.cpp:106] Iteration 23350, lr = 0.000405208
I0809 04:46:18.278373 20451 solver.cpp:228] Iteration 23360, loss = 0.218781
I0809 04:46:18.278545 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:46:18.278561 20451 solver.cpp:244]     Train net output #1: loss = 0.218781 (* 1 = 0.218781 loss)
I0809 04:46:18.278573 20451 sgd_solver.cpp:106] Iteration 23360, lr = 0.000405117
I0809 04:46:40.591967 20451 solver.cpp:228] Iteration 23370, loss = 0.156336
I0809 04:46:40.592020 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:46:40.592034 20451 solver.cpp:244]     Train net output #1: loss = 0.156336 (* 1 = 0.156336 loss)
I0809 04:46:40.592046 20451 sgd_solver.cpp:106] Iteration 23370, lr = 0.000405026
I0809 04:47:02.915599 20451 solver.cpp:228] Iteration 23380, loss = 0.250062
I0809 04:47:02.915709 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 04:47:02.915725 20451 solver.cpp:244]     Train net output #1: loss = 0.250062 (* 1 = 0.250062 loss)
I0809 04:47:02.915738 20451 sgd_solver.cpp:106] Iteration 23380, lr = 0.000404935
I0809 04:47:25.220551 20451 solver.cpp:228] Iteration 23390, loss = 0.093997
I0809 04:47:25.220602 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:47:25.220616 20451 solver.cpp:244]     Train net output #1: loss = 0.0939972 (* 1 = 0.0939972 loss)
I0809 04:47:25.220628 20451 sgd_solver.cpp:106] Iteration 23390, lr = 0.000404844
I0809 04:47:45.312458 20451 solver.cpp:337] Iteration 23400, Testing net (#0)
I0809 04:47:53.842161 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 04:47:53.842211 20451 solver.cpp:404]     Test net output #1: loss = 1.00319 (* 1 = 1.00319 loss)
I0809 04:47:56.047235 20451 solver.cpp:228] Iteration 23400, loss = 0.343783
I0809 04:47:56.047291 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 04:47:56.047307 20451 solver.cpp:244]     Train net output #1: loss = 0.343783 (* 1 = 0.343783 loss)
I0809 04:47:56.047320 20451 sgd_solver.cpp:106] Iteration 23400, lr = 0.000404753
I0809 04:48:18.337712 20451 solver.cpp:228] Iteration 23410, loss = 0.156326
I0809 04:48:18.337926 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:48:18.337942 20451 solver.cpp:244]     Train net output #1: loss = 0.156326 (* 1 = 0.156326 loss)
I0809 04:48:18.337954 20451 sgd_solver.cpp:106] Iteration 23410, lr = 0.000404662
I0809 04:48:40.656203 20451 solver.cpp:228] Iteration 23420, loss = 0.156339
I0809 04:48:40.656245 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:48:40.656260 20451 solver.cpp:244]     Train net output #1: loss = 0.15634 (* 1 = 0.15634 loss)
I0809 04:48:40.656273 20451 sgd_solver.cpp:106] Iteration 23420, lr = 0.000404571
I0809 04:49:02.971314 20451 solver.cpp:228] Iteration 23430, loss = 0.250102
I0809 04:49:02.971523 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:49:02.971537 20451 solver.cpp:244]     Train net output #1: loss = 0.250102 (* 1 = 0.250102 loss)
I0809 04:49:02.971550 20451 sgd_solver.cpp:106] Iteration 23430, lr = 0.000404481
I0809 04:49:25.285887 20451 solver.cpp:228] Iteration 23440, loss = 0.125008
I0809 04:49:25.285939 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:49:25.285953 20451 solver.cpp:244]     Train net output #1: loss = 0.125008 (* 1 = 0.125008 loss)
I0809 04:49:25.285964 20451 sgd_solver.cpp:106] Iteration 23440, lr = 0.00040439
I0809 04:49:47.601296 20451 solver.cpp:228] Iteration 23450, loss = 0.0312662
I0809 04:49:47.601389 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 04:49:47.601407 20451 solver.cpp:244]     Train net output #1: loss = 0.0312664 (* 1 = 0.0312664 loss)
I0809 04:49:47.601419 20451 sgd_solver.cpp:106] Iteration 23450, lr = 0.000404299
I0809 04:50:09.909652 20451 solver.cpp:228] Iteration 23460, loss = 0.156331
I0809 04:50:09.909704 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:50:09.909718 20451 solver.cpp:244]     Train net output #1: loss = 0.156331 (* 1 = 0.156331 loss)
I0809 04:50:09.909731 20451 sgd_solver.cpp:106] Iteration 23460, lr = 0.000404209
I0809 04:50:32.224503 20451 solver.cpp:228] Iteration 23470, loss = 0.0937707
I0809 04:50:32.224689 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:50:32.224705 20451 solver.cpp:244]     Train net output #1: loss = 0.0937709 (* 1 = 0.0937709 loss)
I0809 04:50:32.224719 20451 sgd_solver.cpp:106] Iteration 23470, lr = 0.000404118
I0809 04:50:54.540488 20451 solver.cpp:228] Iteration 23480, loss = 0.125096
I0809 04:50:54.540539 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:50:54.540554 20451 solver.cpp:244]     Train net output #1: loss = 0.125096 (* 1 = 0.125096 loss)
I0809 04:50:54.540565 20451 sgd_solver.cpp:106] Iteration 23480, lr = 0.000404027
I0809 04:51:16.849712 20451 solver.cpp:228] Iteration 23490, loss = 0.156263
I0809 04:51:16.849812 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:51:16.849829 20451 solver.cpp:244]     Train net output #1: loss = 0.156263 (* 1 = 0.156263 loss)
I0809 04:51:16.849843 20451 sgd_solver.cpp:106] Iteration 23490, lr = 0.000403937
I0809 04:51:36.930874 20451 solver.cpp:337] Iteration 23500, Testing net (#0)
I0809 04:51:45.455628 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0809 04:51:45.455680 20451 solver.cpp:404]     Test net output #1: loss = 0.96213 (* 1 = 0.96213 loss)
I0809 04:51:47.660454 20451 solver.cpp:228] Iteration 23500, loss = 0.125232
I0809 04:51:47.660634 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:51:47.660650 20451 solver.cpp:244]     Train net output #1: loss = 0.125232 (* 1 = 0.125232 loss)
I0809 04:51:47.660663 20451 sgd_solver.cpp:106] Iteration 23500, lr = 0.000403847
I0809 04:52:09.949280 20451 solver.cpp:228] Iteration 23510, loss = 0.156262
I0809 04:52:09.949332 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:52:09.949347 20451 solver.cpp:244]     Train net output #1: loss = 0.156262 (* 1 = 0.156262 loss)
I0809 04:52:09.949358 20451 sgd_solver.cpp:106] Iteration 23510, lr = 0.000403756
I0809 04:52:32.266357 20451 solver.cpp:228] Iteration 23520, loss = 0.281782
I0809 04:52:32.266578 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:52:32.266598 20451 solver.cpp:244]     Train net output #1: loss = 0.281782 (* 1 = 0.281782 loss)
I0809 04:52:32.266638 20451 sgd_solver.cpp:106] Iteration 23520, lr = 0.000403666
I0809 04:52:54.572458 20451 solver.cpp:228] Iteration 23530, loss = 0.187617
I0809 04:52:54.572513 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:52:54.572527 20451 solver.cpp:244]     Train net output #1: loss = 0.187617 (* 1 = 0.187617 loss)
I0809 04:52:54.572540 20451 sgd_solver.cpp:106] Iteration 23530, lr = 0.000403576
I0809 04:53:16.890285 20451 solver.cpp:228] Iteration 23540, loss = 0.218915
I0809 04:53:16.890462 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:53:16.890477 20451 solver.cpp:244]     Train net output #1: loss = 0.218916 (* 1 = 0.218916 loss)
I0809 04:53:16.890491 20451 sgd_solver.cpp:106] Iteration 23540, lr = 0.000403485
I0809 04:53:39.198580 20451 solver.cpp:228] Iteration 23550, loss = 0.187515
I0809 04:53:39.198632 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:53:39.198645 20451 solver.cpp:244]     Train net output #1: loss = 0.187515 (* 1 = 0.187515 loss)
I0809 04:53:39.198658 20451 sgd_solver.cpp:106] Iteration 23550, lr = 0.000403395
I0809 04:54:01.519467 20451 solver.cpp:228] Iteration 23560, loss = 0.156401
I0809 04:54:01.519640 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:54:01.519656 20451 solver.cpp:244]     Train net output #1: loss = 0.156401 (* 1 = 0.156401 loss)
I0809 04:54:01.519668 20451 sgd_solver.cpp:106] Iteration 23560, lr = 0.000403305
I0809 04:54:23.831089 20451 solver.cpp:228] Iteration 23570, loss = 0.15626
I0809 04:54:23.831141 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:54:23.831154 20451 solver.cpp:244]     Train net output #1: loss = 0.15626 (* 1 = 0.15626 loss)
I0809 04:54:23.831166 20451 sgd_solver.cpp:106] Iteration 23570, lr = 0.000403215
I0809 04:54:46.150202 20451 solver.cpp:228] Iteration 23580, loss = 0.156272
I0809 04:54:46.150387 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:54:46.150401 20451 solver.cpp:244]     Train net output #1: loss = 0.156272 (* 1 = 0.156272 loss)
I0809 04:54:46.150414 20451 sgd_solver.cpp:106] Iteration 23580, lr = 0.000403125
I0809 04:55:08.461819 20451 solver.cpp:228] Iteration 23590, loss = 0.0937636
I0809 04:55:08.461861 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:55:08.461876 20451 solver.cpp:244]     Train net output #1: loss = 0.0937637 (* 1 = 0.0937637 loss)
I0809 04:55:08.461889 20451 sgd_solver.cpp:106] Iteration 23590, lr = 0.000403035
I0809 04:55:28.533138 20451 solver.cpp:337] Iteration 23600, Testing net (#0)
I0809 04:55:37.061821 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 04:55:37.061863 20451 solver.cpp:404]     Test net output #1: loss = 0.994164 (* 1 = 0.994164 loss)
I0809 04:55:39.265987 20451 solver.cpp:228] Iteration 23600, loss = 0.156347
I0809 04:55:39.266031 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 04:55:39.266046 20451 solver.cpp:244]     Train net output #1: loss = 0.156347 (* 1 = 0.156347 loss)
I0809 04:55:39.266059 20451 sgd_solver.cpp:106] Iteration 23600, lr = 0.000402945
I0809 04:56:01.560884 20451 solver.cpp:228] Iteration 23610, loss = 0.218964
I0809 04:56:01.561056 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:56:01.561072 20451 solver.cpp:244]     Train net output #1: loss = 0.218964 (* 1 = 0.218964 loss)
I0809 04:56:01.561084 20451 sgd_solver.cpp:106] Iteration 23610, lr = 0.000402855
I0809 04:56:23.880905 20451 solver.cpp:228] Iteration 23620, loss = 0.187691
I0809 04:56:23.880956 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 04:56:23.880970 20451 solver.cpp:244]     Train net output #1: loss = 0.187691 (* 1 = 0.187691 loss)
I0809 04:56:23.880982 20451 sgd_solver.cpp:106] Iteration 23620, lr = 0.000402765
I0809 04:56:46.177434 20451 solver.cpp:228] Iteration 23630, loss = 0.125008
I0809 04:56:46.177649 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 04:56:46.177664 20451 solver.cpp:244]     Train net output #1: loss = 0.125008 (* 1 = 0.125008 loss)
I0809 04:56:46.177677 20451 sgd_solver.cpp:106] Iteration 23630, lr = 0.000402675
I0809 04:57:08.494316 20451 solver.cpp:228] Iteration 23640, loss = 0.281348
I0809 04:57:08.494369 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 04:57:08.494382 20451 solver.cpp:244]     Train net output #1: loss = 0.281348 (* 1 = 0.281348 loss)
I0809 04:57:08.494395 20451 sgd_solver.cpp:106] Iteration 23640, lr = 0.000402585
I0809 04:57:30.805482 20451 solver.cpp:228] Iteration 23650, loss = 0.218875
I0809 04:57:30.805663 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:57:30.805678 20451 solver.cpp:244]     Train net output #1: loss = 0.218875 (* 1 = 0.218875 loss)
I0809 04:57:30.805691 20451 sgd_solver.cpp:106] Iteration 23650, lr = 0.000402496
I0809 04:57:53.126664 20451 solver.cpp:228] Iteration 23660, loss = 0.250074
I0809 04:57:53.126714 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 04:57:53.126729 20451 solver.cpp:244]     Train net output #1: loss = 0.250074 (* 1 = 0.250074 loss)
I0809 04:57:53.126741 20451 sgd_solver.cpp:106] Iteration 23660, lr = 0.000402406
I0809 04:58:15.440601 20451 solver.cpp:228] Iteration 23670, loss = 0.062537
I0809 04:58:15.440784 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 04:58:15.440800 20451 solver.cpp:244]     Train net output #1: loss = 0.0625372 (* 1 = 0.0625372 loss)
I0809 04:58:15.440812 20451 sgd_solver.cpp:106] Iteration 23670, lr = 0.000402316
I0809 04:58:37.749135 20451 solver.cpp:228] Iteration 23680, loss = 0.250124
I0809 04:58:37.749183 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 04:58:37.749199 20451 solver.cpp:244]     Train net output #1: loss = 0.250124 (* 1 = 0.250124 loss)
I0809 04:58:37.749212 20451 sgd_solver.cpp:106] Iteration 23680, lr = 0.000402227
I0809 04:59:00.061625 20451 solver.cpp:228] Iteration 23690, loss = 0.218934
I0809 04:59:00.061718 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 04:59:00.061734 20451 solver.cpp:244]     Train net output #1: loss = 0.218934 (* 1 = 0.218934 loss)
I0809 04:59:00.061748 20451 sgd_solver.cpp:106] Iteration 23690, lr = 0.000402137
I0809 04:59:20.163992 20451 solver.cpp:337] Iteration 23700, Testing net (#0)
I0809 04:59:28.688040 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 04:59:28.688082 20451 solver.cpp:404]     Test net output #1: loss = 0.99952 (* 1 = 0.99952 loss)
I0809 04:59:30.891381 20451 solver.cpp:228] Iteration 23700, loss = 0.0939019
I0809 04:59:30.891551 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 04:59:30.891567 20451 solver.cpp:244]     Train net output #1: loss = 0.0939021 (* 1 = 0.0939021 loss)
I0809 04:59:30.891579 20451 sgd_solver.cpp:106] Iteration 23700, lr = 0.000402048
I0809 04:59:53.179154 20451 solver.cpp:228] Iteration 23710, loss = 0.125164
I0809 04:59:53.179196 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 04:59:53.179213 20451 solver.cpp:244]     Train net output #1: loss = 0.125164 (* 1 = 0.125164 loss)
I0809 04:59:53.179225 20451 sgd_solver.cpp:106] Iteration 23710, lr = 0.000401958
I0809 05:00:15.494712 20451 solver.cpp:228] Iteration 23720, loss = 0.187834
I0809 05:00:15.494813 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:00:15.494829 20451 solver.cpp:244]     Train net output #1: loss = 0.187834 (* 1 = 0.187834 loss)
I0809 05:00:15.494840 20451 sgd_solver.cpp:106] Iteration 23720, lr = 0.000401869
I0809 05:00:37.799422 20451 solver.cpp:228] Iteration 23730, loss = 0.250092
I0809 05:00:37.799468 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:00:37.799484 20451 solver.cpp:244]     Train net output #1: loss = 0.250092 (* 1 = 0.250092 loss)
I0809 05:00:37.799496 20451 sgd_solver.cpp:106] Iteration 23730, lr = 0.000401779
I0809 05:01:00.121101 20451 solver.cpp:228] Iteration 23740, loss = 0.187579
I0809 05:01:00.121309 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:01:00.121325 20451 solver.cpp:244]     Train net output #1: loss = 0.18758 (* 1 = 0.18758 loss)
I0809 05:01:00.121337 20451 sgd_solver.cpp:106] Iteration 23740, lr = 0.00040169
I0809 05:01:22.431001 20451 solver.cpp:228] Iteration 23750, loss = 0.156267
I0809 05:01:22.431056 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:01:22.431071 20451 solver.cpp:244]     Train net output #1: loss = 0.156267 (* 1 = 0.156267 loss)
I0809 05:01:22.431082 20451 sgd_solver.cpp:106] Iteration 23750, lr = 0.000401601
I0809 05:01:44.747287 20451 solver.cpp:228] Iteration 23760, loss = 0.218807
I0809 05:01:44.747472 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:01:44.747486 20451 solver.cpp:244]     Train net output #1: loss = 0.218807 (* 1 = 0.218807 loss)
I0809 05:01:44.747499 20451 sgd_solver.cpp:106] Iteration 23760, lr = 0.000401512
I0809 05:02:07.062750 20451 solver.cpp:228] Iteration 23770, loss = 0.218826
I0809 05:02:07.062789 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:02:07.062803 20451 solver.cpp:244]     Train net output #1: loss = 0.218827 (* 1 = 0.218827 loss)
I0809 05:02:07.062816 20451 sgd_solver.cpp:106] Iteration 23770, lr = 0.000401423
I0809 05:02:29.376200 20451 solver.cpp:228] Iteration 23780, loss = 0.156253
I0809 05:02:29.376381 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:02:29.376397 20451 solver.cpp:244]     Train net output #1: loss = 0.156253 (* 1 = 0.156253 loss)
I0809 05:02:29.376410 20451 sgd_solver.cpp:106] Iteration 23780, lr = 0.000401333
I0809 05:02:51.686014 20451 solver.cpp:228] Iteration 23790, loss = 0.156346
I0809 05:02:51.686066 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:02:51.686080 20451 solver.cpp:244]     Train net output #1: loss = 0.156346 (* 1 = 0.156346 loss)
I0809 05:02:51.686092 20451 sgd_solver.cpp:106] Iteration 23790, lr = 0.000401244
I0809 05:03:11.777978 20451 solver.cpp:337] Iteration 23800, Testing net (#0)
I0809 05:03:20.305670 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0809 05:03:20.305719 20451 solver.cpp:404]     Test net output #1: loss = 0.989149 (* 1 = 0.989149 loss)
I0809 05:03:22.506430 20451 solver.cpp:228] Iteration 23800, loss = 0.250032
I0809 05:03:22.506480 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:03:22.506494 20451 solver.cpp:244]     Train net output #1: loss = 0.250032 (* 1 = 0.250032 loss)
I0809 05:03:22.506505 20451 sgd_solver.cpp:106] Iteration 23800, lr = 0.000401155
I0809 05:03:44.787618 20451 solver.cpp:228] Iteration 23810, loss = 0.0937634
I0809 05:03:44.787732 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:03:44.787749 20451 solver.cpp:244]     Train net output #1: loss = 0.0937636 (* 1 = 0.0937636 loss)
I0809 05:03:44.787761 20451 sgd_solver.cpp:106] Iteration 23810, lr = 0.000401066
I0809 05:04:07.108960 20451 solver.cpp:228] Iteration 23820, loss = 0.156301
I0809 05:04:07.109014 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:04:07.109027 20451 solver.cpp:244]     Train net output #1: loss = 0.156301 (* 1 = 0.156301 loss)
I0809 05:04:07.109040 20451 sgd_solver.cpp:106] Iteration 23820, lr = 0.000400977
I0809 05:04:29.421094 20451 solver.cpp:228] Iteration 23830, loss = 0.0937988
I0809 05:04:29.421270 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:04:29.421285 20451 solver.cpp:244]     Train net output #1: loss = 0.093799 (* 1 = 0.093799 loss)
I0809 05:04:29.421298 20451 sgd_solver.cpp:106] Iteration 23830, lr = 0.000400888
I0809 05:04:51.746397 20451 solver.cpp:228] Iteration 23840, loss = 0.187596
I0809 05:04:51.746439 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:04:51.746454 20451 solver.cpp:244]     Train net output #1: loss = 0.187596 (* 1 = 0.187596 loss)
I0809 05:04:51.746466 20451 sgd_solver.cpp:106] Iteration 23840, lr = 0.0004008
I0809 05:05:14.063266 20451 solver.cpp:228] Iteration 23850, loss = 0.156312
I0809 05:05:14.063406 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:05:14.063421 20451 solver.cpp:244]     Train net output #1: loss = 0.156312 (* 1 = 0.156312 loss)
I0809 05:05:14.063434 20451 sgd_solver.cpp:106] Iteration 23850, lr = 0.000400711
I0809 05:05:36.386000 20451 solver.cpp:228] Iteration 23860, loss = 0.250138
I0809 05:05:36.386054 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:05:36.386067 20451 solver.cpp:244]     Train net output #1: loss = 0.250138 (* 1 = 0.250138 loss)
I0809 05:05:36.386080 20451 sgd_solver.cpp:106] Iteration 23860, lr = 0.000400622
I0809 05:05:58.704607 20451 solver.cpp:228] Iteration 23870, loss = 0.218847
I0809 05:05:58.704701 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:05:58.704717 20451 solver.cpp:244]     Train net output #1: loss = 0.218847 (* 1 = 0.218847 loss)
I0809 05:05:58.704731 20451 sgd_solver.cpp:106] Iteration 23870, lr = 0.000400533
I0809 05:06:21.028689 20451 solver.cpp:228] Iteration 23880, loss = 0.219137
I0809 05:06:21.028741 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:06:21.028755 20451 solver.cpp:244]     Train net output #1: loss = 0.219137 (* 1 = 0.219137 loss)
I0809 05:06:21.028767 20451 sgd_solver.cpp:106] Iteration 23880, lr = 0.000400445
I0809 05:06:43.345640 20451 solver.cpp:228] Iteration 23890, loss = 0.312728
I0809 05:06:43.345818 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:06:43.345834 20451 solver.cpp:244]     Train net output #1: loss = 0.312728 (* 1 = 0.312728 loss)
I0809 05:06:43.345846 20451 sgd_solver.cpp:106] Iteration 23890, lr = 0.000400356
I0809 05:07:03.439406 20451 solver.cpp:337] Iteration 23900, Testing net (#0)
I0809 05:07:11.963572 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0809 05:07:11.963624 20451 solver.cpp:404]     Test net output #1: loss = 1.03662 (* 1 = 1.03662 loss)
I0809 05:07:14.167379 20451 solver.cpp:228] Iteration 23900, loss = 0.125123
I0809 05:07:14.167551 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:07:14.167565 20451 solver.cpp:244]     Train net output #1: loss = 0.125124 (* 1 = 0.125124 loss)
I0809 05:07:14.167578 20451 sgd_solver.cpp:106] Iteration 23900, lr = 0.000400267
I0809 05:07:36.463526 20451 solver.cpp:228] Iteration 23910, loss = 0.156275
I0809 05:07:36.463577 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:07:36.463592 20451 solver.cpp:244]     Train net output #1: loss = 0.156276 (* 1 = 0.156276 loss)
I0809 05:07:36.463603 20451 sgd_solver.cpp:106] Iteration 23910, lr = 0.000400179
I0809 05:07:58.776051 20451 solver.cpp:228] Iteration 23920, loss = 0.218847
I0809 05:07:58.776155 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:07:58.776175 20451 solver.cpp:244]     Train net output #1: loss = 0.218847 (* 1 = 0.218847 loss)
I0809 05:07:58.776190 20451 sgd_solver.cpp:106] Iteration 23920, lr = 0.00040009
I0809 05:08:21.095125 20451 solver.cpp:228] Iteration 23930, loss = 0.218818
I0809 05:08:21.095170 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:08:21.095198 20451 solver.cpp:244]     Train net output #1: loss = 0.218818 (* 1 = 0.218818 loss)
I0809 05:08:21.095214 20451 sgd_solver.cpp:106] Iteration 23930, lr = 0.000400002
I0809 05:08:43.401108 20451 solver.cpp:228] Iteration 23940, loss = 0.125178
I0809 05:08:43.401211 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:08:43.401226 20451 solver.cpp:244]     Train net output #1: loss = 0.125179 (* 1 = 0.125179 loss)
I0809 05:08:43.401238 20451 sgd_solver.cpp:106] Iteration 23940, lr = 0.000399914
I0809 05:09:05.718722 20451 solver.cpp:228] Iteration 23950, loss = 0.187815
I0809 05:09:05.718765 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:09:05.718780 20451 solver.cpp:244]     Train net output #1: loss = 0.187815 (* 1 = 0.187815 loss)
I0809 05:09:05.718792 20451 sgd_solver.cpp:106] Iteration 23950, lr = 0.000399825
I0809 05:09:28.028777 20451 solver.cpp:228] Iteration 23960, loss = 0.12514
I0809 05:09:28.028985 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:09:28.029000 20451 solver.cpp:244]     Train net output #1: loss = 0.12514 (* 1 = 0.12514 loss)
I0809 05:09:28.029013 20451 sgd_solver.cpp:106] Iteration 23960, lr = 0.000399737
I0809 05:09:50.338572 20451 solver.cpp:228] Iteration 23970, loss = 0.156439
I0809 05:09:50.338627 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:09:50.338641 20451 solver.cpp:244]     Train net output #1: loss = 0.156439 (* 1 = 0.156439 loss)
I0809 05:09:50.338654 20451 sgd_solver.cpp:106] Iteration 23970, lr = 0.000399649
I0809 05:10:12.643189 20451 solver.cpp:228] Iteration 23980, loss = 0.187551
I0809 05:10:12.643335 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:10:12.643353 20451 solver.cpp:244]     Train net output #1: loss = 0.187551 (* 1 = 0.187551 loss)
I0809 05:10:12.643367 20451 sgd_solver.cpp:106] Iteration 23980, lr = 0.00039956
I0809 05:10:34.951598 20451 solver.cpp:228] Iteration 23990, loss = 0.344157
I0809 05:10:34.951640 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 05:10:34.951656 20451 solver.cpp:244]     Train net output #1: loss = 0.344157 (* 1 = 0.344157 loss)
I0809 05:10:34.951669 20451 sgd_solver.cpp:106] Iteration 23990, lr = 0.000399472
I0809 05:10:55.037138 20451 solver.cpp:337] Iteration 24000, Testing net (#0)
I0809 05:11:03.564960 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 05:11:03.565011 20451 solver.cpp:404]     Test net output #1: loss = 0.984433 (* 1 = 0.984433 loss)
I0809 05:11:05.767976 20451 solver.cpp:228] Iteration 24000, loss = 0.250021
I0809 05:11:05.768018 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:11:05.768033 20451 solver.cpp:244]     Train net output #1: loss = 0.250022 (* 1 = 0.250022 loss)
I0809 05:11:05.768046 20451 sgd_solver.cpp:106] Iteration 24000, lr = 0.000399384
I0809 05:11:28.054204 20451 solver.cpp:228] Iteration 24010, loss = 0.125051
I0809 05:11:28.054384 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:11:28.054399 20451 solver.cpp:244]     Train net output #1: loss = 0.125052 (* 1 = 0.125052 loss)
I0809 05:11:28.054411 20451 sgd_solver.cpp:106] Iteration 24010, lr = 0.000399296
I0809 05:11:50.359175 20451 solver.cpp:228] Iteration 24020, loss = 0.156368
I0809 05:11:50.359228 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:11:50.359243 20451 solver.cpp:244]     Train net output #1: loss = 0.156368 (* 1 = 0.156368 loss)
I0809 05:11:50.359256 20451 sgd_solver.cpp:106] Iteration 24020, lr = 0.000399208
I0809 05:12:12.660986 20451 solver.cpp:228] Iteration 24030, loss = 0.156258
I0809 05:12:12.661167 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:12:12.661182 20451 solver.cpp:244]     Train net output #1: loss = 0.156258 (* 1 = 0.156258 loss)
I0809 05:12:12.661195 20451 sgd_solver.cpp:106] Iteration 24030, lr = 0.00039912
I0809 05:12:34.967788 20451 solver.cpp:228] Iteration 24040, loss = 0.156302
I0809 05:12:34.967840 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:12:34.967854 20451 solver.cpp:244]     Train net output #1: loss = 0.156302 (* 1 = 0.156302 loss)
I0809 05:12:34.967867 20451 sgd_solver.cpp:106] Iteration 24040, lr = 0.000399032
I0809 05:12:57.285115 20451 solver.cpp:228] Iteration 24050, loss = 0.156292
I0809 05:12:57.285290 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:12:57.285305 20451 solver.cpp:244]     Train net output #1: loss = 0.156292 (* 1 = 0.156292 loss)
I0809 05:12:57.285317 20451 sgd_solver.cpp:106] Iteration 24050, lr = 0.000398944
I0809 05:13:19.601523 20451 solver.cpp:228] Iteration 24060, loss = 0.093779
I0809 05:13:19.601567 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:13:19.601583 20451 solver.cpp:244]     Train net output #1: loss = 0.0937792 (* 1 = 0.0937792 loss)
I0809 05:13:19.601595 20451 sgd_solver.cpp:106] Iteration 24060, lr = 0.000398856
I0809 05:13:41.923977 20451 solver.cpp:228] Iteration 24070, loss = 0.187601
I0809 05:13:41.924177 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:13:41.924193 20451 solver.cpp:244]     Train net output #1: loss = 0.187601 (* 1 = 0.187601 loss)
I0809 05:13:41.924206 20451 sgd_solver.cpp:106] Iteration 24070, lr = 0.000398769
I0809 05:14:04.236707 20451 solver.cpp:228] Iteration 24080, loss = 0.156316
I0809 05:14:04.236763 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:14:04.236776 20451 solver.cpp:244]     Train net output #1: loss = 0.156316 (* 1 = 0.156316 loss)
I0809 05:14:04.236788 20451 sgd_solver.cpp:106] Iteration 24080, lr = 0.000398681
I0809 05:14:26.546443 20451 solver.cpp:228] Iteration 24090, loss = 0.187621
I0809 05:14:26.546622 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:14:26.546638 20451 solver.cpp:244]     Train net output #1: loss = 0.187621 (* 1 = 0.187621 loss)
I0809 05:14:26.546650 20451 sgd_solver.cpp:106] Iteration 24090, lr = 0.000398593
I0809 05:14:46.629233 20451 solver.cpp:337] Iteration 24100, Testing net (#0)
I0809 05:14:55.153457 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0809 05:14:55.153511 20451 solver.cpp:404]     Test net output #1: loss = 0.970533 (* 1 = 0.970533 loss)
I0809 05:14:57.361537 20451 solver.cpp:228] Iteration 24100, loss = 0.250083
I0809 05:14:57.361712 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:14:57.361728 20451 solver.cpp:244]     Train net output #1: loss = 0.250083 (* 1 = 0.250083 loss)
I0809 05:14:57.361740 20451 sgd_solver.cpp:106] Iteration 24100, lr = 0.000398505
I0809 05:15:19.660277 20451 solver.cpp:228] Iteration 24110, loss = 0.218892
I0809 05:15:19.660331 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:15:19.660344 20451 solver.cpp:244]     Train net output #1: loss = 0.218892 (* 1 = 0.218892 loss)
I0809 05:15:19.660357 20451 sgd_solver.cpp:106] Iteration 24110, lr = 0.000398418
I0809 05:15:41.981086 20451 solver.cpp:228] Iteration 24120, loss = 0.218828
I0809 05:15:41.981238 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:15:41.981259 20451 solver.cpp:244]     Train net output #1: loss = 0.218828 (* 1 = 0.218828 loss)
I0809 05:15:41.981276 20451 sgd_solver.cpp:106] Iteration 24120, lr = 0.00039833
I0809 05:16:04.297212 20451 solver.cpp:228] Iteration 24130, loss = 0.312597
I0809 05:16:04.297255 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 05:16:04.297272 20451 solver.cpp:244]     Train net output #1: loss = 0.312597 (* 1 = 0.312597 loss)
I0809 05:16:04.297287 20451 sgd_solver.cpp:106] Iteration 24130, lr = 0.000398243
I0809 05:16:26.609504 20451 solver.cpp:228] Iteration 24140, loss = 0.218786
I0809 05:16:26.609678 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:16:26.609694 20451 solver.cpp:244]     Train net output #1: loss = 0.218786 (* 1 = 0.218786 loss)
I0809 05:16:26.609706 20451 sgd_solver.cpp:106] Iteration 24140, lr = 0.000398155
I0809 05:16:48.911870 20451 solver.cpp:228] Iteration 24150, loss = 0.187534
I0809 05:16:48.911916 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:16:48.911943 20451 solver.cpp:244]     Train net output #1: loss = 0.187535 (* 1 = 0.187535 loss)
I0809 05:16:48.911958 20451 sgd_solver.cpp:106] Iteration 24150, lr = 0.000398068
I0809 05:17:11.221204 20451 solver.cpp:228] Iteration 24160, loss = 0.125118
I0809 05:17:11.221437 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:17:11.221452 20451 solver.cpp:244]     Train net output #1: loss = 0.125118 (* 1 = 0.125118 loss)
I0809 05:17:11.221467 20451 sgd_solver.cpp:106] Iteration 24160, lr = 0.00039798
I0809 05:17:33.521980 20451 solver.cpp:228] Iteration 24170, loss = 0.187554
I0809 05:17:33.522023 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:17:33.522042 20451 solver.cpp:244]     Train net output #1: loss = 0.187554 (* 1 = 0.187554 loss)
I0809 05:17:33.522055 20451 sgd_solver.cpp:106] Iteration 24170, lr = 0.000397893
I0809 05:17:55.836787 20451 solver.cpp:228] Iteration 24180, loss = 0.156281
I0809 05:17:55.836905 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:17:55.836925 20451 solver.cpp:244]     Train net output #1: loss = 0.156281 (* 1 = 0.156281 loss)
I0809 05:17:55.836942 20451 sgd_solver.cpp:106] Iteration 24180, lr = 0.000397806
I0809 05:18:18.141083 20451 solver.cpp:228] Iteration 24190, loss = 0.281276
I0809 05:18:18.141126 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 05:18:18.141152 20451 solver.cpp:244]     Train net output #1: loss = 0.281276 (* 1 = 0.281276 loss)
I0809 05:18:18.141168 20451 sgd_solver.cpp:106] Iteration 24190, lr = 0.000397718
I0809 05:18:38.228082 20451 solver.cpp:337] Iteration 24200, Testing net (#0)
I0809 05:18:46.754231 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 05:18:46.754288 20451 solver.cpp:404]     Test net output #1: loss = 1.00788 (* 1 = 1.00788 loss)
I0809 05:18:48.957269 20451 solver.cpp:228] Iteration 24200, loss = 0.187677
I0809 05:18:48.957324 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:18:48.957336 20451 solver.cpp:244]     Train net output #1: loss = 0.187677 (* 1 = 0.187677 loss)
I0809 05:18:48.957350 20451 sgd_solver.cpp:106] Iteration 24200, lr = 0.000397631
I0809 05:19:11.254835 20451 solver.cpp:228] Iteration 24210, loss = 0.218801
I0809 05:19:11.255018 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:19:11.255033 20451 solver.cpp:244]     Train net output #1: loss = 0.218801 (* 1 = 0.218801 loss)
I0809 05:19:11.255046 20451 sgd_solver.cpp:106] Iteration 24210, lr = 0.000397544
I0809 05:19:33.564702 20451 solver.cpp:228] Iteration 24220, loss = 0.187576
I0809 05:19:33.564754 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:19:33.564767 20451 solver.cpp:244]     Train net output #1: loss = 0.187576 (* 1 = 0.187576 loss)
I0809 05:19:33.564779 20451 sgd_solver.cpp:106] Iteration 24220, lr = 0.000397457
I0809 05:19:55.869770 20451 solver.cpp:228] Iteration 24230, loss = 0.218838
I0809 05:19:55.869873 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:19:55.869892 20451 solver.cpp:244]     Train net output #1: loss = 0.218839 (* 1 = 0.218839 loss)
I0809 05:19:55.869909 20451 sgd_solver.cpp:106] Iteration 24230, lr = 0.00039737
I0809 05:20:18.194093 20451 solver.cpp:228] Iteration 24240, loss = 0.0937822
I0809 05:20:18.194149 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:20:18.194164 20451 solver.cpp:244]     Train net output #1: loss = 0.0937824 (* 1 = 0.0937824 loss)
I0809 05:20:18.194176 20451 sgd_solver.cpp:106] Iteration 24240, lr = 0.000397283
I0809 05:20:40.514442 20451 solver.cpp:228] Iteration 24250, loss = 0.187564
I0809 05:20:40.514626 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:20:40.514641 20451 solver.cpp:244]     Train net output #1: loss = 0.187565 (* 1 = 0.187565 loss)
I0809 05:20:40.514652 20451 sgd_solver.cpp:106] Iteration 24250, lr = 0.000397196
I0809 05:21:02.838131 20451 solver.cpp:228] Iteration 24260, loss = 0.187682
I0809 05:21:02.838176 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:21:02.838191 20451 solver.cpp:244]     Train net output #1: loss = 0.187682 (* 1 = 0.187682 loss)
I0809 05:21:02.838205 20451 sgd_solver.cpp:106] Iteration 24260, lr = 0.000397109
I0809 05:21:25.160248 20451 solver.cpp:228] Iteration 24270, loss = 0.156336
I0809 05:21:25.160461 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:21:25.160481 20451 solver.cpp:244]     Train net output #1: loss = 0.156336 (* 1 = 0.156336 loss)
I0809 05:21:25.160495 20451 sgd_solver.cpp:106] Iteration 24270, lr = 0.000397022
I0809 05:21:47.484810 20451 solver.cpp:228] Iteration 24280, loss = 0.187644
I0809 05:21:47.484861 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:21:47.484876 20451 solver.cpp:244]     Train net output #1: loss = 0.187644 (* 1 = 0.187644 loss)
I0809 05:21:47.484889 20451 sgd_solver.cpp:106] Iteration 24280, lr = 0.000396935
I0809 05:22:09.804780 20451 solver.cpp:228] Iteration 24290, loss = 0.156397
I0809 05:22:09.804970 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:22:09.804988 20451 solver.cpp:244]     Train net output #1: loss = 0.156397 (* 1 = 0.156397 loss)
I0809 05:22:09.805004 20451 sgd_solver.cpp:106] Iteration 24290, lr = 0.000396848
I0809 05:22:29.889245 20451 solver.cpp:337] Iteration 24300, Testing net (#0)
I0809 05:22:38.414719 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0809 05:22:38.414772 20451 solver.cpp:404]     Test net output #1: loss = 1.01312 (* 1 = 1.01312 loss)
I0809 05:22:40.621626 20451 solver.cpp:228] Iteration 24300, loss = 0.344065
I0809 05:22:40.621808 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 05:22:40.621822 20451 solver.cpp:244]     Train net output #1: loss = 0.344066 (* 1 = 0.344066 loss)
I0809 05:22:40.621835 20451 sgd_solver.cpp:106] Iteration 24300, lr = 0.000396761
I0809 05:23:02.916416 20451 solver.cpp:228] Iteration 24310, loss = 0.125131
I0809 05:23:02.916470 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:23:02.916483 20451 solver.cpp:244]     Train net output #1: loss = 0.125131 (* 1 = 0.125131 loss)
I0809 05:23:02.916496 20451 sgd_solver.cpp:106] Iteration 24310, lr = 0.000396675
I0809 05:23:25.231847 20451 solver.cpp:228] Iteration 24320, loss = 0.250192
I0809 05:23:25.232030 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:23:25.232049 20451 solver.cpp:244]     Train net output #1: loss = 0.250192 (* 1 = 0.250192 loss)
I0809 05:23:25.232064 20451 sgd_solver.cpp:106] Iteration 24320, lr = 0.000396588
I0809 05:23:47.556615 20451 solver.cpp:228] Iteration 24330, loss = 0.187691
I0809 05:23:47.556660 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:23:47.556679 20451 solver.cpp:244]     Train net output #1: loss = 0.187691 (* 1 = 0.187691 loss)
I0809 05:23:47.556694 20451 sgd_solver.cpp:106] Iteration 24330, lr = 0.000396501
I0809 05:24:09.868274 20451 solver.cpp:228] Iteration 24340, loss = 0.156254
I0809 05:24:09.868465 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:24:09.868480 20451 solver.cpp:244]     Train net output #1: loss = 0.156254 (* 1 = 0.156254 loss)
I0809 05:24:09.868494 20451 sgd_solver.cpp:106] Iteration 24340, lr = 0.000396415
I0809 05:24:32.177474 20451 solver.cpp:228] Iteration 24350, loss = 0.187785
I0809 05:24:32.177525 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:24:32.177541 20451 solver.cpp:244]     Train net output #1: loss = 0.187785 (* 1 = 0.187785 loss)
I0809 05:24:32.177552 20451 sgd_solver.cpp:106] Iteration 24350, lr = 0.000396328
I0809 05:24:54.487148 20451 solver.cpp:228] Iteration 24360, loss = 0.250034
I0809 05:24:54.487284 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:24:54.487306 20451 solver.cpp:244]     Train net output #1: loss = 0.250034 (* 1 = 0.250034 loss)
I0809 05:24:54.487321 20451 sgd_solver.cpp:106] Iteration 24360, lr = 0.000396242
I0809 05:25:16.809115 20451 solver.cpp:228] Iteration 24370, loss = 0.156367
I0809 05:25:16.809161 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:25:16.809180 20451 solver.cpp:244]     Train net output #1: loss = 0.156367 (* 1 = 0.156367 loss)
I0809 05:25:16.809193 20451 sgd_solver.cpp:106] Iteration 24370, lr = 0.000396155
I0809 05:25:39.125862 20451 solver.cpp:228] Iteration 24380, loss = 0.187508
I0809 05:25:39.126092 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:25:39.126112 20451 solver.cpp:244]     Train net output #1: loss = 0.187508 (* 1 = 0.187508 loss)
I0809 05:25:39.126128 20451 sgd_solver.cpp:106] Iteration 24380, lr = 0.000396069
I0809 05:26:01.441560 20451 solver.cpp:228] Iteration 24390, loss = 0.438334
I0809 05:26:01.441614 20451 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0809 05:26:01.441633 20451 solver.cpp:244]     Train net output #1: loss = 0.438335 (* 1 = 0.438335 loss)
I0809 05:26:01.441649 20451 sgd_solver.cpp:106] Iteration 24390, lr = 0.000395982
I0809 05:26:21.543086 20451 solver.cpp:337] Iteration 24400, Testing net (#0)
I0809 05:26:30.068521 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 05:26:30.068565 20451 solver.cpp:404]     Test net output #1: loss = 0.984866 (* 1 = 0.984866 loss)
I0809 05:26:32.273382 20451 solver.cpp:228] Iteration 24400, loss = 0.218912
I0809 05:26:32.273425 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:26:32.273443 20451 solver.cpp:244]     Train net output #1: loss = 0.218912 (* 1 = 0.218912 loss)
I0809 05:26:32.273468 20451 sgd_solver.cpp:106] Iteration 24400, lr = 0.000395896
I0809 05:26:54.568812 20451 solver.cpp:228] Iteration 24410, loss = 0.312569
I0809 05:26:54.568994 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:26:54.569010 20451 solver.cpp:244]     Train net output #1: loss = 0.31257 (* 1 = 0.31257 loss)
I0809 05:26:54.569022 20451 sgd_solver.cpp:106] Iteration 24410, lr = 0.00039581
I0809 05:27:16.885545 20451 solver.cpp:228] Iteration 24420, loss = 0.312597
I0809 05:27:16.885597 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 05:27:16.885612 20451 solver.cpp:244]     Train net output #1: loss = 0.312598 (* 1 = 0.312598 loss)
I0809 05:27:16.885623 20451 sgd_solver.cpp:106] Iteration 24420, lr = 0.000395724
I0809 05:27:39.204720 20451 solver.cpp:228] Iteration 24430, loss = 0.125029
I0809 05:27:39.204907 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:27:39.204922 20451 solver.cpp:244]     Train net output #1: loss = 0.125029 (* 1 = 0.125029 loss)
I0809 05:27:39.204936 20451 sgd_solver.cpp:106] Iteration 24430, lr = 0.000395637
I0809 05:28:01.535215 20451 solver.cpp:228] Iteration 24440, loss = 0.156302
I0809 05:28:01.535266 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:28:01.535284 20451 solver.cpp:244]     Train net output #1: loss = 0.156303 (* 1 = 0.156303 loss)
I0809 05:28:01.535295 20451 sgd_solver.cpp:106] Iteration 24440, lr = 0.000395551
I0809 05:28:23.853338 20451 solver.cpp:228] Iteration 24450, loss = 0.0312939
I0809 05:28:23.853514 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 05:28:23.853530 20451 solver.cpp:244]     Train net output #1: loss = 0.0312941 (* 1 = 0.0312941 loss)
I0809 05:28:23.853543 20451 sgd_solver.cpp:106] Iteration 24450, lr = 0.000395465
I0809 05:28:46.166744 20451 solver.cpp:228] Iteration 24460, loss = 0.125084
I0809 05:28:46.166797 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:28:46.166812 20451 solver.cpp:244]     Train net output #1: loss = 0.125085 (* 1 = 0.125085 loss)
I0809 05:28:46.166824 20451 sgd_solver.cpp:106] Iteration 24460, lr = 0.000395379
I0809 05:29:08.478708 20451 solver.cpp:228] Iteration 24470, loss = 0.250389
I0809 05:29:08.478884 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:29:08.478900 20451 solver.cpp:244]     Train net output #1: loss = 0.250389 (* 1 = 0.250389 loss)
I0809 05:29:08.478914 20451 sgd_solver.cpp:106] Iteration 24470, lr = 0.000395293
I0809 05:29:30.787889 20451 solver.cpp:228] Iteration 24480, loss = 0.125139
I0809 05:29:30.787942 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:29:30.787955 20451 solver.cpp:244]     Train net output #1: loss = 0.125139 (* 1 = 0.125139 loss)
I0809 05:29:30.787967 20451 sgd_solver.cpp:106] Iteration 24480, lr = 0.000395207
I0809 05:29:53.104230 20451 solver.cpp:228] Iteration 24490, loss = 0.15641
I0809 05:29:53.104442 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:29:53.104457 20451 solver.cpp:244]     Train net output #1: loss = 0.15641 (* 1 = 0.15641 loss)
I0809 05:29:53.104492 20451 sgd_solver.cpp:106] Iteration 24490, lr = 0.000395121
I0809 05:30:13.192243 20451 solver.cpp:337] Iteration 24500, Testing net (#0)
I0809 05:30:21.720836 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 05:30:21.720890 20451 solver.cpp:404]     Test net output #1: loss = 1.00424 (* 1 = 1.00424 loss)
I0809 05:30:23.925251 20451 solver.cpp:228] Iteration 24500, loss = 0.125208
I0809 05:30:23.925436 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:30:23.925451 20451 solver.cpp:244]     Train net output #1: loss = 0.125208 (* 1 = 0.125208 loss)
I0809 05:30:23.925464 20451 sgd_solver.cpp:106] Iteration 24500, lr = 0.000395035
I0809 05:30:46.209878 20451 solver.cpp:228] Iteration 24510, loss = 0.250047
I0809 05:30:46.209933 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:30:46.209946 20451 solver.cpp:244]     Train net output #1: loss = 0.250047 (* 1 = 0.250047 loss)
I0809 05:30:46.209959 20451 sgd_solver.cpp:106] Iteration 24510, lr = 0.000394949
I0809 05:31:08.518427 20451 solver.cpp:228] Iteration 24520, loss = 0.250128
I0809 05:31:08.518610 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:31:08.518625 20451 solver.cpp:244]     Train net output #1: loss = 0.250128 (* 1 = 0.250128 loss)
I0809 05:31:08.518638 20451 sgd_solver.cpp:106] Iteration 24520, lr = 0.000394863
I0809 05:31:30.832530 20451 solver.cpp:228] Iteration 24530, loss = 0.187525
I0809 05:31:30.832582 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:31:30.832597 20451 solver.cpp:244]     Train net output #1: loss = 0.187525 (* 1 = 0.187525 loss)
I0809 05:31:30.832608 20451 sgd_solver.cpp:106] Iteration 24530, lr = 0.000394778
I0809 05:31:53.144574 20451 solver.cpp:228] Iteration 24540, loss = 0.187518
I0809 05:31:53.144670 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:31:53.144685 20451 solver.cpp:244]     Train net output #1: loss = 0.187518 (* 1 = 0.187518 loss)
I0809 05:31:53.144696 20451 sgd_solver.cpp:106] Iteration 24540, lr = 0.000394692
I0809 05:32:15.461897 20451 solver.cpp:228] Iteration 24550, loss = 0.312642
I0809 05:32:15.461949 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 05:32:15.461963 20451 solver.cpp:244]     Train net output #1: loss = 0.312643 (* 1 = 0.312643 loss)
I0809 05:32:15.461976 20451 sgd_solver.cpp:106] Iteration 24550, lr = 0.000394606
I0809 05:32:37.780424 20451 solver.cpp:228] Iteration 24560, loss = 0.312654
I0809 05:32:37.780524 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 05:32:37.780545 20451 solver.cpp:244]     Train net output #1: loss = 0.312654 (* 1 = 0.312654 loss)
I0809 05:32:37.780561 20451 sgd_solver.cpp:106] Iteration 24560, lr = 0.000394521
I0809 05:33:00.099463 20451 solver.cpp:228] Iteration 24570, loss = 0.187717
I0809 05:33:00.099514 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:33:00.099526 20451 solver.cpp:244]     Train net output #1: loss = 0.187717 (* 1 = 0.187717 loss)
I0809 05:33:00.099539 20451 sgd_solver.cpp:106] Iteration 24570, lr = 0.000394435
I0809 05:33:22.421372 20451 solver.cpp:228] Iteration 24580, loss = 0.125191
I0809 05:33:22.421545 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:33:22.421561 20451 solver.cpp:244]     Train net output #1: loss = 0.125191 (* 1 = 0.125191 loss)
I0809 05:33:22.421573 20451 sgd_solver.cpp:106] Iteration 24580, lr = 0.000394349
I0809 05:33:44.739343 20451 solver.cpp:228] Iteration 24590, loss = 0.156506
I0809 05:33:44.739395 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:33:44.739409 20451 solver.cpp:244]     Train net output #1: loss = 0.156506 (* 1 = 0.156506 loss)
I0809 05:33:44.739421 20451 sgd_solver.cpp:106] Iteration 24590, lr = 0.000394264
I0809 05:34:04.823072 20451 solver.cpp:337] Iteration 24600, Testing net (#0)
I0809 05:34:13.348825 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 05:34:13.348867 20451 solver.cpp:404]     Test net output #1: loss = 0.975706 (* 1 = 0.975706 loss)
I0809 05:34:15.554031 20451 solver.cpp:228] Iteration 24600, loss = 0.218987
I0809 05:34:15.554081 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:34:15.554095 20451 solver.cpp:244]     Train net output #1: loss = 0.218987 (* 1 = 0.218987 loss)
I0809 05:34:15.554107 20451 sgd_solver.cpp:106] Iteration 24600, lr = 0.000394178
I0809 05:34:37.843566 20451 solver.cpp:228] Iteration 24610, loss = 0.12502
I0809 05:34:37.843734 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:34:37.843776 20451 solver.cpp:244]     Train net output #1: loss = 0.12502 (* 1 = 0.12502 loss)
I0809 05:34:37.843816 20451 sgd_solver.cpp:106] Iteration 24610, lr = 0.000394093
I0809 05:35:00.162010 20451 solver.cpp:228] Iteration 24620, loss = 0.218867
I0809 05:35:00.162053 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:35:00.162073 20451 solver.cpp:244]     Train net output #1: loss = 0.218868 (* 1 = 0.218868 loss)
I0809 05:35:00.162089 20451 sgd_solver.cpp:106] Iteration 24620, lr = 0.000394008
I0809 05:35:22.480051 20451 solver.cpp:228] Iteration 24630, loss = 0.156256
I0809 05:35:22.480228 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:35:22.480243 20451 solver.cpp:244]     Train net output #1: loss = 0.156257 (* 1 = 0.156257 loss)
I0809 05:35:22.480257 20451 sgd_solver.cpp:106] Iteration 24630, lr = 0.000393922
I0809 05:35:44.801970 20451 solver.cpp:228] Iteration 24640, loss = 0.156277
I0809 05:35:44.802023 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:35:44.802037 20451 solver.cpp:244]     Train net output #1: loss = 0.156278 (* 1 = 0.156278 loss)
I0809 05:35:44.802049 20451 sgd_solver.cpp:106] Iteration 24640, lr = 0.000393837
I0809 05:36:07.117324 20451 solver.cpp:228] Iteration 24650, loss = 0.125045
I0809 05:36:07.117420 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:36:07.117435 20451 solver.cpp:244]     Train net output #1: loss = 0.125045 (* 1 = 0.125045 loss)
I0809 05:36:07.117449 20451 sgd_solver.cpp:106] Iteration 24650, lr = 0.000393752
I0809 05:36:29.431205 20451 solver.cpp:228] Iteration 24660, loss = 0.187512
I0809 05:36:29.431257 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:36:29.431278 20451 solver.cpp:244]     Train net output #1: loss = 0.187512 (* 1 = 0.187512 loss)
I0809 05:36:29.431291 20451 sgd_solver.cpp:106] Iteration 24660, lr = 0.000393667
I0809 05:36:51.740761 20451 solver.cpp:228] Iteration 24670, loss = 0.156263
I0809 05:36:51.740937 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:36:51.740952 20451 solver.cpp:244]     Train net output #1: loss = 0.156264 (* 1 = 0.156264 loss)
I0809 05:36:51.740964 20451 sgd_solver.cpp:106] Iteration 24670, lr = 0.000393581
I0809 05:37:14.053670 20451 solver.cpp:228] Iteration 24680, loss = 0.0937545
I0809 05:37:14.053724 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:37:14.053738 20451 solver.cpp:244]     Train net output #1: loss = 0.0937549 (* 1 = 0.0937549 loss)
I0809 05:37:14.053750 20451 sgd_solver.cpp:106] Iteration 24680, lr = 0.000393496
I0809 05:37:36.358947 20451 solver.cpp:228] Iteration 24690, loss = 0.0312539
I0809 05:37:36.359138 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 05:37:36.359153 20451 solver.cpp:244]     Train net output #1: loss = 0.0312542 (* 1 = 0.0312542 loss)
I0809 05:37:36.359166 20451 sgd_solver.cpp:106] Iteration 24690, lr = 0.000393411
I0809 05:37:56.450125 20451 solver.cpp:337] Iteration 24700, Testing net (#0)
I0809 05:38:04.978265 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0809 05:38:04.978314 20451 solver.cpp:404]     Test net output #1: loss = 1.01721 (* 1 = 1.01721 loss)
I0809 05:38:07.181107 20451 solver.cpp:228] Iteration 24700, loss = 0.0938125
I0809 05:38:07.181311 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:38:07.181329 20451 solver.cpp:244]     Train net output #1: loss = 0.0938128 (* 1 = 0.0938128 loss)
I0809 05:38:07.181341 20451 sgd_solver.cpp:106] Iteration 24700, lr = 0.000393326
I0809 05:38:29.475344 20451 solver.cpp:228] Iteration 24710, loss = 0.218883
I0809 05:38:29.475397 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:38:29.475411 20451 solver.cpp:244]     Train net output #1: loss = 0.218884 (* 1 = 0.218884 loss)
I0809 05:38:29.475425 20451 sgd_solver.cpp:106] Iteration 24710, lr = 0.000393241
I0809 05:38:51.786444 20451 solver.cpp:228] Iteration 24720, loss = 0.125133
I0809 05:38:51.786628 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:38:51.786643 20451 solver.cpp:244]     Train net output #1: loss = 0.125133 (* 1 = 0.125133 loss)
I0809 05:38:51.786655 20451 sgd_solver.cpp:106] Iteration 24720, lr = 0.000393156
I0809 05:39:14.102861 20451 solver.cpp:228] Iteration 24730, loss = 0.0937918
I0809 05:39:14.102902 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:39:14.102917 20451 solver.cpp:244]     Train net output #1: loss = 0.0937921 (* 1 = 0.0937921 loss)
I0809 05:39:14.102931 20451 sgd_solver.cpp:106] Iteration 24730, lr = 0.000393071
I0809 05:39:36.410809 20451 solver.cpp:228] Iteration 24740, loss = 0.187575
I0809 05:39:36.410984 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:39:36.410998 20451 solver.cpp:244]     Train net output #1: loss = 0.187576 (* 1 = 0.187576 loss)
I0809 05:39:36.411011 20451 sgd_solver.cpp:106] Iteration 24740, lr = 0.000392987
I0809 05:39:58.726745 20451 solver.cpp:228] Iteration 24750, loss = 0.125014
I0809 05:39:58.726790 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:39:58.726809 20451 solver.cpp:244]     Train net output #1: loss = 0.125014 (* 1 = 0.125014 loss)
I0809 05:39:58.726824 20451 sgd_solver.cpp:106] Iteration 24750, lr = 0.000392902
I0809 05:40:21.050076 20451 solver.cpp:228] Iteration 24760, loss = 0.18756
I0809 05:40:21.050194 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:40:21.050215 20451 solver.cpp:244]     Train net output #1: loss = 0.187561 (* 1 = 0.187561 loss)
I0809 05:40:21.050230 20451 sgd_solver.cpp:106] Iteration 24760, lr = 0.000392817
I0809 05:40:43.373232 20451 solver.cpp:228] Iteration 24770, loss = 0.187553
I0809 05:40:43.373284 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:40:43.373298 20451 solver.cpp:244]     Train net output #1: loss = 0.187554 (* 1 = 0.187554 loss)
I0809 05:40:43.373311 20451 sgd_solver.cpp:106] Iteration 24770, lr = 0.000392732
I0809 05:41:05.692831 20451 solver.cpp:228] Iteration 24780, loss = 0.218777
I0809 05:41:05.693011 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:41:05.693025 20451 solver.cpp:244]     Train net output #1: loss = 0.218778 (* 1 = 0.218778 loss)
I0809 05:41:05.693038 20451 sgd_solver.cpp:106] Iteration 24780, lr = 0.000392648
I0809 05:41:27.997431 20451 solver.cpp:228] Iteration 24790, loss = 0.187518
I0809 05:41:27.997480 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:41:27.997496 20451 solver.cpp:244]     Train net output #1: loss = 0.187519 (* 1 = 0.187519 loss)
I0809 05:41:27.997509 20451 sgd_solver.cpp:106] Iteration 24790, lr = 0.000392563
I0809 05:41:48.090301 20451 solver.cpp:337] Iteration 24800, Testing net (#0)
I0809 05:41:56.614054 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 05:41:56.614106 20451 solver.cpp:404]     Test net output #1: loss = 1.00319 (* 1 = 1.00319 loss)
I0809 05:41:58.814275 20451 solver.cpp:228] Iteration 24800, loss = 0.187518
I0809 05:41:58.814340 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:41:58.814360 20451 solver.cpp:244]     Train net output #1: loss = 0.187518 (* 1 = 0.187518 loss)
I0809 05:41:58.814379 20451 sgd_solver.cpp:106] Iteration 24800, lr = 0.000392478
I0809 05:42:21.091912 20451 solver.cpp:228] Iteration 24810, loss = 0.125023
I0809 05:42:21.092124 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:42:21.092140 20451 solver.cpp:244]     Train net output #1: loss = 0.125023 (* 1 = 0.125023 loss)
I0809 05:42:21.092154 20451 sgd_solver.cpp:106] Iteration 24810, lr = 0.000392394
I0809 05:42:43.396567 20451 solver.cpp:228] Iteration 24820, loss = 0.0626149
I0809 05:42:43.396621 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 05:42:43.396636 20451 solver.cpp:244]     Train net output #1: loss = 0.0626153 (* 1 = 0.0626153 loss)
I0809 05:42:43.396647 20451 sgd_solver.cpp:106] Iteration 24820, lr = 0.000392309
I0809 05:43:05.712843 20451 solver.cpp:228] Iteration 24830, loss = 0.0937672
I0809 05:43:05.713026 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:43:05.713040 20451 solver.cpp:244]     Train net output #1: loss = 0.0937675 (* 1 = 0.0937675 loss)
I0809 05:43:05.713052 20451 sgd_solver.cpp:106] Iteration 24830, lr = 0.000392225
I0809 05:43:28.022111 20451 solver.cpp:228] Iteration 24840, loss = 0.125144
I0809 05:43:28.022156 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:43:28.022171 20451 solver.cpp:244]     Train net output #1: loss = 0.125144 (* 1 = 0.125144 loss)
I0809 05:43:28.022183 20451 sgd_solver.cpp:106] Iteration 24840, lr = 0.00039214
I0809 05:43:50.326349 20451 solver.cpp:228] Iteration 24850, loss = 0.343956
I0809 05:43:50.326529 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:43:50.326544 20451 solver.cpp:244]     Train net output #1: loss = 0.343956 (* 1 = 0.343956 loss)
I0809 05:43:50.326555 20451 sgd_solver.cpp:106] Iteration 24850, lr = 0.000392056
I0809 05:44:12.645206 20451 solver.cpp:228] Iteration 24860, loss = 0.187815
I0809 05:44:12.645258 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:44:12.645272 20451 solver.cpp:244]     Train net output #1: loss = 0.187816 (* 1 = 0.187816 loss)
I0809 05:44:12.645283 20451 sgd_solver.cpp:106] Iteration 24860, lr = 0.000391971
I0809 05:44:34.959820 20451 solver.cpp:228] Iteration 24870, loss = 0.218754
I0809 05:44:34.959990 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:44:34.960005 20451 solver.cpp:244]     Train net output #1: loss = 0.218755 (* 1 = 0.218755 loss)
I0809 05:44:34.960017 20451 sgd_solver.cpp:106] Iteration 24870, lr = 0.000391887
I0809 05:44:57.275653 20451 solver.cpp:228] Iteration 24880, loss = 0.219046
I0809 05:44:57.275707 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:44:57.275720 20451 solver.cpp:244]     Train net output #1: loss = 0.219046 (* 1 = 0.219046 loss)
I0809 05:44:57.275732 20451 sgd_solver.cpp:106] Iteration 24880, lr = 0.000391803
I0809 05:45:19.587656 20451 solver.cpp:228] Iteration 24890, loss = 0.15625
I0809 05:45:19.587834 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:45:19.587849 20451 solver.cpp:244]     Train net output #1: loss = 0.15625 (* 1 = 0.15625 loss)
I0809 05:45:19.587862 20451 sgd_solver.cpp:106] Iteration 24890, lr = 0.000391719
I0809 05:45:39.665328 20451 solver.cpp:337] Iteration 24900, Testing net (#0)
I0809 05:45:48.191853 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 05:45:48.191903 20451 solver.cpp:404]     Test net output #1: loss = 0.975793 (* 1 = 0.975793 loss)
I0809 05:45:50.394276 20451 solver.cpp:228] Iteration 24900, loss = 0.0938636
I0809 05:45:50.394457 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:45:50.394474 20451 solver.cpp:244]     Train net output #1: loss = 0.093864 (* 1 = 0.093864 loss)
I0809 05:45:50.394486 20451 sgd_solver.cpp:106] Iteration 24900, lr = 0.000391635
I0809 05:46:12.679635 20451 solver.cpp:228] Iteration 24910, loss = 0.187513
I0809 05:46:12.679675 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:46:12.679689 20451 solver.cpp:244]     Train net output #1: loss = 0.187513 (* 1 = 0.187513 loss)
I0809 05:46:12.679702 20451 sgd_solver.cpp:106] Iteration 24910, lr = 0.00039155
I0809 05:46:34.985640 20451 solver.cpp:228] Iteration 24920, loss = 0.125086
I0809 05:46:34.985775 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:46:34.985791 20451 solver.cpp:244]     Train net output #1: loss = 0.125086 (* 1 = 0.125086 loss)
I0809 05:46:34.985805 20451 sgd_solver.cpp:106] Iteration 24920, lr = 0.000391466
I0809 05:46:57.289149 20451 solver.cpp:228] Iteration 24930, loss = 0.187547
I0809 05:46:57.289201 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:46:57.289216 20451 solver.cpp:244]     Train net output #1: loss = 0.187547 (* 1 = 0.187547 loss)
I0809 05:46:57.289227 20451 sgd_solver.cpp:106] Iteration 24930, lr = 0.000391382
I0809 05:47:19.585139 20451 solver.cpp:228] Iteration 24940, loss = 0.125055
I0809 05:47:19.585314 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:47:19.585327 20451 solver.cpp:244]     Train net output #1: loss = 0.125056 (* 1 = 0.125056 loss)
I0809 05:47:19.585340 20451 sgd_solver.cpp:106] Iteration 24940, lr = 0.000391298
I0809 05:47:41.893724 20451 solver.cpp:228] Iteration 24950, loss = 0.0937796
I0809 05:47:41.893777 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:47:41.893792 20451 solver.cpp:244]     Train net output #1: loss = 0.0937799 (* 1 = 0.0937799 loss)
I0809 05:47:41.893803 20451 sgd_solver.cpp:106] Iteration 24950, lr = 0.000391214
I0809 05:48:04.204815 20451 solver.cpp:228] Iteration 24960, loss = 0.187564
I0809 05:48:04.204995 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:48:04.205010 20451 solver.cpp:244]     Train net output #1: loss = 0.187565 (* 1 = 0.187565 loss)
I0809 05:48:04.205024 20451 sgd_solver.cpp:106] Iteration 24960, lr = 0.00039113
I0809 05:48:26.516899 20451 solver.cpp:228] Iteration 24970, loss = 0.250097
I0809 05:48:26.516945 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:48:26.516960 20451 solver.cpp:244]     Train net output #1: loss = 0.250097 (* 1 = 0.250097 loss)
I0809 05:48:26.516974 20451 sgd_solver.cpp:106] Iteration 24970, lr = 0.000391046
I0809 05:48:48.827050 20451 solver.cpp:228] Iteration 24980, loss = 0.156332
I0809 05:48:48.827229 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:48:48.827244 20451 solver.cpp:244]     Train net output #1: loss = 0.156333 (* 1 = 0.156333 loss)
I0809 05:48:48.827257 20451 sgd_solver.cpp:106] Iteration 24980, lr = 0.000390963
I0809 05:49:11.141870 20451 solver.cpp:228] Iteration 24990, loss = 0.0937855
I0809 05:49:11.141924 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:49:11.141938 20451 solver.cpp:244]     Train net output #1: loss = 0.0937859 (* 1 = 0.0937859 loss)
I0809 05:49:11.141950 20451 sgd_solver.cpp:106] Iteration 24990, lr = 0.000390879
I0809 05:49:31.221179 20451 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_25000.caffemodel
I0809 05:49:31.412775 20451 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_25000.solverstate
I0809 05:49:31.415374 20451 solver.cpp:337] Iteration 25000, Testing net (#0)
I0809 05:49:39.915448 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 05:49:39.915500 20451 solver.cpp:404]     Test net output #1: loss = 0.99408 (* 1 = 0.99408 loss)
I0809 05:49:42.115682 20451 solver.cpp:228] Iteration 25000, loss = 0.0312652
I0809 05:49:42.115732 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 05:49:42.115746 20451 solver.cpp:244]     Train net output #1: loss = 0.0312655 (* 1 = 0.0312655 loss)
I0809 05:49:42.115758 20451 sgd_solver.cpp:106] Iteration 25000, lr = 0.000390795
I0809 05:50:04.417716 20451 solver.cpp:228] Iteration 25010, loss = 0.0938186
I0809 05:50:04.417891 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:50:04.417906 20451 solver.cpp:244]     Train net output #1: loss = 0.0938189 (* 1 = 0.0938189 loss)
I0809 05:50:04.417920 20451 sgd_solver.cpp:106] Iteration 25010, lr = 0.000390711
I0809 05:50:26.726462 20451 solver.cpp:228] Iteration 25020, loss = 0.156436
I0809 05:50:26.726516 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:50:26.726528 20451 solver.cpp:244]     Train net output #1: loss = 0.156436 (* 1 = 0.156436 loss)
I0809 05:50:26.726541 20451 sgd_solver.cpp:106] Iteration 25020, lr = 0.000390628
I0809 05:50:49.036530 20451 solver.cpp:228] Iteration 25030, loss = 0.281433
I0809 05:50:49.036751 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 05:50:49.036767 20451 solver.cpp:244]     Train net output #1: loss = 0.281433 (* 1 = 0.281433 loss)
I0809 05:50:49.036779 20451 sgd_solver.cpp:106] Iteration 25030, lr = 0.000390544
I0809 05:51:11.345788 20451 solver.cpp:228] Iteration 25040, loss = 0.281478
I0809 05:51:11.345830 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 05:51:11.345845 20451 solver.cpp:244]     Train net output #1: loss = 0.281478 (* 1 = 0.281478 loss)
I0809 05:51:11.345859 20451 sgd_solver.cpp:106] Iteration 25040, lr = 0.00039046
I0809 05:51:33.658080 20451 solver.cpp:228] Iteration 25050, loss = 0.25033
I0809 05:51:33.658184 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 05:51:33.658202 20451 solver.cpp:244]     Train net output #1: loss = 0.250331 (* 1 = 0.250331 loss)
I0809 05:51:33.658217 20451 sgd_solver.cpp:106] Iteration 25050, lr = 0.000390377
I0809 05:51:55.956462 20451 solver.cpp:228] Iteration 25060, loss = 0.187725
I0809 05:51:55.956506 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:51:55.956526 20451 solver.cpp:244]     Train net output #1: loss = 0.187725 (* 1 = 0.187725 loss)
I0809 05:51:55.956540 20451 sgd_solver.cpp:106] Iteration 25060, lr = 0.000390293
I0809 05:52:18.260993 20451 solver.cpp:228] Iteration 25070, loss = 0.125015
I0809 05:52:18.261181 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:52:18.261199 20451 solver.cpp:244]     Train net output #1: loss = 0.125015 (* 1 = 0.125015 loss)
I0809 05:52:18.261212 20451 sgd_solver.cpp:106] Iteration 25070, lr = 0.00039021
I0809 05:52:40.570386 20451 solver.cpp:228] Iteration 25080, loss = 0.156343
I0809 05:52:40.570438 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:52:40.570453 20451 solver.cpp:244]     Train net output #1: loss = 0.156343 (* 1 = 0.156343 loss)
I0809 05:52:40.570464 20451 sgd_solver.cpp:106] Iteration 25080, lr = 0.000390126
I0809 05:53:02.873095 20451 solver.cpp:228] Iteration 25090, loss = 0.43792
I0809 05:53:02.873273 20451 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0809 05:53:02.873288 20451 solver.cpp:244]     Train net output #1: loss = 0.43792 (* 1 = 0.43792 loss)
I0809 05:53:02.873301 20451 sgd_solver.cpp:106] Iteration 25090, lr = 0.000390043
I0809 05:53:22.951319 20451 solver.cpp:337] Iteration 25100, Testing net (#0)
I0809 05:53:31.477466 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 05:53:31.477520 20451 solver.cpp:404]     Test net output #1: loss = 1.00317 (* 1 = 1.00317 loss)
I0809 05:53:33.683765 20451 solver.cpp:228] Iteration 25100, loss = 0.218763
I0809 05:53:33.683861 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:53:33.683876 20451 solver.cpp:244]     Train net output #1: loss = 0.218763 (* 1 = 0.218763 loss)
I0809 05:53:33.683888 20451 sgd_solver.cpp:106] Iteration 25100, lr = 0.00038996
I0809 05:53:55.965109 20451 solver.cpp:228] Iteration 25110, loss = 0.125211
I0809 05:53:55.965162 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:53:55.965176 20451 solver.cpp:244]     Train net output #1: loss = 0.125211 (* 1 = 0.125211 loss)
I0809 05:53:55.965188 20451 sgd_solver.cpp:106] Iteration 25110, lr = 0.000389876
I0809 05:54:18.277237 20451 solver.cpp:228] Iteration 25120, loss = 0.156318
I0809 05:54:18.277453 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:54:18.277469 20451 solver.cpp:244]     Train net output #1: loss = 0.156318 (* 1 = 0.156318 loss)
I0809 05:54:18.277482 20451 sgd_solver.cpp:106] Iteration 25120, lr = 0.000389793
I0809 05:54:40.583552 20451 solver.cpp:228] Iteration 25130, loss = 0.156411
I0809 05:54:40.583607 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:54:40.583621 20451 solver.cpp:244]     Train net output #1: loss = 0.156411 (* 1 = 0.156411 loss)
I0809 05:54:40.583633 20451 sgd_solver.cpp:106] Iteration 25130, lr = 0.00038971
I0809 05:55:02.898535 20451 solver.cpp:228] Iteration 25140, loss = 0.0937616
I0809 05:55:02.898795 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:55:02.898811 20451 solver.cpp:244]     Train net output #1: loss = 0.0937619 (* 1 = 0.0937619 loss)
I0809 05:55:02.898824 20451 sgd_solver.cpp:106] Iteration 25140, lr = 0.000389627
I0809 05:55:25.201045 20451 solver.cpp:228] Iteration 25150, loss = 0.156324
I0809 05:55:25.201098 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:55:25.201112 20451 solver.cpp:244]     Train net output #1: loss = 0.156325 (* 1 = 0.156325 loss)
I0809 05:55:25.201123 20451 sgd_solver.cpp:106] Iteration 25150, lr = 0.000389544
I0809 05:55:47.512279 20451 solver.cpp:228] Iteration 25160, loss = 0.343942
I0809 05:55:47.512390 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:55:47.512406 20451 solver.cpp:244]     Train net output #1: loss = 0.343943 (* 1 = 0.343943 loss)
I0809 05:55:47.512419 20451 sgd_solver.cpp:106] Iteration 25160, lr = 0.00038946
I0809 05:56:09.834343 20451 solver.cpp:228] Iteration 25170, loss = 0.156482
I0809 05:56:09.834394 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:56:09.834408 20451 solver.cpp:244]     Train net output #1: loss = 0.156482 (* 1 = 0.156482 loss)
I0809 05:56:09.834420 20451 sgd_solver.cpp:106] Iteration 25170, lr = 0.000389377
I0809 05:56:32.138798 20451 solver.cpp:228] Iteration 25180, loss = 0.0939374
I0809 05:56:32.138972 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:56:32.138988 20451 solver.cpp:244]     Train net output #1: loss = 0.0939377 (* 1 = 0.0939377 loss)
I0809 05:56:32.139001 20451 sgd_solver.cpp:106] Iteration 25180, lr = 0.000389294
I0809 05:56:54.438405 20451 solver.cpp:228] Iteration 25190, loss = 0.0937792
I0809 05:56:54.438457 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:56:54.438472 20451 solver.cpp:244]     Train net output #1: loss = 0.0937795 (* 1 = 0.0937795 loss)
I0809 05:56:54.438483 20451 sgd_solver.cpp:106] Iteration 25190, lr = 0.000389211
I0809 05:57:14.519333 20451 solver.cpp:337] Iteration 25200, Testing net (#0)
I0809 05:57:23.043783 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0809 05:57:23.043828 20451 solver.cpp:404]     Test net output #1: loss = 0.96598 (* 1 = 0.96598 loss)
I0809 05:57:25.243842 20451 solver.cpp:228] Iteration 25200, loss = 0.156335
I0809 05:57:25.243896 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 05:57:25.243911 20451 solver.cpp:244]     Train net output #1: loss = 0.156336 (* 1 = 0.156336 loss)
I0809 05:57:25.243923 20451 sgd_solver.cpp:106] Iteration 25200, lr = 0.000389128
I0809 05:57:47.526556 20451 solver.cpp:228] Iteration 25210, loss = 0.31255
I0809 05:57:47.526738 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 05:57:47.526753 20451 solver.cpp:244]     Train net output #1: loss = 0.31255 (* 1 = 0.31255 loss)
I0809 05:57:47.526765 20451 sgd_solver.cpp:106] Iteration 25210, lr = 0.000389046
I0809 05:58:09.834475 20451 solver.cpp:228] Iteration 25220, loss = 0.21886
I0809 05:58:09.834528 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 05:58:09.834543 20451 solver.cpp:244]     Train net output #1: loss = 0.218861 (* 1 = 0.218861 loss)
I0809 05:58:09.834555 20451 sgd_solver.cpp:106] Iteration 25220, lr = 0.000388963
I0809 05:58:32.155838 20451 solver.cpp:228] Iteration 25230, loss = 0.125014
I0809 05:58:32.156061 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 05:58:32.156077 20451 solver.cpp:244]     Train net output #1: loss = 0.125015 (* 1 = 0.125015 loss)
I0809 05:58:32.156090 20451 sgd_solver.cpp:106] Iteration 25230, lr = 0.00038888
I0809 05:58:54.459233 20451 solver.cpp:228] Iteration 25240, loss = 0.0938039
I0809 05:58:54.459288 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 05:58:54.459307 20451 solver.cpp:244]     Train net output #1: loss = 0.0938042 (* 1 = 0.0938042 loss)
I0809 05:58:54.459322 20451 sgd_solver.cpp:106] Iteration 25240, lr = 0.000388797
I0809 05:59:16.764312 20451 solver.cpp:228] Iteration 25250, loss = 0.250005
I0809 05:59:16.764405 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 05:59:16.764420 20451 solver.cpp:244]     Train net output #1: loss = 0.250005 (* 1 = 0.250005 loss)
I0809 05:59:16.764433 20451 sgd_solver.cpp:106] Iteration 25250, lr = 0.000388714
I0809 05:59:39.063863 20451 solver.cpp:228] Iteration 25260, loss = 0.187554
I0809 05:59:39.063911 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 05:59:39.063931 20451 solver.cpp:244]     Train net output #1: loss = 0.187554 (* 1 = 0.187554 loss)
I0809 05:59:39.063946 20451 sgd_solver.cpp:106] Iteration 25260, lr = 0.000388632
I0809 06:00:01.369086 20451 solver.cpp:228] Iteration 25270, loss = 0.218789
I0809 06:00:01.369264 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 06:00:01.369282 20451 solver.cpp:244]     Train net output #1: loss = 0.21879 (* 1 = 0.21879 loss)
I0809 06:00:01.369297 20451 sgd_solver.cpp:106] Iteration 25270, lr = 0.000388549
I0809 06:00:23.676882 20451 solver.cpp:228] Iteration 25280, loss = 0.156434
I0809 06:00:23.676925 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 06:00:23.676942 20451 solver.cpp:244]     Train net output #1: loss = 0.156434 (* 1 = 0.156434 loss)
I0809 06:00:23.676957 20451 sgd_solver.cpp:106] Iteration 25280, lr = 0.000388467
I0809 06:00:45.993136 20451 solver.cpp:228] Iteration 25290, loss = 0.125035
I0809 06:00:45.993240 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:00:45.993257 20451 solver.cpp:244]     Train net output #1: loss = 0.125035 (* 1 = 0.125035 loss)
I0809 06:00:45.993269 20451 sgd_solver.cpp:106] Iteration 25290, lr = 0.000388384
I0809 06:01:06.082952 20451 solver.cpp:337] Iteration 25300, Testing net (#0)
I0809 06:01:14.609380 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0809 06:01:14.609426 20451 solver.cpp:404]     Test net output #1: loss = 1.03143 (* 1 = 1.03143 loss)
I0809 06:01:16.812449 20451 solver.cpp:228] Iteration 25300, loss = 0.125032
I0809 06:01:16.812635 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:01:16.812652 20451 solver.cpp:244]     Train net output #1: loss = 0.125032 (* 1 = 0.125032 loss)
I0809 06:01:16.812667 20451 sgd_solver.cpp:106] Iteration 25300, lr = 0.000388301
I0809 06:01:39.096320 20451 solver.cpp:228] Iteration 25310, loss = 0.125018
I0809 06:01:39.096372 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:01:39.096386 20451 solver.cpp:244]     Train net output #1: loss = 0.125018 (* 1 = 0.125018 loss)
I0809 06:01:39.096398 20451 sgd_solver.cpp:106] Iteration 25310, lr = 0.000388219
I0809 06:02:01.410022 20451 solver.cpp:228] Iteration 25320, loss = 0.312661
I0809 06:02:01.410217 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 06:02:01.410233 20451 solver.cpp:244]     Train net output #1: loss = 0.312661 (* 1 = 0.312661 loss)
I0809 06:02:01.410244 20451 sgd_solver.cpp:106] Iteration 25320, lr = 0.000388137
I0809 06:02:23.719528 20451 solver.cpp:228] Iteration 25330, loss = 0.250147
I0809 06:02:23.719578 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:02:23.719593 20451 solver.cpp:244]     Train net output #1: loss = 0.250148 (* 1 = 0.250148 loss)
I0809 06:02:23.719604 20451 sgd_solver.cpp:106] Iteration 25330, lr = 0.000388054
I0809 06:02:46.026595 20451 solver.cpp:228] Iteration 25340, loss = 0.187571
I0809 06:02:46.026811 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:02:46.026826 20451 solver.cpp:244]     Train net output #1: loss = 0.187572 (* 1 = 0.187572 loss)
I0809 06:02:46.026839 20451 sgd_solver.cpp:106] Iteration 25340, lr = 0.000387972
I0809 06:03:08.336567 20451 solver.cpp:228] Iteration 25350, loss = 0.125053
I0809 06:03:08.336619 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:03:08.336634 20451 solver.cpp:244]     Train net output #1: loss = 0.125054 (* 1 = 0.125054 loss)
I0809 06:03:08.336647 20451 sgd_solver.cpp:106] Iteration 25350, lr = 0.000387889
I0809 06:03:30.651831 20451 solver.cpp:228] Iteration 25360, loss = 0.093779
I0809 06:03:30.652011 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:03:30.652027 20451 solver.cpp:244]     Train net output #1: loss = 0.0937793 (* 1 = 0.0937793 loss)
I0809 06:03:30.652040 20451 sgd_solver.cpp:106] Iteration 25360, lr = 0.000387807
I0809 06:03:52.960310 20451 solver.cpp:228] Iteration 25370, loss = 0.125041
I0809 06:03:52.960362 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:03:52.960376 20451 solver.cpp:244]     Train net output #1: loss = 0.125041 (* 1 = 0.125041 loss)
I0809 06:03:52.960388 20451 sgd_solver.cpp:106] Iteration 25370, lr = 0.000387725
I0809 06:04:15.270731 20451 solver.cpp:228] Iteration 25380, loss = 0.281383
I0809 06:04:15.270905 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 06:04:15.270920 20451 solver.cpp:244]     Train net output #1: loss = 0.281383 (* 1 = 0.281383 loss)
I0809 06:04:15.270932 20451 sgd_solver.cpp:106] Iteration 25380, lr = 0.000387643
I0809 06:04:37.591980 20451 solver.cpp:228] Iteration 25390, loss = 0.3439
I0809 06:04:37.592032 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 06:04:37.592046 20451 solver.cpp:244]     Train net output #1: loss = 0.3439 (* 1 = 0.3439 loss)
I0809 06:04:37.592058 20451 sgd_solver.cpp:106] Iteration 25390, lr = 0.000387561
I0809 06:04:57.680619 20451 solver.cpp:337] Iteration 25400, Testing net (#0)
I0809 06:05:06.211947 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 06:05:06.211997 20451 solver.cpp:404]     Test net output #1: loss = 1.00327 (* 1 = 1.00327 loss)
I0809 06:05:08.416081 20451 solver.cpp:228] Iteration 25400, loss = 0.250054
I0809 06:05:08.416131 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:05:08.416144 20451 solver.cpp:244]     Train net output #1: loss = 0.250055 (* 1 = 0.250055 loss)
I0809 06:05:08.416157 20451 sgd_solver.cpp:106] Iteration 25400, lr = 0.000387478
I0809 06:05:30.696068 20451 solver.cpp:228] Iteration 25410, loss = 0.15627
I0809 06:05:30.696244 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:05:30.696259 20451 solver.cpp:244]     Train net output #1: loss = 0.15627 (* 1 = 0.15627 loss)
I0809 06:05:30.696272 20451 sgd_solver.cpp:106] Iteration 25410, lr = 0.000387396
I0809 06:05:53.002527 20451 solver.cpp:228] Iteration 25420, loss = 0.218777
I0809 06:05:53.002579 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 06:05:53.002593 20451 solver.cpp:244]     Train net output #1: loss = 0.218777 (* 1 = 0.218777 loss)
I0809 06:05:53.002605 20451 sgd_solver.cpp:106] Iteration 25420, lr = 0.000387314
I0809 06:06:15.323848 20451 solver.cpp:228] Iteration 25430, loss = 0.187546
I0809 06:06:15.324039 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:06:15.324055 20451 solver.cpp:244]     Train net output #1: loss = 0.187547 (* 1 = 0.187547 loss)
I0809 06:06:15.324067 20451 sgd_solver.cpp:106] Iteration 25430, lr = 0.000387232
I0809 06:06:37.634706 20451 solver.cpp:228] Iteration 25440, loss = 0.281325
I0809 06:06:37.634757 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 06:06:37.634771 20451 solver.cpp:244]     Train net output #1: loss = 0.281325 (* 1 = 0.281325 loss)
I0809 06:06:37.634784 20451 sgd_solver.cpp:106] Iteration 25440, lr = 0.00038715
I0809 06:06:59.956122 20451 solver.cpp:228] Iteration 25450, loss = 0.28138
I0809 06:06:59.956332 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 06:06:59.956348 20451 solver.cpp:244]     Train net output #1: loss = 0.281381 (* 1 = 0.281381 loss)
I0809 06:06:59.956360 20451 sgd_solver.cpp:106] Iteration 25450, lr = 0.000387069
I0809 06:07:22.265796 20451 solver.cpp:228] Iteration 25460, loss = 0.156282
I0809 06:07:22.265848 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:07:22.265862 20451 solver.cpp:244]     Train net output #1: loss = 0.156282 (* 1 = 0.156282 loss)
I0809 06:07:22.265873 20451 sgd_solver.cpp:106] Iteration 25460, lr = 0.000386987
I0809 06:07:44.582799 20451 solver.cpp:228] Iteration 25470, loss = 0.125041
I0809 06:07:44.582975 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:07:44.582989 20451 solver.cpp:244]     Train net output #1: loss = 0.125041 (* 1 = 0.125041 loss)
I0809 06:07:44.583003 20451 sgd_solver.cpp:106] Iteration 25470, lr = 0.000386905
I0809 06:08:06.896172 20451 solver.cpp:228] Iteration 25480, loss = 0.21883
I0809 06:08:06.896224 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 06:08:06.896239 20451 solver.cpp:244]     Train net output #1: loss = 0.21883 (* 1 = 0.21883 loss)
I0809 06:08:06.896251 20451 sgd_solver.cpp:106] Iteration 25480, lr = 0.000386823
I0809 06:08:29.209631 20451 solver.cpp:228] Iteration 25490, loss = 0.18751
I0809 06:08:29.209825 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 06:08:29.209839 20451 solver.cpp:244]     Train net output #1: loss = 0.18751 (* 1 = 0.18751 loss)
I0809 06:08:29.209853 20451 sgd_solver.cpp:106] Iteration 25490, lr = 0.000386741
I0809 06:08:49.288166 20451 solver.cpp:337] Iteration 25500, Testing net (#0)
I0809 06:08:57.811949 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 06:08:57.812000 20451 solver.cpp:404]     Test net output #1: loss = 0.984482 (* 1 = 0.984482 loss)
I0809 06:09:00.017436 20451 solver.cpp:228] Iteration 25500, loss = 0.31255
I0809 06:09:00.017611 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 06:09:00.017627 20451 solver.cpp:244]     Train net output #1: loss = 0.31255 (* 1 = 0.31255 loss)
I0809 06:09:00.017639 20451 sgd_solver.cpp:106] Iteration 25500, lr = 0.00038666
I0809 06:09:22.315999 20451 solver.cpp:228] Iteration 25510, loss = 0.250043
I0809 06:09:22.316045 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:09:22.316059 20451 solver.cpp:244]     Train net output #1: loss = 0.250043 (* 1 = 0.250043 loss)
I0809 06:09:22.316071 20451 sgd_solver.cpp:106] Iteration 25510, lr = 0.000386578
I0809 06:09:44.633726 20451 solver.cpp:228] Iteration 25520, loss = 0.0938826
I0809 06:09:44.633915 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 06:09:44.633931 20451 solver.cpp:244]     Train net output #1: loss = 0.0938829 (* 1 = 0.0938829 loss)
I0809 06:09:44.633944 20451 sgd_solver.cpp:106] Iteration 25520, lr = 0.000386496
I0809 06:10:06.943047 20451 solver.cpp:228] Iteration 25530, loss = 0.0937962
I0809 06:10:06.943089 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:10:06.943104 20451 solver.cpp:244]     Train net output #1: loss = 0.0937965 (* 1 = 0.0937965 loss)
I0809 06:10:06.943117 20451 sgd_solver.cpp:106] Iteration 25530, lr = 0.000386415
I0809 06:10:29.264127 20451 solver.cpp:228] Iteration 25540, loss = 0.125046
I0809 06:10:29.264231 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:10:29.264246 20451 solver.cpp:244]     Train net output #1: loss = 0.125046 (* 1 = 0.125046 loss)
I0809 06:10:29.264259 20451 sgd_solver.cpp:106] Iteration 25540, lr = 0.000386333
I0809 06:10:51.566692 20451 solver.cpp:228] Iteration 25550, loss = 0.156321
I0809 06:10:51.566742 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:10:51.566757 20451 solver.cpp:244]     Train net output #1: loss = 0.156321 (* 1 = 0.156321 loss)
I0809 06:10:51.566771 20451 sgd_solver.cpp:106] Iteration 25550, lr = 0.000386252
I0809 06:11:13.878134 20451 solver.cpp:228] Iteration 25560, loss = 0.125022
I0809 06:11:13.879341 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:11:13.879361 20451 solver.cpp:244]     Train net output #1: loss = 0.125022 (* 1 = 0.125022 loss)
I0809 06:11:13.879376 20451 sgd_solver.cpp:106] Iteration 25560, lr = 0.00038617
I0809 06:11:36.190165 20451 solver.cpp:228] Iteration 25570, loss = 0.125049
I0809 06:11:36.190215 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:11:36.190229 20451 solver.cpp:244]     Train net output #1: loss = 0.125049 (* 1 = 0.125049 loss)
I0809 06:11:36.190242 20451 sgd_solver.cpp:106] Iteration 25570, lr = 0.000386089
I0809 06:11:58.506083 20451 solver.cpp:228] Iteration 25580, loss = 0.0312537
I0809 06:11:58.506261 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 06:11:58.506278 20451 solver.cpp:244]     Train net output #1: loss = 0.0312541 (* 1 = 0.0312541 loss)
I0809 06:11:58.506290 20451 sgd_solver.cpp:106] Iteration 25580, lr = 0.000386007
I0809 06:12:20.806888 20451 solver.cpp:228] Iteration 25590, loss = 0.0937653
I0809 06:12:20.806941 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:12:20.806957 20451 solver.cpp:244]     Train net output #1: loss = 0.0937656 (* 1 = 0.0937656 loss)
I0809 06:12:20.806969 20451 sgd_solver.cpp:106] Iteration 25590, lr = 0.000385926
I0809 06:12:40.883126 20451 solver.cpp:337] Iteration 25600, Testing net (#0)
I0809 06:12:49.408710 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 06:12:49.408762 20451 solver.cpp:404]     Test net output #1: loss = 0.998697 (* 1 = 0.998697 loss)
I0809 06:12:51.610787 20451 solver.cpp:228] Iteration 25600, loss = 0.250096
I0809 06:12:51.610837 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:12:51.610852 20451 solver.cpp:244]     Train net output #1: loss = 0.250097 (* 1 = 0.250097 loss)
I0809 06:12:51.610862 20451 sgd_solver.cpp:106] Iteration 25600, lr = 0.000385845
I0809 06:13:13.893245 20451 solver.cpp:228] Iteration 25610, loss = 0.187593
I0809 06:13:13.893347 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:13:13.893363 20451 solver.cpp:244]     Train net output #1: loss = 0.187593 (* 1 = 0.187593 loss)
I0809 06:13:13.893376 20451 sgd_solver.cpp:106] Iteration 25610, lr = 0.000385763
I0809 06:13:36.191464 20451 solver.cpp:228] Iteration 25620, loss = 0.0312598
I0809 06:13:36.191516 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 06:13:36.191530 20451 solver.cpp:244]     Train net output #1: loss = 0.0312601 (* 1 = 0.0312601 loss)
I0809 06:13:36.191542 20451 sgd_solver.cpp:106] Iteration 25620, lr = 0.000385682
I0809 06:13:58.500334 20451 solver.cpp:228] Iteration 25630, loss = 0.156289
I0809 06:13:58.500506 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:13:58.500521 20451 solver.cpp:244]     Train net output #1: loss = 0.156289 (* 1 = 0.156289 loss)
I0809 06:13:58.500535 20451 sgd_solver.cpp:106] Iteration 25630, lr = 0.000385601
I0809 06:14:20.809058 20451 solver.cpp:228] Iteration 25640, loss = 0.218783
I0809 06:14:20.809111 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 06:14:20.809125 20451 solver.cpp:244]     Train net output #1: loss = 0.218783 (* 1 = 0.218783 loss)
I0809 06:14:20.809136 20451 sgd_solver.cpp:106] Iteration 25640, lr = 0.00038552
I0809 06:14:43.108636 20451 solver.cpp:228] Iteration 25650, loss = 0.18762
I0809 06:14:43.108819 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:14:43.108834 20451 solver.cpp:244]     Train net output #1: loss = 0.187621 (* 1 = 0.187621 loss)
I0809 06:14:43.108847 20451 sgd_solver.cpp:106] Iteration 25650, lr = 0.000385439
I0809 06:15:05.420538 20451 solver.cpp:228] Iteration 25660, loss = 0.125038
I0809 06:15:05.420593 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:15:05.420606 20451 solver.cpp:244]     Train net output #1: loss = 0.125039 (* 1 = 0.125039 loss)
I0809 06:15:05.420619 20451 sgd_solver.cpp:106] Iteration 25660, lr = 0.000385358
I0809 06:15:27.723769 20451 solver.cpp:228] Iteration 25670, loss = 0.218765
I0809 06:15:27.723901 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 06:15:27.723920 20451 solver.cpp:244]     Train net output #1: loss = 0.218765 (* 1 = 0.218765 loss)
I0809 06:15:27.723935 20451 sgd_solver.cpp:106] Iteration 25670, lr = 0.000385277
I0809 06:15:50.037842 20451 solver.cpp:228] Iteration 25680, loss = 0.12502
I0809 06:15:50.037886 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:15:50.037904 20451 solver.cpp:244]     Train net output #1: loss = 0.12502 (* 1 = 0.12502 loss)
I0809 06:15:50.037930 20451 sgd_solver.cpp:106] Iteration 25680, lr = 0.000385196
I0809 06:16:12.345198 20451 solver.cpp:228] Iteration 25690, loss = 0.125081
I0809 06:16:12.345379 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:16:12.345396 20451 solver.cpp:244]     Train net output #1: loss = 0.125082 (* 1 = 0.125082 loss)
I0809 06:16:12.345407 20451 sgd_solver.cpp:106] Iteration 25690, lr = 0.000385115
I0809 06:16:32.432287 20451 solver.cpp:337] Iteration 25700, Testing net (#0)
I0809 06:16:40.955004 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 06:16:40.955046 20451 solver.cpp:404]     Test net output #1: loss = 0.998622 (* 1 = 0.998622 loss)
I0809 06:16:43.156271 20451 solver.cpp:228] Iteration 25700, loss = 0.125045
I0809 06:16:43.156443 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:16:43.156458 20451 solver.cpp:244]     Train net output #1: loss = 0.125045 (* 1 = 0.125045 loss)
I0809 06:16:43.156471 20451 sgd_solver.cpp:106] Iteration 25700, lr = 0.000385034
I0809 06:17:05.435145 20451 solver.cpp:228] Iteration 25710, loss = 0.250072
I0809 06:17:05.435189 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:17:05.435207 20451 solver.cpp:244]     Train net output #1: loss = 0.250073 (* 1 = 0.250073 loss)
I0809 06:17:05.435222 20451 sgd_solver.cpp:106] Iteration 25710, lr = 0.000384953
I0809 06:17:27.735007 20451 solver.cpp:228] Iteration 25720, loss = 0.125051
I0809 06:17:27.735183 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:17:27.735208 20451 solver.cpp:244]     Train net output #1: loss = 0.125051 (* 1 = 0.125051 loss)
I0809 06:17:27.735224 20451 sgd_solver.cpp:106] Iteration 25720, lr = 0.000384872
I0809 06:17:50.040470 20451 solver.cpp:228] Iteration 25730, loss = 0.187563
I0809 06:17:50.040513 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:17:50.040531 20451 solver.cpp:244]     Train net output #1: loss = 0.187563 (* 1 = 0.187563 loss)
I0809 06:17:50.040556 20451 sgd_solver.cpp:106] Iteration 25730, lr = 0.000384791
I0809 06:18:12.352185 20451 solver.cpp:228] Iteration 25740, loss = 0.250067
I0809 06:18:12.352349 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:18:12.352365 20451 solver.cpp:244]     Train net output #1: loss = 0.250068 (* 1 = 0.250068 loss)
I0809 06:18:12.352377 20451 sgd_solver.cpp:106] Iteration 25740, lr = 0.000384711
I0809 06:18:34.671092 20451 solver.cpp:228] Iteration 25750, loss = 0.281341
I0809 06:18:34.671142 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 06:18:34.671156 20451 solver.cpp:244]     Train net output #1: loss = 0.281342 (* 1 = 0.281342 loss)
I0809 06:18:34.671169 20451 sgd_solver.cpp:106] Iteration 25750, lr = 0.00038463
I0809 06:18:56.986389 20451 solver.cpp:228] Iteration 25760, loss = 0.218821
I0809 06:18:56.986493 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 06:18:56.986510 20451 solver.cpp:244]     Train net output #1: loss = 0.218822 (* 1 = 0.218822 loss)
I0809 06:18:56.986522 20451 sgd_solver.cpp:106] Iteration 25760, lr = 0.000384549
I0809 06:19:19.284183 20451 solver.cpp:228] Iteration 25770, loss = 0.125044
I0809 06:19:19.284236 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:19:19.284251 20451 solver.cpp:244]     Train net output #1: loss = 0.125044 (* 1 = 0.125044 loss)
I0809 06:19:19.284265 20451 sgd_solver.cpp:106] Iteration 25770, lr = 0.000384469
I0809 06:19:41.584872 20451 solver.cpp:228] Iteration 25780, loss = 0.437672
I0809 06:19:41.585085 20451 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0809 06:19:41.585101 20451 solver.cpp:244]     Train net output #1: loss = 0.437672 (* 1 = 0.437672 loss)
I0809 06:19:41.585114 20451 sgd_solver.cpp:106] Iteration 25780, lr = 0.000384388
I0809 06:20:03.895529 20451 solver.cpp:228] Iteration 25790, loss = 0.0937709
I0809 06:20:03.895584 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:20:03.895598 20451 solver.cpp:244]     Train net output #1: loss = 0.0937711 (* 1 = 0.0937711 loss)
I0809 06:20:03.895611 20451 sgd_solver.cpp:106] Iteration 25790, lr = 0.000384307
I0809 06:20:23.976723 20451 solver.cpp:337] Iteration 25800, Testing net (#0)
I0809 06:20:32.491888 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 06:20:32.491938 20451 solver.cpp:404]     Test net output #1: loss = 1.00782 (* 1 = 1.00782 loss)
I0809 06:20:34.695149 20451 solver.cpp:228] Iteration 25800, loss = 0.156261
I0809 06:20:34.695196 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 06:20:34.695214 20451 solver.cpp:244]     Train net output #1: loss = 0.156261 (* 1 = 0.156261 loss)
I0809 06:20:34.695230 20451 sgd_solver.cpp:106] Iteration 25800, lr = 0.000384227
I0809 06:20:56.983515 20451 solver.cpp:228] Iteration 25810, loss = 0.125055
I0809 06:20:56.983767 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:20:56.983788 20451 solver.cpp:244]     Train net output #1: loss = 0.125055 (* 1 = 0.125055 loss)
I0809 06:20:56.983803 20451 sgd_solver.cpp:106] Iteration 25810, lr = 0.000384146
I0809 06:21:19.296291 20451 solver.cpp:228] Iteration 25820, loss = 0.187559
I0809 06:21:19.296341 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:21:19.296370 20451 solver.cpp:244]     Train net output #1: loss = 0.187559 (* 1 = 0.187559 loss)
I0809 06:21:19.296386 20451 sgd_solver.cpp:106] Iteration 25820, lr = 0.000384066
I0809 06:21:41.606570 20451 solver.cpp:228] Iteration 25830, loss = 0.187555
I0809 06:21:41.606746 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 06:21:41.606761 20451 solver.cpp:244]     Train net output #1: loss = 0.187555 (* 1 = 0.187555 loss)
I0809 06:21:41.606775 20451 sgd_solver.cpp:106] Iteration 25830, lr = 0.000383986
I0809 06:22:03.902441 20451 solver.cpp:228] Iteration 25840, loss = 0.0625243
I0809 06:22:03.902484 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 06:22:03.902500 20451 solver.cpp:244]     Train net output #1: loss = 0.0625246 (* 1 = 0.0625246 loss)
I0809 06:22:03.902514 20451 sgd_solver.cpp:106] Iteration 25840, lr = 0.000383905
I0809 06:22:26.198623 20451 solver.cpp:228] Iteration 25850, loss = 0.250095
I0809 06:22:26.198809 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:22:26.198824 20451 solver.cpp:244]     Train net output #1: loss = 0.250095 (* 1 = 0.250095 loss)
I0809 06:22:26.198837 20451 sgd_solver.cpp:106] Iteration 25850, lr = 0.000383825
I0809 06:22:48.505355 20451 solver.cpp:228] Iteration 25860, loss = 0.281726
I0809 06:22:48.505408 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 06:22:48.505420 20451 solver.cpp:244]     Train net output #1: loss = 0.281726 (* 1 = 0.281726 loss)
I0809 06:22:48.505432 20451 sgd_solver.cpp:106] Iteration 25860, lr = 0.000383745
I0809 06:23:10.816382 20451 solver.cpp:228] Iteration 25870, loss = 0.125122
I0809 06:23:10.816486 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:23:10.816506 20451 solver.cpp:244]     Train net output #1: loss = 0.125122 (* 1 = 0.125122 loss)
I0809 06:23:10.816521 20451 sgd_solver.cpp:106] Iteration 25870, lr = 0.000383664
I0809 06:23:33.129417 20451 solver.cpp:228] Iteration 25880, loss = 0.187735
I0809 06:23:33.129468 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:23:33.129482 20451 solver.cpp:244]     Train net output #1: loss = 0.187736 (* 1 = 0.187736 loss)
I0809 06:23:33.129495 20451 sgd_solver.cpp:106] Iteration 25880, lr = 0.000383584
I0809 06:23:55.437474 20451 solver.cpp:228] Iteration 25890, loss = 0.0938265
I0809 06:23:55.437697 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:23:55.437739 20451 solver.cpp:244]     Train net output #1: loss = 0.0938267 (* 1 = 0.0938267 loss)
I0809 06:23:55.437757 20451 sgd_solver.cpp:106] Iteration 25890, lr = 0.000383504
I0809 06:24:15.521476 20451 solver.cpp:337] Iteration 25900, Testing net (#0)
I0809 06:24:24.047857 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 06:24:24.047904 20451 solver.cpp:404]     Test net output #1: loss = 1.00393 (* 1 = 1.00393 loss)
I0809 06:24:26.252110 20451 solver.cpp:228] Iteration 25900, loss = 0.0938618
I0809 06:24:26.252288 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:24:26.252305 20451 solver.cpp:244]     Train net output #1: loss = 0.093862 (* 1 = 0.093862 loss)
I0809 06:24:26.252317 20451 sgd_solver.cpp:106] Iteration 25900, lr = 0.000383424
I0809 06:24:48.525668 20451 solver.cpp:228] Iteration 25910, loss = 0.187609
I0809 06:24:48.525720 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:24:48.525733 20451 solver.cpp:244]     Train net output #1: loss = 0.187609 (* 1 = 0.187609 loss)
I0809 06:24:48.525745 20451 sgd_solver.cpp:106] Iteration 25910, lr = 0.000383344
I0809 06:25:10.828320 20451 solver.cpp:228] Iteration 25920, loss = 0.187516
I0809 06:25:10.828419 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:25:10.828438 20451 solver.cpp:244]     Train net output #1: loss = 0.187516 (* 1 = 0.187516 loss)
I0809 06:25:10.828454 20451 sgd_solver.cpp:106] Iteration 25920, lr = 0.000383264
I0809 06:25:33.126322 20451 solver.cpp:228] Iteration 25930, loss = 0.0625029
I0809 06:25:33.126371 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 06:25:33.126385 20451 solver.cpp:244]     Train net output #1: loss = 0.0625031 (* 1 = 0.0625031 loss)
I0809 06:25:33.126397 20451 sgd_solver.cpp:106] Iteration 25930, lr = 0.000383184
I0809 06:25:55.431144 20451 solver.cpp:228] Iteration 25940, loss = 0.0312582
I0809 06:25:55.431334 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 06:25:55.431351 20451 solver.cpp:244]     Train net output #1: loss = 0.0312584 (* 1 = 0.0312584 loss)
I0809 06:25:55.431368 20451 sgd_solver.cpp:106] Iteration 25940, lr = 0.000383104
I0809 06:26:17.738821 20451 solver.cpp:228] Iteration 25950, loss = 0.156293
I0809 06:26:17.738864 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:26:17.738883 20451 solver.cpp:244]     Train net output #1: loss = 0.156294 (* 1 = 0.156294 loss)
I0809 06:26:17.738906 20451 sgd_solver.cpp:106] Iteration 25950, lr = 0.000383024
I0809 06:26:40.042572 20451 solver.cpp:228] Iteration 25960, loss = 0.0937968
I0809 06:26:40.042677 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:26:40.042692 20451 solver.cpp:244]     Train net output #1: loss = 0.093797 (* 1 = 0.093797 loss)
I0809 06:26:40.042706 20451 sgd_solver.cpp:106] Iteration 25960, lr = 0.000382944
I0809 06:27:02.352507 20451 solver.cpp:228] Iteration 25970, loss = 0.187556
I0809 06:27:02.352556 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:27:02.352576 20451 solver.cpp:244]     Train net output #1: loss = 0.187556 (* 1 = 0.187556 loss)
I0809 06:27:02.352596 20451 sgd_solver.cpp:106] Iteration 25970, lr = 0.000382864
I0809 06:27:24.649147 20451 solver.cpp:228] Iteration 25980, loss = 0.312657
I0809 06:27:24.649336 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 06:27:24.649355 20451 solver.cpp:244]     Train net output #1: loss = 0.312658 (* 1 = 0.312658 loss)
I0809 06:27:24.649371 20451 sgd_solver.cpp:106] Iteration 25980, lr = 0.000382784
I0809 06:27:46.965157 20451 solver.cpp:228] Iteration 25990, loss = 0.375075
I0809 06:27:46.965209 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0809 06:27:46.965222 20451 solver.cpp:244]     Train net output #1: loss = 0.375075 (* 1 = 0.375075 loss)
I0809 06:27:46.965234 20451 sgd_solver.cpp:106] Iteration 25990, lr = 0.000382705
I0809 06:28:07.045382 20451 solver.cpp:337] Iteration 26000, Testing net (#0)
I0809 06:28:15.563072 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0809 06:28:15.563123 20451 solver.cpp:404]     Test net output #1: loss = 0.961384 (* 1 = 0.961384 loss)
I0809 06:28:17.762679 20451 solver.cpp:228] Iteration 26000, loss = 0.18763
I0809 06:28:17.762732 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:28:17.762748 20451 solver.cpp:244]     Train net output #1: loss = 0.18763 (* 1 = 0.18763 loss)
I0809 06:28:17.762759 20451 sgd_solver.cpp:106] Iteration 26000, lr = 0.000382625
I0809 06:28:40.034055 20451 solver.cpp:228] Iteration 26010, loss = 0.187563
I0809 06:28:40.034238 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:28:40.034255 20451 solver.cpp:244]     Train net output #1: loss = 0.187563 (* 1 = 0.187563 loss)
I0809 06:28:40.034266 20451 sgd_solver.cpp:106] Iteration 26010, lr = 0.000382545
I0809 06:29:02.337582 20451 solver.cpp:228] Iteration 26020, loss = 0.0937781
I0809 06:29:02.337635 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:29:02.337648 20451 solver.cpp:244]     Train net output #1: loss = 0.0937783 (* 1 = 0.0937783 loss)
I0809 06:29:02.337661 20451 sgd_solver.cpp:106] Iteration 26020, lr = 0.000382465
I0809 06:29:24.636373 20451 solver.cpp:228] Iteration 26030, loss = 0.12506
I0809 06:29:24.636477 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:29:24.636497 20451 solver.cpp:244]     Train net output #1: loss = 0.12506 (* 1 = 0.12506 loss)
I0809 06:29:24.636512 20451 sgd_solver.cpp:106] Iteration 26030, lr = 0.000382386
I0809 06:29:46.941012 20451 solver.cpp:228] Iteration 26040, loss = 0.125035
I0809 06:29:46.941058 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:29:46.941076 20451 solver.cpp:244]     Train net output #1: loss = 0.125036 (* 1 = 0.125036 loss)
I0809 06:29:46.941092 20451 sgd_solver.cpp:106] Iteration 26040, lr = 0.000382306
I0809 06:30:09.248255 20451 solver.cpp:228] Iteration 26050, loss = 0.281344
I0809 06:30:09.248430 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 06:30:09.248450 20451 solver.cpp:244]     Train net output #1: loss = 0.281344 (* 1 = 0.281344 loss)
I0809 06:30:09.248466 20451 sgd_solver.cpp:106] Iteration 26050, lr = 0.000382227
I0809 06:30:31.550765 20451 solver.cpp:228] Iteration 26060, loss = 0.187538
I0809 06:30:31.550817 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:30:31.550832 20451 solver.cpp:244]     Train net output #1: loss = 0.187539 (* 1 = 0.187539 loss)
I0809 06:30:31.550843 20451 sgd_solver.cpp:106] Iteration 26060, lr = 0.000382147
I0809 06:30:53.856652 20451 solver.cpp:228] Iteration 26070, loss = 0.125036
I0809 06:30:53.856830 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:30:53.856847 20451 solver.cpp:244]     Train net output #1: loss = 0.125036 (* 1 = 0.125036 loss)
I0809 06:30:53.856859 20451 sgd_solver.cpp:106] Iteration 26070, lr = 0.000382068
I0809 06:31:16.155630 20451 solver.cpp:228] Iteration 26080, loss = 0.343801
I0809 06:31:16.155683 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 06:31:16.155697 20451 solver.cpp:244]     Train net output #1: loss = 0.343801 (* 1 = 0.343801 loss)
I0809 06:31:16.155709 20451 sgd_solver.cpp:106] Iteration 26080, lr = 0.000381988
I0809 06:31:38.448464 20451 solver.cpp:228] Iteration 26090, loss = 0.125089
I0809 06:31:38.448566 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:31:38.448585 20451 solver.cpp:244]     Train net output #1: loss = 0.125089 (* 1 = 0.125089 loss)
I0809 06:31:38.448599 20451 sgd_solver.cpp:106] Iteration 26090, lr = 0.000381909
I0809 06:31:58.525104 20451 solver.cpp:337] Iteration 26100, Testing net (#0)
I0809 06:32:07.048133 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 06:32:07.048192 20451 solver.cpp:404]     Test net output #1: loss = 0.993944 (* 1 = 0.993944 loss)
I0809 06:32:09.254974 20451 solver.cpp:228] Iteration 26100, loss = 0.125036
I0809 06:32:09.255187 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:32:09.255203 20451 solver.cpp:244]     Train net output #1: loss = 0.125036 (* 1 = 0.125036 loss)
I0809 06:32:09.255216 20451 sgd_solver.cpp:106] Iteration 26100, lr = 0.00038183
I0809 06:32:31.536620 20451 solver.cpp:228] Iteration 26110, loss = 0.187618
I0809 06:32:31.536672 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:32:31.536687 20451 solver.cpp:244]     Train net output #1: loss = 0.187618 (* 1 = 0.187618 loss)
I0809 06:32:31.536700 20451 sgd_solver.cpp:106] Iteration 26110, lr = 0.00038175
I0809 06:32:53.843988 20451 solver.cpp:228] Iteration 26120, loss = 0.15626
I0809 06:32:53.844163 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:32:53.844179 20451 solver.cpp:244]     Train net output #1: loss = 0.15626 (* 1 = 0.15626 loss)
I0809 06:32:53.844192 20451 sgd_solver.cpp:106] Iteration 26120, lr = 0.000381671
I0809 06:33:16.145362 20451 solver.cpp:228] Iteration 26130, loss = 0.18756
I0809 06:33:16.145414 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:33:16.145429 20451 solver.cpp:244]     Train net output #1: loss = 0.18756 (* 1 = 0.18756 loss)
I0809 06:33:16.145442 20451 sgd_solver.cpp:106] Iteration 26130, lr = 0.000381592
I0809 06:33:38.448190 20451 solver.cpp:228] Iteration 26140, loss = 0.187545
I0809 06:33:38.448370 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:33:38.448385 20451 solver.cpp:244]     Train net output #1: loss = 0.187545 (* 1 = 0.187545 loss)
I0809 06:33:38.448397 20451 sgd_solver.cpp:106] Iteration 26140, lr = 0.000381513
I0809 06:34:00.754339 20451 solver.cpp:228] Iteration 26150, loss = 0.281331
I0809 06:34:00.754390 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 06:34:00.754405 20451 solver.cpp:244]     Train net output #1: loss = 0.281331 (* 1 = 0.281331 loss)
I0809 06:34:00.754417 20451 sgd_solver.cpp:106] Iteration 26150, lr = 0.000381433
I0809 06:34:23.055668 20451 solver.cpp:228] Iteration 26160, loss = 0.187678
I0809 06:34:23.055766 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:34:23.055781 20451 solver.cpp:244]     Train net output #1: loss = 0.187679 (* 1 = 0.187679 loss)
I0809 06:34:23.055794 20451 sgd_solver.cpp:106] Iteration 26160, lr = 0.000381354
I0809 06:34:45.362948 20451 solver.cpp:228] Iteration 26170, loss = 0.156391
I0809 06:34:45.363003 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:34:45.363018 20451 solver.cpp:244]     Train net output #1: loss = 0.156391 (* 1 = 0.156391 loss)
I0809 06:34:45.363031 20451 sgd_solver.cpp:106] Iteration 26170, lr = 0.000381275
I0809 06:35:07.677294 20451 solver.cpp:228] Iteration 26180, loss = 0.281552
I0809 06:35:07.677466 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 06:35:07.677482 20451 solver.cpp:244]     Train net output #1: loss = 0.281552 (* 1 = 0.281552 loss)
I0809 06:35:07.677495 20451 sgd_solver.cpp:106] Iteration 26180, lr = 0.000381196
I0809 06:35:29.990097 20451 solver.cpp:228] Iteration 26190, loss = 0.125129
I0809 06:35:29.990144 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:35:29.990159 20451 solver.cpp:244]     Train net output #1: loss = 0.125129 (* 1 = 0.125129 loss)
I0809 06:35:29.990171 20451 sgd_solver.cpp:106] Iteration 26190, lr = 0.000381117
I0809 06:35:50.068603 20451 solver.cpp:337] Iteration 26200, Testing net (#0)
I0809 06:35:58.590070 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 06:35:58.590191 20451 solver.cpp:404]     Test net output #1: loss = 0.999105 (* 1 = 0.999105 loss)
I0809 06:36:00.798640 20451 solver.cpp:228] Iteration 26200, loss = 0.125125
I0809 06:36:00.798688 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:36:00.798702 20451 solver.cpp:244]     Train net output #1: loss = 0.125125 (* 1 = 0.125125 loss)
I0809 06:36:00.798714 20451 sgd_solver.cpp:106] Iteration 26200, lr = 0.000381038
I0809 06:36:23.080186 20451 solver.cpp:228] Iteration 26210, loss = 0.218953
I0809 06:36:23.080395 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 06:36:23.080411 20451 solver.cpp:244]     Train net output #1: loss = 0.218953 (* 1 = 0.218953 loss)
I0809 06:36:23.080425 20451 sgd_solver.cpp:106] Iteration 26210, lr = 0.000380959
I0809 06:36:45.381139 20451 solver.cpp:228] Iteration 26220, loss = 0.125114
I0809 06:36:45.381201 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:36:45.381220 20451 solver.cpp:244]     Train net output #1: loss = 0.125115 (* 1 = 0.125115 loss)
I0809 06:36:45.381238 20451 sgd_solver.cpp:106] Iteration 26220, lr = 0.00038088
I0809 06:37:07.684751 20451 solver.cpp:228] Iteration 26230, loss = 0.0938082
I0809 06:37:07.684881 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:37:07.684897 20451 solver.cpp:244]     Train net output #1: loss = 0.0938084 (* 1 = 0.0938084 loss)
I0809 06:37:07.684909 20451 sgd_solver.cpp:106] Iteration 26230, lr = 0.000380802
I0809 06:37:29.982475 20451 solver.cpp:228] Iteration 26240, loss = 0.343898
I0809 06:37:29.982514 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 06:37:29.982533 20451 solver.cpp:244]     Train net output #1: loss = 0.343898 (* 1 = 0.343898 loss)
I0809 06:37:29.982545 20451 sgd_solver.cpp:106] Iteration 26240, lr = 0.000380723
I0809 06:37:52.285907 20451 solver.cpp:228] Iteration 26250, loss = 0.156463
I0809 06:37:52.286016 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:37:52.286031 20451 solver.cpp:244]     Train net output #1: loss = 0.156463 (* 1 = 0.156463 loss)
I0809 06:37:52.286044 20451 sgd_solver.cpp:106] Iteration 26250, lr = 0.000380644
I0809 06:38:14.591706 20451 solver.cpp:228] Iteration 26260, loss = 0.312757
I0809 06:38:14.591759 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 06:38:14.591773 20451 solver.cpp:244]     Train net output #1: loss = 0.312757 (* 1 = 0.312757 loss)
I0809 06:38:14.591785 20451 sgd_solver.cpp:106] Iteration 26260, lr = 0.000380565
I0809 06:38:36.892760 20451 solver.cpp:228] Iteration 26270, loss = 0.156432
I0809 06:38:36.892940 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:38:36.892956 20451 solver.cpp:244]     Train net output #1: loss = 0.156432 (* 1 = 0.156432 loss)
I0809 06:38:36.892967 20451 sgd_solver.cpp:106] Iteration 26270, lr = 0.000380487
I0809 06:38:59.205122 20451 solver.cpp:228] Iteration 26280, loss = 0.156274
I0809 06:38:59.205174 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:38:59.205188 20451 solver.cpp:244]     Train net output #1: loss = 0.156275 (* 1 = 0.156275 loss)
I0809 06:38:59.205200 20451 sgd_solver.cpp:106] Iteration 26280, lr = 0.000380408
I0809 06:39:21.514320 20451 solver.cpp:228] Iteration 26290, loss = 0.156332
I0809 06:39:21.514503 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:39:21.514523 20451 solver.cpp:244]     Train net output #1: loss = 0.156332 (* 1 = 0.156332 loss)
I0809 06:39:21.514538 20451 sgd_solver.cpp:106] Iteration 26290, lr = 0.000380329
I0809 06:39:41.598631 20451 solver.cpp:337] Iteration 26300, Testing net (#0)
I0809 06:39:50.123164 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0809 06:39:50.123215 20451 solver.cpp:404]     Test net output #1: loss = 0.989143 (* 1 = 0.989143 loss)
I0809 06:39:52.323230 20451 solver.cpp:228] Iteration 26300, loss = 0.218932
I0809 06:39:52.323408 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 06:39:52.323423 20451 solver.cpp:244]     Train net output #1: loss = 0.218932 (* 1 = 0.218932 loss)
I0809 06:39:52.323437 20451 sgd_solver.cpp:106] Iteration 26300, lr = 0.000380251
I0809 06:40:14.599138 20451 solver.cpp:228] Iteration 26310, loss = 0.0937902
I0809 06:40:14.599189 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:40:14.599203 20451 solver.cpp:244]     Train net output #1: loss = 0.0937904 (* 1 = 0.0937904 loss)
I0809 06:40:14.599215 20451 sgd_solver.cpp:106] Iteration 26310, lr = 0.000380172
I0809 06:40:36.897614 20451 solver.cpp:228] Iteration 26320, loss = 0.250054
I0809 06:40:36.897827 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:40:36.897843 20451 solver.cpp:244]     Train net output #1: loss = 0.250054 (* 1 = 0.250054 loss)
I0809 06:40:36.897856 20451 sgd_solver.cpp:106] Iteration 26320, lr = 0.000380094
I0809 06:40:59.201972 20451 solver.cpp:228] Iteration 26330, loss = 0.125035
I0809 06:40:59.202015 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:40:59.202029 20451 solver.cpp:244]     Train net output #1: loss = 0.125035 (* 1 = 0.125035 loss)
I0809 06:40:59.202041 20451 sgd_solver.cpp:106] Iteration 26330, lr = 0.000380015
I0809 06:41:21.508405 20451 solver.cpp:228] Iteration 26340, loss = 0.12523
I0809 06:41:21.508584 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 06:41:21.508597 20451 solver.cpp:244]     Train net output #1: loss = 0.12523 (* 1 = 0.12523 loss)
I0809 06:41:21.508610 20451 sgd_solver.cpp:106] Iteration 26340, lr = 0.000379937
I0809 06:41:43.816684 20451 solver.cpp:228] Iteration 26350, loss = 0.187514
I0809 06:41:43.816735 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:41:43.816752 20451 solver.cpp:244]     Train net output #1: loss = 0.187514 (* 1 = 0.187514 loss)
I0809 06:41:43.816768 20451 sgd_solver.cpp:106] Iteration 26350, lr = 0.000379858
I0809 06:42:06.123109 20451 solver.cpp:228] Iteration 26360, loss = 0.250046
I0809 06:42:06.123289 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:42:06.123306 20451 solver.cpp:244]     Train net output #1: loss = 0.250047 (* 1 = 0.250047 loss)
I0809 06:42:06.123317 20451 sgd_solver.cpp:106] Iteration 26360, lr = 0.00037978
I0809 06:42:28.423758 20451 solver.cpp:228] Iteration 26370, loss = 0.343778
I0809 06:42:28.423810 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 06:42:28.423825 20451 solver.cpp:244]     Train net output #1: loss = 0.343778 (* 1 = 0.343778 loss)
I0809 06:42:28.423836 20451 sgd_solver.cpp:106] Iteration 26370, lr = 0.000379702
I0809 06:42:50.737799 20451 solver.cpp:228] Iteration 26380, loss = 0.281302
I0809 06:42:50.737977 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 06:42:50.737993 20451 solver.cpp:244]     Train net output #1: loss = 0.281302 (* 1 = 0.281302 loss)
I0809 06:42:50.738005 20451 sgd_solver.cpp:106] Iteration 26380, lr = 0.000379623
I0809 06:43:13.030817 20451 solver.cpp:228] Iteration 26390, loss = 0.156257
I0809 06:43:13.030869 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:43:13.030882 20451 solver.cpp:244]     Train net output #1: loss = 0.156257 (* 1 = 0.156257 loss)
I0809 06:43:13.030895 20451 sgd_solver.cpp:106] Iteration 26390, lr = 0.000379545
I0809 06:43:33.103340 20451 solver.cpp:337] Iteration 26400, Testing net (#0)
I0809 06:43:41.622161 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0809 06:43:41.622205 20451 solver.cpp:404]     Test net output #1: loss = 1.03623 (* 1 = 1.03623 loss)
I0809 06:43:43.822152 20451 solver.cpp:228] Iteration 26400, loss = 0.250106
I0809 06:43:43.822201 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:43:43.822221 20451 solver.cpp:244]     Train net output #1: loss = 0.250106 (* 1 = 0.250106 loss)
I0809 06:43:43.822235 20451 sgd_solver.cpp:106] Iteration 26400, lr = 0.000379467
I0809 06:44:06.103148 20451 solver.cpp:228] Iteration 26410, loss = 0.187547
I0809 06:44:06.103386 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:44:06.103461 20451 solver.cpp:244]     Train net output #1: loss = 0.187547 (* 1 = 0.187547 loss)
I0809 06:44:06.103500 20451 sgd_solver.cpp:106] Iteration 26410, lr = 0.000379389
I0809 06:44:28.419981 20451 solver.cpp:228] Iteration 26420, loss = 0.187584
I0809 06:44:28.420027 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:44:28.420047 20451 solver.cpp:244]     Train net output #1: loss = 0.187584 (* 1 = 0.187584 loss)
I0809 06:44:28.420063 20451 sgd_solver.cpp:106] Iteration 26420, lr = 0.000379311
I0809 06:44:50.714320 20451 solver.cpp:228] Iteration 26430, loss = 0.187593
I0809 06:44:50.714504 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:44:50.714524 20451 solver.cpp:244]     Train net output #1: loss = 0.187593 (* 1 = 0.187593 loss)
I0809 06:44:50.714539 20451 sgd_solver.cpp:106] Iteration 26430, lr = 0.000379233
I0809 06:45:13.017266 20451 solver.cpp:228] Iteration 26440, loss = 0.250058
I0809 06:45:13.017315 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:45:13.017329 20451 solver.cpp:244]     Train net output #1: loss = 0.250058 (* 1 = 0.250058 loss)
I0809 06:45:13.017341 20451 sgd_solver.cpp:106] Iteration 26440, lr = 0.000379155
I0809 06:45:35.309715 20451 solver.cpp:228] Iteration 26450, loss = 0.125064
I0809 06:45:35.309897 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:45:35.309912 20451 solver.cpp:244]     Train net output #1: loss = 0.125065 (* 1 = 0.125065 loss)
I0809 06:45:35.309926 20451 sgd_solver.cpp:106] Iteration 26450, lr = 0.000379077
I0809 06:45:57.610424 20451 solver.cpp:228] Iteration 26460, loss = 0.312663
I0809 06:45:57.610477 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 06:45:57.610491 20451 solver.cpp:244]     Train net output #1: loss = 0.312663 (* 1 = 0.312663 loss)
I0809 06:45:57.610503 20451 sgd_solver.cpp:106] Iteration 26460, lr = 0.000378999
I0809 06:46:19.923951 20451 solver.cpp:228] Iteration 26470, loss = 0.312637
I0809 06:46:19.924134 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 06:46:19.924154 20451 solver.cpp:244]     Train net output #1: loss = 0.312637 (* 1 = 0.312637 loss)
I0809 06:46:19.924170 20451 sgd_solver.cpp:106] Iteration 26470, lr = 0.000378921
I0809 06:46:42.232072 20451 solver.cpp:228] Iteration 26480, loss = 0.187758
I0809 06:46:42.232116 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:46:42.232141 20451 solver.cpp:244]     Train net output #1: loss = 0.187758 (* 1 = 0.187758 loss)
I0809 06:46:42.232157 20451 sgd_solver.cpp:106] Iteration 26480, lr = 0.000378843
I0809 06:47:04.534898 20451 solver.cpp:228] Iteration 26490, loss = 0.062518
I0809 06:47:04.535084 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 06:47:04.535099 20451 solver.cpp:244]     Train net output #1: loss = 0.0625182 (* 1 = 0.0625182 loss)
I0809 06:47:04.535110 20451 sgd_solver.cpp:106] Iteration 26490, lr = 0.000378765
I0809 06:47:24.616468 20451 solver.cpp:337] Iteration 26500, Testing net (#0)
I0809 06:47:33.129384 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 06:47:33.129436 20451 solver.cpp:404]     Test net output #1: loss = 0.984987 (* 1 = 0.984987 loss)
I0809 06:47:35.334503 20451 solver.cpp:228] Iteration 26500, loss = 0.156395
I0809 06:47:35.334679 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:47:35.334694 20451 solver.cpp:244]     Train net output #1: loss = 0.156395 (* 1 = 0.156395 loss)
I0809 06:47:35.334708 20451 sgd_solver.cpp:106] Iteration 26500, lr = 0.000378687
I0809 06:47:57.610782 20451 solver.cpp:228] Iteration 26510, loss = 0.18753
I0809 06:47:57.610838 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:47:57.610853 20451 solver.cpp:244]     Train net output #1: loss = 0.18753 (* 1 = 0.18753 loss)
I0809 06:47:57.610865 20451 sgd_solver.cpp:106] Iteration 26510, lr = 0.000378609
I0809 06:48:19.918787 20451 solver.cpp:228] Iteration 26520, loss = 0.187615
I0809 06:48:19.918999 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:48:19.919015 20451 solver.cpp:244]     Train net output #1: loss = 0.187615 (* 1 = 0.187615 loss)
I0809 06:48:19.919029 20451 sgd_solver.cpp:106] Iteration 26520, lr = 0.000378531
I0809 06:48:42.223333 20451 solver.cpp:228] Iteration 26530, loss = 0.187568
I0809 06:48:42.223388 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:48:42.223402 20451 solver.cpp:244]     Train net output #1: loss = 0.187568 (* 1 = 0.187568 loss)
I0809 06:48:42.223414 20451 sgd_solver.cpp:106] Iteration 26530, lr = 0.000378454
I0809 06:49:04.540410 20451 solver.cpp:228] Iteration 26540, loss = 0.250071
I0809 06:49:04.540592 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:49:04.540608 20451 solver.cpp:244]     Train net output #1: loss = 0.250071 (* 1 = 0.250071 loss)
I0809 06:49:04.540621 20451 sgd_solver.cpp:106] Iteration 26540, lr = 0.000378376
I0809 06:49:26.849772 20451 solver.cpp:228] Iteration 26550, loss = 0.281358
I0809 06:49:26.849825 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 06:49:26.849840 20451 solver.cpp:244]     Train net output #1: loss = 0.281358 (* 1 = 0.281358 loss)
I0809 06:49:26.849853 20451 sgd_solver.cpp:106] Iteration 26550, lr = 0.000378298
I0809 06:49:49.160014 20451 solver.cpp:228] Iteration 26560, loss = 0.12505
I0809 06:49:49.160190 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:49:49.160207 20451 solver.cpp:244]     Train net output #1: loss = 0.12505 (* 1 = 0.12505 loss)
I0809 06:49:49.160218 20451 sgd_solver.cpp:106] Iteration 26560, lr = 0.000378221
I0809 06:50:11.466491 20451 solver.cpp:228] Iteration 26570, loss = 0.250138
I0809 06:50:11.466536 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:50:11.466550 20451 solver.cpp:244]     Train net output #1: loss = 0.250139 (* 1 = 0.250139 loss)
I0809 06:50:11.466563 20451 sgd_solver.cpp:106] Iteration 26570, lr = 0.000378143
I0809 06:50:33.768894 20451 solver.cpp:228] Iteration 26580, loss = 0.0937858
I0809 06:50:33.769057 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:50:33.769076 20451 solver.cpp:244]     Train net output #1: loss = 0.093786 (* 1 = 0.093786 loss)
I0809 06:50:33.769090 20451 sgd_solver.cpp:106] Iteration 26580, lr = 0.000378066
I0809 06:50:56.077654 20451 solver.cpp:228] Iteration 26590, loss = 0.218902
I0809 06:50:56.077697 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 06:50:56.077723 20451 solver.cpp:244]     Train net output #1: loss = 0.218902 (* 1 = 0.218902 loss)
I0809 06:50:56.077739 20451 sgd_solver.cpp:106] Iteration 26590, lr = 0.000377988
I0809 06:51:16.172225 20451 solver.cpp:337] Iteration 26600, Testing net (#0)
I0809 06:51:24.699764 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0809 06:51:24.699815 20451 solver.cpp:404]     Test net output #1: loss = 0.970335 (* 1 = 0.970335 loss)
I0809 06:51:26.903705 20451 solver.cpp:228] Iteration 26600, loss = 0.156296
I0809 06:51:26.903749 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 06:51:26.903767 20451 solver.cpp:244]     Train net output #1: loss = 0.156297 (* 1 = 0.156297 loss)
I0809 06:51:26.903782 20451 sgd_solver.cpp:106] Iteration 26600, lr = 0.000377911
I0809 06:51:49.187384 20451 solver.cpp:228] Iteration 26610, loss = 0.250084
I0809 06:51:49.187566 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:51:49.187584 20451 solver.cpp:244]     Train net output #1: loss = 0.250084 (* 1 = 0.250084 loss)
I0809 06:51:49.187600 20451 sgd_solver.cpp:106] Iteration 26610, lr = 0.000377833
I0809 06:52:11.492341 20451 solver.cpp:228] Iteration 26620, loss = 0.156284
I0809 06:52:11.492388 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:52:11.492406 20451 solver.cpp:244]     Train net output #1: loss = 0.156284 (* 1 = 0.156284 loss)
I0809 06:52:11.492421 20451 sgd_solver.cpp:106] Iteration 26620, lr = 0.000377756
I0809 06:52:33.798617 20451 solver.cpp:228] Iteration 26630, loss = 0.156309
I0809 06:52:33.798831 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:52:33.798846 20451 solver.cpp:244]     Train net output #1: loss = 0.156309 (* 1 = 0.156309 loss)
I0809 06:52:33.798859 20451 sgd_solver.cpp:106] Iteration 26630, lr = 0.000377679
I0809 06:52:56.111044 20451 solver.cpp:228] Iteration 26640, loss = 0.156282
I0809 06:52:56.111095 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:52:56.111110 20451 solver.cpp:244]     Train net output #1: loss = 0.156282 (* 1 = 0.156282 loss)
I0809 06:52:56.111122 20451 sgd_solver.cpp:106] Iteration 26640, lr = 0.000377601
I0809 06:53:18.423972 20451 solver.cpp:228] Iteration 26650, loss = 0.313042
I0809 06:53:18.424185 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 06:53:18.424201 20451 solver.cpp:244]     Train net output #1: loss = 0.313042 (* 1 = 0.313042 loss)
I0809 06:53:18.424213 20451 sgd_solver.cpp:106] Iteration 26650, lr = 0.000377524
I0809 06:53:40.738767 20451 solver.cpp:228] Iteration 26660, loss = 0.250117
I0809 06:53:40.738812 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 06:53:40.738831 20451 solver.cpp:244]     Train net output #1: loss = 0.250117 (* 1 = 0.250117 loss)
I0809 06:53:40.738847 20451 sgd_solver.cpp:106] Iteration 26660, lr = 0.000377447
I0809 06:54:03.053633 20451 solver.cpp:228] Iteration 26670, loss = 0.0625195
I0809 06:54:03.053807 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 06:54:03.053827 20451 solver.cpp:244]     Train net output #1: loss = 0.0625197 (* 1 = 0.0625197 loss)
I0809 06:54:03.053841 20451 sgd_solver.cpp:106] Iteration 26670, lr = 0.00037737
I0809 06:54:25.354007 20451 solver.cpp:228] Iteration 26680, loss = 0.0937657
I0809 06:54:25.354058 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:54:25.354073 20451 solver.cpp:244]     Train net output #1: loss = 0.0937659 (* 1 = 0.0937659 loss)
I0809 06:54:25.354084 20451 sgd_solver.cpp:106] Iteration 26680, lr = 0.000377292
I0809 06:54:47.653995 20451 solver.cpp:228] Iteration 26690, loss = 0.187568
I0809 06:54:47.654168 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:54:47.654183 20451 solver.cpp:244]     Train net output #1: loss = 0.187569 (* 1 = 0.187569 loss)
I0809 06:54:47.654196 20451 sgd_solver.cpp:106] Iteration 26690, lr = 0.000377215
I0809 06:55:07.731318 20451 solver.cpp:337] Iteration 26700, Testing net (#0)
I0809 06:55:16.257632 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 06:55:16.257683 20451 solver.cpp:404]     Test net output #1: loss = 1.00799 (* 1 = 1.00799 loss)
I0809 06:55:18.459353 20451 solver.cpp:228] Iteration 26700, loss = 0.312581
I0809 06:55:18.459533 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 06:55:18.459549 20451 solver.cpp:244]     Train net output #1: loss = 0.312581 (* 1 = 0.312581 loss)
I0809 06:55:18.459563 20451 sgd_solver.cpp:106] Iteration 26700, lr = 0.000377138
I0809 06:55:40.736212 20451 solver.cpp:228] Iteration 26710, loss = 0.281334
I0809 06:55:40.736258 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 06:55:40.736273 20451 solver.cpp:244]     Train net output #1: loss = 0.281334 (* 1 = 0.281334 loss)
I0809 06:55:40.736285 20451 sgd_solver.cpp:106] Iteration 26710, lr = 0.000377061
I0809 06:56:03.039557 20451 solver.cpp:228] Iteration 26720, loss = 0.125019
I0809 06:56:03.039734 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:56:03.039749 20451 solver.cpp:244]     Train net output #1: loss = 0.12502 (* 1 = 0.12502 loss)
I0809 06:56:03.039762 20451 sgd_solver.cpp:106] Iteration 26720, lr = 0.000376984
I0809 06:56:25.335728 20451 solver.cpp:228] Iteration 26730, loss = 0.0937841
I0809 06:56:25.335780 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:56:25.335794 20451 solver.cpp:244]     Train net output #1: loss = 0.0937844 (* 1 = 0.0937844 loss)
I0809 06:56:25.335806 20451 sgd_solver.cpp:106] Iteration 26730, lr = 0.000376907
I0809 06:56:47.648447 20451 solver.cpp:228] Iteration 26740, loss = 0.0312588
I0809 06:56:47.648665 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 06:56:47.648681 20451 solver.cpp:244]     Train net output #1: loss = 0.0312591 (* 1 = 0.0312591 loss)
I0809 06:56:47.648694 20451 sgd_solver.cpp:106] Iteration 26740, lr = 0.00037683
I0809 06:57:09.961136 20451 solver.cpp:228] Iteration 26750, loss = 0.187572
I0809 06:57:09.961190 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:57:09.961205 20451 solver.cpp:244]     Train net output #1: loss = 0.187572 (* 1 = 0.187572 loss)
I0809 06:57:09.961217 20451 sgd_solver.cpp:106] Iteration 26750, lr = 0.000376753
I0809 06:57:32.274966 20451 solver.cpp:228] Iteration 26760, loss = 0.187544
I0809 06:57:32.275133 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:57:32.275148 20451 solver.cpp:244]     Train net output #1: loss = 0.187544 (* 1 = 0.187544 loss)
I0809 06:57:32.275161 20451 sgd_solver.cpp:106] Iteration 26760, lr = 0.000376676
I0809 06:57:54.574780 20451 solver.cpp:228] Iteration 26770, loss = 0.0937838
I0809 06:57:54.574827 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 06:57:54.574842 20451 solver.cpp:244]     Train net output #1: loss = 0.0937841 (* 1 = 0.0937841 loss)
I0809 06:57:54.574856 20451 sgd_solver.cpp:106] Iteration 26770, lr = 0.0003766
I0809 06:58:16.885967 20451 solver.cpp:228] Iteration 26780, loss = 0.0625254
I0809 06:58:16.886085 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 06:58:16.886103 20451 solver.cpp:244]     Train net output #1: loss = 0.0625257 (* 1 = 0.0625257 loss)
I0809 06:58:16.886121 20451 sgd_solver.cpp:106] Iteration 26780, lr = 0.000376523
I0809 06:58:39.193657 20451 solver.cpp:228] Iteration 26790, loss = 0.12502
I0809 06:58:39.193709 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 06:58:39.193724 20451 solver.cpp:244]     Train net output #1: loss = 0.125021 (* 1 = 0.125021 loss)
I0809 06:58:39.193737 20451 sgd_solver.cpp:106] Iteration 26790, lr = 0.000376446
I0809 06:58:59.281694 20451 solver.cpp:337] Iteration 26800, Testing net (#0)
I0809 06:59:07.806394 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0809 06:59:07.806440 20451 solver.cpp:404]     Test net output #1: loss = 1.0127 (* 1 = 1.0127 loss)
I0809 06:59:10.011183 20451 solver.cpp:228] Iteration 26800, loss = 0.0625161
I0809 06:59:10.011234 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 06:59:10.011248 20451 solver.cpp:244]     Train net output #1: loss = 0.0625164 (* 1 = 0.0625164 loss)
I0809 06:59:10.011260 20451 sgd_solver.cpp:106] Iteration 26800, lr = 0.000376369
I0809 06:59:32.292690 20451 solver.cpp:228] Iteration 26810, loss = 0.187526
I0809 06:59:32.292783 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 06:59:32.292798 20451 solver.cpp:244]     Train net output #1: loss = 0.187527 (* 1 = 0.187527 loss)
I0809 06:59:32.292809 20451 sgd_solver.cpp:106] Iteration 26810, lr = 0.000376293
I0809 06:59:54.602176 20451 solver.cpp:228] Iteration 26820, loss = 0.156341
I0809 06:59:54.602226 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 06:59:54.602241 20451 solver.cpp:244]     Train net output #1: loss = 0.156341 (* 1 = 0.156341 loss)
I0809 06:59:54.602252 20451 sgd_solver.cpp:106] Iteration 26820, lr = 0.000376216
I0809 07:00:16.911520 20451 solver.cpp:228] Iteration 26830, loss = 0.156291
I0809 07:00:16.911695 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:00:16.911710 20451 solver.cpp:244]     Train net output #1: loss = 0.156291 (* 1 = 0.156291 loss)
I0809 07:00:16.911722 20451 sgd_solver.cpp:106] Iteration 26830, lr = 0.000376139
I0809 07:00:39.211469 20451 solver.cpp:228] Iteration 26840, loss = 0.218865
I0809 07:00:39.211522 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:00:39.211535 20451 solver.cpp:244]     Train net output #1: loss = 0.218865 (* 1 = 0.218865 loss)
I0809 07:00:39.211547 20451 sgd_solver.cpp:106] Iteration 26840, lr = 0.000376063
I0809 07:01:01.528602 20451 solver.cpp:228] Iteration 26850, loss = 0.187551
I0809 07:01:01.528815 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:01:01.528831 20451 solver.cpp:244]     Train net output #1: loss = 0.187552 (* 1 = 0.187552 loss)
I0809 07:01:01.528843 20451 sgd_solver.cpp:106] Iteration 26850, lr = 0.000375986
I0809 07:01:23.836232 20451 solver.cpp:228] Iteration 26860, loss = 0.15633
I0809 07:01:23.836283 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:01:23.836297 20451 solver.cpp:244]     Train net output #1: loss = 0.15633 (* 1 = 0.15633 loss)
I0809 07:01:23.836308 20451 sgd_solver.cpp:106] Iteration 26860, lr = 0.00037591
I0809 07:01:46.141368 20451 solver.cpp:228] Iteration 26870, loss = 0.09376
I0809 07:01:46.141548 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:01:46.141566 20451 solver.cpp:244]     Train net output #1: loss = 0.0937603 (* 1 = 0.0937603 loss)
I0809 07:01:46.141578 20451 sgd_solver.cpp:106] Iteration 26870, lr = 0.000375833
I0809 07:02:08.444393 20451 solver.cpp:228] Iteration 26880, loss = 0.2502
I0809 07:02:08.444444 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:02:08.444458 20451 solver.cpp:244]     Train net output #1: loss = 0.2502 (* 1 = 0.2502 loss)
I0809 07:02:08.444469 20451 sgd_solver.cpp:106] Iteration 26880, lr = 0.000375757
I0809 07:02:30.751392 20451 solver.cpp:228] Iteration 26890, loss = 0.250097
I0809 07:02:30.751499 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:02:30.751514 20451 solver.cpp:244]     Train net output #1: loss = 0.250098 (* 1 = 0.250098 loss)
I0809 07:02:30.751526 20451 sgd_solver.cpp:106] Iteration 26890, lr = 0.00037568
I0809 07:02:50.835317 20451 solver.cpp:337] Iteration 26900, Testing net (#0)
I0809 07:02:59.354960 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 07:02:59.355012 20451 solver.cpp:404]     Test net output #1: loss = 0.984382 (* 1 = 0.984382 loss)
I0809 07:03:01.559890 20451 solver.cpp:228] Iteration 26900, loss = 0.187515
I0809 07:03:01.560070 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:03:01.560086 20451 solver.cpp:244]     Train net output #1: loss = 0.187515 (* 1 = 0.187515 loss)
I0809 07:03:01.560097 20451 sgd_solver.cpp:106] Iteration 26900, lr = 0.000375604
I0809 07:03:23.842494 20451 solver.cpp:228] Iteration 26910, loss = 0.125015
I0809 07:03:23.842545 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:03:23.842558 20451 solver.cpp:244]     Train net output #1: loss = 0.125015 (* 1 = 0.125015 loss)
I0809 07:03:23.842571 20451 sgd_solver.cpp:106] Iteration 26910, lr = 0.000375528
I0809 07:03:46.161619 20451 solver.cpp:228] Iteration 26920, loss = 0.156254
I0809 07:03:46.161803 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:03:46.161818 20451 solver.cpp:244]     Train net output #1: loss = 0.156254 (* 1 = 0.156254 loss)
I0809 07:03:46.161830 20451 sgd_solver.cpp:106] Iteration 26920, lr = 0.000375451
I0809 07:04:08.477249 20451 solver.cpp:228] Iteration 26930, loss = 0.125197
I0809 07:04:08.477303 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:04:08.477319 20451 solver.cpp:244]     Train net output #1: loss = 0.125198 (* 1 = 0.125198 loss)
I0809 07:04:08.477330 20451 sgd_solver.cpp:106] Iteration 26930, lr = 0.000375375
I0809 07:04:30.792703 20451 solver.cpp:228] Iteration 26940, loss = 0.0312703
I0809 07:04:30.792886 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 07:04:30.792901 20451 solver.cpp:244]     Train net output #1: loss = 0.0312706 (* 1 = 0.0312706 loss)
I0809 07:04:30.792914 20451 sgd_solver.cpp:106] Iteration 26940, lr = 0.000375299
I0809 07:04:53.107204 20451 solver.cpp:228] Iteration 26950, loss = 0.0938642
I0809 07:04:53.107245 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:04:53.107264 20451 solver.cpp:244]     Train net output #1: loss = 0.0938645 (* 1 = 0.0938645 loss)
I0809 07:04:53.107297 20451 sgd_solver.cpp:106] Iteration 26950, lr = 0.000375223
I0809 07:05:15.419528 20451 solver.cpp:228] Iteration 26960, loss = 0.0938044
I0809 07:05:15.419751 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:05:15.419771 20451 solver.cpp:244]     Train net output #1: loss = 0.0938047 (* 1 = 0.0938047 loss)
I0809 07:05:15.419790 20451 sgd_solver.cpp:106] Iteration 26960, lr = 0.000375147
I0809 07:05:37.735126 20451 solver.cpp:228] Iteration 26970, loss = 0.0937716
I0809 07:05:37.735169 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:05:37.735188 20451 solver.cpp:244]     Train net output #1: loss = 0.0937719 (* 1 = 0.0937719 loss)
I0809 07:05:37.735205 20451 sgd_solver.cpp:106] Iteration 26970, lr = 0.000375071
I0809 07:06:00.055454 20451 solver.cpp:228] Iteration 26980, loss = 0.250123
I0809 07:06:00.055634 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:06:00.055650 20451 solver.cpp:244]     Train net output #1: loss = 0.250123 (* 1 = 0.250123 loss)
I0809 07:06:00.055662 20451 sgd_solver.cpp:106] Iteration 26980, lr = 0.000374994
I0809 07:06:22.374330 20451 solver.cpp:228] Iteration 26990, loss = 0.031262
I0809 07:06:22.374382 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 07:06:22.374397 20451 solver.cpp:244]     Train net output #1: loss = 0.0312623 (* 1 = 0.0312623 loss)
I0809 07:06:22.374408 20451 sgd_solver.cpp:106] Iteration 26990, lr = 0.000374918
I0809 07:06:42.463655 20451 solver.cpp:337] Iteration 27000, Testing net (#0)
I0809 07:06:50.990669 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 07:06:50.990715 20451 solver.cpp:404]     Test net output #1: loss = 1.00327 (* 1 = 1.00327 loss)
I0809 07:06:53.194612 20451 solver.cpp:228] Iteration 27000, loss = 0.187538
I0809 07:06:53.194663 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:06:53.194676 20451 solver.cpp:244]     Train net output #1: loss = 0.187538 (* 1 = 0.187538 loss)
I0809 07:06:53.194689 20451 sgd_solver.cpp:106] Iteration 27000, lr = 0.000374842
I0809 07:07:15.486910 20451 solver.cpp:228] Iteration 27010, loss = 0.343898
I0809 07:07:15.487084 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 07:07:15.487100 20451 solver.cpp:244]     Train net output #1: loss = 0.343898 (* 1 = 0.343898 loss)
I0809 07:07:15.487112 20451 sgd_solver.cpp:106] Iteration 27010, lr = 0.000374766
I0809 07:07:37.799623 20451 solver.cpp:228] Iteration 27020, loss = 0.156319
I0809 07:07:37.799682 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:07:37.799698 20451 solver.cpp:244]     Train net output #1: loss = 0.15632 (* 1 = 0.15632 loss)
I0809 07:07:37.799712 20451 sgd_solver.cpp:106] Iteration 27020, lr = 0.000374691
I0809 07:08:00.124231 20451 solver.cpp:228] Iteration 27030, loss = 0.281349
I0809 07:08:00.124405 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 07:08:00.124420 20451 solver.cpp:244]     Train net output #1: loss = 0.281349 (* 1 = 0.281349 loss)
I0809 07:08:00.124433 20451 sgd_solver.cpp:106] Iteration 27030, lr = 0.000374615
I0809 07:08:22.444860 20451 solver.cpp:228] Iteration 27040, loss = 0.156266
I0809 07:08:22.444913 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:08:22.444927 20451 solver.cpp:244]     Train net output #1: loss = 0.156266 (* 1 = 0.156266 loss)
I0809 07:08:22.444939 20451 sgd_solver.cpp:106] Iteration 27040, lr = 0.000374539
I0809 07:08:44.752859 20451 solver.cpp:228] Iteration 27050, loss = 0.187576
I0809 07:08:44.753046 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:08:44.753062 20451 solver.cpp:244]     Train net output #1: loss = 0.187576 (* 1 = 0.187576 loss)
I0809 07:08:44.753073 20451 sgd_solver.cpp:106] Iteration 27050, lr = 0.000374463
I0809 07:09:07.067287 20451 solver.cpp:228] Iteration 27060, loss = 0.156275
I0809 07:09:07.067342 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:09:07.067355 20451 solver.cpp:244]     Train net output #1: loss = 0.156275 (* 1 = 0.156275 loss)
I0809 07:09:07.067368 20451 sgd_solver.cpp:106] Iteration 27060, lr = 0.000374387
I0809 07:09:29.381613 20451 solver.cpp:228] Iteration 27070, loss = 0.312572
I0809 07:09:29.381825 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 07:09:29.381840 20451 solver.cpp:244]     Train net output #1: loss = 0.312572 (* 1 = 0.312572 loss)
I0809 07:09:29.381855 20451 sgd_solver.cpp:106] Iteration 27070, lr = 0.000374311
I0809 07:09:51.686054 20451 solver.cpp:228] Iteration 27080, loss = 0.125015
I0809 07:09:51.686105 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:09:51.686118 20451 solver.cpp:244]     Train net output #1: loss = 0.125016 (* 1 = 0.125016 loss)
I0809 07:09:51.686131 20451 sgd_solver.cpp:106] Iteration 27080, lr = 0.000374236
I0809 07:10:13.998034 20451 solver.cpp:228] Iteration 27090, loss = 0.312528
I0809 07:10:13.998196 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 07:10:13.998215 20451 solver.cpp:244]     Train net output #1: loss = 0.312529 (* 1 = 0.312529 loss)
I0809 07:10:13.998227 20451 sgd_solver.cpp:106] Iteration 27090, lr = 0.00037416
I0809 07:10:34.078532 20451 solver.cpp:337] Iteration 27100, Testing net (#0)
I0809 07:10:42.598438 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 07:10:42.598489 20451 solver.cpp:404]     Test net output #1: loss = 0.975097 (* 1 = 0.975097 loss)
I0809 07:10:44.805292 20451 solver.cpp:228] Iteration 27100, loss = 0.187527
I0809 07:10:44.805385 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:10:44.805399 20451 solver.cpp:244]     Train net output #1: loss = 0.187527 (* 1 = 0.187527 loss)
I0809 07:10:44.805413 20451 sgd_solver.cpp:106] Iteration 27100, lr = 0.000374084
I0809 07:11:07.086769 20451 solver.cpp:228] Iteration 27110, loss = 0.156523
I0809 07:11:07.086822 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:11:07.086835 20451 solver.cpp:244]     Train net output #1: loss = 0.156523 (* 1 = 0.156523 loss)
I0809 07:11:07.086848 20451 sgd_solver.cpp:106] Iteration 27110, lr = 0.000374009
I0809 07:11:29.393445 20451 solver.cpp:228] Iteration 27120, loss = 0.250379
I0809 07:11:29.393638 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:11:29.393656 20451 solver.cpp:244]     Train net output #1: loss = 0.250379 (* 1 = 0.250379 loss)
I0809 07:11:29.393669 20451 sgd_solver.cpp:106] Iteration 27120, lr = 0.000373933
I0809 07:11:51.699797 20451 solver.cpp:228] Iteration 27130, loss = 0.187525
I0809 07:11:51.699852 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:11:51.699867 20451 solver.cpp:244]     Train net output #1: loss = 0.187525 (* 1 = 0.187525 loss)
I0809 07:11:51.699878 20451 sgd_solver.cpp:106] Iteration 27130, lr = 0.000373858
I0809 07:12:14.011276 20451 solver.cpp:228] Iteration 27140, loss = 0.125075
I0809 07:12:14.011452 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:12:14.011467 20451 solver.cpp:244]     Train net output #1: loss = 0.125075 (* 1 = 0.125075 loss)
I0809 07:12:14.011481 20451 sgd_solver.cpp:106] Iteration 27140, lr = 0.000373782
I0809 07:12:36.313650 20451 solver.cpp:228] Iteration 27150, loss = 0.156264
I0809 07:12:36.313701 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:12:36.313715 20451 solver.cpp:244]     Train net output #1: loss = 0.156264 (* 1 = 0.156264 loss)
I0809 07:12:36.313729 20451 sgd_solver.cpp:106] Iteration 27150, lr = 0.000373707
I0809 07:12:58.624666 20451 solver.cpp:228] Iteration 27160, loss = 0.156336
I0809 07:12:58.624843 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:12:58.624883 20451 solver.cpp:244]     Train net output #1: loss = 0.156336 (* 1 = 0.156336 loss)
I0809 07:12:58.624933 20451 sgd_solver.cpp:106] Iteration 27160, lr = 0.000373631
I0809 07:13:20.934902 20451 solver.cpp:228] Iteration 27170, loss = 0.125038
I0809 07:13:20.934955 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:13:20.934970 20451 solver.cpp:244]     Train net output #1: loss = 0.125038 (* 1 = 0.125038 loss)
I0809 07:13:20.934983 20451 sgd_solver.cpp:106] Iteration 27170, lr = 0.000373556
I0809 07:13:43.250839 20451 solver.cpp:228] Iteration 27180, loss = 0.34385
I0809 07:13:43.250975 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 07:13:43.250991 20451 solver.cpp:244]     Train net output #1: loss = 0.34385 (* 1 = 0.34385 loss)
I0809 07:13:43.251003 20451 sgd_solver.cpp:106] Iteration 27180, lr = 0.000373481
I0809 07:14:05.549969 20451 solver.cpp:228] Iteration 27190, loss = 0.18759
I0809 07:14:05.550021 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:14:05.550035 20451 solver.cpp:244]     Train net output #1: loss = 0.18759 (* 1 = 0.18759 loss)
I0809 07:14:05.550047 20451 sgd_solver.cpp:106] Iteration 27190, lr = 0.000373405
I0809 07:14:25.625901 20451 solver.cpp:337] Iteration 27200, Testing net (#0)
I0809 07:14:34.154546 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0809 07:14:34.154597 20451 solver.cpp:404]     Test net output #1: loss = 1.01743 (* 1 = 1.01743 loss)
I0809 07:14:36.360285 20451 solver.cpp:228] Iteration 27200, loss = 0.156306
I0809 07:14:36.360337 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:14:36.360352 20451 solver.cpp:244]     Train net output #1: loss = 0.156306 (* 1 = 0.156306 loss)
I0809 07:14:36.360363 20451 sgd_solver.cpp:106] Iteration 27200, lr = 0.00037333
I0809 07:14:58.645046 20451 solver.cpp:228] Iteration 27210, loss = 0.156281
I0809 07:14:58.645215 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:14:58.645252 20451 solver.cpp:244]     Train net output #1: loss = 0.156281 (* 1 = 0.156281 loss)
I0809 07:14:58.645285 20451 sgd_solver.cpp:106] Iteration 27210, lr = 0.000373255
I0809 07:15:20.959120 20451 solver.cpp:228] Iteration 27220, loss = 0.0937743
I0809 07:15:20.959173 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:15:20.959187 20451 solver.cpp:244]     Train net output #1: loss = 0.0937746 (* 1 = 0.0937746 loss)
I0809 07:15:20.959198 20451 sgd_solver.cpp:106] Iteration 27220, lr = 0.000373179
I0809 07:15:43.250560 20451 solver.cpp:228] Iteration 27230, loss = 0.125042
I0809 07:15:43.250735 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:15:43.250749 20451 solver.cpp:244]     Train net output #1: loss = 0.125042 (* 1 = 0.125042 loss)
I0809 07:15:43.250761 20451 sgd_solver.cpp:106] Iteration 27230, lr = 0.000373104
I0809 07:16:05.559897 20451 solver.cpp:228] Iteration 27240, loss = 0.218802
I0809 07:16:05.559949 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:16:05.559963 20451 solver.cpp:244]     Train net output #1: loss = 0.218802 (* 1 = 0.218802 loss)
I0809 07:16:05.559974 20451 sgd_solver.cpp:106] Iteration 27240, lr = 0.000373029
I0809 07:16:27.871001 20451 solver.cpp:228] Iteration 27250, loss = 0.250072
I0809 07:16:27.871191 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:16:27.871206 20451 solver.cpp:244]     Train net output #1: loss = 0.250072 (* 1 = 0.250072 loss)
I0809 07:16:27.871218 20451 sgd_solver.cpp:106] Iteration 27250, lr = 0.000372954
I0809 07:16:50.178148 20451 solver.cpp:228] Iteration 27260, loss = 0.0625027
I0809 07:16:50.178200 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 07:16:50.178215 20451 solver.cpp:244]     Train net output #1: loss = 0.0625029 (* 1 = 0.0625029 loss)
I0809 07:16:50.178226 20451 sgd_solver.cpp:106] Iteration 27260, lr = 0.000372879
I0809 07:17:12.476969 20451 solver.cpp:228] Iteration 27270, loss = 0.0625073
I0809 07:17:12.477152 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 07:17:12.477167 20451 solver.cpp:244]     Train net output #1: loss = 0.0625075 (* 1 = 0.0625075 loss)
I0809 07:17:12.477180 20451 sgd_solver.cpp:106] Iteration 27270, lr = 0.000372804
I0809 07:17:34.778251 20451 solver.cpp:228] Iteration 27280, loss = 0.15627
I0809 07:17:34.778302 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:17:34.778321 20451 solver.cpp:244]     Train net output #1: loss = 0.15627 (* 1 = 0.15627 loss)
I0809 07:17:34.778336 20451 sgd_solver.cpp:106] Iteration 27280, lr = 0.000372729
I0809 07:17:57.083936 20451 solver.cpp:228] Iteration 27290, loss = 0.125006
I0809 07:17:57.084091 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:17:57.084110 20451 solver.cpp:244]     Train net output #1: loss = 0.125007 (* 1 = 0.125007 loss)
I0809 07:17:57.084125 20451 sgd_solver.cpp:106] Iteration 27290, lr = 0.000372654
I0809 07:18:17.164011 20451 solver.cpp:337] Iteration 27300, Testing net (#0)
I0809 07:18:25.688814 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 07:18:25.688860 20451 solver.cpp:404]     Test net output #1: loss = 1.00344 (* 1 = 1.00344 loss)
I0809 07:18:27.893409 20451 solver.cpp:228] Iteration 27300, loss = 0.0937938
I0809 07:18:27.893597 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:18:27.893613 20451 solver.cpp:244]     Train net output #1: loss = 0.093794 (* 1 = 0.093794 loss)
I0809 07:18:27.893625 20451 sgd_solver.cpp:106] Iteration 27300, lr = 0.000372579
I0809 07:18:50.178536 20451 solver.cpp:228] Iteration 27310, loss = 0.156282
I0809 07:18:50.178580 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:18:50.178606 20451 solver.cpp:244]     Train net output #1: loss = 0.156282 (* 1 = 0.156282 loss)
I0809 07:18:50.178622 20451 sgd_solver.cpp:106] Iteration 27310, lr = 0.000372504
I0809 07:19:12.480249 20451 solver.cpp:228] Iteration 27320, loss = 0.25015
I0809 07:19:12.480430 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:19:12.480445 20451 solver.cpp:244]     Train net output #1: loss = 0.250151 (* 1 = 0.250151 loss)
I0809 07:19:12.480459 20451 sgd_solver.cpp:106] Iteration 27320, lr = 0.000372429
I0809 07:19:34.780458 20451 solver.cpp:228] Iteration 27330, loss = 0.156283
I0809 07:19:34.780503 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:19:34.780519 20451 solver.cpp:244]     Train net output #1: loss = 0.156283 (* 1 = 0.156283 loss)
I0809 07:19:34.780532 20451 sgd_solver.cpp:106] Iteration 27330, lr = 0.000372354
I0809 07:19:57.080566 20451 solver.cpp:228] Iteration 27340, loss = 0.21889
I0809 07:19:57.080745 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:19:57.080760 20451 solver.cpp:244]     Train net output #1: loss = 0.218891 (* 1 = 0.218891 loss)
I0809 07:19:57.080773 20451 sgd_solver.cpp:106] Iteration 27340, lr = 0.00037228
I0809 07:20:19.391299 20451 solver.cpp:228] Iteration 27350, loss = 0.156321
I0809 07:20:19.391351 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:20:19.391366 20451 solver.cpp:244]     Train net output #1: loss = 0.156321 (* 1 = 0.156321 loss)
I0809 07:20:19.391377 20451 sgd_solver.cpp:106] Iteration 27350, lr = 0.000372205
I0809 07:20:41.699410 20451 solver.cpp:228] Iteration 27360, loss = 0.218782
I0809 07:20:41.699596 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:20:41.699611 20451 solver.cpp:244]     Train net output #1: loss = 0.218782 (* 1 = 0.218782 loss)
I0809 07:20:41.699623 20451 sgd_solver.cpp:106] Iteration 27360, lr = 0.00037213
I0809 07:21:04.008406 20451 solver.cpp:228] Iteration 27370, loss = 0.125024
I0809 07:21:04.008455 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:21:04.008469 20451 solver.cpp:244]     Train net output #1: loss = 0.125024 (* 1 = 0.125024 loss)
I0809 07:21:04.008481 20451 sgd_solver.cpp:106] Iteration 27370, lr = 0.000372055
I0809 07:21:26.310720 20451 solver.cpp:228] Iteration 27380, loss = 0.156274
I0809 07:21:26.310900 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:21:26.310915 20451 solver.cpp:244]     Train net output #1: loss = 0.156274 (* 1 = 0.156274 loss)
I0809 07:21:26.310928 20451 sgd_solver.cpp:106] Iteration 27380, lr = 0.000371981
I0809 07:21:48.608156 20451 solver.cpp:228] Iteration 27390, loss = 0.125008
I0809 07:21:48.608206 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:21:48.608220 20451 solver.cpp:244]     Train net output #1: loss = 0.125008 (* 1 = 0.125008 loss)
I0809 07:21:48.608232 20451 sgd_solver.cpp:106] Iteration 27390, lr = 0.000371906
I0809 07:22:08.682781 20451 solver.cpp:337] Iteration 27400, Testing net (#0)
I0809 07:22:17.202857 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 07:22:17.202908 20451 solver.cpp:404]     Test net output #1: loss = 0.97513 (* 1 = 0.97513 loss)
I0809 07:22:19.405059 20451 solver.cpp:228] Iteration 27400, loss = 0.125024
I0809 07:22:19.405107 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:22:19.405123 20451 solver.cpp:244]     Train net output #1: loss = 0.125024 (* 1 = 0.125024 loss)
I0809 07:22:19.405140 20451 sgd_solver.cpp:106] Iteration 27400, lr = 0.000371832
I0809 07:22:41.692734 20451 solver.cpp:228] Iteration 27410, loss = 0.187539
I0809 07:22:41.692914 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:22:41.692934 20451 solver.cpp:244]     Train net output #1: loss = 0.187539 (* 1 = 0.187539 loss)
I0809 07:22:41.692950 20451 sgd_solver.cpp:106] Iteration 27410, lr = 0.000371757
I0809 07:23:04.007057 20451 solver.cpp:228] Iteration 27420, loss = 0.125049
I0809 07:23:04.007104 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:23:04.007119 20451 solver.cpp:244]     Train net output #1: loss = 0.125049 (* 1 = 0.125049 loss)
I0809 07:23:04.007131 20451 sgd_solver.cpp:106] Iteration 27420, lr = 0.000371683
I0809 07:23:26.314779 20451 solver.cpp:228] Iteration 27430, loss = 0.187559
I0809 07:23:26.314955 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:23:26.314970 20451 solver.cpp:244]     Train net output #1: loss = 0.187559 (* 1 = 0.187559 loss)
I0809 07:23:26.314983 20451 sgd_solver.cpp:106] Iteration 27430, lr = 0.000371608
I0809 07:23:48.612104 20451 solver.cpp:228] Iteration 27440, loss = 0.125162
I0809 07:23:48.612155 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:23:48.612170 20451 solver.cpp:244]     Train net output #1: loss = 0.125162 (* 1 = 0.125162 loss)
I0809 07:23:48.612182 20451 sgd_solver.cpp:106] Iteration 27440, lr = 0.000371534
I0809 07:24:10.904269 20451 solver.cpp:228] Iteration 27450, loss = 0.250217
I0809 07:24:10.904374 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:24:10.904392 20451 solver.cpp:244]     Train net output #1: loss = 0.250217 (* 1 = 0.250217 loss)
I0809 07:24:10.904405 20451 sgd_solver.cpp:106] Iteration 27450, lr = 0.000371459
I0809 07:24:33.194818 20451 solver.cpp:228] Iteration 27460, loss = 0.0938535
I0809 07:24:33.194867 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:24:33.194881 20451 solver.cpp:244]     Train net output #1: loss = 0.0938537 (* 1 = 0.0938537 loss)
I0809 07:24:33.194895 20451 sgd_solver.cpp:106] Iteration 27460, lr = 0.000371385
I0809 07:24:55.498184 20451 solver.cpp:228] Iteration 27470, loss = 0.0937862
I0809 07:24:55.498369 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:24:55.498384 20451 solver.cpp:244]     Train net output #1: loss = 0.0937864 (* 1 = 0.0937864 loss)
I0809 07:24:55.498399 20451 sgd_solver.cpp:106] Iteration 27470, lr = 0.000371311
I0809 07:25:17.812281 20451 solver.cpp:228] Iteration 27480, loss = 0.218774
I0809 07:25:17.812335 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:25:17.812350 20451 solver.cpp:244]     Train net output #1: loss = 0.218775 (* 1 = 0.218775 loss)
I0809 07:25:17.812362 20451 sgd_solver.cpp:106] Iteration 27480, lr = 0.000371236
I0809 07:25:40.109721 20451 solver.cpp:228] Iteration 27490, loss = 0.125023
I0809 07:25:40.109897 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:25:40.109912 20451 solver.cpp:244]     Train net output #1: loss = 0.125023 (* 1 = 0.125023 loss)
I0809 07:25:40.109925 20451 sgd_solver.cpp:106] Iteration 27490, lr = 0.000371162
I0809 07:26:00.193114 20451 solver.cpp:337] Iteration 27500, Testing net (#0)
I0809 07:26:08.717275 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 07:26:08.717325 20451 solver.cpp:404]     Test net output #1: loss = 0.994037 (* 1 = 0.994037 loss)
I0809 07:26:10.919165 20451 solver.cpp:228] Iteration 27500, loss = 0.218843
I0809 07:26:10.919376 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:26:10.919394 20451 solver.cpp:244]     Train net output #1: loss = 0.218844 (* 1 = 0.218844 loss)
I0809 07:26:10.919406 20451 sgd_solver.cpp:106] Iteration 27500, lr = 0.000371088
I0809 07:26:33.198571 20451 solver.cpp:228] Iteration 27510, loss = 0.0938712
I0809 07:26:33.198619 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:26:33.198635 20451 solver.cpp:244]     Train net output #1: loss = 0.0938714 (* 1 = 0.0938714 loss)
I0809 07:26:33.198649 20451 sgd_solver.cpp:106] Iteration 27510, lr = 0.000371014
I0809 07:26:55.487943 20451 solver.cpp:228] Iteration 27520, loss = 0.0625948
I0809 07:26:55.488051 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 07:26:55.488067 20451 solver.cpp:244]     Train net output #1: loss = 0.0625951 (* 1 = 0.0625951 loss)
I0809 07:26:55.488080 20451 sgd_solver.cpp:106] Iteration 27520, lr = 0.000370939
I0809 07:27:17.791105 20451 solver.cpp:228] Iteration 27530, loss = 0.1563
I0809 07:27:17.791151 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:27:17.791167 20451 solver.cpp:244]     Train net output #1: loss = 0.1563 (* 1 = 0.1563 loss)
I0809 07:27:17.791179 20451 sgd_solver.cpp:106] Iteration 27530, lr = 0.000370865
I0809 07:27:40.086403 20451 solver.cpp:228] Iteration 27540, loss = 0.312848
I0809 07:27:40.086578 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 07:27:40.086593 20451 solver.cpp:244]     Train net output #1: loss = 0.312848 (* 1 = 0.312848 loss)
I0809 07:27:40.086606 20451 sgd_solver.cpp:106] Iteration 27540, lr = 0.000370791
I0809 07:28:02.381369 20451 solver.cpp:228] Iteration 27550, loss = 0.156325
I0809 07:28:02.381423 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:28:02.381438 20451 solver.cpp:244]     Train net output #1: loss = 0.156325 (* 1 = 0.156325 loss)
I0809 07:28:02.381449 20451 sgd_solver.cpp:106] Iteration 27550, lr = 0.000370717
I0809 07:28:24.674796 20451 solver.cpp:228] Iteration 27560, loss = 0.187631
I0809 07:28:24.674988 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:28:24.675004 20451 solver.cpp:244]     Train net output #1: loss = 0.187631 (* 1 = 0.187631 loss)
I0809 07:28:24.675016 20451 sgd_solver.cpp:106] Iteration 27560, lr = 0.000370643
I0809 07:28:46.975129 20451 solver.cpp:228] Iteration 27570, loss = 0.25001
I0809 07:28:46.975183 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:28:46.975196 20451 solver.cpp:244]     Train net output #1: loss = 0.25001 (* 1 = 0.25001 loss)
I0809 07:28:46.975208 20451 sgd_solver.cpp:106] Iteration 27570, lr = 0.000370569
I0809 07:29:09.275890 20451 solver.cpp:228] Iteration 27580, loss = 0.218765
I0809 07:29:09.275990 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:29:09.276005 20451 solver.cpp:244]     Train net output #1: loss = 0.218765 (* 1 = 0.218765 loss)
I0809 07:29:09.276018 20451 sgd_solver.cpp:106] Iteration 27580, lr = 0.000370495
I0809 07:29:31.581188 20451 solver.cpp:228] Iteration 27590, loss = 0.125107
I0809 07:29:31.581240 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:29:31.581254 20451 solver.cpp:244]     Train net output #1: loss = 0.125107 (* 1 = 0.125107 loss)
I0809 07:29:31.581265 20451 sgd_solver.cpp:106] Iteration 27590, lr = 0.000370421
I0809 07:29:51.668015 20451 solver.cpp:337] Iteration 27600, Testing net (#0)
I0809 07:30:00.193513 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 07:30:00.193563 20451 solver.cpp:404]     Test net output #1: loss = 1.00329 (* 1 = 1.00329 loss)
I0809 07:30:02.396059 20451 solver.cpp:228] Iteration 27600, loss = 0.0937731
I0809 07:30:02.396109 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:30:02.396122 20451 solver.cpp:244]     Train net output #1: loss = 0.0937733 (* 1 = 0.0937733 loss)
I0809 07:30:02.396136 20451 sgd_solver.cpp:106] Iteration 27600, lr = 0.000370347
I0809 07:30:24.677240 20451 solver.cpp:228] Iteration 27610, loss = 0.218793
I0809 07:30:24.677422 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:30:24.677438 20451 solver.cpp:244]     Train net output #1: loss = 0.218793 (* 1 = 0.218793 loss)
I0809 07:30:24.677449 20451 sgd_solver.cpp:106] Iteration 27610, lr = 0.000370273
I0809 07:30:46.979389 20451 solver.cpp:228] Iteration 27620, loss = 0.0937847
I0809 07:30:46.979440 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:30:46.979454 20451 solver.cpp:244]     Train net output #1: loss = 0.0937849 (* 1 = 0.0937849 loss)
I0809 07:30:46.979466 20451 sgd_solver.cpp:106] Iteration 27620, lr = 0.0003702
I0809 07:31:09.280292 20451 solver.cpp:228] Iteration 27630, loss = 0.187573
I0809 07:31:09.280475 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:31:09.280490 20451 solver.cpp:244]     Train net output #1: loss = 0.187573 (* 1 = 0.187573 loss)
I0809 07:31:09.280503 20451 sgd_solver.cpp:106] Iteration 27630, lr = 0.000370126
I0809 07:31:31.585721 20451 solver.cpp:228] Iteration 27640, loss = 0.312554
I0809 07:31:31.585769 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 07:31:31.585788 20451 solver.cpp:244]     Train net output #1: loss = 0.312554 (* 1 = 0.312554 loss)
I0809 07:31:31.585803 20451 sgd_solver.cpp:106] Iteration 27640, lr = 0.000370052
I0809 07:31:53.892411 20451 solver.cpp:228] Iteration 27650, loss = 0.281358
I0809 07:31:53.892611 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 07:31:53.892629 20451 solver.cpp:244]     Train net output #1: loss = 0.281359 (* 1 = 0.281359 loss)
I0809 07:31:53.892644 20451 sgd_solver.cpp:106] Iteration 27650, lr = 0.000369978
I0809 07:32:16.193779 20451 solver.cpp:228] Iteration 27660, loss = 0.187562
I0809 07:32:16.193831 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:32:16.193845 20451 solver.cpp:244]     Train net output #1: loss = 0.187562 (* 1 = 0.187562 loss)
I0809 07:32:16.193857 20451 sgd_solver.cpp:106] Iteration 27660, lr = 0.000369905
I0809 07:32:38.498594 20451 solver.cpp:228] Iteration 27670, loss = 0.093776
I0809 07:32:38.498728 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:32:38.498744 20451 solver.cpp:244]     Train net output #1: loss = 0.0937762 (* 1 = 0.0937762 loss)
I0809 07:32:38.498756 20451 sgd_solver.cpp:106] Iteration 27670, lr = 0.000369831
I0809 07:33:00.808434 20451 solver.cpp:228] Iteration 27680, loss = 0.18759
I0809 07:33:00.808486 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:33:00.808501 20451 solver.cpp:244]     Train net output #1: loss = 0.18759 (* 1 = 0.18759 loss)
I0809 07:33:00.808512 20451 sgd_solver.cpp:106] Iteration 27680, lr = 0.000369757
I0809 07:33:23.111572 20451 solver.cpp:228] Iteration 27690, loss = 0.218955
I0809 07:33:23.111753 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:33:23.111769 20451 solver.cpp:244]     Train net output #1: loss = 0.218955 (* 1 = 0.218955 loss)
I0809 07:33:23.111781 20451 sgd_solver.cpp:106] Iteration 27690, lr = 0.000369684
I0809 07:33:43.187687 20451 solver.cpp:337] Iteration 27700, Testing net (#0)
I0809 07:33:51.708488 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0809 07:33:51.708539 20451 solver.cpp:404]     Test net output #1: loss = 0.965784 (* 1 = 0.965784 loss)
I0809 07:33:53.912804 20451 solver.cpp:228] Iteration 27700, loss = 0.0625149
I0809 07:33:53.912940 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 07:33:53.912955 20451 solver.cpp:244]     Train net output #1: loss = 0.0625151 (* 1 = 0.0625151 loss)
I0809 07:33:53.912968 20451 sgd_solver.cpp:106] Iteration 27700, lr = 0.00036961
I0809 07:34:16.196080 20451 solver.cpp:228] Iteration 27710, loss = 0.218808
I0809 07:34:16.196132 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:34:16.196146 20451 solver.cpp:244]     Train net output #1: loss = 0.218808 (* 1 = 0.218808 loss)
I0809 07:34:16.196157 20451 sgd_solver.cpp:106] Iteration 27710, lr = 0.000369537
I0809 07:34:38.496347 20451 solver.cpp:228] Iteration 27720, loss = 0.187523
I0809 07:34:38.496521 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:34:38.496536 20451 solver.cpp:244]     Train net output #1: loss = 0.187523 (* 1 = 0.187523 loss)
I0809 07:34:38.496548 20451 sgd_solver.cpp:106] Iteration 27720, lr = 0.000369463
I0809 07:35:00.799101 20451 solver.cpp:228] Iteration 27730, loss = 0.125016
I0809 07:35:00.799152 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:35:00.799165 20451 solver.cpp:244]     Train net output #1: loss = 0.125016 (* 1 = 0.125016 loss)
I0809 07:35:00.799177 20451 sgd_solver.cpp:106] Iteration 27730, lr = 0.00036939
I0809 07:35:23.102114 20451 solver.cpp:228] Iteration 27740, loss = 0.218781
I0809 07:35:23.102289 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:35:23.102305 20451 solver.cpp:244]     Train net output #1: loss = 0.218781 (* 1 = 0.218781 loss)
I0809 07:35:23.102319 20451 sgd_solver.cpp:106] Iteration 27740, lr = 0.000369316
I0809 07:35:45.398450 20451 solver.cpp:228] Iteration 27750, loss = 0.343909
I0809 07:35:45.398504 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 07:35:45.398519 20451 solver.cpp:244]     Train net output #1: loss = 0.34391 (* 1 = 0.34391 loss)
I0809 07:35:45.398530 20451 sgd_solver.cpp:106] Iteration 27750, lr = 0.000369243
I0809 07:36:07.706379 20451 solver.cpp:228] Iteration 27760, loss = 0.343883
I0809 07:36:07.706475 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 07:36:07.706495 20451 solver.cpp:244]     Train net output #1: loss = 0.343883 (* 1 = 0.343883 loss)
I0809 07:36:07.706507 20451 sgd_solver.cpp:106] Iteration 27760, lr = 0.00036917
I0809 07:36:30.013140 20451 solver.cpp:228] Iteration 27770, loss = 0.125032
I0809 07:36:30.013191 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:36:30.013206 20451 solver.cpp:244]     Train net output #1: loss = 0.125032 (* 1 = 0.125032 loss)
I0809 07:36:30.013218 20451 sgd_solver.cpp:106] Iteration 27770, lr = 0.000369096
I0809 07:36:52.321918 20451 solver.cpp:228] Iteration 27780, loss = 0.250052
I0809 07:36:52.322095 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:36:52.322110 20451 solver.cpp:244]     Train net output #1: loss = 0.250052 (* 1 = 0.250052 loss)
I0809 07:36:52.322124 20451 sgd_solver.cpp:106] Iteration 27780, lr = 0.000369023
I0809 07:37:14.635396 20451 solver.cpp:228] Iteration 27790, loss = 0.156297
I0809 07:37:14.635439 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:37:14.635453 20451 solver.cpp:244]     Train net output #1: loss = 0.156298 (* 1 = 0.156298 loss)
I0809 07:37:14.635467 20451 sgd_solver.cpp:106] Iteration 27790, lr = 0.00036895
I0809 07:37:34.709003 20451 solver.cpp:337] Iteration 27800, Testing net (#0)
I0809 07:37:43.237458 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0809 07:37:43.237510 20451 solver.cpp:404]     Test net output #1: loss = 1.03139 (* 1 = 1.03139 loss)
I0809 07:37:45.437026 20451 solver.cpp:228] Iteration 27800, loss = 0.218793
I0809 07:37:45.437077 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:37:45.437093 20451 solver.cpp:244]     Train net output #1: loss = 0.218793 (* 1 = 0.218793 loss)
I0809 07:37:45.437104 20451 sgd_solver.cpp:106] Iteration 27800, lr = 0.000368877
I0809 07:38:07.723477 20451 solver.cpp:228] Iteration 27810, loss = 0.187504
I0809 07:38:07.723603 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:38:07.723618 20451 solver.cpp:244]     Train net output #1: loss = 0.187504 (* 1 = 0.187504 loss)
I0809 07:38:07.723630 20451 sgd_solver.cpp:106] Iteration 27810, lr = 0.000368803
I0809 07:38:30.027966 20451 solver.cpp:228] Iteration 27820, loss = -2.08616e-07
I0809 07:38:30.028019 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:38:30.028033 20451 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0809 07:38:30.028044 20451 sgd_solver.cpp:106] Iteration 27820, lr = 0.00036873
I0809 07:38:52.338001 20451 solver.cpp:228] Iteration 27830, loss = 0.125035
I0809 07:38:52.338189 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:38:52.338208 20451 solver.cpp:244]     Train net output #1: loss = 0.125035 (* 1 = 0.125035 loss)
I0809 07:38:52.338224 20451 sgd_solver.cpp:106] Iteration 27830, lr = 0.000368657
I0809 07:39:14.646543 20451 solver.cpp:228] Iteration 27840, loss = 0.156525
I0809 07:39:14.646586 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:39:14.646605 20451 solver.cpp:244]     Train net output #1: loss = 0.156525 (* 1 = 0.156525 loss)
I0809 07:39:14.646620 20451 sgd_solver.cpp:106] Iteration 27840, lr = 0.000368584
I0809 07:39:36.950268 20451 solver.cpp:228] Iteration 27850, loss = 0.0938494
I0809 07:39:36.950381 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:39:36.950397 20451 solver.cpp:244]     Train net output #1: loss = 0.0938496 (* 1 = 0.0938496 loss)
I0809 07:39:36.950410 20451 sgd_solver.cpp:106] Iteration 27850, lr = 0.000368511
I0809 07:39:59.252383 20451 solver.cpp:228] Iteration 27860, loss = 0.156371
I0809 07:39:59.252436 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:39:59.252449 20451 solver.cpp:244]     Train net output #1: loss = 0.156372 (* 1 = 0.156372 loss)
I0809 07:39:59.252462 20451 sgd_solver.cpp:106] Iteration 27860, lr = 0.000368438
I0809 07:40:21.562551 20451 solver.cpp:228] Iteration 27870, loss = 0.0938649
I0809 07:40:21.562731 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:40:21.562747 20451 solver.cpp:244]     Train net output #1: loss = 0.0938651 (* 1 = 0.0938651 loss)
I0809 07:40:21.562759 20451 sgd_solver.cpp:106] Iteration 27870, lr = 0.000368365
I0809 07:40:43.876215 20451 solver.cpp:228] Iteration 27880, loss = 0.343924
I0809 07:40:43.876261 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:40:43.876276 20451 solver.cpp:244]     Train net output #1: loss = 0.343924 (* 1 = 0.343924 loss)
I0809 07:40:43.876289 20451 sgd_solver.cpp:106] Iteration 27880, lr = 0.000368292
I0809 07:41:06.183138 20451 solver.cpp:228] Iteration 27890, loss = 0.312825
I0809 07:41:06.183240 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 07:41:06.183255 20451 solver.cpp:244]     Train net output #1: loss = 0.312825 (* 1 = 0.312825 loss)
I0809 07:41:06.183267 20451 sgd_solver.cpp:106] Iteration 27890, lr = 0.000368219
I0809 07:41:26.263048 20451 solver.cpp:337] Iteration 27900, Testing net (#0)
I0809 07:41:34.786890 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 07:41:34.786947 20451 solver.cpp:404]     Test net output #1: loss = 1.00327 (* 1 = 1.00327 loss)
I0809 07:41:36.995578 20451 solver.cpp:228] Iteration 27900, loss = 0.125026
I0809 07:41:36.995687 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:41:36.995703 20451 solver.cpp:244]     Train net output #1: loss = 0.125026 (* 1 = 0.125026 loss)
I0809 07:41:36.995715 20451 sgd_solver.cpp:106] Iteration 27900, lr = 0.000368146
I0809 07:41:59.282889 20451 solver.cpp:228] Iteration 27910, loss = 0.125013
I0809 07:41:59.282932 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:41:59.282946 20451 solver.cpp:244]     Train net output #1: loss = 0.125013 (* 1 = 0.125013 loss)
I0809 07:41:59.282960 20451 sgd_solver.cpp:106] Iteration 27910, lr = 0.000368074
I0809 07:42:21.590355 20451 solver.cpp:228] Iteration 27920, loss = 0.31268
I0809 07:42:21.590570 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 07:42:21.590586 20451 solver.cpp:244]     Train net output #1: loss = 0.31268 (* 1 = 0.31268 loss)
I0809 07:42:21.590598 20451 sgd_solver.cpp:106] Iteration 27920, lr = 0.000368001
I0809 07:42:43.909780 20451 solver.cpp:228] Iteration 27930, loss = 0.125008
I0809 07:42:43.909840 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:42:43.909859 20451 solver.cpp:244]     Train net output #1: loss = 0.125008 (* 1 = 0.125008 loss)
I0809 07:42:43.909874 20451 sgd_solver.cpp:106] Iteration 27930, lr = 0.000367928
I0809 07:43:06.226052 20451 solver.cpp:228] Iteration 27940, loss = 0.25009
I0809 07:43:06.226232 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:43:06.226248 20451 solver.cpp:244]     Train net output #1: loss = 0.250091 (* 1 = 0.250091 loss)
I0809 07:43:06.226260 20451 sgd_solver.cpp:106] Iteration 27940, lr = 0.000367855
I0809 07:43:28.541641 20451 solver.cpp:228] Iteration 27950, loss = 0.250069
I0809 07:43:28.541693 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:43:28.541707 20451 solver.cpp:244]     Train net output #1: loss = 0.250069 (* 1 = 0.250069 loss)
I0809 07:43:28.541719 20451 sgd_solver.cpp:106] Iteration 27950, lr = 0.000367783
I0809 07:43:50.849652 20451 solver.cpp:228] Iteration 27960, loss = 0.187564
I0809 07:43:50.849828 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:43:50.849845 20451 solver.cpp:244]     Train net output #1: loss = 0.187564 (* 1 = 0.187564 loss)
I0809 07:43:50.849858 20451 sgd_solver.cpp:106] Iteration 27960, lr = 0.00036771
I0809 07:44:13.167937 20451 solver.cpp:228] Iteration 27970, loss = 0.156326
I0809 07:44:13.167986 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:44:13.168000 20451 solver.cpp:244]     Train net output #1: loss = 0.156326 (* 1 = 0.156326 loss)
I0809 07:44:13.168012 20451 sgd_solver.cpp:106] Iteration 27970, lr = 0.000367637
I0809 07:44:35.475790 20451 solver.cpp:228] Iteration 27980, loss = 0.031251
I0809 07:44:35.475968 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 07:44:35.475985 20451 solver.cpp:244]     Train net output #1: loss = 0.0312512 (* 1 = 0.0312512 loss)
I0809 07:44:35.475996 20451 sgd_solver.cpp:106] Iteration 27980, lr = 0.000367565
I0809 07:44:57.789517 20451 solver.cpp:228] Iteration 27990, loss = 0.218841
I0809 07:44:57.789572 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:44:57.789587 20451 solver.cpp:244]     Train net output #1: loss = 0.218842 (* 1 = 0.218842 loss)
I0809 07:44:57.789599 20451 sgd_solver.cpp:106] Iteration 27990, lr = 0.000367492
I0809 07:45:17.873970 20451 solver.cpp:337] Iteration 28000, Testing net (#0)
I0809 07:45:26.398720 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 07:45:26.398766 20451 solver.cpp:404]     Test net output #1: loss = 0.984513 (* 1 = 0.984513 loss)
I0809 07:45:28.604804 20451 solver.cpp:228] Iteration 28000, loss = 0.0625126
I0809 07:45:28.604856 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 07:45:28.604869 20451 solver.cpp:244]     Train net output #1: loss = 0.0625128 (* 1 = 0.0625128 loss)
I0809 07:45:28.604882 20451 sgd_solver.cpp:106] Iteration 28000, lr = 0.00036742
I0809 07:45:50.883075 20451 solver.cpp:228] Iteration 28010, loss = 0.343819
I0809 07:45:50.883188 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 07:45:50.883203 20451 solver.cpp:244]     Train net output #1: loss = 0.343819 (* 1 = 0.343819 loss)
I0809 07:45:50.883215 20451 sgd_solver.cpp:106] Iteration 28010, lr = 0.000367347
I0809 07:46:13.198765 20451 solver.cpp:228] Iteration 28020, loss = 0.156319
I0809 07:46:13.198817 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:46:13.198832 20451 solver.cpp:244]     Train net output #1: loss = 0.156319 (* 1 = 0.156319 loss)
I0809 07:46:13.198843 20451 sgd_solver.cpp:106] Iteration 28020, lr = 0.000367275
I0809 07:46:35.516687 20451 solver.cpp:228] Iteration 28030, loss = 0.218789
I0809 07:46:35.516902 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:46:35.516917 20451 solver.cpp:244]     Train net output #1: loss = 0.21879 (* 1 = 0.21879 loss)
I0809 07:46:35.516933 20451 sgd_solver.cpp:106] Iteration 28030, lr = 0.000367202
I0809 07:46:57.827245 20451 solver.cpp:228] Iteration 28040, loss = 0.0938294
I0809 07:46:57.827301 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:46:57.827316 20451 solver.cpp:244]     Train net output #1: loss = 0.0938295 (* 1 = 0.0938295 loss)
I0809 07:46:57.827328 20451 sgd_solver.cpp:106] Iteration 28040, lr = 0.00036713
I0809 07:47:20.142452 20451 solver.cpp:228] Iteration 28050, loss = 0.343987
I0809 07:47:20.142637 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:47:20.142652 20451 solver.cpp:244]     Train net output #1: loss = 0.343987 (* 1 = 0.343987 loss)
I0809 07:47:20.142664 20451 sgd_solver.cpp:106] Iteration 28050, lr = 0.000367057
I0809 07:47:42.442764 20451 solver.cpp:228] Iteration 28060, loss = 0.219066
I0809 07:47:42.442816 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:47:42.442831 20451 solver.cpp:244]     Train net output #1: loss = 0.219066 (* 1 = 0.219066 loss)
I0809 07:47:42.442842 20451 sgd_solver.cpp:106] Iteration 28060, lr = 0.000366985
I0809 07:48:04.749126 20451 solver.cpp:228] Iteration 28070, loss = 0.0937485
I0809 07:48:04.749222 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 07:48:04.749241 20451 solver.cpp:244]     Train net output #1: loss = 0.0937486 (* 1 = 0.0937486 loss)
I0809 07:48:04.749256 20451 sgd_solver.cpp:106] Iteration 28070, lr = 0.000366913
I0809 07:48:27.055018 20451 solver.cpp:228] Iteration 28080, loss = 0.187756
I0809 07:48:27.055070 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:48:27.055084 20451 solver.cpp:244]     Train net output #1: loss = 0.187756 (* 1 = 0.187756 loss)
I0809 07:48:27.055096 20451 sgd_solver.cpp:106] Iteration 28080, lr = 0.000366841
I0809 07:48:49.369251 20451 solver.cpp:228] Iteration 28090, loss = 0.156254
I0809 07:48:49.369428 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:48:49.369444 20451 solver.cpp:244]     Train net output #1: loss = 0.156254 (* 1 = 0.156254 loss)
I0809 07:48:49.369457 20451 sgd_solver.cpp:106] Iteration 28090, lr = 0.000366768
I0809 07:49:09.461153 20451 solver.cpp:337] Iteration 28100, Testing net (#0)
I0809 07:49:17.985903 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 07:49:17.985949 20451 solver.cpp:404]     Test net output #1: loss = 0.998866 (* 1 = 0.998866 loss)
I0809 07:49:20.191395 20451 solver.cpp:228] Iteration 28100, loss = 0.125156
I0809 07:49:20.191575 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:49:20.191591 20451 solver.cpp:244]     Train net output #1: loss = 0.125156 (* 1 = 0.125156 loss)
I0809 07:49:20.191602 20451 sgd_solver.cpp:106] Iteration 28100, lr = 0.000366696
I0809 07:49:42.480473 20451 solver.cpp:228] Iteration 28110, loss = 0.218823
I0809 07:49:42.480525 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:49:42.480537 20451 solver.cpp:244]     Train net output #1: loss = 0.218823 (* 1 = 0.218823 loss)
I0809 07:49:42.480550 20451 sgd_solver.cpp:106] Iteration 28110, lr = 0.000366624
I0809 07:50:04.796196 20451 solver.cpp:228] Iteration 28120, loss = 0.125029
I0809 07:50:04.796308 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:50:04.796326 20451 solver.cpp:244]     Train net output #1: loss = 0.125029 (* 1 = 0.125029 loss)
I0809 07:50:04.796344 20451 sgd_solver.cpp:106] Iteration 28120, lr = 0.000366552
I0809 07:50:27.104362 20451 solver.cpp:228] Iteration 28130, loss = 0.187501
I0809 07:50:27.104410 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:50:27.104429 20451 solver.cpp:244]     Train net output #1: loss = 0.187501 (* 1 = 0.187501 loss)
I0809 07:50:27.104446 20451 sgd_solver.cpp:106] Iteration 28130, lr = 0.00036648
I0809 07:50:49.410974 20451 solver.cpp:228] Iteration 28140, loss = 0.187507
I0809 07:50:49.411185 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:50:49.411201 20451 solver.cpp:244]     Train net output #1: loss = 0.187508 (* 1 = 0.187508 loss)
I0809 07:50:49.411213 20451 sgd_solver.cpp:106] Iteration 28140, lr = 0.000366408
I0809 07:51:11.724783 20451 solver.cpp:228] Iteration 28150, loss = 0.343888
I0809 07:51:11.724835 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 07:51:11.724849 20451 solver.cpp:244]     Train net output #1: loss = 0.343888 (* 1 = 0.343888 loss)
I0809 07:51:11.724860 20451 sgd_solver.cpp:106] Iteration 28150, lr = 0.000366336
I0809 07:51:34.040487 20451 solver.cpp:228] Iteration 28160, loss = 0.125036
I0809 07:51:34.040576 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:51:34.040592 20451 solver.cpp:244]     Train net output #1: loss = 0.125036 (* 1 = 0.125036 loss)
I0809 07:51:34.040606 20451 sgd_solver.cpp:106] Iteration 28160, lr = 0.000366264
I0809 07:51:56.343976 20451 solver.cpp:228] Iteration 28170, loss = 0.187616
I0809 07:51:56.344027 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:51:56.344041 20451 solver.cpp:244]     Train net output #1: loss = 0.187616 (* 1 = 0.187616 loss)
I0809 07:51:56.344054 20451 sgd_solver.cpp:106] Iteration 28170, lr = 0.000366192
I0809 07:52:18.659312 20451 solver.cpp:228] Iteration 28180, loss = 0.1251
I0809 07:52:18.659549 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:52:18.659569 20451 solver.cpp:244]     Train net output #1: loss = 0.1251 (* 1 = 0.1251 loss)
I0809 07:52:18.659584 20451 sgd_solver.cpp:106] Iteration 28180, lr = 0.00036612
I0809 07:52:40.978354 20451 solver.cpp:228] Iteration 28190, loss = 0.281709
I0809 07:52:40.978471 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 07:52:40.978510 20451 solver.cpp:244]     Train net output #1: loss = 0.281709 (* 1 = 0.281709 loss)
I0809 07:52:40.978548 20451 sgd_solver.cpp:106] Iteration 28190, lr = 0.000366048
I0809 07:53:01.075920 20451 solver.cpp:337] Iteration 28200, Testing net (#0)
I0809 07:53:09.598757 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 07:53:09.598809 20451 solver.cpp:404]     Test net output #1: loss = 0.998447 (* 1 = 0.998447 loss)
I0809 07:53:11.804383 20451 solver.cpp:228] Iteration 28200, loss = 0.0937734
I0809 07:53:11.804435 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 07:53:11.804448 20451 solver.cpp:244]     Train net output #1: loss = 0.0937736 (* 1 = 0.0937736 loss)
I0809 07:53:11.804461 20451 sgd_solver.cpp:106] Iteration 28200, lr = 0.000365976
I0809 07:53:34.086136 20451 solver.cpp:228] Iteration 28210, loss = 0.250446
I0809 07:53:34.086303 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:53:34.086318 20451 solver.cpp:244]     Train net output #1: loss = 0.250446 (* 1 = 0.250446 loss)
I0809 07:53:34.086331 20451 sgd_solver.cpp:106] Iteration 28210, lr = 0.000365904
I0809 07:53:56.392964 20451 solver.cpp:228] Iteration 28220, loss = 0.156308
I0809 07:53:56.393012 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 07:53:56.393029 20451 solver.cpp:244]     Train net output #1: loss = 0.156308 (* 1 = 0.156308 loss)
I0809 07:53:56.393044 20451 sgd_solver.cpp:106] Iteration 28220, lr = 0.000365832
I0809 07:54:18.707970 20451 solver.cpp:228] Iteration 28230, loss = 0.0625188
I0809 07:54:18.708153 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 07:54:18.708171 20451 solver.cpp:244]     Train net output #1: loss = 0.0625191 (* 1 = 0.0625191 loss)
I0809 07:54:18.708187 20451 sgd_solver.cpp:106] Iteration 28230, lr = 0.00036576
I0809 07:54:41.017168 20451 solver.cpp:228] Iteration 28240, loss = 0.187584
I0809 07:54:41.017218 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 07:54:41.017232 20451 solver.cpp:244]     Train net output #1: loss = 0.187584 (* 1 = 0.187584 loss)
I0809 07:54:41.017244 20451 sgd_solver.cpp:106] Iteration 28240, lr = 0.000365689
I0809 07:55:03.322821 20451 solver.cpp:228] Iteration 28250, loss = 0.218817
I0809 07:55:03.322928 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:55:03.322944 20451 solver.cpp:244]     Train net output #1: loss = 0.218817 (* 1 = 0.218817 loss)
I0809 07:55:03.322957 20451 sgd_solver.cpp:106] Iteration 28250, lr = 0.000365617
I0809 07:55:25.637601 20451 solver.cpp:228] Iteration 28260, loss = 0.0937827
I0809 07:55:25.637655 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 07:55:25.637670 20451 solver.cpp:244]     Train net output #1: loss = 0.093783 (* 1 = 0.093783 loss)
I0809 07:55:25.637682 20451 sgd_solver.cpp:106] Iteration 28260, lr = 0.000365545
I0809 07:55:47.951062 20451 solver.cpp:228] Iteration 28270, loss = 0.250025
I0809 07:55:47.951252 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:55:47.951268 20451 solver.cpp:244]     Train net output #1: loss = 0.250026 (* 1 = 0.250026 loss)
I0809 07:55:47.951287 20451 sgd_solver.cpp:106] Iteration 28270, lr = 0.000365474
I0809 07:56:10.261941 20451 solver.cpp:228] Iteration 28280, loss = 0.125021
I0809 07:56:10.261996 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:56:10.262009 20451 solver.cpp:244]     Train net output #1: loss = 0.125021 (* 1 = 0.125021 loss)
I0809 07:56:10.262022 20451 sgd_solver.cpp:106] Iteration 28280, lr = 0.000365402
I0809 07:56:32.568753 20451 solver.cpp:228] Iteration 28290, loss = 0.250095
I0809 07:56:32.568862 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:56:32.568878 20451 solver.cpp:244]     Train net output #1: loss = 0.250095 (* 1 = 0.250095 loss)
I0809 07:56:32.568892 20451 sgd_solver.cpp:106] Iteration 28290, lr = 0.000365331
I0809 07:56:52.651542 20451 solver.cpp:337] Iteration 28300, Testing net (#0)
I0809 07:57:01.184577 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 07:57:01.184622 20451 solver.cpp:404]     Test net output #1: loss = 1.00878 (* 1 = 1.00878 loss)
I0809 07:57:03.390413 20451 solver.cpp:228] Iteration 28300, loss = 0.219059
I0809 07:57:03.390493 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:57:03.390511 20451 solver.cpp:244]     Train net output #1: loss = 0.219059 (* 1 = 0.219059 loss)
I0809 07:57:03.390537 20451 sgd_solver.cpp:106] Iteration 28300, lr = 0.000365259
I0809 07:57:25.669157 20451 solver.cpp:228] Iteration 28310, loss = 0.250136
I0809 07:57:25.669203 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:57:25.669220 20451 solver.cpp:244]     Train net output #1: loss = 0.250136 (* 1 = 0.250136 loss)
I0809 07:57:25.669246 20451 sgd_solver.cpp:106] Iteration 28310, lr = 0.000365188
I0809 07:57:47.982244 20451 solver.cpp:228] Iteration 28320, loss = 0.187736
I0809 07:57:47.982347 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 07:57:47.982365 20451 solver.cpp:244]     Train net output #1: loss = 0.187736 (* 1 = 0.187736 loss)
I0809 07:57:47.982380 20451 sgd_solver.cpp:106] Iteration 28320, lr = 0.000365116
I0809 07:58:10.291218 20451 solver.cpp:228] Iteration 28330, loss = 0.125039
I0809 07:58:10.291270 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:58:10.291292 20451 solver.cpp:244]     Train net output #1: loss = 0.125039 (* 1 = 0.125039 loss)
I0809 07:58:10.291304 20451 sgd_solver.cpp:106] Iteration 28330, lr = 0.000365045
I0809 07:58:32.604313 20451 solver.cpp:228] Iteration 28340, loss = 0.125024
I0809 07:58:32.604492 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:58:32.604507 20451 solver.cpp:244]     Train net output #1: loss = 0.125024 (* 1 = 0.125024 loss)
I0809 07:58:32.604521 20451 sgd_solver.cpp:106] Iteration 28340, lr = 0.000364973
I0809 07:58:54.923341 20451 solver.cpp:228] Iteration 28350, loss = 0.125066
I0809 07:58:54.923393 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 07:58:54.923408 20451 solver.cpp:244]     Train net output #1: loss = 0.125067 (* 1 = 0.125067 loss)
I0809 07:58:54.923419 20451 sgd_solver.cpp:106] Iteration 28350, lr = 0.000364902
I0809 07:59:17.243043 20451 solver.cpp:228] Iteration 28360, loss = 0.25007
I0809 07:59:17.243254 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 07:59:17.243270 20451 solver.cpp:244]     Train net output #1: loss = 0.25007 (* 1 = 0.25007 loss)
I0809 07:59:17.243288 20451 sgd_solver.cpp:106] Iteration 28360, lr = 0.00036483
I0809 07:59:39.557169 20451 solver.cpp:228] Iteration 28370, loss = 0.218874
I0809 07:59:39.557220 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 07:59:39.557235 20451 solver.cpp:244]     Train net output #1: loss = 0.218874 (* 1 = 0.218874 loss)
I0809 07:59:39.557246 20451 sgd_solver.cpp:106] Iteration 28370, lr = 0.000364759
I0809 08:00:01.870061 20451 solver.cpp:228] Iteration 28380, loss = 0.281302
I0809 08:00:01.870225 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 08:00:01.870246 20451 solver.cpp:244]     Train net output #1: loss = 0.281302 (* 1 = 0.281302 loss)
I0809 08:00:01.870261 20451 sgd_solver.cpp:106] Iteration 28380, lr = 0.000364688
I0809 08:00:24.178531 20451 solver.cpp:228] Iteration 28390, loss = 0.250148
I0809 08:00:24.178586 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:00:24.178602 20451 solver.cpp:244]     Train net output #1: loss = 0.250149 (* 1 = 0.250149 loss)
I0809 08:00:24.178628 20451 sgd_solver.cpp:106] Iteration 28390, lr = 0.000364617
I0809 08:00:44.261494 20451 solver.cpp:337] Iteration 28400, Testing net (#0)
I0809 08:00:52.781576 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 08:00:52.781623 20451 solver.cpp:404]     Test net output #1: loss = 1.00343 (* 1 = 1.00343 loss)
I0809 08:00:54.985671 20451 solver.cpp:228] Iteration 28400, loss = 0.0312639
I0809 08:00:54.985718 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 08:00:54.985738 20451 solver.cpp:244]     Train net output #1: loss = 0.0312642 (* 1 = 0.0312642 loss)
I0809 08:00:54.985752 20451 sgd_solver.cpp:106] Iteration 28400, lr = 0.000364545
I0809 08:01:17.276020 20451 solver.cpp:228] Iteration 28410, loss = 0.0625119
I0809 08:01:17.276119 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 08:01:17.276139 20451 solver.cpp:244]     Train net output #1: loss = 0.0625122 (* 1 = 0.0625122 loss)
I0809 08:01:17.276154 20451 sgd_solver.cpp:106] Iteration 28410, lr = 0.000364474
I0809 08:01:39.582509 20451 solver.cpp:228] Iteration 28420, loss = 0.187549
I0809 08:01:39.582553 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:01:39.582571 20451 solver.cpp:244]     Train net output #1: loss = 0.18755 (* 1 = 0.18755 loss)
I0809 08:01:39.582587 20451 sgd_solver.cpp:106] Iteration 28420, lr = 0.000364403
I0809 08:02:01.903210 20451 solver.cpp:228] Iteration 28430, loss = 0.218818
I0809 08:02:01.903331 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:02:01.903347 20451 solver.cpp:244]     Train net output #1: loss = 0.218818 (* 1 = 0.218818 loss)
I0809 08:02:01.903359 20451 sgd_solver.cpp:106] Iteration 28430, lr = 0.000364332
I0809 08:02:24.209228 20451 solver.cpp:228] Iteration 28440, loss = 0.218765
I0809 08:02:24.209270 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:02:24.209286 20451 solver.cpp:244]     Train net output #1: loss = 0.218765 (* 1 = 0.218765 loss)
I0809 08:02:24.209300 20451 sgd_solver.cpp:106] Iteration 28440, lr = 0.000364261
I0809 08:02:46.514346 20451 solver.cpp:228] Iteration 28450, loss = 0.125024
I0809 08:02:46.514535 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:02:46.514550 20451 solver.cpp:244]     Train net output #1: loss = 0.125025 (* 1 = 0.125025 loss)
I0809 08:02:46.514562 20451 sgd_solver.cpp:106] Iteration 28450, lr = 0.00036419
I0809 08:03:08.827401 20451 solver.cpp:228] Iteration 28460, loss = 0.0937535
I0809 08:03:08.827442 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 08:03:08.827458 20451 solver.cpp:244]     Train net output #1: loss = 0.0937538 (* 1 = 0.0937538 loss)
I0809 08:03:08.827471 20451 sgd_solver.cpp:106] Iteration 28460, lr = 0.000364119
I0809 08:03:31.140872 20451 solver.cpp:228] Iteration 28470, loss = 0.250103
I0809 08:03:31.141091 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:03:31.141108 20451 solver.cpp:244]     Train net output #1: loss = 0.250104 (* 1 = 0.250104 loss)
I0809 08:03:31.141119 20451 sgd_solver.cpp:106] Iteration 28470, lr = 0.000364048
I0809 08:03:53.447454 20451 solver.cpp:228] Iteration 28480, loss = 0.250015
I0809 08:03:53.447504 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:03:53.447520 20451 solver.cpp:244]     Train net output #1: loss = 0.250016 (* 1 = 0.250016 loss)
I0809 08:03:53.447531 20451 sgd_solver.cpp:106] Iteration 28480, lr = 0.000363977
I0809 08:04:15.760097 20451 solver.cpp:228] Iteration 28490, loss = 0.156282
I0809 08:04:15.760277 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:04:15.760293 20451 solver.cpp:244]     Train net output #1: loss = 0.156283 (* 1 = 0.156283 loss)
I0809 08:04:15.760304 20451 sgd_solver.cpp:106] Iteration 28490, lr = 0.000363906
I0809 08:04:35.840626 20451 solver.cpp:337] Iteration 28500, Testing net (#0)
I0809 08:04:44.365309 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0809 08:04:44.365350 20451 solver.cpp:404]     Test net output #1: loss = 0.96121 (* 1 = 0.96121 loss)
I0809 08:04:46.571007 20451 solver.cpp:228] Iteration 28500, loss = 0.218842
I0809 08:04:46.571182 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:04:46.571198 20451 solver.cpp:244]     Train net output #1: loss = 0.218842 (* 1 = 0.218842 loss)
I0809 08:04:46.571211 20451 sgd_solver.cpp:106] Iteration 28500, lr = 0.000363835
I0809 08:05:08.866940 20451 solver.cpp:228] Iteration 28510, loss = 0.125016
I0809 08:05:08.866991 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:05:08.867003 20451 solver.cpp:244]     Train net output #1: loss = 0.125016 (* 1 = 0.125016 loss)
I0809 08:05:08.867015 20451 sgd_solver.cpp:106] Iteration 28510, lr = 0.000363764
I0809 08:05:31.187968 20451 solver.cpp:228] Iteration 28520, loss = 0.187689
I0809 08:05:31.188148 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:05:31.188163 20451 solver.cpp:244]     Train net output #1: loss = 0.187689 (* 1 = 0.187689 loss)
I0809 08:05:31.188176 20451 sgd_solver.cpp:106] Iteration 28520, lr = 0.000363693
I0809 08:05:53.497548 20451 solver.cpp:228] Iteration 28530, loss = 0.0940319
I0809 08:05:53.497601 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:05:53.497616 20451 solver.cpp:244]     Train net output #1: loss = 0.0940322 (* 1 = 0.0940322 loss)
I0809 08:05:53.497627 20451 sgd_solver.cpp:106] Iteration 28530, lr = 0.000363623
I0809 08:06:15.812364 20451 solver.cpp:228] Iteration 28540, loss = 0.281775
I0809 08:06:15.812552 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 08:06:15.812568 20451 solver.cpp:244]     Train net output #1: loss = 0.281776 (* 1 = 0.281776 loss)
I0809 08:06:15.812582 20451 sgd_solver.cpp:106] Iteration 28540, lr = 0.000363552
I0809 08:06:38.120201 20451 solver.cpp:228] Iteration 28550, loss = 0.156354
I0809 08:06:38.120254 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:06:38.120268 20451 solver.cpp:244]     Train net output #1: loss = 0.156354 (* 1 = 0.156354 loss)
I0809 08:06:38.120280 20451 sgd_solver.cpp:106] Iteration 28550, lr = 0.000363481
I0809 08:07:00.432479 20451 solver.cpp:228] Iteration 28560, loss = 0.12513
I0809 08:07:00.432579 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:07:00.432595 20451 solver.cpp:244]     Train net output #1: loss = 0.12513 (* 1 = 0.12513 loss)
I0809 08:07:00.432605 20451 sgd_solver.cpp:106] Iteration 28560, lr = 0.00036341
I0809 08:07:22.734905 20451 solver.cpp:228] Iteration 28570, loss = 0.187613
I0809 08:07:22.734951 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:07:22.734964 20451 solver.cpp:244]     Train net output #1: loss = 0.187613 (* 1 = 0.187613 loss)
I0809 08:07:22.734978 20451 sgd_solver.cpp:106] Iteration 28570, lr = 0.00036334
I0809 08:07:45.050127 20451 solver.cpp:228] Iteration 28580, loss = 0.218979
I0809 08:07:45.050290 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:07:45.050310 20451 solver.cpp:244]     Train net output #1: loss = 0.218979 (* 1 = 0.218979 loss)
I0809 08:07:45.050326 20451 sgd_solver.cpp:106] Iteration 28580, lr = 0.000363269
I0809 08:08:07.361661 20451 solver.cpp:228] Iteration 28590, loss = 0.125044
I0809 08:08:07.361714 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:08:07.361728 20451 solver.cpp:244]     Train net output #1: loss = 0.125044 (* 1 = 0.125044 loss)
I0809 08:08:07.361742 20451 sgd_solver.cpp:106] Iteration 28590, lr = 0.000363198
I0809 08:08:27.439095 20451 solver.cpp:337] Iteration 28600, Testing net (#0)
I0809 08:08:35.957829 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 08:08:35.957880 20451 solver.cpp:404]     Test net output #1: loss = 0.994093 (* 1 = 0.994093 loss)
I0809 08:08:38.164324 20451 solver.cpp:228] Iteration 28600, loss = 0.250128
I0809 08:08:38.164374 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:08:38.164389 20451 solver.cpp:244]     Train net output #1: loss = 0.250128 (* 1 = 0.250128 loss)
I0809 08:08:38.164402 20451 sgd_solver.cpp:106] Iteration 28600, lr = 0.000363128
I0809 08:09:00.453668 20451 solver.cpp:228] Iteration 28610, loss = 0.250107
I0809 08:09:00.453765 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:09:00.453780 20451 solver.cpp:244]     Train net output #1: loss = 0.250107 (* 1 = 0.250107 loss)
I0809 08:09:00.453793 20451 sgd_solver.cpp:106] Iteration 28610, lr = 0.000363057
I0809 08:09:22.770149 20451 solver.cpp:228] Iteration 28620, loss = 0.21877
I0809 08:09:22.770198 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:09:22.770213 20451 solver.cpp:244]     Train net output #1: loss = 0.218771 (* 1 = 0.218771 loss)
I0809 08:09:22.770227 20451 sgd_solver.cpp:106] Iteration 28620, lr = 0.000362987
I0809 08:09:45.066303 20451 solver.cpp:228] Iteration 28630, loss = 0.1876
I0809 08:09:45.066484 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:09:45.066499 20451 solver.cpp:244]     Train net output #1: loss = 0.187601 (* 1 = 0.187601 loss)
I0809 08:09:45.066512 20451 sgd_solver.cpp:106] Iteration 28630, lr = 0.000362916
I0809 08:10:07.373064 20451 solver.cpp:228] Iteration 28640, loss = 0.0312555
I0809 08:10:07.373111 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 08:10:07.373127 20451 solver.cpp:244]     Train net output #1: loss = 0.0312558 (* 1 = 0.0312558 loss)
I0809 08:10:07.373142 20451 sgd_solver.cpp:106] Iteration 28640, lr = 0.000362846
I0809 08:10:29.683439 20451 solver.cpp:228] Iteration 28650, loss = 0.156281
I0809 08:10:29.683544 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:10:29.683558 20451 solver.cpp:244]     Train net output #1: loss = 0.156281 (* 1 = 0.156281 loss)
I0809 08:10:29.683570 20451 sgd_solver.cpp:106] Iteration 28650, lr = 0.000362775
I0809 08:10:51.992589 20451 solver.cpp:228] Iteration 28660, loss = 0.0937647
I0809 08:10:51.992635 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 08:10:51.992651 20451 solver.cpp:244]     Train net output #1: loss = 0.093765 (* 1 = 0.093765 loss)
I0809 08:10:51.992665 20451 sgd_solver.cpp:106] Iteration 28660, lr = 0.000362705
I0809 08:11:14.306705 20451 solver.cpp:228] Iteration 28670, loss = 0.12515
I0809 08:11:14.306892 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:11:14.306908 20451 solver.cpp:244]     Train net output #1: loss = 0.12515 (* 1 = 0.12515 loss)
I0809 08:11:14.306921 20451 sgd_solver.cpp:106] Iteration 28670, lr = 0.000362635
I0809 08:11:36.612192 20451 solver.cpp:228] Iteration 28680, loss = 0.125162
I0809 08:11:36.612233 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:11:36.612247 20451 solver.cpp:244]     Train net output #1: loss = 0.125162 (* 1 = 0.125162 loss)
I0809 08:11:36.612259 20451 sgd_solver.cpp:106] Iteration 28680, lr = 0.000362564
I0809 08:11:58.913378 20451 solver.cpp:228] Iteration 28690, loss = 0.21888
I0809 08:11:58.913528 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:11:58.913544 20451 solver.cpp:244]     Train net output #1: loss = 0.21888 (* 1 = 0.21888 loss)
I0809 08:11:58.913558 20451 sgd_solver.cpp:106] Iteration 28690, lr = 0.000362494
I0809 08:12:18.997014 20451 solver.cpp:337] Iteration 28700, Testing net (#0)
I0809 08:12:27.521530 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 08:12:27.521595 20451 solver.cpp:404]     Test net output #1: loss = 0.998663 (* 1 = 0.998663 loss)
I0809 08:12:29.726151 20451 solver.cpp:228] Iteration 28700, loss = 0.125042
I0809 08:12:29.726333 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:12:29.726348 20451 solver.cpp:244]     Train net output #1: loss = 0.125042 (* 1 = 0.125042 loss)
I0809 08:12:29.726361 20451 sgd_solver.cpp:106] Iteration 28700, lr = 0.000362424
I0809 08:12:52.014240 20451 solver.cpp:228] Iteration 28710, loss = 0.156269
I0809 08:12:52.014286 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:12:52.014299 20451 solver.cpp:244]     Train net output #1: loss = 0.156269 (* 1 = 0.156269 loss)
I0809 08:12:52.014312 20451 sgd_solver.cpp:106] Iteration 28710, lr = 0.000362354
I0809 08:13:14.327172 20451 solver.cpp:228] Iteration 28720, loss = 0.187564
I0809 08:13:14.327249 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:13:14.327278 20451 solver.cpp:244]     Train net output #1: loss = 0.187565 (* 1 = 0.187565 loss)
I0809 08:13:14.327294 20451 sgd_solver.cpp:106] Iteration 28720, lr = 0.000362283
I0809 08:13:36.636576 20451 solver.cpp:228] Iteration 28730, loss = 0.187784
I0809 08:13:36.636617 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:13:36.636632 20451 solver.cpp:244]     Train net output #1: loss = 0.187784 (* 1 = 0.187784 loss)
I0809 08:13:36.636646 20451 sgd_solver.cpp:106] Iteration 28730, lr = 0.000362213
I0809 08:13:58.943303 20451 solver.cpp:228] Iteration 28740, loss = 0.281616
I0809 08:13:58.943485 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 08:13:58.943500 20451 solver.cpp:244]     Train net output #1: loss = 0.281617 (* 1 = 0.281617 loss)
I0809 08:13:58.943512 20451 sgd_solver.cpp:106] Iteration 28740, lr = 0.000362143
I0809 08:14:21.250011 20451 solver.cpp:228] Iteration 28750, loss = 0.0625204
I0809 08:14:21.250056 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 08:14:21.250084 20451 solver.cpp:244]     Train net output #1: loss = 0.0625207 (* 1 = 0.0625207 loss)
I0809 08:14:21.250100 20451 sgd_solver.cpp:106] Iteration 28750, lr = 0.000362073
I0809 08:14:43.551657 20451 solver.cpp:228] Iteration 28760, loss = 0.125169
I0809 08:14:43.551826 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:14:43.551841 20451 solver.cpp:244]     Train net output #1: loss = 0.125169 (* 1 = 0.125169 loss)
I0809 08:14:43.551854 20451 sgd_solver.cpp:106] Iteration 28760, lr = 0.000362003
I0809 08:15:05.863414 20451 solver.cpp:228] Iteration 28770, loss = 0.156377
I0809 08:15:05.863468 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:15:05.863482 20451 solver.cpp:244]     Train net output #1: loss = 0.156377 (* 1 = 0.156377 loss)
I0809 08:15:05.863494 20451 sgd_solver.cpp:106] Iteration 28770, lr = 0.000361933
I0809 08:15:28.171722 20451 solver.cpp:228] Iteration 28780, loss = 0.187749
I0809 08:15:28.171901 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:15:28.171916 20451 solver.cpp:244]     Train net output #1: loss = 0.187749 (* 1 = 0.187749 loss)
I0809 08:15:28.171929 20451 sgd_solver.cpp:106] Iteration 28780, lr = 0.000361863
I0809 08:15:50.480355 20451 solver.cpp:228] Iteration 28790, loss = 0.156257
I0809 08:15:50.480398 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:15:50.480413 20451 solver.cpp:244]     Train net output #1: loss = 0.156258 (* 1 = 0.156258 loss)
I0809 08:15:50.480427 20451 sgd_solver.cpp:106] Iteration 28790, lr = 0.000361793
I0809 08:16:10.559573 20451 solver.cpp:337] Iteration 28800, Testing net (#0)
I0809 08:16:19.090487 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0809 08:16:19.090538 20451 solver.cpp:404]     Test net output #1: loss = 0.98946 (* 1 = 0.98946 loss)
I0809 08:16:21.295104 20451 solver.cpp:228] Iteration 28800, loss = 0.125075
I0809 08:16:21.295157 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:16:21.295171 20451 solver.cpp:244]     Train net output #1: loss = 0.125075 (* 1 = 0.125075 loss)
I0809 08:16:21.295184 20451 sgd_solver.cpp:106] Iteration 28800, lr = 0.000361723
I0809 08:16:43.563318 20451 solver.cpp:228] Iteration 28810, loss = 0.156264
I0809 08:16:43.563406 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:16:43.563421 20451 solver.cpp:244]     Train net output #1: loss = 0.156265 (* 1 = 0.156265 loss)
I0809 08:16:43.563432 20451 sgd_solver.cpp:106] Iteration 28810, lr = 0.000361653
I0809 08:17:05.864212 20451 solver.cpp:228] Iteration 28820, loss = 0.21877
I0809 08:17:05.864256 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:17:05.864274 20451 solver.cpp:244]     Train net output #1: loss = 0.21877 (* 1 = 0.21877 loss)
I0809 08:17:05.864290 20451 sgd_solver.cpp:106] Iteration 28820, lr = 0.000361583
I0809 08:17:28.168949 20451 solver.cpp:228] Iteration 28830, loss = 0.218808
I0809 08:17:28.169123 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:17:28.169138 20451 solver.cpp:244]     Train net output #1: loss = 0.218808 (* 1 = 0.218808 loss)
I0809 08:17:28.169152 20451 sgd_solver.cpp:106] Iteration 28830, lr = 0.000361513
I0809 08:17:50.480554 20451 solver.cpp:228] Iteration 28840, loss = 0.18758
I0809 08:17:50.480605 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:17:50.480619 20451 solver.cpp:244]     Train net output #1: loss = 0.18758 (* 1 = 0.18758 loss)
I0809 08:17:50.480631 20451 sgd_solver.cpp:106] Iteration 28840, lr = 0.000361444
I0809 08:18:12.795467 20451 solver.cpp:228] Iteration 28850, loss = 0.125022
I0809 08:18:12.795647 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:18:12.795662 20451 solver.cpp:244]     Train net output #1: loss = 0.125023 (* 1 = 0.125023 loss)
I0809 08:18:12.795675 20451 sgd_solver.cpp:106] Iteration 28850, lr = 0.000361374
I0809 08:18:35.112253 20451 solver.cpp:228] Iteration 28860, loss = 0.156332
I0809 08:18:35.112305 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:18:35.112319 20451 solver.cpp:244]     Train net output #1: loss = 0.156332 (* 1 = 0.156332 loss)
I0809 08:18:35.112331 20451 sgd_solver.cpp:106] Iteration 28860, lr = 0.000361304
I0809 08:18:57.421206 20451 solver.cpp:228] Iteration 28870, loss = 0.312607
I0809 08:18:57.421392 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 08:18:57.421407 20451 solver.cpp:244]     Train net output #1: loss = 0.312607 (* 1 = 0.312607 loss)
I0809 08:18:57.421421 20451 sgd_solver.cpp:106] Iteration 28870, lr = 0.000361234
I0809 08:19:19.728507 20451 solver.cpp:228] Iteration 28880, loss = 0.218819
I0809 08:19:19.728554 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:19:19.728569 20451 solver.cpp:244]     Train net output #1: loss = 0.21882 (* 1 = 0.21882 loss)
I0809 08:19:19.728581 20451 sgd_solver.cpp:106] Iteration 28880, lr = 0.000361165
I0809 08:19:42.039885 20451 solver.cpp:228] Iteration 28890, loss = 0.187521
I0809 08:19:42.040107 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:19:42.040122 20451 solver.cpp:244]     Train net output #1: loss = 0.187521 (* 1 = 0.187521 loss)
I0809 08:19:42.040135 20451 sgd_solver.cpp:106] Iteration 28890, lr = 0.000361095
I0809 08:20:02.123278 20451 solver.cpp:337] Iteration 28900, Testing net (#0)
I0809 08:20:10.646252 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0809 08:20:10.646302 20451 solver.cpp:404]     Test net output #1: loss = 1.03609 (* 1 = 1.03609 loss)
I0809 08:20:12.852916 20451 solver.cpp:228] Iteration 28900, loss = 0.156284
I0809 08:20:12.853092 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:20:12.853108 20451 solver.cpp:244]     Train net output #1: loss = 0.156284 (* 1 = 0.156284 loss)
I0809 08:20:12.853121 20451 sgd_solver.cpp:106] Iteration 28900, lr = 0.000361025
I0809 08:20:35.152812 20451 solver.cpp:228] Iteration 28910, loss = 0.0625071
I0809 08:20:35.152866 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 08:20:35.152881 20451 solver.cpp:244]     Train net output #1: loss = 0.0625073 (* 1 = 0.0625073 loss)
I0809 08:20:35.152894 20451 sgd_solver.cpp:106] Iteration 28910, lr = 0.000360956
I0809 08:20:57.458071 20451 solver.cpp:228] Iteration 28920, loss = 0.312654
I0809 08:20:57.458174 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:20:57.458190 20451 solver.cpp:244]     Train net output #1: loss = 0.312655 (* 1 = 0.312655 loss)
I0809 08:20:57.458204 20451 sgd_solver.cpp:106] Iteration 28920, lr = 0.000360886
I0809 08:21:19.763212 20451 solver.cpp:228] Iteration 28930, loss = 0.218778
I0809 08:21:19.763260 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:21:19.763283 20451 solver.cpp:244]     Train net output #1: loss = 0.218778 (* 1 = 0.218778 loss)
I0809 08:21:19.763298 20451 sgd_solver.cpp:106] Iteration 28930, lr = 0.000360817
I0809 08:21:42.080096 20451 solver.cpp:228] Iteration 28940, loss = 0.187516
I0809 08:21:42.080274 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:21:42.080291 20451 solver.cpp:244]     Train net output #1: loss = 0.187516 (* 1 = 0.187516 loss)
I0809 08:21:42.080302 20451 sgd_solver.cpp:106] Iteration 28940, lr = 0.000360747
I0809 08:22:04.388036 20451 solver.cpp:228] Iteration 28950, loss = 0.156303
I0809 08:22:04.388087 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:22:04.388101 20451 solver.cpp:244]     Train net output #1: loss = 0.156303 (* 1 = 0.156303 loss)
I0809 08:22:04.388113 20451 sgd_solver.cpp:106] Iteration 28950, lr = 0.000360678
I0809 08:22:26.694123 20451 solver.cpp:228] Iteration 28960, loss = 0.250282
I0809 08:22:26.694303 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:22:26.694319 20451 solver.cpp:244]     Train net output #1: loss = 0.250283 (* 1 = 0.250283 loss)
I0809 08:22:26.694331 20451 sgd_solver.cpp:106] Iteration 28960, lr = 0.000360608
I0809 08:22:49.006618 20451 solver.cpp:228] Iteration 28970, loss = 0.15649
I0809 08:22:49.006664 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:22:49.006678 20451 solver.cpp:244]     Train net output #1: loss = 0.15649 (* 1 = 0.15649 loss)
I0809 08:22:49.006691 20451 sgd_solver.cpp:106] Iteration 28970, lr = 0.000360539
I0809 08:23:11.321718 20451 solver.cpp:228] Iteration 28980, loss = 0.12501
I0809 08:23:11.321903 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:23:11.321918 20451 solver.cpp:244]     Train net output #1: loss = 0.125011 (* 1 = 0.125011 loss)
I0809 08:23:11.321930 20451 sgd_solver.cpp:106] Iteration 28980, lr = 0.00036047
I0809 08:23:33.625846 20451 solver.cpp:228] Iteration 28990, loss = 0.218792
I0809 08:23:33.625902 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:23:33.625917 20451 solver.cpp:244]     Train net output #1: loss = 0.218792 (* 1 = 0.218792 loss)
I0809 08:23:33.625929 20451 sgd_solver.cpp:106] Iteration 28990, lr = 0.0003604
I0809 08:23:53.708583 20451 solver.cpp:337] Iteration 29000, Testing net (#0)
I0809 08:24:02.230293 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 08:24:02.230342 20451 solver.cpp:404]     Test net output #1: loss = 0.984436 (* 1 = 0.984436 loss)
I0809 08:24:04.432235 20451 solver.cpp:228] Iteration 29000, loss = 0.156403
I0809 08:24:04.432287 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:24:04.432301 20451 solver.cpp:244]     Train net output #1: loss = 0.156404 (* 1 = 0.156404 loss)
I0809 08:24:04.432313 20451 sgd_solver.cpp:106] Iteration 29000, lr = 0.000360331
I0809 08:24:26.721071 20451 solver.cpp:228] Iteration 29010, loss = 0.156508
I0809 08:24:26.721242 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:24:26.721257 20451 solver.cpp:244]     Train net output #1: loss = 0.156508 (* 1 = 0.156508 loss)
I0809 08:24:26.721269 20451 sgd_solver.cpp:106] Iteration 29010, lr = 0.000360262
I0809 08:24:49.025249 20451 solver.cpp:228] Iteration 29020, loss = 0.250393
I0809 08:24:49.025293 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:24:49.025308 20451 solver.cpp:244]     Train net output #1: loss = 0.250394 (* 1 = 0.250394 loss)
I0809 08:24:49.025321 20451 sgd_solver.cpp:106] Iteration 29020, lr = 0.000360192
I0809 08:25:11.342941 20451 solver.cpp:228] Iteration 29030, loss = 0.25016
I0809 08:25:11.343055 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:25:11.343070 20451 solver.cpp:244]     Train net output #1: loss = 0.25016 (* 1 = 0.25016 loss)
I0809 08:25:11.343082 20451 sgd_solver.cpp:106] Iteration 29030, lr = 0.000360123
I0809 08:25:33.650290 20451 solver.cpp:228] Iteration 29040, loss = 0.218989
I0809 08:25:33.650341 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:25:33.650355 20451 solver.cpp:244]     Train net output #1: loss = 0.218989 (* 1 = 0.218989 loss)
I0809 08:25:33.650367 20451 sgd_solver.cpp:106] Iteration 29040, lr = 0.000360054
I0809 08:25:55.951653 20451 solver.cpp:228] Iteration 29050, loss = 0.156273
I0809 08:25:55.951830 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:25:55.951845 20451 solver.cpp:244]     Train net output #1: loss = 0.156273 (* 1 = 0.156273 loss)
I0809 08:25:55.951858 20451 sgd_solver.cpp:106] Iteration 29050, lr = 0.000359985
I0809 08:26:18.267899 20451 solver.cpp:228] Iteration 29060, loss = 0.25013
I0809 08:26:18.267942 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:26:18.267959 20451 solver.cpp:244]     Train net output #1: loss = 0.25013 (* 1 = 0.25013 loss)
I0809 08:26:18.267976 20451 sgd_solver.cpp:106] Iteration 29060, lr = 0.000359916
I0809 08:26:40.572940 20451 solver.cpp:228] Iteration 29070, loss = 0.1563
I0809 08:26:40.573128 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:26:40.573148 20451 solver.cpp:244]     Train net output #1: loss = 0.1563 (* 1 = 0.1563 loss)
I0809 08:26:40.573164 20451 sgd_solver.cpp:106] Iteration 29070, lr = 0.000359847
I0809 08:27:02.892817 20451 solver.cpp:228] Iteration 29080, loss = 0.12502
I0809 08:27:02.892858 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:27:02.892874 20451 solver.cpp:244]     Train net output #1: loss = 0.12502 (* 1 = 0.12502 loss)
I0809 08:27:02.892889 20451 sgd_solver.cpp:106] Iteration 29080, lr = 0.000359778
I0809 08:27:25.197285 20451 solver.cpp:228] Iteration 29090, loss = 0.125014
I0809 08:27:25.197463 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:27:25.197481 20451 solver.cpp:244]     Train net output #1: loss = 0.125014 (* 1 = 0.125014 loss)
I0809 08:27:25.197497 20451 sgd_solver.cpp:106] Iteration 29090, lr = 0.000359709
I0809 08:27:45.277019 20451 solver.cpp:337] Iteration 29100, Testing net (#0)
I0809 08:27:53.798882 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0809 08:27:53.798933 20451 solver.cpp:404]     Test net output #1: loss = 0.970621 (* 1 = 0.970621 loss)
I0809 08:27:56.002867 20451 solver.cpp:228] Iteration 29100, loss = 0.0937943
I0809 08:27:56.003077 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 08:27:56.003093 20451 solver.cpp:244]     Train net output #1: loss = 0.0937945 (* 1 = 0.0937945 loss)
I0809 08:27:56.003106 20451 sgd_solver.cpp:106] Iteration 29100, lr = 0.00035964
I0809 08:28:18.287081 20451 solver.cpp:228] Iteration 29110, loss = 0.125016
I0809 08:28:18.287133 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:28:18.287147 20451 solver.cpp:244]     Train net output #1: loss = 0.125016 (* 1 = 0.125016 loss)
I0809 08:28:18.287159 20451 sgd_solver.cpp:106] Iteration 29110, lr = 0.000359571
I0809 08:28:40.596424 20451 solver.cpp:228] Iteration 29120, loss = 0.250181
I0809 08:28:40.596534 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:28:40.596549 20451 solver.cpp:244]     Train net output #1: loss = 0.250181 (* 1 = 0.250181 loss)
I0809 08:28:40.596560 20451 sgd_solver.cpp:106] Iteration 29120, lr = 0.000359502
I0809 08:29:02.910635 20451 solver.cpp:228] Iteration 29130, loss = 0.156256
I0809 08:29:02.910687 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:29:02.910701 20451 solver.cpp:244]     Train net output #1: loss = 0.156257 (* 1 = 0.156257 loss)
I0809 08:29:02.910713 20451 sgd_solver.cpp:106] Iteration 29130, lr = 0.000359433
I0809 08:29:25.219125 20451 solver.cpp:228] Iteration 29140, loss = 0.187614
I0809 08:29:25.219305 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:29:25.219321 20451 solver.cpp:244]     Train net output #1: loss = 0.187614 (* 1 = 0.187614 loss)
I0809 08:29:25.219333 20451 sgd_solver.cpp:106] Iteration 29140, lr = 0.000359364
I0809 08:29:47.526231 20451 solver.cpp:228] Iteration 29150, loss = 0.125011
I0809 08:29:47.526283 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:29:47.526298 20451 solver.cpp:244]     Train net output #1: loss = 0.125012 (* 1 = 0.125012 loss)
I0809 08:29:47.526309 20451 sgd_solver.cpp:106] Iteration 29150, lr = 0.000359295
I0809 08:30:09.830432 20451 solver.cpp:228] Iteration 29160, loss = 0.156263
I0809 08:30:09.830615 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:30:09.830629 20451 solver.cpp:244]     Train net output #1: loss = 0.156263 (* 1 = 0.156263 loss)
I0809 08:30:09.830642 20451 sgd_solver.cpp:106] Iteration 29160, lr = 0.000359226
I0809 08:30:32.125917 20451 solver.cpp:228] Iteration 29170, loss = 0.281281
I0809 08:30:32.125968 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 08:30:32.125982 20451 solver.cpp:244]     Train net output #1: loss = 0.281281 (* 1 = 0.281281 loss)
I0809 08:30:32.125994 20451 sgd_solver.cpp:106] Iteration 29170, lr = 0.000359157
I0809 08:30:54.427511 20451 solver.cpp:228] Iteration 29180, loss = 0.0625061
I0809 08:30:54.427688 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 08:30:54.427705 20451 solver.cpp:244]     Train net output #1: loss = 0.0625064 (* 1 = 0.0625064 loss)
I0809 08:30:54.427716 20451 sgd_solver.cpp:106] Iteration 29180, lr = 0.000359089
I0809 08:31:16.734880 20451 solver.cpp:228] Iteration 29190, loss = 0.125073
I0809 08:31:16.734926 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:31:16.734944 20451 solver.cpp:244]     Train net output #1: loss = 0.125073 (* 1 = 0.125073 loss)
I0809 08:31:16.734958 20451 sgd_solver.cpp:106] Iteration 29190, lr = 0.00035902
I0809 08:31:36.807183 20451 solver.cpp:337] Iteration 29200, Testing net (#0)
I0809 08:31:45.334473 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 08:31:45.334522 20451 solver.cpp:404]     Test net output #1: loss = 1.00797 (* 1 = 1.00797 loss)
I0809 08:31:47.538108 20451 solver.cpp:228] Iteration 29200, loss = 0.0625139
I0809 08:31:47.538158 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 08:31:47.538172 20451 solver.cpp:244]     Train net output #1: loss = 0.0625142 (* 1 = 0.0625142 loss)
I0809 08:31:47.538183 20451 sgd_solver.cpp:106] Iteration 29200, lr = 0.000358951
I0809 08:32:09.817814 20451 solver.cpp:228] Iteration 29210, loss = 0.187576
I0809 08:32:09.818023 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:32:09.818039 20451 solver.cpp:244]     Train net output #1: loss = 0.187577 (* 1 = 0.187577 loss)
I0809 08:32:09.818053 20451 sgd_solver.cpp:106] Iteration 29210, lr = 0.000358883
I0809 08:32:32.116125 20451 solver.cpp:228] Iteration 29220, loss = 0.187549
I0809 08:32:32.116178 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:32:32.116191 20451 solver.cpp:244]     Train net output #1: loss = 0.187549 (* 1 = 0.187549 loss)
I0809 08:32:32.116204 20451 sgd_solver.cpp:106] Iteration 29220, lr = 0.000358814
I0809 08:32:54.420158 20451 solver.cpp:228] Iteration 29230, loss = 0.218813
I0809 08:32:54.420336 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:32:54.420349 20451 solver.cpp:244]     Train net output #1: loss = 0.218814 (* 1 = 0.218814 loss)
I0809 08:32:54.420361 20451 sgd_solver.cpp:106] Iteration 29230, lr = 0.000358745
I0809 08:33:16.725745 20451 solver.cpp:228] Iteration 29240, loss = 0.218799
I0809 08:33:16.725786 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:33:16.725801 20451 solver.cpp:244]     Train net output #1: loss = 0.2188 (* 1 = 0.2188 loss)
I0809 08:33:16.725814 20451 sgd_solver.cpp:106] Iteration 29240, lr = 0.000358677
I0809 08:33:39.030990 20451 solver.cpp:228] Iteration 29250, loss = 0.187604
I0809 08:33:39.031172 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:33:39.031188 20451 solver.cpp:244]     Train net output #1: loss = 0.187604 (* 1 = 0.187604 loss)
I0809 08:33:39.031199 20451 sgd_solver.cpp:106] Iteration 29250, lr = 0.000358608
I0809 08:34:01.344290 20451 solver.cpp:228] Iteration 29260, loss = 0.125021
I0809 08:34:01.344341 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:34:01.344358 20451 solver.cpp:244]     Train net output #1: loss = 0.125021 (* 1 = 0.125021 loss)
I0809 08:34:01.344373 20451 sgd_solver.cpp:106] Iteration 29260, lr = 0.00035854
I0809 08:34:23.649145 20451 solver.cpp:228] Iteration 29270, loss = 0.281426
I0809 08:34:23.649317 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 08:34:23.649333 20451 solver.cpp:244]     Train net output #1: loss = 0.281427 (* 1 = 0.281427 loss)
I0809 08:34:23.649344 20451 sgd_solver.cpp:106] Iteration 29270, lr = 0.000358471
I0809 08:34:45.949033 20451 solver.cpp:228] Iteration 29280, loss = 0.406433
I0809 08:34:45.949079 20451 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0809 08:34:45.949106 20451 solver.cpp:244]     Train net output #1: loss = 0.406433 (* 1 = 0.406433 loss)
I0809 08:34:45.949121 20451 sgd_solver.cpp:106] Iteration 29280, lr = 0.000358403
I0809 08:35:08.255074 20451 solver.cpp:228] Iteration 29290, loss = 0.0939119
I0809 08:35:08.255264 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 08:35:08.255283 20451 solver.cpp:244]     Train net output #1: loss = 0.0939122 (* 1 = 0.0939122 loss)
I0809 08:35:08.255296 20451 sgd_solver.cpp:106] Iteration 29290, lr = 0.000358334
I0809 08:35:28.336426 20451 solver.cpp:337] Iteration 29300, Testing net (#0)
I0809 08:35:36.861465 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0809 08:35:36.861517 20451 solver.cpp:404]     Test net output #1: loss = 1.01272 (* 1 = 1.01272 loss)
I0809 08:35:39.059824 20451 solver.cpp:228] Iteration 29300, loss = 0.25009
I0809 08:35:39.060003 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:35:39.060019 20451 solver.cpp:244]     Train net output #1: loss = 0.250091 (* 1 = 0.250091 loss)
I0809 08:35:39.060032 20451 sgd_solver.cpp:106] Iteration 29300, lr = 0.000358266
I0809 08:36:01.342234 20451 solver.cpp:228] Iteration 29310, loss = 0.156273
I0809 08:36:01.342285 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:36:01.342300 20451 solver.cpp:244]     Train net output #1: loss = 0.156273 (* 1 = 0.156273 loss)
I0809 08:36:01.342313 20451 sgd_solver.cpp:106] Iteration 29310, lr = 0.000358198
I0809 08:36:23.646560 20451 solver.cpp:228] Iteration 29320, loss = 0.125052
I0809 08:36:23.646780 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:36:23.646798 20451 solver.cpp:244]     Train net output #1: loss = 0.125053 (* 1 = 0.125053 loss)
I0809 08:36:23.646812 20451 sgd_solver.cpp:106] Iteration 29320, lr = 0.000358129
I0809 08:36:45.955474 20451 solver.cpp:228] Iteration 29330, loss = 0.0937779
I0809 08:36:45.955524 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 08:36:45.955538 20451 solver.cpp:244]     Train net output #1: loss = 0.0937783 (* 1 = 0.0937783 loss)
I0809 08:36:45.955549 20451 sgd_solver.cpp:106] Iteration 29330, lr = 0.000358061
I0809 08:37:08.264230 20451 solver.cpp:228] Iteration 29340, loss = 0.281405
I0809 08:37:08.264406 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 08:37:08.264422 20451 solver.cpp:244]     Train net output #1: loss = 0.281406 (* 1 = 0.281406 loss)
I0809 08:37:08.264436 20451 sgd_solver.cpp:106] Iteration 29340, lr = 0.000357993
I0809 08:37:30.577558 20451 solver.cpp:228] Iteration 29350, loss = 0.250039
I0809 08:37:30.577610 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:37:30.577623 20451 solver.cpp:244]     Train net output #1: loss = 0.250039 (* 1 = 0.250039 loss)
I0809 08:37:30.577635 20451 sgd_solver.cpp:106] Iteration 29350, lr = 0.000357925
I0809 08:37:52.890256 20451 solver.cpp:228] Iteration 29360, loss = 0.343905
I0809 08:37:52.890424 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 08:37:52.890439 20451 solver.cpp:244]     Train net output #1: loss = 0.343905 (* 1 = 0.343905 loss)
I0809 08:37:52.890452 20451 sgd_solver.cpp:106] Iteration 29360, lr = 0.000357856
I0809 08:38:15.202785 20451 solver.cpp:228] Iteration 29370, loss = 0.219033
I0809 08:38:15.202828 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:38:15.202843 20451 solver.cpp:244]     Train net output #1: loss = 0.219033 (* 1 = 0.219033 loss)
I0809 08:38:15.202855 20451 sgd_solver.cpp:106] Iteration 29370, lr = 0.000357788
I0809 08:38:37.515910 20451 solver.cpp:228] Iteration 29380, loss = 0.187729
I0809 08:38:37.516093 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:38:37.516109 20451 solver.cpp:244]     Train net output #1: loss = 0.18773 (* 1 = 0.18773 loss)
I0809 08:38:37.516121 20451 sgd_solver.cpp:106] Iteration 29380, lr = 0.00035772
I0809 08:38:59.822993 20451 solver.cpp:228] Iteration 29390, loss = 0.250143
I0809 08:38:59.823034 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:38:59.823047 20451 solver.cpp:244]     Train net output #1: loss = 0.250144 (* 1 = 0.250144 loss)
I0809 08:38:59.823060 20451 sgd_solver.cpp:106] Iteration 29390, lr = 0.000357652
I0809 08:39:19.911422 20451 solver.cpp:337] Iteration 29400, Testing net (#0)
I0809 08:39:28.423965 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 08:39:28.424016 20451 solver.cpp:404]     Test net output #1: loss = 0.984881 (* 1 = 0.984881 loss)
I0809 08:39:30.627367 20451 solver.cpp:228] Iteration 29400, loss = 0.156369
I0809 08:39:30.627420 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:39:30.627434 20451 solver.cpp:244]     Train net output #1: loss = 0.156369 (* 1 = 0.156369 loss)
I0809 08:39:30.627446 20451 sgd_solver.cpp:106] Iteration 29400, lr = 0.000357584
I0809 08:39:52.916149 20451 solver.cpp:228] Iteration 29410, loss = 0.250093
I0809 08:39:52.916324 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:39:52.916340 20451 solver.cpp:244]     Train net output #1: loss = 0.250094 (* 1 = 0.250094 loss)
I0809 08:39:52.916352 20451 sgd_solver.cpp:106] Iteration 29410, lr = 0.000357516
I0809 08:40:15.221632 20451 solver.cpp:228] Iteration 29420, loss = 0.156431
I0809 08:40:15.221681 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:40:15.221695 20451 solver.cpp:244]     Train net output #1: loss = 0.156432 (* 1 = 0.156432 loss)
I0809 08:40:15.221707 20451 sgd_solver.cpp:106] Iteration 29420, lr = 0.000357448
I0809 08:40:37.528064 20451 solver.cpp:228] Iteration 29430, loss = 0.156408
I0809 08:40:37.528273 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:40:37.528290 20451 solver.cpp:244]     Train net output #1: loss = 0.156409 (* 1 = 0.156409 loss)
I0809 08:40:37.528302 20451 sgd_solver.cpp:106] Iteration 29430, lr = 0.00035738
I0809 08:40:59.822281 20451 solver.cpp:228] Iteration 29440, loss = 0.25002
I0809 08:40:59.822334 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:40:59.822347 20451 solver.cpp:244]     Train net output #1: loss = 0.25002 (* 1 = 0.25002 loss)
I0809 08:40:59.822360 20451 sgd_solver.cpp:106] Iteration 29440, lr = 0.000357312
I0809 08:41:22.130026 20451 solver.cpp:228] Iteration 29450, loss = 0.156257
I0809 08:41:22.130216 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:41:22.130231 20451 solver.cpp:244]     Train net output #1: loss = 0.156258 (* 1 = 0.156258 loss)
I0809 08:41:22.130244 20451 sgd_solver.cpp:106] Iteration 29450, lr = 0.000357244
I0809 08:41:44.441460 20451 solver.cpp:228] Iteration 29460, loss = 0.187587
I0809 08:41:44.441510 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 08:41:44.441524 20451 solver.cpp:244]     Train net output #1: loss = 0.187588 (* 1 = 0.187588 loss)
I0809 08:41:44.441535 20451 sgd_solver.cpp:106] Iteration 29460, lr = 0.000357176
I0809 08:42:06.747465 20451 solver.cpp:228] Iteration 29470, loss = 0.062509
I0809 08:42:06.747642 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 08:42:06.747658 20451 solver.cpp:244]     Train net output #1: loss = 0.0625094 (* 1 = 0.0625094 loss)
I0809 08:42:06.747670 20451 sgd_solver.cpp:106] Iteration 29470, lr = 0.000357108
I0809 08:42:29.046612 20451 solver.cpp:228] Iteration 29480, loss = 0.187571
I0809 08:42:29.046664 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:42:29.046679 20451 solver.cpp:244]     Train net output #1: loss = 0.187571 (* 1 = 0.187571 loss)
I0809 08:42:29.046690 20451 sgd_solver.cpp:106] Iteration 29480, lr = 0.00035704
I0809 08:42:51.346482 20451 solver.cpp:228] Iteration 29490, loss = 0.187547
I0809 08:42:51.346668 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:42:51.346683 20451 solver.cpp:244]     Train net output #1: loss = 0.187547 (* 1 = 0.187547 loss)
I0809 08:42:51.346694 20451 sgd_solver.cpp:106] Iteration 29490, lr = 0.000356972
I0809 08:43:11.433989 20451 solver.cpp:337] Iteration 29500, Testing net (#0)
I0809 08:43:19.959923 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 08:43:19.959976 20451 solver.cpp:404]     Test net output #1: loss = 1.00405 (* 1 = 1.00405 loss)
I0809 08:43:22.162190 20451 solver.cpp:228] Iteration 29500, loss = 0.250344
I0809 08:43:22.162365 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:43:22.162381 20451 solver.cpp:244]     Train net output #1: loss = 0.250345 (* 1 = 0.250345 loss)
I0809 08:43:22.162394 20451 sgd_solver.cpp:106] Iteration 29500, lr = 0.000356905
I0809 08:43:44.454696 20451 solver.cpp:228] Iteration 29510, loss = 0.218824
I0809 08:43:44.454746 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:43:44.454761 20451 solver.cpp:244]     Train net output #1: loss = 0.218825 (* 1 = 0.218825 loss)
I0809 08:43:44.454771 20451 sgd_solver.cpp:106] Iteration 29510, lr = 0.000356837
I0809 08:44:06.771795 20451 solver.cpp:228] Iteration 29520, loss = 0.187744
I0809 08:44:06.771975 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:44:06.771988 20451 solver.cpp:244]     Train net output #1: loss = 0.187744 (* 1 = 0.187744 loss)
I0809 08:44:06.772001 20451 sgd_solver.cpp:106] Iteration 29520, lr = 0.000356769
I0809 08:44:29.073407 20451 solver.cpp:228] Iteration 29530, loss = 0.218774
I0809 08:44:29.073451 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:44:29.073465 20451 solver.cpp:244]     Train net output #1: loss = 0.218774 (* 1 = 0.218774 loss)
I0809 08:44:29.073478 20451 sgd_solver.cpp:106] Iteration 29530, lr = 0.000356701
I0809 08:44:51.373052 20451 solver.cpp:228] Iteration 29540, loss = 0.218874
I0809 08:44:51.373186 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:44:51.373203 20451 solver.cpp:244]     Train net output #1: loss = 0.218874 (* 1 = 0.218874 loss)
I0809 08:44:51.373214 20451 sgd_solver.cpp:106] Iteration 29540, lr = 0.000356634
I0809 08:45:13.690755 20451 solver.cpp:228] Iteration 29550, loss = 0.343764
I0809 08:45:13.690811 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 08:45:13.690829 20451 solver.cpp:244]     Train net output #1: loss = 0.343765 (* 1 = 0.343765 loss)
I0809 08:45:13.690845 20451 sgd_solver.cpp:106] Iteration 29550, lr = 0.000356566
I0809 08:45:36.157163 20451 solver.cpp:228] Iteration 29560, loss = 0.250424
I0809 08:45:36.157245 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:45:36.157261 20451 solver.cpp:244]     Train net output #1: loss = 0.250424 (* 1 = 0.250424 loss)
I0809 08:45:36.157274 20451 sgd_solver.cpp:106] Iteration 29560, lr = 0.000356499
I0809 08:45:58.662282 20451 solver.cpp:228] Iteration 29570, loss = 0.218922
I0809 08:45:58.662334 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:45:58.662348 20451 solver.cpp:244]     Train net output #1: loss = 0.218922 (* 1 = 0.218922 loss)
I0809 08:45:58.662360 20451 sgd_solver.cpp:106] Iteration 29570, lr = 0.000356431
I0809 08:46:21.107030 20451 solver.cpp:228] Iteration 29580, loss = 0.343835
I0809 08:46:21.107203 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 08:46:21.107218 20451 solver.cpp:244]     Train net output #1: loss = 0.343835 (* 1 = 0.343835 loss)
I0809 08:46:21.107231 20451 sgd_solver.cpp:106] Iteration 29580, lr = 0.000356363
I0809 08:46:43.392436 20451 solver.cpp:228] Iteration 29590, loss = 0.218817
I0809 08:46:43.392482 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:46:43.392500 20451 solver.cpp:244]     Train net output #1: loss = 0.218818 (* 1 = 0.218818 loss)
I0809 08:46:43.392518 20451 sgd_solver.cpp:106] Iteration 29590, lr = 0.000356296
I0809 08:47:03.559690 20451 solver.cpp:337] Iteration 29600, Testing net (#0)
I0809 08:47:12.209952 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 08:47:12.210002 20451 solver.cpp:404]     Test net output #1: loss = 0.975014 (* 1 = 0.975014 loss)
I0809 08:47:14.419649 20451 solver.cpp:228] Iteration 29600, loss = 0.218756
I0809 08:47:14.419699 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:47:14.419713 20451 solver.cpp:244]     Train net output #1: loss = 0.218756 (* 1 = 0.218756 loss)
I0809 08:47:14.419725 20451 sgd_solver.cpp:106] Iteration 29600, lr = 0.000356228
I0809 08:47:36.769078 20451 solver.cpp:228] Iteration 29610, loss = 0.0937845
I0809 08:47:36.769249 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 08:47:36.769263 20451 solver.cpp:244]     Train net output #1: loss = 0.0937848 (* 1 = 0.0937848 loss)
I0809 08:47:36.769275 20451 sgd_solver.cpp:106] Iteration 29610, lr = 0.000356161
I0809 08:47:59.192826 20451 solver.cpp:228] Iteration 29620, loss = 0.250102
I0809 08:47:59.192885 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 08:47:59.192905 20451 solver.cpp:244]     Train net output #1: loss = 0.250102 (* 1 = 0.250102 loss)
I0809 08:47:59.192921 20451 sgd_solver.cpp:106] Iteration 29620, lr = 0.000356094
I0809 08:48:21.968720 20451 solver.cpp:228] Iteration 29630, loss = 0.125055
I0809 08:48:21.968906 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:48:21.968925 20451 solver.cpp:244]     Train net output #1: loss = 0.125055 (* 1 = 0.125055 loss)
I0809 08:48:21.968940 20451 sgd_solver.cpp:106] Iteration 29630, lr = 0.000356026
I0809 08:48:44.344918 20451 solver.cpp:228] Iteration 29640, loss = 0.125055
I0809 08:48:44.344974 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:48:44.344991 20451 solver.cpp:244]     Train net output #1: loss = 0.125056 (* 1 = 0.125056 loss)
I0809 08:48:44.345007 20451 sgd_solver.cpp:106] Iteration 29640, lr = 0.000355959
I0809 08:49:06.856750 20451 solver.cpp:228] Iteration 29650, loss = 0.312577
I0809 08:49:06.856976 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 08:49:06.856993 20451 solver.cpp:244]     Train net output #1: loss = 0.312577 (* 1 = 0.312577 loss)
I0809 08:49:06.857007 20451 sgd_solver.cpp:106] Iteration 29650, lr = 0.000355892
I0809 08:49:29.392694 20451 solver.cpp:228] Iteration 29660, loss = 0.125054
I0809 08:49:29.392747 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:49:29.392762 20451 solver.cpp:244]     Train net output #1: loss = 0.125054 (* 1 = 0.125054 loss)
I0809 08:49:29.392774 20451 sgd_solver.cpp:106] Iteration 29660, lr = 0.000355824
I0809 08:49:51.843641 20451 solver.cpp:228] Iteration 29670, loss = 0.0937812
I0809 08:49:51.843861 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 08:49:51.843880 20451 solver.cpp:244]     Train net output #1: loss = 0.0937816 (* 1 = 0.0937816 loss)
I0809 08:49:51.843895 20451 sgd_solver.cpp:106] Iteration 29670, lr = 0.000355757
I0809 08:50:14.300983 20451 solver.cpp:228] Iteration 29680, loss = 0.156288
I0809 08:50:14.301028 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:50:14.301045 20451 solver.cpp:244]     Train net output #1: loss = 0.156289 (* 1 = 0.156289 loss)
I0809 08:50:14.301071 20451 sgd_solver.cpp:106] Iteration 29680, lr = 0.00035569
I0809 08:50:36.711395 20451 solver.cpp:228] Iteration 29690, loss = 0.281283
I0809 08:50:36.711491 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 08:50:36.711509 20451 solver.cpp:244]     Train net output #1: loss = 0.281283 (* 1 = 0.281283 loss)
I0809 08:50:36.711524 20451 sgd_solver.cpp:106] Iteration 29690, lr = 0.000355622
I0809 08:50:56.927928 20451 solver.cpp:337] Iteration 29700, Testing net (#0)
I0809 08:51:05.450043 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0809 08:51:05.450094 20451 solver.cpp:404]     Test net output #1: loss = 1.01733 (* 1 = 1.01733 loss)
I0809 08:51:07.653384 20451 solver.cpp:228] Iteration 29700, loss = 0.218796
I0809 08:51:07.653564 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:51:07.653579 20451 solver.cpp:244]     Train net output #1: loss = 0.218796 (* 1 = 0.218796 loss)
I0809 08:51:07.653592 20451 sgd_solver.cpp:106] Iteration 29700, lr = 0.000355555
I0809 08:51:29.925912 20451 solver.cpp:228] Iteration 29710, loss = 0.218808
I0809 08:51:29.925966 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:51:29.925981 20451 solver.cpp:244]     Train net output #1: loss = 0.218808 (* 1 = 0.218808 loss)
I0809 08:51:29.925993 20451 sgd_solver.cpp:106] Iteration 29710, lr = 0.000355488
I0809 08:51:52.224079 20451 solver.cpp:228] Iteration 29720, loss = 0.125021
I0809 08:51:52.224259 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:51:52.224274 20451 solver.cpp:244]     Train net output #1: loss = 0.125022 (* 1 = 0.125022 loss)
I0809 08:51:52.224287 20451 sgd_solver.cpp:106] Iteration 29720, lr = 0.000355421
I0809 08:52:14.514885 20451 solver.cpp:228] Iteration 29730, loss = 0.125049
I0809 08:52:14.514938 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:52:14.514952 20451 solver.cpp:244]     Train net output #1: loss = 0.125049 (* 1 = 0.125049 loss)
I0809 08:52:14.514964 20451 sgd_solver.cpp:106] Iteration 29730, lr = 0.000355354
I0809 08:52:36.799574 20451 solver.cpp:228] Iteration 29740, loss = 0.187549
I0809 08:52:36.799757 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:52:36.799770 20451 solver.cpp:244]     Train net output #1: loss = 0.18755 (* 1 = 0.18755 loss)
I0809 08:52:36.799782 20451 sgd_solver.cpp:106] Iteration 29740, lr = 0.000355287
I0809 08:52:59.088742 20451 solver.cpp:228] Iteration 29750, loss = 0.125033
I0809 08:52:59.088865 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:52:59.088903 20451 solver.cpp:244]     Train net output #1: loss = 0.125033 (* 1 = 0.125033 loss)
I0809 08:52:59.088942 20451 sgd_solver.cpp:106] Iteration 29750, lr = 0.00035522
I0809 08:53:21.610172 20451 solver.cpp:228] Iteration 29760, loss = 0.0312614
I0809 08:53:21.610388 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 08:53:21.610404 20451 solver.cpp:244]     Train net output #1: loss = 0.0312618 (* 1 = 0.0312618 loss)
I0809 08:53:21.610417 20451 sgd_solver.cpp:106] Iteration 29760, lr = 0.000355153
I0809 08:53:43.893810 20451 solver.cpp:228] Iteration 29770, loss = 0.343829
I0809 08:53:43.893862 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 08:53:43.893877 20451 solver.cpp:244]     Train net output #1: loss = 0.343829 (* 1 = 0.343829 loss)
I0809 08:53:43.893889 20451 sgd_solver.cpp:106] Iteration 29770, lr = 0.000355086
I0809 08:54:06.175448 20451 solver.cpp:228] Iteration 29780, loss = 0.156268
I0809 08:54:06.175578 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:54:06.175595 20451 solver.cpp:244]     Train net output #1: loss = 0.156269 (* 1 = 0.156269 loss)
I0809 08:54:06.175607 20451 sgd_solver.cpp:106] Iteration 29780, lr = 0.000355019
I0809 08:54:28.487439 20451 solver.cpp:228] Iteration 29790, loss = 0.125101
I0809 08:54:28.487491 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:54:28.487504 20451 solver.cpp:244]     Train net output #1: loss = 0.125101 (* 1 = 0.125101 loss)
I0809 08:54:28.487516 20451 sgd_solver.cpp:106] Iteration 29790, lr = 0.000354952
I0809 08:54:48.549981 20451 solver.cpp:337] Iteration 29800, Testing net (#0)
I0809 08:54:57.056387 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 08:54:57.056438 20451 solver.cpp:404]     Test net output #1: loss = 1.00314 (* 1 = 1.00314 loss)
I0809 08:54:59.255609 20451 solver.cpp:228] Iteration 29800, loss = 0.28129
I0809 08:54:59.255656 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 08:54:59.255676 20451 solver.cpp:244]     Train net output #1: loss = 0.28129 (* 1 = 0.28129 loss)
I0809 08:54:59.255702 20451 sgd_solver.cpp:106] Iteration 29800, lr = 0.000354885
I0809 08:55:21.538059 20451 solver.cpp:228] Iteration 29810, loss = 0.21883
I0809 08:55:21.538235 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:55:21.538254 20451 solver.cpp:244]     Train net output #1: loss = 0.21883 (* 1 = 0.21883 loss)
I0809 08:55:21.538269 20451 sgd_solver.cpp:106] Iteration 29810, lr = 0.000354818
I0809 08:55:43.830050 20451 solver.cpp:228] Iteration 29820, loss = 0.250128
I0809 08:55:43.830101 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:55:43.830121 20451 solver.cpp:244]     Train net output #1: loss = 0.250128 (* 1 = 0.250128 loss)
I0809 08:55:43.830135 20451 sgd_solver.cpp:106] Iteration 29820, lr = 0.000354751
I0809 08:56:06.113364 20451 solver.cpp:228] Iteration 29830, loss = 0.218769
I0809 08:56:06.113538 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 08:56:06.113554 20451 solver.cpp:244]     Train net output #1: loss = 0.218769 (* 1 = 0.218769 loss)
I0809 08:56:06.113565 20451 sgd_solver.cpp:106] Iteration 29830, lr = 0.000354685
I0809 08:56:28.394608 20451 solver.cpp:228] Iteration 29840, loss = 0.187533
I0809 08:56:28.394660 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:56:28.394673 20451 solver.cpp:244]     Train net output #1: loss = 0.187534 (* 1 = 0.187534 loss)
I0809 08:56:28.394686 20451 sgd_solver.cpp:106] Iteration 29840, lr = 0.000354618
I0809 08:56:50.686838 20451 solver.cpp:228] Iteration 29850, loss = 0.125111
I0809 08:56:50.687022 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:56:50.687037 20451 solver.cpp:244]     Train net output #1: loss = 0.125111 (* 1 = 0.125111 loss)
I0809 08:56:50.687050 20451 sgd_solver.cpp:106] Iteration 29850, lr = 0.000354551
I0809 08:57:13.062172 20451 solver.cpp:228] Iteration 29860, loss = 0.156293
I0809 08:57:13.062216 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:57:13.062234 20451 solver.cpp:244]     Train net output #1: loss = 0.156293 (* 1 = 0.156293 loss)
I0809 08:57:13.062252 20451 sgd_solver.cpp:106] Iteration 29860, lr = 0.000354484
I0809 08:57:35.531641 20451 solver.cpp:228] Iteration 29870, loss = 0.187502
I0809 08:57:35.531852 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 08:57:35.531868 20451 solver.cpp:244]     Train net output #1: loss = 0.187503 (* 1 = 0.187503 loss)
I0809 08:57:35.531882 20451 sgd_solver.cpp:106] Iteration 29870, lr = 0.000354418
I0809 08:57:57.846958 20451 solver.cpp:228] Iteration 29880, loss = 0.156459
I0809 08:57:57.847010 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 08:57:57.847025 20451 solver.cpp:244]     Train net output #1: loss = 0.15646 (* 1 = 0.15646 loss)
I0809 08:57:57.847038 20451 sgd_solver.cpp:106] Iteration 29880, lr = 0.000354351
I0809 08:58:20.138775 20451 solver.cpp:228] Iteration 29890, loss = 0.125007
I0809 08:58:20.138974 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:58:20.138993 20451 solver.cpp:244]     Train net output #1: loss = 0.125007 (* 1 = 0.125007 loss)
I0809 08:58:20.139009 20451 sgd_solver.cpp:106] Iteration 29890, lr = 0.000354284
I0809 08:58:40.206215 20451 solver.cpp:337] Iteration 29900, Testing net (#0)
I0809 08:58:48.798719 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 08:58:48.798774 20451 solver.cpp:404]     Test net output #1: loss = 0.975085 (* 1 = 0.975085 loss)
I0809 08:58:51.036422 20451 solver.cpp:228] Iteration 29900, loss = 0.281428
I0809 08:58:51.036514 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 08:58:51.036533 20451 solver.cpp:244]     Train net output #1: loss = 0.281428 (* 1 = 0.281428 loss)
I0809 08:58:51.036548 20451 sgd_solver.cpp:106] Iteration 29900, lr = 0.000354218
I0809 08:59:13.780683 20451 solver.cpp:228] Iteration 29910, loss = 0.12505
I0809 08:59:13.780727 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 08:59:13.780745 20451 solver.cpp:244]     Train net output #1: loss = 0.12505 (* 1 = 0.12505 loss)
I0809 08:59:13.780761 20451 sgd_solver.cpp:106] Iteration 29910, lr = 0.000354151
I0809 08:59:36.105151 20451 solver.cpp:228] Iteration 29920, loss = 0.0937721
I0809 08:59:36.105335 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 08:59:36.105355 20451 solver.cpp:244]     Train net output #1: loss = 0.0937725 (* 1 = 0.0937725 loss)
I0809 08:59:36.105370 20451 sgd_solver.cpp:106] Iteration 29920, lr = 0.000354085
I0809 08:59:58.513581 20451 solver.cpp:228] Iteration 29930, loss = 0.312572
I0809 08:59:58.513623 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 08:59:58.513640 20451 solver.cpp:244]     Train net output #1: loss = 0.312572 (* 1 = 0.312572 loss)
I0809 08:59:58.513655 20451 sgd_solver.cpp:106] Iteration 29930, lr = 0.000354018
I0809 09:00:20.975414 20451 solver.cpp:228] Iteration 29940, loss = 0.343829
I0809 09:00:20.975586 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 09:00:20.975602 20451 solver.cpp:244]     Train net output #1: loss = 0.343829 (* 1 = 0.343829 loss)
I0809 09:00:20.975615 20451 sgd_solver.cpp:106] Iteration 29940, lr = 0.000353952
I0809 09:00:43.428669 20451 solver.cpp:228] Iteration 29950, loss = 0.18756
I0809 09:00:43.428712 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:00:43.428730 20451 solver.cpp:244]     Train net output #1: loss = 0.18756 (* 1 = 0.18756 loss)
I0809 09:00:43.428745 20451 sgd_solver.cpp:106] Iteration 29950, lr = 0.000353885
I0809 09:01:06.010934 20451 solver.cpp:228] Iteration 29960, loss = 0.187529
I0809 09:01:06.011132 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:01:06.011147 20451 solver.cpp:244]     Train net output #1: loss = 0.187529 (* 1 = 0.187529 loss)
I0809 09:01:06.011159 20451 sgd_solver.cpp:106] Iteration 29960, lr = 0.000353819
I0809 09:01:28.534188 20451 solver.cpp:228] Iteration 29970, loss = 0.156292
I0809 09:01:28.534237 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:01:28.534252 20451 solver.cpp:244]     Train net output #1: loss = 0.156293 (* 1 = 0.156293 loss)
I0809 09:01:28.534263 20451 sgd_solver.cpp:106] Iteration 29970, lr = 0.000353752
I0809 09:01:51.064968 20451 solver.cpp:228] Iteration 29980, loss = 0.156278
I0809 09:01:51.065135 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:01:51.065155 20451 solver.cpp:244]     Train net output #1: loss = 0.156279 (* 1 = 0.156279 loss)
I0809 09:01:51.065171 20451 sgd_solver.cpp:106] Iteration 29980, lr = 0.000353686
I0809 09:02:13.468989 20451 solver.cpp:228] Iteration 29990, loss = 0.21886
I0809 09:02:13.469038 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:02:13.469053 20451 solver.cpp:244]     Train net output #1: loss = 0.21886 (* 1 = 0.21886 loss)
I0809 09:02:13.469063 20451 sgd_solver.cpp:106] Iteration 29990, lr = 0.00035362
I0809 09:02:33.662329 20451 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_30000.caffemodel
I0809 09:02:33.890636 20451 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_30000.solverstate
I0809 09:02:33.893255 20451 solver.cpp:337] Iteration 30000, Testing net (#0)
I0809 09:02:42.398020 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 09:02:42.398071 20451 solver.cpp:404]     Test net output #1: loss = 0.993918 (* 1 = 0.993918 loss)
I0809 09:02:44.602339 20451 solver.cpp:228] Iteration 30000, loss = 0.187547
I0809 09:02:44.602391 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:02:44.602406 20451 solver.cpp:244]     Train net output #1: loss = 0.187548 (* 1 = 0.187548 loss)
I0809 09:02:44.602417 20451 sgd_solver.cpp:106] Iteration 30000, lr = 0.000353553
I0809 09:03:06.934659 20451 solver.cpp:228] Iteration 30010, loss = 0.187519
I0809 09:03:06.934835 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:03:06.934850 20451 solver.cpp:244]     Train net output #1: loss = 0.187519 (* 1 = 0.187519 loss)
I0809 09:03:06.934862 20451 sgd_solver.cpp:106] Iteration 30010, lr = 0.000353487
I0809 09:03:29.286119 20451 solver.cpp:228] Iteration 30020, loss = 0.343953
I0809 09:03:29.286170 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 09:03:29.286185 20451 solver.cpp:244]     Train net output #1: loss = 0.343953 (* 1 = 0.343953 loss)
I0809 09:03:29.286197 20451 sgd_solver.cpp:106] Iteration 30020, lr = 0.000353421
I0809 09:03:51.693562 20451 solver.cpp:228] Iteration 30030, loss = 0.250056
I0809 09:03:51.693742 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 09:03:51.693760 20451 solver.cpp:244]     Train net output #1: loss = 0.250056 (* 1 = 0.250056 loss)
I0809 09:03:51.693775 20451 sgd_solver.cpp:106] Iteration 30030, lr = 0.000353355
I0809 09:04:14.236188 20451 solver.cpp:228] Iteration 30040, loss = 0.218857
I0809 09:04:14.236238 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:04:14.236253 20451 solver.cpp:244]     Train net output #1: loss = 0.218857 (* 1 = 0.218857 loss)
I0809 09:04:14.236264 20451 sgd_solver.cpp:106] Iteration 30040, lr = 0.000353288
I0809 09:04:36.613123 20451 solver.cpp:228] Iteration 30050, loss = 0.187668
I0809 09:04:36.613294 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:04:36.613311 20451 solver.cpp:244]     Train net output #1: loss = 0.187668 (* 1 = 0.187668 loss)
I0809 09:04:36.613322 20451 sgd_solver.cpp:106] Iteration 30050, lr = 0.000353222
I0809 09:04:59.073328 20451 solver.cpp:228] Iteration 30060, loss = 0.344047
I0809 09:04:59.073460 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 09:04:59.073503 20451 solver.cpp:244]     Train net output #1: loss = 0.344047 (* 1 = 0.344047 loss)
I0809 09:04:59.073541 20451 sgd_solver.cpp:106] Iteration 30060, lr = 0.000353156
I0809 09:05:21.609637 20451 solver.cpp:228] Iteration 30070, loss = 0.218992
I0809 09:05:21.609786 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:05:21.609802 20451 solver.cpp:244]     Train net output #1: loss = 0.218993 (* 1 = 0.218993 loss)
I0809 09:05:21.609814 20451 sgd_solver.cpp:106] Iteration 30070, lr = 0.00035309
I0809 09:05:43.978693 20451 solver.cpp:228] Iteration 30080, loss = 0.156369
I0809 09:05:43.978736 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:05:43.978755 20451 solver.cpp:244]     Train net output #1: loss = 0.15637 (* 1 = 0.15637 loss)
I0809 09:05:43.978770 20451 sgd_solver.cpp:106] Iteration 30080, lr = 0.000353024
I0809 09:06:06.550096 20451 solver.cpp:228] Iteration 30090, loss = 0.312785
I0809 09:06:06.550287 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 09:06:06.550305 20451 solver.cpp:244]     Train net output #1: loss = 0.312786 (* 1 = 0.312786 loss)
I0809 09:06:06.550320 20451 sgd_solver.cpp:106] Iteration 30090, lr = 0.000352958
I0809 09:06:26.896051 20451 solver.cpp:337] Iteration 30100, Testing net (#0)
I0809 09:06:35.418139 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 09:06:35.418184 20451 solver.cpp:404]     Test net output #1: loss = 1.00315 (* 1 = 1.00315 loss)
I0809 09:06:37.654737 20451 solver.cpp:228] Iteration 30100, loss = 0.0937534
I0809 09:06:37.654832 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 09:06:37.654847 20451 solver.cpp:244]     Train net output #1: loss = 0.0937537 (* 1 = 0.0937537 loss)
I0809 09:06:37.654860 20451 sgd_solver.cpp:106] Iteration 30100, lr = 0.000352892
I0809 09:07:00.155333 20451 solver.cpp:228] Iteration 30110, loss = 0.187718
I0809 09:07:00.155377 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:07:00.155397 20451 solver.cpp:244]     Train net output #1: loss = 0.187718 (* 1 = 0.187718 loss)
I0809 09:07:00.155411 20451 sgd_solver.cpp:106] Iteration 30110, lr = 0.000352826
I0809 09:07:22.667839 20451 solver.cpp:228] Iteration 30120, loss = 0.125192
I0809 09:07:22.668010 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:07:22.668028 20451 solver.cpp:244]     Train net output #1: loss = 0.125192 (* 1 = 0.125192 loss)
I0809 09:07:22.668043 20451 sgd_solver.cpp:106] Iteration 30120, lr = 0.00035276
I0809 09:07:45.182232 20451 solver.cpp:228] Iteration 30130, loss = 0.0625319
I0809 09:07:45.182283 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 09:07:45.182297 20451 solver.cpp:244]     Train net output #1: loss = 0.0625323 (* 1 = 0.0625323 loss)
I0809 09:07:45.182309 20451 sgd_solver.cpp:106] Iteration 30130, lr = 0.000352694
I0809 09:08:07.602771 20451 solver.cpp:228] Iteration 30140, loss = 0.187517
I0809 09:08:07.602955 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:08:07.602972 20451 solver.cpp:244]     Train net output #1: loss = 0.187517 (* 1 = 0.187517 loss)
I0809 09:08:07.602984 20451 sgd_solver.cpp:106] Iteration 30140, lr = 0.000352628
I0809 09:08:29.994653 20451 solver.cpp:228] Iteration 30150, loss = 0.187528
I0809 09:08:29.994696 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:08:29.994711 20451 solver.cpp:244]     Train net output #1: loss = 0.187529 (* 1 = 0.187529 loss)
I0809 09:08:29.994724 20451 sgd_solver.cpp:106] Iteration 30150, lr = 0.000352562
I0809 09:08:52.459578 20451 solver.cpp:228] Iteration 30160, loss = 0.312547
I0809 09:08:52.459759 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 09:08:52.459779 20451 solver.cpp:244]     Train net output #1: loss = 0.312547 (* 1 = 0.312547 loss)
I0809 09:08:52.459794 20451 sgd_solver.cpp:106] Iteration 30160, lr = 0.000352496
I0809 09:09:14.773756 20451 solver.cpp:228] Iteration 30170, loss = 0.281252
I0809 09:09:14.773798 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 09:09:14.773818 20451 solver.cpp:244]     Train net output #1: loss = 0.281252 (* 1 = 0.281252 loss)
I0809 09:09:14.773843 20451 sgd_solver.cpp:106] Iteration 30170, lr = 0.000352431
I0809 09:09:37.058744 20451 solver.cpp:228] Iteration 30180, loss = 0.219026
I0809 09:09:37.058967 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:09:37.058989 20451 solver.cpp:244]     Train net output #1: loss = 0.219026 (* 1 = 0.219026 loss)
I0809 09:09:37.059003 20451 sgd_solver.cpp:106] Iteration 30180, lr = 0.000352365
I0809 09:09:59.345293 20451 solver.cpp:228] Iteration 30190, loss = 0.281522
I0809 09:09:59.345336 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:09:59.345356 20451 solver.cpp:244]     Train net output #1: loss = 0.281522 (* 1 = 0.281522 loss)
I0809 09:09:59.345381 20451 sgd_solver.cpp:106] Iteration 30190, lr = 0.000352299
I0809 09:10:19.399572 20451 solver.cpp:337] Iteration 30200, Testing net (#0)
I0809 09:10:27.933746 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0809 09:10:27.933789 20451 solver.cpp:404]     Test net output #1: loss = 0.966399 (* 1 = 0.966399 loss)
I0809 09:10:30.137974 20451 solver.cpp:228] Iteration 30200, loss = 0.219012
I0809 09:10:30.138016 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:10:30.138034 20451 solver.cpp:244]     Train net output #1: loss = 0.219012 (* 1 = 0.219012 loss)
I0809 09:10:30.138059 20451 sgd_solver.cpp:106] Iteration 30200, lr = 0.000352233
I0809 09:10:52.584929 20451 solver.cpp:228] Iteration 30210, loss = 0.125021
I0809 09:10:52.585108 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:10:52.585122 20451 solver.cpp:244]     Train net output #1: loss = 0.125022 (* 1 = 0.125022 loss)
I0809 09:10:52.585136 20451 sgd_solver.cpp:106] Iteration 30210, lr = 0.000352168
I0809 09:11:14.865185 20451 solver.cpp:228] Iteration 30220, loss = 0.0625237
I0809 09:11:14.865239 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 09:11:14.865253 20451 solver.cpp:244]     Train net output #1: loss = 0.062524 (* 1 = 0.062524 loss)
I0809 09:11:14.865265 20451 sgd_solver.cpp:106] Iteration 30220, lr = 0.000352102
I0809 09:11:37.158027 20451 solver.cpp:228] Iteration 30230, loss = 0.156389
I0809 09:11:37.158195 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:11:37.158210 20451 solver.cpp:244]     Train net output #1: loss = 0.156389 (* 1 = 0.156389 loss)
I0809 09:11:37.158222 20451 sgd_solver.cpp:106] Iteration 30230, lr = 0.000352036
I0809 09:11:59.436012 20451 solver.cpp:228] Iteration 30240, loss = 0.0937606
I0809 09:11:59.436059 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 09:11:59.436079 20451 solver.cpp:244]     Train net output #1: loss = 0.0937609 (* 1 = 0.0937609 loss)
I0809 09:11:59.436095 20451 sgd_solver.cpp:106] Iteration 30240, lr = 0.000351971
I0809 09:12:21.714484 20451 solver.cpp:228] Iteration 30250, loss = 0.218801
I0809 09:12:21.714673 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:12:21.714691 20451 solver.cpp:244]     Train net output #1: loss = 0.218802 (* 1 = 0.218802 loss)
I0809 09:12:21.714704 20451 sgd_solver.cpp:106] Iteration 30250, lr = 0.000351905
I0809 09:12:43.996116 20451 solver.cpp:228] Iteration 30260, loss = 0.250084
I0809 09:12:43.996170 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 09:12:43.996183 20451 solver.cpp:244]     Train net output #1: loss = 0.250084 (* 1 = 0.250084 loss)
I0809 09:12:43.996196 20451 sgd_solver.cpp:106] Iteration 30260, lr = 0.00035184
I0809 09:13:06.287075 20451 solver.cpp:228] Iteration 30270, loss = 0.187527
I0809 09:13:06.287178 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:13:06.287194 20451 solver.cpp:244]     Train net output #1: loss = 0.187527 (* 1 = 0.187527 loss)
I0809 09:13:06.287206 20451 sgd_solver.cpp:106] Iteration 30270, lr = 0.000351774
I0809 09:13:28.731061 20451 solver.cpp:228] Iteration 30280, loss = 0.375069
I0809 09:13:28.731107 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0809 09:13:28.731127 20451 solver.cpp:244]     Train net output #1: loss = 0.37507 (* 1 = 0.37507 loss)
I0809 09:13:28.731142 20451 sgd_solver.cpp:106] Iteration 30280, lr = 0.000351709
I0809 09:13:51.698349 20451 solver.cpp:228] Iteration 30290, loss = 0.0937682
I0809 09:13:51.698485 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 09:13:51.698506 20451 solver.cpp:244]     Train net output #1: loss = 0.0937685 (* 1 = 0.0937685 loss)
I0809 09:13:51.698520 20451 sgd_solver.cpp:106] Iteration 30290, lr = 0.000351643
I0809 09:14:11.940621 20451 solver.cpp:337] Iteration 30300, Testing net (#0)
I0809 09:14:20.451571 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0809 09:14:20.451611 20451 solver.cpp:404]     Test net output #1: loss = 1.03146 (* 1 = 1.03146 loss)
I0809 09:14:22.649129 20451 solver.cpp:228] Iteration 30300, loss = 0.218817
I0809 09:14:22.649315 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:14:22.649332 20451 solver.cpp:244]     Train net output #1: loss = 0.218817 (* 1 = 0.218817 loss)
I0809 09:14:22.649344 20451 sgd_solver.cpp:106] Iteration 30300, lr = 0.000351578
I0809 09:14:44.916700 20451 solver.cpp:228] Iteration 30310, loss = 0.187504
I0809 09:14:44.916754 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:14:44.916767 20451 solver.cpp:244]     Train net output #1: loss = 0.187505 (* 1 = 0.187505 loss)
I0809 09:14:44.916780 20451 sgd_solver.cpp:106] Iteration 30310, lr = 0.000351512
I0809 09:15:07.194705 20451 solver.cpp:228] Iteration 30320, loss = 0.218823
I0809 09:15:07.194890 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:15:07.194905 20451 solver.cpp:244]     Train net output #1: loss = 0.218823 (* 1 = 0.218823 loss)
I0809 09:15:07.194917 20451 sgd_solver.cpp:106] Iteration 30320, lr = 0.000351447
I0809 09:15:29.485481 20451 solver.cpp:228] Iteration 30330, loss = 0.12501
I0809 09:15:29.485532 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:15:29.485545 20451 solver.cpp:244]     Train net output #1: loss = 0.125011 (* 1 = 0.125011 loss)
I0809 09:15:29.485558 20451 sgd_solver.cpp:106] Iteration 30330, lr = 0.000351381
I0809 09:15:52.286586 20451 solver.cpp:228] Iteration 30340, loss = 0.125026
I0809 09:15:52.286689 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:15:52.286705 20451 solver.cpp:244]     Train net output #1: loss = 0.125026 (* 1 = 0.125026 loss)
I0809 09:15:52.286717 20451 sgd_solver.cpp:106] Iteration 30340, lr = 0.000351316
I0809 09:16:14.934204 20451 solver.cpp:228] Iteration 30350, loss = 0.156299
I0809 09:16:14.934257 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:16:14.934269 20451 solver.cpp:244]     Train net output #1: loss = 0.156299 (* 1 = 0.156299 loss)
I0809 09:16:14.934281 20451 sgd_solver.cpp:106] Iteration 30350, lr = 0.000351251
I0809 09:16:37.219005 20451 solver.cpp:228] Iteration 30360, loss = 0.12508
I0809 09:16:37.219185 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:16:37.219200 20451 solver.cpp:244]     Train net output #1: loss = 0.12508 (* 1 = 0.12508 loss)
I0809 09:16:37.219213 20451 sgd_solver.cpp:106] Iteration 30360, lr = 0.000351186
I0809 09:16:59.699566 20451 solver.cpp:228] Iteration 30370, loss = 0.093778
I0809 09:16:59.699617 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 09:16:59.699633 20451 solver.cpp:244]     Train net output #1: loss = 0.0937783 (* 1 = 0.0937783 loss)
I0809 09:16:59.699645 20451 sgd_solver.cpp:106] Iteration 30370, lr = 0.00035112
I0809 09:17:22.026672 20451 solver.cpp:228] Iteration 30380, loss = 0.125003
I0809 09:17:22.026861 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:17:22.026877 20451 solver.cpp:244]     Train net output #1: loss = 0.125004 (* 1 = 0.125004 loss)
I0809 09:17:22.026890 20451 sgd_solver.cpp:106] Iteration 30380, lr = 0.000351055
I0809 09:17:44.449285 20451 solver.cpp:228] Iteration 30390, loss = 0.250049
I0809 09:17:44.449328 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 09:17:44.449347 20451 solver.cpp:244]     Train net output #1: loss = 0.25005 (* 1 = 0.25005 loss)
I0809 09:17:44.449362 20451 sgd_solver.cpp:106] Iteration 30390, lr = 0.00035099
I0809 09:18:04.784167 20451 solver.cpp:337] Iteration 30400, Testing net (#0)
I0809 09:18:13.341677 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 09:18:13.341730 20451 solver.cpp:404]     Test net output #1: loss = 1.00314 (* 1 = 1.00314 loss)
I0809 09:18:15.543607 20451 solver.cpp:228] Iteration 30400, loss = 0.062502
I0809 09:18:15.543658 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 09:18:15.543671 20451 solver.cpp:244]     Train net output #1: loss = 0.0625023 (* 1 = 0.0625023 loss)
I0809 09:18:15.543684 20451 sgd_solver.cpp:106] Iteration 30400, lr = 0.000350925
I0809 09:18:37.921205 20451 solver.cpp:228] Iteration 30410, loss = 0.156489
I0809 09:18:37.921304 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:18:37.921320 20451 solver.cpp:244]     Train net output #1: loss = 0.15649 (* 1 = 0.15649 loss)
I0809 09:18:37.921332 20451 sgd_solver.cpp:106] Iteration 30410, lr = 0.00035086
I0809 09:19:00.274142 20451 solver.cpp:228] Iteration 30420, loss = 0.125085
I0809 09:19:00.274195 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:19:00.274212 20451 solver.cpp:244]     Train net output #1: loss = 0.125085 (* 1 = 0.125085 loss)
I0809 09:19:00.274227 20451 sgd_solver.cpp:106] Iteration 30420, lr = 0.000350795
I0809 09:19:22.589012 20451 solver.cpp:228] Iteration 30430, loss = 0.125131
I0809 09:19:22.589203 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:19:22.589222 20451 solver.cpp:244]     Train net output #1: loss = 0.125131 (* 1 = 0.125131 loss)
I0809 09:19:22.589238 20451 sgd_solver.cpp:106] Iteration 30430, lr = 0.000350729
I0809 09:19:45.026762 20451 solver.cpp:228] Iteration 30440, loss = 0.187648
I0809 09:19:45.026813 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:19:45.026828 20451 solver.cpp:244]     Train net output #1: loss = 0.187648 (* 1 = 0.187648 loss)
I0809 09:19:45.026839 20451 sgd_solver.cpp:106] Iteration 30440, lr = 0.000350664
I0809 09:20:07.317343 20451 solver.cpp:228] Iteration 30450, loss = 0.312882
I0809 09:20:07.317528 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 09:20:07.317543 20451 solver.cpp:244]     Train net output #1: loss = 0.312882 (* 1 = 0.312882 loss)
I0809 09:20:07.317556 20451 sgd_solver.cpp:106] Iteration 30450, lr = 0.000350599
I0809 09:20:29.654309 20451 solver.cpp:228] Iteration 30460, loss = 0.187569
I0809 09:20:29.654359 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:20:29.654373 20451 solver.cpp:244]     Train net output #1: loss = 0.187569 (* 1 = 0.187569 loss)
I0809 09:20:29.654386 20451 sgd_solver.cpp:106] Iteration 30460, lr = 0.000350534
I0809 09:20:52.104423 20451 solver.cpp:228] Iteration 30470, loss = 0.281621
I0809 09:20:52.104598 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 09:20:52.104612 20451 solver.cpp:244]     Train net output #1: loss = 0.281622 (* 1 = 0.281622 loss)
I0809 09:20:52.104625 20451 sgd_solver.cpp:106] Iteration 30470, lr = 0.000350469
I0809 09:21:14.465234 20451 solver.cpp:228] Iteration 30480, loss = 0.0937643
I0809 09:21:14.465276 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 09:21:14.465292 20451 solver.cpp:244]     Train net output #1: loss = 0.0937646 (* 1 = 0.0937646 loss)
I0809 09:21:14.465304 20451 sgd_solver.cpp:106] Iteration 30480, lr = 0.000350404
I0809 09:21:36.756603 20451 solver.cpp:228] Iteration 30490, loss = 0.156313
I0809 09:21:36.756788 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:21:36.756804 20451 solver.cpp:244]     Train net output #1: loss = 0.156313 (* 1 = 0.156313 loss)
I0809 09:21:36.756816 20451 sgd_solver.cpp:106] Iteration 30490, lr = 0.00035034
I0809 09:21:56.864845 20451 solver.cpp:337] Iteration 30500, Testing net (#0)
I0809 09:22:05.403378 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 09:22:05.403427 20451 solver.cpp:404]     Test net output #1: loss = 0.98454 (* 1 = 0.98454 loss)
I0809 09:22:07.598989 20451 solver.cpp:228] Iteration 30500, loss = 0.156288
I0809 09:22:07.599200 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:22:07.599215 20451 solver.cpp:244]     Train net output #1: loss = 0.156288 (* 1 = 0.156288 loss)
I0809 09:22:07.599228 20451 sgd_solver.cpp:106] Iteration 30500, lr = 0.000350275
I0809 09:22:30.012300 20451 solver.cpp:228] Iteration 30510, loss = 0.187535
I0809 09:22:30.012341 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:22:30.012356 20451 solver.cpp:244]     Train net output #1: loss = 0.187535 (* 1 = 0.187535 loss)
I0809 09:22:30.012368 20451 sgd_solver.cpp:106] Iteration 30510, lr = 0.00035021
I0809 09:22:52.460101 20451 solver.cpp:228] Iteration 30520, loss = 0.156329
I0809 09:22:52.460281 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:22:52.460296 20451 solver.cpp:244]     Train net output #1: loss = 0.156329 (* 1 = 0.156329 loss)
I0809 09:22:52.460309 20451 sgd_solver.cpp:106] Iteration 30520, lr = 0.000350145
I0809 09:23:14.767593 20451 solver.cpp:228] Iteration 30530, loss = 0.0625186
I0809 09:23:14.767645 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 09:23:14.767662 20451 solver.cpp:244]     Train net output #1: loss = 0.0625189 (* 1 = 0.0625189 loss)
I0809 09:23:14.767673 20451 sgd_solver.cpp:106] Iteration 30530, lr = 0.00035008
I0809 09:23:37.254503 20451 solver.cpp:228] Iteration 30540, loss = 0.28131
I0809 09:23:37.254603 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 09:23:37.254618 20451 solver.cpp:244]     Train net output #1: loss = 0.28131 (* 1 = 0.28131 loss)
I0809 09:23:37.254631 20451 sgd_solver.cpp:106] Iteration 30540, lr = 0.000350015
I0809 09:23:59.664348 20451 solver.cpp:228] Iteration 30550, loss = 0.218802
I0809 09:23:59.664398 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:23:59.664412 20451 solver.cpp:244]     Train net output #1: loss = 0.218802 (* 1 = 0.218802 loss)
I0809 09:23:59.664424 20451 sgd_solver.cpp:106] Iteration 30550, lr = 0.000349951
I0809 09:24:21.965366 20451 solver.cpp:228] Iteration 30560, loss = 0.343889
I0809 09:24:21.965533 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 09:24:21.965548 20451 solver.cpp:244]     Train net output #1: loss = 0.343889 (* 1 = 0.343889 loss)
I0809 09:24:21.965560 20451 sgd_solver.cpp:106] Iteration 30560, lr = 0.000349886
I0809 09:24:44.265419 20451 solver.cpp:228] Iteration 30570, loss = 0.343909
I0809 09:24:44.265460 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 09:24:44.265475 20451 solver.cpp:244]     Train net output #1: loss = 0.343909 (* 1 = 0.343909 loss)
I0809 09:24:44.265486 20451 sgd_solver.cpp:106] Iteration 30570, lr = 0.000349821
I0809 09:25:06.563117 20451 solver.cpp:228] Iteration 30580, loss = 0.312758
I0809 09:25:06.563295 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 09:25:06.563313 20451 solver.cpp:244]     Train net output #1: loss = 0.312758 (* 1 = 0.312758 loss)
I0809 09:25:06.563328 20451 sgd_solver.cpp:106] Iteration 30580, lr = 0.000349757
I0809 09:25:28.859282 20451 solver.cpp:228] Iteration 30590, loss = 0.281496
I0809 09:25:28.859336 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 09:25:28.859350 20451 solver.cpp:244]     Train net output #1: loss = 0.281496 (* 1 = 0.281496 loss)
I0809 09:25:28.859362 20451 sgd_solver.cpp:106] Iteration 30590, lr = 0.000349692
I0809 09:25:48.927153 20451 solver.cpp:337] Iteration 30600, Testing net (#0)
I0809 09:25:57.436836 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 09:25:57.436887 20451 solver.cpp:404]     Test net output #1: loss = 0.998987 (* 1 = 0.998987 loss)
I0809 09:25:59.636029 20451 solver.cpp:228] Iteration 30600, loss = 0.156378
I0809 09:25:59.636080 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:25:59.636093 20451 solver.cpp:244]     Train net output #1: loss = 0.156379 (* 1 = 0.156379 loss)
I0809 09:25:59.636106 20451 sgd_solver.cpp:106] Iteration 30600, lr = 0.000349627
I0809 09:26:21.914012 20451 solver.cpp:228] Iteration 30610, loss = 0.125124
I0809 09:26:21.914150 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:26:21.914165 20451 solver.cpp:244]     Train net output #1: loss = 0.125125 (* 1 = 0.125125 loss)
I0809 09:26:21.914177 20451 sgd_solver.cpp:106] Iteration 30610, lr = 0.000349563
I0809 09:26:44.205358 20451 solver.cpp:228] Iteration 30620, loss = 0.125107
I0809 09:26:44.205410 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:26:44.205425 20451 solver.cpp:244]     Train net output #1: loss = 0.125107 (* 1 = 0.125107 loss)
I0809 09:26:44.205436 20451 sgd_solver.cpp:106] Iteration 30620, lr = 0.000349498
I0809 09:27:06.501482 20451 solver.cpp:228] Iteration 30630, loss = 0.156434
I0809 09:27:06.501579 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:27:06.501595 20451 solver.cpp:244]     Train net output #1: loss = 0.156434 (* 1 = 0.156434 loss)
I0809 09:27:06.501607 20451 sgd_solver.cpp:106] Iteration 30630, lr = 0.000349434
I0809 09:27:28.791141 20451 solver.cpp:228] Iteration 30640, loss = 0.156287
I0809 09:27:28.791189 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:27:28.791204 20451 solver.cpp:244]     Train net output #1: loss = 0.156287 (* 1 = 0.156287 loss)
I0809 09:27:28.791218 20451 sgd_solver.cpp:106] Iteration 30640, lr = 0.000349369
I0809 09:27:51.083561 20451 solver.cpp:228] Iteration 30650, loss = 0.0938639
I0809 09:27:51.083734 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 09:27:51.083750 20451 solver.cpp:244]     Train net output #1: loss = 0.0938642 (* 1 = 0.0938642 loss)
I0809 09:27:51.083763 20451 sgd_solver.cpp:106] Iteration 30650, lr = 0.000349305
I0809 09:28:13.374366 20451 solver.cpp:228] Iteration 30660, loss = 0.0937545
I0809 09:28:13.374413 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:28:13.374428 20451 solver.cpp:244]     Train net output #1: loss = 0.0937548 (* 1 = 0.0937548 loss)
I0809 09:28:13.374439 20451 sgd_solver.cpp:106] Iteration 30660, lr = 0.00034924
I0809 09:28:35.679054 20451 solver.cpp:228] Iteration 30670, loss = 0.125183
I0809 09:28:35.679152 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:28:35.679167 20451 solver.cpp:244]     Train net output #1: loss = 0.125183 (* 1 = 0.125183 loss)
I0809 09:28:35.679180 20451 sgd_solver.cpp:106] Iteration 30670, lr = 0.000349176
I0809 09:28:57.967823 20451 solver.cpp:228] Iteration 30680, loss = 0.250355
I0809 09:28:57.967876 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:28:57.967890 20451 solver.cpp:244]     Train net output #1: loss = 0.250356 (* 1 = 0.250356 loss)
I0809 09:28:57.967902 20451 sgd_solver.cpp:106] Iteration 30680, lr = 0.000349112
I0809 09:29:20.264120 20451 solver.cpp:228] Iteration 30690, loss = 0.21896
I0809 09:29:20.264292 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:29:20.264308 20451 solver.cpp:244]     Train net output #1: loss = 0.21896 (* 1 = 0.21896 loss)
I0809 09:29:20.264322 20451 sgd_solver.cpp:106] Iteration 30690, lr = 0.000349047
I0809 09:29:40.448369 20451 solver.cpp:337] Iteration 30700, Testing net (#0)
I0809 09:29:49.151587 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 09:29:49.151638 20451 solver.cpp:404]     Test net output #1: loss = 0.998561 (* 1 = 0.998561 loss)
I0809 09:29:51.379511 20451 solver.cpp:228] Iteration 30700, loss = 0.156278
I0809 09:29:51.379603 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:29:51.379618 20451 solver.cpp:244]     Train net output #1: loss = 0.156278 (* 1 = 0.156278 loss)
I0809 09:29:51.379631 20451 sgd_solver.cpp:106] Iteration 30700, lr = 0.000348983
I0809 09:30:13.937530 20451 solver.cpp:228] Iteration 30710, loss = 0.187578
I0809 09:30:13.937583 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:30:13.937597 20451 solver.cpp:244]     Train net output #1: loss = 0.187579 (* 1 = 0.187579 loss)
I0809 09:30:13.937609 20451 sgd_solver.cpp:106] Iteration 30710, lr = 0.000348919
I0809 09:30:36.276789 20451 solver.cpp:228] Iteration 30720, loss = 0.187525
I0809 09:30:36.276932 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:30:36.276947 20451 solver.cpp:244]     Train net output #1: loss = 0.187525 (* 1 = 0.187525 loss)
I0809 09:30:36.276959 20451 sgd_solver.cpp:106] Iteration 30720, lr = 0.000348854
I0809 09:30:58.764866 20451 solver.cpp:228] Iteration 30730, loss = 0.125043
I0809 09:30:58.764910 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:30:58.764928 20451 solver.cpp:244]     Train net output #1: loss = 0.125043 (* 1 = 0.125043 loss)
I0809 09:30:58.764943 20451 sgd_solver.cpp:106] Iteration 30730, lr = 0.00034879
I0809 09:31:21.548935 20451 solver.cpp:228] Iteration 30740, loss = 0.218803
I0809 09:31:21.549034 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:31:21.549052 20451 solver.cpp:244]     Train net output #1: loss = 0.218804 (* 1 = 0.218804 loss)
I0809 09:31:21.549067 20451 sgd_solver.cpp:106] Iteration 30740, lr = 0.000348726
I0809 09:31:44.254472 20451 solver.cpp:228] Iteration 30750, loss = 0.156308
I0809 09:31:44.254513 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:31:44.254530 20451 solver.cpp:244]     Train net output #1: loss = 0.156308 (* 1 = 0.156308 loss)
I0809 09:31:44.254545 20451 sgd_solver.cpp:106] Iteration 30750, lr = 0.000348662
I0809 09:32:06.790127 20451 solver.cpp:228] Iteration 30760, loss = 0.218878
I0809 09:32:06.790320 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:32:06.790338 20451 solver.cpp:244]     Train net output #1: loss = 0.218878 (* 1 = 0.218878 loss)
I0809 09:32:06.790354 20451 sgd_solver.cpp:106] Iteration 30760, lr = 0.000348598
I0809 09:32:29.344563 20451 solver.cpp:228] Iteration 30770, loss = 0.0625422
I0809 09:32:29.344604 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 09:32:29.344624 20451 solver.cpp:244]     Train net output #1: loss = 0.0625425 (* 1 = 0.0625425 loss)
I0809 09:32:29.344648 20451 sgd_solver.cpp:106] Iteration 30770, lr = 0.000348533
I0809 09:32:51.677708 20451 solver.cpp:228] Iteration 30780, loss = 0.187757
I0809 09:32:51.677810 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:32:51.677829 20451 solver.cpp:244]     Train net output #1: loss = 0.187758 (* 1 = 0.187758 loss)
I0809 09:32:51.677845 20451 sgd_solver.cpp:106] Iteration 30780, lr = 0.000348469
I0809 09:33:14.031365 20451 solver.cpp:228] Iteration 30790, loss = 0.250059
I0809 09:33:14.031419 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:33:14.031433 20451 solver.cpp:244]     Train net output #1: loss = 0.250059 (* 1 = 0.250059 loss)
I0809 09:33:14.031445 20451 sgd_solver.cpp:106] Iteration 30790, lr = 0.000348405
I0809 09:33:34.167371 20451 solver.cpp:337] Iteration 30800, Testing net (#0)
I0809 09:33:42.681529 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 09:33:42.681581 20451 solver.cpp:404]     Test net output #1: loss = 1.00876 (* 1 = 1.00876 loss)
I0809 09:33:44.886620 20451 solver.cpp:228] Iteration 30800, loss = 0.219059
I0809 09:33:44.886672 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:33:44.886685 20451 solver.cpp:244]     Train net output #1: loss = 0.219059 (* 1 = 0.219059 loss)
I0809 09:33:44.886698 20451 sgd_solver.cpp:106] Iteration 30800, lr = 0.000348341
I0809 09:34:07.177052 20451 solver.cpp:228] Iteration 30810, loss = 0.0626368
I0809 09:34:07.177227 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:34:07.177242 20451 solver.cpp:244]     Train net output #1: loss = 0.0626371 (* 1 = 0.0626371 loss)
I0809 09:34:07.177254 20451 sgd_solver.cpp:106] Iteration 30810, lr = 0.000348277
I0809 09:34:29.478888 20451 solver.cpp:228] Iteration 30820, loss = 0.12503
I0809 09:34:29.478934 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:34:29.478951 20451 solver.cpp:244]     Train net output #1: loss = 0.12503 (* 1 = 0.12503 loss)
I0809 09:34:29.478968 20451 sgd_solver.cpp:106] Iteration 30820, lr = 0.000348213
I0809 09:34:51.784950 20451 solver.cpp:228] Iteration 30830, loss = 0.187566
I0809 09:34:51.785166 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:34:51.785182 20451 solver.cpp:244]     Train net output #1: loss = 0.187567 (* 1 = 0.187567 loss)
I0809 09:34:51.785194 20451 sgd_solver.cpp:106] Iteration 30830, lr = 0.000348149
I0809 09:35:14.174357 20451 solver.cpp:228] Iteration 30840, loss = 0.125016
I0809 09:35:14.174410 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:35:14.174424 20451 solver.cpp:244]     Train net output #1: loss = 0.125016 (* 1 = 0.125016 loss)
I0809 09:35:14.174437 20451 sgd_solver.cpp:106] Iteration 30840, lr = 0.000348085
I0809 09:35:36.516300 20451 solver.cpp:228] Iteration 30850, loss = 0.187536
I0809 09:35:36.516479 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:35:36.516494 20451 solver.cpp:244]     Train net output #1: loss = 0.187536 (* 1 = 0.187536 loss)
I0809 09:35:36.516506 20451 sgd_solver.cpp:106] Iteration 30850, lr = 0.000348021
I0809 09:35:59.371850 20451 solver.cpp:228] Iteration 30860, loss = 0.125028
I0809 09:35:59.371901 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:35:59.371918 20451 solver.cpp:244]     Train net output #1: loss = 0.125029 (* 1 = 0.125029 loss)
I0809 09:35:59.371932 20451 sgd_solver.cpp:106] Iteration 30860, lr = 0.000347958
I0809 09:36:21.682960 20451 solver.cpp:228] Iteration 30870, loss = 0.250049
I0809 09:36:21.683148 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 09:36:21.683163 20451 solver.cpp:244]     Train net output #1: loss = 0.25005 (* 1 = 0.25005 loss)
I0809 09:36:21.683176 20451 sgd_solver.cpp:106] Iteration 30870, lr = 0.000347894
I0809 09:36:43.978248 20451 solver.cpp:228] Iteration 30880, loss = 0.156289
I0809 09:36:43.978301 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:36:43.978314 20451 solver.cpp:244]     Train net output #1: loss = 0.15629 (* 1 = 0.15629 loss)
I0809 09:36:43.978327 20451 sgd_solver.cpp:106] Iteration 30880, lr = 0.00034783
I0809 09:37:06.272694 20451 solver.cpp:228] Iteration 30890, loss = 0.187774
I0809 09:37:06.272825 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:37:06.272840 20451 solver.cpp:244]     Train net output #1: loss = 0.187774 (* 1 = 0.187774 loss)
I0809 09:37:06.272852 20451 sgd_solver.cpp:106] Iteration 30890, lr = 0.000347766
I0809 09:37:26.333992 20451 solver.cpp:337] Iteration 30900, Testing net (#0)
I0809 09:37:34.833746 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 09:37:34.833797 20451 solver.cpp:404]     Test net output #1: loss = 1.00364 (* 1 = 1.00364 loss)
I0809 09:37:37.036500 20451 solver.cpp:228] Iteration 30900, loss = 0.0938217
I0809 09:37:37.036685 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 09:37:37.036700 20451 solver.cpp:244]     Train net output #1: loss = 0.0938221 (* 1 = 0.0938221 loss)
I0809 09:37:37.036712 20451 sgd_solver.cpp:106] Iteration 30900, lr = 0.000347702
I0809 09:37:59.541018 20451 solver.cpp:228] Iteration 30910, loss = 0.25008
I0809 09:37:59.541067 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:37:59.541081 20451 solver.cpp:244]     Train net output #1: loss = 0.250081 (* 1 = 0.250081 loss)
I0809 09:37:59.541092 20451 sgd_solver.cpp:106] Iteration 30910, lr = 0.000347639
I0809 09:38:22.130710 20451 solver.cpp:228] Iteration 30920, loss = 0.125025
I0809 09:38:22.130887 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:38:22.130903 20451 solver.cpp:244]     Train net output #1: loss = 0.125026 (* 1 = 0.125026 loss)
I0809 09:38:22.130915 20451 sgd_solver.cpp:106] Iteration 30920, lr = 0.000347575
I0809 09:38:44.606114 20451 solver.cpp:228] Iteration 30930, loss = 0.156279
I0809 09:38:44.606158 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:38:44.606176 20451 solver.cpp:244]     Train net output #1: loss = 0.156279 (* 1 = 0.156279 loss)
I0809 09:38:44.606194 20451 sgd_solver.cpp:106] Iteration 30930, lr = 0.000347511
I0809 09:39:06.911586 20451 solver.cpp:228] Iteration 30940, loss = 0.125217
I0809 09:39:06.911728 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:39:06.911744 20451 solver.cpp:244]     Train net output #1: loss = 0.125218 (* 1 = 0.125218 loss)
I0809 09:39:06.911756 20451 sgd_solver.cpp:106] Iteration 30940, lr = 0.000347447
I0809 09:39:29.284449 20451 solver.cpp:228] Iteration 30950, loss = 0.156392
I0809 09:39:29.284497 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:39:29.284512 20451 solver.cpp:244]     Train net output #1: loss = 0.156392 (* 1 = 0.156392 loss)
I0809 09:39:29.284524 20451 sgd_solver.cpp:106] Iteration 30950, lr = 0.000347384
I0809 09:39:51.589375 20451 solver.cpp:228] Iteration 30960, loss = 0.250156
I0809 09:39:51.589555 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 09:39:51.589570 20451 solver.cpp:244]     Train net output #1: loss = 0.250157 (* 1 = 0.250157 loss)
I0809 09:39:51.589583 20451 sgd_solver.cpp:106] Iteration 30960, lr = 0.00034732
I0809 09:40:13.881395 20451 solver.cpp:228] Iteration 30970, loss = 0.187523
I0809 09:40:13.881445 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:40:13.881464 20451 solver.cpp:244]     Train net output #1: loss = 0.187523 (* 1 = 0.187523 loss)
I0809 09:40:13.881481 20451 sgd_solver.cpp:106] Iteration 30970, lr = 0.000347257
I0809 09:40:36.191179 20451 solver.cpp:228] Iteration 30980, loss = 0.281308
I0809 09:40:36.191282 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 09:40:36.191296 20451 solver.cpp:244]     Train net output #1: loss = 0.281309 (* 1 = 0.281309 loss)
I0809 09:40:36.191309 20451 sgd_solver.cpp:106] Iteration 30980, lr = 0.000347193
I0809 09:40:58.703531 20451 solver.cpp:228] Iteration 30990, loss = 0.0312501
I0809 09:40:58.703574 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 09:40:58.703591 20451 solver.cpp:244]     Train net output #1: loss = 0.0312505 (* 1 = 0.0312505 loss)
I0809 09:40:58.703608 20451 sgd_solver.cpp:106] Iteration 30990, lr = 0.00034713
I0809 09:41:19.166927 20451 solver.cpp:337] Iteration 31000, Testing net (#0)
I0809 09:41:27.861219 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0809 09:41:27.861260 20451 solver.cpp:404]     Test net output #1: loss = 0.961242 (* 1 = 0.961242 loss)
I0809 09:41:30.064363 20451 solver.cpp:228] Iteration 31000, loss = 0.156324
I0809 09:41:30.064406 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:41:30.064421 20451 solver.cpp:244]     Train net output #1: loss = 0.156324 (* 1 = 0.156324 loss)
I0809 09:41:30.064434 20451 sgd_solver.cpp:106] Iteration 31000, lr = 0.000347066
I0809 09:41:53.131738 20451 solver.cpp:228] Iteration 31010, loss = 0.093775
I0809 09:41:53.131916 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 09:41:53.131934 20451 solver.cpp:244]     Train net output #1: loss = 0.0937753 (* 1 = 0.0937753 loss)
I0809 09:41:53.131947 20451 sgd_solver.cpp:106] Iteration 31010, lr = 0.000347003
I0809 09:42:16.270668 20451 solver.cpp:228] Iteration 31020, loss = 0.187545
I0809 09:42:16.270719 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:42:16.270732 20451 solver.cpp:244]     Train net output #1: loss = 0.187545 (* 1 = 0.187545 loss)
I0809 09:42:16.270745 20451 sgd_solver.cpp:106] Iteration 31020, lr = 0.000346939
I0809 09:42:38.763756 20451 solver.cpp:228] Iteration 31030, loss = 0.218832
I0809 09:42:38.763860 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:42:38.763875 20451 solver.cpp:244]     Train net output #1: loss = 0.218832 (* 1 = 0.218832 loss)
I0809 09:42:38.763887 20451 sgd_solver.cpp:106] Iteration 31030, lr = 0.000346876
I0809 09:43:01.086191 20451 solver.cpp:228] Iteration 31040, loss = 0.156292
I0809 09:43:01.086243 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:43:01.086257 20451 solver.cpp:244]     Train net output #1: loss = 0.156292 (* 1 = 0.156292 loss)
I0809 09:43:01.086269 20451 sgd_solver.cpp:106] Iteration 31040, lr = 0.000346812
I0809 09:43:23.405046 20451 solver.cpp:228] Iteration 31050, loss = 0.156306
I0809 09:43:23.405266 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:43:23.405282 20451 solver.cpp:244]     Train net output #1: loss = 0.156306 (* 1 = 0.156306 loss)
I0809 09:43:23.405295 20451 sgd_solver.cpp:106] Iteration 31050, lr = 0.000346749
I0809 09:43:45.935314 20451 solver.cpp:228] Iteration 31060, loss = 0.218783
I0809 09:43:45.935359 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:43:45.935374 20451 solver.cpp:244]     Train net output #1: loss = 0.218784 (* 1 = 0.218784 loss)
I0809 09:43:45.935386 20451 sgd_solver.cpp:106] Iteration 31060, lr = 0.000346686
I0809 09:44:08.230556 20451 solver.cpp:228] Iteration 31070, loss = 0.0937666
I0809 09:44:08.230729 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 09:44:08.230746 20451 solver.cpp:244]     Train net output #1: loss = 0.0937669 (* 1 = 0.0937669 loss)
I0809 09:44:08.230759 20451 sgd_solver.cpp:106] Iteration 31070, lr = 0.000346622
I0809 09:44:30.520615 20451 solver.cpp:228] Iteration 31080, loss = 0.156327
I0809 09:44:30.520668 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:44:30.520681 20451 solver.cpp:244]     Train net output #1: loss = 0.156327 (* 1 = 0.156327 loss)
I0809 09:44:30.520694 20451 sgd_solver.cpp:106] Iteration 31080, lr = 0.000346559
I0809 09:44:52.876689 20451 solver.cpp:228] Iteration 31090, loss = 0.156367
I0809 09:44:52.876801 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:44:52.876821 20451 solver.cpp:244]     Train net output #1: loss = 0.156367 (* 1 = 0.156367 loss)
I0809 09:44:52.876835 20451 sgd_solver.cpp:106] Iteration 31090, lr = 0.000346496
I0809 09:45:13.317255 20451 solver.cpp:337] Iteration 31100, Testing net (#0)
I0809 09:45:21.995193 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 09:45:21.995237 20451 solver.cpp:404]     Test net output #1: loss = 0.993841 (* 1 = 0.993841 loss)
I0809 09:45:24.205529 20451 solver.cpp:228] Iteration 31100, loss = 0.0939904
I0809 09:45:24.205709 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:45:24.205725 20451 solver.cpp:244]     Train net output #1: loss = 0.0939908 (* 1 = 0.0939908 loss)
I0809 09:45:24.205737 20451 sgd_solver.cpp:106] Iteration 31100, lr = 0.000346433
I0809 09:45:46.547627 20451 solver.cpp:228] Iteration 31110, loss = 0.156254
I0809 09:45:46.547677 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:45:46.547691 20451 solver.cpp:244]     Train net output #1: loss = 0.156254 (* 1 = 0.156254 loss)
I0809 09:45:46.547703 20451 sgd_solver.cpp:106] Iteration 31110, lr = 0.000346369
I0809 09:46:08.963549 20451 solver.cpp:228] Iteration 31120, loss = 0.156289
I0809 09:46:08.963670 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:46:08.963690 20451 solver.cpp:244]     Train net output #1: loss = 0.156289 (* 1 = 0.156289 loss)
I0809 09:46:08.963706 20451 sgd_solver.cpp:106] Iteration 31120, lr = 0.000346306
I0809 09:46:31.252775 20451 solver.cpp:228] Iteration 31130, loss = 0.218799
I0809 09:46:31.252823 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:46:31.252841 20451 solver.cpp:244]     Train net output #1: loss = 0.2188 (* 1 = 0.2188 loss)
I0809 09:46:31.252856 20451 sgd_solver.cpp:106] Iteration 31130, lr = 0.000346243
I0809 09:46:53.797798 20451 solver.cpp:228] Iteration 31140, loss = 0.0625217
I0809 09:46:53.797982 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 09:46:53.797997 20451 solver.cpp:244]     Train net output #1: loss = 0.062522 (* 1 = 0.062522 loss)
I0809 09:46:53.798010 20451 sgd_solver.cpp:106] Iteration 31140, lr = 0.00034618
I0809 09:47:16.196312 20451 solver.cpp:228] Iteration 31150, loss = 0.125044
I0809 09:47:16.196364 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:47:16.196378 20451 solver.cpp:244]     Train net output #1: loss = 0.125045 (* 1 = 0.125045 loss)
I0809 09:47:16.196390 20451 sgd_solver.cpp:106] Iteration 31150, lr = 0.000346117
I0809 09:47:38.965958 20451 solver.cpp:228] Iteration 31160, loss = 0.156278
I0809 09:47:38.966176 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:47:38.966190 20451 solver.cpp:244]     Train net output #1: loss = 0.156278 (* 1 = 0.156278 loss)
I0809 09:47:38.966203 20451 sgd_solver.cpp:106] Iteration 31160, lr = 0.000346054
I0809 09:48:01.785022 20451 solver.cpp:228] Iteration 31170, loss = 0.218829
I0809 09:48:01.785068 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:48:01.785089 20451 solver.cpp:244]     Train net output #1: loss = 0.21883 (* 1 = 0.21883 loss)
I0809 09:48:01.785104 20451 sgd_solver.cpp:106] Iteration 31170, lr = 0.000345991
I0809 09:48:24.390270 20451 solver.cpp:228] Iteration 31180, loss = 0.250085
I0809 09:48:24.390445 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 09:48:24.390463 20451 solver.cpp:244]     Train net output #1: loss = 0.250086 (* 1 = 0.250086 loss)
I0809 09:48:24.390478 20451 sgd_solver.cpp:106] Iteration 31180, lr = 0.000345928
I0809 09:48:47.598340 20451 solver.cpp:228] Iteration 31190, loss = 0.156458
I0809 09:48:47.598395 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:48:47.598409 20451 solver.cpp:244]     Train net output #1: loss = 0.156459 (* 1 = 0.156459 loss)
I0809 09:48:47.598422 20451 sgd_solver.cpp:106] Iteration 31190, lr = 0.000345865
I0809 09:49:07.752346 20451 solver.cpp:337] Iteration 31200, Testing net (#0)
I0809 09:49:16.272213 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 09:49:16.272274 20451 solver.cpp:404]     Test net output #1: loss = 0.99907 (* 1 = 0.99907 loss)
I0809 09:49:18.474918 20451 solver.cpp:228] Iteration 31200, loss = 0.187677
I0809 09:49:18.474970 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:49:18.474984 20451 solver.cpp:244]     Train net output #1: loss = 0.187678 (* 1 = 0.187678 loss)
I0809 09:49:18.474997 20451 sgd_solver.cpp:106] Iteration 31200, lr = 0.000345802
I0809 09:49:40.802412 20451 solver.cpp:228] Iteration 31210, loss = 0.125107
I0809 09:49:40.802507 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:49:40.802525 20451 solver.cpp:244]     Train net output #1: loss = 0.125107 (* 1 = 0.125107 loss)
I0809 09:49:40.802537 20451 sgd_solver.cpp:106] Iteration 31210, lr = 0.000345739
I0809 09:50:03.818647 20451 solver.cpp:228] Iteration 31220, loss = 0.312892
I0809 09:50:03.818691 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 09:50:03.818708 20451 solver.cpp:244]     Train net output #1: loss = 0.312892 (* 1 = 0.312892 loss)
I0809 09:50:03.818723 20451 sgd_solver.cpp:106] Iteration 31220, lr = 0.000345676
I0809 09:50:26.554133 20451 solver.cpp:228] Iteration 31230, loss = 0.187502
I0809 09:50:26.554234 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:50:26.554253 20451 solver.cpp:244]     Train net output #1: loss = 0.187502 (* 1 = 0.187502 loss)
I0809 09:50:26.554268 20451 sgd_solver.cpp:106] Iteration 31230, lr = 0.000345613
I0809 09:50:49.029906 20451 solver.cpp:228] Iteration 31240, loss = 0.156272
I0809 09:50:49.029947 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:50:49.029960 20451 solver.cpp:244]     Train net output #1: loss = 0.156272 (* 1 = 0.156272 loss)
I0809 09:50:49.029973 20451 sgd_solver.cpp:106] Iteration 31240, lr = 0.00034555
I0809 09:51:11.619186 20451 solver.cpp:228] Iteration 31250, loss = 0.0937567
I0809 09:51:11.619398 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 09:51:11.619415 20451 solver.cpp:244]     Train net output #1: loss = 0.093757 (* 1 = 0.093757 loss)
I0809 09:51:11.619426 20451 sgd_solver.cpp:106] Iteration 31250, lr = 0.000345487
I0809 09:51:34.041980 20451 solver.cpp:228] Iteration 31260, loss = 0.312707
I0809 09:51:34.042032 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 09:51:34.042045 20451 solver.cpp:244]     Train net output #1: loss = 0.312708 (* 1 = 0.312708 loss)
I0809 09:51:34.042057 20451 sgd_solver.cpp:106] Iteration 31260, lr = 0.000345424
I0809 09:51:56.490134 20451 solver.cpp:228] Iteration 31270, loss = 0.218787
I0809 09:51:56.490375 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:51:56.490389 20451 solver.cpp:244]     Train net output #1: loss = 0.218787 (* 1 = 0.218787 loss)
I0809 09:51:56.490401 20451 sgd_solver.cpp:106] Iteration 31270, lr = 0.000345362
I0809 09:52:18.865067 20451 solver.cpp:228] Iteration 31280, loss = 0.187637
I0809 09:52:18.865118 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:52:18.865133 20451 solver.cpp:244]     Train net output #1: loss = 0.187637 (* 1 = 0.187637 loss)
I0809 09:52:18.865144 20451 sgd_solver.cpp:106] Iteration 31280, lr = 0.000345299
I0809 09:52:41.157850 20451 solver.cpp:228] Iteration 31290, loss = 0.218828
I0809 09:52:41.158026 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:52:41.158042 20451 solver.cpp:244]     Train net output #1: loss = 0.218828 (* 1 = 0.218828 loss)
I0809 09:52:41.158056 20451 sgd_solver.cpp:106] Iteration 31290, lr = 0.000345236
I0809 09:53:01.224905 20451 solver.cpp:337] Iteration 31300, Testing net (#0)
I0809 09:53:09.740948 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0809 09:53:09.740998 20451 solver.cpp:404]     Test net output #1: loss = 0.989937 (* 1 = 0.989937 loss)
I0809 09:53:11.940985 20451 solver.cpp:228] Iteration 31300, loss = 0.219039
I0809 09:53:11.941160 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:53:11.941175 20451 solver.cpp:244]     Train net output #1: loss = 0.219039 (* 1 = 0.219039 loss)
I0809 09:53:11.941189 20451 sgd_solver.cpp:106] Iteration 31300, lr = 0.000345174
I0809 09:53:34.226960 20451 solver.cpp:228] Iteration 31310, loss = 0.250022
I0809 09:53:34.227002 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 09:53:34.227017 20451 solver.cpp:244]     Train net output #1: loss = 0.250022 (* 1 = 0.250022 loss)
I0809 09:53:34.227030 20451 sgd_solver.cpp:106] Iteration 31310, lr = 0.000345111
I0809 09:53:56.527240 20451 solver.cpp:228] Iteration 31320, loss = 0.218877
I0809 09:53:56.527421 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:53:56.527437 20451 solver.cpp:244]     Train net output #1: loss = 0.218877 (* 1 = 0.218877 loss)
I0809 09:53:56.527451 20451 sgd_solver.cpp:106] Iteration 31320, lr = 0.000345048
I0809 09:54:18.831238 20451 solver.cpp:228] Iteration 31330, loss = 0.125092
I0809 09:54:18.831291 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 09:54:18.831310 20451 solver.cpp:244]     Train net output #1: loss = 0.125093 (* 1 = 0.125093 loss)
I0809 09:54:18.831326 20451 sgd_solver.cpp:106] Iteration 31330, lr = 0.000344986
I0809 09:54:41.137101 20451 solver.cpp:228] Iteration 31340, loss = 0.187503
I0809 09:54:41.137200 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:54:41.137220 20451 solver.cpp:244]     Train net output #1: loss = 0.187504 (* 1 = 0.187504 loss)
I0809 09:54:41.137235 20451 sgd_solver.cpp:106] Iteration 31340, lr = 0.000344923
I0809 09:55:03.632154 20451 solver.cpp:228] Iteration 31350, loss = 0.218819
I0809 09:55:03.632194 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:55:03.632210 20451 solver.cpp:244]     Train net output #1: loss = 0.218819 (* 1 = 0.218819 loss)
I0809 09:55:03.632221 20451 sgd_solver.cpp:106] Iteration 31350, lr = 0.00034486
I0809 09:55:25.952016 20451 solver.cpp:228] Iteration 31360, loss = 0.125031
I0809 09:55:25.952157 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:55:25.952172 20451 solver.cpp:244]     Train net output #1: loss = 0.125032 (* 1 = 0.125032 loss)
I0809 09:55:25.952184 20451 sgd_solver.cpp:106] Iteration 31360, lr = 0.000344798
I0809 09:55:48.253531 20451 solver.cpp:228] Iteration 31370, loss = 0.125013
I0809 09:55:48.253583 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:55:48.253597 20451 solver.cpp:244]     Train net output #1: loss = 0.125013 (* 1 = 0.125013 loss)
I0809 09:55:48.253608 20451 sgd_solver.cpp:106] Iteration 31370, lr = 0.000344735
I0809 09:56:10.555997 20451 solver.cpp:228] Iteration 31380, loss = 0.312596
I0809 09:56:10.556181 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 09:56:10.556196 20451 solver.cpp:244]     Train net output #1: loss = 0.312597 (* 1 = 0.312597 loss)
I0809 09:56:10.556210 20451 sgd_solver.cpp:106] Iteration 31380, lr = 0.000344673
I0809 09:56:32.862964 20451 solver.cpp:228] Iteration 31390, loss = 0.0312515
I0809 09:56:32.863018 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 09:56:32.863031 20451 solver.cpp:244]     Train net output #1: loss = 0.0312518 (* 1 = 0.0312518 loss)
I0809 09:56:32.863042 20451 sgd_solver.cpp:106] Iteration 31390, lr = 0.00034461
I0809 09:56:52.931078 20451 solver.cpp:337] Iteration 31400, Testing net (#0)
I0809 09:57:01.454097 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0809 09:57:01.454140 20451 solver.cpp:404]     Test net output #1: loss = 1.03595 (* 1 = 1.03595 loss)
I0809 09:57:03.661406 20451 solver.cpp:228] Iteration 31400, loss = 0.187502
I0809 09:57:03.661453 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:57:03.661468 20451 solver.cpp:244]     Train net output #1: loss = 0.187502 (* 1 = 0.187502 loss)
I0809 09:57:03.661480 20451 sgd_solver.cpp:106] Iteration 31400, lr = 0.000344548
I0809 09:57:26.003691 20451 solver.cpp:228] Iteration 31410, loss = 0.156502
I0809 09:57:26.003856 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 09:57:26.003900 20451 solver.cpp:244]     Train net output #1: loss = 0.156503 (* 1 = 0.156503 loss)
I0809 09:57:26.003918 20451 sgd_solver.cpp:106] Iteration 31410, lr = 0.000344486
I0809 09:57:48.384443 20451 solver.cpp:228] Iteration 31420, loss = 0.218886
I0809 09:57:48.384496 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:57:48.384511 20451 solver.cpp:244]     Train net output #1: loss = 0.218887 (* 1 = 0.218887 loss)
I0809 09:57:48.384523 20451 sgd_solver.cpp:106] Iteration 31420, lr = 0.000344423
I0809 09:58:10.747472 20451 solver.cpp:228] Iteration 31430, loss = 0.18752
I0809 09:58:10.747575 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:58:10.747593 20451 solver.cpp:244]     Train net output #1: loss = 0.18752 (* 1 = 0.18752 loss)
I0809 09:58:10.747607 20451 sgd_solver.cpp:106] Iteration 31430, lr = 0.000344361
I0809 09:58:33.045298 20451 solver.cpp:228] Iteration 31440, loss = 0.125008
I0809 09:58:33.045346 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 09:58:33.045361 20451 solver.cpp:244]     Train net output #1: loss = 0.125009 (* 1 = 0.125009 loss)
I0809 09:58:33.045374 20451 sgd_solver.cpp:106] Iteration 31440, lr = 0.000344299
I0809 09:58:55.347115 20451 solver.cpp:228] Iteration 31450, loss = 0.187506
I0809 09:58:55.347283 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 09:58:55.347298 20451 solver.cpp:244]     Train net output #1: loss = 0.187507 (* 1 = 0.187507 loss)
I0809 09:58:55.347311 20451 sgd_solver.cpp:106] Iteration 31450, lr = 0.000344236
I0809 09:59:17.653144 20451 solver.cpp:228] Iteration 31460, loss = 0.218759
I0809 09:59:17.653190 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:59:17.653205 20451 solver.cpp:244]     Train net output #1: loss = 0.218759 (* 1 = 0.218759 loss)
I0809 09:59:17.653218 20451 sgd_solver.cpp:106] Iteration 31460, lr = 0.000344174
I0809 09:59:40.152940 20451 solver.cpp:228] Iteration 31470, loss = 0.218823
I0809 09:59:40.153157 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 09:59:40.153173 20451 solver.cpp:244]     Train net output #1: loss = 0.218823 (* 1 = 0.218823 loss)
I0809 09:59:40.153185 20451 sgd_solver.cpp:106] Iteration 31470, lr = 0.000344112
I0809 10:00:02.480407 20451 solver.cpp:228] Iteration 31480, loss = 0.187531
I0809 10:00:02.480460 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:00:02.480474 20451 solver.cpp:244]     Train net output #1: loss = 0.187531 (* 1 = 0.187531 loss)
I0809 10:00:02.480486 20451 sgd_solver.cpp:106] Iteration 31480, lr = 0.00034405
I0809 10:00:24.912935 20451 solver.cpp:228] Iteration 31490, loss = 0.156264
I0809 10:00:24.913039 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:00:24.913054 20451 solver.cpp:244]     Train net output #1: loss = 0.156265 (* 1 = 0.156265 loss)
I0809 10:00:24.913067 20451 sgd_solver.cpp:106] Iteration 31490, lr = 0.000343987
I0809 10:00:45.001394 20451 solver.cpp:337] Iteration 31500, Testing net (#0)
I0809 10:00:53.517573 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 10:00:53.517624 20451 solver.cpp:404]     Test net output #1: loss = 0.985321 (* 1 = 0.985321 loss)
I0809 10:00:55.730433 20451 solver.cpp:228] Iteration 31500, loss = 0.156474
I0809 10:00:55.730527 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:00:55.730543 20451 solver.cpp:244]     Train net output #1: loss = 0.156475 (* 1 = 0.156475 loss)
I0809 10:00:55.730556 20451 sgd_solver.cpp:106] Iteration 31500, lr = 0.000343925
I0809 10:01:18.148277 20451 solver.cpp:228] Iteration 31510, loss = 0.156334
I0809 10:01:18.148319 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:01:18.148335 20451 solver.cpp:244]     Train net output #1: loss = 0.156334 (* 1 = 0.156334 loss)
I0809 10:01:18.148349 20451 sgd_solver.cpp:106] Iteration 31510, lr = 0.000343863
I0809 10:01:40.440361 20451 solver.cpp:228] Iteration 31520, loss = 0.21903
I0809 10:01:40.440570 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:01:40.440587 20451 solver.cpp:244]     Train net output #1: loss = 0.219031 (* 1 = 0.219031 loss)
I0809 10:01:40.440598 20451 sgd_solver.cpp:106] Iteration 31520, lr = 0.000343801
I0809 10:02:02.768049 20451 solver.cpp:228] Iteration 31530, loss = 0.218981
I0809 10:02:02.768097 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:02:02.768110 20451 solver.cpp:244]     Train net output #1: loss = 0.218982 (* 1 = 0.218982 loss)
I0809 10:02:02.768122 20451 sgd_solver.cpp:106] Iteration 31530, lr = 0.000343739
I0809 10:02:25.095893 20451 solver.cpp:228] Iteration 31540, loss = 0.21879
I0809 10:02:25.096012 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:02:25.096031 20451 solver.cpp:244]     Train net output #1: loss = 0.218791 (* 1 = 0.218791 loss)
I0809 10:02:25.096048 20451 sgd_solver.cpp:106] Iteration 31540, lr = 0.000343677
I0809 10:02:47.447351 20451 solver.cpp:228] Iteration 31550, loss = 0.281426
I0809 10:02:47.447398 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 10:02:47.447417 20451 solver.cpp:244]     Train net output #1: loss = 0.281427 (* 1 = 0.281427 loss)
I0809 10:02:47.447432 20451 sgd_solver.cpp:106] Iteration 31550, lr = 0.000343615
I0809 10:03:10.023548 20451 solver.cpp:228] Iteration 31560, loss = 0.156288
I0809 10:03:10.023648 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:03:10.023664 20451 solver.cpp:244]     Train net output #1: loss = 0.156288 (* 1 = 0.156288 loss)
I0809 10:03:10.023677 20451 sgd_solver.cpp:106] Iteration 31560, lr = 0.000343553
I0809 10:03:32.438357 20451 solver.cpp:228] Iteration 31570, loss = 0.250037
I0809 10:03:32.438401 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:03:32.438416 20451 solver.cpp:244]     Train net output #1: loss = 0.250037 (* 1 = 0.250037 loss)
I0809 10:03:32.438428 20451 sgd_solver.cpp:106] Iteration 31570, lr = 0.000343491
I0809 10:03:54.826114 20451 solver.cpp:228] Iteration 31580, loss = 0.156329
I0809 10:03:54.826264 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:03:54.826282 20451 solver.cpp:244]     Train net output #1: loss = 0.156329 (* 1 = 0.156329 loss)
I0809 10:03:54.826293 20451 sgd_solver.cpp:106] Iteration 31580, lr = 0.000343429
I0809 10:04:17.189714 20451 solver.cpp:228] Iteration 31590, loss = 0.250064
I0809 10:04:17.189766 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:04:17.189780 20451 solver.cpp:244]     Train net output #1: loss = 0.250065 (* 1 = 0.250065 loss)
I0809 10:04:17.189792 20451 sgd_solver.cpp:106] Iteration 31590, lr = 0.000343367
I0809 10:04:37.584020 20451 solver.cpp:337] Iteration 31600, Testing net (#0)
I0809 10:04:46.296895 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0809 10:04:46.296937 20451 solver.cpp:404]     Test net output #1: loss = 0.970615 (* 1 = 0.970615 loss)
I0809 10:04:48.551695 20451 solver.cpp:228] Iteration 31600, loss = 0.250115
I0809 10:04:48.551753 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:04:48.551766 20451 solver.cpp:244]     Train net output #1: loss = 0.250115 (* 1 = 0.250115 loss)
I0809 10:04:48.551779 20451 sgd_solver.cpp:106] Iteration 31600, lr = 0.000343305
I0809 10:05:11.319725 20451 solver.cpp:228] Iteration 31610, loss = 0.15626
I0809 10:05:11.319941 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:05:11.319958 20451 solver.cpp:244]     Train net output #1: loss = 0.156261 (* 1 = 0.156261 loss)
I0809 10:05:11.319974 20451 sgd_solver.cpp:106] Iteration 31610, lr = 0.000343243
I0809 10:05:33.818562 20451 solver.cpp:228] Iteration 31620, loss = 0.0937939
I0809 10:05:33.818608 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:05:33.818622 20451 solver.cpp:244]     Train net output #1: loss = 0.0937943 (* 1 = 0.0937943 loss)
I0809 10:05:33.818634 20451 sgd_solver.cpp:106] Iteration 31620, lr = 0.000343181
I0809 10:05:56.449478 20451 solver.cpp:228] Iteration 31630, loss = 0.0937565
I0809 10:05:56.449657 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:05:56.449676 20451 solver.cpp:244]     Train net output #1: loss = 0.0937569 (* 1 = 0.0937569 loss)
I0809 10:05:56.449690 20451 sgd_solver.cpp:106] Iteration 31630, lr = 0.000343119
I0809 10:06:18.828593 20451 solver.cpp:228] Iteration 31640, loss = 0.125021
I0809 10:06:18.828642 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:06:18.828656 20451 solver.cpp:244]     Train net output #1: loss = 0.125021 (* 1 = 0.125021 loss)
I0809 10:06:18.828670 20451 sgd_solver.cpp:106] Iteration 31640, lr = 0.000343058
I0809 10:06:41.206558 20451 solver.cpp:228] Iteration 31650, loss = 0.218757
I0809 10:06:41.206748 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:06:41.206768 20451 solver.cpp:244]     Train net output #1: loss = 0.218757 (* 1 = 0.218757 loss)
I0809 10:06:41.206782 20451 sgd_solver.cpp:106] Iteration 31650, lr = 0.000342996
I0809 10:07:03.504642 20451 solver.cpp:228] Iteration 31660, loss = 0.250014
I0809 10:07:03.504695 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:07:03.504709 20451 solver.cpp:244]     Train net output #1: loss = 0.250014 (* 1 = 0.250014 loss)
I0809 10:07:03.504721 20451 sgd_solver.cpp:106] Iteration 31660, lr = 0.000342934
I0809 10:07:25.790997 20451 solver.cpp:228] Iteration 31670, loss = 0.125024
I0809 10:07:25.791096 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:07:25.791112 20451 solver.cpp:244]     Train net output #1: loss = 0.125024 (* 1 = 0.125024 loss)
I0809 10:07:25.791126 20451 sgd_solver.cpp:106] Iteration 31670, lr = 0.000342872
I0809 10:07:48.088865 20451 solver.cpp:228] Iteration 31680, loss = 0.281446
I0809 10:07:48.088918 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 10:07:48.088933 20451 solver.cpp:244]     Train net output #1: loss = 0.281447 (* 1 = 0.281447 loss)
I0809 10:07:48.088945 20451 sgd_solver.cpp:106] Iteration 31680, lr = 0.000342811
I0809 10:08:10.388105 20451 solver.cpp:228] Iteration 31690, loss = 0.156422
I0809 10:08:10.388293 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:08:10.388309 20451 solver.cpp:244]     Train net output #1: loss = 0.156423 (* 1 = 0.156423 loss)
I0809 10:08:10.388321 20451 sgd_solver.cpp:106] Iteration 31690, lr = 0.000342749
I0809 10:08:30.464952 20451 solver.cpp:337] Iteration 31700, Testing net (#0)
I0809 10:08:38.974920 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 10:08:38.974972 20451 solver.cpp:404]     Test net output #1: loss = 1.00843 (* 1 = 1.00843 loss)
I0809 10:08:41.174818 20451 solver.cpp:228] Iteration 31700, loss = 0.125114
I0809 10:08:41.174989 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:08:41.175005 20451 solver.cpp:244]     Train net output #1: loss = 0.125114 (* 1 = 0.125114 loss)
I0809 10:08:41.175019 20451 sgd_solver.cpp:106] Iteration 31700, lr = 0.000342687
I0809 10:09:03.463050 20451 solver.cpp:228] Iteration 31710, loss = 0.250008
I0809 10:09:03.463125 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:09:03.463140 20451 solver.cpp:244]     Train net output #1: loss = 0.250008 (* 1 = 0.250008 loss)
I0809 10:09:03.463165 20451 sgd_solver.cpp:106] Iteration 31710, lr = 0.000342626
I0809 10:09:25.849318 20451 solver.cpp:228] Iteration 31720, loss = 0.156294
I0809 10:09:25.849472 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:09:25.849491 20451 solver.cpp:244]     Train net output #1: loss = 0.156294 (* 1 = 0.156294 loss)
I0809 10:09:25.849509 20451 sgd_solver.cpp:106] Iteration 31720, lr = 0.000342564
I0809 10:09:48.154814 20451 solver.cpp:228] Iteration 31730, loss = 0.156323
I0809 10:09:48.154857 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:09:48.154877 20451 solver.cpp:244]     Train net output #1: loss = 0.156323 (* 1 = 0.156323 loss)
I0809 10:09:48.154901 20451 sgd_solver.cpp:106] Iteration 31730, lr = 0.000342502
I0809 10:10:10.519212 20451 solver.cpp:228] Iteration 31740, loss = 0.0312672
I0809 10:10:10.519407 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 10:10:10.519426 20451 solver.cpp:244]     Train net output #1: loss = 0.0312676 (* 1 = 0.0312676 loss)
I0809 10:10:10.519443 20451 sgd_solver.cpp:106] Iteration 31740, lr = 0.000342441
I0809 10:10:32.821908 20451 solver.cpp:228] Iteration 31750, loss = 0.218757
I0809 10:10:32.821952 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:10:32.821971 20451 solver.cpp:244]     Train net output #1: loss = 0.218757 (* 1 = 0.218757 loss)
I0809 10:10:32.821996 20451 sgd_solver.cpp:106] Iteration 31750, lr = 0.000342379
I0809 10:10:55.190855 20451 solver.cpp:228] Iteration 31760, loss = 0.218801
I0809 10:10:55.191040 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:10:55.191058 20451 solver.cpp:244]     Train net output #1: loss = 0.218802 (* 1 = 0.218802 loss)
I0809 10:10:55.191074 20451 sgd_solver.cpp:106] Iteration 31760, lr = 0.000342318
I0809 10:11:17.490402 20451 solver.cpp:228] Iteration 31770, loss = 0.187531
I0809 10:11:17.490454 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:11:17.490469 20451 solver.cpp:244]     Train net output #1: loss = 0.187532 (* 1 = 0.187532 loss)
I0809 10:11:17.490481 20451 sgd_solver.cpp:106] Iteration 31770, lr = 0.000342256
I0809 10:11:39.897619 20451 solver.cpp:228] Iteration 31780, loss = 0.156258
I0809 10:11:39.897791 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:11:39.897806 20451 solver.cpp:244]     Train net output #1: loss = 0.156258 (* 1 = 0.156258 loss)
I0809 10:11:39.897819 20451 sgd_solver.cpp:106] Iteration 31780, lr = 0.000342195
I0809 10:12:02.197546 20451 solver.cpp:228] Iteration 31790, loss = 0.250018
I0809 10:12:02.197587 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:12:02.197602 20451 solver.cpp:244]     Train net output #1: loss = 0.250018 (* 1 = 0.250018 loss)
I0809 10:12:02.197614 20451 sgd_solver.cpp:106] Iteration 31790, lr = 0.000342134
I0809 10:12:22.278309 20451 solver.cpp:337] Iteration 31800, Testing net (#0)
I0809 10:12:30.827666 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0809 10:12:30.827714 20451 solver.cpp:404]     Test net output #1: loss = 1.01252 (* 1 = 1.01252 loss)
I0809 10:12:33.033628 20451 solver.cpp:228] Iteration 31800, loss = 0.156255
I0809 10:12:33.033677 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:12:33.033691 20451 solver.cpp:244]     Train net output #1: loss = 0.156255 (* 1 = 0.156255 loss)
I0809 10:12:33.033704 20451 sgd_solver.cpp:106] Iteration 31800, lr = 0.000342072
I0809 10:12:55.332643 20451 solver.cpp:228] Iteration 31810, loss = 0.343795
I0809 10:12:55.332815 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 10:12:55.332831 20451 solver.cpp:244]     Train net output #1: loss = 0.343795 (* 1 = 0.343795 loss)
I0809 10:12:55.332844 20451 sgd_solver.cpp:106] Iteration 31810, lr = 0.000342011
I0809 10:13:17.748394 20451 solver.cpp:228] Iteration 31820, loss = 0.312638
I0809 10:13:17.748443 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 10:13:17.748457 20451 solver.cpp:244]     Train net output #1: loss = 0.312638 (* 1 = 0.312638 loss)
I0809 10:13:17.748469 20451 sgd_solver.cpp:106] Iteration 31820, lr = 0.00034195
I0809 10:13:40.046061 20451 solver.cpp:228] Iteration 31830, loss = 0.0937901
I0809 10:13:40.046246 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:13:40.046262 20451 solver.cpp:244]     Train net output #1: loss = 0.0937905 (* 1 = 0.0937905 loss)
I0809 10:13:40.046274 20451 sgd_solver.cpp:106] Iteration 31830, lr = 0.000341888
I0809 10:14:02.329439 20451 solver.cpp:228] Iteration 31840, loss = 0.250056
I0809 10:14:02.329491 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:14:02.329506 20451 solver.cpp:244]     Train net output #1: loss = 0.250056 (* 1 = 0.250056 loss)
I0809 10:14:02.329517 20451 sgd_solver.cpp:106] Iteration 31840, lr = 0.000341827
I0809 10:14:24.700743 20451 solver.cpp:228] Iteration 31850, loss = 0.218842
I0809 10:14:24.700923 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:14:24.700939 20451 solver.cpp:244]     Train net output #1: loss = 0.218843 (* 1 = 0.218843 loss)
I0809 10:14:24.700953 20451 sgd_solver.cpp:106] Iteration 31850, lr = 0.000341766
I0809 10:14:47.101732 20451 solver.cpp:228] Iteration 31860, loss = 0.0937852
I0809 10:14:47.101784 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:14:47.101799 20451 solver.cpp:244]     Train net output #1: loss = 0.0937856 (* 1 = 0.0937856 loss)
I0809 10:14:47.101811 20451 sgd_solver.cpp:106] Iteration 31860, lr = 0.000341704
I0809 10:15:09.496075 20451 solver.cpp:228] Iteration 31870, loss = 0.34386
I0809 10:15:09.496250 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 10:15:09.496265 20451 solver.cpp:244]     Train net output #1: loss = 0.34386 (* 1 = 0.34386 loss)
I0809 10:15:09.496279 20451 sgd_solver.cpp:106] Iteration 31870, lr = 0.000341643
I0809 10:15:31.798107 20451 solver.cpp:228] Iteration 31880, loss = 0.12503
I0809 10:15:31.798151 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:15:31.798167 20451 solver.cpp:244]     Train net output #1: loss = 0.12503 (* 1 = 0.12503 loss)
I0809 10:15:31.798182 20451 sgd_solver.cpp:106] Iteration 31880, lr = 0.000341582
I0809 10:15:54.096277 20451 solver.cpp:228] Iteration 31890, loss = 0.125064
I0809 10:15:54.096400 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:15:54.096421 20451 solver.cpp:244]     Train net output #1: loss = 0.125064 (* 1 = 0.125064 loss)
I0809 10:15:54.096438 20451 sgd_solver.cpp:106] Iteration 31890, lr = 0.000341521
I0809 10:16:14.239621 20451 solver.cpp:337] Iteration 31900, Testing net (#0)
I0809 10:16:22.766134 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 10:16:22.766191 20451 solver.cpp:404]     Test net output #1: loss = 0.984506 (* 1 = 0.984506 loss)
I0809 10:16:24.970939 20451 solver.cpp:228] Iteration 31900, loss = 0.0312558
I0809 10:16:24.971189 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 10:16:24.971205 20451 solver.cpp:244]     Train net output #1: loss = 0.0312562 (* 1 = 0.0312562 loss)
I0809 10:16:24.971218 20451 sgd_solver.cpp:106] Iteration 31900, lr = 0.00034146
I0809 10:16:47.308876 20451 solver.cpp:228] Iteration 31910, loss = 0.281416
I0809 10:16:47.308924 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:16:47.308938 20451 solver.cpp:244]     Train net output #1: loss = 0.281417 (* 1 = 0.281417 loss)
I0809 10:16:47.308950 20451 sgd_solver.cpp:106] Iteration 31910, lr = 0.000341399
I0809 10:17:09.645526 20451 solver.cpp:228] Iteration 31920, loss = 0.125054
I0809 10:17:09.645704 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:17:09.645720 20451 solver.cpp:244]     Train net output #1: loss = 0.125054 (* 1 = 0.125054 loss)
I0809 10:17:09.645732 20451 sgd_solver.cpp:106] Iteration 31920, lr = 0.000341338
I0809 10:17:31.951036 20451 solver.cpp:228] Iteration 31930, loss = 0.156387
I0809 10:17:31.951088 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:17:31.951102 20451 solver.cpp:244]     Train net output #1: loss = 0.156387 (* 1 = 0.156387 loss)
I0809 10:17:31.951114 20451 sgd_solver.cpp:106] Iteration 31930, lr = 0.000341276
I0809 10:17:54.303938 20451 solver.cpp:228] Iteration 31940, loss = 0.250074
I0809 10:17:54.304034 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:17:54.304049 20451 solver.cpp:244]     Train net output #1: loss = 0.250074 (* 1 = 0.250074 loss)
I0809 10:17:54.304061 20451 sgd_solver.cpp:106] Iteration 31940, lr = 0.000341215
I0809 10:18:16.660423 20451 solver.cpp:228] Iteration 31950, loss = 0.187538
I0809 10:18:16.660473 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:18:16.660487 20451 solver.cpp:244]     Train net output #1: loss = 0.187538 (* 1 = 0.187538 loss)
I0809 10:18:16.660500 20451 sgd_solver.cpp:106] Iteration 31950, lr = 0.000341154
I0809 10:18:39.005031 20451 solver.cpp:228] Iteration 31960, loss = 0.187592
I0809 10:18:39.005209 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:18:39.005224 20451 solver.cpp:244]     Train net output #1: loss = 0.187592 (* 1 = 0.187592 loss)
I0809 10:18:39.005237 20451 sgd_solver.cpp:106] Iteration 31960, lr = 0.000341093
I0809 10:19:01.316337 20451 solver.cpp:228] Iteration 31970, loss = 0.218759
I0809 10:19:01.316388 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:19:01.316402 20451 solver.cpp:244]     Train net output #1: loss = 0.218759 (* 1 = 0.218759 loss)
I0809 10:19:01.316413 20451 sgd_solver.cpp:106] Iteration 31970, lr = 0.000341033
I0809 10:19:23.632076 20451 solver.cpp:228] Iteration 31980, loss = 0.187555
I0809 10:19:23.635344 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:19:23.635368 20451 solver.cpp:244]     Train net output #1: loss = 0.187556 (* 1 = 0.187556 loss)
I0809 10:19:23.635381 20451 sgd_solver.cpp:106] Iteration 31980, lr = 0.000340972
I0809 10:19:45.933943 20451 solver.cpp:228] Iteration 31990, loss = 0.0312562
I0809 10:19:45.933995 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 10:19:45.934010 20451 solver.cpp:244]     Train net output #1: loss = 0.0312565 (* 1 = 0.0312565 loss)
I0809 10:19:45.934021 20451 sgd_solver.cpp:106] Iteration 31990, lr = 0.000340911
I0809 10:20:06.030882 20451 solver.cpp:337] Iteration 32000, Testing net (#0)
I0809 10:20:14.549792 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 10:20:14.549841 20451 solver.cpp:404]     Test net output #1: loss = 1.00316 (* 1 = 1.00316 loss)
I0809 10:20:16.750900 20451 solver.cpp:228] Iteration 32000, loss = 0.125007
I0809 10:20:16.750947 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:20:16.750967 20451 solver.cpp:244]     Train net output #1: loss = 0.125007 (* 1 = 0.125007 loss)
I0809 10:20:16.750982 20451 sgd_solver.cpp:106] Iteration 32000, lr = 0.00034085
I0809 10:20:39.056454 20451 solver.cpp:228] Iteration 32010, loss = 0.187561
I0809 10:20:39.056673 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:20:39.056689 20451 solver.cpp:244]     Train net output #1: loss = 0.187562 (* 1 = 0.187562 loss)
I0809 10:20:39.056701 20451 sgd_solver.cpp:106] Iteration 32010, lr = 0.000340789
I0809 10:21:01.368335 20451 solver.cpp:228] Iteration 32020, loss = 0.218798
I0809 10:21:01.368376 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:21:01.368393 20451 solver.cpp:244]     Train net output #1: loss = 0.218798 (* 1 = 0.218798 loss)
I0809 10:21:01.368417 20451 sgd_solver.cpp:106] Iteration 32020, lr = 0.000340728
I0809 10:21:23.684900 20451 solver.cpp:228] Iteration 32030, loss = 0.125048
I0809 10:21:23.685083 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:21:23.685099 20451 solver.cpp:244]     Train net output #1: loss = 0.125049 (* 1 = 0.125049 loss)
I0809 10:21:23.685112 20451 sgd_solver.cpp:106] Iteration 32030, lr = 0.000340667
I0809 10:21:46.003974 20451 solver.cpp:228] Iteration 32040, loss = 0.062523
I0809 10:21:46.004019 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 10:21:46.004034 20451 solver.cpp:244]     Train net output #1: loss = 0.0625234 (* 1 = 0.0625234 loss)
I0809 10:21:46.004048 20451 sgd_solver.cpp:106] Iteration 32040, lr = 0.000340607
I0809 10:22:08.334600 20451 solver.cpp:228] Iteration 32050, loss = 0.187535
I0809 10:22:08.334781 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:22:08.334800 20451 solver.cpp:244]     Train net output #1: loss = 0.187535 (* 1 = 0.187535 loss)
I0809 10:22:08.334815 20451 sgd_solver.cpp:106] Iteration 32050, lr = 0.000340546
I0809 10:22:30.949005 20451 solver.cpp:228] Iteration 32060, loss = 0.125051
I0809 10:22:30.949050 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:22:30.949070 20451 solver.cpp:244]     Train net output #1: loss = 0.125051 (* 1 = 0.125051 loss)
I0809 10:22:30.949085 20451 sgd_solver.cpp:106] Iteration 32060, lr = 0.000340485
I0809 10:22:53.341730 20451 solver.cpp:228] Iteration 32070, loss = 0.156313
I0809 10:22:53.341897 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:22:53.341912 20451 solver.cpp:244]     Train net output #1: loss = 0.156313 (* 1 = 0.156313 loss)
I0809 10:22:53.341924 20451 sgd_solver.cpp:106] Iteration 32070, lr = 0.000340424
I0809 10:23:15.728749 20451 solver.cpp:228] Iteration 32080, loss = 0.125029
I0809 10:23:15.728796 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:23:15.728811 20451 solver.cpp:244]     Train net output #1: loss = 0.12503 (* 1 = 0.12503 loss)
I0809 10:23:15.728824 20451 sgd_solver.cpp:106] Iteration 32080, lr = 0.000340364
I0809 10:23:38.348234 20451 solver.cpp:228] Iteration 32090, loss = 0.21893
I0809 10:23:38.348343 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:23:38.348363 20451 solver.cpp:244]     Train net output #1: loss = 0.21893 (* 1 = 0.21893 loss)
I0809 10:23:38.348379 20451 sgd_solver.cpp:106] Iteration 32090, lr = 0.000340303
I0809 10:23:58.512035 20451 solver.cpp:337] Iteration 32100, Testing net (#0)
I0809 10:24:07.482051 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 10:24:07.482095 20451 solver.cpp:404]     Test net output #1: loss = 0.975185 (* 1 = 0.975185 loss)
I0809 10:24:09.689033 20451 solver.cpp:228] Iteration 32100, loss = 0.125035
I0809 10:24:09.689146 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:24:09.689165 20451 solver.cpp:244]     Train net output #1: loss = 0.125035 (* 1 = 0.125035 loss)
I0809 10:24:09.689177 20451 sgd_solver.cpp:106] Iteration 32100, lr = 0.000340242
I0809 10:24:32.276856 20451 solver.cpp:228] Iteration 32110, loss = 0.218754
I0809 10:24:32.276901 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:24:32.276919 20451 solver.cpp:244]     Train net output #1: loss = 0.218754 (* 1 = 0.218754 loss)
I0809 10:24:32.276933 20451 sgd_solver.cpp:106] Iteration 32110, lr = 0.000340182
I0809 10:24:54.582909 20451 solver.cpp:228] Iteration 32120, loss = 0.37501
I0809 10:24:54.583124 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:24:54.583140 20451 solver.cpp:244]     Train net output #1: loss = 0.375011 (* 1 = 0.375011 loss)
I0809 10:24:54.583153 20451 sgd_solver.cpp:106] Iteration 32120, lr = 0.000340121
I0809 10:25:16.878316 20451 solver.cpp:228] Iteration 32130, loss = 0.218814
I0809 10:25:16.878371 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:25:16.878386 20451 solver.cpp:244]     Train net output #1: loss = 0.218815 (* 1 = 0.218815 loss)
I0809 10:25:16.878398 20451 sgd_solver.cpp:106] Iteration 32130, lr = 0.000340061
I0809 10:25:39.328071 20451 solver.cpp:228] Iteration 32140, loss = 0.125012
I0809 10:25:39.328236 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:25:39.328251 20451 solver.cpp:244]     Train net output #1: loss = 0.125012 (* 1 = 0.125012 loss)
I0809 10:25:39.328264 20451 sgd_solver.cpp:106] Iteration 32140, lr = 0.00034
I0809 10:26:02.010239 20451 solver.cpp:228] Iteration 32150, loss = 0.34397
I0809 10:26:02.010282 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 10:26:02.010298 20451 solver.cpp:244]     Train net output #1: loss = 0.34397 (* 1 = 0.34397 loss)
I0809 10:26:02.010310 20451 sgd_solver.cpp:106] Iteration 32150, lr = 0.00033994
I0809 10:26:25.209377 20451 solver.cpp:228] Iteration 32160, loss = 0.125102
I0809 10:26:25.209480 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:26:25.209498 20451 solver.cpp:244]     Train net output #1: loss = 0.125102 (* 1 = 0.125102 loss)
I0809 10:26:25.209513 20451 sgd_solver.cpp:106] Iteration 32160, lr = 0.000339879
I0809 10:26:47.705420 20451 solver.cpp:228] Iteration 32170, loss = 0.219136
I0809 10:26:47.705471 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:26:47.705490 20451 solver.cpp:244]     Train net output #1: loss = 0.219136 (* 1 = 0.219136 loss)
I0809 10:26:47.705504 20451 sgd_solver.cpp:106] Iteration 32170, lr = 0.000339819
I0809 10:27:10.026864 20451 solver.cpp:228] Iteration 32180, loss = 0.187615
I0809 10:27:10.027040 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:27:10.027056 20451 solver.cpp:244]     Train net output #1: loss = 0.187616 (* 1 = 0.187616 loss)
I0809 10:27:10.027068 20451 sgd_solver.cpp:106] Iteration 32180, lr = 0.000339758
I0809 10:27:32.769953 20451 solver.cpp:228] Iteration 32190, loss = 0.125154
I0809 10:27:32.770005 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:27:32.770020 20451 solver.cpp:244]     Train net output #1: loss = 0.125155 (* 1 = 0.125155 loss)
I0809 10:27:32.770031 20451 sgd_solver.cpp:106] Iteration 32190, lr = 0.000339698
I0809 10:27:53.391964 20451 solver.cpp:337] Iteration 32200, Testing net (#0)
I0809 10:28:02.716208 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0809 10:28:02.716254 20451 solver.cpp:404]     Test net output #1: loss = 1.01776 (* 1 = 1.01776 loss)
I0809 10:28:05.151201 20451 solver.cpp:228] Iteration 32200, loss = 0.187658
I0809 10:28:05.151245 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:28:05.151260 20451 solver.cpp:244]     Train net output #1: loss = 0.187658 (* 1 = 0.187658 loss)
I0809 10:28:05.151275 20451 sgd_solver.cpp:106] Iteration 32200, lr = 0.000339638
I0809 10:28:27.901957 20451 solver.cpp:228] Iteration 32210, loss = 0.25019
I0809 10:28:27.902052 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:28:27.902068 20451 solver.cpp:244]     Train net output #1: loss = 0.250191 (* 1 = 0.250191 loss)
I0809 10:28:27.902081 20451 sgd_solver.cpp:106] Iteration 32210, lr = 0.000339577
I0809 10:28:50.296253 20451 solver.cpp:228] Iteration 32220, loss = 0.156367
I0809 10:28:50.296298 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:28:50.296315 20451 solver.cpp:244]     Train net output #1: loss = 0.156367 (* 1 = 0.156367 loss)
I0809 10:28:50.296330 20451 sgd_solver.cpp:106] Iteration 32220, lr = 0.000339517
I0809 10:29:12.573384 20451 solver.cpp:228] Iteration 32230, loss = 0.187683
I0809 10:29:12.573598 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:29:12.573618 20451 solver.cpp:244]     Train net output #1: loss = 0.187683 (* 1 = 0.187683 loss)
I0809 10:29:12.573633 20451 sgd_solver.cpp:106] Iteration 32230, lr = 0.000339457
I0809 10:29:34.938287 20451 solver.cpp:228] Iteration 32240, loss = 0.250154
I0809 10:29:34.938330 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:29:34.938349 20451 solver.cpp:244]     Train net output #1: loss = 0.250154 (* 1 = 0.250154 loss)
I0809 10:29:34.938364 20451 sgd_solver.cpp:106] Iteration 32240, lr = 0.000339396
I0809 10:29:57.224576 20451 solver.cpp:228] Iteration 32250, loss = 0.156441
I0809 10:29:57.224814 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:29:57.224943 20451 solver.cpp:244]     Train net output #1: loss = 0.156441 (* 1 = 0.156441 loss)
I0809 10:29:57.225020 20451 sgd_solver.cpp:106] Iteration 32250, lr = 0.000339336
I0809 10:30:19.524336 20451 solver.cpp:228] Iteration 32260, loss = 0.125093
I0809 10:30:19.524384 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:30:19.524399 20451 solver.cpp:244]     Train net output #1: loss = 0.125094 (* 1 = 0.125094 loss)
I0809 10:30:19.524412 20451 sgd_solver.cpp:106] Iteration 32260, lr = 0.000339276
I0809 10:30:41.810932 20451 solver.cpp:228] Iteration 32270, loss = 0.125117
I0809 10:30:41.811107 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:30:41.811122 20451 solver.cpp:244]     Train net output #1: loss = 0.125117 (* 1 = 0.125117 loss)
I0809 10:30:41.811134 20451 sgd_solver.cpp:106] Iteration 32270, lr = 0.000339216
I0809 10:31:04.171308 20451 solver.cpp:228] Iteration 32280, loss = 0.18757
I0809 10:31:04.171434 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:31:04.171476 20451 solver.cpp:244]     Train net output #1: loss = 0.18757 (* 1 = 0.18757 loss)
I0809 10:31:04.171515 20451 sgd_solver.cpp:106] Iteration 32280, lr = 0.000339155
I0809 10:31:26.464629 20451 solver.cpp:228] Iteration 32290, loss = 0.187691
I0809 10:31:26.464802 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:31:26.464818 20451 solver.cpp:244]     Train net output #1: loss = 0.187692 (* 1 = 0.187692 loss)
I0809 10:31:26.464830 20451 sgd_solver.cpp:106] Iteration 32290, lr = 0.000339095
I0809 10:31:46.562634 20451 solver.cpp:337] Iteration 32300, Testing net (#0)
I0809 10:31:55.100075 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 10:31:55.100131 20451 solver.cpp:404]     Test net output #1: loss = 1.00314 (* 1 = 1.00314 loss)
I0809 10:31:57.304816 20451 solver.cpp:228] Iteration 32300, loss = 0.156288
I0809 10:31:57.304956 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:31:57.304971 20451 solver.cpp:244]     Train net output #1: loss = 0.156288 (* 1 = 0.156288 loss)
I0809 10:31:57.304983 20451 sgd_solver.cpp:106] Iteration 32300, lr = 0.000339035
I0809 10:32:19.647735 20451 solver.cpp:228] Iteration 32310, loss = 0.187579
I0809 10:32:19.647786 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:32:19.647800 20451 solver.cpp:244]     Train net output #1: loss = 0.187579 (* 1 = 0.187579 loss)
I0809 10:32:19.647812 20451 sgd_solver.cpp:106] Iteration 32310, lr = 0.000338975
I0809 10:32:41.979980 20451 solver.cpp:228] Iteration 32320, loss = 0.250086
I0809 10:32:41.980080 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:32:41.980096 20451 solver.cpp:244]     Train net output #1: loss = 0.250086 (* 1 = 0.250086 loss)
I0809 10:32:41.980108 20451 sgd_solver.cpp:106] Iteration 32320, lr = 0.000338915
I0809 10:33:04.323470 20451 solver.cpp:228] Iteration 32330, loss = 0.281417
I0809 10:33:04.323516 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:33:04.323536 20451 solver.cpp:244]     Train net output #1: loss = 0.281417 (* 1 = 0.281417 loss)
I0809 10:33:04.323556 20451 sgd_solver.cpp:106] Iteration 32330, lr = 0.000338855
I0809 10:33:26.675115 20451 solver.cpp:228] Iteration 32340, loss = 0.187576
I0809 10:33:26.675411 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:33:26.675485 20451 solver.cpp:244]     Train net output #1: loss = 0.187577 (* 1 = 0.187577 loss)
I0809 10:33:26.675520 20451 sgd_solver.cpp:106] Iteration 32340, lr = 0.000338795
I0809 10:33:49.020421 20451 solver.cpp:228] Iteration 32350, loss = 0.218832
I0809 10:33:49.020464 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:33:49.020483 20451 solver.cpp:244]     Train net output #1: loss = 0.218832 (* 1 = 0.218832 loss)
I0809 10:33:49.020506 20451 sgd_solver.cpp:106] Iteration 32350, lr = 0.000338735
I0809 10:34:11.373065 20451 solver.cpp:228] Iteration 32360, loss = 0.250237
I0809 10:34:11.373175 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:34:11.373195 20451 solver.cpp:244]     Train net output #1: loss = 0.250237 (* 1 = 0.250237 loss)
I0809 10:34:11.373211 20451 sgd_solver.cpp:106] Iteration 32360, lr = 0.000338675
I0809 10:34:33.740190 20451 solver.cpp:228] Iteration 32370, loss = 0.0625764
I0809 10:34:33.740238 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 10:34:33.740257 20451 solver.cpp:244]     Train net output #1: loss = 0.0625767 (* 1 = 0.0625767 loss)
I0809 10:34:33.740272 20451 sgd_solver.cpp:106] Iteration 32370, lr = 0.000338615
I0809 10:34:56.070474 20451 solver.cpp:228] Iteration 32380, loss = 0.125007
I0809 10:34:56.070587 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:34:56.070603 20451 solver.cpp:244]     Train net output #1: loss = 0.125007 (* 1 = 0.125007 loss)
I0809 10:34:56.070616 20451 sgd_solver.cpp:106] Iteration 32380, lr = 0.000338555
I0809 10:35:18.427600 20451 solver.cpp:228] Iteration 32390, loss = 0.156423
I0809 10:35:18.427649 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:35:18.427664 20451 solver.cpp:244]     Train net output #1: loss = 0.156424 (* 1 = 0.156424 loss)
I0809 10:35:18.427676 20451 sgd_solver.cpp:106] Iteration 32390, lr = 0.000338495
I0809 10:35:38.513986 20451 solver.cpp:337] Iteration 32400, Testing net (#0)
I0809 10:35:47.022403 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 10:35:47.022454 20451 solver.cpp:404]     Test net output #1: loss = 0.975059 (* 1 = 0.975059 loss)
I0809 10:35:49.223554 20451 solver.cpp:228] Iteration 32400, loss = 0.187516
I0809 10:35:49.223603 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:35:49.223618 20451 solver.cpp:244]     Train net output #1: loss = 0.187516 (* 1 = 0.187516 loss)
I0809 10:35:49.223630 20451 sgd_solver.cpp:106] Iteration 32400, lr = 0.000338435
I0809 10:36:11.549998 20451 solver.cpp:228] Iteration 32410, loss = 0.0625186
I0809 10:36:11.550180 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 10:36:11.550200 20451 solver.cpp:244]     Train net output #1: loss = 0.0625189 (* 1 = 0.0625189 loss)
I0809 10:36:11.550216 20451 sgd_solver.cpp:106] Iteration 32410, lr = 0.000338375
I0809 10:36:33.874366 20451 solver.cpp:228] Iteration 32420, loss = 0.0937744
I0809 10:36:33.874415 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:36:33.874429 20451 solver.cpp:244]     Train net output #1: loss = 0.0937748 (* 1 = 0.0937748 loss)
I0809 10:36:33.874441 20451 sgd_solver.cpp:106] Iteration 32420, lr = 0.000338316
I0809 10:36:56.174911 20451 solver.cpp:228] Iteration 32430, loss = 0.0625075
I0809 10:36:56.175096 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 10:36:56.175115 20451 solver.cpp:244]     Train net output #1: loss = 0.0625079 (* 1 = 0.0625079 loss)
I0809 10:36:56.175130 20451 sgd_solver.cpp:106] Iteration 32430, lr = 0.000338256
I0809 10:37:18.599438 20451 solver.cpp:228] Iteration 32440, loss = 0.156254
I0809 10:37:18.599478 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:37:18.599493 20451 solver.cpp:244]     Train net output #1: loss = 0.156254 (* 1 = 0.156254 loss)
I0809 10:37:18.599505 20451 sgd_solver.cpp:106] Iteration 32440, lr = 0.000338196
I0809 10:37:40.882522 20451 solver.cpp:228] Iteration 32450, loss = 0.218757
I0809 10:37:40.882740 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:37:40.882755 20451 solver.cpp:244]     Train net output #1: loss = 0.218757 (* 1 = 0.218757 loss)
I0809 10:37:40.882786 20451 sgd_solver.cpp:106] Iteration 32450, lr = 0.000338136
I0809 10:38:03.166290 20451 solver.cpp:228] Iteration 32460, loss = 0.187531
I0809 10:38:03.166340 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:38:03.166354 20451 solver.cpp:244]     Train net output #1: loss = 0.187532 (* 1 = 0.187532 loss)
I0809 10:38:03.166366 20451 sgd_solver.cpp:106] Iteration 32460, lr = 0.000338077
I0809 10:38:25.954386 20451 solver.cpp:228] Iteration 32470, loss = 0.0937532
I0809 10:38:25.954526 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:38:25.954545 20451 solver.cpp:244]     Train net output #1: loss = 0.0937536 (* 1 = 0.0937536 loss)
I0809 10:38:25.954561 20451 sgd_solver.cpp:106] Iteration 32470, lr = 0.000338017
I0809 10:38:48.336932 20451 solver.cpp:228] Iteration 32480, loss = 0.0937748
I0809 10:38:48.336978 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:38:48.337008 20451 solver.cpp:244]     Train net output #1: loss = 0.0937752 (* 1 = 0.0937752 loss)
I0809 10:38:48.337025 20451 sgd_solver.cpp:106] Iteration 32480, lr = 0.000337957
I0809 10:39:10.653326 20451 solver.cpp:228] Iteration 32490, loss = 0.218801
I0809 10:39:10.653496 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:39:10.653511 20451 solver.cpp:244]     Train net output #1: loss = 0.218801 (* 1 = 0.218801 loss)
I0809 10:39:10.653523 20451 sgd_solver.cpp:106] Iteration 32490, lr = 0.000337898
I0809 10:39:30.789801 20451 solver.cpp:337] Iteration 32500, Testing net (#0)
I0809 10:39:39.350890 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 10:39:39.350942 20451 solver.cpp:404]     Test net output #1: loss = 0.993856 (* 1 = 0.993856 loss)
I0809 10:39:41.554791 20451 solver.cpp:228] Iteration 32500, loss = 0.156274
I0809 10:39:41.554966 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:39:41.554981 20451 solver.cpp:244]     Train net output #1: loss = 0.156274 (* 1 = 0.156274 loss)
I0809 10:39:41.554993 20451 sgd_solver.cpp:106] Iteration 32500, lr = 0.000337838
I0809 10:40:03.882699 20451 solver.cpp:228] Iteration 32510, loss = 0.156343
I0809 10:40:03.882750 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:40:03.882766 20451 solver.cpp:244]     Train net output #1: loss = 0.156343 (* 1 = 0.156343 loss)
I0809 10:40:03.882777 20451 sgd_solver.cpp:106] Iteration 32510, lr = 0.000337778
I0809 10:40:26.227756 20451 solver.cpp:228] Iteration 32520, loss = 0.343815
I0809 10:40:26.227934 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 10:40:26.227951 20451 solver.cpp:244]     Train net output #1: loss = 0.343815 (* 1 = 0.343815 loss)
I0809 10:40:26.227963 20451 sgd_solver.cpp:106] Iteration 32520, lr = 0.000337719
I0809 10:40:48.612596 20451 solver.cpp:228] Iteration 32530, loss = 0.125018
I0809 10:40:48.612649 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:40:48.612663 20451 solver.cpp:244]     Train net output #1: loss = 0.125018 (* 1 = 0.125018 loss)
I0809 10:40:48.612675 20451 sgd_solver.cpp:106] Iteration 32530, lr = 0.000337659
I0809 10:41:10.967834 20451 solver.cpp:228] Iteration 32540, loss = 0.187572
I0809 10:41:10.968045 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:41:10.968061 20451 solver.cpp:244]     Train net output #1: loss = 0.187573 (* 1 = 0.187573 loss)
I0809 10:41:10.968075 20451 sgd_solver.cpp:106] Iteration 32540, lr = 0.0003376
I0809 10:41:33.308539 20451 solver.cpp:228] Iteration 32550, loss = 0.062515
I0809 10:41:33.308580 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 10:41:33.308598 20451 solver.cpp:244]     Train net output #1: loss = 0.0625154 (* 1 = 0.0625154 loss)
I0809 10:41:33.308614 20451 sgd_solver.cpp:106] Iteration 32550, lr = 0.00033754
I0809 10:41:55.668238 20451 solver.cpp:228] Iteration 32560, loss = 0.0937571
I0809 10:41:55.668442 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:41:55.668463 20451 solver.cpp:244]     Train net output #1: loss = 0.0937574 (* 1 = 0.0937574 loss)
I0809 10:41:55.668479 20451 sgd_solver.cpp:106] Iteration 32560, lr = 0.000337481
I0809 10:42:18.037231 20451 solver.cpp:228] Iteration 32570, loss = 0.125177
I0809 10:42:18.037281 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:42:18.037295 20451 solver.cpp:244]     Train net output #1: loss = 0.125177 (* 1 = 0.125177 loss)
I0809 10:42:18.037307 20451 sgd_solver.cpp:106] Iteration 32570, lr = 0.000337421
I0809 10:42:40.391587 20451 solver.cpp:228] Iteration 32580, loss = 0.250024
I0809 10:42:40.391829 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:42:40.391906 20451 solver.cpp:244]     Train net output #1: loss = 0.250025 (* 1 = 0.250025 loss)
I0809 10:42:40.391947 20451 sgd_solver.cpp:106] Iteration 32580, lr = 0.000337362
I0809 10:43:02.741997 20451 solver.cpp:228] Iteration 32590, loss = 0.343906
I0809 10:43:02.742038 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 10:43:02.742055 20451 solver.cpp:244]     Train net output #1: loss = 0.343906 (* 1 = 0.343906 loss)
I0809 10:43:02.742081 20451 sgd_solver.cpp:106] Iteration 32590, lr = 0.000337302
I0809 10:43:22.901667 20451 solver.cpp:337] Iteration 32600, Testing net (#0)
I0809 10:43:31.445027 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 10:43:31.445071 20451 solver.cpp:404]     Test net output #1: loss = 1.00337 (* 1 = 1.00337 loss)
I0809 10:43:33.643607 20451 solver.cpp:228] Iteration 32600, loss = 0.375138
I0809 10:43:33.643653 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0809 10:43:33.643668 20451 solver.cpp:244]     Train net output #1: loss = 0.375139 (* 1 = 0.375139 loss)
I0809 10:43:33.643682 20451 sgd_solver.cpp:106] Iteration 32600, lr = 0.000337243
I0809 10:43:55.921192 20451 solver.cpp:228] Iteration 32610, loss = 0.125065
I0809 10:43:55.921288 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:43:55.921303 20451 solver.cpp:244]     Train net output #1: loss = 0.125066 (* 1 = 0.125066 loss)
I0809 10:43:55.921315 20451 sgd_solver.cpp:106] Iteration 32610, lr = 0.000337184
I0809 10:44:18.355779 20451 solver.cpp:228] Iteration 32620, loss = 0.218827
I0809 10:44:18.355834 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:44:18.355849 20451 solver.cpp:244]     Train net output #1: loss = 0.218827 (* 1 = 0.218827 loss)
I0809 10:44:18.355860 20451 sgd_solver.cpp:106] Iteration 32620, lr = 0.000337124
I0809 10:44:40.714128 20451 solver.cpp:228] Iteration 32630, loss = 0.250067
I0809 10:44:40.714277 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:44:40.714318 20451 solver.cpp:244]     Train net output #1: loss = 0.250067 (* 1 = 0.250067 loss)
I0809 10:44:40.714352 20451 sgd_solver.cpp:106] Iteration 32630, lr = 0.000337065
I0809 10:45:03.020673 20451 solver.cpp:228] Iteration 32640, loss = 0.187528
I0809 10:45:03.020723 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:45:03.020737 20451 solver.cpp:244]     Train net output #1: loss = 0.187528 (* 1 = 0.187528 loss)
I0809 10:45:03.020748 20451 sgd_solver.cpp:106] Iteration 32640, lr = 0.000337006
I0809 10:45:25.396950 20451 solver.cpp:228] Iteration 32650, loss = 0.0937668
I0809 10:45:25.397083 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:45:25.397099 20451 solver.cpp:244]     Train net output #1: loss = 0.0937671 (* 1 = 0.0937671 loss)
I0809 10:45:25.397110 20451 sgd_solver.cpp:106] Iteration 32650, lr = 0.000336946
I0809 10:45:47.740043 20451 solver.cpp:228] Iteration 32660, loss = 0.062539
I0809 10:45:47.740083 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 10:45:47.740098 20451 solver.cpp:244]     Train net output #1: loss = 0.0625393 (* 1 = 0.0625393 loss)
I0809 10:45:47.740110 20451 sgd_solver.cpp:106] Iteration 32660, lr = 0.000336887
I0809 10:46:10.065237 20451 solver.cpp:228] Iteration 32670, loss = 0.125051
I0809 10:46:10.065332 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:46:10.065352 20451 solver.cpp:244]     Train net output #1: loss = 0.125051 (* 1 = 0.125051 loss)
I0809 10:46:10.065368 20451 sgd_solver.cpp:106] Iteration 32670, lr = 0.000336828
I0809 10:46:32.401754 20451 solver.cpp:228] Iteration 32680, loss = 0.187541
I0809 10:46:32.401806 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:46:32.401820 20451 solver.cpp:244]     Train net output #1: loss = 0.187542 (* 1 = 0.187542 loss)
I0809 10:46:32.401832 20451 sgd_solver.cpp:106] Iteration 32680, lr = 0.000336769
I0809 10:46:54.718042 20451 solver.cpp:228] Iteration 32690, loss = 0.187574
I0809 10:46:54.718225 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:46:54.718245 20451 solver.cpp:244]     Train net output #1: loss = 0.187575 (* 1 = 0.187575 loss)
I0809 10:46:54.718260 20451 sgd_solver.cpp:106] Iteration 32690, lr = 0.00033671
I0809 10:47:14.813534 20451 solver.cpp:337] Iteration 32700, Testing net (#0)
I0809 10:47:23.328668 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0809 10:47:23.328719 20451 solver.cpp:404]     Test net output #1: loss = 0.965757 (* 1 = 0.965757 loss)
I0809 10:47:25.530437 20451 solver.cpp:228] Iteration 32700, loss = 0.218794
I0809 10:47:25.530539 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:47:25.530553 20451 solver.cpp:244]     Train net output #1: loss = 0.218794 (* 1 = 0.218794 loss)
I0809 10:47:25.530566 20451 sgd_solver.cpp:106] Iteration 32700, lr = 0.00033665
I0809 10:47:47.835738 20451 solver.cpp:228] Iteration 32710, loss = 0.218807
I0809 10:47:47.835790 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:47:47.835804 20451 solver.cpp:244]     Train net output #1: loss = 0.218807 (* 1 = 0.218807 loss)
I0809 10:47:47.835816 20451 sgd_solver.cpp:106] Iteration 32710, lr = 0.000336591
I0809 10:48:10.157593 20451 solver.cpp:228] Iteration 32720, loss = 0.125023
I0809 10:48:10.157779 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:48:10.157794 20451 solver.cpp:244]     Train net output #1: loss = 0.125023 (* 1 = 0.125023 loss)
I0809 10:48:10.157806 20451 sgd_solver.cpp:106] Iteration 32720, lr = 0.000336532
I0809 10:48:32.476430 20451 solver.cpp:228] Iteration 32730, loss = 0.156286
I0809 10:48:32.476482 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:48:32.476496 20451 solver.cpp:244]     Train net output #1: loss = 0.156287 (* 1 = 0.156287 loss)
I0809 10:48:32.476508 20451 sgd_solver.cpp:106] Iteration 32730, lr = 0.000336473
I0809 10:48:54.781317 20451 solver.cpp:228] Iteration 32740, loss = 0.250033
I0809 10:48:54.781492 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:48:54.781507 20451 solver.cpp:244]     Train net output #1: loss = 0.250033 (* 1 = 0.250033 loss)
I0809 10:48:54.781520 20451 sgd_solver.cpp:106] Iteration 32740, lr = 0.000336414
I0809 10:49:17.087110 20451 solver.cpp:228] Iteration 32750, loss = 0.218823
I0809 10:49:17.087160 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:49:17.087175 20451 solver.cpp:244]     Train net output #1: loss = 0.218824 (* 1 = 0.218824 loss)
I0809 10:49:17.087188 20451 sgd_solver.cpp:106] Iteration 32750, lr = 0.000336355
I0809 10:49:39.395473 20451 solver.cpp:228] Iteration 32760, loss = 0.187601
I0809 10:49:39.395691 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:49:39.395707 20451 solver.cpp:244]     Train net output #1: loss = 0.187601 (* 1 = 0.187601 loss)
I0809 10:49:39.395720 20451 sgd_solver.cpp:106] Iteration 32760, lr = 0.000336296
I0809 10:50:01.743238 20451 solver.cpp:228] Iteration 32770, loss = 0.156293
I0809 10:50:01.743294 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:50:01.743312 20451 solver.cpp:244]     Train net output #1: loss = 0.156293 (* 1 = 0.156293 loss)
I0809 10:50:01.743325 20451 sgd_solver.cpp:106] Iteration 32770, lr = 0.000336237
I0809 10:50:24.087590 20451 solver.cpp:228] Iteration 32780, loss = 0.281297
I0809 10:50:24.087689 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 10:50:24.087705 20451 solver.cpp:244]     Train net output #1: loss = 0.281298 (* 1 = 0.281298 loss)
I0809 10:50:24.087718 20451 sgd_solver.cpp:106] Iteration 32780, lr = 0.000336178
I0809 10:50:46.424113 20451 solver.cpp:228] Iteration 32790, loss = 0.0625051
I0809 10:50:46.424163 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 10:50:46.424177 20451 solver.cpp:244]     Train net output #1: loss = 0.0625054 (* 1 = 0.0625054 loss)
I0809 10:50:46.424190 20451 sgd_solver.cpp:106] Iteration 32790, lr = 0.000336119
I0809 10:51:06.544651 20451 solver.cpp:337] Iteration 32800, Testing net (#0)
I0809 10:51:15.072873 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0809 10:51:15.072968 20451 solver.cpp:404]     Test net output #1: loss = 1.03164 (* 1 = 1.03164 loss)
I0809 10:51:17.278894 20451 solver.cpp:228] Iteration 32800, loss = 0.156338
I0809 10:51:17.278945 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:51:17.278959 20451 solver.cpp:244]     Train net output #1: loss = 0.156338 (* 1 = 0.156338 loss)
I0809 10:51:17.278970 20451 sgd_solver.cpp:106] Iteration 32800, lr = 0.00033606
I0809 10:51:39.614823 20451 solver.cpp:228] Iteration 32810, loss = 0.187555
I0809 10:51:39.614928 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:51:39.614943 20451 solver.cpp:244]     Train net output #1: loss = 0.187555 (* 1 = 0.187555 loss)
I0809 10:51:39.614954 20451 sgd_solver.cpp:106] Iteration 32810, lr = 0.000336001
I0809 10:52:01.969069 20451 solver.cpp:228] Iteration 32820, loss = 0.218875
I0809 10:52:01.969120 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:52:01.969133 20451 solver.cpp:244]     Train net output #1: loss = 0.218876 (* 1 = 0.218876 loss)
I0809 10:52:01.969146 20451 sgd_solver.cpp:106] Iteration 32820, lr = 0.000335943
I0809 10:52:24.287811 20451 solver.cpp:228] Iteration 32830, loss = 0.125019
I0809 10:52:24.287987 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 10:52:24.288002 20451 solver.cpp:244]     Train net output #1: loss = 0.125019 (* 1 = 0.125019 loss)
I0809 10:52:24.288017 20451 sgd_solver.cpp:106] Iteration 32830, lr = 0.000335884
I0809 10:52:46.620148 20451 solver.cpp:228] Iteration 32840, loss = 0.281386
I0809 10:52:46.620193 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:52:46.620218 20451 solver.cpp:244]     Train net output #1: loss = 0.281386 (* 1 = 0.281386 loss)
I0809 10:52:46.620235 20451 sgd_solver.cpp:106] Iteration 32840, lr = 0.000335825
I0809 10:53:08.944819 20451 solver.cpp:228] Iteration 32850, loss = 0.0625089
I0809 10:53:08.944993 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 10:53:08.945008 20451 solver.cpp:244]     Train net output #1: loss = 0.0625092 (* 1 = 0.0625092 loss)
I0809 10:53:08.945020 20451 sgd_solver.cpp:106] Iteration 32850, lr = 0.000335766
I0809 10:53:31.267244 20451 solver.cpp:228] Iteration 32860, loss = 0.187524
I0809 10:53:31.267302 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:53:31.267318 20451 solver.cpp:244]     Train net output #1: loss = 0.187524 (* 1 = 0.187524 loss)
I0809 10:53:31.267328 20451 sgd_solver.cpp:106] Iteration 32860, lr = 0.000335707
I0809 10:53:53.695080 20451 solver.cpp:228] Iteration 32870, loss = 0.187631
I0809 10:53:53.695216 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:53:53.695235 20451 solver.cpp:244]     Train net output #1: loss = 0.187631 (* 1 = 0.187631 loss)
I0809 10:53:53.695250 20451 sgd_solver.cpp:106] Iteration 32870, lr = 0.000335649
I0809 10:54:16.314959 20451 solver.cpp:228] Iteration 32880, loss = 0.187507
I0809 10:54:16.315011 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:54:16.315026 20451 solver.cpp:244]     Train net output #1: loss = 0.187507 (* 1 = 0.187507 loss)
I0809 10:54:16.315037 20451 sgd_solver.cpp:106] Iteration 32880, lr = 0.00033559
I0809 10:54:38.955417 20451 solver.cpp:228] Iteration 32890, loss = 0.187523
I0809 10:54:38.955596 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 10:54:38.955610 20451 solver.cpp:244]     Train net output #1: loss = 0.187524 (* 1 = 0.187524 loss)
I0809 10:54:38.955623 20451 sgd_solver.cpp:106] Iteration 32890, lr = 0.000335531
I0809 10:54:59.323376 20451 solver.cpp:337] Iteration 32900, Testing net (#0)
I0809 10:55:07.862944 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 10:55:07.862995 20451 solver.cpp:404]     Test net output #1: loss = 1.00324 (* 1 = 1.00324 loss)
I0809 10:55:10.061420 20451 solver.cpp:228] Iteration 32900, loss = 0.0937658
I0809 10:55:10.061540 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:55:10.061561 20451 solver.cpp:244]     Train net output #1: loss = 0.0937661 (* 1 = 0.0937661 loss)
I0809 10:55:10.061576 20451 sgd_solver.cpp:106] Iteration 32900, lr = 0.000335473
I0809 10:55:32.355880 20451 solver.cpp:228] Iteration 32910, loss = 0.187541
I0809 10:55:32.355931 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:55:32.355945 20451 solver.cpp:244]     Train net output #1: loss = 0.187541 (* 1 = 0.187541 loss)
I0809 10:55:32.355957 20451 sgd_solver.cpp:106] Iteration 32910, lr = 0.000335414
I0809 10:55:54.644608 20451 solver.cpp:228] Iteration 32920, loss = 0.156463
I0809 10:55:54.644788 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:55:54.644803 20451 solver.cpp:244]     Train net output #1: loss = 0.156463 (* 1 = 0.156463 loss)
I0809 10:55:54.644815 20451 sgd_solver.cpp:106] Iteration 32920, lr = 0.000335355
I0809 10:56:16.928921 20451 solver.cpp:228] Iteration 32930, loss = 0.187614
I0809 10:56:16.928962 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:56:16.928978 20451 solver.cpp:244]     Train net output #1: loss = 0.187615 (* 1 = 0.187615 loss)
I0809 10:56:16.928990 20451 sgd_solver.cpp:106] Iteration 32930, lr = 0.000335297
I0809 10:56:39.230767 20451 solver.cpp:228] Iteration 32940, loss = 0.218766
I0809 10:56:39.230952 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:56:39.230967 20451 solver.cpp:244]     Train net output #1: loss = 0.218766 (* 1 = 0.218766 loss)
I0809 10:56:39.230979 20451 sgd_solver.cpp:106] Iteration 32940, lr = 0.000335238
I0809 10:57:01.530410 20451 solver.cpp:228] Iteration 32950, loss = 0.187554
I0809 10:57:01.530450 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:57:01.530467 20451 solver.cpp:244]     Train net output #1: loss = 0.187554 (* 1 = 0.187554 loss)
I0809 10:57:01.530478 20451 sgd_solver.cpp:106] Iteration 32950, lr = 0.00033518
I0809 10:57:23.882113 20451 solver.cpp:228] Iteration 32960, loss = 0.187502
I0809 10:57:23.882303 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 10:57:23.882323 20451 solver.cpp:244]     Train net output #1: loss = 0.187503 (* 1 = 0.187503 loss)
I0809 10:57:23.882338 20451 sgd_solver.cpp:106] Iteration 32960, lr = 0.000335121
I0809 10:57:46.178586 20451 solver.cpp:228] Iteration 32970, loss = 0.0625406
I0809 10:57:46.178638 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 10:57:46.178653 20451 solver.cpp:244]     Train net output #1: loss = 0.0625409 (* 1 = 0.0625409 loss)
I0809 10:57:46.178664 20451 sgd_solver.cpp:106] Iteration 32970, lr = 0.000335063
I0809 10:58:08.570147 20451 solver.cpp:228] Iteration 32980, loss = 0.281344
I0809 10:58:08.570370 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 10:58:08.570389 20451 solver.cpp:244]     Train net output #1: loss = 0.281344 (* 1 = 0.281344 loss)
I0809 10:58:08.570405 20451 sgd_solver.cpp:106] Iteration 32980, lr = 0.000335004
I0809 10:58:31.139367 20451 solver.cpp:228] Iteration 32990, loss = 0.250301
I0809 10:58:31.139410 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 10:58:31.139426 20451 solver.cpp:244]     Train net output #1: loss = 0.250301 (* 1 = 0.250301 loss)
I0809 10:58:31.139441 20451 sgd_solver.cpp:106] Iteration 32990, lr = 0.000334946
I0809 10:58:51.224659 20451 solver.cpp:337] Iteration 33000, Testing net (#0)
I0809 10:58:59.741421 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 10:58:59.741462 20451 solver.cpp:404]     Test net output #1: loss = 0.984581 (* 1 = 0.984581 loss)
I0809 10:59:01.941653 20451 solver.cpp:228] Iteration 33000, loss = 0.218818
I0809 10:59:01.941707 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 10:59:01.941720 20451 solver.cpp:244]     Train net output #1: loss = 0.218818 (* 1 = 0.218818 loss)
I0809 10:59:01.941733 20451 sgd_solver.cpp:106] Iteration 33000, lr = 0.000334887
I0809 10:59:24.255223 20451 solver.cpp:228] Iteration 33010, loss = 0.0938447
I0809 10:59:24.255400 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 10:59:24.255416 20451 solver.cpp:244]     Train net output #1: loss = 0.093845 (* 1 = 0.093845 loss)
I0809 10:59:24.255429 20451 sgd_solver.cpp:106] Iteration 33010, lr = 0.000334829
I0809 10:59:46.863405 20451 solver.cpp:228] Iteration 33020, loss = 0.156287
I0809 10:59:46.863457 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 10:59:46.863471 20451 solver.cpp:244]     Train net output #1: loss = 0.156287 (* 1 = 0.156287 loss)
I0809 10:59:46.863483 20451 sgd_solver.cpp:106] Iteration 33020, lr = 0.000334771
I0809 11:00:09.202770 20451 solver.cpp:228] Iteration 33030, loss = 0.187579
I0809 11:00:09.202957 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:00:09.202976 20451 solver.cpp:244]     Train net output #1: loss = 0.18758 (* 1 = 0.18758 loss)
I0809 11:00:09.202992 20451 sgd_solver.cpp:106] Iteration 33030, lr = 0.000334712
I0809 11:00:31.500679 20451 solver.cpp:228] Iteration 33040, loss = 0.156478
I0809 11:00:31.500735 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:00:31.500749 20451 solver.cpp:244]     Train net output #1: loss = 0.156478 (* 1 = 0.156478 loss)
I0809 11:00:31.500761 20451 sgd_solver.cpp:106] Iteration 33040, lr = 0.000334654
I0809 11:00:53.810957 20451 solver.cpp:228] Iteration 33050, loss = 0.218805
I0809 11:00:53.811053 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:00:53.811071 20451 solver.cpp:244]     Train net output #1: loss = 0.218805 (* 1 = 0.218805 loss)
I0809 11:00:53.811085 20451 sgd_solver.cpp:106] Iteration 33050, lr = 0.000334596
I0809 11:01:16.099083 20451 solver.cpp:228] Iteration 33060, loss = 0.250041
I0809 11:01:16.099134 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:01:16.099148 20451 solver.cpp:244]     Train net output #1: loss = 0.250041 (* 1 = 0.250041 loss)
I0809 11:01:16.099160 20451 sgd_solver.cpp:106] Iteration 33060, lr = 0.000334537
I0809 11:01:38.389179 20451 solver.cpp:228] Iteration 33070, loss = 0.187507
I0809 11:01:38.389302 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:01:38.389322 20451 solver.cpp:244]     Train net output #1: loss = 0.187507 (* 1 = 0.187507 loss)
I0809 11:01:38.389338 20451 sgd_solver.cpp:106] Iteration 33070, lr = 0.000334479
I0809 11:02:00.678333 20451 solver.cpp:228] Iteration 33080, loss = 0.156257
I0809 11:02:00.678382 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:02:00.678396 20451 solver.cpp:244]     Train net output #1: loss = 0.156258 (* 1 = 0.156258 loss)
I0809 11:02:00.678409 20451 sgd_solver.cpp:106] Iteration 33080, lr = 0.000334421
I0809 11:02:22.978055 20451 solver.cpp:228] Iteration 33090, loss = 0.218797
I0809 11:02:22.978268 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:02:22.978287 20451 solver.cpp:244]     Train net output #1: loss = 0.218797 (* 1 = 0.218797 loss)
I0809 11:02:22.978302 20451 sgd_solver.cpp:106] Iteration 33090, lr = 0.000334363
I0809 11:02:43.099982 20451 solver.cpp:337] Iteration 33100, Testing net (#0)
I0809 11:02:51.640208 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 11:02:51.640249 20451 solver.cpp:404]     Test net output #1: loss = 0.998506 (* 1 = 0.998506 loss)
I0809 11:02:53.840222 20451 solver.cpp:228] Iteration 33100, loss = 0.218773
I0809 11:02:53.840396 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:02:53.840411 20451 solver.cpp:244]     Train net output #1: loss = 0.218773 (* 1 = 0.218773 loss)
I0809 11:02:53.840425 20451 sgd_solver.cpp:106] Iteration 33100, lr = 0.000334304
I0809 11:03:16.149114 20451 solver.cpp:228] Iteration 33110, loss = 0.187555
I0809 11:03:16.149154 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:03:16.149169 20451 solver.cpp:244]     Train net output #1: loss = 0.187555 (* 1 = 0.187555 loss)
I0809 11:03:16.149181 20451 sgd_solver.cpp:106] Iteration 33110, lr = 0.000334246
I0809 11:03:38.507252 20451 solver.cpp:228] Iteration 33120, loss = 0.156454
I0809 11:03:38.507351 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:03:38.507366 20451 solver.cpp:244]     Train net output #1: loss = 0.156454 (* 1 = 0.156454 loss)
I0809 11:03:38.507378 20451 sgd_solver.cpp:106] Iteration 33120, lr = 0.000334188
I0809 11:04:00.817668 20451 solver.cpp:228] Iteration 33130, loss = 0.21893
I0809 11:04:00.817718 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:04:00.817733 20451 solver.cpp:244]     Train net output #1: loss = 0.21893 (* 1 = 0.21893 loss)
I0809 11:04:00.817744 20451 sgd_solver.cpp:106] Iteration 33130, lr = 0.00033413
I0809 11:04:23.714951 20451 solver.cpp:228] Iteration 33140, loss = 0.156394
I0809 11:04:23.715054 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:04:23.715073 20451 solver.cpp:244]     Train net output #1: loss = 0.156394 (* 1 = 0.156394 loss)
I0809 11:04:23.715088 20451 sgd_solver.cpp:106] Iteration 33140, lr = 0.000334072
I0809 11:04:46.113948 20451 solver.cpp:228] Iteration 33150, loss = 0.0625493
I0809 11:04:46.113992 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 11:04:46.114012 20451 solver.cpp:244]     Train net output #1: loss = 0.0625496 (* 1 = 0.0625496 loss)
I0809 11:04:46.114027 20451 sgd_solver.cpp:106] Iteration 33150, lr = 0.000334014
I0809 11:05:08.419229 20451 solver.cpp:228] Iteration 33160, loss = 0.187584
I0809 11:05:08.419410 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:05:08.419426 20451 solver.cpp:244]     Train net output #1: loss = 0.187584 (* 1 = 0.187584 loss)
I0809 11:05:08.419440 20451 sgd_solver.cpp:106] Iteration 33160, lr = 0.000333956
I0809 11:05:30.826053 20451 solver.cpp:228] Iteration 33170, loss = 0.15635
I0809 11:05:30.826107 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:05:30.826120 20451 solver.cpp:244]     Train net output #1: loss = 0.15635 (* 1 = 0.15635 loss)
I0809 11:05:30.826133 20451 sgd_solver.cpp:106] Iteration 33170, lr = 0.000333898
I0809 11:05:53.269078 20451 solver.cpp:228] Iteration 33180, loss = 0.156268
I0809 11:05:53.269258 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:05:53.269273 20451 solver.cpp:244]     Train net output #1: loss = 0.156268 (* 1 = 0.156268 loss)
I0809 11:05:53.269286 20451 sgd_solver.cpp:106] Iteration 33180, lr = 0.00033384
I0809 11:06:15.618783 20451 solver.cpp:228] Iteration 33190, loss = 0.187559
I0809 11:06:15.618837 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:06:15.618852 20451 solver.cpp:244]     Train net output #1: loss = 0.187559 (* 1 = 0.187559 loss)
I0809 11:06:15.618865 20451 sgd_solver.cpp:106] Iteration 33190, lr = 0.000333782
I0809 11:06:35.678967 20451 solver.cpp:337] Iteration 33200, Testing net (#0)
I0809 11:06:44.384234 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 11:06:44.384285 20451 solver.cpp:404]     Test net output #1: loss = 0.999282 (* 1 = 0.999282 loss)
I0809 11:06:46.659970 20451 solver.cpp:228] Iteration 33200, loss = 0.0312892
I0809 11:06:46.660015 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 11:06:46.660033 20451 solver.cpp:244]     Train net output #1: loss = 0.0312895 (* 1 = 0.0312895 loss)
I0809 11:06:46.660048 20451 sgd_solver.cpp:106] Iteration 33200, lr = 0.000333724
I0809 11:07:09.446835 20451 solver.cpp:228] Iteration 33210, loss = 0.156477
I0809 11:07:09.447057 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:07:09.447075 20451 solver.cpp:244]     Train net output #1: loss = 0.156478 (* 1 = 0.156478 loss)
I0809 11:07:09.447090 20451 sgd_solver.cpp:106] Iteration 33210, lr = 0.000333666
I0809 11:07:31.741209 20451 solver.cpp:228] Iteration 33220, loss = 0.125014
I0809 11:07:31.741257 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:07:31.741276 20451 solver.cpp:244]     Train net output #1: loss = 0.125015 (* 1 = 0.125015 loss)
I0809 11:07:31.741291 20451 sgd_solver.cpp:106] Iteration 33220, lr = 0.000333608
I0809 11:07:54.034559 20451 solver.cpp:228] Iteration 33230, loss = 0.0937715
I0809 11:07:54.034739 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 11:07:54.034757 20451 solver.cpp:244]     Train net output #1: loss = 0.0937718 (* 1 = 0.0937718 loss)
I0809 11:07:54.034772 20451 sgd_solver.cpp:106] Iteration 33230, lr = 0.00033355
I0809 11:08:16.520789 20451 solver.cpp:228] Iteration 33240, loss = 0.312548
I0809 11:08:16.520838 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 11:08:16.520853 20451 solver.cpp:244]     Train net output #1: loss = 0.312548 (* 1 = 0.312548 loss)
I0809 11:08:16.520864 20451 sgd_solver.cpp:106] Iteration 33240, lr = 0.000333492
I0809 11:08:38.861722 20451 solver.cpp:228] Iteration 33250, loss = 0.093773
I0809 11:08:38.861901 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 11:08:38.861915 20451 solver.cpp:244]     Train net output #1: loss = 0.0937733 (* 1 = 0.0937733 loss)
I0809 11:08:38.861928 20451 sgd_solver.cpp:106] Iteration 33250, lr = 0.000333434
I0809 11:09:01.177673 20451 solver.cpp:228] Iteration 33260, loss = 0.18769
I0809 11:09:01.177726 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:09:01.177739 20451 solver.cpp:244]     Train net output #1: loss = 0.18769 (* 1 = 0.18769 loss)
I0809 11:09:01.177752 20451 sgd_solver.cpp:106] Iteration 33260, lr = 0.000333377
I0809 11:09:23.493402 20451 solver.cpp:228] Iteration 33270, loss = 0.156314
I0809 11:09:23.493500 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:09:23.493515 20451 solver.cpp:244]     Train net output #1: loss = 0.156314 (* 1 = 0.156314 loss)
I0809 11:09:23.493528 20451 sgd_solver.cpp:106] Iteration 33270, lr = 0.000333319
I0809 11:09:45.802621 20451 solver.cpp:228] Iteration 33280, loss = 0.312524
I0809 11:09:45.802675 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 11:09:45.802688 20451 solver.cpp:244]     Train net output #1: loss = 0.312525 (* 1 = 0.312525 loss)
I0809 11:09:45.802700 20451 sgd_solver.cpp:106] Iteration 33280, lr = 0.000333261
I0809 11:10:08.111876 20451 solver.cpp:228] Iteration 33290, loss = 0.250015
I0809 11:10:08.112045 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:10:08.112059 20451 solver.cpp:244]     Train net output #1: loss = 0.250015 (* 1 = 0.250015 loss)
I0809 11:10:08.112072 20451 sgd_solver.cpp:106] Iteration 33290, lr = 0.000333203
I0809 11:10:28.182193 20451 solver.cpp:337] Iteration 33300, Testing net (#0)
I0809 11:10:36.699542 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 11:10:36.699587 20451 solver.cpp:404]     Test net output #1: loss = 1.00791 (* 1 = 1.00791 loss)
I0809 11:10:38.906007 20451 solver.cpp:228] Iteration 33300, loss = 0.156271
I0809 11:10:38.906224 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:10:38.906241 20451 solver.cpp:244]     Train net output #1: loss = 0.156272 (* 1 = 0.156272 loss)
I0809 11:10:38.906253 20451 sgd_solver.cpp:106] Iteration 33300, lr = 0.000333146
I0809 11:11:01.210552 20451 solver.cpp:228] Iteration 33310, loss = 0.312529
I0809 11:11:01.210603 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 11:11:01.210618 20451 solver.cpp:244]     Train net output #1: loss = 0.31253 (* 1 = 0.31253 loss)
I0809 11:11:01.210629 20451 sgd_solver.cpp:106] Iteration 33310, lr = 0.000333088
I0809 11:11:23.539011 20451 solver.cpp:228] Iteration 33320, loss = 0.28144
I0809 11:11:23.539188 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 11:11:23.539203 20451 solver.cpp:244]     Train net output #1: loss = 0.28144 (* 1 = 0.28144 loss)
I0809 11:11:23.539216 20451 sgd_solver.cpp:106] Iteration 33320, lr = 0.00033303
I0809 11:11:45.840577 20451 solver.cpp:228] Iteration 33330, loss = 0.125056
I0809 11:11:45.840631 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:11:45.840646 20451 solver.cpp:244]     Train net output #1: loss = 0.125056 (* 1 = 0.125056 loss)
I0809 11:11:45.840657 20451 sgd_solver.cpp:106] Iteration 33330, lr = 0.000332973
I0809 11:12:08.148360 20451 solver.cpp:228] Iteration 33340, loss = 0.28133
I0809 11:12:08.148542 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 11:12:08.148557 20451 solver.cpp:244]     Train net output #1: loss = 0.28133 (* 1 = 0.28133 loss)
I0809 11:12:08.148571 20451 sgd_solver.cpp:106] Iteration 33340, lr = 0.000332915
I0809 11:12:30.457506 20451 solver.cpp:228] Iteration 33350, loss = 0.187646
I0809 11:12:30.457557 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:12:30.457571 20451 solver.cpp:244]     Train net output #1: loss = 0.187647 (* 1 = 0.187647 loss)
I0809 11:12:30.457583 20451 sgd_solver.cpp:106] Iteration 33350, lr = 0.000332857
I0809 11:12:52.764889 20451 solver.cpp:228] Iteration 33360, loss = 0.375189
I0809 11:12:52.764991 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0809 11:12:52.765010 20451 solver.cpp:244]     Train net output #1: loss = 0.375189 (* 1 = 0.375189 loss)
I0809 11:12:52.765025 20451 sgd_solver.cpp:106] Iteration 33360, lr = 0.0003328
I0809 11:13:15.080129 20451 solver.cpp:228] Iteration 33370, loss = 0.40628
I0809 11:13:15.080178 20451 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0809 11:13:15.080193 20451 solver.cpp:244]     Train net output #1: loss = 0.40628 (* 1 = 0.40628 loss)
I0809 11:13:15.080205 20451 sgd_solver.cpp:106] Iteration 33370, lr = 0.000332742
I0809 11:13:37.385102 20451 solver.cpp:228] Iteration 33380, loss = 0.156303
I0809 11:13:37.385270 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:13:37.385285 20451 solver.cpp:244]     Train net output #1: loss = 0.156304 (* 1 = 0.156304 loss)
I0809 11:13:37.385298 20451 sgd_solver.cpp:106] Iteration 33380, lr = 0.000332685
I0809 11:13:59.693717 20451 solver.cpp:228] Iteration 33390, loss = 0.281377
I0809 11:13:59.693768 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 11:13:59.693780 20451 solver.cpp:244]     Train net output #1: loss = 0.281377 (* 1 = 0.281377 loss)
I0809 11:13:59.693792 20451 sgd_solver.cpp:106] Iteration 33390, lr = 0.000332627
I0809 11:14:19.801996 20451 solver.cpp:337] Iteration 33400, Testing net (#0)
I0809 11:14:28.329825 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 11:14:28.329877 20451 solver.cpp:404]     Test net output #1: loss = 1.00326 (* 1 = 1.00326 loss)
I0809 11:14:30.532436 20451 solver.cpp:228] Iteration 33400, loss = 0.218792
I0809 11:14:30.532480 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:14:30.532495 20451 solver.cpp:244]     Train net output #1: loss = 0.218792 (* 1 = 0.218792 loss)
I0809 11:14:30.532507 20451 sgd_solver.cpp:106] Iteration 33400, lr = 0.00033257
I0809 11:14:52.861624 20451 solver.cpp:228] Iteration 33410, loss = 0.218844
I0809 11:14:52.861766 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:14:52.861783 20451 solver.cpp:244]     Train net output #1: loss = 0.218844 (* 1 = 0.218844 loss)
I0809 11:14:52.861796 20451 sgd_solver.cpp:106] Iteration 33410, lr = 0.000332512
I0809 11:15:15.198416 20451 solver.cpp:228] Iteration 33420, loss = 0.281344
I0809 11:15:15.198462 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 11:15:15.198480 20451 solver.cpp:244]     Train net output #1: loss = 0.281344 (* 1 = 0.281344 loss)
I0809 11:15:15.198495 20451 sgd_solver.cpp:106] Iteration 33420, lr = 0.000332455
I0809 11:15:37.532431 20451 solver.cpp:228] Iteration 33430, loss = 0.12506
I0809 11:15:37.532557 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:15:37.532575 20451 solver.cpp:244]     Train net output #1: loss = 0.125061 (* 1 = 0.125061 loss)
I0809 11:15:37.532591 20451 sgd_solver.cpp:106] Iteration 33430, lr = 0.000332397
I0809 11:15:59.862776 20451 solver.cpp:228] Iteration 33440, loss = 0.0937741
I0809 11:15:59.862828 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 11:15:59.862841 20451 solver.cpp:244]     Train net output #1: loss = 0.0937744 (* 1 = 0.0937744 loss)
I0809 11:15:59.862854 20451 sgd_solver.cpp:106] Iteration 33440, lr = 0.00033234
I0809 11:16:22.173310 20451 solver.cpp:228] Iteration 33450, loss = 0.125041
I0809 11:16:22.173415 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:16:22.173434 20451 solver.cpp:244]     Train net output #1: loss = 0.125042 (* 1 = 0.125042 loss)
I0809 11:16:22.173450 20451 sgd_solver.cpp:106] Iteration 33450, lr = 0.000332283
I0809 11:16:44.503897 20451 solver.cpp:228] Iteration 33460, loss = 0.218804
I0809 11:16:44.503942 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:16:44.503968 20451 solver.cpp:244]     Train net output #1: loss = 0.218804 (* 1 = 0.218804 loss)
I0809 11:16:44.503984 20451 sgd_solver.cpp:106] Iteration 33460, lr = 0.000332225
I0809 11:17:06.852128 20451 solver.cpp:228] Iteration 33470, loss = 0.250078
I0809 11:17:06.852442 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:17:06.852458 20451 solver.cpp:244]     Train net output #1: loss = 0.250078 (* 1 = 0.250078 loss)
I0809 11:17:06.852470 20451 sgd_solver.cpp:106] Iteration 33470, lr = 0.000332168
I0809 11:17:29.184840 20451 solver.cpp:228] Iteration 33480, loss = 0.218836
I0809 11:17:29.184890 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:17:29.184905 20451 solver.cpp:244]     Train net output #1: loss = 0.218836 (* 1 = 0.218836 loss)
I0809 11:17:29.184916 20451 sgd_solver.cpp:106] Iteration 33480, lr = 0.000332111
I0809 11:17:51.494882 20451 solver.cpp:228] Iteration 33490, loss = 0.156441
I0809 11:17:51.495057 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:17:51.495072 20451 solver.cpp:244]     Train net output #1: loss = 0.156442 (* 1 = 0.156442 loss)
I0809 11:17:51.495085 20451 sgd_solver.cpp:106] Iteration 33490, lr = 0.000332053
I0809 11:18:11.592514 20451 solver.cpp:337] Iteration 33500, Testing net (#0)
I0809 11:18:20.137348 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0809 11:18:20.137398 20451 solver.cpp:404]     Test net output #1: loss = 0.961017 (* 1 = 0.961017 loss)
I0809 11:18:22.337702 20451 solver.cpp:228] Iteration 33500, loss = 0.25003
I0809 11:18:22.337879 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:18:22.337894 20451 solver.cpp:244]     Train net output #1: loss = 0.25003 (* 1 = 0.25003 loss)
I0809 11:18:22.337908 20451 sgd_solver.cpp:106] Iteration 33500, lr = 0.000331996
I0809 11:18:44.690968 20451 solver.cpp:228] Iteration 33510, loss = 0.0625035
I0809 11:18:44.691009 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 11:18:44.691026 20451 solver.cpp:244]     Train net output #1: loss = 0.0625037 (* 1 = 0.0625037 loss)
I0809 11:18:44.691041 20451 sgd_solver.cpp:106] Iteration 33510, lr = 0.000331939
I0809 11:19:07.023216 20451 solver.cpp:228] Iteration 33520, loss = 0.125081
I0809 11:19:07.023363 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:19:07.023381 20451 solver.cpp:244]     Train net output #1: loss = 0.125081 (* 1 = 0.125081 loss)
I0809 11:19:07.023396 20451 sgd_solver.cpp:106] Iteration 33520, lr = 0.000331882
I0809 11:19:29.361593 20451 solver.cpp:228] Iteration 33530, loss = 0.250167
I0809 11:19:29.361644 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:19:29.361659 20451 solver.cpp:244]     Train net output #1: loss = 0.250167 (* 1 = 0.250167 loss)
I0809 11:19:29.361671 20451 sgd_solver.cpp:106] Iteration 33530, lr = 0.000331825
I0809 11:19:51.694650 20451 solver.cpp:228] Iteration 33540, loss = 0.156428
I0809 11:19:51.694831 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:19:51.694847 20451 solver.cpp:244]     Train net output #1: loss = 0.156428 (* 1 = 0.156428 loss)
I0809 11:19:51.694860 20451 sgd_solver.cpp:106] Iteration 33540, lr = 0.000331767
I0809 11:20:14.048739 20451 solver.cpp:228] Iteration 33550, loss = 0.156299
I0809 11:20:14.048799 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:20:14.048815 20451 solver.cpp:244]     Train net output #1: loss = 0.1563 (* 1 = 0.1563 loss)
I0809 11:20:14.048830 20451 sgd_solver.cpp:106] Iteration 33550, lr = 0.00033171
I0809 11:20:36.486927 20451 solver.cpp:228] Iteration 33560, loss = 0.0625618
I0809 11:20:36.487107 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 11:20:36.487123 20451 solver.cpp:244]     Train net output #1: loss = 0.0625621 (* 1 = 0.0625621 loss)
I0809 11:20:36.487135 20451 sgd_solver.cpp:106] Iteration 33560, lr = 0.000331653
I0809 11:20:58.803023 20451 solver.cpp:228] Iteration 33570, loss = 0.218859
I0809 11:20:58.803068 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:20:58.803086 20451 solver.cpp:244]     Train net output #1: loss = 0.21886 (* 1 = 0.21886 loss)
I0809 11:20:58.803103 20451 sgd_solver.cpp:106] Iteration 33570, lr = 0.000331596
I0809 11:21:21.134294 20451 solver.cpp:228] Iteration 33580, loss = 0.156331
I0809 11:21:21.134460 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:21:21.134480 20451 solver.cpp:244]     Train net output #1: loss = 0.156332 (* 1 = 0.156332 loss)
I0809 11:21:21.134492 20451 sgd_solver.cpp:106] Iteration 33580, lr = 0.000331539
I0809 11:21:43.480690 20451 solver.cpp:228] Iteration 33590, loss = 0.0625388
I0809 11:21:43.480744 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 11:21:43.480762 20451 solver.cpp:244]     Train net output #1: loss = 0.062539 (* 1 = 0.062539 loss)
I0809 11:21:43.480778 20451 sgd_solver.cpp:106] Iteration 33590, lr = 0.000331482
I0809 11:22:03.570601 20451 solver.cpp:337] Iteration 33600, Testing net (#0)
I0809 11:22:12.100495 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 11:22:12.100549 20451 solver.cpp:404]     Test net output #1: loss = 0.993816 (* 1 = 0.993816 loss)
I0809 11:22:14.302165 20451 solver.cpp:228] Iteration 33600, loss = 0.156265
I0809 11:22:14.302217 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:22:14.302229 20451 solver.cpp:244]     Train net output #1: loss = 0.156265 (* 1 = 0.156265 loss)
I0809 11:22:14.302242 20451 sgd_solver.cpp:106] Iteration 33600, lr = 0.000331425
I0809 11:22:36.631857 20451 solver.cpp:228] Iteration 33610, loss = 0.125008
I0809 11:22:36.631965 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:22:36.631980 20451 solver.cpp:244]     Train net output #1: loss = 0.125009 (* 1 = 0.125009 loss)
I0809 11:22:36.631994 20451 sgd_solver.cpp:106] Iteration 33610, lr = 0.000331368
I0809 11:22:58.978240 20451 solver.cpp:228] Iteration 33620, loss = 0.218773
I0809 11:22:58.978284 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:22:58.978301 20451 solver.cpp:244]     Train net output #1: loss = 0.218773 (* 1 = 0.218773 loss)
I0809 11:22:58.978312 20451 sgd_solver.cpp:106] Iteration 33620, lr = 0.000331311
I0809 11:23:21.324015 20451 solver.cpp:228] Iteration 33630, loss = 0.156287
I0809 11:23:21.324170 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:23:21.324185 20451 solver.cpp:244]     Train net output #1: loss = 0.156287 (* 1 = 0.156287 loss)
I0809 11:23:21.324198 20451 sgd_solver.cpp:106] Iteration 33630, lr = 0.000331254
I0809 11:23:43.658027 20451 solver.cpp:228] Iteration 33640, loss = 0.125056
I0809 11:23:43.658077 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:23:43.658090 20451 solver.cpp:244]     Train net output #1: loss = 0.125057 (* 1 = 0.125057 loss)
I0809 11:23:43.658102 20451 sgd_solver.cpp:106] Iteration 33640, lr = 0.000331197
I0809 11:24:05.992738 20451 solver.cpp:228] Iteration 33650, loss = 0.156282
I0809 11:24:05.992914 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:24:05.992929 20451 solver.cpp:244]     Train net output #1: loss = 0.156282 (* 1 = 0.156282 loss)
I0809 11:24:05.992941 20451 sgd_solver.cpp:106] Iteration 33650, lr = 0.00033114
I0809 11:24:28.340255 20451 solver.cpp:228] Iteration 33660, loss = 0.375079
I0809 11:24:28.340297 20451 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0809 11:24:28.340312 20451 solver.cpp:244]     Train net output #1: loss = 0.375079 (* 1 = 0.375079 loss)
I0809 11:24:28.340325 20451 sgd_solver.cpp:106] Iteration 33660, lr = 0.000331083
I0809 11:24:50.652101 20451 solver.cpp:228] Iteration 33670, loss = 0.218869
I0809 11:24:50.652281 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:24:50.652297 20451 solver.cpp:244]     Train net output #1: loss = 0.218869 (* 1 = 0.218869 loss)
I0809 11:24:50.652309 20451 sgd_solver.cpp:106] Iteration 33670, lr = 0.000331026
I0809 11:25:12.968070 20451 solver.cpp:228] Iteration 33680, loss = 0.218764
I0809 11:25:12.968122 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:25:12.968135 20451 solver.cpp:244]     Train net output #1: loss = 0.218765 (* 1 = 0.218765 loss)
I0809 11:25:12.968147 20451 sgd_solver.cpp:106] Iteration 33680, lr = 0.00033097
I0809 11:25:35.283834 20451 solver.cpp:228] Iteration 33690, loss = 0.281613
I0809 11:25:35.284014 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 11:25:35.284030 20451 solver.cpp:244]     Train net output #1: loss = 0.281613 (* 1 = 0.281613 loss)
I0809 11:25:35.284044 20451 sgd_solver.cpp:106] Iteration 33690, lr = 0.000330913
I0809 11:25:55.373488 20451 solver.cpp:337] Iteration 33700, Testing net (#0)
I0809 11:26:03.897303 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 11:26:03.897354 20451 solver.cpp:404]     Test net output #1: loss = 0.998449 (* 1 = 0.998449 loss)
I0809 11:26:06.102627 20451 solver.cpp:228] Iteration 33700, loss = 0.312522
I0809 11:26:06.102794 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:26:06.102810 20451 solver.cpp:244]     Train net output #1: loss = 0.312522 (* 1 = 0.312522 loss)
I0809 11:26:06.102824 20451 sgd_solver.cpp:106] Iteration 33700, lr = 0.000330856
I0809 11:26:28.405163 20451 solver.cpp:228] Iteration 33710, loss = 0.218925
I0809 11:26:28.405202 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:26:28.405218 20451 solver.cpp:244]     Train net output #1: loss = 0.218925 (* 1 = 0.218925 loss)
I0809 11:26:28.405230 20451 sgd_solver.cpp:106] Iteration 33710, lr = 0.000330799
I0809 11:26:50.728767 20451 solver.cpp:228] Iteration 33720, loss = 0.0938026
I0809 11:26:50.728873 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 11:26:50.728888 20451 solver.cpp:244]     Train net output #1: loss = 0.0938029 (* 1 = 0.0938029 loss)
I0809 11:26:50.728901 20451 sgd_solver.cpp:106] Iteration 33720, lr = 0.000330742
I0809 11:27:13.262362 20451 solver.cpp:228] Iteration 33730, loss = 0.281535
I0809 11:27:13.262413 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 11:27:13.262426 20451 solver.cpp:244]     Train net output #1: loss = 0.281535 (* 1 = 0.281535 loss)
I0809 11:27:13.262439 20451 sgd_solver.cpp:106] Iteration 33730, lr = 0.000330686
I0809 11:27:35.747833 20451 solver.cpp:228] Iteration 33740, loss = 0.250134
I0809 11:27:35.748034 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:27:35.748052 20451 solver.cpp:244]     Train net output #1: loss = 0.250134 (* 1 = 0.250134 loss)
I0809 11:27:35.748067 20451 sgd_solver.cpp:106] Iteration 33740, lr = 0.000330629
I0809 11:27:58.151170 20451 solver.cpp:228] Iteration 33750, loss = 0.0312768
I0809 11:27:58.151213 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 11:27:58.151232 20451 solver.cpp:244]     Train net output #1: loss = 0.031277 (* 1 = 0.031277 loss)
I0809 11:27:58.151257 20451 sgd_solver.cpp:106] Iteration 33750, lr = 0.000330572
I0809 11:28:20.435549 20451 solver.cpp:228] Iteration 33760, loss = 0.0937654
I0809 11:28:20.435739 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 11:28:20.435755 20451 solver.cpp:244]     Train net output #1: loss = 0.0937656 (* 1 = 0.0937656 loss)
I0809 11:28:20.435767 20451 sgd_solver.cpp:106] Iteration 33760, lr = 0.000330516
I0809 11:28:42.725913 20451 solver.cpp:228] Iteration 33770, loss = 0.187575
I0809 11:28:42.725965 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:28:42.725977 20451 solver.cpp:244]     Train net output #1: loss = 0.187575 (* 1 = 0.187575 loss)
I0809 11:28:42.725989 20451 sgd_solver.cpp:106] Iteration 33770, lr = 0.000330459
I0809 11:29:05.015645 20451 solver.cpp:228] Iteration 33780, loss = 0.125021
I0809 11:29:05.015751 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:29:05.015766 20451 solver.cpp:244]     Train net output #1: loss = 0.125021 (* 1 = 0.125021 loss)
I0809 11:29:05.015779 20451 sgd_solver.cpp:106] Iteration 33780, lr = 0.000330402
I0809 11:29:27.307929 20451 solver.cpp:228] Iteration 33790, loss = 0.125065
I0809 11:29:27.307981 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:29:27.307994 20451 solver.cpp:244]     Train net output #1: loss = 0.125065 (* 1 = 0.125065 loss)
I0809 11:29:27.308006 20451 sgd_solver.cpp:106] Iteration 33790, lr = 0.000330346
I0809 11:29:47.658103 20451 solver.cpp:337] Iteration 33800, Testing net (#0)
I0809 11:29:56.168653 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0809 11:29:56.168702 20451 solver.cpp:404]     Test net output #1: loss = 0.989273 (* 1 = 0.989273 loss)
I0809 11:29:58.364992 20451 solver.cpp:228] Iteration 33800, loss = 0.218819
I0809 11:29:58.365044 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:29:58.365058 20451 solver.cpp:244]     Train net output #1: loss = 0.218819 (* 1 = 0.218819 loss)
I0809 11:29:58.365070 20451 sgd_solver.cpp:106] Iteration 33800, lr = 0.000330289
I0809 11:30:20.651720 20451 solver.cpp:228] Iteration 33810, loss = 0.218817
I0809 11:30:20.651826 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:30:20.651846 20451 solver.cpp:244]     Train net output #1: loss = 0.218817 (* 1 = 0.218817 loss)
I0809 11:30:20.651861 20451 sgd_solver.cpp:106] Iteration 33810, lr = 0.000330233
I0809 11:30:42.947007 20451 solver.cpp:228] Iteration 33820, loss = 0.218774
I0809 11:30:42.947057 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:30:42.947072 20451 solver.cpp:244]     Train net output #1: loss = 0.218775 (* 1 = 0.218775 loss)
I0809 11:30:42.947083 20451 sgd_solver.cpp:106] Iteration 33820, lr = 0.000330176
I0809 11:31:05.227488 20451 solver.cpp:228] Iteration 33830, loss = 0.250147
I0809 11:31:05.227702 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:31:05.227718 20451 solver.cpp:244]     Train net output #1: loss = 0.250147 (* 1 = 0.250147 loss)
I0809 11:31:05.227731 20451 sgd_solver.cpp:106] Iteration 33830, lr = 0.00033012
I0809 11:31:27.515089 20451 solver.cpp:228] Iteration 33840, loss = 0.156284
I0809 11:31:27.515142 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:31:27.515157 20451 solver.cpp:244]     Train net output #1: loss = 0.156284 (* 1 = 0.156284 loss)
I0809 11:31:27.515169 20451 sgd_solver.cpp:106] Iteration 33840, lr = 0.000330063
I0809 11:31:49.800217 20451 solver.cpp:228] Iteration 33850, loss = 0.43769
I0809 11:31:49.800321 20451 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0809 11:31:49.800339 20451 solver.cpp:244]     Train net output #1: loss = 0.437691 (* 1 = 0.437691 loss)
I0809 11:31:49.800355 20451 sgd_solver.cpp:106] Iteration 33850, lr = 0.000330007
I0809 11:32:12.092794 20451 solver.cpp:228] Iteration 33860, loss = 0.281343
I0809 11:32:12.092839 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 11:32:12.092861 20451 solver.cpp:244]     Train net output #1: loss = 0.281343 (* 1 = 0.281343 loss)
I0809 11:32:12.092877 20451 sgd_solver.cpp:106] Iteration 33860, lr = 0.00032995
I0809 11:32:34.382747 20451 solver.cpp:228] Iteration 33870, loss = 0.187572
I0809 11:32:34.382927 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:32:34.382946 20451 solver.cpp:244]     Train net output #1: loss = 0.187572 (* 1 = 0.187572 loss)
I0809 11:32:34.382961 20451 sgd_solver.cpp:106] Iteration 33870, lr = 0.000329894
I0809 11:32:56.712126 20451 solver.cpp:228] Iteration 33880, loss = 0.187571
I0809 11:32:56.712178 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:32:56.712193 20451 solver.cpp:244]     Train net output #1: loss = 0.187572 (* 1 = 0.187572 loss)
I0809 11:32:56.712204 20451 sgd_solver.cpp:106] Iteration 33880, lr = 0.000329838
I0809 11:33:19.058930 20451 solver.cpp:228] Iteration 33890, loss = 0.125025
I0809 11:33:19.059108 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:33:19.059123 20451 solver.cpp:244]     Train net output #1: loss = 0.125025 (* 1 = 0.125025 loss)
I0809 11:33:19.059135 20451 sgd_solver.cpp:106] Iteration 33890, lr = 0.000329781
I0809 11:33:39.154026 20451 solver.cpp:337] Iteration 33900, Testing net (#0)
I0809 11:33:47.674422 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0809 11:33:47.674474 20451 solver.cpp:404]     Test net output #1: loss = 1.03615 (* 1 = 1.03615 loss)
I0809 11:33:49.877014 20451 solver.cpp:228] Iteration 33900, loss = 0.187557
I0809 11:33:49.877116 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:33:49.877132 20451 solver.cpp:244]     Train net output #1: loss = 0.187558 (* 1 = 0.187558 loss)
I0809 11:33:49.877146 20451 sgd_solver.cpp:106] Iteration 33900, lr = 0.000329725
I0809 11:34:12.182149 20451 solver.cpp:228] Iteration 33910, loss = 0.250045
I0809 11:34:12.182201 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:34:12.182216 20451 solver.cpp:244]     Train net output #1: loss = 0.250045 (* 1 = 0.250045 loss)
I0809 11:34:12.182229 20451 sgd_solver.cpp:106] Iteration 33910, lr = 0.000329669
I0809 11:34:34.507294 20451 solver.cpp:228] Iteration 33920, loss = 0.250075
I0809 11:34:34.507464 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:34:34.507479 20451 solver.cpp:244]     Train net output #1: loss = 0.250075 (* 1 = 0.250075 loss)
I0809 11:34:34.507491 20451 sgd_solver.cpp:106] Iteration 33920, lr = 0.000329612
I0809 11:34:56.814205 20451 solver.cpp:228] Iteration 33930, loss = 0.21878
I0809 11:34:56.814254 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:34:56.814272 20451 solver.cpp:244]     Train net output #1: loss = 0.21878 (* 1 = 0.21878 loss)
I0809 11:34:56.814286 20451 sgd_solver.cpp:106] Iteration 33930, lr = 0.000329556
I0809 11:35:19.141461 20451 solver.cpp:228] Iteration 33940, loss = 0.25008
I0809 11:35:19.141685 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:35:19.141700 20451 solver.cpp:244]     Train net output #1: loss = 0.25008 (* 1 = 0.25008 loss)
I0809 11:35:19.141713 20451 sgd_solver.cpp:106] Iteration 33940, lr = 0.0003295
I0809 11:35:41.461283 20451 solver.cpp:228] Iteration 33950, loss = 0.187761
I0809 11:35:41.461334 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:35:41.461349 20451 solver.cpp:244]     Train net output #1: loss = 0.187761 (* 1 = 0.187761 loss)
I0809 11:35:41.461360 20451 sgd_solver.cpp:106] Iteration 33950, lr = 0.000329443
I0809 11:36:03.770113 20451 solver.cpp:228] Iteration 33960, loss = 0.0625533
I0809 11:36:03.770297 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 11:36:03.770313 20451 solver.cpp:244]     Train net output #1: loss = 0.0625536 (* 1 = 0.0625536 loss)
I0809 11:36:03.770325 20451 sgd_solver.cpp:106] Iteration 33960, lr = 0.000329387
I0809 11:36:26.084522 20451 solver.cpp:228] Iteration 33970, loss = 0.156256
I0809 11:36:26.084575 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:36:26.084590 20451 solver.cpp:244]     Train net output #1: loss = 0.156256 (* 1 = 0.156256 loss)
I0809 11:36:26.084602 20451 sgd_solver.cpp:106] Iteration 33970, lr = 0.000329331
I0809 11:36:48.392194 20451 solver.cpp:228] Iteration 33980, loss = 0.218889
I0809 11:36:48.392369 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:36:48.392385 20451 solver.cpp:244]     Train net output #1: loss = 0.218889 (* 1 = 0.218889 loss)
I0809 11:36:48.392397 20451 sgd_solver.cpp:106] Iteration 33980, lr = 0.000329275
I0809 11:37:10.695456 20451 solver.cpp:228] Iteration 33990, loss = 0.187562
I0809 11:37:10.695502 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:37:10.695520 20451 solver.cpp:244]     Train net output #1: loss = 0.187563 (* 1 = 0.187563 loss)
I0809 11:37:10.695535 20451 sgd_solver.cpp:106] Iteration 33990, lr = 0.000329219
I0809 11:37:30.784576 20451 solver.cpp:337] Iteration 34000, Testing net (#0)
I0809 11:37:39.307152 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 11:37:39.307193 20451 solver.cpp:404]     Test net output #1: loss = 0.984646 (* 1 = 0.984646 loss)
I0809 11:37:41.509395 20451 solver.cpp:228] Iteration 34000, loss = 0.312627
I0809 11:37:41.509446 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 11:37:41.509459 20451 solver.cpp:244]     Train net output #1: loss = 0.312628 (* 1 = 0.312628 loss)
I0809 11:37:41.509471 20451 sgd_solver.cpp:106] Iteration 34000, lr = 0.000329163
I0809 11:38:03.826861 20451 solver.cpp:228] Iteration 34010, loss = 0.187522
I0809 11:38:03.827044 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:38:03.827059 20451 solver.cpp:244]     Train net output #1: loss = 0.187522 (* 1 = 0.187522 loss)
I0809 11:38:03.827071 20451 sgd_solver.cpp:106] Iteration 34010, lr = 0.000329107
I0809 11:38:26.146813 20451 solver.cpp:228] Iteration 34020, loss = 0.187628
I0809 11:38:26.146864 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:38:26.146878 20451 solver.cpp:244]     Train net output #1: loss = 0.187629 (* 1 = 0.187629 loss)
I0809 11:38:26.146889 20451 sgd_solver.cpp:106] Iteration 34020, lr = 0.00032905
I0809 11:38:48.476966 20451 solver.cpp:228] Iteration 34030, loss = 0.125007
I0809 11:38:48.477144 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:38:48.477159 20451 solver.cpp:244]     Train net output #1: loss = 0.125007 (* 1 = 0.125007 loss)
I0809 11:38:48.477171 20451 sgd_solver.cpp:106] Iteration 34030, lr = 0.000328994
I0809 11:39:10.794577 20451 solver.cpp:228] Iteration 34040, loss = 0.0939623
I0809 11:39:10.794625 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:39:10.794644 20451 solver.cpp:244]     Train net output #1: loss = 0.0939626 (* 1 = 0.0939626 loss)
I0809 11:39:10.794662 20451 sgd_solver.cpp:106] Iteration 34040, lr = 0.000328938
I0809 11:39:33.108721 20451 solver.cpp:228] Iteration 34050, loss = 0.125123
I0809 11:39:33.108868 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:39:33.108887 20451 solver.cpp:244]     Train net output #1: loss = 0.125123 (* 1 = 0.125123 loss)
I0809 11:39:33.108903 20451 sgd_solver.cpp:106] Iteration 34050, lr = 0.000328882
I0809 11:39:55.412817 20451 solver.cpp:228] Iteration 34060, loss = 0.156381
I0809 11:39:55.412864 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:39:55.412883 20451 solver.cpp:244]     Train net output #1: loss = 0.156382 (* 1 = 0.156382 loss)
I0809 11:39:55.412897 20451 sgd_solver.cpp:106] Iteration 34060, lr = 0.000328826
I0809 11:40:17.718299 20451 solver.cpp:228] Iteration 34070, loss = 0.187594
I0809 11:40:17.718513 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:40:17.718528 20451 solver.cpp:244]     Train net output #1: loss = 0.187594 (* 1 = 0.187594 loss)
I0809 11:40:17.718540 20451 sgd_solver.cpp:106] Iteration 34070, lr = 0.00032877
I0809 11:40:40.017249 20451 solver.cpp:228] Iteration 34080, loss = 0.281367
I0809 11:40:40.017302 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:40:40.017318 20451 solver.cpp:244]     Train net output #1: loss = 0.281368 (* 1 = 0.281368 loss)
I0809 11:40:40.017329 20451 sgd_solver.cpp:106] Iteration 34080, lr = 0.000328714
I0809 11:41:02.344126 20451 solver.cpp:228] Iteration 34090, loss = 0.0937713
I0809 11:41:02.344321 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 11:41:02.344341 20451 solver.cpp:244]     Train net output #1: loss = 0.0937715 (* 1 = 0.0937715 loss)
I0809 11:41:02.344357 20451 sgd_solver.cpp:106] Iteration 34090, lr = 0.000328659
I0809 11:41:22.426893 20451 solver.cpp:337] Iteration 34100, Testing net (#0)
I0809 11:41:30.942396 20451 solver.cpp:404]     Test net output #0: accuracy = 0.676562
I0809 11:41:30.942446 20451 solver.cpp:404]     Test net output #1: loss = 0.970387 (* 1 = 0.970387 loss)
I0809 11:41:33.142984 20451 solver.cpp:228] Iteration 34100, loss = 0.281281
I0809 11:41:33.143162 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 11:41:33.143177 20451 solver.cpp:244]     Train net output #1: loss = 0.281281 (* 1 = 0.281281 loss)
I0809 11:41:33.143189 20451 sgd_solver.cpp:106] Iteration 34100, lr = 0.000328603
I0809 11:41:55.442261 20451 solver.cpp:228] Iteration 34110, loss = 0.125053
I0809 11:41:55.442313 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:41:55.442327 20451 solver.cpp:244]     Train net output #1: loss = 0.125054 (* 1 = 0.125054 loss)
I0809 11:41:55.442339 20451 sgd_solver.cpp:106] Iteration 34110, lr = 0.000328547
I0809 11:42:17.792227 20451 solver.cpp:228] Iteration 34120, loss = 0.250033
I0809 11:42:17.792320 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:42:17.792335 20451 solver.cpp:244]     Train net output #1: loss = 0.250034 (* 1 = 0.250034 loss)
I0809 11:42:17.792348 20451 sgd_solver.cpp:106] Iteration 34120, lr = 0.000328491
I0809 11:42:40.253852 20451 solver.cpp:228] Iteration 34130, loss = 0.312594
I0809 11:42:40.253902 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 11:42:40.253916 20451 solver.cpp:244]     Train net output #1: loss = 0.312594 (* 1 = 0.312594 loss)
I0809 11:42:40.253927 20451 sgd_solver.cpp:106] Iteration 34130, lr = 0.000328435
I0809 11:43:02.639842 20451 solver.cpp:228] Iteration 34140, loss = 0.156289
I0809 11:43:02.640023 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:43:02.640038 20451 solver.cpp:244]     Train net output #1: loss = 0.156289 (* 1 = 0.156289 loss)
I0809 11:43:02.640051 20451 sgd_solver.cpp:106] Iteration 34140, lr = 0.000328379
I0809 11:43:25.575530 20451 solver.cpp:228] Iteration 34150, loss = 0.125046
I0809 11:43:25.575595 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:43:25.575614 20451 solver.cpp:244]     Train net output #1: loss = 0.125046 (* 1 = 0.125046 loss)
I0809 11:43:25.575634 20451 sgd_solver.cpp:106] Iteration 34150, lr = 0.000328324
I0809 11:43:48.594571 20451 solver.cpp:228] Iteration 34160, loss = 0.218793
I0809 11:43:48.594786 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:43:48.594805 20451 solver.cpp:244]     Train net output #1: loss = 0.218793 (* 1 = 0.218793 loss)
I0809 11:43:48.594821 20451 sgd_solver.cpp:106] Iteration 34160, lr = 0.000328268
I0809 11:44:10.889957 20451 solver.cpp:228] Iteration 34170, loss = 0.18756
I0809 11:44:10.890003 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:44:10.890022 20451 solver.cpp:244]     Train net output #1: loss = 0.18756 (* 1 = 0.18756 loss)
I0809 11:44:10.890038 20451 sgd_solver.cpp:106] Iteration 34170, lr = 0.000328212
I0809 11:44:33.183151 20451 solver.cpp:228] Iteration 34180, loss = 0.0937664
I0809 11:44:33.183338 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 11:44:33.183357 20451 solver.cpp:244]     Train net output #1: loss = 0.0937666 (* 1 = 0.0937666 loss)
I0809 11:44:33.183370 20451 sgd_solver.cpp:106] Iteration 34180, lr = 0.000328156
I0809 11:44:55.478214 20451 solver.cpp:228] Iteration 34190, loss = 0.125044
I0809 11:44:55.478257 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:44:55.478276 20451 solver.cpp:244]     Train net output #1: loss = 0.125044 (* 1 = 0.125044 loss)
I0809 11:44:55.478301 20451 sgd_solver.cpp:106] Iteration 34190, lr = 0.000328101
I0809 11:45:15.552224 20451 solver.cpp:337] Iteration 34200, Testing net (#0)
I0809 11:45:24.065915 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 11:45:24.065960 20451 solver.cpp:404]     Test net output #1: loss = 1.00796 (* 1 = 1.00796 loss)
I0809 11:45:26.266041 20451 solver.cpp:228] Iteration 34200, loss = 0.156283
I0809 11:45:26.266094 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:45:26.266108 20451 solver.cpp:244]     Train net output #1: loss = 0.156284 (* 1 = 0.156284 loss)
I0809 11:45:26.266120 20451 sgd_solver.cpp:106] Iteration 34200, lr = 0.000328045
I0809 11:45:48.548012 20451 solver.cpp:228] Iteration 34210, loss = 0.0625127
I0809 11:45:48.548202 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 11:45:48.548218 20451 solver.cpp:244]     Train net output #1: loss = 0.0625129 (* 1 = 0.0625129 loss)
I0809 11:45:48.548230 20451 sgd_solver.cpp:106] Iteration 34210, lr = 0.000327989
I0809 11:46:10.837105 20451 solver.cpp:228] Iteration 34220, loss = 0.0625265
I0809 11:46:10.837153 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 11:46:10.837172 20451 solver.cpp:244]     Train net output #1: loss = 0.0625267 (* 1 = 0.0625267 loss)
I0809 11:46:10.837188 20451 sgd_solver.cpp:106] Iteration 34220, lr = 0.000327934
I0809 11:46:33.123349 20451 solver.cpp:228] Iteration 34230, loss = 0.156278
I0809 11:46:33.123528 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:46:33.123546 20451 solver.cpp:244]     Train net output #1: loss = 0.156278 (* 1 = 0.156278 loss)
I0809 11:46:33.123563 20451 sgd_solver.cpp:106] Iteration 34230, lr = 0.000327878
I0809 11:46:55.413717 20451 solver.cpp:228] Iteration 34240, loss = 0.0625093
I0809 11:46:55.413760 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 11:46:55.413777 20451 solver.cpp:244]     Train net output #1: loss = 0.0625095 (* 1 = 0.0625095 loss)
I0809 11:46:55.413792 20451 sgd_solver.cpp:106] Iteration 34240, lr = 0.000327822
I0809 11:47:17.709318 20451 solver.cpp:228] Iteration 34250, loss = 0.187573
I0809 11:47:17.709496 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:47:17.709516 20451 solver.cpp:244]     Train net output #1: loss = 0.187574 (* 1 = 0.187574 loss)
I0809 11:47:17.709530 20451 sgd_solver.cpp:106] Iteration 34250, lr = 0.000327767
I0809 11:47:39.997155 20451 solver.cpp:228] Iteration 34260, loss = 0.156282
I0809 11:47:39.997201 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:47:39.997217 20451 solver.cpp:244]     Train net output #1: loss = 0.156283 (* 1 = 0.156283 loss)
I0809 11:47:39.997231 20451 sgd_solver.cpp:106] Iteration 34260, lr = 0.000327711
I0809 11:48:02.294071 20451 solver.cpp:228] Iteration 34270, loss = 0.125061
I0809 11:48:02.294275 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:48:02.294292 20451 solver.cpp:244]     Train net output #1: loss = 0.125061 (* 1 = 0.125061 loss)
I0809 11:48:02.294304 20451 sgd_solver.cpp:106] Iteration 34270, lr = 0.000327656
I0809 11:48:24.585045 20451 solver.cpp:228] Iteration 34280, loss = 0.125026
I0809 11:48:24.585098 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:48:24.585113 20451 solver.cpp:244]     Train net output #1: loss = 0.125026 (* 1 = 0.125026 loss)
I0809 11:48:24.585125 20451 sgd_solver.cpp:106] Iteration 34280, lr = 0.0003276
I0809 11:48:46.875645 20451 solver.cpp:228] Iteration 34290, loss = 0.218835
I0809 11:48:46.875818 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:48:46.875834 20451 solver.cpp:244]     Train net output #1: loss = 0.218836 (* 1 = 0.218836 loss)
I0809 11:48:46.875847 20451 sgd_solver.cpp:106] Iteration 34290, lr = 0.000327545
I0809 11:49:06.943657 20451 solver.cpp:337] Iteration 34300, Testing net (#0)
I0809 11:49:15.453949 20451 solver.cpp:404]     Test net output #0: accuracy = 0.6625
I0809 11:49:15.453999 20451 solver.cpp:404]     Test net output #1: loss = 1.01278 (* 1 = 1.01278 loss)
I0809 11:49:17.652932 20451 solver.cpp:228] Iteration 34300, loss = 0.125052
I0809 11:49:17.653108 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:49:17.653127 20451 solver.cpp:244]     Train net output #1: loss = 0.125052 (* 1 = 0.125052 loss)
I0809 11:49:17.653139 20451 sgd_solver.cpp:106] Iteration 34300, lr = 0.000327489
I0809 11:49:39.936367 20451 solver.cpp:228] Iteration 34310, loss = 0.343773
I0809 11:49:39.936421 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:49:39.936435 20451 solver.cpp:244]     Train net output #1: loss = 0.343773 (* 1 = 0.343773 loss)
I0809 11:49:39.936449 20451 sgd_solver.cpp:106] Iteration 34310, lr = 0.000327434
I0809 11:50:02.238627 20451 solver.cpp:228] Iteration 34320, loss = 0.250319
I0809 11:50:02.238811 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:50:02.238827 20451 solver.cpp:244]     Train net output #1: loss = 0.250319 (* 1 = 0.250319 loss)
I0809 11:50:02.238839 20451 sgd_solver.cpp:106] Iteration 34320, lr = 0.000327379
I0809 11:50:24.526988 20451 solver.cpp:228] Iteration 34330, loss = 0.156251
I0809 11:50:24.527034 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:50:24.527050 20451 solver.cpp:244]     Train net output #1: loss = 0.156251 (* 1 = 0.156251 loss)
I0809 11:50:24.527061 20451 sgd_solver.cpp:106] Iteration 34330, lr = 0.000327323
I0809 11:50:46.820729 20451 solver.cpp:228] Iteration 34340, loss = 0.219023
I0809 11:50:46.820832 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:50:46.820852 20451 solver.cpp:244]     Train net output #1: loss = 0.219024 (* 1 = 0.219024 loss)
I0809 11:50:46.820866 20451 sgd_solver.cpp:106] Iteration 34340, lr = 0.000327268
I0809 11:51:09.113684 20451 solver.cpp:228] Iteration 34350, loss = 0.218759
I0809 11:51:09.113737 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:51:09.113751 20451 solver.cpp:244]     Train net output #1: loss = 0.218759 (* 1 = 0.218759 loss)
I0809 11:51:09.113764 20451 sgd_solver.cpp:106] Iteration 34350, lr = 0.000327212
I0809 11:51:31.414119 20451 solver.cpp:228] Iteration 34360, loss = 0.0938834
I0809 11:51:31.414294 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 11:51:31.414309 20451 solver.cpp:244]     Train net output #1: loss = 0.0938836 (* 1 = 0.0938836 loss)
I0809 11:51:31.414322 20451 sgd_solver.cpp:106] Iteration 34360, lr = 0.000327157
I0809 11:51:53.719358 20451 solver.cpp:228] Iteration 34370, loss = 0.25014
I0809 11:51:53.719411 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:51:53.719425 20451 solver.cpp:244]     Train net output #1: loss = 0.25014 (* 1 = 0.25014 loss)
I0809 11:51:53.719437 20451 sgd_solver.cpp:106] Iteration 34370, lr = 0.000327102
I0809 11:52:16.011294 20451 solver.cpp:228] Iteration 34380, loss = 0.18769
I0809 11:52:16.011445 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:52:16.011461 20451 solver.cpp:244]     Train net output #1: loss = 0.187691 (* 1 = 0.187691 loss)
I0809 11:52:16.011474 20451 sgd_solver.cpp:106] Iteration 34380, lr = 0.000327047
I0809 11:52:38.307147 20451 solver.cpp:228] Iteration 34390, loss = 0.218831
I0809 11:52:38.307200 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:52:38.307214 20451 solver.cpp:244]     Train net output #1: loss = 0.218831 (* 1 = 0.218831 loss)
I0809 11:52:38.307226 20451 sgd_solver.cpp:106] Iteration 34390, lr = 0.000326991
I0809 11:52:58.589172 20451 solver.cpp:337] Iteration 34400, Testing net (#0)
I0809 11:53:07.104432 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 11:53:07.104483 20451 solver.cpp:404]     Test net output #1: loss = 0.984492 (* 1 = 0.984492 loss)
I0809 11:53:09.310190 20451 solver.cpp:228] Iteration 34400, loss = 0.250044
I0809 11:53:09.310243 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:53:09.310257 20451 solver.cpp:244]     Train net output #1: loss = 0.250044 (* 1 = 0.250044 loss)
I0809 11:53:09.310269 20451 sgd_solver.cpp:106] Iteration 34400, lr = 0.000326936
I0809 11:53:31.668735 20451 solver.cpp:228] Iteration 34410, loss = 0.125233
I0809 11:53:31.668854 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:53:31.668869 20451 solver.cpp:244]     Train net output #1: loss = 0.125233 (* 1 = 0.125233 loss)
I0809 11:53:31.668882 20451 sgd_solver.cpp:106] Iteration 34410, lr = 0.000326881
I0809 11:53:53.983094 20451 solver.cpp:228] Iteration 34420, loss = 0.125062
I0809 11:53:53.983139 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 11:53:53.983157 20451 solver.cpp:244]     Train net output #1: loss = 0.125062 (* 1 = 0.125062 loss)
I0809 11:53:53.983170 20451 sgd_solver.cpp:106] Iteration 34420, lr = 0.000326826
I0809 11:54:16.319514 20451 solver.cpp:228] Iteration 34430, loss = 0.218759
I0809 11:54:16.319699 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:54:16.319713 20451 solver.cpp:244]     Train net output #1: loss = 0.218759 (* 1 = 0.218759 loss)
I0809 11:54:16.319726 20451 sgd_solver.cpp:106] Iteration 34430, lr = 0.00032677
I0809 11:54:38.614344 20451 solver.cpp:228] Iteration 34440, loss = 0.187754
I0809 11:54:38.614385 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:54:38.614400 20451 solver.cpp:244]     Train net output #1: loss = 0.187754 (* 1 = 0.187754 loss)
I0809 11:54:38.614413 20451 sgd_solver.cpp:106] Iteration 34440, lr = 0.000326715
I0809 11:55:00.920433 20451 solver.cpp:228] Iteration 34450, loss = 0.218848
I0809 11:55:00.920608 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:55:00.920624 20451 solver.cpp:244]     Train net output #1: loss = 0.218848 (* 1 = 0.218848 loss)
I0809 11:55:00.920637 20451 sgd_solver.cpp:106] Iteration 34450, lr = 0.00032666
I0809 11:55:23.556027 20451 solver.cpp:228] Iteration 34460, loss = 0.250223
I0809 11:55:23.556079 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:55:23.556093 20451 solver.cpp:244]     Train net output #1: loss = 0.250223 (* 1 = 0.250223 loss)
I0809 11:55:23.556105 20451 sgd_solver.cpp:106] Iteration 34460, lr = 0.000326605
I0809 11:55:46.078326 20451 solver.cpp:228] Iteration 34470, loss = 0.15629
I0809 11:55:46.078441 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:55:46.078457 20451 solver.cpp:244]     Train net output #1: loss = 0.15629 (* 1 = 0.15629 loss)
I0809 11:55:46.078469 20451 sgd_solver.cpp:106] Iteration 34470, lr = 0.00032655
I0809 11:56:08.512964 20451 solver.cpp:228] Iteration 34480, loss = 0.0625623
I0809 11:56:08.513015 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 11:56:08.513031 20451 solver.cpp:244]     Train net output #1: loss = 0.0625625 (* 1 = 0.0625625 loss)
I0809 11:56:08.513041 20451 sgd_solver.cpp:106] Iteration 34480, lr = 0.000326495
I0809 11:56:30.849625 20451 solver.cpp:228] Iteration 34490, loss = 0.187531
I0809 11:56:30.849848 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 11:56:30.849864 20451 solver.cpp:244]     Train net output #1: loss = 0.187531 (* 1 = 0.187531 loss)
I0809 11:56:30.849876 20451 sgd_solver.cpp:106] Iteration 34490, lr = 0.00032644
I0809 11:56:50.973600 20451 solver.cpp:337] Iteration 34500, Testing net (#0)
I0809 11:56:59.488979 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 11:56:59.489023 20451 solver.cpp:404]     Test net output #1: loss = 1.00342 (* 1 = 1.00342 loss)
I0809 11:57:01.691414 20451 solver.cpp:228] Iteration 34500, loss = 0.0937901
I0809 11:57:01.691526 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 11:57:01.691546 20451 solver.cpp:244]     Train net output #1: loss = 0.0937903 (* 1 = 0.0937903 loss)
I0809 11:57:01.691561 20451 sgd_solver.cpp:106] Iteration 34500, lr = 0.000326385
I0809 11:57:24.050715 20451 solver.cpp:228] Iteration 34510, loss = 0.156305
I0809 11:57:24.050761 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 11:57:24.050779 20451 solver.cpp:244]     Train net output #1: loss = 0.156305 (* 1 = 0.156305 loss)
I0809 11:57:24.050791 20451 sgd_solver.cpp:106] Iteration 34510, lr = 0.00032633
I0809 11:57:46.428932 20451 solver.cpp:228] Iteration 34520, loss = 0.250111
I0809 11:57:46.429116 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:57:46.429131 20451 solver.cpp:244]     Train net output #1: loss = 0.250111 (* 1 = 0.250111 loss)
I0809 11:57:46.429143 20451 sgd_solver.cpp:106] Iteration 34520, lr = 0.000326275
I0809 11:58:08.713557 20451 solver.cpp:228] Iteration 34530, loss = 0.0938031
I0809 11:58:08.713609 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 11:58:08.713624 20451 solver.cpp:244]     Train net output #1: loss = 0.0938034 (* 1 = 0.0938034 loss)
I0809 11:58:08.713636 20451 sgd_solver.cpp:106] Iteration 34530, lr = 0.00032622
I0809 11:58:31.003356 20451 solver.cpp:228] Iteration 34540, loss = 0.250342
I0809 11:58:31.003531 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:58:31.003547 20451 solver.cpp:244]     Train net output #1: loss = 0.250342 (* 1 = 0.250342 loss)
I0809 11:58:31.003561 20451 sgd_solver.cpp:106] Iteration 34540, lr = 0.000326165
I0809 11:58:53.289075 20451 solver.cpp:228] Iteration 34550, loss = 0.25001
I0809 11:58:53.289127 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 11:58:53.289142 20451 solver.cpp:244]     Train net output #1: loss = 0.25001 (* 1 = 0.25001 loss)
I0809 11:58:53.289155 20451 sgd_solver.cpp:106] Iteration 34550, lr = 0.00032611
I0809 11:59:15.579771 20451 solver.cpp:228] Iteration 34560, loss = 0.218904
I0809 11:59:15.579955 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 11:59:15.579972 20451 solver.cpp:244]     Train net output #1: loss = 0.218904 (* 1 = 0.218904 loss)
I0809 11:59:15.579984 20451 sgd_solver.cpp:106] Iteration 34560, lr = 0.000326055
I0809 11:59:37.865438 20451 solver.cpp:228] Iteration 34570, loss = 0.312699
I0809 11:59:37.865488 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 11:59:37.865507 20451 solver.cpp:244]     Train net output #1: loss = 0.3127 (* 1 = 0.3127 loss)
I0809 11:59:37.865525 20451 sgd_solver.cpp:106] Iteration 34570, lr = 0.000326
I0809 12:00:00.159700 20451 solver.cpp:228] Iteration 34580, loss = 0.187768
I0809 12:00:00.159801 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:00:00.159819 20451 solver.cpp:244]     Train net output #1: loss = 0.187768 (* 1 = 0.187768 loss)
I0809 12:00:00.159834 20451 sgd_solver.cpp:106] Iteration 34580, lr = 0.000325945
I0809 12:00:22.450629 20451 solver.cpp:228] Iteration 34590, loss = 0.21901
I0809 12:00:22.450685 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:00:22.450702 20451 solver.cpp:244]     Train net output #1: loss = 0.21901 (* 1 = 0.21901 loss)
I0809 12:00:22.450723 20451 sgd_solver.cpp:106] Iteration 34590, lr = 0.000325891
I0809 12:00:42.518926 20451 solver.cpp:337] Iteration 34600, Testing net (#0)
I0809 12:00:51.029781 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 12:00:51.029831 20451 solver.cpp:404]     Test net output #1: loss = 0.975571 (* 1 = 0.975571 loss)
I0809 12:00:53.228646 20451 solver.cpp:228] Iteration 34600, loss = 0.344051
I0809 12:00:53.228699 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 12:00:53.228713 20451 solver.cpp:244]     Train net output #1: loss = 0.344051 (* 1 = 0.344051 loss)
I0809 12:00:53.228725 20451 sgd_solver.cpp:106] Iteration 34600, lr = 0.000325836
I0809 12:01:15.511679 20451 solver.cpp:228] Iteration 34610, loss = 0.156298
I0809 12:01:15.511870 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:01:15.511889 20451 solver.cpp:244]     Train net output #1: loss = 0.156298 (* 1 = 0.156298 loss)
I0809 12:01:15.511905 20451 sgd_solver.cpp:106] Iteration 34610, lr = 0.000325781
I0809 12:01:37.807994 20451 solver.cpp:228] Iteration 34620, loss = 0.156297
I0809 12:01:37.808045 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:01:37.808064 20451 solver.cpp:244]     Train net output #1: loss = 0.156297 (* 1 = 0.156297 loss)
I0809 12:01:37.808081 20451 sgd_solver.cpp:106] Iteration 34620, lr = 0.000325726
I0809 12:02:00.136353 20451 solver.cpp:228] Iteration 34630, loss = 0.187523
I0809 12:02:00.136528 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:02:00.136543 20451 solver.cpp:244]     Train net output #1: loss = 0.187523 (* 1 = 0.187523 loss)
I0809 12:02:00.136555 20451 sgd_solver.cpp:106] Iteration 34630, lr = 0.000325672
I0809 12:02:22.438249 20451 solver.cpp:228] Iteration 34640, loss = 0.218856
I0809 12:02:22.438304 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:02:22.438318 20451 solver.cpp:244]     Train net output #1: loss = 0.218856 (* 1 = 0.218856 loss)
I0809 12:02:22.438330 20451 sgd_solver.cpp:106] Iteration 34640, lr = 0.000325617
I0809 12:02:44.837682 20451 solver.cpp:228] Iteration 34650, loss = 0.0937725
I0809 12:02:44.837870 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:02:44.837890 20451 solver.cpp:244]     Train net output #1: loss = 0.0937728 (* 1 = 0.0937728 loss)
I0809 12:02:44.837909 20451 sgd_solver.cpp:106] Iteration 34650, lr = 0.000325562
I0809 12:03:07.146505 20451 solver.cpp:228] Iteration 34660, loss = 0.343904
I0809 12:03:07.146556 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 12:03:07.146570 20451 solver.cpp:244]     Train net output #1: loss = 0.343904 (* 1 = 0.343904 loss)
I0809 12:03:07.146582 20451 sgd_solver.cpp:106] Iteration 34660, lr = 0.000325508
I0809 12:03:29.443284 20451 solver.cpp:228] Iteration 34670, loss = 0.18768
I0809 12:03:29.443462 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:03:29.443478 20451 solver.cpp:244]     Train net output #1: loss = 0.18768 (* 1 = 0.18768 loss)
I0809 12:03:29.443490 20451 sgd_solver.cpp:106] Iteration 34670, lr = 0.000325453
I0809 12:03:51.775212 20451 solver.cpp:228] Iteration 34680, loss = 0.281646
I0809 12:03:51.775264 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 12:03:51.775285 20451 solver.cpp:244]     Train net output #1: loss = 0.281647 (* 1 = 0.281647 loss)
I0809 12:03:51.775296 20451 sgd_solver.cpp:106] Iteration 34680, lr = 0.000325398
I0809 12:04:14.074187 20451 solver.cpp:228] Iteration 34690, loss = 0.250096
I0809 12:04:14.074290 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:04:14.074306 20451 solver.cpp:244]     Train net output #1: loss = 0.250096 (* 1 = 0.250096 loss)
I0809 12:04:14.074318 20451 sgd_solver.cpp:106] Iteration 34690, lr = 0.000325344
I0809 12:04:34.147188 20451 solver.cpp:337] Iteration 34700, Testing net (#0)
I0809 12:04:42.657476 20451 solver.cpp:404]     Test net output #0: accuracy = 0.660937
I0809 12:04:42.657526 20451 solver.cpp:404]     Test net output #1: loss = 1.01779 (* 1 = 1.01779 loss)
I0809 12:04:44.960476 20451 solver.cpp:228] Iteration 34700, loss = 0.250221
I0809 12:04:44.960700 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:04:44.960716 20451 solver.cpp:244]     Train net output #1: loss = 0.250221 (* 1 = 0.250221 loss)
I0809 12:04:44.960729 20451 sgd_solver.cpp:106] Iteration 34700, lr = 0.000325289
I0809 12:05:07.546464 20451 solver.cpp:228] Iteration 34710, loss = 0.218763
I0809 12:05:07.546517 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:05:07.546531 20451 solver.cpp:244]     Train net output #1: loss = 0.218763 (* 1 = 0.218763 loss)
I0809 12:05:07.546545 20451 sgd_solver.cpp:106] Iteration 34710, lr = 0.000325234
I0809 12:05:30.481281 20451 solver.cpp:228] Iteration 34720, loss = 0.0937874
I0809 12:05:30.481463 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:05:30.481482 20451 solver.cpp:244]     Train net output #1: loss = 0.0937877 (* 1 = 0.0937877 loss)
I0809 12:05:30.481498 20451 sgd_solver.cpp:106] Iteration 34720, lr = 0.00032518
I0809 12:05:53.022395 20451 solver.cpp:228] Iteration 34730, loss = 0.187536
I0809 12:05:53.022440 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:05:53.022459 20451 solver.cpp:244]     Train net output #1: loss = 0.187537 (* 1 = 0.187537 loss)
I0809 12:05:53.022475 20451 sgd_solver.cpp:106] Iteration 34730, lr = 0.000325125
I0809 12:06:16.140624 20451 solver.cpp:228] Iteration 34740, loss = 0.218779
I0809 12:06:16.140728 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:06:16.140744 20451 solver.cpp:244]     Train net output #1: loss = 0.218779 (* 1 = 0.218779 loss)
I0809 12:06:16.140758 20451 sgd_solver.cpp:106] Iteration 34740, lr = 0.000325071
I0809 12:06:38.490622 20451 solver.cpp:228] Iteration 34750, loss = 0.187512
I0809 12:06:38.490666 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:06:38.490681 20451 solver.cpp:244]     Train net output #1: loss = 0.187512 (* 1 = 0.187512 loss)
I0809 12:06:38.490694 20451 sgd_solver.cpp:106] Iteration 34750, lr = 0.000325016
I0809 12:07:00.792831 20451 solver.cpp:228] Iteration 34760, loss = 0.0938239
I0809 12:07:00.793010 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:07:00.793026 20451 solver.cpp:244]     Train net output #1: loss = 0.0938241 (* 1 = 0.0938241 loss)
I0809 12:07:00.793038 20451 sgd_solver.cpp:106] Iteration 34760, lr = 0.000324962
I0809 12:07:23.086220 20451 solver.cpp:228] Iteration 34770, loss = 0.218892
I0809 12:07:23.086264 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:07:23.086279 20451 solver.cpp:244]     Train net output #1: loss = 0.218892 (* 1 = 0.218892 loss)
I0809 12:07:23.086292 20451 sgd_solver.cpp:106] Iteration 34770, lr = 0.000324907
I0809 12:07:45.384030 20451 solver.cpp:228] Iteration 34780, loss = 0.0312604
I0809 12:07:45.384208 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 12:07:45.384224 20451 solver.cpp:244]     Train net output #1: loss = 0.0312606 (* 1 = 0.0312606 loss)
I0809 12:07:45.384238 20451 sgd_solver.cpp:106] Iteration 34780, lr = 0.000324853
I0809 12:08:07.674582 20451 solver.cpp:228] Iteration 34790, loss = 0.281254
I0809 12:08:07.674635 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:08:07.674649 20451 solver.cpp:244]     Train net output #1: loss = 0.281254 (* 1 = 0.281254 loss)
I0809 12:08:07.674661 20451 sgd_solver.cpp:106] Iteration 34790, lr = 0.000324799
I0809 12:08:27.745733 20451 solver.cpp:337] Iteration 34800, Testing net (#0)
I0809 12:08:36.263185 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 12:08:36.263236 20451 solver.cpp:404]     Test net output #1: loss = 1.00338 (* 1 = 1.00338 loss)
I0809 12:08:38.461895 20451 solver.cpp:228] Iteration 34800, loss = 0.187571
I0809 12:08:38.461947 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:08:38.461962 20451 solver.cpp:244]     Train net output #1: loss = 0.187572 (* 1 = 0.187572 loss)
I0809 12:08:38.461974 20451 sgd_solver.cpp:106] Iteration 34800, lr = 0.000324744
I0809 12:09:00.736109 20451 solver.cpp:228] Iteration 34810, loss = 0.156411
I0809 12:09:00.736292 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:09:00.736309 20451 solver.cpp:244]     Train net output #1: loss = 0.156411 (* 1 = 0.156411 loss)
I0809 12:09:00.736321 20451 sgd_solver.cpp:106] Iteration 34810, lr = 0.00032469
I0809 12:09:23.030928 20451 solver.cpp:228] Iteration 34820, loss = 0.125181
I0809 12:09:23.030978 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:09:23.030992 20451 solver.cpp:244]     Train net output #1: loss = 0.125181 (* 1 = 0.125181 loss)
I0809 12:09:23.031004 20451 sgd_solver.cpp:106] Iteration 34820, lr = 0.000324636
I0809 12:09:45.326535 20451 solver.cpp:228] Iteration 34830, loss = 0.187507
I0809 12:09:45.326638 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:09:45.326654 20451 solver.cpp:244]     Train net output #1: loss = 0.187507 (* 1 = 0.187507 loss)
I0809 12:09:45.326666 20451 sgd_solver.cpp:106] Iteration 34830, lr = 0.000324581
I0809 12:10:07.615928 20451 solver.cpp:228] Iteration 34840, loss = 0.250035
I0809 12:10:07.615981 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:10:07.615995 20451 solver.cpp:244]     Train net output #1: loss = 0.250035 (* 1 = 0.250035 loss)
I0809 12:10:07.616008 20451 sgd_solver.cpp:106] Iteration 34840, lr = 0.000324527
I0809 12:10:29.916251 20451 solver.cpp:228] Iteration 34850, loss = 0.062571
I0809 12:10:29.916431 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:10:29.916447 20451 solver.cpp:244]     Train net output #1: loss = 0.0625712 (* 1 = 0.0625712 loss)
I0809 12:10:29.916460 20451 sgd_solver.cpp:106] Iteration 34850, lr = 0.000324473
I0809 12:10:52.213590 20451 solver.cpp:228] Iteration 34860, loss = 0.281363
I0809 12:10:52.213642 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 12:10:52.213656 20451 solver.cpp:244]     Train net output #1: loss = 0.281364 (* 1 = 0.281364 loss)
I0809 12:10:52.213668 20451 sgd_solver.cpp:106] Iteration 34860, lr = 0.000324418
I0809 12:11:14.508276 20451 solver.cpp:228] Iteration 34870, loss = 0.0937624
I0809 12:11:14.508456 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:11:14.508471 20451 solver.cpp:244]     Train net output #1: loss = 0.0937626 (* 1 = 0.0937626 loss)
I0809 12:11:14.508484 20451 sgd_solver.cpp:106] Iteration 34870, lr = 0.000324364
I0809 12:11:36.797137 20451 solver.cpp:228] Iteration 34880, loss = 0.125003
I0809 12:11:36.797190 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:11:36.797204 20451 solver.cpp:244]     Train net output #1: loss = 0.125003 (* 1 = 0.125003 loss)
I0809 12:11:36.797216 20451 sgd_solver.cpp:106] Iteration 34880, lr = 0.00032431
I0809 12:11:59.085350 20451 solver.cpp:228] Iteration 34890, loss = 0.250028
I0809 12:11:59.085536 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:11:59.085551 20451 solver.cpp:244]     Train net output #1: loss = 0.250028 (* 1 = 0.250028 loss)
I0809 12:11:59.085563 20451 sgd_solver.cpp:106] Iteration 34890, lr = 0.000324256
I0809 12:12:19.153713 20451 solver.cpp:337] Iteration 34900, Testing net (#0)
I0809 12:12:27.675462 20451 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0809 12:12:27.675513 20451 solver.cpp:404]     Test net output #1: loss = 0.975054 (* 1 = 0.975054 loss)
I0809 12:12:29.874500 20451 solver.cpp:228] Iteration 34900, loss = 0.12501
I0809 12:12:29.874667 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:12:29.874682 20451 solver.cpp:244]     Train net output #1: loss = 0.12501 (* 1 = 0.12501 loss)
I0809 12:12:29.874694 20451 sgd_solver.cpp:106] Iteration 34900, lr = 0.000324202
I0809 12:12:52.154011 20451 solver.cpp:228] Iteration 34910, loss = 0.187546
I0809 12:12:52.154063 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:12:52.154078 20451 solver.cpp:244]     Train net output #1: loss = 0.187546 (* 1 = 0.187546 loss)
I0809 12:12:52.154089 20451 sgd_solver.cpp:106] Iteration 34910, lr = 0.000324148
I0809 12:13:14.446055 20451 solver.cpp:228] Iteration 34920, loss = 0.218832
I0809 12:13:14.446197 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:13:14.446216 20451 solver.cpp:244]     Train net output #1: loss = 0.218832 (* 1 = 0.218832 loss)
I0809 12:13:14.446231 20451 sgd_solver.cpp:106] Iteration 34920, lr = 0.000324093
I0809 12:13:36.733949 20451 solver.cpp:228] Iteration 34930, loss = 0.250129
I0809 12:13:36.733995 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:13:36.734014 20451 solver.cpp:244]     Train net output #1: loss = 0.25013 (* 1 = 0.25013 loss)
I0809 12:13:36.734038 20451 sgd_solver.cpp:106] Iteration 34930, lr = 0.000324039
I0809 12:13:59.020402 20451 solver.cpp:228] Iteration 34940, loss = 0.18752
I0809 12:13:59.020592 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:13:59.020612 20451 solver.cpp:244]     Train net output #1: loss = 0.18752 (* 1 = 0.18752 loss)
I0809 12:13:59.020627 20451 sgd_solver.cpp:106] Iteration 34940, lr = 0.000323985
I0809 12:14:21.313428 20451 solver.cpp:228] Iteration 34950, loss = 0.312673
I0809 12:14:21.313473 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 12:14:21.313489 20451 solver.cpp:244]     Train net output #1: loss = 0.312673 (* 1 = 0.312673 loss)
I0809 12:14:21.313501 20451 sgd_solver.cpp:106] Iteration 34950, lr = 0.000323931
I0809 12:14:43.612421 20451 solver.cpp:228] Iteration 34960, loss = 0.312529
I0809 12:14:43.612601 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 12:14:43.612617 20451 solver.cpp:244]     Train net output #1: loss = 0.312529 (* 1 = 0.312529 loss)
I0809 12:14:43.612630 20451 sgd_solver.cpp:106] Iteration 34960, lr = 0.000323877
I0809 12:15:05.897027 20451 solver.cpp:228] Iteration 34970, loss = 0.125047
I0809 12:15:05.897079 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:15:05.897094 20451 solver.cpp:244]     Train net output #1: loss = 0.125047 (* 1 = 0.125047 loss)
I0809 12:15:05.897106 20451 sgd_solver.cpp:106] Iteration 34970, lr = 0.000323823
I0809 12:15:28.183051 20451 solver.cpp:228] Iteration 34980, loss = 0.156308
I0809 12:15:28.183231 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:15:28.183250 20451 solver.cpp:244]     Train net output #1: loss = 0.156309 (* 1 = 0.156309 loss)
I0809 12:15:28.183265 20451 sgd_solver.cpp:106] Iteration 34980, lr = 0.000323769
I0809 12:15:50.464917 20451 solver.cpp:228] Iteration 34990, loss = 0.18755
I0809 12:15:50.464968 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:15:50.464982 20451 solver.cpp:244]     Train net output #1: loss = 0.18755 (* 1 = 0.18755 loss)
I0809 12:15:50.464995 20451 sgd_solver.cpp:106] Iteration 34990, lr = 0.000323715
I0809 12:16:10.518801 20451 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_35000.caffemodel
I0809 12:16:10.692868 20451 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_35000.solverstate
I0809 12:16:10.695668 20451 solver.cpp:337] Iteration 35000, Testing net (#0)
I0809 12:16:19.168545 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 12:16:19.168586 20451 solver.cpp:404]     Test net output #1: loss = 0.994029 (* 1 = 0.994029 loss)
I0809 12:16:21.366231 20451 solver.cpp:228] Iteration 35000, loss = 0.218842
I0809 12:16:21.366282 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:16:21.366297 20451 solver.cpp:244]     Train net output #1: loss = 0.218842 (* 1 = 0.218842 loss)
I0809 12:16:21.366309 20451 sgd_solver.cpp:106] Iteration 35000, lr = 0.000323661
I0809 12:16:43.649108 20451 solver.cpp:228] Iteration 35010, loss = 0.125022
I0809 12:16:43.649332 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:16:43.649348 20451 solver.cpp:244]     Train net output #1: loss = 0.125023 (* 1 = 0.125023 loss)
I0809 12:16:43.649360 20451 sgd_solver.cpp:106] Iteration 35010, lr = 0.000323607
I0809 12:17:05.947209 20451 solver.cpp:228] Iteration 35020, loss = 0.0937812
I0809 12:17:05.947262 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:17:05.947283 20451 solver.cpp:244]     Train net output #1: loss = 0.0937814 (* 1 = 0.0937814 loss)
I0809 12:17:05.947295 20451 sgd_solver.cpp:106] Iteration 35020, lr = 0.000323553
I0809 12:17:28.235191 20451 solver.cpp:228] Iteration 35030, loss = 0.218859
I0809 12:17:28.235363 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:17:28.235380 20451 solver.cpp:244]     Train net output #1: loss = 0.218859 (* 1 = 0.218859 loss)
I0809 12:17:28.235395 20451 sgd_solver.cpp:106] Iteration 35030, lr = 0.000323499
I0809 12:17:50.524205 20451 solver.cpp:228] Iteration 35040, loss = 0.218846
I0809 12:17:50.524248 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:17:50.524276 20451 solver.cpp:244]     Train net output #1: loss = 0.218846 (* 1 = 0.218846 loss)
I0809 12:17:50.524292 20451 sgd_solver.cpp:106] Iteration 35040, lr = 0.000323446
I0809 12:18:12.814620 20451 solver.cpp:228] Iteration 35050, loss = 0.0937601
I0809 12:18:12.814795 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:18:12.814810 20451 solver.cpp:244]     Train net output #1: loss = 0.0937603 (* 1 = 0.0937603 loss)
I0809 12:18:12.814823 20451 sgd_solver.cpp:106] Iteration 35050, lr = 0.000323392
I0809 12:18:35.108781 20451 solver.cpp:228] Iteration 35060, loss = 0.250065
I0809 12:18:35.108824 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:18:35.108839 20451 solver.cpp:244]     Train net output #1: loss = 0.250065 (* 1 = 0.250065 loss)
I0809 12:18:35.108850 20451 sgd_solver.cpp:106] Iteration 35060, lr = 0.000323338
I0809 12:18:57.393072 20451 solver.cpp:228] Iteration 35070, loss = 0.219095
I0809 12:18:57.393174 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:18:57.393195 20451 solver.cpp:244]     Train net output #1: loss = 0.219095 (* 1 = 0.219095 loss)
I0809 12:18:57.393209 20451 sgd_solver.cpp:106] Iteration 35070, lr = 0.000323284
I0809 12:19:19.674604 20451 solver.cpp:228] Iteration 35080, loss = 0.250294
I0809 12:19:19.674656 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:19:19.674670 20451 solver.cpp:244]     Train net output #1: loss = 0.250294 (* 1 = 0.250294 loss)
I0809 12:19:19.674682 20451 sgd_solver.cpp:106] Iteration 35080, lr = 0.00032323
I0809 12:19:42.118507 20451 solver.cpp:228] Iteration 35090, loss = 0.156367
I0809 12:19:42.118604 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:19:42.118619 20451 solver.cpp:244]     Train net output #1: loss = 0.156368 (* 1 = 0.156368 loss)
I0809 12:19:42.118631 20451 sgd_solver.cpp:106] Iteration 35090, lr = 0.000323177
I0809 12:20:02.484832 20451 solver.cpp:337] Iteration 35100, Testing net (#0)
I0809 12:20:11.173185 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 12:20:11.173235 20451 solver.cpp:404]     Test net output #1: loss = 1.00365 (* 1 = 1.00365 loss)
I0809 12:20:13.382874 20451 solver.cpp:228] Iteration 35100, loss = 0.250191
I0809 12:20:13.383059 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:20:13.383074 20451 solver.cpp:244]     Train net output #1: loss = 0.250191 (* 1 = 0.250191 loss)
I0809 12:20:13.383087 20451 sgd_solver.cpp:106] Iteration 35100, lr = 0.000323123
I0809 12:20:35.749490 20451 solver.cpp:228] Iteration 35110, loss = 0.125033
I0809 12:20:35.749541 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:20:35.749554 20451 solver.cpp:244]     Train net output #1: loss = 0.125034 (* 1 = 0.125034 loss)
I0809 12:20:35.749567 20451 sgd_solver.cpp:106] Iteration 35110, lr = 0.000323069
I0809 12:20:58.109336 20451 solver.cpp:228] Iteration 35120, loss = 0.250078
I0809 12:20:58.109549 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:20:58.109565 20451 solver.cpp:244]     Train net output #1: loss = 0.250078 (* 1 = 0.250078 loss)
I0809 12:20:58.109578 20451 sgd_solver.cpp:106] Iteration 35120, lr = 0.000323015
I0809 12:21:20.463537 20451 solver.cpp:228] Iteration 35130, loss = 0.187532
I0809 12:21:20.463587 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:21:20.463600 20451 solver.cpp:244]     Train net output #1: loss = 0.187532 (* 1 = 0.187532 loss)
I0809 12:21:20.463613 20451 sgd_solver.cpp:106] Iteration 35130, lr = 0.000322962
I0809 12:21:42.827016 20451 solver.cpp:228] Iteration 35140, loss = 0.250094
I0809 12:21:42.827118 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:21:42.827134 20451 solver.cpp:244]     Train net output #1: loss = 0.250094 (* 1 = 0.250094 loss)
I0809 12:21:42.827148 20451 sgd_solver.cpp:106] Iteration 35140, lr = 0.000322908
I0809 12:22:05.192121 20451 solver.cpp:228] Iteration 35150, loss = 0.156307
I0809 12:22:05.192173 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:22:05.192188 20451 solver.cpp:244]     Train net output #1: loss = 0.156307 (* 1 = 0.156307 loss)
I0809 12:22:05.192199 20451 sgd_solver.cpp:106] Iteration 35150, lr = 0.000322854
I0809 12:22:27.555181 20451 solver.cpp:228] Iteration 35160, loss = 0.250066
I0809 12:22:27.555359 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:22:27.555374 20451 solver.cpp:244]     Train net output #1: loss = 0.250066 (* 1 = 0.250066 loss)
I0809 12:22:27.555387 20451 sgd_solver.cpp:106] Iteration 35160, lr = 0.000322801
I0809 12:22:49.909523 20451 solver.cpp:228] Iteration 35170, loss = 0.343913
I0809 12:22:49.909575 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 12:22:49.909590 20451 solver.cpp:244]     Train net output #1: loss = 0.343914 (* 1 = 0.343914 loss)
I0809 12:22:49.909601 20451 sgd_solver.cpp:106] Iteration 35170, lr = 0.000322747
I0809 12:23:12.273311 20451 solver.cpp:228] Iteration 35180, loss = 0.218796
I0809 12:23:12.273494 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:23:12.273509 20451 solver.cpp:244]     Train net output #1: loss = 0.218796 (* 1 = 0.218796 loss)
I0809 12:23:12.273521 20451 sgd_solver.cpp:106] Iteration 35180, lr = 0.000322694
I0809 12:23:34.636677 20451 solver.cpp:228] Iteration 35190, loss = 0.125033
I0809 12:23:34.636728 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:23:34.636741 20451 solver.cpp:244]     Train net output #1: loss = 0.125033 (* 1 = 0.125033 loss)
I0809 12:23:34.636754 20451 sgd_solver.cpp:106] Iteration 35190, lr = 0.00032264
I0809 12:23:54.764086 20451 solver.cpp:337] Iteration 35200, Testing net (#0)
I0809 12:24:03.321636 20451 solver.cpp:404]     Test net output #0: accuracy = 0.678125
I0809 12:24:03.321688 20451 solver.cpp:404]     Test net output #1: loss = 0.965713 (* 1 = 0.965713 loss)
I0809 12:24:05.531391 20451 solver.cpp:228] Iteration 35200, loss = 0.0937623
I0809 12:24:05.531442 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:24:05.531456 20451 solver.cpp:244]     Train net output #1: loss = 0.0937625 (* 1 = 0.0937625 loss)
I0809 12:24:05.531468 20451 sgd_solver.cpp:106] Iteration 35200, lr = 0.000322587
I0809 12:24:27.870313 20451 solver.cpp:228] Iteration 35210, loss = 0.125003
I0809 12:24:27.870483 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:24:27.870498 20451 solver.cpp:244]     Train net output #1: loss = 0.125003 (* 1 = 0.125003 loss)
I0809 12:24:27.870510 20451 sgd_solver.cpp:106] Iteration 35210, lr = 0.000322533
I0809 12:24:50.228684 20451 solver.cpp:228] Iteration 35220, loss = 0.187532
I0809 12:24:50.228726 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:24:50.228744 20451 solver.cpp:244]     Train net output #1: loss = 0.187532 (* 1 = 0.187532 loss)
I0809 12:24:50.228759 20451 sgd_solver.cpp:106] Iteration 35220, lr = 0.000322479
I0809 12:25:12.606294 20451 solver.cpp:228] Iteration 35230, loss = 0.218775
I0809 12:25:12.606520 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:25:12.606540 20451 solver.cpp:244]     Train net output #1: loss = 0.218775 (* 1 = 0.218775 loss)
I0809 12:25:12.606555 20451 sgd_solver.cpp:106] Iteration 35230, lr = 0.000322426
I0809 12:25:34.965926 20451 solver.cpp:228] Iteration 35240, loss = 0.0938678
I0809 12:25:34.965970 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:25:34.965986 20451 solver.cpp:244]     Train net output #1: loss = 0.0938681 (* 1 = 0.0938681 loss)
I0809 12:25:34.965998 20451 sgd_solver.cpp:106] Iteration 35240, lr = 0.000322373
I0809 12:25:57.332263 20451 solver.cpp:228] Iteration 35250, loss = 0.156264
I0809 12:25:57.332445 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:25:57.332461 20451 solver.cpp:244]     Train net output #1: loss = 0.156264 (* 1 = 0.156264 loss)
I0809 12:25:57.332474 20451 sgd_solver.cpp:106] Iteration 35250, lr = 0.000322319
I0809 12:26:19.701117 20451 solver.cpp:228] Iteration 35260, loss = 0.0937672
I0809 12:26:19.701162 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:26:19.701182 20451 solver.cpp:244]     Train net output #1: loss = 0.0937674 (* 1 = 0.0937674 loss)
I0809 12:26:19.701197 20451 sgd_solver.cpp:106] Iteration 35260, lr = 0.000322266
I0809 12:26:42.072332 20451 solver.cpp:228] Iteration 35270, loss = 0.187585
I0809 12:26:42.072434 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:26:42.072451 20451 solver.cpp:244]     Train net output #1: loss = 0.187585 (* 1 = 0.187585 loss)
I0809 12:26:42.072463 20451 sgd_solver.cpp:106] Iteration 35270, lr = 0.000322212
I0809 12:27:04.432494 20451 solver.cpp:228] Iteration 35280, loss = 0.156448
I0809 12:27:04.432548 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:27:04.432561 20451 solver.cpp:244]     Train net output #1: loss = 0.156448 (* 1 = 0.156448 loss)
I0809 12:27:04.432574 20451 sgd_solver.cpp:106] Iteration 35280, lr = 0.000322159
I0809 12:27:26.791357 20451 solver.cpp:228] Iteration 35290, loss = 0.218829
I0809 12:27:26.791473 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:27:26.791493 20451 solver.cpp:244]     Train net output #1: loss = 0.218829 (* 1 = 0.218829 loss)
I0809 12:27:26.791509 20451 sgd_solver.cpp:106] Iteration 35290, lr = 0.000322106
I0809 12:27:46.919736 20451 solver.cpp:337] Iteration 35300, Testing net (#0)
I0809 12:27:55.476716 20451 solver.cpp:404]     Test net output #0: accuracy = 0.65625
I0809 12:27:55.476757 20451 solver.cpp:404]     Test net output #1: loss = 1.03127 (* 1 = 1.03127 loss)
I0809 12:27:57.692497 20451 solver.cpp:228] Iteration 35300, loss = 0.312512
I0809 12:27:57.692667 20451 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0809 12:27:57.692682 20451 solver.cpp:244]     Train net output #1: loss = 0.312513 (* 1 = 0.312513 loss)
I0809 12:27:57.692695 20451 sgd_solver.cpp:106] Iteration 35300, lr = 0.000322052
I0809 12:28:20.034821 20451 solver.cpp:228] Iteration 35310, loss = 0.125169
I0809 12:28:20.034865 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:28:20.034881 20451 solver.cpp:244]     Train net output #1: loss = 0.125169 (* 1 = 0.125169 loss)
I0809 12:28:20.034894 20451 sgd_solver.cpp:106] Iteration 35310, lr = 0.000321999
I0809 12:28:42.396816 20451 solver.cpp:228] Iteration 35320, loss = 0.218858
I0809 12:28:42.396987 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:28:42.397002 20451 solver.cpp:244]     Train net output #1: loss = 0.218859 (* 1 = 0.218859 loss)
I0809 12:28:42.397016 20451 sgd_solver.cpp:106] Iteration 35320, lr = 0.000321946
I0809 12:29:04.765791 20451 solver.cpp:228] Iteration 35330, loss = 0.187729
I0809 12:29:04.765836 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:29:04.765852 20451 solver.cpp:244]     Train net output #1: loss = 0.187729 (* 1 = 0.187729 loss)
I0809 12:29:04.765866 20451 sgd_solver.cpp:106] Iteration 35330, lr = 0.000321892
I0809 12:29:27.132611 20451 solver.cpp:228] Iteration 35340, loss = 0.156348
I0809 12:29:27.132823 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:29:27.132838 20451 solver.cpp:244]     Train net output #1: loss = 0.156349 (* 1 = 0.156349 loss)
I0809 12:29:27.132851 20451 sgd_solver.cpp:106] Iteration 35340, lr = 0.000321839
I0809 12:29:49.496659 20451 solver.cpp:228] Iteration 35350, loss = 0.187513
I0809 12:29:49.496711 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:29:49.496724 20451 solver.cpp:244]     Train net output #1: loss = 0.187514 (* 1 = 0.187514 loss)
I0809 12:29:49.496737 20451 sgd_solver.cpp:106] Iteration 35350, lr = 0.000321786
I0809 12:30:11.855068 20451 solver.cpp:228] Iteration 35360, loss = 0.218807
I0809 12:30:11.855245 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:30:11.855260 20451 solver.cpp:244]     Train net output #1: loss = 0.218807 (* 1 = 0.218807 loss)
I0809 12:30:11.855278 20451 sgd_solver.cpp:106] Iteration 35360, lr = 0.000321733
I0809 12:30:34.226006 20451 solver.cpp:228] Iteration 35370, loss = 0.250009
I0809 12:30:34.226057 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:30:34.226070 20451 solver.cpp:244]     Train net output #1: loss = 0.250009 (* 1 = 0.250009 loss)
I0809 12:30:34.226083 20451 sgd_solver.cpp:106] Iteration 35370, lr = 0.00032168
I0809 12:30:56.597280 20451 solver.cpp:228] Iteration 35380, loss = 0.0937638
I0809 12:30:56.597409 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:30:56.597424 20451 solver.cpp:244]     Train net output #1: loss = 0.093764 (* 1 = 0.093764 loss)
I0809 12:30:56.597437 20451 sgd_solver.cpp:106] Iteration 35380, lr = 0.000321626
I0809 12:31:18.965515 20451 solver.cpp:228] Iteration 35390, loss = 0.18752
I0809 12:31:18.965565 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:31:18.965579 20451 solver.cpp:244]     Train net output #1: loss = 0.18752 (* 1 = 0.18752 loss)
I0809 12:31:18.965590 20451 sgd_solver.cpp:106] Iteration 35390, lr = 0.000321573
I0809 12:31:39.101505 20451 solver.cpp:337] Iteration 35400, Testing net (#0)
I0809 12:31:47.648118 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 12:31:47.648167 20451 solver.cpp:404]     Test net output #1: loss = 1.0033 (* 1 = 1.0033 loss)
I0809 12:31:49.855713 20451 solver.cpp:228] Iteration 35400, loss = 0.156289
I0809 12:31:49.855761 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:31:49.855775 20451 solver.cpp:244]     Train net output #1: loss = 0.156289 (* 1 = 0.156289 loss)
I0809 12:31:49.855789 20451 sgd_solver.cpp:106] Iteration 35400, lr = 0.00032152
I0809 12:32:12.189569 20451 solver.cpp:228] Iteration 35410, loss = 0.187516
I0809 12:32:12.189748 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:32:12.189762 20451 solver.cpp:244]     Train net output #1: loss = 0.187516 (* 1 = 0.187516 loss)
I0809 12:32:12.189775 20451 sgd_solver.cpp:106] Iteration 35410, lr = 0.000321467
I0809 12:32:34.545195 20451 solver.cpp:228] Iteration 35420, loss = 0.25004
I0809 12:32:34.545248 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:32:34.545261 20451 solver.cpp:244]     Train net output #1: loss = 0.250041 (* 1 = 0.250041 loss)
I0809 12:32:34.545274 20451 sgd_solver.cpp:106] Iteration 35420, lr = 0.000321414
I0809 12:32:56.904307 20451 solver.cpp:228] Iteration 35430, loss = 0.218915
I0809 12:32:56.904479 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:32:56.904495 20451 solver.cpp:244]     Train net output #1: loss = 0.218915 (* 1 = 0.218915 loss)
I0809 12:32:56.904506 20451 sgd_solver.cpp:106] Iteration 35430, lr = 0.000321361
I0809 12:33:19.269549 20451 solver.cpp:228] Iteration 35440, loss = 0.343794
I0809 12:33:19.269598 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 12:33:19.269613 20451 solver.cpp:244]     Train net output #1: loss = 0.343795 (* 1 = 0.343795 loss)
I0809 12:33:19.269624 20451 sgd_solver.cpp:106] Iteration 35440, lr = 0.000321308
I0809 12:33:41.625731 20451 solver.cpp:228] Iteration 35450, loss = 0.218938
I0809 12:33:41.625941 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:33:41.625957 20451 solver.cpp:244]     Train net output #1: loss = 0.218938 (* 1 = 0.218938 loss)
I0809 12:33:41.625990 20451 sgd_solver.cpp:106] Iteration 35450, lr = 0.000321255
I0809 12:34:03.979128 20451 solver.cpp:228] Iteration 35460, loss = 0.187602
I0809 12:34:03.979176 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:34:03.979194 20451 solver.cpp:244]     Train net output #1: loss = 0.187602 (* 1 = 0.187602 loss)
I0809 12:34:03.979210 20451 sgd_solver.cpp:106] Iteration 35460, lr = 0.000321202
I0809 12:34:26.340328 20451 solver.cpp:228] Iteration 35470, loss = 0.156266
I0809 12:34:26.340504 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:34:26.340523 20451 solver.cpp:244]     Train net output #1: loss = 0.156266 (* 1 = 0.156266 loss)
I0809 12:34:26.340538 20451 sgd_solver.cpp:106] Iteration 35470, lr = 0.000321149
I0809 12:34:48.701833 20451 solver.cpp:228] Iteration 35480, loss = 0.187513
I0809 12:34:48.701875 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:34:48.701892 20451 solver.cpp:244]     Train net output #1: loss = 0.187513 (* 1 = 0.187513 loss)
I0809 12:34:48.701905 20451 sgd_solver.cpp:106] Iteration 35480, lr = 0.000321096
I0809 12:35:11.054313 20451 solver.cpp:228] Iteration 35490, loss = 0.156332
I0809 12:35:11.054489 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:35:11.054504 20451 solver.cpp:244]     Train net output #1: loss = 0.156332 (* 1 = 0.156332 loss)
I0809 12:35:11.054517 20451 sgd_solver.cpp:106] Iteration 35490, lr = 0.000321043
I0809 12:35:31.174708 20451 solver.cpp:337] Iteration 35500, Testing net (#0)
I0809 12:35:39.727551 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 12:35:39.727602 20451 solver.cpp:404]     Test net output #1: loss = 0.984533 (* 1 = 0.984533 loss)
I0809 12:35:41.935861 20451 solver.cpp:228] Iteration 35500, loss = 0.281317
I0809 12:35:41.936044 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 12:35:41.936059 20451 solver.cpp:244]     Train net output #1: loss = 0.281317 (* 1 = 0.281317 loss)
I0809 12:35:41.936072 20451 sgd_solver.cpp:106] Iteration 35500, lr = 0.00032099
I0809 12:36:04.254020 20451 solver.cpp:228] Iteration 35510, loss = 0.218804
I0809 12:36:04.254146 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:36:04.254185 20451 solver.cpp:244]     Train net output #1: loss = 0.218805 (* 1 = 0.218805 loss)
I0809 12:36:04.254223 20451 sgd_solver.cpp:106] Iteration 35510, lr = 0.000320937
I0809 12:36:26.607807 20451 solver.cpp:228] Iteration 35520, loss = 0.218852
I0809 12:36:26.607992 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:36:26.608007 20451 solver.cpp:244]     Train net output #1: loss = 0.218852 (* 1 = 0.218852 loss)
I0809 12:36:26.608021 20451 sgd_solver.cpp:106] Iteration 35520, lr = 0.000320884
I0809 12:36:48.956243 20451 solver.cpp:228] Iteration 35530, loss = 0.344076
I0809 12:36:48.956295 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 12:36:48.956308 20451 solver.cpp:244]     Train net output #1: loss = 0.344077 (* 1 = 0.344077 loss)
I0809 12:36:48.956321 20451 sgd_solver.cpp:106] Iteration 35530, lr = 0.000320831
I0809 12:37:11.318313 20451 solver.cpp:228] Iteration 35540, loss = 0.218836
I0809 12:37:11.318405 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:37:11.318421 20451 solver.cpp:244]     Train net output #1: loss = 0.218836 (* 1 = 0.218836 loss)
I0809 12:37:11.318434 20451 sgd_solver.cpp:106] Iteration 35540, lr = 0.000320778
I0809 12:37:33.685868 20451 solver.cpp:228] Iteration 35550, loss = 0.187702
I0809 12:37:33.685916 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:37:33.685930 20451 solver.cpp:244]     Train net output #1: loss = 0.187702 (* 1 = 0.187702 loss)
I0809 12:37:33.685942 20451 sgd_solver.cpp:106] Iteration 35550, lr = 0.000320726
I0809 12:37:56.039181 20451 solver.cpp:228] Iteration 35560, loss = 0.250097
I0809 12:37:56.039404 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:37:56.039422 20451 solver.cpp:244]     Train net output #1: loss = 0.250098 (* 1 = 0.250098 loss)
I0809 12:37:56.039433 20451 sgd_solver.cpp:106] Iteration 35560, lr = 0.000320673
I0809 12:38:18.405267 20451 solver.cpp:228] Iteration 35570, loss = 0.187692
I0809 12:38:18.405310 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:38:18.405328 20451 solver.cpp:244]     Train net output #1: loss = 0.187692 (* 1 = 0.187692 loss)
I0809 12:38:18.405354 20451 sgd_solver.cpp:106] Iteration 35570, lr = 0.00032062
I0809 12:38:40.765010 20451 solver.cpp:228] Iteration 35580, loss = 0.218771
I0809 12:38:40.765121 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:38:40.765141 20451 solver.cpp:244]     Train net output #1: loss = 0.218771 (* 1 = 0.218771 loss)
I0809 12:38:40.765156 20451 sgd_solver.cpp:106] Iteration 35580, lr = 0.000320567
I0809 12:39:03.128106 20451 solver.cpp:228] Iteration 35590, loss = 0.15632
I0809 12:39:03.128157 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:39:03.128171 20451 solver.cpp:244]     Train net output #1: loss = 0.15632 (* 1 = 0.15632 loss)
I0809 12:39:03.128183 20451 sgd_solver.cpp:106] Iteration 35590, lr = 0.000320515
I0809 12:39:23.246851 20451 solver.cpp:337] Iteration 35600, Testing net (#0)
I0809 12:39:31.805352 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 12:39:31.805402 20451 solver.cpp:404]     Test net output #1: loss = 0.998514 (* 1 = 0.998514 loss)
I0809 12:39:34.014924 20451 solver.cpp:228] Iteration 35600, loss = 0.312658
I0809 12:39:34.014964 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:39:34.014989 20451 solver.cpp:244]     Train net output #1: loss = 0.312659 (* 1 = 0.312659 loss)
I0809 12:39:34.015005 20451 sgd_solver.cpp:106] Iteration 35600, lr = 0.000320462
I0809 12:39:56.337239 20451 solver.cpp:228] Iteration 35610, loss = 0.250265
I0809 12:39:56.337419 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:39:56.337437 20451 solver.cpp:244]     Train net output #1: loss = 0.250265 (* 1 = 0.250265 loss)
I0809 12:39:56.337453 20451 sgd_solver.cpp:106] Iteration 35610, lr = 0.000320409
I0809 12:40:18.687507 20451 solver.cpp:228] Iteration 35620, loss = 0.0938229
I0809 12:40:18.687549 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:40:18.687564 20451 solver.cpp:244]     Train net output #1: loss = 0.0938232 (* 1 = 0.0938232 loss)
I0809 12:40:18.687577 20451 sgd_solver.cpp:106] Iteration 35620, lr = 0.000320357
I0809 12:40:41.039877 20451 solver.cpp:228] Iteration 35630, loss = 0.125166
I0809 12:40:41.040071 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:40:41.040086 20451 solver.cpp:244]     Train net output #1: loss = 0.125166 (* 1 = 0.125166 loss)
I0809 12:40:41.040099 20451 sgd_solver.cpp:106] Iteration 35630, lr = 0.000320304
I0809 12:41:03.399888 20451 solver.cpp:228] Iteration 35640, loss = 0.125159
I0809 12:41:03.399940 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:41:03.399953 20451 solver.cpp:244]     Train net output #1: loss = 0.125159 (* 1 = 0.125159 loss)
I0809 12:41:03.399966 20451 sgd_solver.cpp:106] Iteration 35640, lr = 0.000320251
I0809 12:41:25.753320 20451 solver.cpp:228] Iteration 35650, loss = 0.250242
I0809 12:41:25.753481 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:41:25.753518 20451 solver.cpp:244]     Train net output #1: loss = 0.250242 (* 1 = 0.250242 loss)
I0809 12:41:25.753551 20451 sgd_solver.cpp:106] Iteration 35650, lr = 0.000320199
I0809 12:41:48.117559 20451 solver.cpp:228] Iteration 35660, loss = 0.125045
I0809 12:41:48.117611 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:41:48.117626 20451 solver.cpp:244]     Train net output #1: loss = 0.125046 (* 1 = 0.125046 loss)
I0809 12:41:48.117638 20451 sgd_solver.cpp:106] Iteration 35660, lr = 0.000320146
I0809 12:42:10.482511 20451 solver.cpp:228] Iteration 35670, loss = 0.0937895
I0809 12:42:10.482899 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:42:10.482916 20451 solver.cpp:244]     Train net output #1: loss = 0.0937898 (* 1 = 0.0937898 loss)
I0809 12:42:10.482928 20451 sgd_solver.cpp:106] Iteration 35670, lr = 0.000320093
I0809 12:42:32.844736 20451 solver.cpp:228] Iteration 35680, loss = 0.218773
I0809 12:42:32.844790 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:42:32.844805 20451 solver.cpp:244]     Train net output #1: loss = 0.218773 (* 1 = 0.218773 loss)
I0809 12:42:32.844816 20451 sgd_solver.cpp:106] Iteration 35680, lr = 0.000320041
I0809 12:42:55.208783 20451 solver.cpp:228] Iteration 35690, loss = 0.343891
I0809 12:42:55.208976 20451 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0809 12:42:55.208995 20451 solver.cpp:244]     Train net output #1: loss = 0.343892 (* 1 = 0.343892 loss)
I0809 12:42:55.209009 20451 sgd_solver.cpp:106] Iteration 35690, lr = 0.000319988
I0809 12:43:15.356957 20451 solver.cpp:337] Iteration 35700, Testing net (#0)
I0809 12:43:23.914014 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 12:43:23.914057 20451 solver.cpp:404]     Test net output #1: loss = 0.998599 (* 1 = 0.998599 loss)
I0809 12:43:26.124279 20451 solver.cpp:228] Iteration 35700, loss = 0.250059
I0809 12:43:26.124387 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:43:26.124403 20451 solver.cpp:244]     Train net output #1: loss = 0.250059 (* 1 = 0.250059 loss)
I0809 12:43:26.124416 20451 sgd_solver.cpp:106] Iteration 35700, lr = 0.000319936
I0809 12:43:48.452447 20451 solver.cpp:228] Iteration 35710, loss = 0.187566
I0809 12:43:48.452497 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:43:48.452512 20451 solver.cpp:244]     Train net output #1: loss = 0.187566 (* 1 = 0.187566 loss)
I0809 12:43:48.452524 20451 sgd_solver.cpp:106] Iteration 35710, lr = 0.000319883
I0809 12:44:10.820314 20451 solver.cpp:228] Iteration 35720, loss = 0.187557
I0809 12:44:10.820425 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:44:10.820446 20451 solver.cpp:244]     Train net output #1: loss = 0.187557 (* 1 = 0.187557 loss)
I0809 12:44:10.820464 20451 sgd_solver.cpp:106] Iteration 35720, lr = 0.000319831
I0809 12:44:33.177670 20451 solver.cpp:228] Iteration 35730, loss = 0.156304
I0809 12:44:33.177721 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:44:33.177736 20451 solver.cpp:244]     Train net output #1: loss = 0.156304 (* 1 = 0.156304 loss)
I0809 12:44:33.177748 20451 sgd_solver.cpp:106] Iteration 35730, lr = 0.000319778
I0809 12:44:55.543390 20451 solver.cpp:228] Iteration 35740, loss = 0.093775
I0809 12:44:55.543567 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:44:55.543582 20451 solver.cpp:244]     Train net output #1: loss = 0.0937752 (* 1 = 0.0937752 loss)
I0809 12:44:55.543594 20451 sgd_solver.cpp:106] Iteration 35740, lr = 0.000319726
I0809 12:45:17.912850 20451 solver.cpp:228] Iteration 35750, loss = 0.218771
I0809 12:45:17.912890 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:45:17.912905 20451 solver.cpp:244]     Train net output #1: loss = 0.218771 (* 1 = 0.218771 loss)
I0809 12:45:17.912919 20451 sgd_solver.cpp:106] Iteration 35750, lr = 0.000319674
I0809 12:45:40.282829 20451 solver.cpp:228] Iteration 35760, loss = 0.218822
I0809 12:45:40.283004 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:45:40.283020 20451 solver.cpp:244]     Train net output #1: loss = 0.218822 (* 1 = 0.218822 loss)
I0809 12:45:40.283031 20451 sgd_solver.cpp:106] Iteration 35760, lr = 0.000319621
I0809 12:46:02.653578 20451 solver.cpp:228] Iteration 35770, loss = -2.68221e-07
I0809 12:46:02.653625 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:46:02.653641 20451 solver.cpp:244]     Train net output #1: loss = 0 (* 1 = 0 loss)
I0809 12:46:02.653656 20451 sgd_solver.cpp:106] Iteration 35770, lr = 0.000319569
I0809 12:46:25.011247 20451 solver.cpp:228] Iteration 35780, loss = 0.0312815
I0809 12:46:25.011466 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 12:46:25.011487 20451 solver.cpp:244]     Train net output #1: loss = 0.0312817 (* 1 = 0.0312817 loss)
I0809 12:46:25.011500 20451 sgd_solver.cpp:106] Iteration 35780, lr = 0.000319516
I0809 12:46:47.372869 20451 solver.cpp:228] Iteration 35790, loss = 0.187766
I0809 12:46:47.372920 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:46:47.372934 20451 solver.cpp:244]     Train net output #1: loss = 0.187766 (* 1 = 0.187766 loss)
I0809 12:46:47.372946 20451 sgd_solver.cpp:106] Iteration 35790, lr = 0.000319464
I0809 12:47:07.505806 20451 solver.cpp:337] Iteration 35800, Testing net (#0)
I0809 12:47:16.064654 20451 solver.cpp:404]     Test net output #0: accuracy = 0.664062
I0809 12:47:16.064699 20451 solver.cpp:404]     Test net output #1: loss = 1.00786 (* 1 = 1.00786 loss)
I0809 12:47:18.271085 20451 solver.cpp:228] Iteration 35800, loss = 0.156261
I0809 12:47:18.271136 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:47:18.271152 20451 solver.cpp:244]     Train net output #1: loss = 0.156261 (* 1 = 0.156261 loss)
I0809 12:47:18.271163 20451 sgd_solver.cpp:106] Iteration 35800, lr = 0.000319412
I0809 12:47:40.596891 20451 solver.cpp:228] Iteration 35810, loss = 0.218846
I0809 12:47:40.597070 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:47:40.597085 20451 solver.cpp:244]     Train net output #1: loss = 0.218846 (* 1 = 0.218846 loss)
I0809 12:47:40.597097 20451 sgd_solver.cpp:106] Iteration 35810, lr = 0.000319359
I0809 12:48:02.970789 20451 solver.cpp:228] Iteration 35820, loss = 0.0937709
I0809 12:48:02.970840 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:48:02.970854 20451 solver.cpp:244]     Train net output #1: loss = 0.0937712 (* 1 = 0.0937712 loss)
I0809 12:48:02.970866 20451 sgd_solver.cpp:106] Iteration 35820, lr = 0.000319307
I0809 12:48:25.333045 20451 solver.cpp:228] Iteration 35830, loss = 0.062518
I0809 12:48:25.333230 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 12:48:25.333245 20451 solver.cpp:244]     Train net output #1: loss = 0.0625183 (* 1 = 0.0625183 loss)
I0809 12:48:25.333258 20451 sgd_solver.cpp:106] Iteration 35830, lr = 0.000319255
I0809 12:48:47.694087 20451 solver.cpp:228] Iteration 35840, loss = 0.218767
I0809 12:48:47.694140 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:48:47.694154 20451 solver.cpp:244]     Train net output #1: loss = 0.218767 (* 1 = 0.218767 loss)
I0809 12:48:47.694167 20451 sgd_solver.cpp:106] Iteration 35840, lr = 0.000319203
I0809 12:49:10.058040 20451 solver.cpp:228] Iteration 35850, loss = 0.218856
I0809 12:49:10.058215 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 12:49:10.058230 20451 solver.cpp:244]     Train net output #1: loss = 0.218856 (* 1 = 0.218856 loss)
I0809 12:49:10.058243 20451 sgd_solver.cpp:106] Iteration 35850, lr = 0.00031915
I0809 12:49:32.424204 20451 solver.cpp:228] Iteration 35860, loss = 0.187584
I0809 12:49:32.424243 20451 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I0809 12:49:32.424265 20451 solver.cpp:244]     Train net output #1: loss = 0.187585 (* 1 = 0.187585 loss)
I0809 12:49:32.424280 20451 sgd_solver.cpp:106] Iteration 35860, lr = 0.000319098
I0809 12:49:54.790704 20451 solver.cpp:228] Iteration 35870, loss = 0.250063
I0809 12:49:54.790808 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:49:54.790825 20451 solver.cpp:244]     Train net output #1: loss = 0.250064 (* 1 = 0.250064 loss)
I0809 12:49:54.790839 20451 sgd_solver.cpp:106] Iteration 35870, lr = 0.000319046
I0809 12:50:17.157024 20451 solver.cpp:228] Iteration 35880, loss = 0.125025
I0809 12:50:17.157069 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:50:17.157084 20451 solver.cpp:244]     Train net output #1: loss = 0.125026 (* 1 = 0.125026 loss)
I0809 12:50:17.157099 20451 sgd_solver.cpp:106] Iteration 35880, lr = 0.000318994
I0809 12:50:39.522209 20451 solver.cpp:228] Iteration 35890, loss = 0.250112
I0809 12:50:39.522430 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:50:39.522445 20451 solver.cpp:244]     Train net output #1: loss = 0.250112 (* 1 = 0.250112 loss)
I0809 12:50:39.522459 20451 sgd_solver.cpp:106] Iteration 35890, lr = 0.000318942
I0809 12:50:59.651029 20451 solver.cpp:337] Iteration 35900, Testing net (#0)
I0809 12:51:08.213768 20451 solver.cpp:404]     Test net output #0: accuracy = 0.665625
I0809 12:51:08.213819 20451 solver.cpp:404]     Test net output #1: loss = 1.00315 (* 1 = 1.00315 loss)
I0809 12:51:10.423193 20451 solver.cpp:228] Iteration 35900, loss = 0.187507
I0809 12:51:10.423370 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:51:10.423389 20451 solver.cpp:244]     Train net output #1: loss = 0.187507 (* 1 = 0.187507 loss)
I0809 12:51:10.423403 20451 sgd_solver.cpp:106] Iteration 35900, lr = 0.00031889
I0809 12:51:32.753317 20451 solver.cpp:228] Iteration 35910, loss = 0.125004
I0809 12:51:32.753360 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:51:32.753376 20451 solver.cpp:244]     Train net output #1: loss = 0.125004 (* 1 = 0.125004 loss)
I0809 12:51:32.753388 20451 sgd_solver.cpp:106] Iteration 35910, lr = 0.000318838
I0809 12:51:55.113320 20451 solver.cpp:228] Iteration 35920, loss = 0.187586
I0809 12:51:55.113497 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:51:55.113512 20451 solver.cpp:244]     Train net output #1: loss = 0.187586 (* 1 = 0.187586 loss)
I0809 12:51:55.113524 20451 sgd_solver.cpp:106] Iteration 35920, lr = 0.000318786
I0809 12:52:17.477366 20451 solver.cpp:228] Iteration 35930, loss = 0.281341
I0809 12:52:17.477418 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 12:52:17.477432 20451 solver.cpp:244]     Train net output #1: loss = 0.281341 (* 1 = 0.281341 loss)
I0809 12:52:17.477444 20451 sgd_solver.cpp:106] Iteration 35930, lr = 0.000318733
I0809 12:52:39.839675 20451 solver.cpp:228] Iteration 35940, loss = 0.187553
I0809 12:52:39.839851 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:52:39.839866 20451 solver.cpp:244]     Train net output #1: loss = 0.187553 (* 1 = 0.187553 loss)
I0809 12:52:39.839879 20451 sgd_solver.cpp:106] Iteration 35940, lr = 0.000318681
I0809 12:53:02.211304 20451 solver.cpp:228] Iteration 35950, loss = 0.250031
I0809 12:53:02.211356 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:53:02.211371 20451 solver.cpp:244]     Train net output #1: loss = 0.250031 (* 1 = 0.250031 loss)
I0809 12:53:02.211383 20451 sgd_solver.cpp:106] Iteration 35950, lr = 0.000318629
I0809 12:53:24.572477 20451 solver.cpp:228] Iteration 35960, loss = 0.125052
I0809 12:53:24.572651 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:53:24.572667 20451 solver.cpp:244]     Train net output #1: loss = 0.125052 (* 1 = 0.125052 loss)
I0809 12:53:24.572680 20451 sgd_solver.cpp:106] Iteration 35960, lr = 0.000318577
I0809 12:53:46.934463 20451 solver.cpp:228] Iteration 35970, loss = 0.250111
I0809 12:53:46.934512 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:53:46.934526 20451 solver.cpp:244]     Train net output #1: loss = 0.250111 (* 1 = 0.250111 loss)
I0809 12:53:46.934538 20451 sgd_solver.cpp:106] Iteration 35970, lr = 0.000318525
I0809 12:54:09.295111 20451 solver.cpp:228] Iteration 35980, loss = 0.125052
I0809 12:54:09.295229 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:54:09.295249 20451 solver.cpp:244]     Train net output #1: loss = 0.125053 (* 1 = 0.125053 loss)
I0809 12:54:09.295264 20451 sgd_solver.cpp:106] Iteration 35980, lr = 0.000318474
I0809 12:54:31.658311 20451 solver.cpp:228] Iteration 35990, loss = 0.156254
I0809 12:54:31.658357 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:54:31.658375 20451 solver.cpp:244]     Train net output #1: loss = 0.156254 (* 1 = 0.156254 loss)
I0809 12:54:31.658391 20451 sgd_solver.cpp:106] Iteration 35990, lr = 0.000318422
I0809 12:54:51.792057 20451 solver.cpp:337] Iteration 36000, Testing net (#0)
I0809 12:55:00.350241 20451 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0809 12:55:00.350292 20451 solver.cpp:404]     Test net output #1: loss = 0.961172 (* 1 = 0.961172 loss)
I0809 12:55:02.561259 20451 solver.cpp:228] Iteration 36000, loss = 0.250088
I0809 12:55:02.561311 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 12:55:02.561326 20451 solver.cpp:244]     Train net output #1: loss = 0.250088 (* 1 = 0.250088 loss)
I0809 12:55:02.561337 20451 sgd_solver.cpp:106] Iteration 36000, lr = 0.00031837
I0809 12:55:24.895236 20451 solver.cpp:228] Iteration 36010, loss = 0.125044
I0809 12:55:24.895421 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:55:24.895439 20451 solver.cpp:244]     Train net output #1: loss = 0.125045 (* 1 = 0.125045 loss)
I0809 12:55:24.895454 20451 sgd_solver.cpp:106] Iteration 36010, lr = 0.000318318
I0809 12:55:47.258160 20451 solver.cpp:228] Iteration 36020, loss = 0.156262
I0809 12:55:47.258208 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:55:47.258225 20451 solver.cpp:244]     Train net output #1: loss = 0.156262 (* 1 = 0.156262 loss)
I0809 12:55:47.258241 20451 sgd_solver.cpp:106] Iteration 36020, lr = 0.000318266
I0809 12:56:09.624138 20451 solver.cpp:228] Iteration 36030, loss = 0.0937565
I0809 12:56:09.624308 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:56:09.624327 20451 solver.cpp:244]     Train net output #1: loss = 0.0937568 (* 1 = 0.0937568 loss)
I0809 12:56:09.624342 20451 sgd_solver.cpp:106] Iteration 36030, lr = 0.000318214
I0809 12:56:31.981482 20451 solver.cpp:228] Iteration 36040, loss = 0.125022
I0809 12:56:31.981530 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:56:31.981549 20451 solver.cpp:244]     Train net output #1: loss = 0.125022 (* 1 = 0.125022 loss)
I0809 12:56:31.981565 20451 sgd_solver.cpp:106] Iteration 36040, lr = 0.000318162
I0809 12:56:54.350654 20451 solver.cpp:228] Iteration 36050, loss = 0.187519
I0809 12:56:54.350837 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 12:56:54.350853 20451 solver.cpp:244]     Train net output #1: loss = 0.18752 (* 1 = 0.18752 loss)
I0809 12:56:54.350865 20451 sgd_solver.cpp:106] Iteration 36050, lr = 0.00031811
I0809 12:57:16.719868 20451 solver.cpp:228] Iteration 36060, loss = 0.125024
I0809 12:57:16.719910 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 12:57:16.719925 20451 solver.cpp:244]     Train net output #1: loss = 0.125025 (* 1 = 0.125025 loss)
I0809 12:57:16.719938 20451 sgd_solver.cpp:106] Iteration 36060, lr = 0.000318059
I0809 12:57:39.093576 20451 solver.cpp:228] Iteration 36070, loss = 0.0625232
I0809 12:57:39.096717 20451 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0809 12:57:39.096735 20451 solver.cpp:244]     Train net output #1: loss = 0.0625235 (* 1 = 0.0625235 loss)
I0809 12:57:39.096748 20451 sgd_solver.cpp:106] Iteration 36070, lr = 0.000318007
I0809 12:58:01.445760 20451 solver.cpp:228] Iteration 36080, loss = 0.0937602
I0809 12:58:01.445811 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:58:01.445825 20451 solver.cpp:244]     Train net output #1: loss = 0.0937605 (* 1 = 0.0937605 loss)
I0809 12:58:01.445837 20451 sgd_solver.cpp:106] Iteration 36080, lr = 0.000317955
I0809 12:58:23.811771 20451 solver.cpp:228] Iteration 36090, loss = 0.156325
I0809 12:58:23.811992 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 12:58:23.812008 20451 solver.cpp:244]     Train net output #1: loss = 0.156325 (* 1 = 0.156325 loss)
I0809 12:58:23.812021 20451 sgd_solver.cpp:106] Iteration 36090, lr = 0.000317903
I0809 12:58:43.949791 20451 solver.cpp:337] Iteration 36100, Testing net (#0)
I0809 12:58:52.497887 20451 solver.cpp:404]     Test net output #0: accuracy = 0.66875
I0809 12:58:52.497941 20451 solver.cpp:404]     Test net output #1: loss = 0.993812 (* 1 = 0.993812 loss)
I0809 12:58:54.711993 20451 solver.cpp:228] Iteration 36100, loss = 0.156264
I0809 12:58:54.712087 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 12:58:54.712103 20451 solver.cpp:244]     Train net output #1: loss = 0.156264 (* 1 = 0.156264 loss)
I0809 12:58:54.712116 20451 sgd_solver.cpp:106] Iteration 36100, lr = 0.000317852
I0809 12:59:17.039199 20451 solver.cpp:228] Iteration 36110, loss = 0.093766
I0809 12:59:17.039250 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:59:17.039265 20451 solver.cpp:244]     Train net output #1: loss = 0.0937663 (* 1 = 0.0937663 loss)
I0809 12:59:17.039280 20451 sgd_solver.cpp:106] Iteration 36110, lr = 0.0003178
I0809 12:59:39.395572 20451 solver.cpp:228] Iteration 36120, loss = 0.0937707
I0809 12:59:39.395721 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 12:59:39.395745 20451 solver.cpp:244]     Train net output #1: loss = 0.093771 (* 1 = 0.093771 loss)
I0809 12:59:39.395761 20451 sgd_solver.cpp:106] Iteration 36120, lr = 0.000317748
I0809 13:00:01.758095 20451 solver.cpp:228] Iteration 36130, loss = 0.156454
I0809 13:00:01.758139 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 13:00:01.758157 20451 solver.cpp:244]     Train net output #1: loss = 0.156454 (* 1 = 0.156454 loss)
I0809 13:00:01.758172 20451 sgd_solver.cpp:106] Iteration 36130, lr = 0.000317697
I0809 13:00:24.117058 20451 solver.cpp:228] Iteration 36140, loss = 0.187617
I0809 13:00:24.117233 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 13:00:24.117249 20451 solver.cpp:244]     Train net output #1: loss = 0.187617 (* 1 = 0.187617 loss)
I0809 13:00:24.117261 20451 sgd_solver.cpp:106] Iteration 36140, lr = 0.000317645
I0809 13:00:46.477619 20451 solver.cpp:228] Iteration 36150, loss = 0.0938585
I0809 13:00:46.477669 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 13:00:46.477684 20451 solver.cpp:244]     Train net output #1: loss = 0.0938588 (* 1 = 0.0938588 loss)
I0809 13:00:46.477697 20451 sgd_solver.cpp:106] Iteration 36150, lr = 0.000317593
I0809 13:01:08.843642 20451 solver.cpp:228] Iteration 36160, loss = 0.187675
I0809 13:01:08.843768 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 13:01:08.843789 20451 solver.cpp:244]     Train net output #1: loss = 0.187675 (* 1 = 0.187675 loss)
I0809 13:01:08.843806 20451 sgd_solver.cpp:106] Iteration 36160, lr = 0.000317542
I0809 13:01:31.299588 20451 solver.cpp:228] Iteration 36170, loss = 0.218899
I0809 13:01:31.299631 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 13:01:31.299649 20451 solver.cpp:244]     Train net output #1: loss = 0.2189 (* 1 = 0.2189 loss)
I0809 13:01:31.299664 20451 sgd_solver.cpp:106] Iteration 36170, lr = 0.00031749
I0809 13:01:53.751869 20451 solver.cpp:228] Iteration 36180, loss = 0.281412
I0809 13:01:53.751971 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 13:01:53.751991 20451 solver.cpp:244]     Train net output #1: loss = 0.281413 (* 1 = 0.281413 loss)
I0809 13:01:53.752007 20451 sgd_solver.cpp:106] Iteration 36180, lr = 0.000317438
I0809 13:02:16.053274 20451 solver.cpp:228] Iteration 36190, loss = 0.125131
I0809 13:02:16.053326 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 13:02:16.053339 20451 solver.cpp:244]     Train net output #1: loss = 0.125132 (* 1 = 0.125132 loss)
I0809 13:02:16.053351 20451 sgd_solver.cpp:106] Iteration 36190, lr = 0.000317387
I0809 13:02:36.126014 20451 solver.cpp:337] Iteration 36200, Testing net (#0)
I0809 13:02:44.639595 20451 solver.cpp:404]     Test net output #0: accuracy = 0.667188
I0809 13:02:44.639644 20451 solver.cpp:404]     Test net output #1: loss = 0.9989 (* 1 = 0.9989 loss)
I0809 13:02:46.844146 20451 solver.cpp:228] Iteration 36200, loss = 0.125086
I0809 13:02:46.844195 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 13:02:46.844214 20451 solver.cpp:244]     Train net output #1: loss = 0.125086 (* 1 = 0.125086 loss)
I0809 13:02:46.844230 20451 sgd_solver.cpp:106] Iteration 36200, lr = 0.000317335
I0809 13:03:09.138216 20451 solver.cpp:228] Iteration 36210, loss = 0.218975
I0809 13:03:09.138394 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 13:03:09.138411 20451 solver.cpp:244]     Train net output #1: loss = 0.218975 (* 1 = 0.218975 loss)
I0809 13:03:09.138423 20451 sgd_solver.cpp:106] Iteration 36210, lr = 0.000317284
I0809 13:03:31.447535 20451 solver.cpp:228] Iteration 36220, loss = 0.281533
I0809 13:03:31.447585 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 13:03:31.447599 20451 solver.cpp:244]     Train net output #1: loss = 0.281533 (* 1 = 0.281533 loss)
I0809 13:03:31.447610 20451 sgd_solver.cpp:106] Iteration 36220, lr = 0.000317232
I0809 13:03:53.760792 20451 solver.cpp:228] Iteration 36230, loss = 0.125066
I0809 13:03:53.760908 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 13:03:53.760927 20451 solver.cpp:244]     Train net output #1: loss = 0.125066 (* 1 = 0.125066 loss)
I0809 13:03:53.760941 20451 sgd_solver.cpp:106] Iteration 36230, lr = 0.000317181
I0809 13:04:16.077342 20451 solver.cpp:228] Iteration 36240, loss = 0.0938461
I0809 13:04:16.077385 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 13:04:16.077404 20451 solver.cpp:244]     Train net output #1: loss = 0.0938464 (* 1 = 0.0938464 loss)
I0809 13:04:16.077424 20451 sgd_solver.cpp:106] Iteration 36240, lr = 0.00031713
I0809 13:04:38.386690 20451 solver.cpp:228] Iteration 36250, loss = 0.125023
I0809 13:04:38.386790 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 13:04:38.386804 20451 solver.cpp:244]     Train net output #1: loss = 0.125024 (* 1 = 0.125024 loss)
I0809 13:04:38.386817 20451 sgd_solver.cpp:106] Iteration 36250, lr = 0.000317078
I0809 13:05:00.853091 20451 solver.cpp:228] Iteration 36260, loss = 0.218806
I0809 13:05:00.853142 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 13:05:00.853155 20451 solver.cpp:244]     Train net output #1: loss = 0.218806 (* 1 = 0.218806 loss)
I0809 13:05:00.853166 20451 sgd_solver.cpp:106] Iteration 36260, lr = 0.000317027
I0809 13:05:23.350404 20451 solver.cpp:228] Iteration 36270, loss = 0.125047
I0809 13:05:23.350584 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 13:05:23.350602 20451 solver.cpp:244]     Train net output #1: loss = 0.125048 (* 1 = 0.125048 loss)
I0809 13:05:23.350618 20451 sgd_solver.cpp:106] Iteration 36270, lr = 0.000316975
I0809 13:05:45.692538 20451 solver.cpp:228] Iteration 36280, loss = 0.15628
I0809 13:05:45.692581 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 13:05:45.692600 20451 solver.cpp:244]     Train net output #1: loss = 0.15628 (* 1 = 0.15628 loss)
I0809 13:05:45.692615 20451 sgd_solver.cpp:106] Iteration 36280, lr = 0.000316924
I0809 13:06:08.102248 20451 solver.cpp:228] Iteration 36290, loss = 0.156327
I0809 13:06:08.102418 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 13:06:08.102434 20451 solver.cpp:244]     Train net output #1: loss = 0.156328 (* 1 = 0.156328 loss)
I0809 13:06:08.102447 20451 sgd_solver.cpp:106] Iteration 36290, lr = 0.000316873
I0809 13:06:28.351663 20451 solver.cpp:337] Iteration 36300, Testing net (#0)
I0809 13:06:36.882731 20451 solver.cpp:404]     Test net output #0: accuracy = 0.670313
I0809 13:06:36.882776 20451 solver.cpp:404]     Test net output #1: loss = 0.989169 (* 1 = 0.989169 loss)
I0809 13:06:39.083252 20451 solver.cpp:228] Iteration 36300, loss = 0.156274
I0809 13:06:39.083403 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 13:06:39.083425 20451 solver.cpp:244]     Train net output #1: loss = 0.156274 (* 1 = 0.156274 loss)
I0809 13:06:39.083439 20451 sgd_solver.cpp:106] Iteration 36300, lr = 0.000316821
I0809 13:07:01.552456 20451 solver.cpp:228] Iteration 36310, loss = 0.250157
I0809 13:07:01.552505 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 13:07:01.552520 20451 solver.cpp:244]     Train net output #1: loss = 0.250157 (* 1 = 0.250157 loss)
I0809 13:07:01.552531 20451 sgd_solver.cpp:106] Iteration 36310, lr = 0.00031677
I0809 13:07:24.041698 20451 solver.cpp:228] Iteration 36320, loss = 0.218773
I0809 13:07:24.041931 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 13:07:24.042002 20451 solver.cpp:244]     Train net output #1: loss = 0.218773 (* 1 = 0.218773 loss)
I0809 13:07:24.042043 20451 sgd_solver.cpp:106] Iteration 36320, lr = 0.000316719
I0809 13:07:46.587451 20451 solver.cpp:228] Iteration 36330, loss = 0.156311
I0809 13:07:46.587502 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 13:07:46.587515 20451 solver.cpp:244]     Train net output #1: loss = 0.156311 (* 1 = 0.156311 loss)
I0809 13:07:46.587527 20451 sgd_solver.cpp:106] Iteration 36330, lr = 0.000316667
I0809 13:08:08.923861 20451 solver.cpp:228] Iteration 36340, loss = 0.218815
I0809 13:08:08.923959 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 13:08:08.923974 20451 solver.cpp:244]     Train net output #1: loss = 0.218815 (* 1 = 0.218815 loss)
I0809 13:08:08.923987 20451 sgd_solver.cpp:106] Iteration 36340, lr = 0.000316616
I0809 13:08:31.316897 20451 solver.cpp:228] Iteration 36350, loss = 0.250048
I0809 13:08:31.316948 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 13:08:31.316962 20451 solver.cpp:244]     Train net output #1: loss = 0.250049 (* 1 = 0.250049 loss)
I0809 13:08:31.316973 20451 sgd_solver.cpp:106] Iteration 36350, lr = 0.000316565
I0809 13:08:53.755533 20451 solver.cpp:228] Iteration 36360, loss = 0.125034
I0809 13:08:53.755626 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 13:08:53.755641 20451 solver.cpp:244]     Train net output #1: loss = 0.125034 (* 1 = 0.125034 loss)
I0809 13:08:53.755652 20451 sgd_solver.cpp:106] Iteration 36360, lr = 0.000316514
I0809 13:09:16.371687 20451 solver.cpp:228] Iteration 36370, loss = 0.218779
I0809 13:09:16.371728 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 13:09:16.371743 20451 solver.cpp:244]     Train net output #1: loss = 0.218779 (* 1 = 0.218779 loss)
I0809 13:09:16.371757 20451 sgd_solver.cpp:106] Iteration 36370, lr = 0.000316462
I0809 13:09:38.820974 20451 solver.cpp:228] Iteration 36380, loss = 0.156276
I0809 13:09:38.821156 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 13:09:38.821173 20451 solver.cpp:244]     Train net output #1: loss = 0.156276 (* 1 = 0.156276 loss)
I0809 13:09:38.821192 20451 sgd_solver.cpp:106] Iteration 36380, lr = 0.000316411
I0809 13:10:01.241595 20451 solver.cpp:228] Iteration 36390, loss = 0.1875
I0809 13:10:01.241634 20451 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0809 13:10:01.241650 20451 solver.cpp:244]     Train net output #1: loss = 0.187501 (* 1 = 0.187501 loss)
I0809 13:10:01.241662 20451 sgd_solver.cpp:106] Iteration 36390, lr = 0.00031636
I0809 13:10:21.452143 20451 solver.cpp:337] Iteration 36400, Testing net (#0)
I0809 13:10:30.036758 20451 solver.cpp:404]     Test net output #0: accuracy = 0.654688
I0809 13:10:30.036809 20451 solver.cpp:404]     Test net output #1: loss = 1.03605 (* 1 = 1.03605 loss)
I0809 13:10:32.252022 20451 solver.cpp:228] Iteration 36400, loss = 0.156275
I0809 13:10:32.252065 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 13:10:32.252080 20451 solver.cpp:244]     Train net output #1: loss = 0.156276 (* 1 = 0.156276 loss)
I0809 13:10:32.252092 20451 sgd_solver.cpp:106] Iteration 36400, lr = 0.000316309
I0809 13:10:54.581367 20451 solver.cpp:228] Iteration 36410, loss = 0.218756
I0809 13:10:54.581765 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 13:10:54.581811 20451 solver.cpp:244]     Train net output #1: loss = 0.218756 (* 1 = 0.218756 loss)
I0809 13:10:54.581850 20451 sgd_solver.cpp:106] Iteration 36410, lr = 0.000316258
I0809 13:11:16.986469 20451 solver.cpp:228] Iteration 36420, loss = 0.156447
I0809 13:11:16.986515 20451 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0809 13:11:16.986531 20451 solver.cpp:244]     Train net output #1: loss = 0.156447 (* 1 = 0.156447 loss)
I0809 13:11:16.986542 20451 sgd_solver.cpp:106] Iteration 36420, lr = 0.000316207
I0809 13:11:39.460916 20451 solver.cpp:228] Iteration 36430, loss = 0.218866
I0809 13:11:39.461096 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 13:11:39.461112 20451 solver.cpp:244]     Train net output #1: loss = 0.218867 (* 1 = 0.218867 loss)
I0809 13:11:39.461124 20451 sgd_solver.cpp:106] Iteration 36430, lr = 0.000316156
I0809 13:12:01.909083 20451 solver.cpp:228] Iteration 36440, loss = 0.218804
I0809 13:12:01.909124 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 13:12:01.909139 20451 solver.cpp:244]     Train net output #1: loss = 0.218804 (* 1 = 0.218804 loss)
I0809 13:12:01.909152 20451 sgd_solver.cpp:106] Iteration 36440, lr = 0.000316105
I0809 13:12:24.244369 20451 solver.cpp:228] Iteration 36450, loss = 0.0939901
I0809 13:12:24.244467 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 13:12:24.244485 20451 solver.cpp:244]     Train net output #1: loss = 0.0939904 (* 1 = 0.0939904 loss)
I0809 13:12:24.244501 20451 sgd_solver.cpp:106] Iteration 36450, lr = 0.000316054
I0809 13:12:46.643260 20451 solver.cpp:228] Iteration 36460, loss = 0.18757
I0809 13:12:46.643308 20451 solver.cpp:244]     Train net output #0: accuracy = 1
I0809 13:12:46.643326 20451 solver.cpp:244]     Train net output #1: loss = 0.18757 (* 1 = 0.18757 loss)
I0809 13:12:46.643338 20451 sgd_solver.cpp:106] Iteration 36460, lr = 0.000316003
I0809 13:13:09.133651 20451 solver.cpp:228] Iteration 36470, loss = 0.28125
I0809 13:13:09.133749 20451 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0809 13:13:09.133764 20451 solver.cpp:244]     Train net output #1: loss = 0.28125 (* 1 = 0.28125 loss)
I0809 13:13:09.133776 20451 sgd_solver.cpp:106] Iteration 36470, lr = 0.000315952
I0809 13:13:31.469588 20451 solver.cpp:228] Iteration 36480, loss = 0.250086
I0809 13:13:31.469642 20451 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0809 13:13:31.469656 20451 solver.cpp:244]     Train net output #1: loss = 0.250086 (* 1 = 0.250086 loss)
I0809 13:13:31.469668 20451 sgd_solver.cpp:106] Iteration 36480, lr = 0.000315901
I0809 13:13:53.955334 20451 solver.cpp:228] Iteration 36490, loss = 0.0937682
I0809 13:13:53.955510 20451 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I0809 13:13:53.955529 20451 solver.cpp:244]     Train net output #1: loss = 0.0937685 (* 1 = 0.0937685 loss)
I0809 13:13:53.955545 20451 sgd_solver.cpp:106] Iteration 36490, lr = 0.00031585
I0809 13:14:14.177346 20451 solver.cpp:337] Iteration 36500, Testing net (#0)
I0809 13:14:22.722998 20451 solver.cpp:404]     Test net output #0: accuracy = 0.671875
I0809 13:14:22.723044 20451 solver.cpp:404]     Test net output #1: loss = 0.984436 (* 1 = 0.984436 loss)
I0809 13:14:24.937633 20451 solver.cpp:228] Iteration 36500, loss = 0.21877
I0809 13:14:24.937815 20451 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0809 13:14:24.937830 20451 solver.cpp:244]     Train net output #1: loss = 0.21877 (* 1 = 0.21877 loss)
I0809 13:14:24.937844 20451 sgd_solver.cpp:106] Iteration 36500, lr = 0.000315799
I0809 13:14:47.306457 20451 solver.cpp:228] Iteration 36510, loss = 0.125042
I0809 13:14:47.306500 20451 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0809 13:14:47.306529 20451 solver.cpp:244]     Train net output #1: loss = 0.125042 (* 1 = 0.125042 loss)
I0809 13:14:47.306543 20451 sgd_solver.cpp:106] Iteration 36510, lr = 0.000315748
