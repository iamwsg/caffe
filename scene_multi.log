./build/tools/caffe: /home/shaogangwang/anaconda2/lib/libtiff.so.5: no version information available (required by /usr/local/lib/libopencv_highgui.so.2.4)
I0816 16:03:59.365404 20404 caffe.cpp:185] Using GPUs 0
I0816 16:03:59.379818 20404 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0816 16:03:59.716140 20404 solver.cpp:48] Initializing solver from parameters: 
train_net: "examples/scene/matchNetTrainHingeMini.prototxt"
test_net: "examples/scene/matchNetTestHingeMini.prototxt"
test_iter: 10
test_interval: 40
base_lr: 0.001
display: 10
max_iter: 300000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0002
snapshot: 1000
snapshot_prefix: "examples/scene/scene"
solver_mode: GPU
device_id: 0
I0816 16:03:59.716332 20404 solver.cpp:81] Creating training net from train_net file: examples/scene/matchNetTrainHingeMini.prototxt
I0816 16:03:59.759481 20404 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215689
    mirror: true
    mean_file: "examples/scene/scene_mean.binaryproto"
  }
  data_param {
    source: "examples/scene/train_pairs_1000_pad.lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "th"
  type: "Threshold"
  bottom: "label"
  top: "th"
  threshold_param {
    threshold: 0
  }
}
layer {
  name: "i1"
  type: "Slice"
  bottom: "data"
  top: "i1"
  top: "i2"
  slice_param {
    slice_dim: 1
    slice_point: 3
  }
}
layer {
  name: "p1"
  type: "Pooling"
  bottom: "i1"
  top: "p1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "p2"
  type: "Pooling"
  bottom: "i2"
  top: "p2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input1"
  type: "Input"
  top: "Input1"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c11"
  type: "Crop"
  bottom: "i1"
  bottom: "Input1"
  top: "c11"
  crop_param {
    axis: 2
    offset: 0
    offset: 0
  }
}
layer {
  name: "Input2"
  type: "Input"
  top: "Input2"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c12"
  type: "Crop"
  bottom: "i1"
  bottom: "Input2"
  top: "c12"
  crop_param {
    axis: 2
    offset: 0
    offset: 32
  }
}
layer {
  name: "Input3"
  type: "Input"
  top: "Input3"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c13"
  type: "Crop"
  bottom: "i1"
  bottom: "Input3"
  top: "c13"
  crop_param {
    axis: 2
    offset: 0
    offset: 64
  }
}
layer {
  name: "Input4"
  type: "Input"
  top: "Input4"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c14"
  type: "Crop"
  bottom: "i1"
  bottom: "Input4"
  top: "c14"
  crop_param {
    axis: 2
    offset: 32
    offset: 0
  }
}
layer {
  name: "Input5"
  type: "Input"
  top: "Input5"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c15"
  type: "Crop"
  bottom: "i1"
  bottom: "Input5"
  top: "c15"
  crop_param {
    axis: 2
    offset: 32
    offset: 32
  }
}
layer {
  name: "Input6"
  type: "Input"
  top: "Input6"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c16"
  type: "Crop"
  bottom: "i1"
  bottom: "Input6"
  top: "c16"
  crop_param {
    axis: 2
    offset: 32
    offset: 64
  }
}
layer {
  name: "Input7"
  type: "Input"
  top: "Input7"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c17"
  type: "Crop"
  bottom: "i1"
  bottom: "Input7"
  top: "c17"
  crop_param {
    axis: 2
    offset: 64
    offset: 0
  }
}
layer {
  name: "Input8"
  type: "Input"
  top: "Input8"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c18"
  type: "Crop"
  bottom: "i1"
  bottom: "Input8"
  top: "c18"
  crop_param {
    axis: 2
    offset: 64
    offset: 32
  }
}
layer {
  name: "Input9"
  type: "Input"
  top: "Input9"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c19"
  type: "Crop"
  bottom: "i1"
  bottom: "Input9"
  top: "c19"
  crop_param {
    axis: 2
    offset: 64
    offset: 64
  }
}
layer {
  name: "Input10"
  type: "Input"
  top: "Input10"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c21"
  type: "Crop"
  bottom: "i2"
  bottom: "Input10"
  top: "c21"
  crop_param {
    axis: 2
    offset: 0
    offset: 0
  }
}
layer {
  name: "Input11"
  type: "Input"
  top: "Input11"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c22"
  type: "Crop"
  bottom: "i2"
  bottom: "Input11"
  top: "c22"
  crop_param {
    axis: 2
    offset: 0
    offset: 32
  }
}
layer {
  name: "Input12"
  type: "Input"
  top: "Input12"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c23"
  type: "Crop"
  bottom: "i2"
  bottom: "Input12"
  top: "c23"
  crop_param {
    axis: 2
    offset: 0
    offset: 64
  }
}
layer {
  name: "Input13"
  type: "Input"
  top: "Input13"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c24"
  type: "Crop"
  bottom: "i2"
  bottom: "Input13"
  top: "c24"
  crop_param {
    axis: 2
    offset: 32
    offset: 0
  }
}
layer {
  name: "Input14"
  type: "Input"
  top: "Input14"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c25"
  type: "Crop"
  bottom: "i2"
  bottom: "Input14"
  top: "c25"
  crop_param {
    axis: 2
    offset: 32
    offset: 32
  }
}
layer {
  name: "Input15"
  type: "Input"
  top: "Input15"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c26"
  type: "Crop"
  bottom: "i2"
  bottom: "Input15"
  top: "c26"
  crop_param {
    axis: 2
    offset: 32
    offset: 64
  }
}
layer {
  name: "Input16"
  type: "Input"
  top: "Input16"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c27"
  type: "Crop"
  bottom: "i2"
  bottom: "Input16"
  top: "c27"
  crop_param {
    axis: 2
    offset: 64
    offset: 0
  }
}
layer {
  name: "Input17"
  type: "Input"
  top: "Input17"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c28"
  type: "Crop"
  bottom: "i2"
  bottom: "Input17"
  top: "c28"
  crop_param {
    axis: 2
    offset: 64
    offset: 32
  }
}
layer {
  name: "Input18"
  type: "Input"
  top: "Input18"
  include {
    phase: TRAIN
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c29"
  type: "Crop"
  bottom: "i2"
  bottom: "Input18"
  top: "c29"
  crop_param {
    axis: 2
    offset: 64
    offset: 64
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "Convolution1"
  top: "LRN1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "LRN1"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Pooling1"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "Convolution2"
  top: "LRN2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "LRN2"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Pooling2"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution3"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "Convolution5"
  top: "Pooling3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling3"
  top: "InnerProduct1"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "InnerProduct1"
  top: "InnerProduct2"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "InnerProduct2"
  top: "InnerProduct2"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "p2"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "Convolution6"
  top: "LRN3"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "LRN3"
  top: "Pooling4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Pooling4"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution7"
  top: "Convolution7"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "Convolution7"
  top: "LRN4"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "LRN4"
  top: "Pooling5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Pooling5"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "Convolution10"
  top: "Pooling6"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "Pooling6"
  top: "InnerProduct3"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "InnerProduct3"
  top: "InnerProduct3"
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "InnerProduct3"
  top: "InnerProduct4"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "InnerProduct4"
  top: "InnerProduct4"
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "InnerProduct2"
  bottom: "InnerProduct4"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct5"
  type: "InnerProduct"
  bottom: "Concat1"
  top: "InnerProduct5"
  param {
    name: "fc8_w"
    lr_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "InnerProduct5"
  top: "InnerProduct5"
}
layer {
  name: "InnerProduct6"
  type: "InnerProduct"
  bottom: "InnerProduct5"
  top: "InnerProduct6"
  param {
    name: "fc9_w"
    lr_mult: 1
  }
  param {
    name: "fc9_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "InnerProduct6"
  top: "InnerProduct6"
}
layer {
  name: "dt0"
  type: "InnerProduct"
  bottom: "InnerProduct6"
  top: "dt0"
  param {
    name: "fc10_w"
    lr_mult: 1
  }
  param {
    name: "fc10_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "Convolution11"
  top: "LRN5"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "LRN5"
  top: "Pooling7"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Pooling7"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "Convolution12"
  top: "LRN6"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "LRN6"
  top: "Pooling8"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Pooling8"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "Convolution15"
  top: "Pooling9"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "InnerProduct7"
  type: "InnerProduct"
  bottom: "Pooling9"
  top: "InnerProduct7"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "InnerProduct7"
  top: "InnerProduct7"
}
layer {
  name: "InnerProduct8"
  type: "InnerProduct"
  bottom: "InnerProduct7"
  top: "InnerProduct8"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "InnerProduct8"
  top: "InnerProduct8"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "c21"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "Convolution16"
  top: "LRN7"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "LRN7"
  top: "Pooling10"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Pooling10"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "Convolution17"
  top: "LRN8"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "LRN8"
  top: "Pooling11"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Pooling11"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "Convolution20"
  top: "Pooling12"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "InnerProduct9"
  type: "InnerProduct"
  bottom: "Pooling12"
  top: "InnerProduct9"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "InnerProduct9"
  top: "InnerProduct9"
}
layer {
  name: "InnerProduct10"
  type: "InnerProduct"
  bottom: "InnerProduct9"
  top: "InnerProduct10"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "InnerProduct10"
  top: "InnerProduct10"
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "InnerProduct8"
  bottom: "InnerProduct10"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct11"
  type: "InnerProduct"
  bottom: "Concat2"
  top: "InnerProduct11"
  param {
    name: "fc8_w"
    lr_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "InnerProduct11"
  top: "InnerProduct11"
}
layer {
  name: "InnerProduct12"
  type: "InnerProduct"
  bottom: "InnerProduct11"
  top: "InnerProduct12"
  param {
    name: "fc9_w"
    lr_mult: 1
  }
  param {
    name: "fc9_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "InnerProduct12"
  top: "InnerProduct12"
}
layer {
  name: "dt1"
  type: "InnerProduct"
  bottom: "InnerProduct12"
  top: "dt1"
  param {
    name: "fc10_w"
    lr_mult: 1
  }
  param {
    name: "fc10_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "Convolution21"
  top: "LRN9"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "LRN9"
  top: "Pooling13"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Pooling13"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "Convolution22"
  top: "LRN10"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "LRN10"
  top: "Pooling14"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Pooling14"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "Convolution25"
  top: "Pooling15"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "InnerProduct13"
  type: "InnerProduct"
  bottom: "Pooling15"
  top: "InnerProduct13"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "InnerProduct13"
  top: "InnerProduct13"
}
layer {
  name: "InnerProduct14"
  type: "InnerProduct"
  bottom: "InnerProduct13"
  top: "InnerProduct14"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "InnerProduct14"
  top: "InnerProduct14"
}
layer {
  name: "conv1"
  type: "Convolution"
 
I0816 16:03:59.766497 20404 layer_factory.hpp:77] Creating layer data
I0816 16:03:59.767405 20404 net.cpp:91] Creating Layer data
I0816 16:03:59.767426 20404 net.cpp:399] data -> data
I0816 16:03:59.767464 20404 net.cpp:399] data -> label
I0816 16:03:59.767490 20404 data_transformer.cpp:25] Loading mean file from: examples/scene/scene_mean.binaryproto
I0816 16:03:59.768841 20412 db_lmdb.cpp:35] Opened lmdb examples/scene/train_pairs_1000_pad.lmdb
I0816 16:03:59.790372 20404 data_layer.cpp:41] output data size: 100,6,128,128
I0816 16:03:59.891811 20404 net.cpp:141] Setting up data
I0816 16:03:59.891862 20404 net.cpp:148] Top shape: 100 6 128 128 (9830400)
I0816 16:03:59.891873 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:03:59.891882 20404 net.cpp:156] Memory required for data: 39322000
I0816 16:03:59.891898 20404 layer_factory.hpp:77] Creating layer label_data_1_split
I0816 16:03:59.891928 20404 net.cpp:91] Creating Layer label_data_1_split
I0816 16:03:59.891939 20404 net.cpp:425] label_data_1_split <- label
I0816 16:03:59.891957 20404 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0816 16:03:59.891978 20404 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0816 16:03:59.892051 20404 net.cpp:141] Setting up label_data_1_split
I0816 16:03:59.892067 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:03:59.892078 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:03:59.892089 20404 net.cpp:156] Memory required for data: 39322800
I0816 16:03:59.892099 20404 layer_factory.hpp:77] Creating layer th
I0816 16:03:59.892120 20404 net.cpp:91] Creating Layer th
I0816 16:03:59.892132 20404 net.cpp:425] th <- label_data_1_split_0
I0816 16:03:59.892143 20404 net.cpp:399] th -> th
I0816 16:03:59.892186 20404 net.cpp:141] Setting up th
I0816 16:03:59.892200 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:03:59.892210 20404 net.cpp:156] Memory required for data: 39323200
I0816 16:03:59.892220 20404 layer_factory.hpp:77] Creating layer th_th_0_split
I0816 16:03:59.892230 20404 net.cpp:91] Creating Layer th_th_0_split
I0816 16:03:59.892238 20404 net.cpp:425] th_th_0_split <- th
I0816 16:03:59.892249 20404 net.cpp:399] th_th_0_split -> th_th_0_split_0
I0816 16:03:59.892282 20404 net.cpp:399] th_th_0_split -> th_th_0_split_1
I0816 16:03:59.892331 20404 net.cpp:141] Setting up th_th_0_split
I0816 16:03:59.892344 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:03:59.892357 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:03:59.892366 20404 net.cpp:156] Memory required for data: 39324000
I0816 16:03:59.892374 20404 layer_factory.hpp:77] Creating layer i1
I0816 16:03:59.892395 20404 net.cpp:91] Creating Layer i1
I0816 16:03:59.892403 20404 net.cpp:425] i1 <- data
I0816 16:03:59.892416 20404 net.cpp:399] i1 -> i1
I0816 16:03:59.892436 20404 net.cpp:399] i1 -> i2
I0816 16:03:59.892487 20404 net.cpp:141] Setting up i1
I0816 16:03:59.892498 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.892511 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.892521 20404 net.cpp:156] Memory required for data: 78645600
I0816 16:03:59.892529 20404 layer_factory.hpp:77] Creating layer i1_i1_0_split
I0816 16:03:59.892542 20404 net.cpp:91] Creating Layer i1_i1_0_split
I0816 16:03:59.892554 20404 net.cpp:425] i1_i1_0_split <- i1
I0816 16:03:59.892565 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_0
I0816 16:03:59.892582 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_1
I0816 16:03:59.892601 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_2
I0816 16:03:59.892618 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_3
I0816 16:03:59.892635 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_4
I0816 16:03:59.892652 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_5
I0816 16:03:59.892669 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_6
I0816 16:03:59.892686 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_7
I0816 16:03:59.892706 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_8
I0816 16:03:59.892724 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_9
I0816 16:03:59.892902 20404 net.cpp:141] Setting up i1_i1_0_split
I0816 16:03:59.892915 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.892928 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.892940 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.892951 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.892964 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.892976 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.892987 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.893000 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.893013 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.893026 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.893036 20404 net.cpp:156] Memory required for data: 275253600
I0816 16:03:59.893044 20404 layer_factory.hpp:77] Creating layer i2_i1_1_split
I0816 16:03:59.893059 20404 net.cpp:91] Creating Layer i2_i1_1_split
I0816 16:03:59.893069 20404 net.cpp:425] i2_i1_1_split <- i2
I0816 16:03:59.893082 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_0
I0816 16:03:59.893100 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_1
I0816 16:03:59.893120 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_2
I0816 16:03:59.893137 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_3
I0816 16:03:59.893154 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_4
I0816 16:03:59.893172 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_5
I0816 16:03:59.893189 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_6
I0816 16:03:59.893206 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_7
I0816 16:03:59.893224 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_8
I0816 16:03:59.893240 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_9
I0816 16:03:59.899155 20404 net.cpp:141] Setting up i2_i1_1_split
I0816 16:03:59.899174 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.899184 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.899196 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.899206 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.899232 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.899245 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.899256 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.899267 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.899322 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.899340 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:03:59.899354 20404 net.cpp:156] Memory required for data: 471861600
I0816 16:03:59.899369 20404 layer_factory.hpp:77] Creating layer p1
I0816 16:03:59.899394 20404 net.cpp:91] Creating Layer p1
I0816 16:03:59.899410 20404 net.cpp:425] p1 <- i1_i1_0_split_0
I0816 16:03:59.899427 20404 net.cpp:399] p1 -> p1
I0816 16:03:59.899500 20404 net.cpp:141] Setting up p1
I0816 16:03:59.899518 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.899533 20404 net.cpp:156] Memory required for data: 476776800
I0816 16:03:59.899547 20404 layer_factory.hpp:77] Creating layer p1_p1_0_split
I0816 16:03:59.899571 20404 net.cpp:91] Creating Layer p1_p1_0_split
I0816 16:03:59.899585 20404 net.cpp:425] p1_p1_0_split <- p1
I0816 16:03:59.899605 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_0
I0816 16:03:59.899631 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_1
I0816 16:03:59.899658 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_2
I0816 16:03:59.899693 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_3
I0816 16:03:59.899718 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_4
I0816 16:03:59.899744 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_5
I0816 16:03:59.899770 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_6
I0816 16:03:59.899797 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_7
I0816 16:03:59.899823 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_8
I0816 16:03:59.899852 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_9
I0816 16:03:59.900099 20404 net.cpp:141] Setting up p1_p1_0_split
I0816 16:03:59.900117 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900133 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900151 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900166 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900180 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900195 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900212 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900226 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900243 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900257 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900269 20404 net.cpp:156] Memory required for data: 525928800
I0816 16:03:59.900280 20404 layer_factory.hpp:77] Creating layer p2
I0816 16:03:59.900296 20404 net.cpp:91] Creating Layer p2
I0816 16:03:59.900308 20404 net.cpp:425] p2 <- i2_i1_1_split_0
I0816 16:03:59.900326 20404 net.cpp:399] p2 -> p2
I0816 16:03:59.900378 20404 net.cpp:141] Setting up p2
I0816 16:03:59.900395 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.900408 20404 net.cpp:156] Memory required for data: 530844000
I0816 16:03:59.900418 20404 layer_factory.hpp:77] Creating layer p2_p2_0_split
I0816 16:03:59.900434 20404 net.cpp:91] Creating Layer p2_p2_0_split
I0816 16:03:59.900446 20404 net.cpp:425] p2_p2_0_split <- p2
I0816 16:03:59.900465 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_0
I0816 16:03:59.900487 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_1
I0816 16:03:59.900511 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_2
I0816 16:03:59.900538 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_3
I0816 16:03:59.900564 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_4
I0816 16:03:59.900591 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_5
I0816 16:03:59.900619 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_6
I0816 16:03:59.900642 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_7
I0816 16:03:59.900666 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_8
I0816 16:03:59.900713 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_9
I0816 16:03:59.900995 20404 net.cpp:141] Setting up p2_p2_0_split
I0816 16:03:59.901017 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901031 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901046 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901060 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901075 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901089 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901103 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901118 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901131 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901145 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901155 20404 net.cpp:156] Memory required for data: 579996000
I0816 16:03:59.901166 20404 layer_factory.hpp:77] Creating layer Input1
I0816 16:03:59.901185 20404 net.cpp:91] Creating Layer Input1
I0816 16:03:59.901201 20404 net.cpp:399] Input1 -> Input1
I0816 16:03:59.901275 20404 net.cpp:141] Setting up Input1
I0816 16:03:59.901296 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901310 20404 net.cpp:156] Memory required for data: 584911200
I0816 16:03:59.901324 20404 layer_factory.hpp:77] Creating layer c11
I0816 16:03:59.901353 20404 net.cpp:91] Creating Layer c11
I0816 16:03:59.901366 20404 net.cpp:425] c11 <- i1_i1_0_split_1
I0816 16:03:59.901381 20404 net.cpp:425] c11 <- Input1
I0816 16:03:59.901398 20404 net.cpp:399] c11 -> c11
I0816 16:03:59.901463 20404 net.cpp:141] Setting up c11
I0816 16:03:59.901479 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901490 20404 net.cpp:156] Memory required for data: 589826400
I0816 16:03:59.901501 20404 layer_factory.hpp:77] Creating layer Input2
I0816 16:03:59.901517 20404 net.cpp:91] Creating Layer Input2
I0816 16:03:59.901532 20404 net.cpp:399] Input2 -> Input2
I0816 16:03:59.901585 20404 net.cpp:141] Setting up Input2
I0816 16:03:59.901602 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901612 20404 net.cpp:156] Memory required for data: 594741600
I0816 16:03:59.901623 20404 layer_factory.hpp:77] Creating layer c12
I0816 16:03:59.901639 20404 net.cpp:91] Creating Layer c12
I0816 16:03:59.901650 20404 net.cpp:425] c12 <- i1_i1_0_split_2
I0816 16:03:59.901666 20404 net.cpp:425] c12 <- Input2
I0816 16:03:59.901684 20404 net.cpp:399] c12 -> c12
I0816 16:03:59.901739 20404 net.cpp:141] Setting up c12
I0816 16:03:59.901764 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901778 20404 net.cpp:156] Memory required for data: 599656800
I0816 16:03:59.901789 20404 layer_factory.hpp:77] Creating layer Input3
I0816 16:03:59.901804 20404 net.cpp:91] Creating Layer Input3
I0816 16:03:59.901819 20404 net.cpp:399] Input3 -> Input3
I0816 16:03:59.901872 20404 net.cpp:141] Setting up Input3
I0816 16:03:59.901888 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.901898 20404 net.cpp:156] Memory required for data: 604572000
I0816 16:03:59.901909 20404 layer_factory.hpp:77] Creating layer c13
I0816 16:03:59.901931 20404 net.cpp:91] Creating Layer c13
I0816 16:03:59.901942 20404 net.cpp:425] c13 <- i1_i1_0_split_3
I0816 16:03:59.901957 20404 net.cpp:425] c13 <- Input3
I0816 16:03:59.901975 20404 net.cpp:399] c13 -> c13
I0816 16:03:59.902029 20404 net.cpp:141] Setting up c13
I0816 16:03:59.902046 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.902056 20404 net.cpp:156] Memory required for data: 609487200
I0816 16:03:59.902067 20404 layer_factory.hpp:77] Creating layer Input4
I0816 16:03:59.902084 20404 net.cpp:91] Creating Layer Input4
I0816 16:03:59.902099 20404 net.cpp:399] Input4 -> Input4
I0816 16:03:59.902151 20404 net.cpp:141] Setting up Input4
I0816 16:03:59.902168 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.902179 20404 net.cpp:156] Memory required for data: 614402400
I0816 16:03:59.902209 20404 layer_factory.hpp:77] Creating layer c14
I0816 16:03:59.902225 20404 net.cpp:91] Creating Layer c14
I0816 16:03:59.902237 20404 net.cpp:425] c14 <- i1_i1_0_split_4
I0816 16:03:59.902252 20404 net.cpp:425] c14 <- Input4
I0816 16:03:59.902269 20404 net.cpp:399] c14 -> c14
I0816 16:03:59.902323 20404 net.cpp:141] Setting up c14
I0816 16:03:59.902339 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.902350 20404 net.cpp:156] Memory required for data: 619317600
I0816 16:03:59.902361 20404 layer_factory.hpp:77] Creating layer Input5
I0816 16:03:59.902377 20404 net.cpp:91] Creating Layer Input5
I0816 16:03:59.902391 20404 net.cpp:399] Input5 -> Input5
I0816 16:03:59.902443 20404 net.cpp:141] Setting up Input5
I0816 16:03:59.902462 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.902473 20404 net.cpp:156] Memory required for data: 624232800
I0816 16:03:59.902483 20404 layer_factory.hpp:77] Creating layer c15
I0816 16:03:59.902498 20404 net.cpp:91] Creating Layer c15
I0816 16:03:59.902508 20404 net.cpp:425] c15 <- i1_i1_0_split_5
I0816 16:03:59.902523 20404 net.cpp:425] c15 <- Input5
I0816 16:03:59.902539 20404 net.cpp:399] c15 -> c15
I0816 16:03:59.902591 20404 net.cpp:141] Setting up c15
I0816 16:03:59.902607 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.902618 20404 net.cpp:156] Memory required for data: 629148000
I0816 16:03:59.902629 20404 layer_factory.hpp:77] Creating layer Input6
I0816 16:03:59.902644 20404 net.cpp:91] Creating Layer Input6
I0816 16:03:59.902660 20404 net.cpp:399] Input6 -> Input6
I0816 16:03:59.902712 20404 net.cpp:141] Setting up Input6
I0816 16:03:59.902732 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.902743 20404 net.cpp:156] Memory required for data: 634063200
I0816 16:03:59.902755 20404 layer_factory.hpp:77] Creating layer c16
I0816 16:03:59.902770 20404 net.cpp:91] Creating Layer c16
I0816 16:03:59.902782 20404 net.cpp:425] c16 <- i1_i1_0_split_6
I0816 16:03:59.902798 20404 net.cpp:425] c16 <- Input6
I0816 16:03:59.902817 20404 net.cpp:399] c16 -> c16
I0816 16:03:59.902868 20404 net.cpp:141] Setting up c16
I0816 16:03:59.902885 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.902896 20404 net.cpp:156] Memory required for data: 638978400
I0816 16:03:59.902907 20404 layer_factory.hpp:77] Creating layer Input7
I0816 16:03:59.902923 20404 net.cpp:91] Creating Layer Input7
I0816 16:03:59.902940 20404 net.cpp:399] Input7 -> Input7
I0816 16:03:59.902989 20404 net.cpp:141] Setting up Input7
I0816 16:03:59.903007 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.903018 20404 net.cpp:156] Memory required for data: 643893600
I0816 16:03:59.903029 20404 layer_factory.hpp:77] Creating layer c17
I0816 16:03:59.903045 20404 net.cpp:91] Creating Layer c17
I0816 16:03:59.903059 20404 net.cpp:425] c17 <- i1_i1_0_split_7
I0816 16:03:59.903074 20404 net.cpp:425] c17 <- Input7
I0816 16:03:59.903090 20404 net.cpp:399] c17 -> c17
I0816 16:03:59.903152 20404 net.cpp:141] Setting up c17
I0816 16:03:59.903172 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.903183 20404 net.cpp:156] Memory required for data: 648808800
I0816 16:03:59.903194 20404 layer_factory.hpp:77] Creating layer Input8
I0816 16:03:59.903210 20404 net.cpp:91] Creating Layer Input8
I0816 16:03:59.903225 20404 net.cpp:399] Input8 -> Input8
I0816 16:03:59.903286 20404 net.cpp:141] Setting up Input8
I0816 16:03:59.903306 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.903317 20404 net.cpp:156] Memory required for data: 653724000
I0816 16:03:59.903329 20404 layer_factory.hpp:77] Creating layer c18
I0816 16:03:59.903345 20404 net.cpp:91] Creating Layer c18
I0816 16:03:59.903357 20404 net.cpp:425] c18 <- i1_i1_0_split_8
I0816 16:03:59.903375 20404 net.cpp:425] c18 <- Input8
I0816 16:03:59.903393 20404 net.cpp:399] c18 -> c18
I0816 16:03:59.903445 20404 net.cpp:141] Setting up c18
I0816 16:03:59.903463 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.903496 20404 net.cpp:156] Memory required for data: 658639200
I0816 16:03:59.903508 20404 layer_factory.hpp:77] Creating layer Input9
I0816 16:03:59.903524 20404 net.cpp:91] Creating Layer Input9
I0816 16:03:59.903539 20404 net.cpp:399] Input9 -> Input9
I0816 16:03:59.903592 20404 net.cpp:141] Setting up Input9
I0816 16:03:59.903610 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.903621 20404 net.cpp:156] Memory required for data: 663554400
I0816 16:03:59.903632 20404 layer_factory.hpp:77] Creating layer c19
I0816 16:03:59.903647 20404 net.cpp:91] Creating Layer c19
I0816 16:03:59.903661 20404 net.cpp:425] c19 <- i1_i1_0_split_9
I0816 16:03:59.903676 20404 net.cpp:425] c19 <- Input9
I0816 16:03:59.903692 20404 net.cpp:399] c19 -> c19
I0816 16:03:59.903743 20404 net.cpp:141] Setting up c19
I0816 16:03:59.903761 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.903772 20404 net.cpp:156] Memory required for data: 668469600
I0816 16:03:59.903784 20404 layer_factory.hpp:77] Creating layer Input10
I0816 16:03:59.903800 20404 net.cpp:91] Creating Layer Input10
I0816 16:03:59.903815 20404 net.cpp:399] Input10 -> Input10
I0816 16:03:59.903864 20404 net.cpp:141] Setting up Input10
I0816 16:03:59.903882 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.903893 20404 net.cpp:156] Memory required for data: 673384800
I0816 16:03:59.903904 20404 layer_factory.hpp:77] Creating layer c21
I0816 16:03:59.903920 20404 net.cpp:91] Creating Layer c21
I0816 16:03:59.903933 20404 net.cpp:425] c21 <- i2_i1_1_split_1
I0816 16:03:59.903949 20404 net.cpp:425] c21 <- Input10
I0816 16:03:59.903965 20404 net.cpp:399] c21 -> c21
I0816 16:03:59.904016 20404 net.cpp:141] Setting up c21
I0816 16:03:59.904033 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.904045 20404 net.cpp:156] Memory required for data: 678300000
I0816 16:03:59.904057 20404 layer_factory.hpp:77] Creating layer Input11
I0816 16:03:59.904072 20404 net.cpp:91] Creating Layer Input11
I0816 16:03:59.904086 20404 net.cpp:399] Input11 -> Input11
I0816 16:03:59.904136 20404 net.cpp:141] Setting up Input11
I0816 16:03:59.904155 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.904165 20404 net.cpp:156] Memory required for data: 683215200
I0816 16:03:59.904176 20404 layer_factory.hpp:77] Creating layer c22
I0816 16:03:59.904201 20404 net.cpp:91] Creating Layer c22
I0816 16:03:59.904212 20404 net.cpp:425] c22 <- i2_i1_1_split_2
I0816 16:03:59.904227 20404 net.cpp:425] c22 <- Input11
I0816 16:03:59.904245 20404 net.cpp:399] c22 -> c22
I0816 16:03:59.904296 20404 net.cpp:141] Setting up c22
I0816 16:03:59.904315 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.904326 20404 net.cpp:156] Memory required for data: 688130400
I0816 16:03:59.904338 20404 layer_factory.hpp:77] Creating layer Input12
I0816 16:03:59.904355 20404 net.cpp:91] Creating Layer Input12
I0816 16:03:59.904369 20404 net.cpp:399] Input12 -> Input12
I0816 16:03:59.904422 20404 net.cpp:141] Setting up Input12
I0816 16:03:59.904439 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.904450 20404 net.cpp:156] Memory required for data: 693045600
I0816 16:03:59.904461 20404 layer_factory.hpp:77] Creating layer c23
I0816 16:03:59.904477 20404 net.cpp:91] Creating Layer c23
I0816 16:03:59.904490 20404 net.cpp:425] c23 <- i2_i1_1_split_3
I0816 16:03:59.904506 20404 net.cpp:425] c23 <- Input12
I0816 16:03:59.904523 20404 net.cpp:399] c23 -> c23
I0816 16:03:59.904573 20404 net.cpp:141] Setting up c23
I0816 16:03:59.904592 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.904603 20404 net.cpp:156] Memory required for data: 697960800
I0816 16:03:59.904614 20404 layer_factory.hpp:77] Creating layer Input13
I0816 16:03:59.904630 20404 net.cpp:91] Creating Layer Input13
I0816 16:03:59.904646 20404 net.cpp:399] Input13 -> Input13
I0816 16:03:59.904698 20404 net.cpp:141] Setting up Input13
I0816 16:03:59.904717 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.904728 20404 net.cpp:156] Memory required for data: 702876000
I0816 16:03:59.904759 20404 layer_factory.hpp:77] Creating layer c24
I0816 16:03:59.904777 20404 net.cpp:91] Creating Layer c24
I0816 16:03:59.904788 20404 net.cpp:425] c24 <- i2_i1_1_split_4
I0816 16:03:59.904803 20404 net.cpp:425] c24 <- Input13
I0816 16:03:59.904821 20404 net.cpp:399] c24 -> c24
I0816 16:03:59.904872 20404 net.cpp:141] Setting up c24
I0816 16:03:59.904891 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.904902 20404 net.cpp:156] Memory required for data: 707791200
I0816 16:03:59.904913 20404 layer_factory.hpp:77] Creating layer Input14
I0816 16:03:59.904929 20404 net.cpp:91] Creating Layer Input14
I0816 16:03:59.904945 20404 net.cpp:399] Input14 -> Input14
I0816 16:03:59.904994 20404 net.cpp:141] Setting up Input14
I0816 16:03:59.905012 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.905024 20404 net.cpp:156] Memory required for data: 712706400
I0816 16:03:59.905035 20404 layer_factory.hpp:77] Creating layer c25
I0816 16:03:59.905050 20404 net.cpp:91] Creating Layer c25
I0816 16:03:59.905062 20404 net.cpp:425] c25 <- i2_i1_1_split_5
I0816 16:03:59.905077 20404 net.cpp:425] c25 <- Input14
I0816 16:03:59.905094 20404 net.cpp:399] c25 -> c25
I0816 16:03:59.905146 20404 net.cpp:141] Setting up c25
I0816 16:03:59.905164 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.905175 20404 net.cpp:156] Memory required for data: 717621600
I0816 16:03:59.905186 20404 layer_factory.hpp:77] Creating layer Input15
I0816 16:03:59.905202 20404 net.cpp:91] Creating Layer Input15
I0816 16:03:59.905217 20404 net.cpp:399] Input15 -> Input15
I0816 16:03:59.905268 20404 net.cpp:141] Setting up Input15
I0816 16:03:59.905287 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.905297 20404 net.cpp:156] Memory required for data: 722536800
I0816 16:03:59.905308 20404 layer_factory.hpp:77] Creating layer c26
I0816 16:03:59.905326 20404 net.cpp:91] Creating Layer c26
I0816 16:03:59.905339 20404 net.cpp:425] c26 <- i2_i1_1_split_6
I0816 16:03:59.905354 20404 net.cpp:425] c26 <- Input15
I0816 16:03:59.905371 20404 net.cpp:399] c26 -> c26
I0816 16:03:59.905421 20404 net.cpp:141] Setting up c26
I0816 16:03:59.905439 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.905452 20404 net.cpp:156] Memory required for data: 727452000
I0816 16:03:59.905462 20404 layer_factory.hpp:77] Creating layer Input16
I0816 16:03:59.905478 20404 net.cpp:91] Creating Layer Input16
I0816 16:03:59.905493 20404 net.cpp:399] Input16 -> Input16
I0816 16:03:59.905541 20404 net.cpp:141] Setting up Input16
I0816 16:03:59.905560 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.905570 20404 net.cpp:156] Memory required for data: 732367200
I0816 16:03:59.905581 20404 layer_factory.hpp:77] Creating layer c27
I0816 16:03:59.905597 20404 net.cpp:91] Creating Layer c27
I0816 16:03:59.905609 20404 net.cpp:425] c27 <- i2_i1_1_split_7
I0816 16:03:59.905625 20404 net.cpp:425] c27 <- Input16
I0816 16:03:59.905642 20404 net.cpp:399] c27 -> c27
I0816 16:03:59.905694 20404 net.cpp:141] Setting up c27
I0816 16:03:59.905712 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.905725 20404 net.cpp:156] Memory required for data: 737282400
I0816 16:03:59.905735 20404 layer_factory.hpp:77] Creating layer Input17
I0816 16:03:59.905751 20404 net.cpp:91] Creating Layer Input17
I0816 16:03:59.905766 20404 net.cpp:399] Input17 -> Input17
I0816 16:03:59.905818 20404 net.cpp:141] Setting up Input17
I0816 16:03:59.905835 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.905848 20404 net.cpp:156] Memory required for data: 742197600
I0816 16:03:59.905858 20404 layer_factory.hpp:77] Creating layer c28
I0816 16:03:59.905874 20404 net.cpp:91] Creating Layer c28
I0816 16:03:59.905886 20404 net.cpp:425] c28 <- i2_i1_1_split_8
I0816 16:03:59.905902 20404 net.cpp:425] c28 <- Input17
I0816 16:03:59.905920 20404 net.cpp:399] c28 -> c28
I0816 16:03:59.905972 20404 net.cpp:141] Setting up c28
I0816 16:03:59.905989 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.906018 20404 net.cpp:156] Memory required for data: 747112800
I0816 16:03:59.906030 20404 layer_factory.hpp:77] Creating layer Input18
I0816 16:03:59.906047 20404 net.cpp:91] Creating Layer Input18
I0816 16:03:59.906062 20404 net.cpp:399] Input18 -> Input18
I0816 16:03:59.906113 20404 net.cpp:141] Setting up Input18
I0816 16:03:59.906131 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.906142 20404 net.cpp:156] Memory required for data: 752028000
I0816 16:03:59.906154 20404 layer_factory.hpp:77] Creating layer c29
I0816 16:03:59.906170 20404 net.cpp:91] Creating Layer c29
I0816 16:03:59.906183 20404 net.cpp:425] c29 <- i2_i1_1_split_9
I0816 16:03:59.906198 20404 net.cpp:425] c29 <- Input18
I0816 16:03:59.906215 20404 net.cpp:399] c29 -> c29
I0816 16:03:59.906266 20404 net.cpp:141] Setting up c29
I0816 16:03:59.906285 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:03:59.906296 20404 net.cpp:156] Memory required for data: 756943200
I0816 16:03:59.906306 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:03:59.906339 20404 net.cpp:91] Creating Layer conv1
I0816 16:03:59.906355 20404 net.cpp:425] conv1 <- p1_p1_0_split_0
I0816 16:03:59.906375 20404 net.cpp:399] conv1 -> Convolution1
I0816 16:03:59.910224 20404 net.cpp:141] Setting up conv1
I0816 16:03:59.910255 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:03:59.910269 20404 net.cpp:156] Memory required for data: 766773600
I0816 16:03:59.910305 20404 layer_factory.hpp:77] Creating layer ReLU1
I0816 16:03:59.910328 20404 net.cpp:91] Creating Layer ReLU1
I0816 16:03:59.910342 20404 net.cpp:425] ReLU1 <- Convolution1
I0816 16:03:59.910359 20404 net.cpp:386] ReLU1 -> Convolution1 (in-place)
I0816 16:03:59.910380 20404 net.cpp:141] Setting up ReLU1
I0816 16:03:59.910398 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:03:59.910409 20404 net.cpp:156] Memory required for data: 776604000
I0816 16:03:59.910420 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:03:59.910437 20404 net.cpp:91] Creating Layer norm1
I0816 16:03:59.910449 20404 net.cpp:425] norm1 <- Convolution1
I0816 16:03:59.910466 20404 net.cpp:399] norm1 -> LRN1
I0816 16:03:59.910537 20404 net.cpp:141] Setting up norm1
I0816 16:03:59.910555 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:03:59.910567 20404 net.cpp:156] Memory required for data: 786434400
I0816 16:03:59.910578 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:03:59.910595 20404 net.cpp:91] Creating Layer pool1
I0816 16:03:59.910607 20404 net.cpp:425] pool1 <- LRN1
I0816 16:03:59.910625 20404 net.cpp:399] pool1 -> Pooling1
I0816 16:03:59.910701 20404 net.cpp:141] Setting up pool1
I0816 16:03:59.910718 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:03:59.910729 20404 net.cpp:156] Memory required for data: 788892000
I0816 16:03:59.910742 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:03:59.910765 20404 net.cpp:91] Creating Layer conv2
I0816 16:03:59.910778 20404 net.cpp:425] conv2 <- Pooling1
I0816 16:03:59.910796 20404 net.cpp:399] conv2 -> Convolution2
I0816 16:03:59.926650 20404 net.cpp:141] Setting up conv2
I0816 16:03:59.926679 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:03:59.926688 20404 net.cpp:156] Memory required for data: 795445600
I0816 16:03:59.926712 20404 layer_factory.hpp:77] Creating layer ReLU2
I0816 16:03:59.926726 20404 net.cpp:91] Creating Layer ReLU2
I0816 16:03:59.926736 20404 net.cpp:425] ReLU2 <- Convolution2
I0816 16:03:59.926753 20404 net.cpp:386] ReLU2 -> Convolution2 (in-place)
I0816 16:03:59.926769 20404 net.cpp:141] Setting up ReLU2
I0816 16:03:59.926779 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:03:59.926785 20404 net.cpp:156] Memory required for data: 801999200
I0816 16:03:59.926794 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:03:59.926805 20404 net.cpp:91] Creating Layer norm2
I0816 16:03:59.926813 20404 net.cpp:425] norm2 <- Convolution2
I0816 16:03:59.926827 20404 net.cpp:399] norm2 -> LRN2
I0816 16:03:59.926885 20404 net.cpp:141] Setting up norm2
I0816 16:03:59.926915 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:03:59.926923 20404 net.cpp:156] Memory required for data: 808552800
I0816 16:03:59.926931 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:03:59.926944 20404 net.cpp:91] Creating Layer pool2
I0816 16:03:59.926951 20404 net.cpp:425] pool2 <- LRN2
I0816 16:03:59.926964 20404 net.cpp:399] pool2 -> Pooling2
I0816 16:03:59.927017 20404 net.cpp:141] Setting up pool2
I0816 16:03:59.927031 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:03:59.927037 20404 net.cpp:156] Memory required for data: 810191200
I0816 16:03:59.927045 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:03:59.927065 20404 net.cpp:91] Creating Layer conv3
I0816 16:03:59.927076 20404 net.cpp:425] conv3 <- Pooling2
I0816 16:03:59.927090 20404 net.cpp:399] conv3 -> Convolution3
I0816 16:03:59.972849 20404 net.cpp:141] Setting up conv3
I0816 16:03:59.972890 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:03:59.972899 20404 net.cpp:156] Memory required for data: 812648800
I0816 16:03:59.972926 20404 layer_factory.hpp:77] Creating layer ReLU3
I0816 16:03:59.972944 20404 net.cpp:91] Creating Layer ReLU3
I0816 16:03:59.972955 20404 net.cpp:425] ReLU3 <- Convolution3
I0816 16:03:59.972970 20404 net.cpp:386] ReLU3 -> Convolution3 (in-place)
I0816 16:03:59.972988 20404 net.cpp:141] Setting up ReLU3
I0816 16:03:59.973000 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:03:59.973006 20404 net.cpp:156] Memory required for data: 815106400
I0816 16:03:59.973014 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:03:59.973036 20404 net.cpp:91] Creating Layer conv4
I0816 16:03:59.973044 20404 net.cpp:425] conv4 <- Convolution3
I0816 16:03:59.973058 20404 net.cpp:399] conv4 -> Convolution4
I0816 16:04:00.007014 20404 net.cpp:141] Setting up conv4
I0816 16:04:00.007057 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.007067 20404 net.cpp:156] Memory required for data: 817564000
I0816 16:04:00.007086 20404 layer_factory.hpp:77] Creating layer ReLU4
I0816 16:04:00.007104 20404 net.cpp:91] Creating Layer ReLU4
I0816 16:04:00.007117 20404 net.cpp:425] ReLU4 <- Convolution4
I0816 16:04:00.007129 20404 net.cpp:386] ReLU4 -> Convolution4 (in-place)
I0816 16:04:00.007146 20404 net.cpp:141] Setting up ReLU4
I0816 16:04:00.007158 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.007164 20404 net.cpp:156] Memory required for data: 820021600
I0816 16:04:00.007172 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:00.007192 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:00.007202 20404 net.cpp:425] conv5 <- Convolution4
I0816 16:04:00.007220 20404 net.cpp:399] conv5 -> Convolution5
I0816 16:04:00.030962 20404 net.cpp:141] Setting up conv5
I0816 16:04:00.031002 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.031010 20404 net.cpp:156] Memory required for data: 821660000
I0816 16:04:00.031039 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:00.031059 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:00.031070 20404 net.cpp:425] pool5 <- Convolution5
I0816 16:04:00.031085 20404 net.cpp:399] pool5 -> Pooling3
I0816 16:04:00.031162 20404 net.cpp:141] Setting up pool5
I0816 16:04:00.031177 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:00.031184 20404 net.cpp:156] Memory required for data: 822069600
I0816 16:04:00.031193 20404 layer_factory.hpp:77] Creating layer InnerProduct1
I0816 16:04:00.031206 20404 net.cpp:91] Creating Layer InnerProduct1
I0816 16:04:00.031215 20404 net.cpp:425] InnerProduct1 <- Pooling3
I0816 16:04:00.031231 20404 net.cpp:399] InnerProduct1 -> InnerProduct1
I0816 16:04:00.034085 20404 net.cpp:141] Setting up InnerProduct1
I0816 16:04:00.034106 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.034114 20404 net.cpp:156] Memory required for data: 822172000
I0816 16:04:00.034127 20404 layer_factory.hpp:77] Creating layer ReLU5
I0816 16:04:00.034139 20404 net.cpp:91] Creating Layer ReLU5
I0816 16:04:00.034169 20404 net.cpp:425] ReLU5 <- InnerProduct1
I0816 16:04:00.034183 20404 net.cpp:386] ReLU5 -> InnerProduct1 (in-place)
I0816 16:04:00.034196 20404 net.cpp:141] Setting up ReLU5
I0816 16:04:00.034206 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.034214 20404 net.cpp:156] Memory required for data: 822274400
I0816 16:04:00.034221 20404 layer_factory.hpp:77] Creating layer InnerProduct2
I0816 16:04:00.034235 20404 net.cpp:91] Creating Layer InnerProduct2
I0816 16:04:00.034242 20404 net.cpp:425] InnerProduct2 <- InnerProduct1
I0816 16:04:00.034260 20404 net.cpp:399] InnerProduct2 -> InnerProduct2
I0816 16:04:00.034919 20404 net.cpp:141] Setting up InnerProduct2
I0816 16:04:00.034934 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.034941 20404 net.cpp:156] Memory required for data: 822376800
I0816 16:04:00.034952 20404 layer_factory.hpp:77] Creating layer ReLU6
I0816 16:04:00.034988 20404 net.cpp:91] Creating Layer ReLU6
I0816 16:04:00.034998 20404 net.cpp:425] ReLU6 <- InnerProduct2
I0816 16:04:00.035009 20404 net.cpp:386] ReLU6 -> InnerProduct2 (in-place)
I0816 16:04:00.035020 20404 net.cpp:141] Setting up ReLU6
I0816 16:04:00.035030 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.035038 20404 net.cpp:156] Memory required for data: 822479200
I0816 16:04:00.035048 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:00.035068 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:00.035078 20404 net.cpp:425] conv1 <- p2_p2_0_split_0
I0816 16:04:00.035091 20404 net.cpp:399] conv1 -> Convolution6
I0816 16:04:00.037106 20404 net.cpp:141] Setting up conv1
I0816 16:04:00.037122 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.037130 20404 net.cpp:156] Memory required for data: 832309600
I0816 16:04:00.037144 20404 layer_factory.hpp:77] Creating layer ReLU7
I0816 16:04:00.037154 20404 net.cpp:91] Creating Layer ReLU7
I0816 16:04:00.037163 20404 net.cpp:425] ReLU7 <- Convolution6
I0816 16:04:00.037178 20404 net.cpp:386] ReLU7 -> Convolution6 (in-place)
I0816 16:04:00.037190 20404 net.cpp:141] Setting up ReLU7
I0816 16:04:00.037201 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.037209 20404 net.cpp:156] Memory required for data: 842140000
I0816 16:04:00.037216 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:00.037231 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:00.037240 20404 net.cpp:425] norm1 <- Convolution6
I0816 16:04:00.037251 20404 net.cpp:399] norm1 -> LRN3
I0816 16:04:00.037304 20404 net.cpp:141] Setting up norm1
I0816 16:04:00.037317 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.037324 20404 net.cpp:156] Memory required for data: 851970400
I0816 16:04:00.037333 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:00.037346 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:00.037354 20404 net.cpp:425] pool1 <- LRN3
I0816 16:04:00.037365 20404 net.cpp:399] pool1 -> Pooling4
I0816 16:04:00.037427 20404 net.cpp:141] Setting up pool1
I0816 16:04:00.037441 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:00.037448 20404 net.cpp:156] Memory required for data: 854428000
I0816 16:04:00.037456 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:00.037473 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:00.037482 20404 net.cpp:425] conv2 <- Pooling4
I0816 16:04:00.037498 20404 net.cpp:399] conv2 -> Convolution7
I0816 16:04:00.053292 20404 net.cpp:141] Setting up conv2
I0816 16:04:00.053329 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.053339 20404 net.cpp:156] Memory required for data: 860981600
I0816 16:04:00.053370 20404 layer_factory.hpp:77] Creating layer ReLU8
I0816 16:04:00.053385 20404 net.cpp:91] Creating Layer ReLU8
I0816 16:04:00.053395 20404 net.cpp:425] ReLU8 <- Convolution7
I0816 16:04:00.053406 20404 net.cpp:386] ReLU8 -> Convolution7 (in-place)
I0816 16:04:00.053421 20404 net.cpp:141] Setting up ReLU8
I0816 16:04:00.053429 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.053436 20404 net.cpp:156] Memory required for data: 867535200
I0816 16:04:00.053462 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:00.053478 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:00.053486 20404 net.cpp:425] norm2 <- Convolution7
I0816 16:04:00.053498 20404 net.cpp:399] norm2 -> LRN4
I0816 16:04:00.053558 20404 net.cpp:141] Setting up norm2
I0816 16:04:00.053568 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.053575 20404 net.cpp:156] Memory required for data: 874088800
I0816 16:04:00.053581 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:00.053592 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:00.053599 20404 net.cpp:425] pool2 <- LRN4
I0816 16:04:00.053612 20404 net.cpp:399] pool2 -> Pooling5
I0816 16:04:00.053665 20404 net.cpp:141] Setting up pool2
I0816 16:04:00.053680 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.053688 20404 net.cpp:156] Memory required for data: 875727200
I0816 16:04:00.053694 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:00.053715 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:00.053722 20404 net.cpp:425] conv3 <- Pooling5
I0816 16:04:00.053738 20404 net.cpp:399] conv3 -> Convolution8
I0816 16:04:00.098556 20404 net.cpp:141] Setting up conv3
I0816 16:04:00.098590 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.098599 20404 net.cpp:156] Memory required for data: 878184800
I0816 16:04:00.098628 20404 layer_factory.hpp:77] Creating layer ReLU9
I0816 16:04:00.098645 20404 net.cpp:91] Creating Layer ReLU9
I0816 16:04:00.098657 20404 net.cpp:425] ReLU9 <- Convolution8
I0816 16:04:00.098676 20404 net.cpp:386] ReLU9 -> Convolution8 (in-place)
I0816 16:04:00.098706 20404 net.cpp:141] Setting up ReLU9
I0816 16:04:00.098718 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.098728 20404 net.cpp:156] Memory required for data: 880642400
I0816 16:04:00.098738 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:00.098758 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:00.098768 20404 net.cpp:425] conv4 <- Convolution8
I0816 16:04:00.098784 20404 net.cpp:399] conv4 -> Convolution9
I0816 16:04:00.131777 20404 net.cpp:141] Setting up conv4
I0816 16:04:00.131804 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.131813 20404 net.cpp:156] Memory required for data: 883100000
I0816 16:04:00.131839 20404 layer_factory.hpp:77] Creating layer ReLU10
I0816 16:04:00.131855 20404 net.cpp:91] Creating Layer ReLU10
I0816 16:04:00.131866 20404 net.cpp:425] ReLU10 <- Convolution9
I0816 16:04:00.131891 20404 net.cpp:386] ReLU10 -> Convolution9 (in-place)
I0816 16:04:00.131918 20404 net.cpp:141] Setting up ReLU10
I0816 16:04:00.131932 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.131942 20404 net.cpp:156] Memory required for data: 885557600
I0816 16:04:00.131952 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:00.131974 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:00.131984 20404 net.cpp:425] conv5 <- Convolution9
I0816 16:04:00.131997 20404 net.cpp:399] conv5 -> Convolution10
I0816 16:04:00.154110 20404 net.cpp:141] Setting up conv5
I0816 16:04:00.154134 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.154141 20404 net.cpp:156] Memory required for data: 887196000
I0816 16:04:00.154167 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:00.154184 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:00.154197 20404 net.cpp:425] pool5 <- Convolution10
I0816 16:04:00.154217 20404 net.cpp:399] pool5 -> Pooling6
I0816 16:04:00.154287 20404 net.cpp:141] Setting up pool5
I0816 16:04:00.154301 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:00.154312 20404 net.cpp:156] Memory required for data: 887605600
I0816 16:04:00.154320 20404 layer_factory.hpp:77] Creating layer InnerProduct3
I0816 16:04:00.154336 20404 net.cpp:91] Creating Layer InnerProduct3
I0816 16:04:00.154350 20404 net.cpp:425] InnerProduct3 <- Pooling6
I0816 16:04:00.154366 20404 net.cpp:399] InnerProduct3 -> InnerProduct3
I0816 16:04:00.157088 20404 net.cpp:141] Setting up InnerProduct3
I0816 16:04:00.157124 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.157131 20404 net.cpp:156] Memory required for data: 887708000
I0816 16:04:00.157140 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:00.157150 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:00.157171 20404 layer_factory.hpp:77] Creating layer ReLU11
I0816 16:04:00.157181 20404 net.cpp:91] Creating Layer ReLU11
I0816 16:04:00.157189 20404 net.cpp:425] ReLU11 <- InnerProduct3
I0816 16:04:00.157205 20404 net.cpp:386] ReLU11 -> InnerProduct3 (in-place)
I0816 16:04:00.157232 20404 net.cpp:141] Setting up ReLU11
I0816 16:04:00.157246 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.157256 20404 net.cpp:156] Memory required for data: 887810400
I0816 16:04:00.157266 20404 layer_factory.hpp:77] Creating layer InnerProduct4
I0816 16:04:00.157279 20404 net.cpp:91] Creating Layer InnerProduct4
I0816 16:04:00.157289 20404 net.cpp:425] InnerProduct4 <- InnerProduct3
I0816 16:04:00.157305 20404 net.cpp:399] InnerProduct4 -> InnerProduct4
I0816 16:04:00.157951 20404 net.cpp:141] Setting up InnerProduct4
I0816 16:04:00.157963 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.157971 20404 net.cpp:156] Memory required for data: 887912800
I0816 16:04:00.157990 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:00.157999 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:00.158004 20404 layer_factory.hpp:77] Creating layer ReLU12
I0816 16:04:00.158012 20404 net.cpp:91] Creating Layer ReLU12
I0816 16:04:00.158018 20404 net.cpp:425] ReLU12 <- InnerProduct4
I0816 16:04:00.158027 20404 net.cpp:386] ReLU12 -> InnerProduct4 (in-place)
I0816 16:04:00.158036 20404 net.cpp:141] Setting up ReLU12
I0816 16:04:00.158043 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.158049 20404 net.cpp:156] Memory required for data: 888015200
I0816 16:04:00.158056 20404 layer_factory.hpp:77] Creating layer Concat1
I0816 16:04:00.158071 20404 net.cpp:91] Creating Layer Concat1
I0816 16:04:00.158077 20404 net.cpp:425] Concat1 <- InnerProduct2
I0816 16:04:00.158084 20404 net.cpp:425] Concat1 <- InnerProduct4
I0816 16:04:00.158097 20404 net.cpp:399] Concat1 -> Concat1
I0816 16:04:00.158131 20404 net.cpp:141] Setting up Concat1
I0816 16:04:00.158139 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:00.158144 20404 net.cpp:156] Memory required for data: 888220000
I0816 16:04:00.158150 20404 layer_factory.hpp:77] Creating layer InnerProduct5
I0816 16:04:00.158159 20404 net.cpp:91] Creating Layer InnerProduct5
I0816 16:04:00.158164 20404 net.cpp:425] InnerProduct5 <- Concat1
I0816 16:04:00.158177 20404 net.cpp:399] InnerProduct5 -> InnerProduct5
I0816 16:04:00.159324 20404 net.cpp:141] Setting up InnerProduct5
I0816 16:04:00.159345 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.159350 20404 net.cpp:156] Memory required for data: 888322400
I0816 16:04:00.159358 20404 layer_factory.hpp:77] Creating layer ReLU13
I0816 16:04:00.159368 20404 net.cpp:91] Creating Layer ReLU13
I0816 16:04:00.159373 20404 net.cpp:425] ReLU13 <- InnerProduct5
I0816 16:04:00.159381 20404 net.cpp:386] ReLU13 -> InnerProduct5 (in-place)
I0816 16:04:00.159390 20404 net.cpp:141] Setting up ReLU13
I0816 16:04:00.159406 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.159411 20404 net.cpp:156] Memory required for data: 888424800
I0816 16:04:00.159417 20404 layer_factory.hpp:77] Creating layer InnerProduct6
I0816 16:04:00.159430 20404 net.cpp:91] Creating Layer InnerProduct6
I0816 16:04:00.159435 20404 net.cpp:425] InnerProduct6 <- InnerProduct5
I0816 16:04:00.159445 20404 net.cpp:399] InnerProduct6 -> InnerProduct6
I0816 16:04:00.159818 20404 net.cpp:141] Setting up InnerProduct6
I0816 16:04:00.159828 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:00.159834 20404 net.cpp:156] Memory required for data: 888476000
I0816 16:04:00.159842 20404 layer_factory.hpp:77] Creating layer ReLU14
I0816 16:04:00.159862 20404 net.cpp:91] Creating Layer ReLU14
I0816 16:04:00.159869 20404 net.cpp:425] ReLU14 <- InnerProduct6
I0816 16:04:00.159878 20404 net.cpp:386] ReLU14 -> InnerProduct6 (in-place)
I0816 16:04:00.159886 20404 net.cpp:141] Setting up ReLU14
I0816 16:04:00.159893 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:00.159899 20404 net.cpp:156] Memory required for data: 888527200
I0816 16:04:00.159905 20404 layer_factory.hpp:77] Creating layer dt0
I0816 16:04:00.159916 20404 net.cpp:91] Creating Layer dt0
I0816 16:04:00.159924 20404 net.cpp:425] dt0 <- InnerProduct6
I0816 16:04:00.159934 20404 net.cpp:399] dt0 -> dt0
I0816 16:04:00.160053 20404 net.cpp:141] Setting up dt0
I0816 16:04:00.160063 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:00.160068 20404 net.cpp:156] Memory required for data: 888527600
I0816 16:04:00.160086 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:00.160104 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:00.160112 20404 net.cpp:425] conv1 <- p1_p1_0_split_1
I0816 16:04:00.160122 20404 net.cpp:399] conv1 -> Convolution11
I0816 16:04:00.162673 20404 net.cpp:141] Setting up conv1
I0816 16:04:00.162699 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.162705 20404 net.cpp:156] Memory required for data: 898358000
I0816 16:04:00.162716 20404 layer_factory.hpp:77] Creating layer ReLU15
I0816 16:04:00.162724 20404 net.cpp:91] Creating Layer ReLU15
I0816 16:04:00.162731 20404 net.cpp:425] ReLU15 <- Convolution11
I0816 16:04:00.162741 20404 net.cpp:386] ReLU15 -> Convolution11 (in-place)
I0816 16:04:00.162760 20404 net.cpp:141] Setting up ReLU15
I0816 16:04:00.162767 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.162773 20404 net.cpp:156] Memory required for data: 908188400
I0816 16:04:00.162780 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:00.162788 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:00.162794 20404 net.cpp:425] norm1 <- Convolution11
I0816 16:04:00.162806 20404 net.cpp:399] norm1 -> LRN5
I0816 16:04:00.162847 20404 net.cpp:141] Setting up norm1
I0816 16:04:00.162855 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.162860 20404 net.cpp:156] Memory required for data: 918018800
I0816 16:04:00.162866 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:00.162878 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:00.162883 20404 net.cpp:425] pool1 <- LRN5
I0816 16:04:00.162892 20404 net.cpp:399] pool1 -> Pooling7
I0816 16:04:00.162940 20404 net.cpp:141] Setting up pool1
I0816 16:04:00.162950 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:00.162955 20404 net.cpp:156] Memory required for data: 920476400
I0816 16:04:00.162961 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:00.162974 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:00.162981 20404 net.cpp:425] conv2 <- Pooling7
I0816 16:04:00.162991 20404 net.cpp:399] conv2 -> Convolution12
I0816 16:04:00.178403 20404 net.cpp:141] Setting up conv2
I0816 16:04:00.178421 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.178426 20404 net.cpp:156] Memory required for data: 927030000
I0816 16:04:00.178438 20404 layer_factory.hpp:77] Creating layer ReLU16
I0816 16:04:00.178450 20404 net.cpp:91] Creating Layer ReLU16
I0816 16:04:00.178457 20404 net.cpp:425] ReLU16 <- Convolution12
I0816 16:04:00.178467 20404 net.cpp:386] ReLU16 -> Convolution12 (in-place)
I0816 16:04:00.178478 20404 net.cpp:141] Setting up ReLU16
I0816 16:04:00.178484 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.178490 20404 net.cpp:156] Memory required for data: 933583600
I0816 16:04:00.178495 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:00.178506 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:00.178513 20404 net.cpp:425] norm2 <- Convolution12
I0816 16:04:00.178521 20404 net.cpp:399] norm2 -> LRN6
I0816 16:04:00.178571 20404 net.cpp:141] Setting up norm2
I0816 16:04:00.178581 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.178603 20404 net.cpp:156] Memory required for data: 940137200
I0816 16:04:00.178611 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:00.178618 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:00.178624 20404 net.cpp:425] pool2 <- LRN6
I0816 16:04:00.178635 20404 net.cpp:399] pool2 -> Pooling8
I0816 16:04:00.178683 20404 net.cpp:141] Setting up pool2
I0816 16:04:00.178692 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.178697 20404 net.cpp:156] Memory required for data: 941775600
I0816 16:04:00.178704 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:00.178719 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:00.178725 20404 net.cpp:425] conv3 <- Pooling8
I0816 16:04:00.178735 20404 net.cpp:399] conv3 -> Convolution13
I0816 16:04:00.222851 20404 net.cpp:141] Setting up conv3
I0816 16:04:00.222892 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.222898 20404 net.cpp:156] Memory required for data: 944233200
I0816 16:04:00.222913 20404 layer_factory.hpp:77] Creating layer ReLU17
I0816 16:04:00.222924 20404 net.cpp:91] Creating Layer ReLU17
I0816 16:04:00.222935 20404 net.cpp:425] ReLU17 <- Convolution13
I0816 16:04:00.222955 20404 net.cpp:386] ReLU17 -> Convolution13 (in-place)
I0816 16:04:00.222968 20404 net.cpp:141] Setting up ReLU17
I0816 16:04:00.222976 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.222982 20404 net.cpp:156] Memory required for data: 946690800
I0816 16:04:00.222987 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:00.223004 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:00.223011 20404 net.cpp:425] conv4 <- Convolution13
I0816 16:04:00.223026 20404 net.cpp:399] conv4 -> Convolution14
I0816 16:04:00.256091 20404 net.cpp:141] Setting up conv4
I0816 16:04:00.256119 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.256127 20404 net.cpp:156] Memory required for data: 949148400
I0816 16:04:00.256142 20404 layer_factory.hpp:77] Creating layer ReLU18
I0816 16:04:00.256158 20404 net.cpp:91] Creating Layer ReLU18
I0816 16:04:00.256173 20404 net.cpp:425] ReLU18 <- Convolution14
I0816 16:04:00.256187 20404 net.cpp:386] ReLU18 -> Convolution14 (in-place)
I0816 16:04:00.256206 20404 net.cpp:141] Setting up ReLU18
I0816 16:04:00.256219 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.256229 20404 net.cpp:156] Memory required for data: 951606000
I0816 16:04:00.256239 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:00.256265 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:00.256278 20404 net.cpp:425] conv5 <- Convolution14
I0816 16:04:00.256290 20404 net.cpp:399] conv5 -> Convolution15
I0816 16:04:00.278749 20404 net.cpp:141] Setting up conv5
I0816 16:04:00.278779 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.278787 20404 net.cpp:156] Memory required for data: 953244400
I0816 16:04:00.278803 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:00.278817 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:00.278827 20404 net.cpp:425] pool5 <- Convolution15
I0816 16:04:00.278843 20404 net.cpp:399] pool5 -> Pooling9
I0816 16:04:00.278908 20404 net.cpp:141] Setting up pool5
I0816 16:04:00.278920 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:00.278928 20404 net.cpp:156] Memory required for data: 953654000
I0816 16:04:00.278935 20404 layer_factory.hpp:77] Creating layer InnerProduct7
I0816 16:04:00.278949 20404 net.cpp:91] Creating Layer InnerProduct7
I0816 16:04:00.278955 20404 net.cpp:425] InnerProduct7 <- Pooling9
I0816 16:04:00.278971 20404 net.cpp:399] InnerProduct7 -> InnerProduct7
I0816 16:04:00.281936 20404 net.cpp:141] Setting up InnerProduct7
I0816 16:04:00.281956 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.281965 20404 net.cpp:156] Memory required for data: 953756400
I0816 16:04:00.281975 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:00.281983 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:00.282011 20404 layer_factory.hpp:77] Creating layer ReLU19
I0816 16:04:00.282021 20404 net.cpp:91] Creating Layer ReLU19
I0816 16:04:00.282027 20404 net.cpp:425] ReLU19 <- InnerProduct7
I0816 16:04:00.282039 20404 net.cpp:386] ReLU19 -> InnerProduct7 (in-place)
I0816 16:04:00.282050 20404 net.cpp:141] Setting up ReLU19
I0816 16:04:00.282058 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.282063 20404 net.cpp:156] Memory required for data: 953858800
I0816 16:04:00.282069 20404 layer_factory.hpp:77] Creating layer InnerProduct8
I0816 16:04:00.282079 20404 net.cpp:91] Creating Layer InnerProduct8
I0816 16:04:00.282085 20404 net.cpp:425] InnerProduct8 <- InnerProduct7
I0816 16:04:00.282097 20404 net.cpp:399] InnerProduct8 -> InnerProduct8
I0816 16:04:00.282740 20404 net.cpp:141] Setting up InnerProduct8
I0816 16:04:00.282753 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.282763 20404 net.cpp:156] Memory required for data: 953961200
I0816 16:04:00.282768 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:00.282776 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:00.282783 20404 layer_factory.hpp:77] Creating layer ReLU20
I0816 16:04:00.282793 20404 net.cpp:91] Creating Layer ReLU20
I0816 16:04:00.282799 20404 net.cpp:425] ReLU20 <- InnerProduct8
I0816 16:04:00.282807 20404 net.cpp:386] ReLU20 -> InnerProduct8 (in-place)
I0816 16:04:00.282816 20404 net.cpp:141] Setting up ReLU20
I0816 16:04:00.282824 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.282829 20404 net.cpp:156] Memory required for data: 954063600
I0816 16:04:00.282835 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:00.282848 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:00.282855 20404 net.cpp:425] conv1 <- c21
I0816 16:04:00.282868 20404 net.cpp:399] conv1 -> Convolution16
I0816 16:04:00.284868 20404 net.cpp:141] Setting up conv1
I0816 16:04:00.284876 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.284883 20404 net.cpp:156] Memory required for data: 963894000
I0816 16:04:00.284893 20404 layer_factory.hpp:77] Creating layer ReLU21
I0816 16:04:00.284901 20404 net.cpp:91] Creating Layer ReLU21
I0816 16:04:00.284907 20404 net.cpp:425] ReLU21 <- Convolution16
I0816 16:04:00.284915 20404 net.cpp:386] ReLU21 -> Convolution16 (in-place)
I0816 16:04:00.284925 20404 net.cpp:141] Setting up ReLU21
I0816 16:04:00.284932 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.284939 20404 net.cpp:156] Memory required for data: 973724400
I0816 16:04:00.284943 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:00.284955 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:00.284961 20404 net.cpp:425] norm1 <- Convolution16
I0816 16:04:00.284970 20404 net.cpp:399] norm1 -> LRN7
I0816 16:04:00.285043 20404 net.cpp:141] Setting up norm1
I0816 16:04:00.285051 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.285058 20404 net.cpp:156] Memory required for data: 983554800
I0816 16:04:00.285063 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:00.285076 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:00.285082 20404 net.cpp:425] pool1 <- LRN7
I0816 16:04:00.285094 20404 net.cpp:399] pool1 -> Pooling10
I0816 16:04:00.285140 20404 net.cpp:141] Setting up pool1
I0816 16:04:00.285147 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:00.285153 20404 net.cpp:156] Memory required for data: 986012400
I0816 16:04:00.285158 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:00.285171 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:00.285177 20404 net.cpp:425] conv2 <- Pooling10
I0816 16:04:00.285189 20404 net.cpp:399] conv2 -> Convolution17
I0816 16:04:00.300953 20404 net.cpp:141] Setting up conv2
I0816 16:04:00.300978 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.300984 20404 net.cpp:156] Memory required for data: 992566000
I0816 16:04:00.300997 20404 layer_factory.hpp:77] Creating layer ReLU22
I0816 16:04:00.301028 20404 net.cpp:91] Creating Layer ReLU22
I0816 16:04:00.301035 20404 net.cpp:425] ReLU22 <- Convolution17
I0816 16:04:00.301048 20404 net.cpp:386] ReLU22 -> Convolution17 (in-place)
I0816 16:04:00.301061 20404 net.cpp:141] Setting up ReLU22
I0816 16:04:00.301069 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.301074 20404 net.cpp:156] Memory required for data: 999119600
I0816 16:04:00.301080 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:00.301093 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:00.301100 20404 net.cpp:425] norm2 <- Convolution17
I0816 16:04:00.301110 20404 net.cpp:399] norm2 -> LRN8
I0816 16:04:00.301159 20404 net.cpp:141] Setting up norm2
I0816 16:04:00.301167 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.301172 20404 net.cpp:156] Memory required for data: 1005673200
I0816 16:04:00.301178 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:00.301187 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:00.301192 20404 net.cpp:425] pool2 <- LRN8
I0816 16:04:00.301201 20404 net.cpp:399] pool2 -> Pooling11
I0816 16:04:00.301250 20404 net.cpp:141] Setting up pool2
I0816 16:04:00.301257 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.301264 20404 net.cpp:156] Memory required for data: 1007311600
I0816 16:04:00.301268 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:00.301285 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:00.301291 20404 net.cpp:425] conv3 <- Pooling11
I0816 16:04:00.301303 20404 net.cpp:399] conv3 -> Convolution18
I0816 16:04:00.345278 20404 net.cpp:141] Setting up conv3
I0816 16:04:00.345320 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.345326 20404 net.cpp:156] Memory required for data: 1009769200
I0816 16:04:00.345340 20404 layer_factory.hpp:77] Creating layer ReLU23
I0816 16:04:00.345352 20404 net.cpp:91] Creating Layer ReLU23
I0816 16:04:00.345361 20404 net.cpp:425] ReLU23 <- Convolution18
I0816 16:04:00.345382 20404 net.cpp:386] ReLU23 -> Convolution18 (in-place)
I0816 16:04:00.345396 20404 net.cpp:141] Setting up ReLU23
I0816 16:04:00.345403 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.345409 20404 net.cpp:156] Memory required for data: 1012226800
I0816 16:04:00.345414 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:00.345432 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:00.345438 20404 net.cpp:425] conv4 <- Convolution18
I0816 16:04:00.345453 20404 net.cpp:399] conv4 -> Convolution19
I0816 16:04:00.378774 20404 net.cpp:141] Setting up conv4
I0816 16:04:00.378813 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.378823 20404 net.cpp:156] Memory required for data: 1014684400
I0816 16:04:00.378839 20404 layer_factory.hpp:77] Creating layer ReLU24
I0816 16:04:00.378852 20404 net.cpp:91] Creating Layer ReLU24
I0816 16:04:00.378868 20404 net.cpp:425] ReLU24 <- Convolution19
I0816 16:04:00.378880 20404 net.cpp:386] ReLU24 -> Convolution19 (in-place)
I0816 16:04:00.378893 20404 net.cpp:141] Setting up ReLU24
I0816 16:04:00.378901 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.378907 20404 net.cpp:156] Memory required for data: 1017142000
I0816 16:04:00.378913 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:00.378929 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:00.378937 20404 net.cpp:425] conv5 <- Convolution19
I0816 16:04:00.378947 20404 net.cpp:399] conv5 -> Convolution20
I0816 16:04:00.401582 20404 net.cpp:141] Setting up conv5
I0816 16:04:00.401617 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.401624 20404 net.cpp:156] Memory required for data: 1018780400
I0816 16:04:00.401641 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:00.401657 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:00.401667 20404 net.cpp:425] pool5 <- Convolution20
I0816 16:04:00.401684 20404 net.cpp:399] pool5 -> Pooling12
I0816 16:04:00.401754 20404 net.cpp:141] Setting up pool5
I0816 16:04:00.401764 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:00.401772 20404 net.cpp:156] Memory required for data: 1019190000
I0816 16:04:00.401803 20404 layer_factory.hpp:77] Creating layer InnerProduct9
I0816 16:04:00.401820 20404 net.cpp:91] Creating Layer InnerProduct9
I0816 16:04:00.401828 20404 net.cpp:425] InnerProduct9 <- Pooling12
I0816 16:04:00.401844 20404 net.cpp:399] InnerProduct9 -> InnerProduct9
I0816 16:04:00.404845 20404 net.cpp:141] Setting up InnerProduct9
I0816 16:04:00.404878 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.404886 20404 net.cpp:156] Memory required for data: 1019292400
I0816 16:04:00.404894 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:00.404904 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:00.404911 20404 layer_factory.hpp:77] Creating layer ReLU25
I0816 16:04:00.404924 20404 net.cpp:91] Creating Layer ReLU25
I0816 16:04:00.404938 20404 net.cpp:425] ReLU25 <- InnerProduct9
I0816 16:04:00.404952 20404 net.cpp:386] ReLU25 -> InnerProduct9 (in-place)
I0816 16:04:00.404965 20404 net.cpp:141] Setting up ReLU25
I0816 16:04:00.404973 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.404979 20404 net.cpp:156] Memory required for data: 1019394800
I0816 16:04:00.404985 20404 layer_factory.hpp:77] Creating layer InnerProduct10
I0816 16:04:00.404996 20404 net.cpp:91] Creating Layer InnerProduct10
I0816 16:04:00.405004 20404 net.cpp:425] InnerProduct10 <- InnerProduct9
I0816 16:04:00.405017 20404 net.cpp:399] InnerProduct10 -> InnerProduct10
I0816 16:04:00.405711 20404 net.cpp:141] Setting up InnerProduct10
I0816 16:04:00.405735 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.405742 20404 net.cpp:156] Memory required for data: 1019497200
I0816 16:04:00.405750 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:00.405760 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:00.405767 20404 layer_factory.hpp:77] Creating layer ReLU26
I0816 16:04:00.405777 20404 net.cpp:91] Creating Layer ReLU26
I0816 16:04:00.405786 20404 net.cpp:425] ReLU26 <- InnerProduct10
I0816 16:04:00.405799 20404 net.cpp:386] ReLU26 -> InnerProduct10 (in-place)
I0816 16:04:00.405812 20404 net.cpp:141] Setting up ReLU26
I0816 16:04:00.405822 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.405833 20404 net.cpp:156] Memory required for data: 1019599600
I0816 16:04:00.405839 20404 layer_factory.hpp:77] Creating layer Concat2
I0816 16:04:00.405850 20404 net.cpp:91] Creating Layer Concat2
I0816 16:04:00.405859 20404 net.cpp:425] Concat2 <- InnerProduct8
I0816 16:04:00.405871 20404 net.cpp:425] Concat2 <- InnerProduct10
I0816 16:04:00.405886 20404 net.cpp:399] Concat2 -> Concat2
I0816 16:04:00.405925 20404 net.cpp:141] Setting up Concat2
I0816 16:04:00.405937 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:00.405944 20404 net.cpp:156] Memory required for data: 1019804400
I0816 16:04:00.405951 20404 layer_factory.hpp:77] Creating layer InnerProduct11
I0816 16:04:00.405969 20404 net.cpp:91] Creating Layer InnerProduct11
I0816 16:04:00.406018 20404 net.cpp:425] InnerProduct11 <- Concat2
I0816 16:04:00.406036 20404 net.cpp:399] InnerProduct11 -> InnerProduct11
I0816 16:04:00.407929 20404 net.cpp:141] Setting up InnerProduct11
I0816 16:04:00.407950 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.407958 20404 net.cpp:156] Memory required for data: 1019906800
I0816 16:04:00.407968 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:00.407980 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:00.407989 20404 layer_factory.hpp:77] Creating layer ReLU27
I0816 16:04:00.408000 20404 net.cpp:91] Creating Layer ReLU27
I0816 16:04:00.408048 20404 net.cpp:425] ReLU27 <- InnerProduct11
I0816 16:04:00.408063 20404 net.cpp:386] ReLU27 -> InnerProduct11 (in-place)
I0816 16:04:00.408077 20404 net.cpp:141] Setting up ReLU27
I0816 16:04:00.408100 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.408110 20404 net.cpp:156] Memory required for data: 1020009200
I0816 16:04:00.408118 20404 layer_factory.hpp:77] Creating layer InnerProduct12
I0816 16:04:00.408171 20404 net.cpp:91] Creating Layer InnerProduct12
I0816 16:04:00.408181 20404 net.cpp:425] InnerProduct12 <- InnerProduct11
I0816 16:04:00.408193 20404 net.cpp:399] InnerProduct12 -> InnerProduct12
I0816 16:04:00.408612 20404 net.cpp:141] Setting up InnerProduct12
I0816 16:04:00.408625 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:00.408632 20404 net.cpp:156] Memory required for data: 1020060400
I0816 16:04:00.408668 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:00.408679 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:00.408687 20404 layer_factory.hpp:77] Creating layer ReLU28
I0816 16:04:00.408697 20404 net.cpp:91] Creating Layer ReLU28
I0816 16:04:00.408707 20404 net.cpp:425] ReLU28 <- InnerProduct12
I0816 16:04:00.408717 20404 net.cpp:386] ReLU28 -> InnerProduct12 (in-place)
I0816 16:04:00.408731 20404 net.cpp:141] Setting up ReLU28
I0816 16:04:00.408743 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:00.408753 20404 net.cpp:156] Memory required for data: 1020111600
I0816 16:04:00.408761 20404 layer_factory.hpp:77] Creating layer dt1
I0816 16:04:00.408779 20404 net.cpp:91] Creating Layer dt1
I0816 16:04:00.408789 20404 net.cpp:425] dt1 <- InnerProduct12
I0816 16:04:00.408805 20404 net.cpp:399] dt1 -> dt1
I0816 16:04:00.408963 20404 net.cpp:141] Setting up dt1
I0816 16:04:00.408975 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:00.409009 20404 net.cpp:156] Memory required for data: 1020112000
I0816 16:04:00.409020 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:00.409029 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:00.409039 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:00.409055 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:00.409065 20404 net.cpp:425] conv1 <- p1_p1_0_split_2
I0816 16:04:00.409082 20404 net.cpp:399] conv1 -> Convolution21
I0816 16:04:00.411885 20404 net.cpp:141] Setting up conv1
I0816 16:04:00.411907 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.411914 20404 net.cpp:156] Memory required for data: 1029942400
I0816 16:04:00.411932 20404 layer_factory.hpp:77] Creating layer ReLU29
I0816 16:04:00.411947 20404 net.cpp:91] Creating Layer ReLU29
I0816 16:04:00.411959 20404 net.cpp:425] ReLU29 <- Convolution21
I0816 16:04:00.411969 20404 net.cpp:386] ReLU29 -> Convolution21 (in-place)
I0816 16:04:00.411985 20404 net.cpp:141] Setting up ReLU29
I0816 16:04:00.411996 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.412005 20404 net.cpp:156] Memory required for data: 1039772800
I0816 16:04:00.412012 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:00.412025 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:00.412035 20404 net.cpp:425] norm1 <- Convolution21
I0816 16:04:00.412046 20404 net.cpp:399] norm1 -> LRN9
I0816 16:04:00.412104 20404 net.cpp:141] Setting up norm1
I0816 16:04:00.412147 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.412173 20404 net.cpp:156] Memory required for data: 1049603200
I0816 16:04:00.412199 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:00.412228 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:00.412253 20404 net.cpp:425] pool1 <- LRN9
I0816 16:04:00.412354 20404 net.cpp:399] pool1 -> Pooling13
I0816 16:04:00.412441 20404 net.cpp:141] Setting up pool1
I0816 16:04:00.412472 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:00.412497 20404 net.cpp:156] Memory required for data: 1052060800
I0816 16:04:00.412528 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:00.412569 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:00.412595 20404 net.cpp:425] conv2 <- Pooling13
I0816 16:04:00.412642 20404 net.cpp:399] conv2 -> Convolution22
I0816 16:04:00.428387 20404 net.cpp:141] Setting up conv2
I0816 16:04:00.428409 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.428416 20404 net.cpp:156] Memory required for data: 1058614400
I0816 16:04:00.428428 20404 layer_factory.hpp:77] Creating layer ReLU30
I0816 16:04:00.428439 20404 net.cpp:91] Creating Layer ReLU30
I0816 16:04:00.428453 20404 net.cpp:425] ReLU30 <- Convolution22
I0816 16:04:00.428465 20404 net.cpp:386] ReLU30 -> Convolution22 (in-place)
I0816 16:04:00.428481 20404 net.cpp:141] Setting up ReLU30
I0816 16:04:00.428493 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.428514 20404 net.cpp:156] Memory required for data: 1065168000
I0816 16:04:00.428524 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:00.428542 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:00.428551 20404 net.cpp:425] norm2 <- Convolution22
I0816 16:04:00.428567 20404 net.cpp:399] norm2 -> LRN10
I0816 16:04:00.428632 20404 net.cpp:141] Setting up norm2
I0816 16:04:00.428645 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.428653 20404 net.cpp:156] Memory required for data: 1071721600
I0816 16:04:00.428661 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:00.428676 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:00.428684 20404 net.cpp:425] pool2 <- LRN10
I0816 16:04:00.428696 20404 net.cpp:399] pool2 -> Pooling14
I0816 16:04:00.428756 20404 net.cpp:141] Setting up pool2
I0816 16:04:00.428769 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.428777 20404 net.cpp:156] Memory required for data: 1073360000
I0816 16:04:00.428784 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:00.428810 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:00.428819 20404 net.cpp:425] conv3 <- Pooling14
I0816 16:04:00.428835 20404 net.cpp:399] conv3 -> Convolution23
I0816 16:04:00.473500 20404 net.cpp:141] Setting up conv3
I0816 16:04:00.473536 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.473554 20404 net.cpp:156] Memory required for data: 1075817600
I0816 16:04:00.473570 20404 layer_factory.hpp:77] Creating layer ReLU31
I0816 16:04:00.473587 20404 net.cpp:91] Creating Layer ReLU31
I0816 16:04:00.473598 20404 net.cpp:425] ReLU31 <- Convolution23
I0816 16:04:00.473624 20404 net.cpp:386] ReLU31 -> Convolution23 (in-place)
I0816 16:04:00.473641 20404 net.cpp:141] Setting up ReLU31
I0816 16:04:00.473657 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.473664 20404 net.cpp:156] Memory required for data: 1078275200
I0816 16:04:00.473672 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:00.473693 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:00.473706 20404 net.cpp:425] conv4 <- Convolution23
I0816 16:04:00.473721 20404 net.cpp:399] conv4 -> Convolution24
I0816 16:04:00.507323 20404 net.cpp:141] Setting up conv4
I0816 16:04:00.507367 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.507374 20404 net.cpp:156] Memory required for data: 1080732800
I0816 16:04:00.507387 20404 layer_factory.hpp:77] Creating layer ReLU32
I0816 16:04:00.507405 20404 net.cpp:91] Creating Layer ReLU32
I0816 16:04:00.507426 20404 net.cpp:425] ReLU32 <- Convolution24
I0816 16:04:00.507438 20404 net.cpp:386] ReLU32 -> Convolution24 (in-place)
I0816 16:04:00.507453 20404 net.cpp:141] Setting up ReLU32
I0816 16:04:00.507460 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.507467 20404 net.cpp:156] Memory required for data: 1083190400
I0816 16:04:00.507472 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:00.507491 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:00.507498 20404 net.cpp:425] conv5 <- Convolution24
I0816 16:04:00.507511 20404 net.cpp:399] conv5 -> Convolution25
I0816 16:04:00.529934 20404 net.cpp:141] Setting up conv5
I0816 16:04:00.529968 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.529975 20404 net.cpp:156] Memory required for data: 1084828800
I0816 16:04:00.529988 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:00.530038 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:00.530048 20404 net.cpp:425] pool5 <- Convolution25
I0816 16:04:00.530059 20404 net.cpp:399] pool5 -> Pooling15
I0816 16:04:00.530119 20404 net.cpp:141] Setting up pool5
I0816 16:04:00.530128 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:00.530133 20404 net.cpp:156] Memory required for data: 1085238400
I0816 16:04:00.530138 20404 layer_factory.hpp:77] Creating layer InnerProduct13
I0816 16:04:00.530153 20404 net.cpp:91] Creating Layer InnerProduct13
I0816 16:04:00.530158 20404 net.cpp:425] InnerProduct13 <- Pooling15
I0816 16:04:00.530169 20404 net.cpp:399] InnerProduct13 -> InnerProduct13
I0816 16:04:00.532909 20404 net.cpp:141] Setting up InnerProduct13
I0816 16:04:00.532929 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.532946 20404 net.cpp:156] Memory required for data: 1085340800
I0816 16:04:00.532956 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:00.532966 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:00.532974 20404 layer_factory.hpp:77] Creating layer ReLU33
I0816 16:04:00.532989 20404 net.cpp:91] Creating Layer ReLU33
I0816 16:04:00.532997 20404 net.cpp:425] ReLU33 <- InnerProduct13
I0816 16:04:00.533020 20404 net.cpp:386] ReLU33 -> InnerProduct13 (in-place)
I0816 16:04:00.533032 20404 net.cpp:141] Setting up ReLU33
I0816 16:04:00.533043 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.533051 20404 net.cpp:156] Memory required for data: 1085443200
I0816 16:04:00.533057 20404 layer_factory.hpp:77] Creating layer InnerProduct14
I0816 16:04:00.533073 20404 net.cpp:91] Creating Layer InnerProduct14
I0816 16:04:00.533082 20404 net.cpp:425] InnerProduct14 <- InnerProduct13
I0816 16:04:00.533094 20404 net.cpp:399] InnerProduct14 -> InnerProduct14
I0816 16:04:00.533761 20404 net.cpp:141] Setting up InnerProduct14
I0816 16:04:00.533774 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.533782 20404 net.cpp:156] Memory required for data: 1085545600
I0816 16:04:00.533792 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:00.533800 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:00.533808 20404 layer_factory.hpp:77] Creating layer ReLU34
I0816 16:04:00.533818 20404 net.cpp:91] Creating Layer ReLU34
I0816 16:04:00.533828 20404 net.cpp:425] ReLU34 <- InnerProduct14
I0816 16:04:00.533838 20404 net.cpp:386] ReLU34 -> InnerProduct14 (in-place)
I0816 16:04:00.533850 20404 net.cpp:141] Setting up ReLU34
I0816 16:04:00.533860 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.533869 20404 net.cpp:156] Memory required for data: 1085648000
I0816 16:04:00.533875 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:00.533898 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:00.533908 20404 net.cpp:425] conv1 <- c22
I0816 16:04:00.533922 20404 net.cpp:399] conv1 -> Convolution26
I0816 16:04:00.535998 20404 net.cpp:141] Setting up conv1
I0816 16:04:00.536015 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.536023 20404 net.cpp:156] Memory required for data: 1095478400
I0816 16:04:00.536037 20404 layer_factory.hpp:77] Creating layer ReLU35
I0816 16:04:00.536049 20404 net.cpp:91] Creating Layer ReLU35
I0816 16:04:00.536057 20404 net.cpp:425] ReLU35 <- Convolution26
I0816 16:04:00.536072 20404 net.cpp:386] ReLU35 -> Convolution26 (in-place)
I0816 16:04:00.536087 20404 net.cpp:141] Setting up ReLU35
I0816 16:04:00.536097 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.536104 20404 net.cpp:156] Memory required for data: 1105308800
I0816 16:04:00.536111 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:00.536123 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:00.536133 20404 net.cpp:425] norm1 <- Convolution26
I0816 16:04:00.536149 20404 net.cpp:399] norm1 -> LRN11
I0816 16:04:00.536202 20404 net.cpp:141] Setting up norm1
I0816 16:04:00.536229 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.536237 20404 net.cpp:156] Memory required for data: 1115139200
I0816 16:04:00.536244 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:00.536258 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:00.536267 20404 net.cpp:425] pool1 <- LRN11
I0816 16:04:00.536278 20404 net.cpp:399] pool1 -> Pooling16
I0816 16:04:00.536339 20404 net.cpp:141] Setting up pool1
I0816 16:04:00.536352 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:00.536360 20404 net.cpp:156] Memory required for data: 1117596800
I0816 16:04:00.536367 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:00.536386 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:00.536398 20404 net.cpp:425] conv2 <- Pooling16
I0816 16:04:00.536412 20404 net.cpp:399] conv2 -> Convolution27
I0816 16:04:00.551996 20404 net.cpp:141] Setting up conv2
I0816 16:04:00.552018 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.552027 20404 net.cpp:156] Memory required for data: 1124150400
I0816 16:04:00.552043 20404 layer_factory.hpp:77] Creating layer ReLU36
I0816 16:04:00.552055 20404 net.cpp:91] Creating Layer ReLU36
I0816 16:04:00.552065 20404 net.cpp:425] ReLU36 <- Convolution27
I0816 16:04:00.552078 20404 net.cpp:386] ReLU36 -> Convolution27 (in-place)
I0816 16:04:00.552093 20404 net.cpp:141] Setting up ReLU36
I0816 16:04:00.552103 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.552110 20404 net.cpp:156] Memory required for data: 1130704000
I0816 16:04:00.552117 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:00.552134 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:00.552142 20404 net.cpp:425] norm2 <- Convolution27
I0816 16:04:00.552157 20404 net.cpp:399] norm2 -> LRN12
I0816 16:04:00.552222 20404 net.cpp:141] Setting up norm2
I0816 16:04:00.552237 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.552243 20404 net.cpp:156] Memory required for data: 1137257600
I0816 16:04:00.552251 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:00.552265 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:00.552273 20404 net.cpp:425] pool2 <- LRN12
I0816 16:04:00.552285 20404 net.cpp:399] pool2 -> Pooling17
I0816 16:04:00.552345 20404 net.cpp:141] Setting up pool2
I0816 16:04:00.552357 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.552366 20404 net.cpp:156] Memory required for data: 1138896000
I0816 16:04:00.552372 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:00.552392 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:00.552402 20404 net.cpp:425] conv3 <- Pooling17
I0816 16:04:00.552418 20404 net.cpp:399] conv3 -> Convolution28
I0816 16:04:00.596451 20404 net.cpp:141] Setting up conv3
I0816 16:04:00.596480 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.596489 20404 net.cpp:156] Memory required for data: 1141353600
I0816 16:04:00.596518 20404 layer_factory.hpp:77] Creating layer ReLU37
I0816 16:04:00.596534 20404 net.cpp:91] Creating Layer ReLU37
I0816 16:04:00.596545 20404 net.cpp:425] ReLU37 <- Convolution28
I0816 16:04:00.596559 20404 net.cpp:386] ReLU37 -> Convolution28 (in-place)
I0816 16:04:00.596575 20404 net.cpp:141] Setting up ReLU37
I0816 16:04:00.596585 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.596592 20404 net.cpp:156] Memory required for data: 1143811200
I0816 16:04:00.596601 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:00.596621 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:00.596637 20404 net.cpp:425] conv4 <- Convolution28
I0816 16:04:00.596654 20404 net.cpp:399] conv4 -> Convolution29
I0816 16:04:00.630302 20404 net.cpp:141] Setting up conv4
I0816 16:04:00.630338 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.630347 20404 net.cpp:156] Memory required for data: 1146268800
I0816 16:04:00.630365 20404 layer_factory.hpp:77] Creating layer ReLU38
I0816 16:04:00.630381 20404 net.cpp:91] Creating Layer ReLU38
I0816 16:04:00.630396 20404 net.cpp:425] ReLU38 <- Convolution29
I0816 16:04:00.630429 20404 net.cpp:386] ReLU38 -> Convolution29 (in-place)
I0816 16:04:00.630446 20404 net.cpp:141] Setting up ReLU38
I0816 16:04:00.630457 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.630465 20404 net.cpp:156] Memory required for data: 1148726400
I0816 16:04:00.630472 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:00.630493 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:00.630502 20404 net.cpp:425] conv5 <- Convolution29
I0816 16:04:00.630517 20404 net.cpp:399] conv5 -> Convolution30
I0816 16:04:00.653234 20404 net.cpp:141] Setting up conv5
I0816 16:04:00.653265 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.653283 20404 net.cpp:156] Memory required for data: 1150364800
I0816 16:04:00.653301 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:00.653316 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:00.653326 20404 net.cpp:425] pool5 <- Convolution30
I0816 16:04:00.653352 20404 net.cpp:399] pool5 -> Pooling18
I0816 16:04:00.653419 20404 net.cpp:141] Setting up pool5
I0816 16:04:00.653435 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:00.653444 20404 net.cpp:156] Memory required for data: 1150774400
I0816 16:04:00.653450 20404 layer_factory.hpp:77] Creating layer InnerProduct15
I0816 16:04:00.653465 20404 net.cpp:91] Creating Layer InnerProduct15
I0816 16:04:00.653473 20404 net.cpp:425] InnerProduct15 <- Pooling18
I0816 16:04:00.653489 20404 net.cpp:399] InnerProduct15 -> InnerProduct15
I0816 16:04:00.656383 20404 net.cpp:141] Setting up InnerProduct15
I0816 16:04:00.656433 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.656458 20404 net.cpp:156] Memory required for data: 1150876800
I0816 16:04:00.656486 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:00.656512 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:00.656538 20404 layer_factory.hpp:77] Creating layer ReLU39
I0816 16:04:00.656564 20404 net.cpp:91] Creating Layer ReLU39
I0816 16:04:00.656589 20404 net.cpp:425] ReLU39 <- InnerProduct15
I0816 16:04:00.656618 20404 net.cpp:386] ReLU39 -> InnerProduct15 (in-place)
I0816 16:04:00.656649 20404 net.cpp:141] Setting up ReLU39
I0816 16:04:00.656675 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.656697 20404 net.cpp:156] Memory required for data: 1150979200
I0816 16:04:00.656723 20404 layer_factory.hpp:77] Creating layer InnerProduct16
I0816 16:04:00.656756 20404 net.cpp:91] Creating Layer InnerProduct16
I0816 16:04:00.656785 20404 net.cpp:425] InnerProduct16 <- InnerProduct15
I0816 16:04:00.656821 20404 net.cpp:399] InnerProduct16 -> InnerProduct16
I0816 16:04:00.657528 20404 net.cpp:141] Setting up InnerProduct16
I0816 16:04:00.657546 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.657554 20404 net.cpp:156] Memory required for data: 1151081600
I0816 16:04:00.657563 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:00.657573 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:00.657582 20404 layer_factory.hpp:77] Creating layer ReLU40
I0816 16:04:00.657595 20404 net.cpp:91] Creating Layer ReLU40
I0816 16:04:00.657603 20404 net.cpp:425] ReLU40 <- InnerProduct16
I0816 16:04:00.657615 20404 net.cpp:386] ReLU40 -> InnerProduct16 (in-place)
I0816 16:04:00.657629 20404 net.cpp:141] Setting up ReLU40
I0816 16:04:00.657639 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.657646 20404 net.cpp:156] Memory required for data: 1151184000
I0816 16:04:00.657654 20404 layer_factory.hpp:77] Creating layer Concat3
I0816 16:04:00.657665 20404 net.cpp:91] Creating Layer Concat3
I0816 16:04:00.657673 20404 net.cpp:425] Concat3 <- InnerProduct14
I0816 16:04:00.657683 20404 net.cpp:425] Concat3 <- InnerProduct16
I0816 16:04:00.657696 20404 net.cpp:399] Concat3 -> Concat3
I0816 16:04:00.657737 20404 net.cpp:141] Setting up Concat3
I0816 16:04:00.657774 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:00.657816 20404 net.cpp:156] Memory required for data: 1151388800
I0816 16:04:00.657843 20404 layer_factory.hpp:77] Creating layer InnerProduct17
I0816 16:04:00.657877 20404 net.cpp:91] Creating Layer InnerProduct17
I0816 16:04:00.657905 20404 net.cpp:425] InnerProduct17 <- Concat3
I0816 16:04:00.657941 20404 net.cpp:399] InnerProduct17 -> InnerProduct17
I0816 16:04:00.659143 20404 net.cpp:141] Setting up InnerProduct17
I0816 16:04:00.659160 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.659168 20404 net.cpp:156] Memory required for data: 1151491200
I0816 16:04:00.659178 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:00.659186 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:00.659195 20404 layer_factory.hpp:77] Creating layer ReLU41
I0816 16:04:00.659206 20404 net.cpp:91] Creating Layer ReLU41
I0816 16:04:00.659214 20404 net.cpp:425] ReLU41 <- InnerProduct17
I0816 16:04:00.659225 20404 net.cpp:386] ReLU41 -> InnerProduct17 (in-place)
I0816 16:04:00.659237 20404 net.cpp:141] Setting up ReLU41
I0816 16:04:00.659248 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.659255 20404 net.cpp:156] Memory required for data: 1151593600
I0816 16:04:00.659263 20404 layer_factory.hpp:77] Creating layer InnerProduct18
I0816 16:04:00.659281 20404 net.cpp:91] Creating Layer InnerProduct18
I0816 16:04:00.659291 20404 net.cpp:425] InnerProduct18 <- InnerProduct17
I0816 16:04:00.659307 20404 net.cpp:399] InnerProduct18 -> InnerProduct18
I0816 16:04:00.659714 20404 net.cpp:141] Setting up InnerProduct18
I0816 16:04:00.659729 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:00.659737 20404 net.cpp:156] Memory required for data: 1151644800
I0816 16:04:00.659745 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:00.659754 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:00.659764 20404 layer_factory.hpp:77] Creating layer ReLU42
I0816 16:04:00.659773 20404 net.cpp:91] Creating Layer ReLU42
I0816 16:04:00.659781 20404 net.cpp:425] ReLU42 <- InnerProduct18
I0816 16:04:00.659795 20404 net.cpp:386] ReLU42 -> InnerProduct18 (in-place)
I0816 16:04:00.659808 20404 net.cpp:141] Setting up ReLU42
I0816 16:04:00.659818 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:00.659826 20404 net.cpp:156] Memory required for data: 1151696000
I0816 16:04:00.659833 20404 layer_factory.hpp:77] Creating layer dt2
I0816 16:04:00.659845 20404 net.cpp:91] Creating Layer dt2
I0816 16:04:00.659853 20404 net.cpp:425] dt2 <- InnerProduct18
I0816 16:04:00.659867 20404 net.cpp:399] dt2 -> dt2
I0816 16:04:00.660009 20404 net.cpp:141] Setting up dt2
I0816 16:04:00.660023 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:00.660030 20404 net.cpp:156] Memory required for data: 1151696400
I0816 16:04:00.660038 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:00.660048 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:00.660056 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:00.660073 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:00.660081 20404 net.cpp:425] conv1 <- p1_p1_0_split_3
I0816 16:04:00.660099 20404 net.cpp:399] conv1 -> Convolution31
I0816 16:04:00.662819 20404 net.cpp:141] Setting up conv1
I0816 16:04:00.662844 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.662853 20404 net.cpp:156] Memory required for data: 1161526800
I0816 16:04:00.662868 20404 layer_factory.hpp:77] Creating layer ReLU43
I0816 16:04:00.662883 20404 net.cpp:91] Creating Layer ReLU43
I0816 16:04:00.662894 20404 net.cpp:425] ReLU43 <- Convolution31
I0816 16:04:00.662905 20404 net.cpp:386] ReLU43 -> Convolution31 (in-place)
I0816 16:04:00.662920 20404 net.cpp:141] Setting up ReLU43
I0816 16:04:00.662930 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.662938 20404 net.cpp:156] Memory required for data: 1171357200
I0816 16:04:00.662971 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:00.662988 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:00.662997 20404 net.cpp:425] norm1 <- Convolution31
I0816 16:04:00.663009 20404 net.cpp:399] norm1 -> LRN13
I0816 16:04:00.663065 20404 net.cpp:141] Setting up norm1
I0816 16:04:00.663079 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.663086 20404 net.cpp:156] Memory required for data: 1181187600
I0816 16:04:00.663094 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:00.663105 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:00.663113 20404 net.cpp:425] pool1 <- LRN13
I0816 16:04:00.663128 20404 net.cpp:399] pool1 -> Pooling19
I0816 16:04:00.663187 20404 net.cpp:141] Setting up pool1
I0816 16:04:00.663199 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:00.663208 20404 net.cpp:156] Memory required for data: 1183645200
I0816 16:04:00.663214 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:00.663239 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:00.663250 20404 net.cpp:425] conv2 <- Pooling19
I0816 16:04:00.663264 20404 net.cpp:399] conv2 -> Convolution32
I0816 16:04:00.679116 20404 net.cpp:141] Setting up conv2
I0816 16:04:00.679150 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.679158 20404 net.cpp:156] Memory required for data: 1190198800
I0816 16:04:00.679178 20404 layer_factory.hpp:77] Creating layer ReLU44
I0816 16:04:00.679196 20404 net.cpp:91] Creating Layer ReLU44
I0816 16:04:00.679208 20404 net.cpp:425] ReLU44 <- Convolution32
I0816 16:04:00.679219 20404 net.cpp:386] ReLU44 -> Convolution32 (in-place)
I0816 16:04:00.679235 20404 net.cpp:141] Setting up ReLU44
I0816 16:04:00.679245 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.679253 20404 net.cpp:156] Memory required for data: 1196752400
I0816 16:04:00.679261 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:00.679292 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:00.679302 20404 net.cpp:425] norm2 <- Convolution32
I0816 16:04:00.679318 20404 net.cpp:399] norm2 -> LRN14
I0816 16:04:00.679379 20404 net.cpp:141] Setting up norm2
I0816 16:04:00.679394 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.679401 20404 net.cpp:156] Memory required for data: 1203306000
I0816 16:04:00.679409 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:00.679424 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:00.679432 20404 net.cpp:425] pool2 <- LRN14
I0816 16:04:00.679443 20404 net.cpp:399] pool2 -> Pooling20
I0816 16:04:00.679527 20404 net.cpp:141] Setting up pool2
I0816 16:04:00.679541 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.679549 20404 net.cpp:156] Memory required for data: 1204944400
I0816 16:04:00.679558 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:00.679594 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:00.679605 20404 net.cpp:425] conv3 <- Pooling20
I0816 16:04:00.679622 20404 net.cpp:399] conv3 -> Convolution33
I0816 16:04:00.723567 20404 net.cpp:141] Setting up conv3
I0816 16:04:00.723598 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.723618 20404 net.cpp:156] Memory required for data: 1207402000
I0816 16:04:00.723634 20404 layer_factory.hpp:77] Creating layer ReLU45
I0816 16:04:00.723649 20404 net.cpp:91] Creating Layer ReLU45
I0816 16:04:00.723659 20404 net.cpp:425] ReLU45 <- Convolution33
I0816 16:04:00.723685 20404 net.cpp:386] ReLU45 -> Convolution33 (in-place)
I0816 16:04:00.723702 20404 net.cpp:141] Setting up ReLU45
I0816 16:04:00.723717 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.723726 20404 net.cpp:156] Memory required for data: 1209859600
I0816 16:04:00.723733 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:00.723754 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:00.723767 20404 net.cpp:425] conv4 <- Convolution33
I0816 16:04:00.723783 20404 net.cpp:399] conv4 -> Convolution34
I0816 16:04:00.756883 20404 net.cpp:141] Setting up conv4
I0816 16:04:00.756932 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.756952 20404 net.cpp:156] Memory required for data: 1212317200
I0816 16:04:00.756968 20404 layer_factory.hpp:77] Creating layer ReLU46
I0816 16:04:00.756984 20404 net.cpp:91] Creating Layer ReLU46
I0816 16:04:00.756994 20404 net.cpp:425] ReLU46 <- Convolution34
I0816 16:04:00.757016 20404 net.cpp:386] ReLU46 -> Convolution34 (in-place)
I0816 16:04:00.757031 20404 net.cpp:141] Setting up ReLU46
I0816 16:04:00.757041 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.757050 20404 net.cpp:156] Memory required for data: 1214774800
I0816 16:04:00.757056 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:00.757076 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:00.757086 20404 net.cpp:425] conv5 <- Convolution34
I0816 16:04:00.757102 20404 net.cpp:399] conv5 -> Convolution35
I0816 16:04:00.779392 20404 net.cpp:141] Setting up conv5
I0816 16:04:00.779417 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.779425 20404 net.cpp:156] Memory required for data: 1216413200
I0816 16:04:00.779441 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:00.779465 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:00.779476 20404 net.cpp:425] pool5 <- Convolution35
I0816 16:04:00.779490 20404 net.cpp:399] pool5 -> Pooling21
I0816 16:04:00.779558 20404 net.cpp:141] Setting up pool5
I0816 16:04:00.779572 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:00.779580 20404 net.cpp:156] Memory required for data: 1216822800
I0816 16:04:00.779588 20404 layer_factory.hpp:77] Creating layer InnerProduct19
I0816 16:04:00.779605 20404 net.cpp:91] Creating Layer InnerProduct19
I0816 16:04:00.779614 20404 net.cpp:425] InnerProduct19 <- Pooling21
I0816 16:04:00.779628 20404 net.cpp:399] InnerProduct19 -> InnerProduct19
I0816 16:04:00.782337 20404 net.cpp:141] Setting up InnerProduct19
I0816 16:04:00.782357 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.782374 20404 net.cpp:156] Memory required for data: 1216925200
I0816 16:04:00.782384 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:00.782394 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:00.782402 20404 layer_factory.hpp:77] Creating layer ReLU47
I0816 16:04:00.782416 20404 net.cpp:91] Creating Layer ReLU47
I0816 16:04:00.782425 20404 net.cpp:425] ReLU47 <- InnerProduct19
I0816 16:04:00.782446 20404 net.cpp:386] ReLU47 -> InnerProduct19 (in-place)
I0816 16:04:00.782460 20404 net.cpp:141] Setting up ReLU47
I0816 16:04:00.782470 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.782479 20404 net.cpp:156] Memory required for data: 1217027600
I0816 16:04:00.782486 20404 layer_factory.hpp:77] Creating layer InnerProduct20
I0816 16:04:00.782501 20404 net.cpp:91] Creating Layer InnerProduct20
I0816 16:04:00.782510 20404 net.cpp:425] InnerProduct20 <- InnerProduct19
I0816 16:04:00.782522 20404 net.cpp:399] InnerProduct20 -> InnerProduct20
I0816 16:04:00.783190 20404 net.cpp:141] Setting up InnerProduct20
I0816 16:04:00.783205 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.783221 20404 net.cpp:156] Memory required for data: 1217130000
I0816 16:04:00.783229 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:00.783239 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:00.783246 20404 layer_factory.hpp:77] Creating layer ReLU48
I0816 16:04:00.783257 20404 net.cpp:91] Creating Layer ReLU48
I0816 16:04:00.783265 20404 net.cpp:425] ReLU48 <- InnerProduct20
I0816 16:04:00.783282 20404 net.cpp:386] ReLU48 -> InnerProduct20 (in-place)
I0816 16:04:00.783295 20404 net.cpp:141] Setting up ReLU48
I0816 16:04:00.783305 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.783313 20404 net.cpp:156] Memory required for data: 1217232400
I0816 16:04:00.783320 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:00.783360 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:00.783370 20404 net.cpp:425] conv1 <- c23
I0816 16:04:00.783385 20404 net.cpp:399] conv1 -> Convolution36
I0816 16:04:00.785408 20404 net.cpp:141] Setting up conv1
I0816 16:04:00.785423 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.785430 20404 net.cpp:156] Memory required for data: 1227062800
I0816 16:04:00.785444 20404 layer_factory.hpp:77] Creating layer ReLU49
I0816 16:04:00.785454 20404 net.cpp:91] Creating Layer ReLU49
I0816 16:04:00.785466 20404 net.cpp:425] ReLU49 <- Convolution36
I0816 16:04:00.785477 20404 net.cpp:386] ReLU49 -> Convolution36 (in-place)
I0816 16:04:00.785490 20404 net.cpp:141] Setting up ReLU49
I0816 16:04:00.785501 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.785508 20404 net.cpp:156] Memory required for data: 1236893200
I0816 16:04:00.785516 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:00.785527 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:00.785537 20404 net.cpp:425] norm1 <- Convolution36
I0816 16:04:00.785552 20404 net.cpp:399] norm1 -> LRN15
I0816 16:04:00.785605 20404 net.cpp:141] Setting up norm1
I0816 16:04:00.785619 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.785626 20404 net.cpp:156] Memory required for data: 1246723600
I0816 16:04:00.785634 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:00.785647 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:00.785656 20404 net.cpp:425] pool1 <- LRN15
I0816 16:04:00.785667 20404 net.cpp:399] pool1 -> Pooling22
I0816 16:04:00.785728 20404 net.cpp:141] Setting up pool1
I0816 16:04:00.785742 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:00.785750 20404 net.cpp:156] Memory required for data: 1249181200
I0816 16:04:00.785758 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:00.785775 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:00.785784 20404 net.cpp:425] conv2 <- Pooling22
I0816 16:04:00.785799 20404 net.cpp:399] conv2 -> Convolution37
I0816 16:04:00.801414 20404 net.cpp:141] Setting up conv2
I0816 16:04:00.801439 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.801458 20404 net.cpp:156] Memory required for data: 1255734800
I0816 16:04:00.801473 20404 layer_factory.hpp:77] Creating layer ReLU50
I0816 16:04:00.801486 20404 net.cpp:91] Creating Layer ReLU50
I0816 16:04:00.801496 20404 net.cpp:425] ReLU50 <- Convolution37
I0816 16:04:00.801509 20404 net.cpp:386] ReLU50 -> Convolution37 (in-place)
I0816 16:04:00.801533 20404 net.cpp:141] Setting up ReLU50
I0816 16:04:00.801543 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.801551 20404 net.cpp:156] Memory required for data: 1262288400
I0816 16:04:00.801558 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:00.801573 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:00.801583 20404 net.cpp:425] norm2 <- Convolution37
I0816 16:04:00.801597 20404 net.cpp:399] norm2 -> LRN16
I0816 16:04:00.801659 20404 net.cpp:141] Setting up norm2
I0816 16:04:00.801673 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.801681 20404 net.cpp:156] Memory required for data: 1268842000
I0816 16:04:00.801688 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:00.801702 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:00.801710 20404 net.cpp:425] pool2 <- LRN16
I0816 16:04:00.801723 20404 net.cpp:399] pool2 -> Pooling23
I0816 16:04:00.801785 20404 net.cpp:141] Setting up pool2
I0816 16:04:00.801800 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.801806 20404 net.cpp:156] Memory required for data: 1270480400
I0816 16:04:00.801815 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:00.801833 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:00.801841 20404 net.cpp:425] conv3 <- Pooling23
I0816 16:04:00.801859 20404 net.cpp:399] conv3 -> Convolution38
I0816 16:04:00.845397 20404 net.cpp:141] Setting up conv3
I0816 16:04:00.845427 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.845435 20404 net.cpp:156] Memory required for data: 1272938000
I0816 16:04:00.845492 20404 layer_factory.hpp:77] Creating layer ReLU51
I0816 16:04:00.845515 20404 net.cpp:91] Creating Layer ReLU51
I0816 16:04:00.845546 20404 net.cpp:425] ReLU51 <- Convolution38
I0816 16:04:00.845562 20404 net.cpp:386] ReLU51 -> Convolution38 (in-place)
I0816 16:04:00.845580 20404 net.cpp:141] Setting up ReLU51
I0816 16:04:00.845595 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.845605 20404 net.cpp:156] Memory required for data: 1275395600
I0816 16:04:00.845614 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:00.845638 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:00.845650 20404 net.cpp:425] conv4 <- Convolution38
I0816 16:04:00.845664 20404 net.cpp:399] conv4 -> Convolution39
I0816 16:04:00.878538 20404 net.cpp:141] Setting up conv4
I0816 16:04:00.878566 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.878574 20404 net.cpp:156] Memory required for data: 1277853200
I0816 16:04:00.878599 20404 layer_factory.hpp:77] Creating layer ReLU52
I0816 16:04:00.878636 20404 net.cpp:91] Creating Layer ReLU52
I0816 16:04:00.878650 20404 net.cpp:425] ReLU52 <- Convolution39
I0816 16:04:00.878671 20404 net.cpp:386] ReLU52 -> Convolution39 (in-place)
I0816 16:04:00.878689 20404 net.cpp:141] Setting up ReLU52
I0816 16:04:00.878703 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.878731 20404 net.cpp:156] Memory required for data: 1280310800
I0816 16:04:00.878742 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:00.878763 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:00.878777 20404 net.cpp:425] conv5 <- Convolution39
I0816 16:04:00.878798 20404 net.cpp:399] conv5 -> Convolution40
I0816 16:04:00.901172 20404 net.cpp:141] Setting up conv5
I0816 16:04:00.901199 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.901207 20404 net.cpp:156] Memory required for data: 1281949200
I0816 16:04:00.901233 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:00.901289 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:00.901327 20404 net.cpp:425] pool5 <- Convolution40
I0816 16:04:00.901363 20404 net.cpp:399] pool5 -> Pooling24
I0816 16:04:00.901442 20404 net.cpp:141] Setting up pool5
I0816 16:04:00.901455 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:00.901463 20404 net.cpp:156] Memory required for data: 1282358800
I0816 16:04:00.901470 20404 layer_factory.hpp:77] Creating layer InnerProduct21
I0816 16:04:00.901486 20404 net.cpp:91] Creating Layer InnerProduct21
I0816 16:04:00.901494 20404 net.cpp:425] InnerProduct21 <- Pooling24
I0816 16:04:00.901504 20404 net.cpp:399] InnerProduct21 -> InnerProduct21
I0816 16:04:00.904269 20404 net.cpp:141] Setting up InnerProduct21
I0816 16:04:00.904296 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.904302 20404 net.cpp:156] Memory required for data: 1282461200
I0816 16:04:00.904310 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:00.904319 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:00.904325 20404 layer_factory.hpp:77] Creating layer ReLU53
I0816 16:04:00.904335 20404 net.cpp:91] Creating Layer ReLU53
I0816 16:04:00.904342 20404 net.cpp:425] ReLU53 <- InnerProduct21
I0816 16:04:00.904362 20404 net.cpp:386] ReLU53 -> InnerProduct21 (in-place)
I0816 16:04:00.904373 20404 net.cpp:141] Setting up ReLU53
I0816 16:04:00.904381 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.904386 20404 net.cpp:156] Memory required for data: 1282563600
I0816 16:04:00.904392 20404 layer_factory.hpp:77] Creating layer InnerProduct22
I0816 16:04:00.904403 20404 net.cpp:91] Creating Layer InnerProduct22
I0816 16:04:00.904410 20404 net.cpp:425] InnerProduct22 <- InnerProduct21
I0816 16:04:00.904419 20404 net.cpp:399] InnerProduct22 -> InnerProduct22
I0816 16:04:00.905088 20404 net.cpp:141] Setting up InnerProduct22
I0816 16:04:00.905103 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.905109 20404 net.cpp:156] Memory required for data: 1282666000
I0816 16:04:00.905179 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:00.905189 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:00.905194 20404 layer_factory.hpp:77] Creating layer ReLU54
I0816 16:04:00.905203 20404 net.cpp:91] Creating Layer ReLU54
I0816 16:04:00.905210 20404 net.cpp:425] ReLU54 <- InnerProduct22
I0816 16:04:00.905221 20404 net.cpp:386] ReLU54 -> InnerProduct22 (in-place)
I0816 16:04:00.905232 20404 net.cpp:141] Setting up ReLU54
I0816 16:04:00.905239 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.905246 20404 net.cpp:156] Memory required for data: 1282768400
I0816 16:04:00.905251 20404 layer_factory.hpp:77] Creating layer Concat4
I0816 16:04:00.905261 20404 net.cpp:91] Creating Layer Concat4
I0816 16:04:00.905267 20404 net.cpp:425] Concat4 <- InnerProduct20
I0816 16:04:00.905275 20404 net.cpp:425] Concat4 <- InnerProduct22
I0816 16:04:00.905284 20404 net.cpp:399] Concat4 -> Concat4
I0816 16:04:00.905316 20404 net.cpp:141] Setting up Concat4
I0816 16:04:00.905361 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:00.905372 20404 net.cpp:156] Memory required for data: 1282973200
I0816 16:04:00.905380 20404 layer_factory.hpp:77] Creating layer InnerProduct23
I0816 16:04:00.905395 20404 net.cpp:91] Creating Layer InnerProduct23
I0816 16:04:00.905401 20404 net.cpp:425] InnerProduct23 <- Concat4
I0816 16:04:00.905411 20404 net.cpp:399] InnerProduct23 -> InnerProduct23
I0816 16:04:00.907155 20404 net.cpp:141] Setting up InnerProduct23
I0816 16:04:00.907179 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.907186 20404 net.cpp:156] Memory required for data: 1283075600
I0816 16:04:00.907192 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:00.907201 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:00.907207 20404 layer_factory.hpp:77] Creating layer ReLU55
I0816 16:04:00.907214 20404 net.cpp:91] Creating Layer ReLU55
I0816 16:04:00.907222 20404 net.cpp:425] ReLU55 <- InnerProduct23
I0816 16:04:00.907239 20404 net.cpp:386] ReLU55 -> InnerProduct23 (in-place)
I0816 16:04:00.907250 20404 net.cpp:141] Setting up ReLU55
I0816 16:04:00.907258 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:00.907263 20404 net.cpp:156] Memory required for data: 1283178000
I0816 16:04:00.907269 20404 layer_factory.hpp:77] Creating layer InnerProduct24
I0816 16:04:00.907297 20404 net.cpp:91] Creating Layer InnerProduct24
I0816 16:04:00.907304 20404 net.cpp:425] InnerProduct24 <- InnerProduct23
I0816 16:04:00.907313 20404 net.cpp:399] InnerProduct24 -> InnerProduct24
I0816 16:04:00.907719 20404 net.cpp:141] Setting up InnerProduct24
I0816 16:04:00.907730 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:00.907737 20404 net.cpp:156] Memory required for data: 1283229200
I0816 16:04:00.907743 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:00.907752 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:00.907758 20404 layer_factory.hpp:77] Creating layer ReLU56
I0816 16:04:00.907766 20404 net.cpp:91] Creating Layer ReLU56
I0816 16:04:00.907774 20404 net.cpp:425] ReLU56 <- InnerProduct24
I0816 16:04:00.907783 20404 net.cpp:386] ReLU56 -> InnerProduct24 (in-place)
I0816 16:04:00.907793 20404 net.cpp:141] Setting up ReLU56
I0816 16:04:00.907800 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:00.907806 20404 net.cpp:156] Memory required for data: 1283280400
I0816 16:04:00.907811 20404 layer_factory.hpp:77] Creating layer dt3
I0816 16:04:00.907821 20404 net.cpp:91] Creating Layer dt3
I0816 16:04:00.907827 20404 net.cpp:425] dt3 <- InnerProduct24
I0816 16:04:00.907842 20404 net.cpp:399] dt3 -> dt3
I0816 16:04:00.907984 20404 net.cpp:141] Setting up dt3
I0816 16:04:00.907994 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:00.908023 20404 net.cpp:156] Memory required for data: 1283280800
I0816 16:04:00.908032 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:00.908041 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:00.908049 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:00.908071 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:00.908077 20404 net.cpp:425] conv1 <- p1_p1_0_split_4
I0816 16:04:00.908088 20404 net.cpp:399] conv1 -> Convolution41
I0816 16:04:00.910678 20404 net.cpp:141] Setting up conv1
I0816 16:04:00.910706 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.910712 20404 net.cpp:156] Memory required for data: 1293111200
I0816 16:04:00.910722 20404 layer_factory.hpp:77] Creating layer ReLU57
I0816 16:04:00.910730 20404 net.cpp:91] Creating Layer ReLU57
I0816 16:04:00.910737 20404 net.cpp:425] ReLU57 <- Convolution41
I0816 16:04:00.910748 20404 net.cpp:386] ReLU57 -> Convolution41 (in-place)
I0816 16:04:00.910765 20404 net.cpp:141] Setting up ReLU57
I0816 16:04:00.910773 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.910778 20404 net.cpp:156] Memory required for data: 1302941600
I0816 16:04:00.910784 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:00.910795 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:00.910802 20404 net.cpp:425] norm1 <- Convolution41
I0816 16:04:00.910811 20404 net.cpp:399] norm1 -> LRN17
I0816 16:04:00.910857 20404 net.cpp:141] Setting up norm1
I0816 16:04:00.910867 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:00.910873 20404 net.cpp:156] Memory required for data: 1312772000
I0816 16:04:00.910878 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:00.910889 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:00.910895 20404 net.cpp:425] pool1 <- LRN17
I0816 16:04:00.910904 20404 net.cpp:399] pool1 -> Pooling25
I0816 16:04:00.910956 20404 net.cpp:141] Setting up pool1
I0816 16:04:00.910966 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:00.910972 20404 net.cpp:156] Memory required for data: 1315229600
I0816 16:04:00.910977 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:00.910992 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:00.911005 20404 net.cpp:425] conv2 <- Pooling25
I0816 16:04:00.911022 20404 net.cpp:399] conv2 -> Convolution42
I0816 16:04:00.926800 20404 net.cpp:141] Setting up conv2
I0816 16:04:00.926827 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.926836 20404 net.cpp:156] Memory required for data: 1321783200
I0816 16:04:00.926862 20404 layer_factory.hpp:77] Creating layer ReLU58
I0816 16:04:00.926903 20404 net.cpp:91] Creating Layer ReLU58
I0816 16:04:00.926944 20404 net.cpp:425] ReLU58 <- Convolution42
I0816 16:04:00.926975 20404 net.cpp:386] ReLU58 -> Convolution42 (in-place)
I0816 16:04:00.927012 20404 net.cpp:141] Setting up ReLU58
I0816 16:04:00.927026 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.927032 20404 net.cpp:156] Memory required for data: 1328336800
I0816 16:04:00.927038 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:00.927048 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:00.927054 20404 net.cpp:425] norm2 <- Convolution42
I0816 16:04:00.927067 20404 net.cpp:399] norm2 -> LRN18
I0816 16:04:00.927132 20404 net.cpp:141] Setting up norm2
I0816 16:04:00.927145 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:00.927152 20404 net.cpp:156] Memory required for data: 1334890400
I0816 16:04:00.927158 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:00.927175 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:00.927181 20404 net.cpp:425] pool2 <- LRN18
I0816 16:04:00.927192 20404 net.cpp:399] pool2 -> Pooling26
I0816 16:04:00.927254 20404 net.cpp:141] Setting up pool2
I0816 16:04:00.927268 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:00.927278 20404 net.cpp:156] Memory required for data: 1336528800
I0816 16:04:00.927284 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:00.927316 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:00.927323 20404 net.cpp:425] conv3 <- Pooling26
I0816 16:04:00.927335 20404 net.cpp:399] conv3 -> Convolution43
I0816 16:04:00.971207 20404 net.cpp:141] Setting up conv3
I0816 16:04:00.971246 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.971252 20404 net.cpp:156] Memory required for data: 1338986400
I0816 16:04:00.971266 20404 layer_factory.hpp:77] Creating layer ReLU59
I0816 16:04:00.971283 20404 net.cpp:91] Creating Layer ReLU59
I0816 16:04:00.971302 20404 net.cpp:425] ReLU59 <- Convolution43
I0816 16:04:00.971313 20404 net.cpp:386] ReLU59 -> Convolution43 (in-place)
I0816 16:04:00.971326 20404 net.cpp:141] Setting up ReLU59
I0816 16:04:00.971334 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:00.971339 20404 net.cpp:156] Memory required for data: 1341444000
I0816 16:04:00.971345 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:00.971361 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:00.971369 20404 net.cpp:425] conv4 <- Convolution43
I0816 16:04:00.971380 20404 net.cpp:399] conv4 -> Convolution44
I0816 16:04:01.004613 20404 net.cpp:141] Setting up conv4
I0816 16:04:01.004650 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.004657 20404 net.cpp:156] Memory required for data: 1343901600
I0816 16:04:01.004668 20404 layer_factory.hpp:77] Creating layer ReLU60
I0816 16:04:01.004681 20404 net.cpp:91] Creating Layer ReLU60
I0816 16:04:01.004689 20404 net.cpp:425] ReLU60 <- Convolution44
I0816 16:04:01.004719 20404 net.cpp:386] ReLU60 -> Convolution44 (in-place)
I0816 16:04:01.004731 20404 net.cpp:141] Setting up ReLU60
I0816 16:04:01.004739 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.004745 20404 net.cpp:156] Memory required for data: 1346359200
I0816 16:04:01.004751 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:01.004766 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:01.004812 20404 net.cpp:425] conv5 <- Convolution44
I0816 16:04:01.004830 20404 net.cpp:399] conv5 -> Convolution45
I0816 16:04:01.027124 20404 net.cpp:141] Setting up conv5
I0816 16:04:01.027158 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.027164 20404 net.cpp:156] Memory required for data: 1347997600
I0816 16:04:01.027175 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:01.027187 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:01.027195 20404 net.cpp:425] pool5 <- Convolution45
I0816 16:04:01.027220 20404 net.cpp:399] pool5 -> Pooling27
I0816 16:04:01.027298 20404 net.cpp:141] Setting up pool5
I0816 16:04:01.027312 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:01.027320 20404 net.cpp:156] Memory required for data: 1348407200
I0816 16:04:01.027328 20404 layer_factory.hpp:77] Creating layer InnerProduct25
I0816 16:04:01.027379 20404 net.cpp:91] Creating Layer InnerProduct25
I0816 16:04:01.027390 20404 net.cpp:425] InnerProduct25 <- Pooling27
I0816 16:04:01.027403 20404 net.cpp:399] InnerProduct25 -> InnerProduct25
I0816 16:04:01.030200 20404 net.cpp:141] Setting up InnerProduct25
I0816 16:04:01.030226 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.030232 20404 net.cpp:156] Memory required for data: 1348509600
I0816 16:04:01.030241 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:01.030248 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:01.030256 20404 layer_factory.hpp:77] Creating layer ReLU61
I0816 16:04:01.030264 20404 net.cpp:91] Creating Layer ReLU61
I0816 16:04:01.030272 20404 net.cpp:425] ReLU61 <- InnerProduct25
I0816 16:04:01.030283 20404 net.cpp:386] ReLU61 -> InnerProduct25 (in-place)
I0816 16:04:01.030294 20404 net.cpp:141] Setting up ReLU61
I0816 16:04:01.030303 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.030308 20404 net.cpp:156] Memory required for data: 1348612000
I0816 16:04:01.030313 20404 layer_factory.hpp:77] Creating layer InnerProduct26
I0816 16:04:01.030325 20404 net.cpp:91] Creating Layer InnerProduct26
I0816 16:04:01.030357 20404 net.cpp:425] InnerProduct26 <- InnerProduct25
I0816 16:04:01.030374 20404 net.cpp:399] InnerProduct26 -> InnerProduct26
I0816 16:04:01.031090 20404 net.cpp:141] Setting up InnerProduct26
I0816 16:04:01.031110 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.031116 20404 net.cpp:156] Memory required for data: 1348714400
I0816 16:04:01.031123 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:01.031132 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:01.031139 20404 layer_factory.hpp:77] Creating layer ReLU62
I0816 16:04:01.031150 20404 net.cpp:91] Creating Layer ReLU62
I0816 16:04:01.031159 20404 net.cpp:425] ReLU62 <- InnerProduct26
I0816 16:04:01.031179 20404 net.cpp:386] ReLU62 -> InnerProduct26 (in-place)
I0816 16:04:01.031193 20404 net.cpp:141] Setting up ReLU62
I0816 16:04:01.031203 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.031208 20404 net.cpp:156] Memory required for data: 1348816800
I0816 16:04:01.031215 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:01.031235 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:01.031247 20404 net.cpp:425] conv1 <- c24
I0816 16:04:01.031307 20404 net.cpp:399] conv1 -> Convolution46
I0816 16:04:01.033423 20404 net.cpp:141] Setting up conv1
I0816 16:04:01.033440 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.033447 20404 net.cpp:156] Memory required for data: 1358647200
I0816 16:04:01.033458 20404 layer_factory.hpp:77] Creating layer ReLU63
I0816 16:04:01.033471 20404 net.cpp:91] Creating Layer ReLU63
I0816 16:04:01.033478 20404 net.cpp:425] ReLU63 <- Convolution46
I0816 16:04:01.033494 20404 net.cpp:386] ReLU63 -> Convolution46 (in-place)
I0816 16:04:01.033509 20404 net.cpp:141] Setting up ReLU63
I0816 16:04:01.033519 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.033529 20404 net.cpp:156] Memory required for data: 1368477600
I0816 16:04:01.033536 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:01.033550 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:01.033561 20404 net.cpp:425] norm1 <- Convolution46
I0816 16:04:01.033574 20404 net.cpp:399] norm1 -> LRN19
I0816 16:04:01.033637 20404 net.cpp:141] Setting up norm1
I0816 16:04:01.033648 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.033653 20404 net.cpp:156] Memory required for data: 1378308000
I0816 16:04:01.033659 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:01.033675 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:01.033684 20404 net.cpp:425] pool1 <- LRN19
I0816 16:04:01.033694 20404 net.cpp:399] pool1 -> Pooling28
I0816 16:04:01.033762 20404 net.cpp:141] Setting up pool1
I0816 16:04:01.033774 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:01.033779 20404 net.cpp:156] Memory required for data: 1380765600
I0816 16:04:01.033785 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:01.033803 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:01.033814 20404 net.cpp:425] conv2 <- Pooling28
I0816 16:04:01.033830 20404 net.cpp:399] conv2 -> Convolution47
I0816 16:04:01.049598 20404 net.cpp:141] Setting up conv2
I0816 16:04:01.049623 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.049629 20404 net.cpp:156] Memory required for data: 1387319200
I0816 16:04:01.049641 20404 layer_factory.hpp:77] Creating layer ReLU64
I0816 16:04:01.049655 20404 net.cpp:91] Creating Layer ReLU64
I0816 16:04:01.049670 20404 net.cpp:425] ReLU64 <- Convolution47
I0816 16:04:01.049682 20404 net.cpp:386] ReLU64 -> Convolution47 (in-place)
I0816 16:04:01.049697 20404 net.cpp:141] Setting up ReLU64
I0816 16:04:01.049729 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.049741 20404 net.cpp:156] Memory required for data: 1393872800
I0816 16:04:01.049748 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:01.049763 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:01.049772 20404 net.cpp:425] norm2 <- Convolution47
I0816 16:04:01.049804 20404 net.cpp:399] norm2 -> LRN20
I0816 16:04:01.049867 20404 net.cpp:141] Setting up norm2
I0816 16:04:01.049880 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.049888 20404 net.cpp:156] Memory required for data: 1400426400
I0816 16:04:01.049898 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:01.049912 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:01.049921 20404 net.cpp:425] pool2 <- LRN20
I0816 16:04:01.049932 20404 net.cpp:399] pool2 -> Pooling29
I0816 16:04:01.049985 20404 net.cpp:141] Setting up pool2
I0816 16:04:01.049995 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.050001 20404 net.cpp:156] Memory required for data: 1402064800
I0816 16:04:01.050006 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:01.050024 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:01.050031 20404 net.cpp:425] conv3 <- Pooling29
I0816 16:04:01.050045 20404 net.cpp:399] conv3 -> Convolution48
I0816 16:04:01.093907 20404 net.cpp:141] Setting up conv3
I0816 16:04:01.093933 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.093940 20404 net.cpp:156] Memory required for data: 1404522400
I0816 16:04:01.093953 20404 layer_factory.hpp:77] Creating layer ReLU65
I0816 16:04:01.093968 20404 net.cpp:91] Creating Layer ReLU65
I0816 16:04:01.093978 20404 net.cpp:425] ReLU65 <- Convolution48
I0816 16:04:01.093988 20404 net.cpp:386] ReLU65 -> Convolution48 (in-place)
I0816 16:04:01.094002 20404 net.cpp:141] Setting up ReLU65
I0816 16:04:01.094009 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.094014 20404 net.cpp:156] Memory required for data: 1406980000
I0816 16:04:01.094020 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:01.094036 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:01.094043 20404 net.cpp:425] conv4 <- Convolution48
I0816 16:04:01.094055 20404 net.cpp:399] conv4 -> Convolution49
I0816 16:04:01.127369 20404 net.cpp:141] Setting up conv4
I0816 16:04:01.127408 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.127415 20404 net.cpp:156] Memory required for data: 1409437600
I0816 16:04:01.127429 20404 layer_factory.hpp:77] Creating layer ReLU66
I0816 16:04:01.127440 20404 net.cpp:91] Creating Layer ReLU66
I0816 16:04:01.127486 20404 net.cpp:425] ReLU66 <- Convolution49
I0816 16:04:01.127504 20404 net.cpp:386] ReLU66 -> Convolution49 (in-place)
I0816 16:04:01.127522 20404 net.cpp:141] Setting up ReLU66
I0816 16:04:01.127535 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.127542 20404 net.cpp:156] Memory required for data: 1411895200
I0816 16:04:01.127548 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:01.127568 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:01.127617 20404 net.cpp:425] conv5 <- Convolution49
I0816 16:04:01.127635 20404 net.cpp:399] conv5 -> Convolution50
I0816 16:04:01.150038 20404 net.cpp:141] Setting up conv5
I0816 16:04:01.150074 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.150080 20404 net.cpp:156] Memory required for data: 1413533600
I0816 16:04:01.150092 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:01.150105 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:01.150115 20404 net.cpp:425] pool5 <- Convolution50
I0816 16:04:01.150140 20404 net.cpp:399] pool5 -> Pooling30
I0816 16:04:01.150204 20404 net.cpp:141] Setting up pool5
I0816 16:04:01.150218 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:01.150225 20404 net.cpp:156] Memory required for data: 1413943200
I0816 16:04:01.150233 20404 layer_factory.hpp:77] Creating layer InnerProduct27
I0816 16:04:01.150256 20404 net.cpp:91] Creating Layer InnerProduct27
I0816 16:04:01.150267 20404 net.cpp:425] InnerProduct27 <- Pooling30
I0816 16:04:01.150284 20404 net.cpp:399] InnerProduct27 -> InnerProduct27
I0816 16:04:01.153203 20404 net.cpp:141] Setting up InnerProduct27
I0816 16:04:01.153228 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.153236 20404 net.cpp:156] Memory required for data: 1414045600
I0816 16:04:01.153269 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:01.153281 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:01.153291 20404 layer_factory.hpp:77] Creating layer ReLU67
I0816 16:04:01.153304 20404 net.cpp:91] Creating Layer ReLU67
I0816 16:04:01.153317 20404 net.cpp:425] ReLU67 <- InnerProduct27
I0816 16:04:01.153337 20404 net.cpp:386] ReLU67 -> InnerProduct27 (in-place)
I0816 16:04:01.153355 20404 net.cpp:141] Setting up ReLU67
I0816 16:04:01.153370 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.153379 20404 net.cpp:156] Memory required for data: 1414148000
I0816 16:04:01.153389 20404 layer_factory.hpp:77] Creating layer InnerProduct28
I0816 16:04:01.153403 20404 net.cpp:91] Creating Layer InnerProduct28
I0816 16:04:01.153415 20404 net.cpp:425] InnerProduct28 <- InnerProduct27
I0816 16:04:01.153431 20404 net.cpp:399] InnerProduct28 -> InnerProduct28
I0816 16:04:01.154105 20404 net.cpp:141] Setting up InnerProduct28
I0816 16:04:01.154119 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.154126 20404 net.cpp:156] Memory required for data: 1414250400
I0816 16:04:01.154137 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:01.154147 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:01.154155 20404 layer_factory.hpp:77] Creating layer ReLU68
I0816 16:04:01.154166 20404 net.cpp:91] Creating Layer ReLU68
I0816 16:04:01.154206 20404 net.cpp:425] ReLU68 <- InnerProduct28
I0816 16:04:01.154222 20404 net.cpp:386] ReLU68 -> InnerProduct28 (in-place)
I0816 16:04:01.154234 20404 net.cpp:141] Setting up ReLU68
I0816 16:04:01.154247 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.154254 20404 net.cpp:156] Memory required for data: 1414352800
I0816 16:04:01.154265 20404 layer_factory.hpp:77] Creating layer Concat5
I0816 16:04:01.154276 20404 net.cpp:91] Creating Layer Concat5
I0816 16:04:01.154284 20404 net.cpp:425] Concat5 <- InnerProduct26
I0816 16:04:01.154294 20404 net.cpp:425] Concat5 <- InnerProduct28
I0816 16:04:01.154311 20404 net.cpp:399] Concat5 -> Concat5
I0816 16:04:01.154357 20404 net.cpp:141] Setting up Concat5
I0816 16:04:01.154371 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:01.154381 20404 net.cpp:156] Memory required for data: 1414557600
I0816 16:04:01.154388 20404 layer_factory.hpp:77] Creating layer InnerProduct29
I0816 16:04:01.154399 20404 net.cpp:91] Creating Layer InnerProduct29
I0816 16:04:01.154410 20404 net.cpp:425] InnerProduct29 <- Concat5
I0816 16:04:01.154428 20404 net.cpp:399] InnerProduct29 -> InnerProduct29
I0816 16:04:01.155608 20404 net.cpp:141] Setting up InnerProduct29
I0816 16:04:01.155623 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.155629 20404 net.cpp:156] Memory required for data: 1414660000
I0816 16:04:01.155637 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:01.155643 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:01.155650 20404 layer_factory.hpp:77] Creating layer ReLU69
I0816 16:04:01.155663 20404 net.cpp:91] Creating Layer ReLU69
I0816 16:04:01.155671 20404 net.cpp:425] ReLU69 <- InnerProduct29
I0816 16:04:01.155683 20404 net.cpp:386] ReLU69 -> InnerProduct29 (in-place)
I0816 16:04:01.155696 20404 net.cpp:141] Setting up ReLU69
I0816 16:04:01.155733 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.155743 20404 net.cpp:156] Memory required for data: 1414762400
I0816 16:04:01.155751 20404 layer_factory.hpp:77] Creating layer InnerProduct30
I0816 16:04:01.155766 20404 net.cpp:91] Creating Layer InnerProduct30
I0816 16:04:01.155777 20404 net.cpp:425] InnerProduct30 <- InnerProduct29
I0816 16:04:01.155792 20404 net.cpp:399] InnerProduct30 -> InnerProduct30
I0816 16:04:01.156203 20404 net.cpp:141] Setting up InnerProduct30
I0816 16:04:01.156213 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:01.156234 20404 net.cpp:156] Memory required for data: 1414813600
I0816 16:04:01.156240 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:01.156249 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:01.156255 20404 layer_factory.hpp:77] Creating layer ReLU70
I0816 16:04:01.156262 20404 net.cpp:91] Creating Layer ReLU70
I0816 16:04:01.156271 20404 net.cpp:425] ReLU70 <- InnerProduct30
I0816 16:04:01.156280 20404 net.cpp:386] ReLU70 -> InnerProduct30 (in-place)
I0816 16:04:01.156289 20404 net.cpp:141] Setting up ReLU70
I0816 16:04:01.156299 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:01.156306 20404 net.cpp:156] Memory required for data: 1414864800
I0816 16:04:01.156311 20404 layer_factory.hpp:77] Creating layer dt4
I0816 16:04:01.156391 20404 net.cpp:91] Creating Layer dt4
I0816 16:04:01.156400 20404 net.cpp:425] dt4 <- InnerProduct30
I0816 16:04:01.156411 20404 net.cpp:399] dt4 -> dt4
I0816 16:04:01.156555 20404 net.cpp:141] Setting up dt4
I0816 16:04:01.156568 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:01.156574 20404 net.cpp:156] Memory required for data: 1414865200
I0816 16:04:01.156579 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:01.156589 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:01.156596 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:01.156610 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:01.156617 20404 net.cpp:425] conv1 <- p1_p1_0_split_5
I0816 16:04:01.156631 20404 net.cpp:399] conv1 -> Convolution51
I0816 16:04:01.159317 20404 net.cpp:141] Setting up conv1
I0816 16:04:01.159334 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.159340 20404 net.cpp:156] Memory required for data: 1424695600
I0816 16:04:01.159353 20404 layer_factory.hpp:77] Creating layer ReLU71
I0816 16:04:01.159361 20404 net.cpp:91] Creating Layer ReLU71
I0816 16:04:01.159371 20404 net.cpp:425] ReLU71 <- Convolution51
I0816 16:04:01.159381 20404 net.cpp:386] ReLU71 -> Convolution51 (in-place)
I0816 16:04:01.159391 20404 net.cpp:141] Setting up ReLU71
I0816 16:04:01.159401 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.159407 20404 net.cpp:156] Memory required for data: 1434526000
I0816 16:04:01.159413 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:01.159425 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:01.159432 20404 net.cpp:425] norm1 <- Convolution51
I0816 16:04:01.159442 20404 net.cpp:399] norm1 -> LRN21
I0816 16:04:01.159492 20404 net.cpp:141] Setting up norm1
I0816 16:04:01.159502 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.159507 20404 net.cpp:156] Memory required for data: 1444356400
I0816 16:04:01.159512 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:01.159521 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:01.159530 20404 net.cpp:425] pool1 <- LRN21
I0816 16:04:01.159541 20404 net.cpp:399] pool1 -> Pooling31
I0816 16:04:01.159596 20404 net.cpp:141] Setting up pool1
I0816 16:04:01.159606 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:01.159611 20404 net.cpp:156] Memory required for data: 1446814000
I0816 16:04:01.159617 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:01.159636 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:01.159643 20404 net.cpp:425] conv2 <- Pooling31
I0816 16:04:01.159654 20404 net.cpp:399] conv2 -> Convolution52
I0816 16:04:01.175331 20404 net.cpp:141] Setting up conv2
I0816 16:04:01.175354 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.175362 20404 net.cpp:156] Memory required for data: 1453367600
I0816 16:04:01.175377 20404 layer_factory.hpp:77] Creating layer ReLU72
I0816 16:04:01.175393 20404 net.cpp:91] Creating Layer ReLU72
I0816 16:04:01.175403 20404 net.cpp:425] ReLU72 <- Convolution52
I0816 16:04:01.175418 20404 net.cpp:386] ReLU72 -> Convolution52 (in-place)
I0816 16:04:01.175434 20404 net.cpp:141] Setting up ReLU72
I0816 16:04:01.175462 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.175472 20404 net.cpp:156] Memory required for data: 1459921200
I0816 16:04:01.175482 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:01.175504 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:01.175516 20404 net.cpp:425] norm2 <- Convolution52
I0816 16:04:01.175531 20404 net.cpp:399] norm2 -> LRN22
I0816 16:04:01.175597 20404 net.cpp:141] Setting up norm2
I0816 16:04:01.175611 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.175619 20404 net.cpp:156] Memory required for data: 1466474800
I0816 16:04:01.175628 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:01.175642 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:01.175653 20404 net.cpp:425] pool2 <- LRN22
I0816 16:04:01.175664 20404 net.cpp:399] pool2 -> Pooling32
I0816 16:04:01.175726 20404 net.cpp:141] Setting up pool2
I0816 16:04:01.175740 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.175768 20404 net.cpp:156] Memory required for data: 1468113200
I0816 16:04:01.175778 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:01.175797 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:01.175807 20404 net.cpp:425] conv3 <- Pooling32
I0816 16:04:01.175861 20404 net.cpp:399] conv3 -> Convolution53
I0816 16:04:01.220285 20404 net.cpp:141] Setting up conv3
I0816 16:04:01.220320 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.220329 20404 net.cpp:156] Memory required for data: 1470570800
I0816 16:04:01.220357 20404 layer_factory.hpp:77] Creating layer ReLU73
I0816 16:04:01.220398 20404 net.cpp:91] Creating Layer ReLU73
I0816 16:04:01.220440 20404 net.cpp:425] ReLU73 <- Convolution53
I0816 16:04:01.220479 20404 net.cpp:386] ReLU73 -> Convolution53 (in-place)
I0816 16:04:01.220520 20404 net.cpp:141] Setting up ReLU73
I0816 16:04:01.220535 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.220542 20404 net.cpp:156] Memory required for data: 1473028400
I0816 16:04:01.220548 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:01.220566 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:01.220573 20404 net.cpp:425] conv4 <- Convolution53
I0816 16:04:01.220584 20404 net.cpp:399] conv4 -> Convolution54
I0816 16:04:01.254035 20404 net.cpp:141] Setting up conv4
I0816 16:04:01.254065 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.254071 20404 net.cpp:156] Memory required for data: 1475486000
I0816 16:04:01.254086 20404 layer_factory.hpp:77] Creating layer ReLU74
I0816 16:04:01.254101 20404 net.cpp:91] Creating Layer ReLU74
I0816 16:04:01.254117 20404 net.cpp:425] ReLU74 <- Convolution54
I0816 16:04:01.254130 20404 net.cpp:386] ReLU74 -> Convolution54 (in-place)
I0816 16:04:01.254148 20404 net.cpp:141] Setting up ReLU74
I0816 16:04:01.254159 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.254191 20404 net.cpp:156] Memory required for data: 1477943600
I0816 16:04:01.254204 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:01.254225 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:01.254237 20404 net.cpp:425] conv5 <- Convolution54
I0816 16:04:01.254256 20404 net.cpp:399] conv5 -> Convolution55
I0816 16:04:01.276957 20404 net.cpp:141] Setting up conv5
I0816 16:04:01.276986 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.276994 20404 net.cpp:156] Memory required for data: 1479582000
I0816 16:04:01.277014 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:01.277036 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:01.277050 20404 net.cpp:425] pool5 <- Convolution55
I0816 16:04:01.277079 20404 net.cpp:399] pool5 -> Pooling33
I0816 16:04:01.277168 20404 net.cpp:141] Setting up pool5
I0816 16:04:01.277182 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:01.277190 20404 net.cpp:156] Memory required for data: 1479991600
I0816 16:04:01.277199 20404 layer_factory.hpp:77] Creating layer InnerProduct31
I0816 16:04:01.277216 20404 net.cpp:91] Creating Layer InnerProduct31
I0816 16:04:01.277248 20404 net.cpp:425] InnerProduct31 <- Pooling33
I0816 16:04:01.277263 20404 net.cpp:399] InnerProduct31 -> InnerProduct31
I0816 16:04:01.280097 20404 net.cpp:141] Setting up InnerProduct31
I0816 16:04:01.280117 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.280125 20404 net.cpp:156] Memory required for data: 1480094000
I0816 16:04:01.280135 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:01.280146 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:01.280154 20404 layer_factory.hpp:77] Creating layer ReLU75
I0816 16:04:01.280169 20404 net.cpp:91] Creating Layer ReLU75
I0816 16:04:01.280179 20404 net.cpp:425] ReLU75 <- InnerProduct31
I0816 16:04:01.280190 20404 net.cpp:386] ReLU75 -> InnerProduct31 (in-place)
I0816 16:04:01.280205 20404 net.cpp:141] Setting up ReLU75
I0816 16:04:01.280215 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.280223 20404 net.cpp:156] Memory required for data: 1480196400
I0816 16:04:01.280230 20404 layer_factory.hpp:77] Creating layer InnerProduct32
I0816 16:04:01.280246 20404 net.cpp:91] Creating Layer InnerProduct32
I0816 16:04:01.280254 20404 net.cpp:425] InnerProduct32 <- InnerProduct31
I0816 16:04:01.280267 20404 net.cpp:399] InnerProduct32 -> InnerProduct32
I0816 16:04:01.280936 20404 net.cpp:141] Setting up InnerProduct32
I0816 16:04:01.280951 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.280958 20404 net.cpp:156] Memory required for data: 1480298800
I0816 16:04:01.280966 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:01.280977 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:01.280984 20404 layer_factory.hpp:77] Creating layer ReLU76
I0816 16:04:01.280995 20404 net.cpp:91] Creating Layer ReLU76
I0816 16:04:01.281003 20404 net.cpp:425] ReLU76 <- InnerProduct32
I0816 16:04:01.281014 20404 net.cpp:386] ReLU76 -> InnerProduct32 (in-place)
I0816 16:04:01.281026 20404 net.cpp:141] Setting up ReLU76
I0816 16:04:01.281036 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.281044 20404 net.cpp:156] Memory required for data: 1480401200
I0816 16:04:01.281051 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:01.281075 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:01.281085 20404 net.cpp:425] conv1 <- c25
I0816 16:04:01.281100 20404 net.cpp:399] conv1 -> Convolution56
I0816 16:04:01.283138 20404 net.cpp:141] Setting up conv1
I0816 16:04:01.283152 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.283159 20404 net.cpp:156] Memory required for data: 1490231600
I0816 16:04:01.283171 20404 layer_factory.hpp:77] Creating layer ReLU77
I0816 16:04:01.283182 20404 net.cpp:91] Creating Layer ReLU77
I0816 16:04:01.283196 20404 net.cpp:425] ReLU77 <- Convolution56
I0816 16:04:01.283207 20404 net.cpp:386] ReLU77 -> Convolution56 (in-place)
I0816 16:04:01.283221 20404 net.cpp:141] Setting up ReLU77
I0816 16:04:01.283231 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.283238 20404 net.cpp:156] Memory required for data: 1500062000
I0816 16:04:01.283246 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:01.283257 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:01.283265 20404 net.cpp:425] norm1 <- Convolution56
I0816 16:04:01.283293 20404 net.cpp:399] norm1 -> LRN23
I0816 16:04:01.283356 20404 net.cpp:141] Setting up norm1
I0816 16:04:01.283372 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.283380 20404 net.cpp:156] Memory required for data: 1509892400
I0816 16:04:01.283388 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:01.283404 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:01.283413 20404 net.cpp:425] pool1 <- LRN23
I0816 16:04:01.283427 20404 net.cpp:399] pool1 -> Pooling34
I0816 16:04:01.283499 20404 net.cpp:141] Setting up pool1
I0816 16:04:01.283514 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:01.283522 20404 net.cpp:156] Memory required for data: 1512350000
I0816 16:04:01.283551 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:01.283571 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:01.283581 20404 net.cpp:425] conv2 <- Pooling34
I0816 16:04:01.283599 20404 net.cpp:399] conv2 -> Convolution57
I0816 16:04:01.300031 20404 net.cpp:141] Setting up conv2
I0816 16:04:01.300056 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.300065 20404 net.cpp:156] Memory required for data: 1518903600
I0816 16:04:01.300088 20404 layer_factory.hpp:77] Creating layer ReLU78
I0816 16:04:01.300101 20404 net.cpp:91] Creating Layer ReLU78
I0816 16:04:01.300112 20404 net.cpp:425] ReLU78 <- Convolution57
I0816 16:04:01.300122 20404 net.cpp:386] ReLU78 -> Convolution57 (in-place)
I0816 16:04:01.300137 20404 net.cpp:141] Setting up ReLU78
I0816 16:04:01.300154 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.300161 20404 net.cpp:156] Memory required for data: 1525457200
I0816 16:04:01.300169 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:01.300184 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:01.300194 20404 net.cpp:425] norm2 <- Convolution57
I0816 16:04:01.300209 20404 net.cpp:399] norm2 -> LRN24
I0816 16:04:01.300271 20404 net.cpp:141] Setting up norm2
I0816 16:04:01.300284 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.300292 20404 net.cpp:156] Memory required for data: 1532010800
I0816 16:04:01.300299 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:01.300315 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:01.300323 20404 net.cpp:425] pool2 <- LRN24
I0816 16:04:01.300335 20404 net.cpp:399] pool2 -> Pooling35
I0816 16:04:01.300397 20404 net.cpp:141] Setting up pool2
I0816 16:04:01.300410 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.300417 20404 net.cpp:156] Memory required for data: 1533649200
I0816 16:04:01.300426 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:01.300443 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:01.300452 20404 net.cpp:425] conv3 <- Pooling35
I0816 16:04:01.300470 20404 net.cpp:399] conv3 -> Convolution58
I0816 16:04:01.344434 20404 net.cpp:141] Setting up conv3
I0816 16:04:01.344468 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.344487 20404 net.cpp:156] Memory required for data: 1536106800
I0816 16:04:01.344504 20404 layer_factory.hpp:77] Creating layer ReLU79
I0816 16:04:01.344522 20404 net.cpp:91] Creating Layer ReLU79
I0816 16:04:01.344533 20404 net.cpp:425] ReLU79 <- Convolution58
I0816 16:04:01.344555 20404 net.cpp:386] ReLU79 -> Convolution58 (in-place)
I0816 16:04:01.344573 20404 net.cpp:141] Setting up ReLU79
I0816 16:04:01.344583 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.344590 20404 net.cpp:156] Memory required for data: 1538564400
I0816 16:04:01.344599 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:01.344619 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:01.344633 20404 net.cpp:425] conv4 <- Convolution58
I0816 16:04:01.344646 20404 net.cpp:399] conv4 -> Convolution59
I0816 16:04:01.378037 20404 net.cpp:141] Setting up conv4
I0816 16:04:01.378070 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.378089 20404 net.cpp:156] Memory required for data: 1541022000
I0816 16:04:01.378106 20404 layer_factory.hpp:77] Creating layer ReLU80
I0816 16:04:01.378120 20404 net.cpp:91] Creating Layer ReLU80
I0816 16:04:01.378131 20404 net.cpp:425] ReLU80 <- Convolution59
I0816 16:04:01.378154 20404 net.cpp:386] ReLU80 -> Convolution59 (in-place)
I0816 16:04:01.378171 20404 net.cpp:141] Setting up ReLU80
I0816 16:04:01.378181 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.378190 20404 net.cpp:156] Memory required for data: 1543479600
I0816 16:04:01.378197 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:01.378217 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:01.378226 20404 net.cpp:425] conv5 <- Convolution59
I0816 16:04:01.378244 20404 net.cpp:399] conv5 -> Convolution60
I0816 16:04:01.400375 20404 net.cpp:141] Setting up conv5
I0816 16:04:01.400400 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.400409 20404 net.cpp:156] Memory required for data: 1545118000
I0816 16:04:01.400439 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:01.400454 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:01.400463 20404 net.cpp:425] pool5 <- Convolution60
I0816 16:04:01.400477 20404 net.cpp:399] pool5 -> Pooling36
I0816 16:04:01.400549 20404 net.cpp:141] Setting up pool5
I0816 16:04:01.400564 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:01.400573 20404 net.cpp:156] Memory required for data: 1545527600
I0816 16:04:01.400579 20404 layer_factory.hpp:77] Creating layer InnerProduct33
I0816 16:04:01.400596 20404 net.cpp:91] Creating Layer InnerProduct33
I0816 16:04:01.400605 20404 net.cpp:425] InnerProduct33 <- Pooling36
I0816 16:04:01.400619 20404 net.cpp:399] InnerProduct33 -> InnerProduct33
I0816 16:04:01.403411 20404 net.cpp:141] Setting up InnerProduct33
I0816 16:04:01.403432 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.403440 20404 net.cpp:156] Memory required for data: 1545630000
I0816 16:04:01.403450 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:01.403461 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:01.403470 20404 layer_factory.hpp:77] Creating layer ReLU81
I0816 16:04:01.403481 20404 net.cpp:91] Creating Layer ReLU81
I0816 16:04:01.403489 20404 net.cpp:425] ReLU81 <- InnerProduct33
I0816 16:04:01.403501 20404 net.cpp:386] ReLU81 -> InnerProduct33 (in-place)
I0816 16:04:01.403515 20404 net.cpp:141] Setting up ReLU81
I0816 16:04:01.403525 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.403532 20404 net.cpp:156] Memory required for data: 1545732400
I0816 16:04:01.403540 20404 layer_factory.hpp:77] Creating layer InnerProduct34
I0816 16:04:01.403556 20404 net.cpp:91] Creating Layer InnerProduct34
I0816 16:04:01.403564 20404 net.cpp:425] InnerProduct34 <- InnerProduct33
I0816 16:04:01.403578 20404 net.cpp:399] InnerProduct34 -> InnerProduct34
I0816 16:04:01.404248 20404 net.cpp:141] Setting up InnerProduct34
I0816 16:04:01.404263 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.404270 20404 net.cpp:156] Memory required for data: 1545834800
I0816 16:04:01.404279 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:01.404289 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:01.404296 20404 layer_factory.hpp:77] Creating layer ReLU82
I0816 16:04:01.404306 20404 net.cpp:91] Creating Layer ReLU82
I0816 16:04:01.404314 20404 net.cpp:425] ReLU82 <- InnerProduct34
I0816 16:04:01.404325 20404 net.cpp:386] ReLU82 -> InnerProduct34 (in-place)
I0816 16:04:01.404337 20404 net.cpp:141] Setting up ReLU82
I0816 16:04:01.404347 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.404356 20404 net.cpp:156] Memory required for data: 1545937200
I0816 16:04:01.404363 20404 layer_factory.hpp:77] Creating layer Concat6
I0816 16:04:01.404374 20404 net.cpp:91] Creating Layer Concat6
I0816 16:04:01.404382 20404 net.cpp:425] Concat6 <- InnerProduct32
I0816 16:04:01.404392 20404 net.cpp:425] Concat6 <- InnerProduct34
I0816 16:04:01.404405 20404 net.cpp:399] Concat6 -> Concat6
I0816 16:04:01.404449 20404 net.cpp:141] Setting up Concat6
I0816 16:04:01.404464 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:01.404470 20404 net.cpp:156] Memory required for data: 1546142000
I0816 16:04:01.404479 20404 layer_factory.hpp:77] Creating layer InnerProduct35
I0816 16:04:01.404492 20404 net.cpp:91] Creating Layer InnerProduct35
I0816 16:04:01.404500 20404 net.cpp:425] InnerProduct35 <- Concat6
I0816 16:04:01.404513 20404 net.cpp:399] InnerProduct35 -> InnerProduct35
I0816 16:04:01.406273 20404 net.cpp:141] Setting up InnerProduct35
I0816 16:04:01.406294 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.406302 20404 net.cpp:156] Memory required for data: 1546244400
I0816 16:04:01.406328 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:01.406338 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:01.406347 20404 layer_factory.hpp:77] Creating layer ReLU83
I0816 16:04:01.406361 20404 net.cpp:91] Creating Layer ReLU83
I0816 16:04:01.406371 20404 net.cpp:425] ReLU83 <- InnerProduct35
I0816 16:04:01.406383 20404 net.cpp:386] ReLU83 -> InnerProduct35 (in-place)
I0816 16:04:01.406396 20404 net.cpp:141] Setting up ReLU83
I0816 16:04:01.406406 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.406414 20404 net.cpp:156] Memory required for data: 1546346800
I0816 16:04:01.406420 20404 layer_factory.hpp:77] Creating layer InnerProduct36
I0816 16:04:01.406436 20404 net.cpp:91] Creating Layer InnerProduct36
I0816 16:04:01.406445 20404 net.cpp:425] InnerProduct36 <- InnerProduct35
I0816 16:04:01.406457 20404 net.cpp:399] InnerProduct36 -> InnerProduct36
I0816 16:04:01.406872 20404 net.cpp:141] Setting up InnerProduct36
I0816 16:04:01.406885 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:01.406893 20404 net.cpp:156] Memory required for data: 1546398000
I0816 16:04:01.406901 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:01.406910 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:01.406919 20404 layer_factory.hpp:77] Creating layer ReLU84
I0816 16:04:01.406929 20404 net.cpp:91] Creating Layer ReLU84
I0816 16:04:01.406937 20404 net.cpp:425] ReLU84 <- InnerProduct36
I0816 16:04:01.406947 20404 net.cpp:386] ReLU84 -> InnerProduct36 (in-place)
I0816 16:04:01.406960 20404 net.cpp:141] Setting up ReLU84
I0816 16:04:01.406970 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:01.406977 20404 net.cpp:156] Memory required for data: 1546449200
I0816 16:04:01.406985 20404 layer_factory.hpp:77] Creating layer dt5
I0816 16:04:01.406999 20404 net.cpp:91] Creating Layer dt5
I0816 16:04:01.407007 20404 net.cpp:425] dt5 <- InnerProduct36
I0816 16:04:01.407024 20404 net.cpp:399] dt5 -> dt5
I0816 16:04:01.407177 20404 net.cpp:141] Setting up dt5
I0816 16:04:01.407192 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:01.407199 20404 net.cpp:156] Memory required for data: 1546449600
I0816 16:04:01.407207 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:01.407217 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:01.407224 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:01.407240 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:01.407248 20404 net.cpp:425] conv1 <- p1_p1_0_split_6
I0816 16:04:01.407268 20404 net.cpp:399] conv1 -> Convolution61
I0816 16:04:01.409987 20404 net.cpp:141] Setting up conv1
I0816 16:04:01.410009 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.410017 20404 net.cpp:156] Memory required for data: 1556280000
I0816 16:04:01.410032 20404 layer_factory.hpp:77] Creating layer ReLU85
I0816 16:04:01.410048 20404 net.cpp:91] Creating Layer ReLU85
I0816 16:04:01.410058 20404 net.cpp:425] ReLU85 <- Convolution61
I0816 16:04:01.410069 20404 net.cpp:386] ReLU85 -> Convolution61 (in-place)
I0816 16:04:01.410084 20404 net.cpp:141] Setting up ReLU85
I0816 16:04:01.410094 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.410101 20404 net.cpp:156] Memory required for data: 1566110400
I0816 16:04:01.410109 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:01.410123 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:01.410132 20404 net.cpp:425] norm1 <- Convolution61
I0816 16:04:01.410145 20404 net.cpp:399] norm1 -> LRN25
I0816 16:04:01.410266 20404 net.cpp:141] Setting up norm1
I0816 16:04:01.410284 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.410292 20404 net.cpp:156] Memory required for data: 1575940800
I0816 16:04:01.410300 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:01.410336 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:01.410343 20404 net.cpp:425] pool1 <- LRN25
I0816 16:04:01.410356 20404 net.cpp:399] pool1 -> Pooling37
I0816 16:04:01.410420 20404 net.cpp:141] Setting up pool1
I0816 16:04:01.410434 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:01.410441 20404 net.cpp:156] Memory required for data: 1578398400
I0816 16:04:01.410449 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:01.410468 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:01.410476 20404 net.cpp:425] conv2 <- Pooling37
I0816 16:04:01.410492 20404 net.cpp:399] conv2 -> Convolution62
I0816 16:04:01.426141 20404 net.cpp:141] Setting up conv2
I0816 16:04:01.426163 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.426172 20404 net.cpp:156] Memory required for data: 1584952000
I0816 16:04:01.426190 20404 layer_factory.hpp:77] Creating layer ReLU86
I0816 16:04:01.426206 20404 net.cpp:91] Creating Layer ReLU86
I0816 16:04:01.426216 20404 net.cpp:425] ReLU86 <- Convolution62
I0816 16:04:01.426228 20404 net.cpp:386] ReLU86 -> Convolution62 (in-place)
I0816 16:04:01.426242 20404 net.cpp:141] Setting up ReLU86
I0816 16:04:01.426252 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.426260 20404 net.cpp:156] Memory required for data: 1591505600
I0816 16:04:01.426268 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:01.426280 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:01.426287 20404 net.cpp:425] norm2 <- Convolution62
I0816 16:04:01.426303 20404 net.cpp:399] norm2 -> LRN26
I0816 16:04:01.426365 20404 net.cpp:141] Setting up norm2
I0816 16:04:01.426379 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.426388 20404 net.cpp:156] Memory required for data: 1598059200
I0816 16:04:01.426394 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:01.426409 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:01.426417 20404 net.cpp:425] pool2 <- LRN26
I0816 16:04:01.426431 20404 net.cpp:399] pool2 -> Pooling38
I0816 16:04:01.426492 20404 net.cpp:141] Setting up pool2
I0816 16:04:01.426506 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.426513 20404 net.cpp:156] Memory required for data: 1599697600
I0816 16:04:01.426522 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:01.426540 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:01.426553 20404 net.cpp:425] conv3 <- Pooling38
I0816 16:04:01.426570 20404 net.cpp:399] conv3 -> Convolution63
I0816 16:04:01.470568 20404 net.cpp:141] Setting up conv3
I0816 16:04:01.470643 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.470672 20404 net.cpp:156] Memory required for data: 1602155200
I0816 16:04:01.470693 20404 layer_factory.hpp:77] Creating layer ReLU87
I0816 16:04:01.470712 20404 net.cpp:91] Creating Layer ReLU87
I0816 16:04:01.470731 20404 net.cpp:425] ReLU87 <- Convolution63
I0816 16:04:01.470743 20404 net.cpp:386] ReLU87 -> Convolution63 (in-place)
I0816 16:04:01.470759 20404 net.cpp:141] Setting up ReLU87
I0816 16:04:01.470772 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.470780 20404 net.cpp:156] Memory required for data: 1604612800
I0816 16:04:01.470788 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:01.470809 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:01.470823 20404 net.cpp:425] conv4 <- Convolution63
I0816 16:04:01.470839 20404 net.cpp:399] conv4 -> Convolution64
I0816 16:04:01.503960 20404 net.cpp:141] Setting up conv4
I0816 16:04:01.503990 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.503999 20404 net.cpp:156] Memory required for data: 1607070400
I0816 16:04:01.504015 20404 layer_factory.hpp:77] Creating layer ReLU88
I0816 16:04:01.504029 20404 net.cpp:91] Creating Layer ReLU88
I0816 16:04:01.504040 20404 net.cpp:425] ReLU88 <- Convolution64
I0816 16:04:01.504060 20404 net.cpp:386] ReLU88 -> Convolution64 (in-place)
I0816 16:04:01.504076 20404 net.cpp:141] Setting up ReLU88
I0816 16:04:01.504087 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.504117 20404 net.cpp:156] Memory required for data: 1609528000
I0816 16:04:01.504125 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:01.504145 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:01.504154 20404 net.cpp:425] conv5 <- Convolution64
I0816 16:04:01.504169 20404 net.cpp:399] conv5 -> Convolution65
I0816 16:04:01.526229 20404 net.cpp:141] Setting up conv5
I0816 16:04:01.526252 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.526262 20404 net.cpp:156] Memory required for data: 1611166400
I0816 16:04:01.526276 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:01.526293 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:01.526302 20404 net.cpp:425] pool5 <- Convolution65
I0816 16:04:01.526319 20404 net.cpp:399] pool5 -> Pooling39
I0816 16:04:01.526386 20404 net.cpp:141] Setting up pool5
I0816 16:04:01.526401 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:01.526407 20404 net.cpp:156] Memory required for data: 1611576000
I0816 16:04:01.526415 20404 layer_factory.hpp:77] Creating layer InnerProduct37
I0816 16:04:01.526432 20404 net.cpp:91] Creating Layer InnerProduct37
I0816 16:04:01.526440 20404 net.cpp:425] InnerProduct37 <- Pooling39
I0816 16:04:01.526456 20404 net.cpp:399] InnerProduct37 -> InnerProduct37
I0816 16:04:01.529203 20404 net.cpp:141] Setting up InnerProduct37
I0816 16:04:01.529223 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.529232 20404 net.cpp:156] Memory required for data: 1611678400
I0816 16:04:01.529242 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:01.529252 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:01.529259 20404 layer_factory.hpp:77] Creating layer ReLU89
I0816 16:04:01.529270 20404 net.cpp:91] Creating Layer ReLU89
I0816 16:04:01.529279 20404 net.cpp:425] ReLU89 <- InnerProduct37
I0816 16:04:01.529291 20404 net.cpp:386] ReLU89 -> InnerProduct37 (in-place)
I0816 16:04:01.529305 20404 net.cpp:141] Setting up ReLU89
I0816 16:04:01.529315 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.529322 20404 net.cpp:156] Memory required for data: 1611780800
I0816 16:04:01.529330 20404 layer_factory.hpp:77] Creating layer InnerProduct38
I0816 16:04:01.529345 20404 net.cpp:91] Creating Layer InnerProduct38
I0816 16:04:01.529353 20404 net.cpp:425] InnerProduct38 <- InnerProduct37
I0816 16:04:01.529369 20404 net.cpp:399] InnerProduct38 -> InnerProduct38
I0816 16:04:01.530042 20404 net.cpp:141] Setting up InnerProduct38
I0816 16:04:01.530057 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.530066 20404 net.cpp:156] Memory required for data: 1611883200
I0816 16:04:01.530074 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:01.530084 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:01.530092 20404 layer_factory.hpp:77] Creating layer ReLU90
I0816 16:04:01.530103 20404 net.cpp:91] Creating Layer ReLU90
I0816 16:04:01.530112 20404 net.cpp:425] ReLU90 <- InnerProduct38
I0816 16:04:01.530122 20404 net.cpp:386] ReLU90 -> InnerProduct38 (in-place)
I0816 16:04:01.530134 20404 net.cpp:141] Setting up ReLU90
I0816 16:04:01.530144 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.530151 20404 net.cpp:156] Memory required for data: 1611985600
I0816 16:04:01.530159 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:01.530179 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:01.530189 20404 net.cpp:425] conv1 <- c26
I0816 16:04:01.530205 20404 net.cpp:399] conv1 -> Convolution66
I0816 16:04:01.532286 20404 net.cpp:141] Setting up conv1
I0816 16:04:01.532304 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.532311 20404 net.cpp:156] Memory required for data: 1621816000
I0816 16:04:01.532325 20404 layer_factory.hpp:77] Creating layer ReLU91
I0816 16:04:01.532341 20404 net.cpp:91] Creating Layer ReLU91
I0816 16:04:01.532351 20404 net.cpp:425] ReLU91 <- Convolution66
I0816 16:04:01.532382 20404 net.cpp:386] ReLU91 -> Convolution66 (in-place)
I0816 16:04:01.532395 20404 net.cpp:141] Setting up ReLU91
I0816 16:04:01.532407 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.532414 20404 net.cpp:156] Memory required for data: 1631646400
I0816 16:04:01.532421 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:01.532435 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:01.532444 20404 net.cpp:425] norm1 <- Convolution66
I0816 16:04:01.532457 20404 net.cpp:399] norm1 -> LRN27
I0816 16:04:01.532517 20404 net.cpp:141] Setting up norm1
I0816 16:04:01.532531 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.532539 20404 net.cpp:156] Memory required for data: 1641476800
I0816 16:04:01.532546 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:01.532557 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:01.532565 20404 net.cpp:425] pool1 <- LRN27
I0816 16:04:01.532577 20404 net.cpp:399] pool1 -> Pooling40
I0816 16:04:01.532642 20404 net.cpp:141] Setting up pool1
I0816 16:04:01.532656 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:01.532665 20404 net.cpp:156] Memory required for data: 1643934400
I0816 16:04:01.532671 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:01.532688 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:01.532699 20404 net.cpp:425] conv2 <- Pooling40
I0816 16:04:01.532712 20404 net.cpp:399] conv2 -> Convolution67
I0816 16:04:01.548235 20404 net.cpp:141] Setting up conv2
I0816 16:04:01.548257 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.548265 20404 net.cpp:156] Memory required for data: 1650488000
I0816 16:04:01.548290 20404 layer_factory.hpp:77] Creating layer ReLU92
I0816 16:04:01.548305 20404 net.cpp:91] Creating Layer ReLU92
I0816 16:04:01.548313 20404 net.cpp:425] ReLU92 <- Convolution67
I0816 16:04:01.548324 20404 net.cpp:386] ReLU92 -> Convolution67 (in-place)
I0816 16:04:01.548338 20404 net.cpp:141] Setting up ReLU92
I0816 16:04:01.548357 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.548364 20404 net.cpp:156] Memory required for data: 1657041600
I0816 16:04:01.548372 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:01.548385 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:01.548394 20404 net.cpp:425] norm2 <- Convolution67
I0816 16:04:01.548406 20404 net.cpp:399] norm2 -> LRN28
I0816 16:04:01.548470 20404 net.cpp:141] Setting up norm2
I0816 16:04:01.548483 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.548491 20404 net.cpp:156] Memory required for data: 1663595200
I0816 16:04:01.548498 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:01.548512 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:01.548521 20404 net.cpp:425] pool2 <- LRN28
I0816 16:04:01.548535 20404 net.cpp:399] pool2 -> Pooling41
I0816 16:04:01.548596 20404 net.cpp:141] Setting up pool2
I0816 16:04:01.548610 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.548617 20404 net.cpp:156] Memory required for data: 1665233600
I0816 16:04:01.548624 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:01.548645 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:01.548652 20404 net.cpp:425] conv3 <- Pooling41
I0816 16:04:01.548671 20404 net.cpp:399] conv3 -> Convolution68
I0816 16:04:01.592870 20404 net.cpp:141] Setting up conv3
I0816 16:04:01.592905 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.592923 20404 net.cpp:156] Memory required for data: 1667691200
I0816 16:04:01.592938 20404 layer_factory.hpp:77] Creating layer ReLU93
I0816 16:04:01.592957 20404 net.cpp:91] Creating Layer ReLU93
I0816 16:04:01.592970 20404 net.cpp:425] ReLU93 <- Convolution68
I0816 16:04:01.592993 20404 net.cpp:386] ReLU93 -> Convolution68 (in-place)
I0816 16:04:01.593008 20404 net.cpp:141] Setting up ReLU93
I0816 16:04:01.593019 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.593026 20404 net.cpp:156] Memory required for data: 1670148800
I0816 16:04:01.593034 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:01.593075 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:01.593083 20404 net.cpp:425] conv4 <- Convolution68
I0816 16:04:01.593102 20404 net.cpp:399] conv4 -> Convolution69
I0816 16:04:01.626421 20404 net.cpp:141] Setting up conv4
I0816 16:04:01.626452 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.626461 20404 net.cpp:156] Memory required for data: 1672606400
I0816 16:04:01.626477 20404 layer_factory.hpp:77] Creating layer ReLU94
I0816 16:04:01.626493 20404 net.cpp:91] Creating Layer ReLU94
I0816 16:04:01.626505 20404 net.cpp:425] ReLU94 <- Convolution69
I0816 16:04:01.626528 20404 net.cpp:386] ReLU94 -> Convolution69 (in-place)
I0816 16:04:01.626550 20404 net.cpp:141] Setting up ReLU94
I0816 16:04:01.626564 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.626570 20404 net.cpp:156] Memory required for data: 1675064000
I0816 16:04:01.626579 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:01.626598 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:01.626607 20404 net.cpp:425] conv5 <- Convolution69
I0816 16:04:01.626621 20404 net.cpp:399] conv5 -> Convolution70
I0816 16:04:01.648924 20404 net.cpp:141] Setting up conv5
I0816 16:04:01.648948 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.648957 20404 net.cpp:156] Memory required for data: 1676702400
I0816 16:04:01.648980 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:01.648995 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:01.649004 20404 net.cpp:425] pool5 <- Convolution70
I0816 16:04:01.649022 20404 net.cpp:399] pool5 -> Pooling42
I0816 16:04:01.649101 20404 net.cpp:141] Setting up pool5
I0816 16:04:01.649114 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:01.649121 20404 net.cpp:156] Memory required for data: 1677112000
I0816 16:04:01.649129 20404 layer_factory.hpp:77] Creating layer InnerProduct39
I0816 16:04:01.649147 20404 net.cpp:91] Creating Layer InnerProduct39
I0816 16:04:01.649155 20404 net.cpp:425] InnerProduct39 <- Pooling42
I0816 16:04:01.649173 20404 net.cpp:399] InnerProduct39 -> InnerProduct39
I0816 16:04:01.651917 20404 net.cpp:141] Setting up InnerProduct39
I0816 16:04:01.651937 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.651952 20404 net.cpp:156] Memory required for data: 1677214400
I0816 16:04:01.651962 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:01.651971 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:01.651979 20404 layer_factory.hpp:77] Creating layer ReLU95
I0816 16:04:01.651991 20404 net.cpp:91] Creating Layer ReLU95
I0816 16:04:01.651999 20404 net.cpp:425] ReLU95 <- InnerProduct39
I0816 16:04:01.652024 20404 net.cpp:386] ReLU95 -> InnerProduct39 (in-place)
I0816 16:04:01.652039 20404 net.cpp:141] Setting up ReLU95
I0816 16:04:01.652048 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.652056 20404 net.cpp:156] Memory required for data: 1677316800
I0816 16:04:01.652065 20404 layer_factory.hpp:77] Creating layer InnerProduct40
I0816 16:04:01.652076 20404 net.cpp:91] Creating Layer InnerProduct40
I0816 16:04:01.652084 20404 net.cpp:425] InnerProduct40 <- InnerProduct39
I0816 16:04:01.652101 20404 net.cpp:399] InnerProduct40 -> InnerProduct40
I0816 16:04:01.652776 20404 net.cpp:141] Setting up InnerProduct40
I0816 16:04:01.652791 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.652798 20404 net.cpp:156] Memory required for data: 1677419200
I0816 16:04:01.652807 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:01.652817 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:01.652824 20404 layer_factory.hpp:77] Creating layer ReLU96
I0816 16:04:01.652835 20404 net.cpp:91] Creating Layer ReLU96
I0816 16:04:01.652843 20404 net.cpp:425] ReLU96 <- InnerProduct40
I0816 16:04:01.652855 20404 net.cpp:386] ReLU96 -> InnerProduct40 (in-place)
I0816 16:04:01.652884 20404 net.cpp:141] Setting up ReLU96
I0816 16:04:01.652899 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.652906 20404 net.cpp:156] Memory required for data: 1677521600
I0816 16:04:01.652914 20404 layer_factory.hpp:77] Creating layer Concat7
I0816 16:04:01.652925 20404 net.cpp:91] Creating Layer Concat7
I0816 16:04:01.652933 20404 net.cpp:425] Concat7 <- InnerProduct38
I0816 16:04:01.652943 20404 net.cpp:425] Concat7 <- InnerProduct40
I0816 16:04:01.652959 20404 net.cpp:399] Concat7 -> Concat7
I0816 16:04:01.653000 20404 net.cpp:141] Setting up Concat7
I0816 16:04:01.653017 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:01.653024 20404 net.cpp:156] Memory required for data: 1677726400
I0816 16:04:01.653033 20404 layer_factory.hpp:77] Creating layer InnerProduct41
I0816 16:04:01.653044 20404 net.cpp:91] Creating Layer InnerProduct41
I0816 16:04:01.653053 20404 net.cpp:425] InnerProduct41 <- Concat7
I0816 16:04:01.653069 20404 net.cpp:399] InnerProduct41 -> InnerProduct41
I0816 16:04:01.654297 20404 net.cpp:141] Setting up InnerProduct41
I0816 16:04:01.654345 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.654357 20404 net.cpp:156] Memory required for data: 1677828800
I0816 16:04:01.654368 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:01.654378 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:01.654386 20404 layer_factory.hpp:77] Creating layer ReLU97
I0816 16:04:01.654398 20404 net.cpp:91] Creating Layer ReLU97
I0816 16:04:01.654407 20404 net.cpp:425] ReLU97 <- InnerProduct41
I0816 16:04:01.654418 20404 net.cpp:386] ReLU97 -> InnerProduct41 (in-place)
I0816 16:04:01.654433 20404 net.cpp:141] Setting up ReLU97
I0816 16:04:01.654443 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.654450 20404 net.cpp:156] Memory required for data: 1677931200
I0816 16:04:01.654458 20404 layer_factory.hpp:77] Creating layer InnerProduct42
I0816 16:04:01.654474 20404 net.cpp:91] Creating Layer InnerProduct42
I0816 16:04:01.654482 20404 net.cpp:425] InnerProduct42 <- InnerProduct41
I0816 16:04:01.654497 20404 net.cpp:399] InnerProduct42 -> InnerProduct42
I0816 16:04:01.654912 20404 net.cpp:141] Setting up InnerProduct42
I0816 16:04:01.654927 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:01.654934 20404 net.cpp:156] Memory required for data: 1677982400
I0816 16:04:01.654942 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:01.654952 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:01.654960 20404 layer_factory.hpp:77] Creating layer ReLU98
I0816 16:04:01.654970 20404 net.cpp:91] Creating Layer ReLU98
I0816 16:04:01.654978 20404 net.cpp:425] ReLU98 <- InnerProduct42
I0816 16:04:01.654989 20404 net.cpp:386] ReLU98 -> InnerProduct42 (in-place)
I0816 16:04:01.655001 20404 net.cpp:141] Setting up ReLU98
I0816 16:04:01.655011 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:01.655019 20404 net.cpp:156] Memory required for data: 1678033600
I0816 16:04:01.655026 20404 layer_factory.hpp:77] Creating layer dt6
I0816 16:04:01.655040 20404 net.cpp:91] Creating Layer dt6
I0816 16:04:01.655047 20404 net.cpp:425] dt6 <- InnerProduct42
I0816 16:04:01.655063 20404 net.cpp:399] dt6 -> dt6
I0816 16:04:01.655220 20404 net.cpp:141] Setting up dt6
I0816 16:04:01.655235 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:01.655242 20404 net.cpp:156] Memory required for data: 1678034000
I0816 16:04:01.655251 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:01.655259 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:01.655267 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:01.655293 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:01.655303 20404 net.cpp:425] conv1 <- p1_p1_0_split_7
I0816 16:04:01.655318 20404 net.cpp:399] conv1 -> Convolution71
I0816 16:04:01.658018 20404 net.cpp:141] Setting up conv1
I0816 16:04:01.658054 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.658066 20404 net.cpp:156] Memory required for data: 1687864400
I0816 16:04:01.658080 20404 layer_factory.hpp:77] Creating layer ReLU99
I0816 16:04:01.658092 20404 net.cpp:91] Creating Layer ReLU99
I0816 16:04:01.658102 20404 net.cpp:425] ReLU99 <- Convolution71
I0816 16:04:01.658113 20404 net.cpp:386] ReLU99 -> Convolution71 (in-place)
I0816 16:04:01.658128 20404 net.cpp:141] Setting up ReLU99
I0816 16:04:01.658138 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.658145 20404 net.cpp:156] Memory required for data: 1697694800
I0816 16:04:01.658152 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:01.658169 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:01.658177 20404 net.cpp:425] norm1 <- Convolution71
I0816 16:04:01.658193 20404 net.cpp:399] norm1 -> LRN29
I0816 16:04:01.658252 20404 net.cpp:141] Setting up norm1
I0816 16:04:01.658265 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.658273 20404 net.cpp:156] Memory required for data: 1707525200
I0816 16:04:01.658280 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:01.658293 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:01.658300 20404 net.cpp:425] pool1 <- LRN29
I0816 16:04:01.658315 20404 net.cpp:399] pool1 -> Pooling43
I0816 16:04:01.658377 20404 net.cpp:141] Setting up pool1
I0816 16:04:01.658395 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:01.658402 20404 net.cpp:156] Memory required for data: 1709982800
I0816 16:04:01.658411 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:01.658429 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:01.658438 20404 net.cpp:425] conv2 <- Pooling43
I0816 16:04:01.658452 20404 net.cpp:399] conv2 -> Convolution72
I0816 16:04:01.673912 20404 net.cpp:141] Setting up conv2
I0816 16:04:01.673933 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.673940 20404 net.cpp:156] Memory required for data: 1716536400
I0816 16:04:01.673964 20404 layer_factory.hpp:77] Creating layer ReLU100
I0816 16:04:01.673976 20404 net.cpp:91] Creating Layer ReLU100
I0816 16:04:01.673985 20404 net.cpp:425] ReLU100 <- Convolution72
I0816 16:04:01.674000 20404 net.cpp:386] ReLU100 -> Convolution72 (in-place)
I0816 16:04:01.674015 20404 net.cpp:141] Setting up ReLU100
I0816 16:04:01.674031 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.674038 20404 net.cpp:156] Memory required for data: 1723090000
I0816 16:04:01.674046 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:01.674057 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:01.674065 20404 net.cpp:425] norm2 <- Convolution72
I0816 16:04:01.674077 20404 net.cpp:399] norm2 -> LRN30
I0816 16:04:01.674145 20404 net.cpp:141] Setting up norm2
I0816 16:04:01.674160 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.674167 20404 net.cpp:156] Memory required for data: 1729643600
I0816 16:04:01.674175 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:01.674187 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:01.674196 20404 net.cpp:425] pool2 <- LRN30
I0816 16:04:01.674207 20404 net.cpp:399] pool2 -> Pooling44
I0816 16:04:01.674276 20404 net.cpp:141] Setting up pool2
I0816 16:04:01.674290 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.674298 20404 net.cpp:156] Memory required for data: 1731282000
I0816 16:04:01.674305 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:01.674324 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:01.674331 20404 net.cpp:425] conv3 <- Pooling44
I0816 16:04:01.674345 20404 net.cpp:399] conv3 -> Convolution73
I0816 16:04:01.718204 20404 net.cpp:141] Setting up conv3
I0816 16:04:01.718236 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.718245 20404 net.cpp:156] Memory required for data: 1733739600
I0816 16:04:01.718262 20404 layer_factory.hpp:77] Creating layer ReLU101
I0816 16:04:01.718276 20404 net.cpp:91] Creating Layer ReLU101
I0816 16:04:01.718288 20404 net.cpp:425] ReLU101 <- Convolution73
I0816 16:04:01.718322 20404 net.cpp:386] ReLU101 -> Convolution73 (in-place)
I0816 16:04:01.718343 20404 net.cpp:141] Setting up ReLU101
I0816 16:04:01.718356 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.718364 20404 net.cpp:156] Memory required for data: 1736197200
I0816 16:04:01.718372 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:01.718394 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:01.718405 20404 net.cpp:425] conv4 <- Convolution73
I0816 16:04:01.718420 20404 net.cpp:399] conv4 -> Convolution74
I0816 16:04:01.756839 20404 net.cpp:141] Setting up conv4
I0816 16:04:01.756881 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.756887 20404 net.cpp:156] Memory required for data: 1738654800
I0816 16:04:01.756901 20404 layer_factory.hpp:77] Creating layer ReLU102
I0816 16:04:01.756913 20404 net.cpp:91] Creating Layer ReLU102
I0816 16:04:01.756925 20404 net.cpp:425] ReLU102 <- Convolution74
I0816 16:04:01.756942 20404 net.cpp:386] ReLU102 -> Convolution74 (in-place)
I0816 16:04:01.756958 20404 net.cpp:141] Setting up ReLU102
I0816 16:04:01.756965 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.756971 20404 net.cpp:156] Memory required for data: 1741112400
I0816 16:04:01.756976 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:01.757004 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:01.757010 20404 net.cpp:425] conv5 <- Convolution74
I0816 16:04:01.757024 20404 net.cpp:399] conv5 -> Convolution75
I0816 16:04:01.779145 20404 net.cpp:141] Setting up conv5
I0816 16:04:01.779175 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.779186 20404 net.cpp:156] Memory required for data: 1742750800
I0816 16:04:01.779202 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:01.779244 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:01.779281 20404 net.cpp:425] pool5 <- Convolution75
I0816 16:04:01.779320 20404 net.cpp:399] pool5 -> Pooling45
I0816 16:04:01.779404 20404 net.cpp:141] Setting up pool5
I0816 16:04:01.779419 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:01.779428 20404 net.cpp:156] Memory required for data: 1743160400
I0816 16:04:01.779458 20404 layer_factory.hpp:77] Creating layer InnerProduct43
I0816 16:04:01.779492 20404 net.cpp:91] Creating Layer InnerProduct43
I0816 16:04:01.779520 20404 net.cpp:425] InnerProduct43 <- Pooling45
I0816 16:04:01.779557 20404 net.cpp:399] InnerProduct43 -> InnerProduct43
I0816 16:04:01.782358 20404 net.cpp:141] Setting up InnerProduct43
I0816 16:04:01.782389 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.782395 20404 net.cpp:156] Memory required for data: 1743262800
I0816 16:04:01.782403 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:01.782412 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:01.782418 20404 layer_factory.hpp:77] Creating layer ReLU103
I0816 16:04:01.782426 20404 net.cpp:91] Creating Layer ReLU103
I0816 16:04:01.782435 20404 net.cpp:425] ReLU103 <- InnerProduct43
I0816 16:04:01.782454 20404 net.cpp:386] ReLU103 -> InnerProduct43 (in-place)
I0816 16:04:01.782464 20404 net.cpp:141] Setting up ReLU103
I0816 16:04:01.782472 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.782477 20404 net.cpp:156] Memory required for data: 1743365200
I0816 16:04:01.782483 20404 layer_factory.hpp:77] Creating layer InnerProduct44
I0816 16:04:01.782500 20404 net.cpp:91] Creating Layer InnerProduct44
I0816 16:04:01.782510 20404 net.cpp:425] InnerProduct44 <- InnerProduct43
I0816 16:04:01.782521 20404 net.cpp:399] InnerProduct44 -> InnerProduct44
I0816 16:04:01.783210 20404 net.cpp:141] Setting up InnerProduct44
I0816 16:04:01.783226 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.783231 20404 net.cpp:156] Memory required for data: 1743467600
I0816 16:04:01.783238 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:01.783246 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:01.783270 20404 layer_factory.hpp:77] Creating layer ReLU104
I0816 16:04:01.783300 20404 net.cpp:91] Creating Layer ReLU104
I0816 16:04:01.783308 20404 net.cpp:425] ReLU104 <- InnerProduct44
I0816 16:04:01.783315 20404 net.cpp:386] ReLU104 -> InnerProduct44 (in-place)
I0816 16:04:01.783325 20404 net.cpp:141] Setting up ReLU104
I0816 16:04:01.783337 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.783344 20404 net.cpp:156] Memory required for data: 1743570000
I0816 16:04:01.783351 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:01.783367 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:01.783376 20404 net.cpp:425] conv1 <- c27
I0816 16:04:01.783395 20404 net.cpp:399] conv1 -> Convolution76
I0816 16:04:01.785461 20404 net.cpp:141] Setting up conv1
I0816 16:04:01.785473 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.785482 20404 net.cpp:156] Memory required for data: 1753400400
I0816 16:04:01.785492 20404 layer_factory.hpp:77] Creating layer ReLU105
I0816 16:04:01.785501 20404 net.cpp:91] Creating Layer ReLU105
I0816 16:04:01.785507 20404 net.cpp:425] ReLU105 <- Convolution76
I0816 16:04:01.785517 20404 net.cpp:386] ReLU105 -> Convolution76 (in-place)
I0816 16:04:01.785527 20404 net.cpp:141] Setting up ReLU105
I0816 16:04:01.785542 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.785548 20404 net.cpp:156] Memory required for data: 1763230800
I0816 16:04:01.785553 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:01.785565 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:01.785572 20404 net.cpp:425] norm1 <- Convolution76
I0816 16:04:01.785581 20404 net.cpp:399] norm1 -> LRN31
I0816 16:04:01.785645 20404 net.cpp:141] Setting up norm1
I0816 16:04:01.785655 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.785662 20404 net.cpp:156] Memory required for data: 1773061200
I0816 16:04:01.785670 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:01.785682 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:01.785691 20404 net.cpp:425] pool1 <- LRN31
I0816 16:04:01.785701 20404 net.cpp:399] pool1 -> Pooling46
I0816 16:04:01.785763 20404 net.cpp:141] Setting up pool1
I0816 16:04:01.785773 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:01.785778 20404 net.cpp:156] Memory required for data: 1775518800
I0816 16:04:01.785784 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:01.785796 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:01.785802 20404 net.cpp:425] conv2 <- Pooling46
I0816 16:04:01.785815 20404 net.cpp:399] conv2 -> Convolution77
I0816 16:04:01.801225 20404 net.cpp:141] Setting up conv2
I0816 16:04:01.801259 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.801265 20404 net.cpp:156] Memory required for data: 1782072400
I0816 16:04:01.801275 20404 layer_factory.hpp:77] Creating layer ReLU106
I0816 16:04:01.801285 20404 net.cpp:91] Creating Layer ReLU106
I0816 16:04:01.801293 20404 net.cpp:425] ReLU106 <- Convolution77
I0816 16:04:01.801316 20404 net.cpp:386] ReLU106 -> Convolution77 (in-place)
I0816 16:04:01.801327 20404 net.cpp:141] Setting up ReLU106
I0816 16:04:01.801336 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.801342 20404 net.cpp:156] Memory required for data: 1788626000
I0816 16:04:01.801347 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:01.801355 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:01.801362 20404 net.cpp:425] norm2 <- Convolution77
I0816 16:04:01.801373 20404 net.cpp:399] norm2 -> LRN32
I0816 16:04:01.801430 20404 net.cpp:141] Setting up norm2
I0816 16:04:01.801439 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.801443 20404 net.cpp:156] Memory required for data: 1795179600
I0816 16:04:01.801450 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:01.801460 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:01.801465 20404 net.cpp:425] pool2 <- LRN32
I0816 16:04:01.801475 20404 net.cpp:399] pool2 -> Pooling47
I0816 16:04:01.801549 20404 net.cpp:141] Setting up pool2
I0816 16:04:01.801559 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.801565 20404 net.cpp:156] Memory required for data: 1796818000
I0816 16:04:01.801571 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:01.801585 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:01.801591 20404 net.cpp:425] conv3 <- Pooling47
I0816 16:04:01.801604 20404 net.cpp:399] conv3 -> Convolution78
I0816 16:04:01.845219 20404 net.cpp:141] Setting up conv3
I0816 16:04:01.845258 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.845265 20404 net.cpp:156] Memory required for data: 1799275600
I0816 16:04:01.845386 20404 layer_factory.hpp:77] Creating layer ReLU107
I0816 16:04:01.845401 20404 net.cpp:91] Creating Layer ReLU107
I0816 16:04:01.845412 20404 net.cpp:425] ReLU107 <- Convolution78
I0816 16:04:01.845424 20404 net.cpp:386] ReLU107 -> Convolution78 (in-place)
I0816 16:04:01.845440 20404 net.cpp:141] Setting up ReLU107
I0816 16:04:01.845450 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.845459 20404 net.cpp:156] Memory required for data: 1801733200
I0816 16:04:01.845466 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:01.845486 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:01.845494 20404 net.cpp:425] conv4 <- Convolution78
I0816 16:04:01.845510 20404 net.cpp:399] conv4 -> Convolution79
I0816 16:04:01.878779 20404 net.cpp:141] Setting up conv4
I0816 16:04:01.878810 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.878818 20404 net.cpp:156] Memory required for data: 1804190800
I0816 16:04:01.878830 20404 layer_factory.hpp:77] Creating layer ReLU108
I0816 16:04:01.878841 20404 net.cpp:91] Creating Layer ReLU108
I0816 16:04:01.878850 20404 net.cpp:425] ReLU108 <- Convolution79
I0816 16:04:01.878860 20404 net.cpp:386] ReLU108 -> Convolution79 (in-place)
I0816 16:04:01.878875 20404 net.cpp:141] Setting up ReLU108
I0816 16:04:01.878882 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.878887 20404 net.cpp:156] Memory required for data: 1806648400
I0816 16:04:01.878893 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:01.878909 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:01.878916 20404 net.cpp:425] conv5 <- Convolution79
I0816 16:04:01.878928 20404 net.cpp:399] conv5 -> Convolution80
I0816 16:04:01.901623 20404 net.cpp:141] Setting up conv5
I0816 16:04:01.901648 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.901655 20404 net.cpp:156] Memory required for data: 1808286800
I0816 16:04:01.901667 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:01.901684 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:01.901693 20404 net.cpp:425] pool5 <- Convolution80
I0816 16:04:01.901705 20404 net.cpp:399] pool5 -> Pooling48
I0816 16:04:01.901782 20404 net.cpp:141] Setting up pool5
I0816 16:04:01.901799 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:01.901808 20404 net.cpp:156] Memory required for data: 1808696400
I0816 16:04:01.901816 20404 layer_factory.hpp:77] Creating layer InnerProduct45
I0816 16:04:01.901835 20404 net.cpp:91] Creating Layer InnerProduct45
I0816 16:04:01.901844 20404 net.cpp:425] InnerProduct45 <- Pooling48
I0816 16:04:01.901859 20404 net.cpp:399] InnerProduct45 -> InnerProduct45
I0816 16:04:01.904713 20404 net.cpp:141] Setting up InnerProduct45
I0816 16:04:01.904734 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.904742 20404 net.cpp:156] Memory required for data: 1808798800
I0816 16:04:01.904752 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:01.904762 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:01.904770 20404 layer_factory.hpp:77] Creating layer ReLU109
I0816 16:04:01.904785 20404 net.cpp:91] Creating Layer ReLU109
I0816 16:04:01.904794 20404 net.cpp:425] ReLU109 <- InnerProduct45
I0816 16:04:01.904805 20404 net.cpp:386] ReLU109 -> InnerProduct45 (in-place)
I0816 16:04:01.904850 20404 net.cpp:141] Setting up ReLU109
I0816 16:04:01.904862 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.904870 20404 net.cpp:156] Memory required for data: 1808901200
I0816 16:04:01.904877 20404 layer_factory.hpp:77] Creating layer InnerProduct46
I0816 16:04:01.904893 20404 net.cpp:91] Creating Layer InnerProduct46
I0816 16:04:01.904901 20404 net.cpp:425] InnerProduct46 <- InnerProduct45
I0816 16:04:01.904914 20404 net.cpp:399] InnerProduct46 -> InnerProduct46
I0816 16:04:01.905596 20404 net.cpp:141] Setting up InnerProduct46
I0816 16:04:01.905609 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.905617 20404 net.cpp:156] Memory required for data: 1809003600
I0816 16:04:01.905625 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:01.905635 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:01.905643 20404 layer_factory.hpp:77] Creating layer ReLU110
I0816 16:04:01.905653 20404 net.cpp:91] Creating Layer ReLU110
I0816 16:04:01.905661 20404 net.cpp:425] ReLU110 <- InnerProduct46
I0816 16:04:01.905675 20404 net.cpp:386] ReLU110 -> InnerProduct46 (in-place)
I0816 16:04:01.905689 20404 net.cpp:141] Setting up ReLU110
I0816 16:04:01.905699 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.905705 20404 net.cpp:156] Memory required for data: 1809106000
I0816 16:04:01.905712 20404 layer_factory.hpp:77] Creating layer Concat8
I0816 16:04:01.905725 20404 net.cpp:91] Creating Layer Concat8
I0816 16:04:01.905731 20404 net.cpp:425] Concat8 <- InnerProduct44
I0816 16:04:01.905741 20404 net.cpp:425] Concat8 <- InnerProduct46
I0816 16:04:01.905755 20404 net.cpp:399] Concat8 -> Concat8
I0816 16:04:01.905800 20404 net.cpp:141] Setting up Concat8
I0816 16:04:01.905838 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:01.905865 20404 net.cpp:156] Memory required for data: 1809310800
I0816 16:04:01.905892 20404 layer_factory.hpp:77] Creating layer InnerProduct47
I0816 16:04:01.905930 20404 net.cpp:91] Creating Layer InnerProduct47
I0816 16:04:01.906252 20404 net.cpp:425] InnerProduct47 <- Concat8
I0816 16:04:01.906271 20404 net.cpp:399] InnerProduct47 -> InnerProduct47
I0816 16:04:01.908067 20404 net.cpp:141] Setting up InnerProduct47
I0816 16:04:01.908090 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.908098 20404 net.cpp:156] Memory required for data: 1809413200
I0816 16:04:01.908108 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:01.908119 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:01.908128 20404 layer_factory.hpp:77] Creating layer ReLU111
I0816 16:04:01.908139 20404 net.cpp:91] Creating Layer ReLU111
I0816 16:04:01.908148 20404 net.cpp:425] ReLU111 <- InnerProduct47
I0816 16:04:01.908159 20404 net.cpp:386] ReLU111 -> InnerProduct47 (in-place)
I0816 16:04:01.908174 20404 net.cpp:141] Setting up ReLU111
I0816 16:04:01.908182 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:01.908190 20404 net.cpp:156] Memory required for data: 1809515600
I0816 16:04:01.908197 20404 layer_factory.hpp:77] Creating layer InnerProduct48
I0816 16:04:01.908213 20404 net.cpp:91] Creating Layer InnerProduct48
I0816 16:04:01.908221 20404 net.cpp:425] InnerProduct48 <- InnerProduct47
I0816 16:04:01.908234 20404 net.cpp:399] InnerProduct48 -> InnerProduct48
I0816 16:04:01.908659 20404 net.cpp:141] Setting up InnerProduct48
I0816 16:04:01.908675 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:01.908684 20404 net.cpp:156] Memory required for data: 1809566800
I0816 16:04:01.908691 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:01.908701 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:01.908710 20404 layer_factory.hpp:77] Creating layer ReLU112
I0816 16:04:01.908725 20404 net.cpp:91] Creating Layer ReLU112
I0816 16:04:01.908732 20404 net.cpp:425] ReLU112 <- InnerProduct48
I0816 16:04:01.908757 20404 net.cpp:386] ReLU112 -> InnerProduct48 (in-place)
I0816 16:04:01.908771 20404 net.cpp:141] Setting up ReLU112
I0816 16:04:01.908782 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:01.908788 20404 net.cpp:156] Memory required for data: 1809618000
I0816 16:04:01.908797 20404 layer_factory.hpp:77] Creating layer dt7
I0816 16:04:01.908808 20404 net.cpp:91] Creating Layer dt7
I0816 16:04:01.908816 20404 net.cpp:425] dt7 <- InnerProduct48
I0816 16:04:01.908830 20404 net.cpp:399] dt7 -> dt7
I0816 16:04:01.908999 20404 net.cpp:141] Setting up dt7
I0816 16:04:01.909013 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:01.909021 20404 net.cpp:156] Memory required for data: 1809618400
I0816 16:04:01.909030 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:01.909039 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:01.909047 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:01.909068 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:01.909082 20404 net.cpp:425] conv1 <- p1_p1_0_split_8
I0816 16:04:01.909096 20404 net.cpp:399] conv1 -> Convolution81
I0816 16:04:01.911803 20404 net.cpp:141] Setting up conv1
I0816 16:04:01.911823 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.911831 20404 net.cpp:156] Memory required for data: 1819448800
I0816 16:04:01.911845 20404 layer_factory.hpp:77] Creating layer ReLU113
I0816 16:04:01.911859 20404 net.cpp:91] Creating Layer ReLU113
I0816 16:04:01.911867 20404 net.cpp:425] ReLU113 <- Convolution81
I0816 16:04:01.911880 20404 net.cpp:386] ReLU113 -> Convolution81 (in-place)
I0816 16:04:01.911892 20404 net.cpp:141] Setting up ReLU113
I0816 16:04:01.911903 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.911911 20404 net.cpp:156] Memory required for data: 1829279200
I0816 16:04:01.911918 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:01.911933 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:01.911942 20404 net.cpp:425] norm1 <- Convolution81
I0816 16:04:01.911955 20404 net.cpp:399] norm1 -> LRN33
I0816 16:04:01.912016 20404 net.cpp:141] Setting up norm1
I0816 16:04:01.912030 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:01.912037 20404 net.cpp:156] Memory required for data: 1839109600
I0816 16:04:01.912045 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:01.912056 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:01.912065 20404 net.cpp:425] pool1 <- LRN33
I0816 16:04:01.912080 20404 net.cpp:399] pool1 -> Pooling49
I0816 16:04:01.912144 20404 net.cpp:141] Setting up pool1
I0816 16:04:01.912158 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:01.912166 20404 net.cpp:156] Memory required for data: 1841567200
I0816 16:04:01.912173 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:01.912191 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:01.912199 20404 net.cpp:425] conv2 <- Pooling49
I0816 16:04:01.912215 20404 net.cpp:399] conv2 -> Convolution82
I0816 16:04:01.928344 20404 net.cpp:141] Setting up conv2
I0816 16:04:01.928406 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.928419 20404 net.cpp:156] Memory required for data: 1848120800
I0816 16:04:01.928436 20404 layer_factory.hpp:77] Creating layer ReLU114
I0816 16:04:01.928452 20404 net.cpp:91] Creating Layer ReLU114
I0816 16:04:01.928462 20404 net.cpp:425] ReLU114 <- Convolution82
I0816 16:04:01.928474 20404 net.cpp:386] ReLU114 -> Convolution82 (in-place)
I0816 16:04:01.928489 20404 net.cpp:141] Setting up ReLU114
I0816 16:04:01.928499 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.928508 20404 net.cpp:156] Memory required for data: 1854674400
I0816 16:04:01.928515 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:01.928531 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:01.928541 20404 net.cpp:425] norm2 <- Convolution82
I0816 16:04:01.928553 20404 net.cpp:399] norm2 -> LRN34
I0816 16:04:01.928613 20404 net.cpp:141] Setting up norm2
I0816 16:04:01.928640 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:01.928647 20404 net.cpp:156] Memory required for data: 1861228000
I0816 16:04:01.928655 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:01.928669 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:01.928678 20404 net.cpp:425] pool2 <- LRN34
I0816 16:04:01.928692 20404 net.cpp:399] pool2 -> Pooling50
I0816 16:04:01.928748 20404 net.cpp:141] Setting up pool2
I0816 16:04:01.928762 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:01.928769 20404 net.cpp:156] Memory required for data: 1862866400
I0816 16:04:01.928777 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:01.928795 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:01.928808 20404 net.cpp:425] conv3 <- Pooling50
I0816 16:04:01.928825 20404 net.cpp:399] conv3 -> Convolution83
I0816 16:04:01.973909 20404 net.cpp:141] Setting up conv3
I0816 16:04:01.973943 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.973961 20404 net.cpp:156] Memory required for data: 1865324000
I0816 16:04:01.973978 20404 layer_factory.hpp:77] Creating layer ReLU115
I0816 16:04:01.973997 20404 net.cpp:91] Creating Layer ReLU115
I0816 16:04:01.974010 20404 net.cpp:425] ReLU115 <- Convolution83
I0816 16:04:01.974032 20404 net.cpp:386] ReLU115 -> Convolution83 (in-place)
I0816 16:04:01.974050 20404 net.cpp:141] Setting up ReLU115
I0816 16:04:01.974059 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:01.974067 20404 net.cpp:156] Memory required for data: 1867781600
I0816 16:04:01.974076 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:01.974097 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:01.974112 20404 net.cpp:425] conv4 <- Convolution83
I0816 16:04:01.974128 20404 net.cpp:399] conv4 -> Convolution84
I0816 16:04:02.007542 20404 net.cpp:141] Setting up conv4
I0816 16:04:02.007572 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.007581 20404 net.cpp:156] Memory required for data: 1870239200
I0816 16:04:02.007598 20404 layer_factory.hpp:77] Creating layer ReLU116
I0816 16:04:02.007613 20404 net.cpp:91] Creating Layer ReLU116
I0816 16:04:02.007624 20404 net.cpp:425] ReLU116 <- Convolution84
I0816 16:04:02.007642 20404 net.cpp:386] ReLU116 -> Convolution84 (in-place)
I0816 16:04:02.007659 20404 net.cpp:141] Setting up ReLU116
I0816 16:04:02.007673 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.007681 20404 net.cpp:156] Memory required for data: 1872696800
I0816 16:04:02.007689 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:02.007709 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:02.007717 20404 net.cpp:425] conv5 <- Convolution84
I0816 16:04:02.007731 20404 net.cpp:399] conv5 -> Convolution85
I0816 16:04:02.030149 20404 net.cpp:141] Setting up conv5
I0816 16:04:02.030176 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.030184 20404 net.cpp:156] Memory required for data: 1874335200
I0816 16:04:02.030200 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:02.030215 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:02.030226 20404 net.cpp:425] pool5 <- Convolution85
I0816 16:04:02.030243 20404 net.cpp:399] pool5 -> Pooling51
I0816 16:04:02.030305 20404 net.cpp:141] Setting up pool5
I0816 16:04:02.030320 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:02.030328 20404 net.cpp:156] Memory required for data: 1874744800
I0816 16:04:02.030335 20404 layer_factory.hpp:77] Creating layer InnerProduct49
I0816 16:04:02.030352 20404 net.cpp:91] Creating Layer InnerProduct49
I0816 16:04:02.030361 20404 net.cpp:425] InnerProduct49 <- Pooling51
I0816 16:04:02.030378 20404 net.cpp:399] InnerProduct49 -> InnerProduct49
I0816 16:04:02.033148 20404 net.cpp:141] Setting up InnerProduct49
I0816 16:04:02.033170 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.033179 20404 net.cpp:156] Memory required for data: 1874847200
I0816 16:04:02.033190 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:02.033219 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:02.033228 20404 layer_factory.hpp:77] Creating layer ReLU117
I0816 16:04:02.033241 20404 net.cpp:91] Creating Layer ReLU117
I0816 16:04:02.033251 20404 net.cpp:425] ReLU117 <- InnerProduct49
I0816 16:04:02.033265 20404 net.cpp:386] ReLU117 -> InnerProduct49 (in-place)
I0816 16:04:02.033282 20404 net.cpp:141] Setting up ReLU117
I0816 16:04:02.033291 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.033299 20404 net.cpp:156] Memory required for data: 1874949600
I0816 16:04:02.033306 20404 layer_factory.hpp:77] Creating layer InnerProduct50
I0816 16:04:02.033319 20404 net.cpp:91] Creating Layer InnerProduct50
I0816 16:04:02.033327 20404 net.cpp:425] InnerProduct50 <- InnerProduct49
I0816 16:04:02.033344 20404 net.cpp:399] InnerProduct50 -> InnerProduct50
I0816 16:04:02.034005 20404 net.cpp:141] Setting up InnerProduct50
I0816 16:04:02.034029 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.034036 20404 net.cpp:156] Memory required for data: 1875052000
I0816 16:04:02.034044 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:02.034054 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:02.034060 20404 layer_factory.hpp:77] Creating layer ReLU118
I0816 16:04:02.034071 20404 net.cpp:91] Creating Layer ReLU118
I0816 16:04:02.034080 20404 net.cpp:425] ReLU118 <- InnerProduct50
I0816 16:04:02.034098 20404 net.cpp:386] ReLU118 -> InnerProduct50 (in-place)
I0816 16:04:02.034111 20404 net.cpp:141] Setting up ReLU118
I0816 16:04:02.034121 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.034128 20404 net.cpp:156] Memory required for data: 1875154400
I0816 16:04:02.034135 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:02.034157 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:02.034168 20404 net.cpp:425] conv1 <- c28
I0816 16:04:02.034185 20404 net.cpp:399] conv1 -> Convolution86
I0816 16:04:02.036169 20404 net.cpp:141] Setting up conv1
I0816 16:04:02.036183 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.036201 20404 net.cpp:156] Memory required for data: 1884984800
I0816 16:04:02.036214 20404 layer_factory.hpp:77] Creating layer ReLU119
I0816 16:04:02.036227 20404 net.cpp:91] Creating Layer ReLU119
I0816 16:04:02.036237 20404 net.cpp:425] ReLU119 <- Convolution86
I0816 16:04:02.036247 20404 net.cpp:386] ReLU119 -> Convolution86 (in-place)
I0816 16:04:02.036269 20404 net.cpp:141] Setting up ReLU119
I0816 16:04:02.036279 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.036288 20404 net.cpp:156] Memory required for data: 1894815200
I0816 16:04:02.036294 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:02.036309 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:02.036317 20404 net.cpp:425] norm1 <- Convolution86
I0816 16:04:02.036330 20404 net.cpp:399] norm1 -> LRN35
I0816 16:04:02.036382 20404 net.cpp:141] Setting up norm1
I0816 16:04:02.036396 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.036404 20404 net.cpp:156] Memory required for data: 1904645600
I0816 16:04:02.036412 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:02.036422 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:02.036430 20404 net.cpp:425] pool1 <- LRN35
I0816 16:04:02.036444 20404 net.cpp:399] pool1 -> Pooling52
I0816 16:04:02.036497 20404 net.cpp:141] Setting up pool1
I0816 16:04:02.036511 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:02.036519 20404 net.cpp:156] Memory required for data: 1907103200
I0816 16:04:02.036525 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:02.036545 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:02.036553 20404 net.cpp:425] conv2 <- Pooling52
I0816 16:04:02.036567 20404 net.cpp:399] conv2 -> Convolution87
I0816 16:04:02.052100 20404 net.cpp:141] Setting up conv2
I0816 16:04:02.052125 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.052165 20404 net.cpp:156] Memory required for data: 1913656800
I0816 16:04:02.052180 20404 layer_factory.hpp:77] Creating layer ReLU120
I0816 16:04:02.052192 20404 net.cpp:91] Creating Layer ReLU120
I0816 16:04:02.052201 20404 net.cpp:425] ReLU120 <- Convolution87
I0816 16:04:02.052222 20404 net.cpp:386] ReLU120 -> Convolution87 (in-place)
I0816 16:04:02.052235 20404 net.cpp:141] Setting up ReLU120
I0816 16:04:02.052250 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.052258 20404 net.cpp:156] Memory required for data: 1920210400
I0816 16:04:02.052265 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:02.052280 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:02.052289 20404 net.cpp:425] norm2 <- Convolution87
I0816 16:04:02.052302 20404 net.cpp:399] norm2 -> LRN36
I0816 16:04:02.052361 20404 net.cpp:141] Setting up norm2
I0816 16:04:02.052373 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.052381 20404 net.cpp:156] Memory required for data: 1926764000
I0816 16:04:02.052389 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:02.052399 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:02.052407 20404 net.cpp:425] pool2 <- LRN36
I0816 16:04:02.052423 20404 net.cpp:399] pool2 -> Pooling53
I0816 16:04:02.052476 20404 net.cpp:141] Setting up pool2
I0816 16:04:02.052495 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.052502 20404 net.cpp:156] Memory required for data: 1928402400
I0816 16:04:02.052510 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:02.052525 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:02.052533 20404 net.cpp:425] conv3 <- Pooling53
I0816 16:04:02.052551 20404 net.cpp:399] conv3 -> Convolution88
I0816 16:04:02.096282 20404 net.cpp:141] Setting up conv3
I0816 16:04:02.096312 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.096330 20404 net.cpp:156] Memory required for data: 1930860000
I0816 16:04:02.096348 20404 layer_factory.hpp:77] Creating layer ReLU121
I0816 16:04:02.096361 20404 net.cpp:91] Creating Layer ReLU121
I0816 16:04:02.096372 20404 net.cpp:425] ReLU121 <- Convolution88
I0816 16:04:02.096386 20404 net.cpp:386] ReLU121 -> Convolution88 (in-place)
I0816 16:04:02.096410 20404 net.cpp:141] Setting up ReLU121
I0816 16:04:02.096421 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.096428 20404 net.cpp:156] Memory required for data: 1933317600
I0816 16:04:02.096436 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:02.096457 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:02.096465 20404 net.cpp:425] conv4 <- Convolution88
I0816 16:04:02.096482 20404 net.cpp:399] conv4 -> Convolution89
I0816 16:04:02.129850 20404 net.cpp:141] Setting up conv4
I0816 16:04:02.129883 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.129901 20404 net.cpp:156] Memory required for data: 1935775200
I0816 16:04:02.129917 20404 layer_factory.hpp:77] Creating layer ReLU122
I0816 16:04:02.129933 20404 net.cpp:91] Creating Layer ReLU122
I0816 16:04:02.129945 20404 net.cpp:425] ReLU122 <- Convolution89
I0816 16:04:02.129971 20404 net.cpp:386] ReLU122 -> Convolution89 (in-place)
I0816 16:04:02.129987 20404 net.cpp:141] Setting up ReLU122
I0816 16:04:02.130002 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.130010 20404 net.cpp:156] Memory required for data: 1938232800
I0816 16:04:02.130018 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:02.130039 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:02.130049 20404 net.cpp:425] conv5 <- Convolution89
I0816 16:04:02.130064 20404 net.cpp:399] conv5 -> Convolution90
I0816 16:04:02.152030 20404 net.cpp:141] Setting up conv5
I0816 16:04:02.152052 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.152071 20404 net.cpp:156] Memory required for data: 1939871200
I0816 16:04:02.152086 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:02.152099 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:02.152108 20404 net.cpp:425] pool5 <- Convolution90
I0816 16:04:02.152132 20404 net.cpp:399] pool5 -> Pooling54
I0816 16:04:02.152211 20404 net.cpp:141] Setting up pool5
I0816 16:04:02.152226 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:02.152233 20404 net.cpp:156] Memory required for data: 1940280800
I0816 16:04:02.152241 20404 layer_factory.hpp:77] Creating layer InnerProduct51
I0816 16:04:02.152258 20404 net.cpp:91] Creating Layer InnerProduct51
I0816 16:04:02.152267 20404 net.cpp:425] InnerProduct51 <- Pooling54
I0816 16:04:02.152284 20404 net.cpp:399] InnerProduct51 -> InnerProduct51
I0816 16:04:02.155033 20404 net.cpp:141] Setting up InnerProduct51
I0816 16:04:02.155053 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.155061 20404 net.cpp:156] Memory required for data: 1940383200
I0816 16:04:02.155071 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:02.155081 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:02.155089 20404 layer_factory.hpp:77] Creating layer ReLU123
I0816 16:04:02.155100 20404 net.cpp:91] Creating Layer ReLU123
I0816 16:04:02.155109 20404 net.cpp:425] ReLU123 <- InnerProduct51
I0816 16:04:02.155124 20404 net.cpp:386] ReLU123 -> InnerProduct51 (in-place)
I0816 16:04:02.155138 20404 net.cpp:141] Setting up ReLU123
I0816 16:04:02.155148 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.155156 20404 net.cpp:156] Memory required for data: 1940485600
I0816 16:04:02.155164 20404 layer_factory.hpp:77] Creating layer InnerProduct52
I0816 16:04:02.155176 20404 net.cpp:91] Creating Layer InnerProduct52
I0816 16:04:02.155184 20404 net.cpp:425] InnerProduct52 <- InnerProduct51
I0816 16:04:02.155200 20404 net.cpp:399] InnerProduct52 -> InnerProduct52
I0816 16:04:02.155869 20404 net.cpp:141] Setting up InnerProduct52
I0816 16:04:02.155885 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.155892 20404 net.cpp:156] Memory required for data: 1940588000
I0816 16:04:02.155900 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:02.155910 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:02.155918 20404 layer_factory.hpp:77] Creating layer ReLU124
I0816 16:04:02.155928 20404 net.cpp:91] Creating Layer ReLU124
I0816 16:04:02.155937 20404 net.cpp:425] ReLU124 <- InnerProduct52
I0816 16:04:02.155947 20404 net.cpp:386] ReLU124 -> InnerProduct52 (in-place)
I0816 16:04:02.155961 20404 net.cpp:141] Setting up ReLU124
I0816 16:04:02.155972 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.155979 20404 net.cpp:156] Memory required for data: 1940690400
I0816 16:04:02.155987 20404 layer_factory.hpp:77] Creating layer Concat9
I0816 16:04:02.155998 20404 net.cpp:91] Creating Layer Concat9
I0816 16:04:02.156007 20404 net.cpp:425] Concat9 <- InnerProduct50
I0816 16:04:02.156016 20404 net.cpp:425] Concat9 <- InnerProduct52
I0816 16:04:02.156031 20404 net.cpp:399] Concat9 -> Concat9
I0816 16:04:02.156071 20404 net.cpp:141] Setting up Concat9
I0816 16:04:02.156085 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:02.156092 20404 net.cpp:156] Memory required for data: 1940895200
I0816 16:04:02.156100 20404 layer_factory.hpp:77] Creating layer InnerProduct53
I0816 16:04:02.156111 20404 net.cpp:91] Creating Layer InnerProduct53
I0816 16:04:02.156119 20404 net.cpp:425] InnerProduct53 <- Concat9
I0816 16:04:02.156136 20404 net.cpp:399] InnerProduct53 -> InnerProduct53
I0816 16:04:02.157323 20404 net.cpp:141] Setting up InnerProduct53
I0816 16:04:02.157341 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.157349 20404 net.cpp:156] Memory required for data: 1940997600
I0816 16:04:02.157358 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:02.157368 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:02.157377 20404 layer_factory.hpp:77] Creating layer ReLU125
I0816 16:04:02.157388 20404 net.cpp:91] Creating Layer ReLU125
I0816 16:04:02.157412 20404 net.cpp:425] ReLU125 <- InnerProduct53
I0816 16:04:02.157428 20404 net.cpp:386] ReLU125 -> InnerProduct53 (in-place)
I0816 16:04:02.157441 20404 net.cpp:141] Setting up ReLU125
I0816 16:04:02.157451 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.157459 20404 net.cpp:156] Memory required for data: 1941100000
I0816 16:04:02.157466 20404 layer_factory.hpp:77] Creating layer InnerProduct54
I0816 16:04:02.157479 20404 net.cpp:91] Creating Layer InnerProduct54
I0816 16:04:02.157487 20404 net.cpp:425] InnerProduct54 <- InnerProduct53
I0816 16:04:02.157502 20404 net.cpp:399] InnerProduct54 -> InnerProduct54
I0816 16:04:02.157896 20404 net.cpp:141] Setting up InnerProduct54
I0816 16:04:02.157912 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:02.157918 20404 net.cpp:156] Memory required for data: 1941151200
I0816 16:04:02.157927 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:02.157937 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:02.157944 20404 layer_factory.hpp:77] Creating layer ReLU126
I0816 16:04:02.157954 20404 net.cpp:91] Creating Layer ReLU126
I0816 16:04:02.157963 20404 net.cpp:425] ReLU126 <- InnerProduct54
I0816 16:04:02.157974 20404 net.cpp:386] ReLU126 -> InnerProduct54 (in-place)
I0816 16:04:02.157986 20404 net.cpp:141] Setting up ReLU126
I0816 16:04:02.157995 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:02.158004 20404 net.cpp:156] Memory required for data: 1941202400
I0816 16:04:02.158010 20404 layer_factory.hpp:77] Creating layer dt8
I0816 16:04:02.158023 20404 net.cpp:91] Creating Layer dt8
I0816 16:04:02.158031 20404 net.cpp:425] dt8 <- InnerProduct54
I0816 16:04:02.158047 20404 net.cpp:399] dt8 -> dt8
I0816 16:04:02.158179 20404 net.cpp:141] Setting up dt8
I0816 16:04:02.158193 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:02.158201 20404 net.cpp:156] Memory required for data: 1941202800
I0816 16:04:02.158210 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:02.158218 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:02.158226 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:02.158246 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:02.158254 20404 net.cpp:425] conv1 <- p1_p1_0_split_9
I0816 16:04:02.158268 20404 net.cpp:399] conv1 -> Convolution91
I0816 16:04:02.160904 20404 net.cpp:141] Setting up conv1
I0816 16:04:02.160926 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.160935 20404 net.cpp:156] Memory required for data: 1951033200
I0816 16:04:02.160949 20404 layer_factory.hpp:77] Creating layer ReLU127
I0816 16:04:02.160962 20404 net.cpp:91] Creating Layer ReLU127
I0816 16:04:02.160971 20404 net.cpp:425] ReLU127 <- Convolution91
I0816 16:04:02.160982 20404 net.cpp:386] ReLU127 -> Convolution91 (in-place)
I0816 16:04:02.160996 20404 net.cpp:141] Setting up ReLU127
I0816 16:04:02.161006 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.161015 20404 net.cpp:156] Memory required for data: 1960863600
I0816 16:04:02.161021 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:02.161036 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:02.161046 20404 net.cpp:425] norm1 <- Convolution91
I0816 16:04:02.161061 20404 net.cpp:399] norm1 -> LRN37
I0816 16:04:02.161115 20404 net.cpp:141] Setting up norm1
I0816 16:04:02.161130 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.161139 20404 net.cpp:156] Memory required for data: 1970694000
I0816 16:04:02.161145 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:02.161156 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:02.161164 20404 net.cpp:425] pool1 <- LRN37
I0816 16:04:02.161180 20404 net.cpp:399] pool1 -> Pooling55
I0816 16:04:02.161237 20404 net.cpp:141] Setting up pool1
I0816 16:04:02.161252 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:02.161259 20404 net.cpp:156] Memory required for data: 1973151600
I0816 16:04:02.161283 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:02.161303 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:02.161316 20404 net.cpp:425] conv2 <- Pooling55
I0816 16:04:02.161330 20404 net.cpp:399] conv2 -> Convolution92
I0816 16:04:02.176844 20404 net.cpp:141] Setting up conv2
I0816 16:04:02.176872 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.176879 20404 net.cpp:156] Memory required for data: 1979705200
I0816 16:04:02.176894 20404 layer_factory.hpp:77] Creating layer ReLU128
I0816 16:04:02.176908 20404 net.cpp:91] Creating Layer ReLU128
I0816 16:04:02.176916 20404 net.cpp:425] ReLU128 <- Convolution92
I0816 16:04:02.176931 20404 net.cpp:386] ReLU128 -> Convolution92 (in-place)
I0816 16:04:02.176946 20404 net.cpp:141] Setting up ReLU128
I0816 16:04:02.176956 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.176964 20404 net.cpp:156] Memory required for data: 1986258800
I0816 16:04:02.176971 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:02.176982 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:02.176991 20404 net.cpp:425] norm2 <- Convolution92
I0816 16:04:02.177006 20404 net.cpp:399] norm2 -> LRN38
I0816 16:04:02.177064 20404 net.cpp:141] Setting up norm2
I0816 16:04:02.177078 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.177086 20404 net.cpp:156] Memory required for data: 1992812400
I0816 16:04:02.177093 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:02.177106 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:02.177115 20404 net.cpp:425] pool2 <- LRN38
I0816 16:04:02.177126 20404 net.cpp:399] pool2 -> Pooling56
I0816 16:04:02.177186 20404 net.cpp:141] Setting up pool2
I0816 16:04:02.177201 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.177207 20404 net.cpp:156] Memory required for data: 1994450800
I0816 16:04:02.177215 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:02.177233 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:02.177242 20404 net.cpp:425] conv3 <- Pooling56
I0816 16:04:02.177258 20404 net.cpp:399] conv3 -> Convolution93
I0816 16:04:02.221837 20404 net.cpp:141] Setting up conv3
I0816 16:04:02.221871 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.221889 20404 net.cpp:156] Memory required for data: 1996908400
I0816 16:04:02.221905 20404 layer_factory.hpp:77] Creating layer ReLU129
I0816 16:04:02.221921 20404 net.cpp:91] Creating Layer ReLU129
I0816 16:04:02.221933 20404 net.cpp:425] ReLU129 <- Convolution93
I0816 16:04:02.221957 20404 net.cpp:386] ReLU129 -> Convolution93 (in-place)
I0816 16:04:02.221976 20404 net.cpp:141] Setting up ReLU129
I0816 16:04:02.221987 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.221993 20404 net.cpp:156] Memory required for data: 1999366000
I0816 16:04:02.222002 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:02.222023 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:02.222030 20404 net.cpp:425] conv4 <- Convolution93
I0816 16:04:02.222044 20404 net.cpp:399] conv4 -> Convolution94
I0816 16:04:02.255621 20404 net.cpp:141] Setting up conv4
I0816 16:04:02.255653 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.255662 20404 net.cpp:156] Memory required for data: 2001823600
I0816 16:04:02.255678 20404 layer_factory.hpp:77] Creating layer ReLU130
I0816 16:04:02.255694 20404 net.cpp:91] Creating Layer ReLU130
I0816 16:04:02.255707 20404 net.cpp:425] ReLU130 <- Convolution94
I0816 16:04:02.255719 20404 net.cpp:386] ReLU130 -> Convolution94 (in-place)
I0816 16:04:02.255735 20404 net.cpp:141] Setting up ReLU130
I0816 16:04:02.255745 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.255753 20404 net.cpp:156] Memory required for data: 2004281200
I0816 16:04:02.255761 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:02.255782 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:02.255790 20404 net.cpp:425] conv5 <- Convolution94
I0816 16:04:02.255807 20404 net.cpp:399] conv5 -> Convolution95
I0816 16:04:02.278167 20404 net.cpp:141] Setting up conv5
I0816 16:04:02.278215 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.278223 20404 net.cpp:156] Memory required for data: 2005919600
I0816 16:04:02.278239 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:02.278254 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:02.278264 20404 net.cpp:425] pool5 <- Convolution95
I0816 16:04:02.278278 20404 net.cpp:399] pool5 -> Pooling57
I0816 16:04:02.278342 20404 net.cpp:141] Setting up pool5
I0816 16:04:02.278357 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:02.278364 20404 net.cpp:156] Memory required for data: 2006329200
I0816 16:04:02.278372 20404 layer_factory.hpp:77] Creating layer InnerProduct55
I0816 16:04:02.278388 20404 net.cpp:91] Creating Layer InnerProduct55
I0816 16:04:02.278398 20404 net.cpp:425] InnerProduct55 <- Pooling57
I0816 16:04:02.278411 20404 net.cpp:399] InnerProduct55 -> InnerProduct55
I0816 16:04:02.281201 20404 net.cpp:141] Setting up InnerProduct55
I0816 16:04:02.281224 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.281231 20404 net.cpp:156] Memory required for data: 2006431600
I0816 16:04:02.281241 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:02.281251 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:02.281260 20404 layer_factory.hpp:77] Creating layer ReLU131
I0816 16:04:02.281272 20404 net.cpp:91] Creating Layer ReLU131
I0816 16:04:02.281282 20404 net.cpp:425] ReLU131 <- InnerProduct55
I0816 16:04:02.281293 20404 net.cpp:386] ReLU131 -> InnerProduct55 (in-place)
I0816 16:04:02.281308 20404 net.cpp:141] Setting up ReLU131
I0816 16:04:02.281318 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.281327 20404 net.cpp:156] Memory required for data: 2006534000
I0816 16:04:02.281333 20404 layer_factory.hpp:77] Creating layer InnerProduct56
I0816 16:04:02.281350 20404 net.cpp:91] Creating Layer InnerProduct56
I0816 16:04:02.281358 20404 net.cpp:425] InnerProduct56 <- InnerProduct55
I0816 16:04:02.281371 20404 net.cpp:399] InnerProduct56 -> InnerProduct56
I0816 16:04:02.282027 20404 net.cpp:141] Setting up InnerProduct56
I0816 16:04:02.282042 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.282049 20404 net.cpp:156] Memory required for data: 2006636400
I0816 16:04:02.282058 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:02.282068 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:02.282074 20404 layer_factory.hpp:77] Creating layer ReLU132
I0816 16:04:02.282085 20404 net.cpp:91] Creating Layer ReLU132
I0816 16:04:02.282094 20404 net.cpp:425] ReLU132 <- InnerProduct56
I0816 16:04:02.282104 20404 net.cpp:386] ReLU132 -> InnerProduct56 (in-place)
I0816 16:04:02.282116 20404 net.cpp:141] Setting up ReLU132
I0816 16:04:02.282127 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.282135 20404 net.cpp:156] Memory required for data: 2006738800
I0816 16:04:02.282142 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:02.282163 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:02.282173 20404 net.cpp:425] conv1 <- c29
I0816 16:04:02.282188 20404 net.cpp:399] conv1 -> Convolution96
I0816 16:04:02.284189 20404 net.cpp:141] Setting up conv1
I0816 16:04:02.284204 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.284211 20404 net.cpp:156] Memory required for data: 2016569200
I0816 16:04:02.284230 20404 layer_factory.hpp:77] Creating layer ReLU133
I0816 16:04:02.284240 20404 net.cpp:91] Creating Layer ReLU133
I0816 16:04:02.284250 20404 net.cpp:425] ReLU133 <- Convolution96
I0816 16:04:02.284262 20404 net.cpp:386] ReLU133 -> Convolution96 (in-place)
I0816 16:04:02.284286 20404 net.cpp:141] Setting up ReLU133
I0816 16:04:02.284296 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.284303 20404 net.cpp:156] Memory required for data: 2026399600
I0816 16:04:02.284310 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:02.284344 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:02.284358 20404 net.cpp:425] norm1 <- Convolution96
I0816 16:04:02.284371 20404 net.cpp:399] norm1 -> LRN39
I0816 16:04:02.284423 20404 net.cpp:141] Setting up norm1
I0816 16:04:02.284438 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.284446 20404 net.cpp:156] Memory required for data: 2036230000
I0816 16:04:02.284452 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:02.284466 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:02.284476 20404 net.cpp:425] pool1 <- LRN39
I0816 16:04:02.284487 20404 net.cpp:399] pool1 -> Pooling58
I0816 16:04:02.284545 20404 net.cpp:141] Setting up pool1
I0816 16:04:02.284559 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:02.284567 20404 net.cpp:156] Memory required for data: 2038687600
I0816 16:04:02.284574 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:02.284591 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:02.284600 20404 net.cpp:425] conv2 <- Pooling58
I0816 16:04:02.284615 20404 net.cpp:399] conv2 -> Convolution97
I0816 16:04:02.300266 20404 net.cpp:141] Setting up conv2
I0816 16:04:02.300289 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.300297 20404 net.cpp:156] Memory required for data: 2045241200
I0816 16:04:02.300317 20404 layer_factory.hpp:77] Creating layer ReLU134
I0816 16:04:02.300329 20404 net.cpp:91] Creating Layer ReLU134
I0816 16:04:02.300339 20404 net.cpp:425] ReLU134 <- Convolution97
I0816 16:04:02.300356 20404 net.cpp:386] ReLU134 -> Convolution97 (in-place)
I0816 16:04:02.300371 20404 net.cpp:141] Setting up ReLU134
I0816 16:04:02.300382 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.300390 20404 net.cpp:156] Memory required for data: 2051794800
I0816 16:04:02.300397 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:02.300408 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:02.300416 20404 net.cpp:425] norm2 <- Convolution97
I0816 16:04:02.300431 20404 net.cpp:399] norm2 -> LRN40
I0816 16:04:02.300488 20404 net.cpp:141] Setting up norm2
I0816 16:04:02.300503 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.300510 20404 net.cpp:156] Memory required for data: 2058348400
I0816 16:04:02.300518 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:02.300532 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:02.300540 20404 net.cpp:425] pool2 <- LRN40
I0816 16:04:02.300552 20404 net.cpp:399] pool2 -> Pooling59
I0816 16:04:02.300611 20404 net.cpp:141] Setting up pool2
I0816 16:04:02.300626 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.300633 20404 net.cpp:156] Memory required for data: 2059986800
I0816 16:04:02.300640 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:02.300660 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:02.300673 20404 net.cpp:425] conv3 <- Pooling59
I0816 16:04:02.300691 20404 net.cpp:399] conv3 -> Convolution98
I0816 16:04:02.344414 20404 net.cpp:141] Setting up conv3
I0816 16:04:02.344449 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.344456 20404 net.cpp:156] Memory required for data: 2062444400
I0816 16:04:02.344482 20404 layer_factory.hpp:77] Creating layer ReLU135
I0816 16:04:02.344497 20404 net.cpp:91] Creating Layer ReLU135
I0816 16:04:02.344509 20404 net.cpp:425] ReLU135 <- Convolution98
I0816 16:04:02.344526 20404 net.cpp:386] ReLU135 -> Convolution98 (in-place)
I0816 16:04:02.344550 20404 net.cpp:141] Setting up ReLU135
I0816 16:04:02.344560 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.344568 20404 net.cpp:156] Memory required for data: 2064902000
I0816 16:04:02.344575 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:02.344596 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:02.344605 20404 net.cpp:425] conv4 <- Convolution98
I0816 16:04:02.344619 20404 net.cpp:399] conv4 -> Convolution99
I0816 16:04:02.377902 20404 net.cpp:141] Setting up conv4
I0816 16:04:02.377936 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.377944 20404 net.cpp:156] Memory required for data: 2067359600
I0816 16:04:02.377988 20404 layer_factory.hpp:77] Creating layer ReLU136
I0816 16:04:02.378005 20404 net.cpp:91] Creating Layer ReLU136
I0816 16:04:02.378016 20404 net.cpp:425] ReLU136 <- Convolution99
I0816 16:04:02.378029 20404 net.cpp:386] ReLU136 -> Convolution99 (in-place)
I0816 16:04:02.378046 20404 net.cpp:141] Setting up ReLU136
I0816 16:04:02.378062 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.378069 20404 net.cpp:156] Memory required for data: 2069817200
I0816 16:04:02.378077 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:02.378103 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:02.378119 20404 net.cpp:425] conv5 <- Convolution99
I0816 16:04:02.378135 20404 net.cpp:399] conv5 -> Convolution100
I0816 16:04:02.400293 20404 net.cpp:141] Setting up conv5
I0816 16:04:02.400316 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.400333 20404 net.cpp:156] Memory required for data: 2071455600
I0816 16:04:02.400348 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:02.400363 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:02.400372 20404 net.cpp:425] pool5 <- Convolution100
I0816 16:04:02.400387 20404 net.cpp:399] pool5 -> Pooling60
I0816 16:04:02.400461 20404 net.cpp:141] Setting up pool5
I0816 16:04:02.400475 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:02.400483 20404 net.cpp:156] Memory required for data: 2071865200
I0816 16:04:02.400491 20404 layer_factory.hpp:77] Creating layer InnerProduct57
I0816 16:04:02.400507 20404 net.cpp:91] Creating Layer InnerProduct57
I0816 16:04:02.400516 20404 net.cpp:425] InnerProduct57 <- Pooling60
I0816 16:04:02.400532 20404 net.cpp:399] InnerProduct57 -> InnerProduct57
I0816 16:04:02.403237 20404 net.cpp:141] Setting up InnerProduct57
I0816 16:04:02.403256 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.403280 20404 net.cpp:156] Memory required for data: 2071967600
I0816 16:04:02.403291 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:02.403301 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:02.403309 20404 layer_factory.hpp:77] Creating layer ReLU137
I0816 16:04:02.403321 20404 net.cpp:91] Creating Layer ReLU137
I0816 16:04:02.403331 20404 net.cpp:425] ReLU137 <- InnerProduct57
I0816 16:04:02.403350 20404 net.cpp:386] ReLU137 -> InnerProduct57 (in-place)
I0816 16:04:02.403365 20404 net.cpp:141] Setting up ReLU137
I0816 16:04:02.403375 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.403383 20404 net.cpp:156] Memory required for data: 2072070000
I0816 16:04:02.403390 20404 layer_factory.hpp:77] Creating layer InnerProduct58
I0816 16:04:02.403408 20404 net.cpp:91] Creating Layer InnerProduct58
I0816 16:04:02.403415 20404 net.cpp:425] InnerProduct58 <- InnerProduct57
I0816 16:04:02.403430 20404 net.cpp:399] InnerProduct58 -> InnerProduct58
I0816 16:04:02.404090 20404 net.cpp:141] Setting up InnerProduct58
I0816 16:04:02.404104 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.404120 20404 net.cpp:156] Memory required for data: 2072172400
I0816 16:04:02.404129 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:02.404137 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:02.404145 20404 layer_factory.hpp:77] Creating layer ReLU138
I0816 16:04:02.404156 20404 net.cpp:91] Creating Layer ReLU138
I0816 16:04:02.404163 20404 net.cpp:425] ReLU138 <- InnerProduct58
I0816 16:04:02.404178 20404 net.cpp:386] ReLU138 -> InnerProduct58 (in-place)
I0816 16:04:02.404191 20404 net.cpp:141] Setting up ReLU138
I0816 16:04:02.404201 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.404209 20404 net.cpp:156] Memory required for data: 2072274800
I0816 16:04:02.404217 20404 layer_factory.hpp:77] Creating layer Concat10
I0816 16:04:02.404227 20404 net.cpp:91] Creating Layer Concat10
I0816 16:04:02.404237 20404 net.cpp:425] Concat10 <- InnerProduct56
I0816 16:04:02.404261 20404 net.cpp:425] Concat10 <- InnerProduct58
I0816 16:04:02.404273 20404 net.cpp:399] Concat10 -> Concat10
I0816 16:04:02.404315 20404 net.cpp:141] Setting up Concat10
I0816 16:04:02.404330 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:02.404336 20404 net.cpp:156] Memory required for data: 2072479600
I0816 16:04:02.404345 20404 layer_factory.hpp:77] Creating layer InnerProduct59
I0816 16:04:02.404359 20404 net.cpp:91] Creating Layer InnerProduct59
I0816 16:04:02.404367 20404 net.cpp:425] InnerProduct59 <- Concat10
I0816 16:04:02.404379 20404 net.cpp:399] InnerProduct59 -> InnerProduct59
I0816 16:04:02.406131 20404 net.cpp:141] Setting up InnerProduct59
I0816 16:04:02.406150 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.406158 20404 net.cpp:156] Memory required for data: 2072582000
I0816 16:04:02.406168 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:02.406177 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:02.406185 20404 layer_factory.hpp:77] Creating layer ReLU139
I0816 16:04:02.406200 20404 net.cpp:91] Creating Layer ReLU139
I0816 16:04:02.406209 20404 net.cpp:425] ReLU139 <- InnerProduct59
I0816 16:04:02.406221 20404 net.cpp:386] ReLU139 -> InnerProduct59 (in-place)
I0816 16:04:02.406234 20404 net.cpp:141] Setting up ReLU139
I0816 16:04:02.406245 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.406252 20404 net.cpp:156] Memory required for data: 2072684400
I0816 16:04:02.406260 20404 layer_factory.hpp:77] Creating layer InnerProduct60
I0816 16:04:02.406275 20404 net.cpp:91] Creating Layer InnerProduct60
I0816 16:04:02.406285 20404 net.cpp:425] InnerProduct60 <- InnerProduct59
I0816 16:04:02.406296 20404 net.cpp:399] InnerProduct60 -> InnerProduct60
I0816 16:04:02.406719 20404 net.cpp:141] Setting up InnerProduct60
I0816 16:04:02.406762 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:02.406796 20404 net.cpp:156] Memory required for data: 2072735600
I0816 16:04:02.406831 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:02.406870 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:02.406904 20404 layer_factory.hpp:77] Creating layer ReLU140
I0816 16:04:02.406934 20404 net.cpp:91] Creating Layer ReLU140
I0816 16:04:02.406963 20404 net.cpp:425] ReLU140 <- InnerProduct60
I0816 16:04:02.406994 20404 net.cpp:386] ReLU140 -> InnerProduct60 (in-place)
I0816 16:04:02.407028 20404 net.cpp:141] Setting up ReLU140
I0816 16:04:02.407059 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:02.407083 20404 net.cpp:156] Memory required for data: 2072786800
I0816 16:04:02.407107 20404 layer_factory.hpp:77] Creating layer dt9
I0816 16:04:02.407143 20404 net.cpp:91] Creating Layer dt9
I0816 16:04:02.407172 20404 net.cpp:425] dt9 <- InnerProduct60
I0816 16:04:02.407209 20404 net.cpp:399] dt9 -> dt9
I0816 16:04:02.407387 20404 net.cpp:141] Setting up dt9
I0816 16:04:02.407402 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:02.407410 20404 net.cpp:156] Memory required for data: 2072787200
I0816 16:04:02.407419 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:02.407428 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:02.407436 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:02.407454 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:02.407462 20404 net.cpp:425] conv1 <- p2_p2_0_split_1
I0816 16:04:02.407480 20404 net.cpp:399] conv1 -> Convolution101
I0816 16:04:02.410136 20404 net.cpp:141] Setting up conv1
I0816 16:04:02.410157 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.410164 20404 net.cpp:156] Memory required for data: 2082617600
I0816 16:04:02.410181 20404 layer_factory.hpp:77] Creating layer ReLU141
I0816 16:04:02.410193 20404 net.cpp:91] Creating Layer ReLU141
I0816 16:04:02.410217 20404 net.cpp:425] ReLU141 <- Convolution101
I0816 16:04:02.410229 20404 net.cpp:386] ReLU141 -> Convolution101 (in-place)
I0816 16:04:02.410248 20404 net.cpp:141] Setting up ReLU141
I0816 16:04:02.410259 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.410266 20404 net.cpp:156] Memory required for data: 2092448000
I0816 16:04:02.410274 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:02.410289 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:02.410296 20404 net.cpp:425] norm1 <- Convolution101
I0816 16:04:02.410310 20404 net.cpp:399] norm1 -> LRN41
I0816 16:04:02.410365 20404 net.cpp:141] Setting up norm1
I0816 16:04:02.410379 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.410387 20404 net.cpp:156] Memory required for data: 2102278400
I0816 16:04:02.410394 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:02.410405 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:02.410414 20404 net.cpp:425] pool1 <- LRN41
I0816 16:04:02.410429 20404 net.cpp:399] pool1 -> Pooling61
I0816 16:04:02.410487 20404 net.cpp:141] Setting up pool1
I0816 16:04:02.410501 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:02.410509 20404 net.cpp:156] Memory required for data: 2104736000
I0816 16:04:02.410516 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:02.410539 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:02.410550 20404 net.cpp:425] conv2 <- Pooling61
I0816 16:04:02.410563 20404 net.cpp:399] conv2 -> Convolution102
I0816 16:04:02.425947 20404 net.cpp:141] Setting up conv2
I0816 16:04:02.425969 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.425976 20404 net.cpp:156] Memory required for data: 2111289600
I0816 16:04:02.425999 20404 layer_factory.hpp:77] Creating layer ReLU142
I0816 16:04:02.426012 20404 net.cpp:91] Creating Layer ReLU142
I0816 16:04:02.426020 20404 net.cpp:425] ReLU142 <- Convolution102
I0816 16:04:02.426031 20404 net.cpp:386] ReLU142 -> Convolution102 (in-place)
I0816 16:04:02.426044 20404 net.cpp:141] Setting up ReLU142
I0816 16:04:02.426064 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.426071 20404 net.cpp:156] Memory required for data: 2117843200
I0816 16:04:02.426079 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:02.426095 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:02.426102 20404 net.cpp:425] norm2 <- Convolution102
I0816 16:04:02.426117 20404 net.cpp:399] norm2 -> LRN42
I0816 16:04:02.426174 20404 net.cpp:141] Setting up norm2
I0816 16:04:02.426188 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.426195 20404 net.cpp:156] Memory required for data: 2124396800
I0816 16:04:02.426203 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:02.426218 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:02.426225 20404 net.cpp:425] pool2 <- LRN42
I0816 16:04:02.426236 20404 net.cpp:399] pool2 -> Pooling62
I0816 16:04:02.426297 20404 net.cpp:141] Setting up pool2
I0816 16:04:02.426311 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.426319 20404 net.cpp:156] Memory required for data: 2126035200
I0816 16:04:02.426326 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:02.426344 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:02.426353 20404 net.cpp:425] conv3 <- Pooling62
I0816 16:04:02.426369 20404 net.cpp:399] conv3 -> Convolution103
I0816 16:04:02.470181 20404 net.cpp:141] Setting up conv3
I0816 16:04:02.470214 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.470232 20404 net.cpp:156] Memory required for data: 2128492800
I0816 16:04:02.470249 20404 layer_factory.hpp:77] Creating layer ReLU143
I0816 16:04:02.470263 20404 net.cpp:91] Creating Layer ReLU143
I0816 16:04:02.470274 20404 net.cpp:425] ReLU143 <- Convolution103
I0816 16:04:02.470300 20404 net.cpp:386] ReLU143 -> Convolution103 (in-place)
I0816 16:04:02.470316 20404 net.cpp:141] Setting up ReLU143
I0816 16:04:02.470327 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.470335 20404 net.cpp:156] Memory required for data: 2130950400
I0816 16:04:02.470360 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:02.470381 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:02.470396 20404 net.cpp:425] conv4 <- Convolution103
I0816 16:04:02.470409 20404 net.cpp:399] conv4 -> Convolution104
I0816 16:04:02.503603 20404 net.cpp:141] Setting up conv4
I0816 16:04:02.503633 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.503650 20404 net.cpp:156] Memory required for data: 2133408000
I0816 16:04:02.503666 20404 layer_factory.hpp:77] Creating layer ReLU144
I0816 16:04:02.503690 20404 net.cpp:91] Creating Layer ReLU144
I0816 16:04:02.503700 20404 net.cpp:425] ReLU144 <- Convolution104
I0816 16:04:02.503723 20404 net.cpp:386] ReLU144 -> Convolution104 (in-place)
I0816 16:04:02.503738 20404 net.cpp:141] Setting up ReLU144
I0816 16:04:02.503749 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.503756 20404 net.cpp:156] Memory required for data: 2135865600
I0816 16:04:02.503764 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:02.503784 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:02.503793 20404 net.cpp:425] conv5 <- Convolution104
I0816 16:04:02.503809 20404 net.cpp:399] conv5 -> Convolution105
I0816 16:04:02.525813 20404 net.cpp:141] Setting up conv5
I0816 16:04:02.525835 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.525843 20404 net.cpp:156] Memory required for data: 2137504000
I0816 16:04:02.525867 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:02.525887 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:02.525895 20404 net.cpp:425] pool5 <- Convolution105
I0816 16:04:02.525910 20404 net.cpp:399] pool5 -> Pooling63
I0816 16:04:02.525985 20404 net.cpp:141] Setting up pool5
I0816 16:04:02.526000 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:02.526007 20404 net.cpp:156] Memory required for data: 2137913600
I0816 16:04:02.526015 20404 layer_factory.hpp:77] Creating layer InnerProduct61
I0816 16:04:02.526032 20404 net.cpp:91] Creating Layer InnerProduct61
I0816 16:04:02.526041 20404 net.cpp:425] InnerProduct61 <- Pooling63
I0816 16:04:02.526056 20404 net.cpp:399] InnerProduct61 -> InnerProduct61
I0816 16:04:02.528759 20404 net.cpp:141] Setting up InnerProduct61
I0816 16:04:02.528779 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.528786 20404 net.cpp:156] Memory required for data: 2138016000
I0816 16:04:02.528801 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:02.528811 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:02.528820 20404 layer_factory.hpp:77] Creating layer ReLU145
I0816 16:04:02.528834 20404 net.cpp:91] Creating Layer ReLU145
I0816 16:04:02.528843 20404 net.cpp:425] ReLU145 <- InnerProduct61
I0816 16:04:02.528863 20404 net.cpp:386] ReLU145 -> InnerProduct61 (in-place)
I0816 16:04:02.528877 20404 net.cpp:141] Setting up ReLU145
I0816 16:04:02.528887 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.528894 20404 net.cpp:156] Memory required for data: 2138118400
I0816 16:04:02.528903 20404 layer_factory.hpp:77] Creating layer InnerProduct62
I0816 16:04:02.528918 20404 net.cpp:91] Creating Layer InnerProduct62
I0816 16:04:02.528925 20404 net.cpp:425] InnerProduct62 <- InnerProduct61
I0816 16:04:02.528937 20404 net.cpp:399] InnerProduct62 -> InnerProduct62
I0816 16:04:02.529600 20404 net.cpp:141] Setting up InnerProduct62
I0816 16:04:02.529615 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.529623 20404 net.cpp:156] Memory required for data: 2138220800
I0816 16:04:02.529631 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:02.529641 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:02.529649 20404 layer_factory.hpp:77] Creating layer ReLU146
I0816 16:04:02.529659 20404 net.cpp:91] Creating Layer ReLU146
I0816 16:04:02.529667 20404 net.cpp:425] ReLU146 <- InnerProduct62
I0816 16:04:02.529678 20404 net.cpp:386] ReLU146 -> InnerProduct62 (in-place)
I0816 16:04:02.529708 20404 net.cpp:141] Setting up ReLU146
I0816 16:04:02.529719 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.529726 20404 net.cpp:156] Memory required for data: 2138323200
I0816 16:04:02.529733 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:02.529755 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:02.529764 20404 net.cpp:425] conv1 <- c11
I0816 16:04:02.529778 20404 net.cpp:399] conv1 -> Convolution106
I0816 16:04:02.531821 20404 net.cpp:141] Setting up conv1
I0816 16:04:02.531841 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.531847 20404 net.cpp:156] Memory required for data: 2148153600
I0816 16:04:02.531862 20404 layer_factory.hpp:77] Creating layer ReLU147
I0816 16:04:02.531873 20404 net.cpp:91] Creating Layer ReLU147
I0816 16:04:02.531882 20404 net.cpp:425] ReLU147 <- Convolution106
I0816 16:04:02.531896 20404 net.cpp:386] ReLU147 -> Convolution106 (in-place)
I0816 16:04:02.531909 20404 net.cpp:141] Setting up ReLU147
I0816 16:04:02.531920 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.531927 20404 net.cpp:156] Memory required for data: 2157984000
I0816 16:04:02.531935 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:02.531946 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:02.531955 20404 net.cpp:425] norm1 <- Convolution106
I0816 16:04:02.531971 20404 net.cpp:399] norm1 -> LRN43
I0816 16:04:02.532023 20404 net.cpp:141] Setting up norm1
I0816 16:04:02.532037 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.532044 20404 net.cpp:156] Memory required for data: 2167814400
I0816 16:04:02.532052 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:02.532065 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:02.532074 20404 net.cpp:425] pool1 <- LRN43
I0816 16:04:02.532085 20404 net.cpp:399] pool1 -> Pooling64
I0816 16:04:02.532146 20404 net.cpp:141] Setting up pool1
I0816 16:04:02.532160 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:02.532167 20404 net.cpp:156] Memory required for data: 2170272000
I0816 16:04:02.532176 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:02.532192 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:02.532202 20404 net.cpp:425] conv2 <- Pooling64
I0816 16:04:02.532214 20404 net.cpp:399] conv2 -> Convolution107
I0816 16:04:02.547653 20404 net.cpp:141] Setting up conv2
I0816 16:04:02.547675 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.547693 20404 net.cpp:156] Memory required for data: 2176825600
I0816 16:04:02.547708 20404 layer_factory.hpp:77] Creating layer ReLU148
I0816 16:04:02.547719 20404 net.cpp:91] Creating Layer ReLU148
I0816 16:04:02.547726 20404 net.cpp:425] ReLU148 <- Convolution107
I0816 16:04:02.547739 20404 net.cpp:386] ReLU148 -> Convolution107 (in-place)
I0816 16:04:02.547761 20404 net.cpp:141] Setting up ReLU148
I0816 16:04:02.547770 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.547778 20404 net.cpp:156] Memory required for data: 2183379200
I0816 16:04:02.547786 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:02.547801 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:02.547808 20404 net.cpp:425] norm2 <- Convolution107
I0816 16:04:02.547824 20404 net.cpp:399] norm2 -> LRN44
I0816 16:04:02.547885 20404 net.cpp:141] Setting up norm2
I0816 16:04:02.547899 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.547906 20404 net.cpp:156] Memory required for data: 2189932800
I0816 16:04:02.547914 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:02.547927 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:02.547935 20404 net.cpp:425] pool2 <- LRN44
I0816 16:04:02.547947 20404 net.cpp:399] pool2 -> Pooling65
I0816 16:04:02.548007 20404 net.cpp:141] Setting up pool2
I0816 16:04:02.548022 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.548028 20404 net.cpp:156] Memory required for data: 2191571200
I0816 16:04:02.548035 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:02.548070 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:02.548079 20404 net.cpp:425] conv3 <- Pooling65
I0816 16:04:02.548095 20404 net.cpp:399] conv3 -> Convolution108
I0816 16:04:02.591826 20404 net.cpp:141] Setting up conv3
I0816 16:04:02.591858 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.591876 20404 net.cpp:156] Memory required for data: 2194028800
I0816 16:04:02.591892 20404 layer_factory.hpp:77] Creating layer ReLU149
I0816 16:04:02.591910 20404 net.cpp:91] Creating Layer ReLU149
I0816 16:04:02.591920 20404 net.cpp:425] ReLU149 <- Convolution108
I0816 16:04:02.591934 20404 net.cpp:386] ReLU149 -> Convolution108 (in-place)
I0816 16:04:02.591958 20404 net.cpp:141] Setting up ReLU149
I0816 16:04:02.591969 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.591976 20404 net.cpp:156] Memory required for data: 2196486400
I0816 16:04:02.591984 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:02.592005 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:02.592013 20404 net.cpp:425] conv4 <- Convolution108
I0816 16:04:02.592027 20404 net.cpp:399] conv4 -> Convolution109
I0816 16:04:02.625125 20404 net.cpp:141] Setting up conv4
I0816 16:04:02.625154 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.625162 20404 net.cpp:156] Memory required for data: 2198944000
I0816 16:04:02.625185 20404 layer_factory.hpp:77] Creating layer ReLU150
I0816 16:04:02.625200 20404 net.cpp:91] Creating Layer ReLU150
I0816 16:04:02.625211 20404 net.cpp:425] ReLU150 <- Convolution109
I0816 16:04:02.625222 20404 net.cpp:386] ReLU150 -> Convolution109 (in-place)
I0816 16:04:02.625247 20404 net.cpp:141] Setting up ReLU150
I0816 16:04:02.625257 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.625265 20404 net.cpp:156] Memory required for data: 2201401600
I0816 16:04:02.625272 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:02.625293 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:02.625301 20404 net.cpp:425] conv5 <- Convolution109
I0816 16:04:02.625319 20404 net.cpp:399] conv5 -> Convolution110
I0816 16:04:02.647207 20404 net.cpp:141] Setting up conv5
I0816 16:04:02.647230 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.647238 20404 net.cpp:156] Memory required for data: 2203040000
I0816 16:04:02.647260 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:02.647287 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:02.647297 20404 net.cpp:425] pool5 <- Convolution110
I0816 16:04:02.647321 20404 net.cpp:399] pool5 -> Pooling66
I0816 16:04:02.647388 20404 net.cpp:141] Setting up pool5
I0816 16:04:02.647403 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:02.647410 20404 net.cpp:156] Memory required for data: 2203449600
I0816 16:04:02.647418 20404 layer_factory.hpp:77] Creating layer InnerProduct63
I0816 16:04:02.647435 20404 net.cpp:91] Creating Layer InnerProduct63
I0816 16:04:02.647444 20404 net.cpp:425] InnerProduct63 <- Pooling66
I0816 16:04:02.647459 20404 net.cpp:399] InnerProduct63 -> InnerProduct63
I0816 16:04:02.650182 20404 net.cpp:141] Setting up InnerProduct63
I0816 16:04:02.650202 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.650210 20404 net.cpp:156] Memory required for data: 2203552000
I0816 16:04:02.650220 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:02.650230 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:02.650239 20404 layer_factory.hpp:77] Creating layer ReLU151
I0816 16:04:02.650254 20404 net.cpp:91] Creating Layer ReLU151
I0816 16:04:02.650264 20404 net.cpp:425] ReLU151 <- InnerProduct63
I0816 16:04:02.650275 20404 net.cpp:386] ReLU151 -> InnerProduct63 (in-place)
I0816 16:04:02.650290 20404 net.cpp:141] Setting up ReLU151
I0816 16:04:02.650300 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.650306 20404 net.cpp:156] Memory required for data: 2203654400
I0816 16:04:02.650315 20404 layer_factory.hpp:77] Creating layer InnerProduct64
I0816 16:04:02.650329 20404 net.cpp:91] Creating Layer InnerProduct64
I0816 16:04:02.650360 20404 net.cpp:425] InnerProduct64 <- InnerProduct63
I0816 16:04:02.650373 20404 net.cpp:399] InnerProduct64 -> InnerProduct64
I0816 16:04:02.651036 20404 net.cpp:141] Setting up InnerProduct64
I0816 16:04:02.651049 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.651057 20404 net.cpp:156] Memory required for data: 2203756800
I0816 16:04:02.651067 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:02.651075 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:02.651083 20404 layer_factory.hpp:77] Creating layer ReLU152
I0816 16:04:02.651094 20404 net.cpp:91] Creating Layer ReLU152
I0816 16:04:02.651103 20404 net.cpp:425] ReLU152 <- InnerProduct64
I0816 16:04:02.651116 20404 net.cpp:386] ReLU152 -> InnerProduct64 (in-place)
I0816 16:04:02.651129 20404 net.cpp:141] Setting up ReLU152
I0816 16:04:02.651139 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.651146 20404 net.cpp:156] Memory required for data: 2203859200
I0816 16:04:02.651154 20404 layer_factory.hpp:77] Creating layer Concat11
I0816 16:04:02.651166 20404 net.cpp:91] Creating Layer Concat11
I0816 16:04:02.651175 20404 net.cpp:425] Concat11 <- InnerProduct62
I0816 16:04:02.651185 20404 net.cpp:425] Concat11 <- InnerProduct64
I0816 16:04:02.651196 20404 net.cpp:399] Concat11 -> Concat11
I0816 16:04:02.651237 20404 net.cpp:141] Setting up Concat11
I0816 16:04:02.651249 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:02.651257 20404 net.cpp:156] Memory required for data: 2204064000
I0816 16:04:02.651265 20404 layer_factory.hpp:77] Creating layer InnerProduct65
I0816 16:04:02.651288 20404 net.cpp:91] Creating Layer InnerProduct65
I0816 16:04:02.651296 20404 net.cpp:425] InnerProduct65 <- Concat11
I0816 16:04:02.651311 20404 net.cpp:399] InnerProduct65 -> InnerProduct65
I0816 16:04:02.652518 20404 net.cpp:141] Setting up InnerProduct65
I0816 16:04:02.652560 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.652588 20404 net.cpp:156] Memory required for data: 2204166400
I0816 16:04:02.652616 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:02.652648 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:02.652676 20404 layer_factory.hpp:77] Creating layer ReLU153
I0816 16:04:02.652710 20404 net.cpp:91] Creating Layer ReLU153
I0816 16:04:02.652739 20404 net.cpp:425] ReLU153 <- InnerProduct65
I0816 16:04:02.652756 20404 net.cpp:386] ReLU153 -> InnerProduct65 (in-place)
I0816 16:04:02.652770 20404 net.cpp:141] Setting up ReLU153
I0816 16:04:02.652781 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.652789 20404 net.cpp:156] Memory required for data: 2204268800
I0816 16:04:02.652796 20404 layer_factory.hpp:77] Creating layer InnerProduct66
I0816 16:04:02.652814 20404 net.cpp:91] Creating Layer InnerProduct66
I0816 16:04:02.652823 20404 net.cpp:425] InnerProduct66 <- InnerProduct65
I0816 16:04:02.652835 20404 net.cpp:399] InnerProduct66 -> InnerProduct66
I0816 16:04:02.653239 20404 net.cpp:141] Setting up InnerProduct66
I0816 16:04:02.653254 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:02.653261 20404 net.cpp:156] Memory required for data: 2204320000
I0816 16:04:02.653270 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:02.653280 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:02.653287 20404 layer_factory.hpp:77] Creating layer ReLU154
I0816 16:04:02.653297 20404 net.cpp:91] Creating Layer ReLU154
I0816 16:04:02.653306 20404 net.cpp:425] ReLU154 <- InnerProduct66
I0816 16:04:02.653316 20404 net.cpp:386] ReLU154 -> InnerProduct66 (in-place)
I0816 16:04:02.653328 20404 net.cpp:141] Setting up ReLU154
I0816 16:04:02.653338 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:02.653347 20404 net.cpp:156] Memory required for data: 2204371200
I0816 16:04:02.653367 20404 layer_factory.hpp:77] Creating layer dt10
I0816 16:04:02.653383 20404 net.cpp:91] Creating Layer dt10
I0816 16:04:02.653393 20404 net.cpp:425] dt10 <- InnerProduct66
I0816 16:04:02.653405 20404 net.cpp:399] dt10 -> dt10
I0816 16:04:02.653553 20404 net.cpp:141] Setting up dt10
I0816 16:04:02.653566 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:02.653574 20404 net.cpp:156] Memory required for data: 2204371600
I0816 16:04:02.653583 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:02.653591 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:02.653599 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:02.653615 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:02.653625 20404 net.cpp:425] conv1 <- p2_p2_0_split_2
I0816 16:04:02.653641 20404 net.cpp:399] conv1 -> Convolution111
I0816 16:04:02.656333 20404 net.cpp:141] Setting up conv1
I0816 16:04:02.656355 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.656363 20404 net.cpp:156] Memory required for data: 2214202000
I0816 16:04:02.656378 20404 layer_factory.hpp:77] Creating layer ReLU155
I0816 16:04:02.656394 20404 net.cpp:91] Creating Layer ReLU155
I0816 16:04:02.656402 20404 net.cpp:425] ReLU155 <- Convolution111
I0816 16:04:02.656414 20404 net.cpp:386] ReLU155 -> Convolution111 (in-place)
I0816 16:04:02.656429 20404 net.cpp:141] Setting up ReLU155
I0816 16:04:02.656438 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.656446 20404 net.cpp:156] Memory required for data: 2224032400
I0816 16:04:02.656453 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:02.656467 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:02.656476 20404 net.cpp:425] norm1 <- Convolution111
I0816 16:04:02.656489 20404 net.cpp:399] norm1 -> LRN45
I0816 16:04:02.656543 20404 net.cpp:141] Setting up norm1
I0816 16:04:02.656559 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.656566 20404 net.cpp:156] Memory required for data: 2233862800
I0816 16:04:02.656574 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:02.656725 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:02.656738 20404 net.cpp:425] pool1 <- LRN45
I0816 16:04:02.656749 20404 net.cpp:399] pool1 -> Pooling67
I0816 16:04:02.656806 20404 net.cpp:141] Setting up pool1
I0816 16:04:02.656821 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:02.656827 20404 net.cpp:156] Memory required for data: 2236320400
I0816 16:04:02.656836 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:02.656868 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:02.656880 20404 net.cpp:425] conv2 <- Pooling67
I0816 16:04:02.656893 20404 net.cpp:399] conv2 -> Convolution112
I0816 16:04:02.672298 20404 net.cpp:141] Setting up conv2
I0816 16:04:02.672323 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.672332 20404 net.cpp:156] Memory required for data: 2242874000
I0816 16:04:02.672356 20404 layer_factory.hpp:77] Creating layer ReLU156
I0816 16:04:02.672369 20404 net.cpp:91] Creating Layer ReLU156
I0816 16:04:02.672377 20404 net.cpp:425] ReLU156 <- Convolution112
I0816 16:04:02.672389 20404 net.cpp:386] ReLU156 -> Convolution112 (in-place)
I0816 16:04:02.672402 20404 net.cpp:141] Setting up ReLU156
I0816 16:04:02.672422 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.672430 20404 net.cpp:156] Memory required for data: 2249427600
I0816 16:04:02.672437 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:02.672452 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:02.672461 20404 net.cpp:425] norm2 <- Convolution112
I0816 16:04:02.672473 20404 net.cpp:399] norm2 -> LRN46
I0816 16:04:02.672536 20404 net.cpp:141] Setting up norm2
I0816 16:04:02.672550 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.672557 20404 net.cpp:156] Memory required for data: 2255981200
I0816 16:04:02.672565 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:02.672576 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:02.672600 20404 net.cpp:425] pool2 <- LRN46
I0816 16:04:02.672616 20404 net.cpp:399] pool2 -> Pooling68
I0816 16:04:02.672674 20404 net.cpp:141] Setting up pool2
I0816 16:04:02.672691 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.672698 20404 net.cpp:156] Memory required for data: 2257619600
I0816 16:04:02.672705 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:02.672721 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:02.672730 20404 net.cpp:425] conv3 <- Pooling68
I0816 16:04:02.672746 20404 net.cpp:399] conv3 -> Convolution113
I0816 16:04:02.716609 20404 net.cpp:141] Setting up conv3
I0816 16:04:02.716642 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.716660 20404 net.cpp:156] Memory required for data: 2260077200
I0816 16:04:02.716678 20404 layer_factory.hpp:77] Creating layer ReLU157
I0816 16:04:02.716694 20404 net.cpp:91] Creating Layer ReLU157
I0816 16:04:02.716706 20404 net.cpp:425] ReLU157 <- Convolution113
I0816 16:04:02.716723 20404 net.cpp:386] ReLU157 -> Convolution113 (in-place)
I0816 16:04:02.716742 20404 net.cpp:141] Setting up ReLU157
I0816 16:04:02.716752 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.716759 20404 net.cpp:156] Memory required for data: 2262534800
I0816 16:04:02.716768 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:02.716789 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:02.716797 20404 net.cpp:425] conv4 <- Convolution113
I0816 16:04:02.716814 20404 net.cpp:399] conv4 -> Convolution114
I0816 16:04:02.750221 20404 net.cpp:141] Setting up conv4
I0816 16:04:02.750252 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.750264 20404 net.cpp:156] Memory required for data: 2264992400
I0816 16:04:02.750282 20404 layer_factory.hpp:77] Creating layer ReLU158
I0816 16:04:02.750298 20404 net.cpp:91] Creating Layer ReLU158
I0816 16:04:02.750308 20404 net.cpp:425] ReLU158 <- Convolution114
I0816 16:04:02.750324 20404 net.cpp:386] ReLU158 -> Convolution114 (in-place)
I0816 16:04:02.750341 20404 net.cpp:141] Setting up ReLU158
I0816 16:04:02.750352 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.750360 20404 net.cpp:156] Memory required for data: 2267450000
I0816 16:04:02.750366 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:02.750386 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:02.750396 20404 net.cpp:425] conv5 <- Convolution114
I0816 16:04:02.750408 20404 net.cpp:399] conv5 -> Convolution115
I0816 16:04:02.772884 20404 net.cpp:141] Setting up conv5
I0816 16:04:02.772922 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.772930 20404 net.cpp:156] Memory required for data: 2269088400
I0816 16:04:02.772946 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:02.772963 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:02.772972 20404 net.cpp:425] pool5 <- Convolution115
I0816 16:04:02.772991 20404 net.cpp:399] pool5 -> Pooling69
I0816 16:04:02.773058 20404 net.cpp:141] Setting up pool5
I0816 16:04:02.773072 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:02.773080 20404 net.cpp:156] Memory required for data: 2269498000
I0816 16:04:02.773087 20404 layer_factory.hpp:77] Creating layer InnerProduct67
I0816 16:04:02.773104 20404 net.cpp:91] Creating Layer InnerProduct67
I0816 16:04:02.773113 20404 net.cpp:425] InnerProduct67 <- Pooling69
I0816 16:04:02.773129 20404 net.cpp:399] InnerProduct67 -> InnerProduct67
I0816 16:04:02.775926 20404 net.cpp:141] Setting up InnerProduct67
I0816 16:04:02.775949 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.775959 20404 net.cpp:156] Memory required for data: 2269600400
I0816 16:04:02.775969 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:02.775979 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:02.775987 20404 layer_factory.hpp:77] Creating layer ReLU159
I0816 16:04:02.776000 20404 net.cpp:91] Creating Layer ReLU159
I0816 16:04:02.776010 20404 net.cpp:425] ReLU159 <- InnerProduct67
I0816 16:04:02.776041 20404 net.cpp:386] ReLU159 -> InnerProduct67 (in-place)
I0816 16:04:02.776062 20404 net.cpp:141] Setting up ReLU159
I0816 16:04:02.776077 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.776083 20404 net.cpp:156] Memory required for data: 2269702800
I0816 16:04:02.776092 20404 layer_factory.hpp:77] Creating layer InnerProduct68
I0816 16:04:02.776103 20404 net.cpp:91] Creating Layer InnerProduct68
I0816 16:04:02.776113 20404 net.cpp:425] InnerProduct68 <- InnerProduct67
I0816 16:04:02.776127 20404 net.cpp:399] InnerProduct68 -> InnerProduct68
I0816 16:04:02.776798 20404 net.cpp:141] Setting up InnerProduct68
I0816 16:04:02.776813 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.776820 20404 net.cpp:156] Memory required for data: 2269805200
I0816 16:04:02.776829 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:02.776839 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:02.776846 20404 layer_factory.hpp:77] Creating layer ReLU160
I0816 16:04:02.776856 20404 net.cpp:91] Creating Layer ReLU160
I0816 16:04:02.776865 20404 net.cpp:425] ReLU160 <- InnerProduct68
I0816 16:04:02.776875 20404 net.cpp:386] ReLU160 -> InnerProduct68 (in-place)
I0816 16:04:02.776887 20404 net.cpp:141] Setting up ReLU160
I0816 16:04:02.776897 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.776906 20404 net.cpp:156] Memory required for data: 2269907600
I0816 16:04:02.776912 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:02.776932 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:02.776942 20404 net.cpp:425] conv1 <- c12
I0816 16:04:02.776959 20404 net.cpp:399] conv1 -> Convolution116
I0816 16:04:02.778996 20404 net.cpp:141] Setting up conv1
I0816 16:04:02.779011 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.779028 20404 net.cpp:156] Memory required for data: 2279738000
I0816 16:04:02.779042 20404 layer_factory.hpp:77] Creating layer ReLU161
I0816 16:04:02.779052 20404 net.cpp:91] Creating Layer ReLU161
I0816 16:04:02.779060 20404 net.cpp:425] ReLU161 <- Convolution116
I0816 16:04:02.779072 20404 net.cpp:386] ReLU161 -> Convolution116 (in-place)
I0816 16:04:02.779093 20404 net.cpp:141] Setting up ReLU161
I0816 16:04:02.779103 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.779109 20404 net.cpp:156] Memory required for data: 2289568400
I0816 16:04:02.779117 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:02.779131 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:02.779139 20404 net.cpp:425] norm1 <- Convolution116
I0816 16:04:02.779152 20404 net.cpp:399] norm1 -> LRN47
I0816 16:04:02.779209 20404 net.cpp:141] Setting up norm1
I0816 16:04:02.779223 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.779232 20404 net.cpp:156] Memory required for data: 2299398800
I0816 16:04:02.779239 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:02.779250 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:02.779258 20404 net.cpp:425] pool1 <- LRN47
I0816 16:04:02.779287 20404 net.cpp:399] pool1 -> Pooling70
I0816 16:04:02.779352 20404 net.cpp:141] Setting up pool1
I0816 16:04:02.779367 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:02.779374 20404 net.cpp:156] Memory required for data: 2301856400
I0816 16:04:02.779382 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:02.779402 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:02.779415 20404 net.cpp:425] conv2 <- Pooling70
I0816 16:04:02.779428 20404 net.cpp:399] conv2 -> Convolution117
I0816 16:04:02.795074 20404 net.cpp:141] Setting up conv2
I0816 16:04:02.795102 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.795111 20404 net.cpp:156] Memory required for data: 2308410000
I0816 16:04:02.795136 20404 layer_factory.hpp:77] Creating layer ReLU162
I0816 16:04:02.795150 20404 net.cpp:91] Creating Layer ReLU162
I0816 16:04:02.795161 20404 net.cpp:425] ReLU162 <- Convolution117
I0816 16:04:02.795194 20404 net.cpp:386] ReLU162 -> Convolution117 (in-place)
I0816 16:04:02.795210 20404 net.cpp:141] Setting up ReLU162
I0816 16:04:02.795222 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.795229 20404 net.cpp:156] Memory required for data: 2314963600
I0816 16:04:02.795238 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:02.795253 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:02.795261 20404 net.cpp:425] norm2 <- Convolution117
I0816 16:04:02.795279 20404 net.cpp:399] norm2 -> LRN48
I0816 16:04:02.795346 20404 net.cpp:141] Setting up norm2
I0816 16:04:02.795361 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.795368 20404 net.cpp:156] Memory required for data: 2321517200
I0816 16:04:02.795377 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:02.795387 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:02.795394 20404 net.cpp:425] pool2 <- LRN48
I0816 16:04:02.795409 20404 net.cpp:399] pool2 -> Pooling71
I0816 16:04:02.795470 20404 net.cpp:141] Setting up pool2
I0816 16:04:02.795490 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.795496 20404 net.cpp:156] Memory required for data: 2323155600
I0816 16:04:02.795505 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:02.795522 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:02.795531 20404 net.cpp:425] conv3 <- Pooling71
I0816 16:04:02.795544 20404 net.cpp:399] conv3 -> Convolution118
I0816 16:04:02.839210 20404 net.cpp:141] Setting up conv3
I0816 16:04:02.839243 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.839262 20404 net.cpp:156] Memory required for data: 2325613200
I0816 16:04:02.839296 20404 layer_factory.hpp:77] Creating layer ReLU163
I0816 16:04:02.839314 20404 net.cpp:91] Creating Layer ReLU163
I0816 16:04:02.839334 20404 net.cpp:425] ReLU163 <- Convolution118
I0816 16:04:02.839349 20404 net.cpp:386] ReLU163 -> Convolution118 (in-place)
I0816 16:04:02.839367 20404 net.cpp:141] Setting up ReLU163
I0816 16:04:02.839382 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.839390 20404 net.cpp:156] Memory required for data: 2328070800
I0816 16:04:02.839398 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:02.839416 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:02.839424 20404 net.cpp:425] conv4 <- Convolution118
I0816 16:04:02.839442 20404 net.cpp:399] conv4 -> Convolution119
I0816 16:04:02.872544 20404 net.cpp:141] Setting up conv4
I0816 16:04:02.872573 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.872584 20404 net.cpp:156] Memory required for data: 2330528400
I0816 16:04:02.872601 20404 layer_factory.hpp:77] Creating layer ReLU164
I0816 16:04:02.872615 20404 net.cpp:91] Creating Layer ReLU164
I0816 16:04:02.872625 20404 net.cpp:425] ReLU164 <- Convolution119
I0816 16:04:02.872642 20404 net.cpp:386] ReLU164 -> Convolution119 (in-place)
I0816 16:04:02.872658 20404 net.cpp:141] Setting up ReLU164
I0816 16:04:02.872668 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.872675 20404 net.cpp:156] Memory required for data: 2332986000
I0816 16:04:02.872684 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:02.872704 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:02.872712 20404 net.cpp:425] conv5 <- Convolution119
I0816 16:04:02.872725 20404 net.cpp:399] conv5 -> Convolution120
I0816 16:04:02.894856 20404 net.cpp:141] Setting up conv5
I0816 16:04:02.894881 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.894889 20404 net.cpp:156] Memory required for data: 2334624400
I0816 16:04:02.894912 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:02.894927 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:02.894935 20404 net.cpp:425] pool5 <- Convolution120
I0816 16:04:02.894956 20404 net.cpp:399] pool5 -> Pooling72
I0816 16:04:02.895022 20404 net.cpp:141] Setting up pool5
I0816 16:04:02.895036 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:02.895045 20404 net.cpp:156] Memory required for data: 2335034000
I0816 16:04:02.895053 20404 layer_factory.hpp:77] Creating layer InnerProduct69
I0816 16:04:02.895087 20404 net.cpp:91] Creating Layer InnerProduct69
I0816 16:04:02.895100 20404 net.cpp:425] InnerProduct69 <- Pooling72
I0816 16:04:02.895117 20404 net.cpp:399] InnerProduct69 -> InnerProduct69
I0816 16:04:02.897852 20404 net.cpp:141] Setting up InnerProduct69
I0816 16:04:02.897873 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.897881 20404 net.cpp:156] Memory required for data: 2335136400
I0816 16:04:02.897891 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:02.897902 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:02.897910 20404 layer_factory.hpp:77] Creating layer ReLU165
I0816 16:04:02.897922 20404 net.cpp:91] Creating Layer ReLU165
I0816 16:04:02.897930 20404 net.cpp:425] ReLU165 <- InnerProduct69
I0816 16:04:02.897945 20404 net.cpp:386] ReLU165 -> InnerProduct69 (in-place)
I0816 16:04:02.897959 20404 net.cpp:141] Setting up ReLU165
I0816 16:04:02.897970 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.897977 20404 net.cpp:156] Memory required for data: 2335238800
I0816 16:04:02.897985 20404 layer_factory.hpp:77] Creating layer InnerProduct70
I0816 16:04:02.897997 20404 net.cpp:91] Creating Layer InnerProduct70
I0816 16:04:02.898006 20404 net.cpp:425] InnerProduct70 <- InnerProduct69
I0816 16:04:02.898022 20404 net.cpp:399] InnerProduct70 -> InnerProduct70
I0816 16:04:02.898687 20404 net.cpp:141] Setting up InnerProduct70
I0816 16:04:02.898702 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.898710 20404 net.cpp:156] Memory required for data: 2335341200
I0816 16:04:02.898717 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:02.898727 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:02.898736 20404 layer_factory.hpp:77] Creating layer ReLU166
I0816 16:04:02.898746 20404 net.cpp:91] Creating Layer ReLU166
I0816 16:04:02.898754 20404 net.cpp:425] ReLU166 <- InnerProduct70
I0816 16:04:02.898764 20404 net.cpp:386] ReLU166 -> InnerProduct70 (in-place)
I0816 16:04:02.898777 20404 net.cpp:141] Setting up ReLU166
I0816 16:04:02.898787 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.898795 20404 net.cpp:156] Memory required for data: 2335443600
I0816 16:04:02.898802 20404 layer_factory.hpp:77] Creating layer Concat12
I0816 16:04:02.898814 20404 net.cpp:91] Creating Layer Concat12
I0816 16:04:02.898823 20404 net.cpp:425] Concat12 <- InnerProduct68
I0816 16:04:02.898833 20404 net.cpp:425] Concat12 <- InnerProduct70
I0816 16:04:02.898847 20404 net.cpp:399] Concat12 -> Concat12
I0816 16:04:02.898888 20404 net.cpp:141] Setting up Concat12
I0816 16:04:02.898902 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:02.898910 20404 net.cpp:156] Memory required for data: 2335648400
I0816 16:04:02.898917 20404 layer_factory.hpp:77] Creating layer InnerProduct71
I0816 16:04:02.898929 20404 net.cpp:91] Creating Layer InnerProduct71
I0816 16:04:02.898937 20404 net.cpp:425] InnerProduct71 <- Concat12
I0816 16:04:02.898952 20404 net.cpp:399] InnerProduct71 -> InnerProduct71
I0816 16:04:02.900887 20404 net.cpp:141] Setting up InnerProduct71
I0816 16:04:02.900909 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.900918 20404 net.cpp:156] Memory required for data: 2335750800
I0816 16:04:02.900928 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:02.900938 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:02.900946 20404 layer_factory.hpp:77] Creating layer ReLU167
I0816 16:04:02.900957 20404 net.cpp:91] Creating Layer ReLU167
I0816 16:04:02.900966 20404 net.cpp:425] ReLU167 <- InnerProduct71
I0816 16:04:02.900981 20404 net.cpp:386] ReLU167 -> InnerProduct71 (in-place)
I0816 16:04:02.900995 20404 net.cpp:141] Setting up ReLU167
I0816 16:04:02.901006 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:02.901027 20404 net.cpp:156] Memory required for data: 2335853200
I0816 16:04:02.901036 20404 layer_factory.hpp:77] Creating layer InnerProduct72
I0816 16:04:02.901049 20404 net.cpp:91] Creating Layer InnerProduct72
I0816 16:04:02.901057 20404 net.cpp:425] InnerProduct72 <- InnerProduct71
I0816 16:04:02.901077 20404 net.cpp:399] InnerProduct72 -> InnerProduct72
I0816 16:04:02.901482 20404 net.cpp:141] Setting up InnerProduct72
I0816 16:04:02.901496 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:02.901504 20404 net.cpp:156] Memory required for data: 2335904400
I0816 16:04:02.901512 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:02.901522 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:02.901530 20404 layer_factory.hpp:77] Creating layer ReLU168
I0816 16:04:02.901540 20404 net.cpp:91] Creating Layer ReLU168
I0816 16:04:02.901548 20404 net.cpp:425] ReLU168 <- InnerProduct72
I0816 16:04:02.901562 20404 net.cpp:386] ReLU168 -> InnerProduct72 (in-place)
I0816 16:04:02.901576 20404 net.cpp:141] Setting up ReLU168
I0816 16:04:02.901585 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:02.901593 20404 net.cpp:156] Memory required for data: 2335955600
I0816 16:04:02.901600 20404 layer_factory.hpp:77] Creating layer dt11
I0816 16:04:02.901612 20404 net.cpp:91] Creating Layer dt11
I0816 16:04:02.901619 20404 net.cpp:425] dt11 <- InnerProduct72
I0816 16:04:02.901633 20404 net.cpp:399] dt11 -> dt11
I0816 16:04:02.901785 20404 net.cpp:141] Setting up dt11
I0816 16:04:02.901799 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:02.901808 20404 net.cpp:156] Memory required for data: 2335956000
I0816 16:04:02.901815 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:02.901825 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:02.901834 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:02.901854 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:02.901867 20404 net.cpp:425] conv1 <- p2_p2_0_split_3
I0816 16:04:02.901881 20404 net.cpp:399] conv1 -> Convolution121
I0816 16:04:02.904567 20404 net.cpp:141] Setting up conv1
I0816 16:04:02.904587 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.904595 20404 net.cpp:156] Memory required for data: 2345786400
I0816 16:04:02.904609 20404 layer_factory.hpp:77] Creating layer ReLU169
I0816 16:04:02.904624 20404 net.cpp:91] Creating Layer ReLU169
I0816 16:04:02.904633 20404 net.cpp:425] ReLU169 <- Convolution121
I0816 16:04:02.904645 20404 net.cpp:386] ReLU169 -> Convolution121 (in-place)
I0816 16:04:02.904659 20404 net.cpp:141] Setting up ReLU169
I0816 16:04:02.904670 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.904677 20404 net.cpp:156] Memory required for data: 2355616800
I0816 16:04:02.904685 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:02.904696 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:02.904705 20404 net.cpp:425] norm1 <- Convolution121
I0816 16:04:02.904721 20404 net.cpp:399] norm1 -> LRN49
I0816 16:04:02.904777 20404 net.cpp:141] Setting up norm1
I0816 16:04:02.904790 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:02.904798 20404 net.cpp:156] Memory required for data: 2365447200
I0816 16:04:02.904805 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:02.904819 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:02.904827 20404 net.cpp:425] pool1 <- LRN49
I0816 16:04:02.904839 20404 net.cpp:399] pool1 -> Pooling73
I0816 16:04:02.904908 20404 net.cpp:141] Setting up pool1
I0816 16:04:02.904922 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:02.904929 20404 net.cpp:156] Memory required for data: 2367904800
I0816 16:04:02.904937 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:02.904956 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:02.904965 20404 net.cpp:425] conv2 <- Pooling73
I0816 16:04:02.904983 20404 net.cpp:399] conv2 -> Convolution122
I0816 16:04:02.920706 20404 net.cpp:141] Setting up conv2
I0816 16:04:02.920729 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.920737 20404 net.cpp:156] Memory required for data: 2374458400
I0816 16:04:02.920753 20404 layer_factory.hpp:77] Creating layer ReLU170
I0816 16:04:02.920765 20404 net.cpp:91] Creating Layer ReLU170
I0816 16:04:02.920778 20404 net.cpp:425] ReLU170 <- Convolution122
I0816 16:04:02.920794 20404 net.cpp:386] ReLU170 -> Convolution122 (in-place)
I0816 16:04:02.920809 20404 net.cpp:141] Setting up ReLU170
I0816 16:04:02.920819 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.920826 20404 net.cpp:156] Memory required for data: 2381012000
I0816 16:04:02.920835 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:02.920848 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:02.920856 20404 net.cpp:425] norm2 <- Convolution122
I0816 16:04:02.920869 20404 net.cpp:399] norm2 -> LRN50
I0816 16:04:02.920933 20404 net.cpp:141] Setting up norm2
I0816 16:04:02.920946 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:02.920953 20404 net.cpp:156] Memory required for data: 2387565600
I0816 16:04:02.920960 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:02.920971 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:02.920979 20404 net.cpp:425] pool2 <- LRN50
I0816 16:04:02.920991 20404 net.cpp:399] pool2 -> Pooling74
I0816 16:04:02.921053 20404 net.cpp:141] Setting up pool2
I0816 16:04:02.921067 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:02.921075 20404 net.cpp:156] Memory required for data: 2389204000
I0816 16:04:02.921082 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:02.921103 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:02.921115 20404 net.cpp:425] conv3 <- Pooling74
I0816 16:04:02.921129 20404 net.cpp:399] conv3 -> Convolution123
I0816 16:04:02.965185 20404 net.cpp:141] Setting up conv3
I0816 16:04:02.965219 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.965237 20404 net.cpp:156] Memory required for data: 2391661600
I0816 16:04:02.965255 20404 layer_factory.hpp:77] Creating layer ReLU171
I0816 16:04:02.965270 20404 net.cpp:91] Creating Layer ReLU171
I0816 16:04:02.965281 20404 net.cpp:425] ReLU171 <- Convolution123
I0816 16:04:02.965299 20404 net.cpp:386] ReLU171 -> Convolution123 (in-place)
I0816 16:04:02.965317 20404 net.cpp:141] Setting up ReLU171
I0816 16:04:02.965327 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.965335 20404 net.cpp:156] Memory required for data: 2394119200
I0816 16:04:02.965343 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:02.965364 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:02.965373 20404 net.cpp:425] conv4 <- Convolution123
I0816 16:04:02.965389 20404 net.cpp:399] conv4 -> Convolution124
I0816 16:04:02.998744 20404 net.cpp:141] Setting up conv4
I0816 16:04:02.998775 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.998783 20404 net.cpp:156] Memory required for data: 2396576800
I0816 16:04:02.998816 20404 layer_factory.hpp:77] Creating layer ReLU172
I0816 16:04:02.998831 20404 net.cpp:91] Creating Layer ReLU172
I0816 16:04:02.998842 20404 net.cpp:425] ReLU172 <- Convolution124
I0816 16:04:02.998854 20404 net.cpp:386] ReLU172 -> Convolution124 (in-place)
I0816 16:04:02.998872 20404 net.cpp:141] Setting up ReLU172
I0816 16:04:02.998881 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:02.998889 20404 net.cpp:156] Memory required for data: 2399034400
I0816 16:04:02.998898 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:02.998917 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:02.998926 20404 net.cpp:425] conv5 <- Convolution124
I0816 16:04:02.998940 20404 net.cpp:399] conv5 -> Convolution125
I0816 16:04:03.021419 20404 net.cpp:141] Setting up conv5
I0816 16:04:03.021452 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.021461 20404 net.cpp:156] Memory required for data: 2400672800
I0816 16:04:03.021477 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:03.021512 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:03.021524 20404 net.cpp:425] pool5 <- Convolution125
I0816 16:04:03.021543 20404 net.cpp:399] pool5 -> Pooling75
I0816 16:04:03.021615 20404 net.cpp:141] Setting up pool5
I0816 16:04:03.021631 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:03.021638 20404 net.cpp:156] Memory required for data: 2401082400
I0816 16:04:03.021646 20404 layer_factory.hpp:77] Creating layer InnerProduct73
I0816 16:04:03.021661 20404 net.cpp:91] Creating Layer InnerProduct73
I0816 16:04:03.021668 20404 net.cpp:425] InnerProduct73 <- Pooling75
I0816 16:04:03.021685 20404 net.cpp:399] InnerProduct73 -> InnerProduct73
I0816 16:04:03.024467 20404 net.cpp:141] Setting up InnerProduct73
I0816 16:04:03.024488 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.024503 20404 net.cpp:156] Memory required for data: 2401184800
I0816 16:04:03.024514 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:03.024524 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:03.024533 20404 layer_factory.hpp:77] Creating layer ReLU173
I0816 16:04:03.024544 20404 net.cpp:91] Creating Layer ReLU173
I0816 16:04:03.024554 20404 net.cpp:425] ReLU173 <- InnerProduct73
I0816 16:04:03.024569 20404 net.cpp:386] ReLU173 -> InnerProduct73 (in-place)
I0816 16:04:03.024585 20404 net.cpp:141] Setting up ReLU173
I0816 16:04:03.024595 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.024602 20404 net.cpp:156] Memory required for data: 2401287200
I0816 16:04:03.024610 20404 layer_factory.hpp:77] Creating layer InnerProduct74
I0816 16:04:03.024623 20404 net.cpp:91] Creating Layer InnerProduct74
I0816 16:04:03.024631 20404 net.cpp:425] InnerProduct74 <- InnerProduct73
I0816 16:04:03.024646 20404 net.cpp:399] InnerProduct74 -> InnerProduct74
I0816 16:04:03.025313 20404 net.cpp:141] Setting up InnerProduct74
I0816 16:04:03.025327 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.025338 20404 net.cpp:156] Memory required for data: 2401389600
I0816 16:04:03.025346 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:03.025357 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:03.025364 20404 layer_factory.hpp:77] Creating layer ReLU174
I0816 16:04:03.025378 20404 net.cpp:91] Creating Layer ReLU174
I0816 16:04:03.025387 20404 net.cpp:425] ReLU174 <- InnerProduct74
I0816 16:04:03.025398 20404 net.cpp:386] ReLU174 -> InnerProduct74 (in-place)
I0816 16:04:03.025410 20404 net.cpp:141] Setting up ReLU174
I0816 16:04:03.025420 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.025427 20404 net.cpp:156] Memory required for data: 2401492000
I0816 16:04:03.025435 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:03.025452 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:03.025461 20404 net.cpp:425] conv1 <- c13
I0816 16:04:03.025478 20404 net.cpp:399] conv1 -> Convolution126
I0816 16:04:03.027493 20404 net.cpp:141] Setting up conv1
I0816 16:04:03.027508 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.027516 20404 net.cpp:156] Memory required for data: 2411322400
I0816 16:04:03.027535 20404 layer_factory.hpp:77] Creating layer ReLU175
I0816 16:04:03.027545 20404 net.cpp:91] Creating Layer ReLU175
I0816 16:04:03.027554 20404 net.cpp:425] ReLU175 <- Convolution126
I0816 16:04:03.027565 20404 net.cpp:386] ReLU175 -> Convolution126 (in-place)
I0816 16:04:03.027577 20404 net.cpp:141] Setting up ReLU175
I0816 16:04:03.027595 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.027602 20404 net.cpp:156] Memory required for data: 2421152800
I0816 16:04:03.027611 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:03.027624 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:03.027632 20404 net.cpp:425] norm1 <- Convolution126
I0816 16:04:03.027647 20404 net.cpp:399] norm1 -> LRN51
I0816 16:04:03.027705 20404 net.cpp:141] Setting up norm1
I0816 16:04:03.027732 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.027740 20404 net.cpp:156] Memory required for data: 2430983200
I0816 16:04:03.027747 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:03.027758 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:03.027766 20404 net.cpp:425] pool1 <- LRN51
I0816 16:04:03.027781 20404 net.cpp:399] pool1 -> Pooling76
I0816 16:04:03.027842 20404 net.cpp:141] Setting up pool1
I0816 16:04:03.027858 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:03.027865 20404 net.cpp:156] Memory required for data: 2433440800
I0816 16:04:03.027873 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:03.027887 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:03.027895 20404 net.cpp:425] conv2 <- Pooling76
I0816 16:04:03.027912 20404 net.cpp:399] conv2 -> Convolution127
I0816 16:04:03.043603 20404 net.cpp:141] Setting up conv2
I0816 16:04:03.043627 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.043634 20404 net.cpp:156] Memory required for data: 2439994400
I0816 16:04:03.043648 20404 layer_factory.hpp:77] Creating layer ReLU176
I0816 16:04:03.043666 20404 net.cpp:91] Creating Layer ReLU176
I0816 16:04:03.043676 20404 net.cpp:425] ReLU176 <- Convolution127
I0816 16:04:03.043689 20404 net.cpp:386] ReLU176 -> Convolution127 (in-place)
I0816 16:04:03.043702 20404 net.cpp:141] Setting up ReLU176
I0816 16:04:03.043714 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.043720 20404 net.cpp:156] Memory required for data: 2446548000
I0816 16:04:03.043728 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:03.043742 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:03.043751 20404 net.cpp:425] norm2 <- Convolution127
I0816 16:04:03.043762 20404 net.cpp:399] norm2 -> LRN52
I0816 16:04:03.043826 20404 net.cpp:141] Setting up norm2
I0816 16:04:03.043840 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.043848 20404 net.cpp:156] Memory required for data: 2453101600
I0816 16:04:03.043855 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:03.043865 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:03.043874 20404 net.cpp:425] pool2 <- LRN52
I0816 16:04:03.043889 20404 net.cpp:399] pool2 -> Pooling77
I0816 16:04:03.043949 20404 net.cpp:141] Setting up pool2
I0816 16:04:03.043963 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.043972 20404 net.cpp:156] Memory required for data: 2454740000
I0816 16:04:03.043978 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:03.044000 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:03.044013 20404 net.cpp:425] conv3 <- Pooling77
I0816 16:04:03.044025 20404 net.cpp:399] conv3 -> Convolution128
I0816 16:04:03.088232 20404 net.cpp:141] Setting up conv3
I0816 16:04:03.088264 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.088284 20404 net.cpp:156] Memory required for data: 2457197600
I0816 16:04:03.088300 20404 layer_factory.hpp:77] Creating layer ReLU177
I0816 16:04:03.088315 20404 net.cpp:91] Creating Layer ReLU177
I0816 16:04:03.088327 20404 net.cpp:425] ReLU177 <- Convolution128
I0816 16:04:03.088340 20404 net.cpp:386] ReLU177 -> Convolution128 (in-place)
I0816 16:04:03.088364 20404 net.cpp:141] Setting up ReLU177
I0816 16:04:03.088376 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.088382 20404 net.cpp:156] Memory required for data: 2459655200
I0816 16:04:03.088390 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:03.088412 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:03.088420 20404 net.cpp:425] conv4 <- Convolution128
I0816 16:04:03.088436 20404 net.cpp:399] conv4 -> Convolution129
I0816 16:04:03.121665 20404 net.cpp:141] Setting up conv4
I0816 16:04:03.121693 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.121712 20404 net.cpp:156] Memory required for data: 2462112800
I0816 16:04:03.121728 20404 layer_factory.hpp:77] Creating layer ReLU178
I0816 16:04:03.121744 20404 net.cpp:91] Creating Layer ReLU178
I0816 16:04:03.121788 20404 net.cpp:425] ReLU178 <- Convolution129
I0816 16:04:03.121801 20404 net.cpp:386] ReLU178 -> Convolution129 (in-place)
I0816 16:04:03.121817 20404 net.cpp:141] Setting up ReLU178
I0816 16:04:03.121831 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.121839 20404 net.cpp:156] Memory required for data: 2464570400
I0816 16:04:03.121847 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:03.121873 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:03.121887 20404 net.cpp:425] conv5 <- Convolution129
I0816 16:04:03.121904 20404 net.cpp:399] conv5 -> Convolution130
I0816 16:04:03.143805 20404 net.cpp:141] Setting up conv5
I0816 16:04:03.143827 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.143846 20404 net.cpp:156] Memory required for data: 2466208800
I0816 16:04:03.143860 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:03.143873 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:03.143882 20404 net.cpp:425] pool5 <- Convolution130
I0816 16:04:03.143899 20404 net.cpp:399] pool5 -> Pooling78
I0816 16:04:03.143973 20404 net.cpp:141] Setting up pool5
I0816 16:04:03.143990 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:03.143997 20404 net.cpp:156] Memory required for data: 2466618400
I0816 16:04:03.144004 20404 layer_factory.hpp:77] Creating layer InnerProduct75
I0816 16:04:03.144019 20404 net.cpp:91] Creating Layer InnerProduct75
I0816 16:04:03.144027 20404 net.cpp:425] InnerProduct75 <- Pooling78
I0816 16:04:03.144044 20404 net.cpp:399] InnerProduct75 -> InnerProduct75
I0816 16:04:03.146775 20404 net.cpp:141] Setting up InnerProduct75
I0816 16:04:03.146795 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.146803 20404 net.cpp:156] Memory required for data: 2466720800
I0816 16:04:03.146814 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:03.146824 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:03.146832 20404 layer_factory.hpp:77] Creating layer ReLU179
I0816 16:04:03.146844 20404 net.cpp:91] Creating Layer ReLU179
I0816 16:04:03.146853 20404 net.cpp:425] ReLU179 <- InnerProduct75
I0816 16:04:03.146867 20404 net.cpp:386] ReLU179 -> InnerProduct75 (in-place)
I0816 16:04:03.146883 20404 net.cpp:141] Setting up ReLU179
I0816 16:04:03.146893 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.146900 20404 net.cpp:156] Memory required for data: 2466823200
I0816 16:04:03.146908 20404 layer_factory.hpp:77] Creating layer InnerProduct76
I0816 16:04:03.146919 20404 net.cpp:91] Creating Layer InnerProduct76
I0816 16:04:03.146927 20404 net.cpp:425] InnerProduct76 <- InnerProduct75
I0816 16:04:03.146942 20404 net.cpp:399] InnerProduct76 -> InnerProduct76
I0816 16:04:03.147621 20404 net.cpp:141] Setting up InnerProduct76
I0816 16:04:03.147636 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.147644 20404 net.cpp:156] Memory required for data: 2466925600
I0816 16:04:03.147652 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:03.147662 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:03.147670 20404 layer_factory.hpp:77] Creating layer ReLU180
I0816 16:04:03.147685 20404 net.cpp:91] Creating Layer ReLU180
I0816 16:04:03.147692 20404 net.cpp:425] ReLU180 <- InnerProduct76
I0816 16:04:03.147703 20404 net.cpp:386] ReLU180 -> InnerProduct76 (in-place)
I0816 16:04:03.147716 20404 net.cpp:141] Setting up ReLU180
I0816 16:04:03.147725 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.147733 20404 net.cpp:156] Memory required for data: 2467028000
I0816 16:04:03.147742 20404 layer_factory.hpp:77] Creating layer Concat13
I0816 16:04:03.147753 20404 net.cpp:91] Creating Layer Concat13
I0816 16:04:03.147760 20404 net.cpp:425] Concat13 <- InnerProduct74
I0816 16:04:03.147770 20404 net.cpp:425] Concat13 <- InnerProduct76
I0816 16:04:03.147783 20404 net.cpp:399] Concat13 -> Concat13
I0816 16:04:03.147825 20404 net.cpp:141] Setting up Concat13
I0816 16:04:03.147851 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:03.147858 20404 net.cpp:156] Memory required for data: 2467232800
I0816 16:04:03.147866 20404 layer_factory.hpp:77] Creating layer InnerProduct77
I0816 16:04:03.147881 20404 net.cpp:91] Creating Layer InnerProduct77
I0816 16:04:03.147889 20404 net.cpp:425] InnerProduct77 <- Concat13
I0816 16:04:03.147907 20404 net.cpp:399] InnerProduct77 -> InnerProduct77
I0816 16:04:03.149111 20404 net.cpp:141] Setting up InnerProduct77
I0816 16:04:03.149130 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.149138 20404 net.cpp:156] Memory required for data: 2467335200
I0816 16:04:03.149147 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:03.149158 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:03.149165 20404 layer_factory.hpp:77] Creating layer ReLU181
I0816 16:04:03.149176 20404 net.cpp:91] Creating Layer ReLU181
I0816 16:04:03.149185 20404 net.cpp:425] ReLU181 <- InnerProduct77
I0816 16:04:03.149197 20404 net.cpp:386] ReLU181 -> InnerProduct77 (in-place)
I0816 16:04:03.149211 20404 net.cpp:141] Setting up ReLU181
I0816 16:04:03.149221 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.149229 20404 net.cpp:156] Memory required for data: 2467437600
I0816 16:04:03.149236 20404 layer_factory.hpp:77] Creating layer InnerProduct78
I0816 16:04:03.149248 20404 net.cpp:91] Creating Layer InnerProduct78
I0816 16:04:03.149256 20404 net.cpp:425] InnerProduct78 <- InnerProduct77
I0816 16:04:03.149271 20404 net.cpp:399] InnerProduct78 -> InnerProduct78
I0816 16:04:03.149677 20404 net.cpp:141] Setting up InnerProduct78
I0816 16:04:03.149690 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:03.149698 20404 net.cpp:156] Memory required for data: 2467488800
I0816 16:04:03.149706 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:03.149716 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:03.149724 20404 layer_factory.hpp:77] Creating layer ReLU182
I0816 16:04:03.149734 20404 net.cpp:91] Creating Layer ReLU182
I0816 16:04:03.149742 20404 net.cpp:425] ReLU182 <- InnerProduct78
I0816 16:04:03.149755 20404 net.cpp:386] ReLU182 -> InnerProduct78 (in-place)
I0816 16:04:03.149768 20404 net.cpp:141] Setting up ReLU182
I0816 16:04:03.149778 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:03.149786 20404 net.cpp:156] Memory required for data: 2467540000
I0816 16:04:03.149793 20404 layer_factory.hpp:77] Creating layer dt12
I0816 16:04:03.149806 20404 net.cpp:91] Creating Layer dt12
I0816 16:04:03.149813 20404 net.cpp:425] dt12 <- InnerProduct78
I0816 16:04:03.149827 20404 net.cpp:399] dt12 -> dt12
I0816 16:04:03.149982 20404 net.cpp:141] Setting up dt12
I0816 16:04:03.149997 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:03.150004 20404 net.cpp:156] Memory required for data: 2467540400
I0816 16:04:03.150013 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:03.150022 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:03.150030 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:03.150049 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:03.150058 20404 net.cpp:425] conv1 <- p2_p2_0_split_4
I0816 16:04:03.150073 20404 net.cpp:399] conv1 -> Convolution131
I0816 16:04:03.152768 20404 net.cpp:141] Setting up conv1
I0816 16:04:03.152789 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.152797 20404 net.cpp:156] Memory required for data: 2477370800
I0816 16:04:03.152812 20404 layer_factory.hpp:77] Creating layer ReLU183
I0816 16:04:03.152824 20404 net.cpp:91] Creating Layer ReLU183
I0816 16:04:03.152834 20404 net.cpp:425] ReLU183 <- Convolution131
I0816 16:04:03.152848 20404 net.cpp:386] ReLU183 -> Convolution131 (in-place)
I0816 16:04:03.152863 20404 net.cpp:141] Setting up ReLU183
I0816 16:04:03.152892 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.152900 20404 net.cpp:156] Memory required for data: 2487201200
I0816 16:04:03.152907 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:03.152920 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:03.152927 20404 net.cpp:425] norm1 <- Convolution131
I0816 16:04:03.152940 20404 net.cpp:399] norm1 -> LRN53
I0816 16:04:03.152999 20404 net.cpp:141] Setting up norm1
I0816 16:04:03.153013 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.153022 20404 net.cpp:156] Memory required for data: 2497031600
I0816 16:04:03.153028 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:03.153039 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:03.153048 20404 net.cpp:425] pool1 <- LRN53
I0816 16:04:03.153069 20404 net.cpp:399] pool1 -> Pooling79
I0816 16:04:03.153131 20404 net.cpp:141] Setting up pool1
I0816 16:04:03.153144 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:03.153151 20404 net.cpp:156] Memory required for data: 2499489200
I0816 16:04:03.153158 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:03.153180 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:03.153190 20404 net.cpp:425] conv2 <- Pooling79
I0816 16:04:03.153203 20404 net.cpp:399] conv2 -> Convolution132
I0816 16:04:03.168915 20404 net.cpp:141] Setting up conv2
I0816 16:04:03.168937 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.168946 20404 net.cpp:156] Memory required for data: 2506042800
I0816 16:04:03.168964 20404 layer_factory.hpp:77] Creating layer ReLU184
I0816 16:04:03.168978 20404 net.cpp:91] Creating Layer ReLU184
I0816 16:04:03.168987 20404 net.cpp:425] ReLU184 <- Convolution132
I0816 16:04:03.168999 20404 net.cpp:386] ReLU184 -> Convolution132 (in-place)
I0816 16:04:03.169013 20404 net.cpp:141] Setting up ReLU184
I0816 16:04:03.169024 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.169031 20404 net.cpp:156] Memory required for data: 2512596400
I0816 16:04:03.169039 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:03.169054 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:03.169062 20404 net.cpp:425] norm2 <- Convolution132
I0816 16:04:03.169077 20404 net.cpp:399] norm2 -> LRN54
I0816 16:04:03.169139 20404 net.cpp:141] Setting up norm2
I0816 16:04:03.169153 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.169160 20404 net.cpp:156] Memory required for data: 2519150000
I0816 16:04:03.169167 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:03.169181 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:03.169189 20404 net.cpp:425] pool2 <- LRN54
I0816 16:04:03.169201 20404 net.cpp:399] pool2 -> Pooling80
I0816 16:04:03.169263 20404 net.cpp:141] Setting up pool2
I0816 16:04:03.169277 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.169284 20404 net.cpp:156] Memory required for data: 2520788400
I0816 16:04:03.169292 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:03.169312 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:03.169324 20404 net.cpp:425] conv3 <- Pooling80
I0816 16:04:03.169342 20404 net.cpp:399] conv3 -> Convolution133
I0816 16:04:03.213167 20404 net.cpp:141] Setting up conv3
I0816 16:04:03.213198 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.213217 20404 net.cpp:156] Memory required for data: 2523246000
I0816 16:04:03.213232 20404 layer_factory.hpp:77] Creating layer ReLU185
I0816 16:04:03.213250 20404 net.cpp:91] Creating Layer ReLU185
I0816 16:04:03.213261 20404 net.cpp:425] ReLU185 <- Convolution133
I0816 16:04:03.213281 20404 net.cpp:386] ReLU185 -> Convolution133 (in-place)
I0816 16:04:03.213300 20404 net.cpp:141] Setting up ReLU185
I0816 16:04:03.213311 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.213318 20404 net.cpp:156] Memory required for data: 2525703600
I0816 16:04:03.213326 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:03.213346 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:03.213356 20404 net.cpp:425] conv4 <- Convolution133
I0816 16:04:03.213389 20404 net.cpp:399] conv4 -> Convolution134
I0816 16:04:03.246397 20404 net.cpp:141] Setting up conv4
I0816 16:04:03.246425 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.246433 20404 net.cpp:156] Memory required for data: 2528161200
I0816 16:04:03.246449 20404 layer_factory.hpp:77] Creating layer ReLU186
I0816 16:04:03.246467 20404 net.cpp:91] Creating Layer ReLU186
I0816 16:04:03.246479 20404 net.cpp:425] ReLU186 <- Convolution134
I0816 16:04:03.246490 20404 net.cpp:386] ReLU186 -> Convolution134 (in-place)
I0816 16:04:03.246507 20404 net.cpp:141] Setting up ReLU186
I0816 16:04:03.246517 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.246525 20404 net.cpp:156] Memory required for data: 2530618800
I0816 16:04:03.246532 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:03.246552 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:03.246562 20404 net.cpp:425] conv5 <- Convolution134
I0816 16:04:03.246583 20404 net.cpp:399] conv5 -> Convolution135
I0816 16:04:03.268620 20404 net.cpp:141] Setting up conv5
I0816 16:04:03.268642 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.268659 20404 net.cpp:156] Memory required for data: 2532257200
I0816 16:04:03.268673 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:03.268692 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:03.268702 20404 net.cpp:425] pool5 <- Convolution135
I0816 16:04:03.268717 20404 net.cpp:399] pool5 -> Pooling81
I0816 16:04:03.268795 20404 net.cpp:141] Setting up pool5
I0816 16:04:03.268810 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:03.268816 20404 net.cpp:156] Memory required for data: 2532666800
I0816 16:04:03.268824 20404 layer_factory.hpp:77] Creating layer InnerProduct79
I0816 16:04:03.268841 20404 net.cpp:91] Creating Layer InnerProduct79
I0816 16:04:03.268849 20404 net.cpp:425] InnerProduct79 <- Pooling81
I0816 16:04:03.268862 20404 net.cpp:399] InnerProduct79 -> InnerProduct79
I0816 16:04:03.271589 20404 net.cpp:141] Setting up InnerProduct79
I0816 16:04:03.271608 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.271616 20404 net.cpp:156] Memory required for data: 2532769200
I0816 16:04:03.271632 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:03.271642 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:03.271651 20404 layer_factory.hpp:77] Creating layer ReLU187
I0816 16:04:03.271664 20404 net.cpp:91] Creating Layer ReLU187
I0816 16:04:03.271673 20404 net.cpp:425] ReLU187 <- InnerProduct79
I0816 16:04:03.271695 20404 net.cpp:386] ReLU187 -> InnerProduct79 (in-place)
I0816 16:04:03.271709 20404 net.cpp:141] Setting up ReLU187
I0816 16:04:03.271719 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.271726 20404 net.cpp:156] Memory required for data: 2532871600
I0816 16:04:03.271734 20404 layer_factory.hpp:77] Creating layer InnerProduct80
I0816 16:04:03.271749 20404 net.cpp:91] Creating Layer InnerProduct80
I0816 16:04:03.271759 20404 net.cpp:425] InnerProduct80 <- InnerProduct79
I0816 16:04:03.271770 20404 net.cpp:399] InnerProduct80 -> InnerProduct80
I0816 16:04:03.272441 20404 net.cpp:141] Setting up InnerProduct80
I0816 16:04:03.272456 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.272474 20404 net.cpp:156] Memory required for data: 2532974000
I0816 16:04:03.272481 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:03.272491 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:03.272500 20404 layer_factory.hpp:77] Creating layer ReLU188
I0816 16:04:03.272510 20404 net.cpp:91] Creating Layer ReLU188
I0816 16:04:03.272517 20404 net.cpp:425] ReLU188 <- InnerProduct80
I0816 16:04:03.272536 20404 net.cpp:386] ReLU188 -> InnerProduct80 (in-place)
I0816 16:04:03.272548 20404 net.cpp:141] Setting up ReLU188
I0816 16:04:03.272559 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.272588 20404 net.cpp:156] Memory required for data: 2533076400
I0816 16:04:03.272596 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:03.272615 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:03.272624 20404 net.cpp:425] conv1 <- c14
I0816 16:04:03.272639 20404 net.cpp:399] conv1 -> Convolution136
I0816 16:04:03.274696 20404 net.cpp:141] Setting up conv1
I0816 16:04:03.274736 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.274763 20404 net.cpp:156] Memory required for data: 2542906800
I0816 16:04:03.274797 20404 layer_factory.hpp:77] Creating layer ReLU189
I0816 16:04:03.274832 20404 net.cpp:91] Creating Layer ReLU189
I0816 16:04:03.274860 20404 net.cpp:425] ReLU189 <- Convolution136
I0816 16:04:03.274893 20404 net.cpp:386] ReLU189 -> Convolution136 (in-place)
I0816 16:04:03.274933 20404 net.cpp:141] Setting up ReLU189
I0816 16:04:03.274968 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.275002 20404 net.cpp:156] Memory required for data: 2552737200
I0816 16:04:03.275032 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:03.275063 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:03.275090 20404 net.cpp:425] norm1 <- Convolution136
I0816 16:04:03.275128 20404 net.cpp:399] norm1 -> LRN55
I0816 16:04:03.275213 20404 net.cpp:141] Setting up norm1
I0816 16:04:03.275243 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.275276 20404 net.cpp:156] Memory required for data: 2562567600
I0816 16:04:03.275306 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:03.275341 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:03.275369 20404 net.cpp:425] pool1 <- LRN55
I0816 16:04:03.275385 20404 net.cpp:399] pool1 -> Pooling82
I0816 16:04:03.275454 20404 net.cpp:141] Setting up pool1
I0816 16:04:03.275467 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:03.275475 20404 net.cpp:156] Memory required for data: 2565025200
I0816 16:04:03.275482 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:03.275501 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:03.275509 20404 net.cpp:425] conv2 <- Pooling82
I0816 16:04:03.275526 20404 net.cpp:399] conv2 -> Convolution137
I0816 16:04:03.291278 20404 net.cpp:141] Setting up conv2
I0816 16:04:03.291304 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.291317 20404 net.cpp:156] Memory required for data: 2571578800
I0816 16:04:03.291333 20404 layer_factory.hpp:77] Creating layer ReLU190
I0816 16:04:03.291347 20404 net.cpp:91] Creating Layer ReLU190
I0816 16:04:03.291357 20404 net.cpp:425] ReLU190 <- Convolution137
I0816 16:04:03.291373 20404 net.cpp:386] ReLU190 -> Convolution137 (in-place)
I0816 16:04:03.291389 20404 net.cpp:141] Setting up ReLU190
I0816 16:04:03.291399 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.291407 20404 net.cpp:156] Memory required for data: 2578132400
I0816 16:04:03.291415 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:03.291426 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:03.291435 20404 net.cpp:425] norm2 <- Convolution137
I0816 16:04:03.291450 20404 net.cpp:399] norm2 -> LRN56
I0816 16:04:03.291514 20404 net.cpp:141] Setting up norm2
I0816 16:04:03.291528 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.291537 20404 net.cpp:156] Memory required for data: 2584686000
I0816 16:04:03.291544 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:03.291558 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:03.291566 20404 net.cpp:425] pool2 <- LRN56
I0816 16:04:03.291579 20404 net.cpp:399] pool2 -> Pooling83
I0816 16:04:03.291643 20404 net.cpp:141] Setting up pool2
I0816 16:04:03.291657 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.291666 20404 net.cpp:156] Memory required for data: 2586324400
I0816 16:04:03.291672 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:03.291692 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:03.291702 20404 net.cpp:425] conv3 <- Pooling83
I0816 16:04:03.291719 20404 net.cpp:399] conv3 -> Convolution138
I0816 16:04:03.335541 20404 net.cpp:141] Setting up conv3
I0816 16:04:03.335594 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.335603 20404 net.cpp:156] Memory required for data: 2588782000
I0816 16:04:03.335620 20404 layer_factory.hpp:77] Creating layer ReLU191
I0816 16:04:03.335641 20404 net.cpp:91] Creating Layer ReLU191
I0816 16:04:03.335654 20404 net.cpp:425] ReLU191 <- Convolution138
I0816 16:04:03.335666 20404 net.cpp:386] ReLU191 -> Convolution138 (in-place)
I0816 16:04:03.335683 20404 net.cpp:141] Setting up ReLU191
I0816 16:04:03.335693 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.335700 20404 net.cpp:156] Memory required for data: 2591239600
I0816 16:04:03.335708 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:03.335728 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:03.335743 20404 net.cpp:425] conv4 <- Convolution138
I0816 16:04:03.335762 20404 net.cpp:399] conv4 -> Convolution139
I0816 16:04:03.368854 20404 net.cpp:141] Setting up conv4
I0816 16:04:03.368881 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.368901 20404 net.cpp:156] Memory required for data: 2593697200
I0816 16:04:03.368916 20404 layer_factory.hpp:77] Creating layer ReLU192
I0816 16:04:03.368932 20404 net.cpp:91] Creating Layer ReLU192
I0816 16:04:03.368942 20404 net.cpp:425] ReLU192 <- Convolution139
I0816 16:04:03.368966 20404 net.cpp:386] ReLU192 -> Convolution139 (in-place)
I0816 16:04:03.368983 20404 net.cpp:141] Setting up ReLU192
I0816 16:04:03.368993 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.369001 20404 net.cpp:156] Memory required for data: 2596154800
I0816 16:04:03.369009 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:03.369026 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:03.369035 20404 net.cpp:425] conv5 <- Convolution139
I0816 16:04:03.369051 20404 net.cpp:399] conv5 -> Convolution140
I0816 16:04:03.391067 20404 net.cpp:141] Setting up conv5
I0816 16:04:03.391091 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.391108 20404 net.cpp:156] Memory required for data: 2597793200
I0816 16:04:03.391122 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:03.391141 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:03.391151 20404 net.cpp:425] pool5 <- Convolution140
I0816 16:04:03.391170 20404 net.cpp:399] pool5 -> Pooling84
I0816 16:04:03.391238 20404 net.cpp:141] Setting up pool5
I0816 16:04:03.391252 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:03.391260 20404 net.cpp:156] Memory required for data: 2598202800
I0816 16:04:03.391268 20404 layer_factory.hpp:77] Creating layer InnerProduct81
I0816 16:04:03.391299 20404 net.cpp:91] Creating Layer InnerProduct81
I0816 16:04:03.391307 20404 net.cpp:425] InnerProduct81 <- Pooling84
I0816 16:04:03.391321 20404 net.cpp:399] InnerProduct81 -> InnerProduct81
I0816 16:04:03.394037 20404 net.cpp:141] Setting up InnerProduct81
I0816 16:04:03.394057 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.394065 20404 net.cpp:156] Memory required for data: 2598305200
I0816 16:04:03.394075 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:03.394085 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:03.394093 20404 layer_factory.hpp:77] Creating layer ReLU193
I0816 16:04:03.394107 20404 net.cpp:91] Creating Layer ReLU193
I0816 16:04:03.394117 20404 net.cpp:425] ReLU193 <- InnerProduct81
I0816 16:04:03.394129 20404 net.cpp:386] ReLU193 -> InnerProduct81 (in-place)
I0816 16:04:03.394142 20404 net.cpp:141] Setting up ReLU193
I0816 16:04:03.394152 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.394160 20404 net.cpp:156] Memory required for data: 2598407600
I0816 16:04:03.394167 20404 layer_factory.hpp:77] Creating layer InnerProduct82
I0816 16:04:03.394182 20404 net.cpp:91] Creating Layer InnerProduct82
I0816 16:04:03.394191 20404 net.cpp:425] InnerProduct82 <- InnerProduct81
I0816 16:04:03.394204 20404 net.cpp:399] InnerProduct82 -> InnerProduct82
I0816 16:04:03.394899 20404 net.cpp:141] Setting up InnerProduct82
I0816 16:04:03.394914 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.394922 20404 net.cpp:156] Memory required for data: 2598510000
I0816 16:04:03.394930 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:03.394939 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:03.394948 20404 layer_factory.hpp:77] Creating layer ReLU194
I0816 16:04:03.394958 20404 net.cpp:91] Creating Layer ReLU194
I0816 16:04:03.394966 20404 net.cpp:425] ReLU194 <- InnerProduct82
I0816 16:04:03.394980 20404 net.cpp:386] ReLU194 -> InnerProduct82 (in-place)
I0816 16:04:03.394994 20404 net.cpp:141] Setting up ReLU194
I0816 16:04:03.395004 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.395010 20404 net.cpp:156] Memory required for data: 2598612400
I0816 16:04:03.395018 20404 layer_factory.hpp:77] Creating layer Concat14
I0816 16:04:03.395030 20404 net.cpp:91] Creating Layer Concat14
I0816 16:04:03.395038 20404 net.cpp:425] Concat14 <- InnerProduct80
I0816 16:04:03.395047 20404 net.cpp:425] Concat14 <- InnerProduct82
I0816 16:04:03.395063 20404 net.cpp:399] Concat14 -> Concat14
I0816 16:04:03.395104 20404 net.cpp:141] Setting up Concat14
I0816 16:04:03.395117 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:03.395125 20404 net.cpp:156] Memory required for data: 2598817200
I0816 16:04:03.395133 20404 layer_factory.hpp:77] Creating layer InnerProduct83
I0816 16:04:03.395148 20404 net.cpp:91] Creating Layer InnerProduct83
I0816 16:04:03.395156 20404 net.cpp:425] InnerProduct83 <- Concat14
I0816 16:04:03.395174 20404 net.cpp:399] InnerProduct83 -> InnerProduct83
I0816 16:04:03.397085 20404 net.cpp:141] Setting up InnerProduct83
I0816 16:04:03.397114 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.397124 20404 net.cpp:156] Memory required for data: 2598919600
I0816 16:04:03.397135 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:03.397145 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:03.397155 20404 layer_factory.hpp:77] Creating layer ReLU195
I0816 16:04:03.397171 20404 net.cpp:91] Creating Layer ReLU195
I0816 16:04:03.397181 20404 net.cpp:425] ReLU195 <- InnerProduct83
I0816 16:04:03.397193 20404 net.cpp:386] ReLU195 -> InnerProduct83 (in-place)
I0816 16:04:03.397210 20404 net.cpp:141] Setting up ReLU195
I0816 16:04:03.397263 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.397274 20404 net.cpp:156] Memory required for data: 2599022000
I0816 16:04:03.397284 20404 layer_factory.hpp:77] Creating layer InnerProduct84
I0816 16:04:03.397301 20404 net.cpp:91] Creating Layer InnerProduct84
I0816 16:04:03.397338 20404 net.cpp:425] InnerProduct84 <- InnerProduct83
I0816 16:04:03.397359 20404 net.cpp:399] InnerProduct84 -> InnerProduct84
I0816 16:04:03.397827 20404 net.cpp:141] Setting up InnerProduct84
I0816 16:04:03.397841 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:03.397848 20404 net.cpp:156] Memory required for data: 2599073200
I0816 16:04:03.397860 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:03.397869 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:03.397878 20404 layer_factory.hpp:77] Creating layer ReLU196
I0816 16:04:03.397891 20404 net.cpp:91] Creating Layer ReLU196
I0816 16:04:03.397898 20404 net.cpp:425] ReLU196 <- InnerProduct84
I0816 16:04:03.397909 20404 net.cpp:386] ReLU196 -> InnerProduct84 (in-place)
I0816 16:04:03.397920 20404 net.cpp:141] Setting up ReLU196
I0816 16:04:03.397930 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:03.397935 20404 net.cpp:156] Memory required for data: 2599124400
I0816 16:04:03.397941 20404 layer_factory.hpp:77] Creating layer dt13
I0816 16:04:03.397953 20404 net.cpp:91] Creating Layer dt13
I0816 16:04:03.397960 20404 net.cpp:425] dt13 <- InnerProduct84
I0816 16:04:03.397991 20404 net.cpp:399] dt13 -> dt13
I0816 16:04:03.398166 20404 net.cpp:141] Setting up dt13
I0816 16:04:03.398178 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:03.398185 20404 net.cpp:156] Memory required for data: 2599124800
I0816 16:04:03.398191 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:03.398198 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:03.398205 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:03.398221 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:03.398228 20404 net.cpp:425] conv1 <- p2_p2_0_split_5
I0816 16:04:03.398239 20404 net.cpp:399] conv1 -> Convolution141
I0816 16:04:03.401032 20404 net.cpp:141] Setting up conv1
I0816 16:04:03.401051 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.401057 20404 net.cpp:156] Memory required for data: 2608955200
I0816 16:04:03.401068 20404 layer_factory.hpp:77] Creating layer ReLU197
I0816 16:04:03.401077 20404 net.cpp:91] Creating Layer ReLU197
I0816 16:04:03.401085 20404 net.cpp:425] ReLU197 <- Convolution141
I0816 16:04:03.401094 20404 net.cpp:386] ReLU197 -> Convolution141 (in-place)
I0816 16:04:03.401105 20404 net.cpp:141] Setting up ReLU197
I0816 16:04:03.401113 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.401118 20404 net.cpp:156] Memory required for data: 2618785600
I0816 16:04:03.401124 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:03.401136 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:03.401142 20404 net.cpp:425] norm1 <- Convolution141
I0816 16:04:03.401154 20404 net.cpp:399] norm1 -> LRN57
I0816 16:04:03.401211 20404 net.cpp:141] Setting up norm1
I0816 16:04:03.401228 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.401235 20404 net.cpp:156] Memory required for data: 2628616000
I0816 16:04:03.401243 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:03.401255 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:03.401263 20404 net.cpp:425] pool1 <- LRN57
I0816 16:04:03.401279 20404 net.cpp:399] pool1 -> Pooling85
I0816 16:04:03.401342 20404 net.cpp:141] Setting up pool1
I0816 16:04:03.401361 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:03.401368 20404 net.cpp:156] Memory required for data: 2631073600
I0816 16:04:03.401376 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:03.401396 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:03.401406 20404 net.cpp:425] conv2 <- Pooling85
I0816 16:04:03.401418 20404 net.cpp:399] conv2 -> Convolution142
I0816 16:04:03.421666 20404 net.cpp:141] Setting up conv2
I0816 16:04:03.421699 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.421705 20404 net.cpp:156] Memory required for data: 2637627200
I0816 16:04:03.421715 20404 layer_factory.hpp:77] Creating layer ReLU198
I0816 16:04:03.421725 20404 net.cpp:91] Creating Layer ReLU198
I0816 16:04:03.421735 20404 net.cpp:425] ReLU198 <- Convolution142
I0816 16:04:03.421744 20404 net.cpp:386] ReLU198 -> Convolution142 (in-place)
I0816 16:04:03.421766 20404 net.cpp:141] Setting up ReLU198
I0816 16:04:03.421773 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.421778 20404 net.cpp:156] Memory required for data: 2644180800
I0816 16:04:03.421784 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:03.421793 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:03.421799 20404 net.cpp:425] norm2 <- Convolution142
I0816 16:04:03.421809 20404 net.cpp:399] norm2 -> LRN58
I0816 16:04:03.421867 20404 net.cpp:141] Setting up norm2
I0816 16:04:03.421875 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.421880 20404 net.cpp:156] Memory required for data: 2650734400
I0816 16:04:03.421886 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:03.421897 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:03.421905 20404 net.cpp:425] pool2 <- LRN58
I0816 16:04:03.421916 20404 net.cpp:399] pool2 -> Pooling86
I0816 16:04:03.421974 20404 net.cpp:141] Setting up pool2
I0816 16:04:03.422003 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.422009 20404 net.cpp:156] Memory required for data: 2652372800
I0816 16:04:03.422015 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:03.422030 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:03.422037 20404 net.cpp:425] conv3 <- Pooling86
I0816 16:04:03.422047 20404 net.cpp:399] conv3 -> Convolution143
I0816 16:04:03.466084 20404 net.cpp:141] Setting up conv3
I0816 16:04:03.466120 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.466127 20404 net.cpp:156] Memory required for data: 2654830400
I0816 16:04:03.466140 20404 layer_factory.hpp:77] Creating layer ReLU199
I0816 16:04:03.466151 20404 net.cpp:91] Creating Layer ReLU199
I0816 16:04:03.466161 20404 net.cpp:425] ReLU199 <- Convolution143
I0816 16:04:03.466183 20404 net.cpp:386] ReLU199 -> Convolution143 (in-place)
I0816 16:04:03.466197 20404 net.cpp:141] Setting up ReLU199
I0816 16:04:03.466204 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.466210 20404 net.cpp:156] Memory required for data: 2657288000
I0816 16:04:03.466217 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:03.466234 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:03.466241 20404 net.cpp:425] conv4 <- Convolution143
I0816 16:04:03.466251 20404 net.cpp:399] conv4 -> Convolution144
I0816 16:04:03.499137 20404 net.cpp:141] Setting up conv4
I0816 16:04:03.499171 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.499177 20404 net.cpp:156] Memory required for data: 2659745600
I0816 16:04:03.499189 20404 layer_factory.hpp:77] Creating layer ReLU200
I0816 16:04:03.499200 20404 net.cpp:91] Creating Layer ReLU200
I0816 16:04:03.499209 20404 net.cpp:425] ReLU200 <- Convolution144
I0816 16:04:03.499229 20404 net.cpp:386] ReLU200 -> Convolution144 (in-place)
I0816 16:04:03.499241 20404 net.cpp:141] Setting up ReLU200
I0816 16:04:03.499249 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.499255 20404 net.cpp:156] Memory required for data: 2662203200
I0816 16:04:03.499261 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:03.499294 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:03.499301 20404 net.cpp:425] conv5 <- Convolution144
I0816 16:04:03.499315 20404 net.cpp:399] conv5 -> Convolution145
I0816 16:04:03.521641 20404 net.cpp:141] Setting up conv5
I0816 16:04:03.521667 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.521674 20404 net.cpp:156] Memory required for data: 2663841600
I0816 16:04:03.521687 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:03.521703 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:03.521710 20404 net.cpp:425] pool5 <- Convolution145
I0816 16:04:03.521723 20404 net.cpp:399] pool5 -> Pooling87
I0816 16:04:03.521786 20404 net.cpp:141] Setting up pool5
I0816 16:04:03.521800 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:03.521806 20404 net.cpp:156] Memory required for data: 2664251200
I0816 16:04:03.521811 20404 layer_factory.hpp:77] Creating layer InnerProduct85
I0816 16:04:03.521822 20404 net.cpp:91] Creating Layer InnerProduct85
I0816 16:04:03.521827 20404 net.cpp:425] InnerProduct85 <- Pooling87
I0816 16:04:03.521842 20404 net.cpp:399] InnerProduct85 -> InnerProduct85
I0816 16:04:03.524569 20404 net.cpp:141] Setting up InnerProduct85
I0816 16:04:03.524600 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.524605 20404 net.cpp:156] Memory required for data: 2664353600
I0816 16:04:03.524612 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:03.524621 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:03.524627 20404 layer_factory.hpp:77] Creating layer ReLU201
I0816 16:04:03.524636 20404 net.cpp:91] Creating Layer ReLU201
I0816 16:04:03.524642 20404 net.cpp:425] ReLU201 <- InnerProduct85
I0816 16:04:03.524659 20404 net.cpp:386] ReLU201 -> InnerProduct85 (in-place)
I0816 16:04:03.524670 20404 net.cpp:141] Setting up ReLU201
I0816 16:04:03.524698 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.524704 20404 net.cpp:156] Memory required for data: 2664456000
I0816 16:04:03.524710 20404 layer_factory.hpp:77] Creating layer InnerProduct86
I0816 16:04:03.524720 20404 net.cpp:91] Creating Layer InnerProduct86
I0816 16:04:03.524726 20404 net.cpp:425] InnerProduct86 <- InnerProduct85
I0816 16:04:03.524739 20404 net.cpp:399] InnerProduct86 -> InnerProduct86
I0816 16:04:03.525403 20404 net.cpp:141] Setting up InnerProduct86
I0816 16:04:03.525424 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.525429 20404 net.cpp:156] Memory required for data: 2664558400
I0816 16:04:03.525435 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:03.525442 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:03.525449 20404 layer_factory.hpp:77] Creating layer ReLU202
I0816 16:04:03.525455 20404 net.cpp:91] Creating Layer ReLU202
I0816 16:04:03.525461 20404 net.cpp:425] ReLU202 <- InnerProduct86
I0816 16:04:03.525470 20404 net.cpp:386] ReLU202 -> InnerProduct86 (in-place)
I0816 16:04:03.525478 20404 net.cpp:141] Setting up ReLU202
I0816 16:04:03.525485 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.525491 20404 net.cpp:156] Memory required for data: 2664660800
I0816 16:04:03.525497 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:03.525509 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:03.525516 20404 net.cpp:425] conv1 <- c15
I0816 16:04:03.525530 20404 net.cpp:399] conv1 -> Convolution146
I0816 16:04:03.527555 20404 net.cpp:141] Setting up conv1
I0816 16:04:03.527577 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.527583 20404 net.cpp:156] Memory required for data: 2674491200
I0816 16:04:03.527593 20404 layer_factory.hpp:77] Creating layer ReLU203
I0816 16:04:03.527601 20404 net.cpp:91] Creating Layer ReLU203
I0816 16:04:03.527607 20404 net.cpp:425] ReLU203 <- Convolution146
I0816 16:04:03.527617 20404 net.cpp:386] ReLU203 -> Convolution146 (in-place)
I0816 16:04:03.527636 20404 net.cpp:141] Setting up ReLU203
I0816 16:04:03.527642 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.527648 20404 net.cpp:156] Memory required for data: 2684321600
I0816 16:04:03.527653 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:03.527664 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:03.527672 20404 net.cpp:425] norm1 <- Convolution146
I0816 16:04:03.527684 20404 net.cpp:399] norm1 -> LRN59
I0816 16:04:03.527734 20404 net.cpp:141] Setting up norm1
I0816 16:04:03.527740 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.527746 20404 net.cpp:156] Memory required for data: 2694152000
I0816 16:04:03.527751 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:03.527762 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:03.527768 20404 net.cpp:425] pool1 <- LRN59
I0816 16:04:03.527776 20404 net.cpp:399] pool1 -> Pooling88
I0816 16:04:03.527832 20404 net.cpp:141] Setting up pool1
I0816 16:04:03.527842 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:03.527848 20404 net.cpp:156] Memory required for data: 2696609600
I0816 16:04:03.527853 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:03.527866 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:03.527873 20404 net.cpp:425] conv2 <- Pooling88
I0816 16:04:03.527886 20404 net.cpp:399] conv2 -> Convolution147
I0816 16:04:03.543256 20404 net.cpp:141] Setting up conv2
I0816 16:04:03.543290 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.543298 20404 net.cpp:156] Memory required for data: 2703163200
I0816 16:04:03.543308 20404 layer_factory.hpp:77] Creating layer ReLU204
I0816 16:04:03.543318 20404 net.cpp:91] Creating Layer ReLU204
I0816 16:04:03.543324 20404 net.cpp:425] ReLU204 <- Convolution147
I0816 16:04:03.543344 20404 net.cpp:386] ReLU204 -> Convolution147 (in-place)
I0816 16:04:03.543355 20404 net.cpp:141] Setting up ReLU204
I0816 16:04:03.543364 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.543383 20404 net.cpp:156] Memory required for data: 2709716800
I0816 16:04:03.543390 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:03.543398 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:03.543404 20404 net.cpp:425] norm2 <- Convolution147
I0816 16:04:03.543413 20404 net.cpp:399] norm2 -> LRN60
I0816 16:04:03.543472 20404 net.cpp:141] Setting up norm2
I0816 16:04:03.543479 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.543485 20404 net.cpp:156] Memory required for data: 2716270400
I0816 16:04:03.543490 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:03.543501 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:03.543507 20404 net.cpp:425] pool2 <- LRN60
I0816 16:04:03.543516 20404 net.cpp:399] pool2 -> Pooling89
I0816 16:04:03.543573 20404 net.cpp:141] Setting up pool2
I0816 16:04:03.543581 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.543586 20404 net.cpp:156] Memory required for data: 2717908800
I0816 16:04:03.543592 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:03.543606 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:03.543612 20404 net.cpp:425] conv3 <- Pooling89
I0816 16:04:03.543624 20404 net.cpp:399] conv3 -> Convolution148
I0816 16:04:03.587355 20404 net.cpp:141] Setting up conv3
I0816 16:04:03.587393 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.587399 20404 net.cpp:156] Memory required for data: 2720366400
I0816 16:04:03.587410 20404 layer_factory.hpp:77] Creating layer ReLU205
I0816 16:04:03.587422 20404 net.cpp:91] Creating Layer ReLU205
I0816 16:04:03.587431 20404 net.cpp:425] ReLU205 <- Convolution148
I0816 16:04:03.587451 20404 net.cpp:386] ReLU205 -> Convolution148 (in-place)
I0816 16:04:03.587465 20404 net.cpp:141] Setting up ReLU205
I0816 16:04:03.587472 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.587477 20404 net.cpp:156] Memory required for data: 2722824000
I0816 16:04:03.587483 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:03.587499 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:03.587505 20404 net.cpp:425] conv4 <- Convolution148
I0816 16:04:03.587517 20404 net.cpp:399] conv4 -> Convolution149
I0816 16:04:03.620640 20404 net.cpp:141] Setting up conv4
I0816 16:04:03.620677 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.620683 20404 net.cpp:156] Memory required for data: 2725281600
I0816 16:04:03.620695 20404 layer_factory.hpp:77] Creating layer ReLU206
I0816 16:04:03.620707 20404 net.cpp:91] Creating Layer ReLU206
I0816 16:04:03.620715 20404 net.cpp:425] ReLU206 <- Convolution149
I0816 16:04:03.620733 20404 net.cpp:386] ReLU206 -> Convolution149 (in-place)
I0816 16:04:03.620745 20404 net.cpp:141] Setting up ReLU206
I0816 16:04:03.620753 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.620759 20404 net.cpp:156] Memory required for data: 2727739200
I0816 16:04:03.620764 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:03.620782 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:03.620789 20404 net.cpp:425] conv5 <- Convolution149
I0816 16:04:03.620801 20404 net.cpp:399] conv5 -> Convolution150
I0816 16:04:03.642812 20404 net.cpp:141] Setting up conv5
I0816 16:04:03.642845 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.642851 20404 net.cpp:156] Memory required for data: 2729377600
I0816 16:04:03.642863 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:03.642874 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:03.642881 20404 net.cpp:425] pool5 <- Convolution150
I0816 16:04:03.642901 20404 net.cpp:399] pool5 -> Pooling90
I0816 16:04:03.642963 20404 net.cpp:141] Setting up pool5
I0816 16:04:03.642971 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:03.642977 20404 net.cpp:156] Memory required for data: 2729787200
I0816 16:04:03.642982 20404 layer_factory.hpp:77] Creating layer InnerProduct87
I0816 16:04:03.642997 20404 net.cpp:91] Creating Layer InnerProduct87
I0816 16:04:03.643002 20404 net.cpp:425] InnerProduct87 <- Pooling90
I0816 16:04:03.643034 20404 net.cpp:399] InnerProduct87 -> InnerProduct87
I0816 16:04:03.645759 20404 net.cpp:141] Setting up InnerProduct87
I0816 16:04:03.645787 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.645793 20404 net.cpp:156] Memory required for data: 2729889600
I0816 16:04:03.645802 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:03.645809 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:03.645815 20404 layer_factory.hpp:77] Creating layer ReLU207
I0816 16:04:03.645824 20404 net.cpp:91] Creating Layer ReLU207
I0816 16:04:03.645831 20404 net.cpp:425] ReLU207 <- InnerProduct87
I0816 16:04:03.645848 20404 net.cpp:386] ReLU207 -> InnerProduct87 (in-place)
I0816 16:04:03.645859 20404 net.cpp:141] Setting up ReLU207
I0816 16:04:03.645866 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.645871 20404 net.cpp:156] Memory required for data: 2729992000
I0816 16:04:03.645877 20404 layer_factory.hpp:77] Creating layer InnerProduct88
I0816 16:04:03.645894 20404 net.cpp:91] Creating Layer InnerProduct88
I0816 16:04:03.645900 20404 net.cpp:425] InnerProduct88 <- InnerProduct87
I0816 16:04:03.645910 20404 net.cpp:399] InnerProduct88 -> InnerProduct88
I0816 16:04:03.646580 20404 net.cpp:141] Setting up InnerProduct88
I0816 16:04:03.646591 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.646596 20404 net.cpp:156] Memory required for data: 2730094400
I0816 16:04:03.646603 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:03.646610 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:03.646616 20404 layer_factory.hpp:77] Creating layer ReLU208
I0816 16:04:03.646627 20404 net.cpp:91] Creating Layer ReLU208
I0816 16:04:03.646633 20404 net.cpp:425] ReLU208 <- InnerProduct88
I0816 16:04:03.646641 20404 net.cpp:386] ReLU208 -> InnerProduct88 (in-place)
I0816 16:04:03.646651 20404 net.cpp:141] Setting up ReLU208
I0816 16:04:03.646658 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.646663 20404 net.cpp:156] Memory required for data: 2730196800
I0816 16:04:03.646669 20404 layer_factory.hpp:77] Creating layer Concat15
I0816 16:04:03.646678 20404 net.cpp:91] Creating Layer Concat15
I0816 16:04:03.646684 20404 net.cpp:425] Concat15 <- InnerProduct86
I0816 16:04:03.646692 20404 net.cpp:425] Concat15 <- InnerProduct88
I0816 16:04:03.646702 20404 net.cpp:399] Concat15 -> Concat15
I0816 16:04:03.646738 20404 net.cpp:141] Setting up Concat15
I0816 16:04:03.646745 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:03.646750 20404 net.cpp:156] Memory required for data: 2730401600
I0816 16:04:03.646756 20404 layer_factory.hpp:77] Creating layer InnerProduct89
I0816 16:04:03.646767 20404 net.cpp:91] Creating Layer InnerProduct89
I0816 16:04:03.646773 20404 net.cpp:425] InnerProduct89 <- Concat15
I0816 16:04:03.646782 20404 net.cpp:399] InnerProduct89 -> InnerProduct89
I0816 16:04:03.647965 20404 net.cpp:141] Setting up InnerProduct89
I0816 16:04:03.647976 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.647982 20404 net.cpp:156] Memory required for data: 2730504000
I0816 16:04:03.647989 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:03.647996 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:03.648002 20404 layer_factory.hpp:77] Creating layer ReLU209
I0816 16:04:03.648010 20404 net.cpp:91] Creating Layer ReLU209
I0816 16:04:03.648016 20404 net.cpp:425] ReLU209 <- InnerProduct89
I0816 16:04:03.648025 20404 net.cpp:386] ReLU209 -> InnerProduct89 (in-place)
I0816 16:04:03.648033 20404 net.cpp:141] Setting up ReLU209
I0816 16:04:03.648041 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.648046 20404 net.cpp:156] Memory required for data: 2730606400
I0816 16:04:03.648051 20404 layer_factory.hpp:77] Creating layer InnerProduct90
I0816 16:04:03.648061 20404 net.cpp:91] Creating Layer InnerProduct90
I0816 16:04:03.648082 20404 net.cpp:425] InnerProduct90 <- InnerProduct89
I0816 16:04:03.648094 20404 net.cpp:399] InnerProduct90 -> InnerProduct90
I0816 16:04:03.648506 20404 net.cpp:141] Setting up InnerProduct90
I0816 16:04:03.648524 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:03.648530 20404 net.cpp:156] Memory required for data: 2730657600
I0816 16:04:03.648540 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:03.648550 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:03.648561 20404 layer_factory.hpp:77] Creating layer ReLU210
I0816 16:04:03.648574 20404 net.cpp:91] Creating Layer ReLU210
I0816 16:04:03.648586 20404 net.cpp:425] ReLU210 <- InnerProduct90
I0816 16:04:03.648597 20404 net.cpp:386] ReLU210 -> InnerProduct90 (in-place)
I0816 16:04:03.648609 20404 net.cpp:141] Setting up ReLU210
I0816 16:04:03.648617 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:03.648623 20404 net.cpp:156] Memory required for data: 2730708800
I0816 16:04:03.648628 20404 layer_factory.hpp:77] Creating layer dt14
I0816 16:04:03.648638 20404 net.cpp:91] Creating Layer dt14
I0816 16:04:03.648643 20404 net.cpp:425] dt14 <- InnerProduct90
I0816 16:04:03.648654 20404 net.cpp:399] dt14 -> dt14
I0816 16:04:03.648814 20404 net.cpp:141] Setting up dt14
I0816 16:04:03.648823 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:03.648828 20404 net.cpp:156] Memory required for data: 2730709200
I0816 16:04:03.648833 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:03.648841 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:03.648847 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:03.648861 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:03.648869 20404 net.cpp:425] conv1 <- p2_p2_0_split_6
I0816 16:04:03.648880 20404 net.cpp:399] conv1 -> Convolution151
I0816 16:04:03.651561 20404 net.cpp:141] Setting up conv1
I0816 16:04:03.651582 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.651589 20404 net.cpp:156] Memory required for data: 2740539600
I0816 16:04:03.651605 20404 layer_factory.hpp:77] Creating layer ReLU211
I0816 16:04:03.651618 20404 net.cpp:91] Creating Layer ReLU211
I0816 16:04:03.651625 20404 net.cpp:425] ReLU211 <- Convolution151
I0816 16:04:03.651634 20404 net.cpp:386] ReLU211 -> Convolution151 (in-place)
I0816 16:04:03.651645 20404 net.cpp:141] Setting up ReLU211
I0816 16:04:03.651654 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.651659 20404 net.cpp:156] Memory required for data: 2750370000
I0816 16:04:03.651664 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:03.651675 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:03.651682 20404 net.cpp:425] norm1 <- Convolution151
I0816 16:04:03.651692 20404 net.cpp:399] norm1 -> LRN61
I0816 16:04:03.651746 20404 net.cpp:141] Setting up norm1
I0816 16:04:03.651753 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.651758 20404 net.cpp:156] Memory required for data: 2760200400
I0816 16:04:03.651764 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:03.651782 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:03.651787 20404 net.cpp:425] pool1 <- LRN61
I0816 16:04:03.651796 20404 net.cpp:399] pool1 -> Pooling91
I0816 16:04:03.651855 20404 net.cpp:141] Setting up pool1
I0816 16:04:03.651864 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:03.651868 20404 net.cpp:156] Memory required for data: 2762658000
I0816 16:04:03.651875 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:03.651890 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:03.651895 20404 net.cpp:425] conv2 <- Pooling91
I0816 16:04:03.651908 20404 net.cpp:399] conv2 -> Convolution152
I0816 16:04:03.667754 20404 net.cpp:141] Setting up conv2
I0816 16:04:03.667785 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.667791 20404 net.cpp:156] Memory required for data: 2769211600
I0816 16:04:03.667999 20404 layer_factory.hpp:77] Creating layer ReLU212
I0816 16:04:03.668014 20404 net.cpp:91] Creating Layer ReLU212
I0816 16:04:03.668021 20404 net.cpp:425] ReLU212 <- Convolution152
I0816 16:04:03.668030 20404 net.cpp:386] ReLU212 -> Convolution152 (in-place)
I0816 16:04:03.668042 20404 net.cpp:141] Setting up ReLU212
I0816 16:04:03.668050 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.668056 20404 net.cpp:156] Memory required for data: 2775765200
I0816 16:04:03.668061 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:03.668069 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:03.668076 20404 net.cpp:425] norm2 <- Convolution152
I0816 16:04:03.668086 20404 net.cpp:399] norm2 -> LRN62
I0816 16:04:03.668146 20404 net.cpp:141] Setting up norm2
I0816 16:04:03.668154 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.668160 20404 net.cpp:156] Memory required for data: 2782318800
I0816 16:04:03.668166 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:03.668174 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:03.668180 20404 net.cpp:425] pool2 <- LRN62
I0816 16:04:03.668191 20404 net.cpp:399] pool2 -> Pooling92
I0816 16:04:03.668390 20404 net.cpp:141] Setting up pool2
I0816 16:04:03.668408 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.668414 20404 net.cpp:156] Memory required for data: 2783957200
I0816 16:04:03.668421 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:03.668436 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:03.668442 20404 net.cpp:425] conv3 <- Pooling92
I0816 16:04:03.668452 20404 net.cpp:399] conv3 -> Convolution153
I0816 16:04:03.712119 20404 net.cpp:141] Setting up conv3
I0816 16:04:03.712146 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.712152 20404 net.cpp:156] Memory required for data: 2786414800
I0816 16:04:03.712164 20404 layer_factory.hpp:77] Creating layer ReLU213
I0816 16:04:03.712177 20404 net.cpp:91] Creating Layer ReLU213
I0816 16:04:03.712185 20404 net.cpp:425] ReLU213 <- Convolution153
I0816 16:04:03.712195 20404 net.cpp:386] ReLU213 -> Convolution153 (in-place)
I0816 16:04:03.712208 20404 net.cpp:141] Setting up ReLU213
I0816 16:04:03.712215 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.712220 20404 net.cpp:156] Memory required for data: 2788872400
I0816 16:04:03.712226 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:03.712241 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:03.712249 20404 net.cpp:425] conv4 <- Convolution153
I0816 16:04:03.712262 20404 net.cpp:399] conv4 -> Convolution154
I0816 16:04:03.745442 20404 net.cpp:141] Setting up conv4
I0816 16:04:03.745470 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.745477 20404 net.cpp:156] Memory required for data: 2791330000
I0816 16:04:03.745491 20404 layer_factory.hpp:77] Creating layer ReLU214
I0816 16:04:03.745504 20404 net.cpp:91] Creating Layer ReLU214
I0816 16:04:03.745514 20404 net.cpp:425] ReLU214 <- Convolution154
I0816 16:04:03.745527 20404 net.cpp:386] ReLU214 -> Convolution154 (in-place)
I0816 16:04:03.745543 20404 net.cpp:141] Setting up ReLU214
I0816 16:04:03.745550 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.745558 20404 net.cpp:156] Memory required for data: 2793787600
I0816 16:04:03.745563 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:03.745581 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:03.745589 20404 net.cpp:425] conv5 <- Convolution154
I0816 16:04:03.745600 20404 net.cpp:399] conv5 -> Convolution155
I0816 16:04:03.768144 20404 net.cpp:141] Setting up conv5
I0816 16:04:03.768177 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.768182 20404 net.cpp:156] Memory required for data: 2795426000
I0816 16:04:03.768194 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:03.768206 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:03.768214 20404 net.cpp:425] pool5 <- Convolution155
I0816 16:04:03.768239 20404 net.cpp:399] pool5 -> Pooling93
I0816 16:04:03.768322 20404 net.cpp:141] Setting up pool5
I0816 16:04:03.768331 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:03.768337 20404 net.cpp:156] Memory required for data: 2795835600
I0816 16:04:03.768342 20404 layer_factory.hpp:77] Creating layer InnerProduct91
I0816 16:04:03.768357 20404 net.cpp:91] Creating Layer InnerProduct91
I0816 16:04:03.768362 20404 net.cpp:425] InnerProduct91 <- Pooling93
I0816 16:04:03.768376 20404 net.cpp:399] InnerProduct91 -> InnerProduct91
I0816 16:04:03.771143 20404 net.cpp:141] Setting up InnerProduct91
I0816 16:04:03.771159 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.771165 20404 net.cpp:156] Memory required for data: 2795938000
I0816 16:04:03.771173 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:03.771181 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:03.771188 20404 layer_factory.hpp:77] Creating layer ReLU215
I0816 16:04:03.771196 20404 net.cpp:91] Creating Layer ReLU215
I0816 16:04:03.771203 20404 net.cpp:425] ReLU215 <- InnerProduct91
I0816 16:04:03.771219 20404 net.cpp:386] ReLU215 -> InnerProduct91 (in-place)
I0816 16:04:03.771230 20404 net.cpp:141] Setting up ReLU215
I0816 16:04:03.771237 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.771244 20404 net.cpp:156] Memory required for data: 2796040400
I0816 16:04:03.771248 20404 layer_factory.hpp:77] Creating layer InnerProduct92
I0816 16:04:03.771258 20404 net.cpp:91] Creating Layer InnerProduct92
I0816 16:04:03.771265 20404 net.cpp:425] InnerProduct92 <- InnerProduct91
I0816 16:04:03.771286 20404 net.cpp:399] InnerProduct92 -> InnerProduct92
I0816 16:04:03.771956 20404 net.cpp:141] Setting up InnerProduct92
I0816 16:04:03.771972 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.771981 20404 net.cpp:156] Memory required for data: 2796142800
I0816 16:04:03.771989 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:03.771998 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:03.772006 20404 layer_factory.hpp:77] Creating layer ReLU216
I0816 16:04:03.772017 20404 net.cpp:91] Creating Layer ReLU216
I0816 16:04:03.772027 20404 net.cpp:425] ReLU216 <- InnerProduct92
I0816 16:04:03.772037 20404 net.cpp:386] ReLU216 -> InnerProduct92 (in-place)
I0816 16:04:03.772053 20404 net.cpp:141] Setting up ReLU216
I0816 16:04:03.772063 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.772069 20404 net.cpp:156] Memory required for data: 2796245200
I0816 16:04:03.772074 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:03.772090 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:03.772097 20404 net.cpp:425] conv1 <- c16
I0816 16:04:03.772111 20404 net.cpp:399] conv1 -> Convolution156
I0816 16:04:03.774171 20404 net.cpp:141] Setting up conv1
I0816 16:04:03.774183 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.774191 20404 net.cpp:156] Memory required for data: 2806075600
I0816 16:04:03.774205 20404 layer_factory.hpp:77] Creating layer ReLU217
I0816 16:04:03.774215 20404 net.cpp:91] Creating Layer ReLU217
I0816 16:04:03.774224 20404 net.cpp:425] ReLU217 <- Convolution156
I0816 16:04:03.774232 20404 net.cpp:386] ReLU217 -> Convolution156 (in-place)
I0816 16:04:03.774245 20404 net.cpp:141] Setting up ReLU217
I0816 16:04:03.774255 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.774261 20404 net.cpp:156] Memory required for data: 2815906000
I0816 16:04:03.774269 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:03.774282 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:03.774289 20404 net.cpp:425] norm1 <- Convolution156
I0816 16:04:03.774301 20404 net.cpp:399] norm1 -> LRN63
I0816 16:04:03.774356 20404 net.cpp:141] Setting up norm1
I0816 16:04:03.774364 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.774370 20404 net.cpp:156] Memory required for data: 2825736400
I0816 16:04:03.774390 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:03.774399 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:03.774405 20404 net.cpp:425] pool1 <- LRN63
I0816 16:04:03.774417 20404 net.cpp:399] pool1 -> Pooling94
I0816 16:04:03.774474 20404 net.cpp:141] Setting up pool1
I0816 16:04:03.774482 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:03.774487 20404 net.cpp:156] Memory required for data: 2828194000
I0816 16:04:03.774493 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:03.774512 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:03.774518 20404 net.cpp:425] conv2 <- Pooling94
I0816 16:04:03.774528 20404 net.cpp:399] conv2 -> Convolution157
I0816 16:04:03.790072 20404 net.cpp:141] Setting up conv2
I0816 16:04:03.790107 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.790112 20404 net.cpp:156] Memory required for data: 2834747600
I0816 16:04:03.790123 20404 layer_factory.hpp:77] Creating layer ReLU218
I0816 16:04:03.790133 20404 net.cpp:91] Creating Layer ReLU218
I0816 16:04:03.790141 20404 net.cpp:425] ReLU218 <- Convolution157
I0816 16:04:03.790158 20404 net.cpp:386] ReLU218 -> Convolution157 (in-place)
I0816 16:04:03.790170 20404 net.cpp:141] Setting up ReLU218
I0816 16:04:03.790179 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.790184 20404 net.cpp:156] Memory required for data: 2841301200
I0816 16:04:03.790189 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:03.790202 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:03.790210 20404 net.cpp:425] norm2 <- Convolution157
I0816 16:04:03.790218 20404 net.cpp:399] norm2 -> LRN64
I0816 16:04:03.790278 20404 net.cpp:141] Setting up norm2
I0816 16:04:03.790287 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.790292 20404 net.cpp:156] Memory required for data: 2847854800
I0816 16:04:03.790297 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:03.790307 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:03.790313 20404 net.cpp:425] pool2 <- LRN64
I0816 16:04:03.790324 20404 net.cpp:399] pool2 -> Pooling95
I0816 16:04:03.790380 20404 net.cpp:141] Setting up pool2
I0816 16:04:03.790390 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.790395 20404 net.cpp:156] Memory required for data: 2849493200
I0816 16:04:03.790401 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:03.790416 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:03.790426 20404 net.cpp:425] conv3 <- Pooling95
I0816 16:04:03.790438 20404 net.cpp:399] conv3 -> Convolution158
I0816 16:04:03.834287 20404 net.cpp:141] Setting up conv3
I0816 16:04:03.834326 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.834332 20404 net.cpp:156] Memory required for data: 2851950800
I0816 16:04:03.834344 20404 layer_factory.hpp:77] Creating layer ReLU219
I0816 16:04:03.834357 20404 net.cpp:91] Creating Layer ReLU219
I0816 16:04:03.834365 20404 net.cpp:425] ReLU219 <- Convolution158
I0816 16:04:03.834385 20404 net.cpp:386] ReLU219 -> Convolution158 (in-place)
I0816 16:04:03.834399 20404 net.cpp:141] Setting up ReLU219
I0816 16:04:03.834408 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.834413 20404 net.cpp:156] Memory required for data: 2854408400
I0816 16:04:03.834419 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:03.834435 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:03.834441 20404 net.cpp:425] conv4 <- Convolution158
I0816 16:04:03.834455 20404 net.cpp:399] conv4 -> Convolution159
I0816 16:04:03.867840 20404 net.cpp:141] Setting up conv4
I0816 16:04:03.867875 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.867882 20404 net.cpp:156] Memory required for data: 2856866000
I0816 16:04:03.867893 20404 layer_factory.hpp:77] Creating layer ReLU220
I0816 16:04:03.867905 20404 net.cpp:91] Creating Layer ReLU220
I0816 16:04:03.867914 20404 net.cpp:425] ReLU220 <- Convolution159
I0816 16:04:03.867938 20404 net.cpp:386] ReLU220 -> Convolution159 (in-place)
I0816 16:04:03.867950 20404 net.cpp:141] Setting up ReLU220
I0816 16:04:03.867979 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.867985 20404 net.cpp:156] Memory required for data: 2859323600
I0816 16:04:03.867990 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:03.868006 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:03.868012 20404 net.cpp:425] conv5 <- Convolution159
I0816 16:04:03.868023 20404 net.cpp:399] conv5 -> Convolution160
I0816 16:04:03.890060 20404 net.cpp:141] Setting up conv5
I0816 16:04:03.890079 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.890086 20404 net.cpp:156] Memory required for data: 2860962000
I0816 16:04:03.890097 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:03.890108 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:03.890116 20404 net.cpp:425] pool5 <- Convolution160
I0816 16:04:03.890130 20404 net.cpp:399] pool5 -> Pooling96
I0816 16:04:03.890192 20404 net.cpp:141] Setting up pool5
I0816 16:04:03.890200 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:03.890207 20404 net.cpp:156] Memory required for data: 2861371600
I0816 16:04:03.890211 20404 layer_factory.hpp:77] Creating layer InnerProduct93
I0816 16:04:03.890224 20404 net.cpp:91] Creating Layer InnerProduct93
I0816 16:04:03.890231 20404 net.cpp:425] InnerProduct93 <- Pooling96
I0816 16:04:03.890245 20404 net.cpp:399] InnerProduct93 -> InnerProduct93
I0816 16:04:03.893102 20404 net.cpp:141] Setting up InnerProduct93
I0816 16:04:03.893129 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.893136 20404 net.cpp:156] Memory required for data: 2861474000
I0816 16:04:03.893143 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:03.893151 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:03.893158 20404 layer_factory.hpp:77] Creating layer ReLU221
I0816 16:04:03.893167 20404 net.cpp:91] Creating Layer ReLU221
I0816 16:04:03.893174 20404 net.cpp:425] ReLU221 <- InnerProduct93
I0816 16:04:03.893193 20404 net.cpp:386] ReLU221 -> InnerProduct93 (in-place)
I0816 16:04:03.893205 20404 net.cpp:141] Setting up ReLU221
I0816 16:04:03.893213 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.893218 20404 net.cpp:156] Memory required for data: 2861576400
I0816 16:04:03.893224 20404 layer_factory.hpp:77] Creating layer InnerProduct94
I0816 16:04:03.893234 20404 net.cpp:91] Creating Layer InnerProduct94
I0816 16:04:03.893239 20404 net.cpp:425] InnerProduct94 <- InnerProduct93
I0816 16:04:03.893251 20404 net.cpp:399] InnerProduct94 -> InnerProduct94
I0816 16:04:03.893924 20404 net.cpp:141] Setting up InnerProduct94
I0816 16:04:03.893935 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.893944 20404 net.cpp:156] Memory required for data: 2861678800
I0816 16:04:03.893949 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:03.893956 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:03.893962 20404 layer_factory.hpp:77] Creating layer ReLU222
I0816 16:04:03.893970 20404 net.cpp:91] Creating Layer ReLU222
I0816 16:04:03.893976 20404 net.cpp:425] ReLU222 <- InnerProduct94
I0816 16:04:03.893985 20404 net.cpp:386] ReLU222 -> InnerProduct94 (in-place)
I0816 16:04:03.893995 20404 net.cpp:141] Setting up ReLU222
I0816 16:04:03.894001 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.894007 20404 net.cpp:156] Memory required for data: 2861781200
I0816 16:04:03.894012 20404 layer_factory.hpp:77] Creating layer Concat16
I0816 16:04:03.894021 20404 net.cpp:91] Creating Layer Concat16
I0816 16:04:03.894027 20404 net.cpp:425] Concat16 <- InnerProduct92
I0816 16:04:03.894035 20404 net.cpp:425] Concat16 <- InnerProduct94
I0816 16:04:03.894047 20404 net.cpp:399] Concat16 -> Concat16
I0816 16:04:03.894084 20404 net.cpp:141] Setting up Concat16
I0816 16:04:03.894093 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:03.894098 20404 net.cpp:156] Memory required for data: 2861986000
I0816 16:04:03.894104 20404 layer_factory.hpp:77] Creating layer InnerProduct95
I0816 16:04:03.894129 20404 net.cpp:91] Creating Layer InnerProduct95
I0816 16:04:03.894134 20404 net.cpp:425] InnerProduct95 <- Concat16
I0816 16:04:03.894147 20404 net.cpp:399] InnerProduct95 -> InnerProduct95
I0816 16:04:03.895951 20404 net.cpp:141] Setting up InnerProduct95
I0816 16:04:03.895970 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.895977 20404 net.cpp:156] Memory required for data: 2862088400
I0816 16:04:03.895984 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:03.895992 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:03.895998 20404 layer_factory.hpp:77] Creating layer ReLU223
I0816 16:04:03.896008 20404 net.cpp:91] Creating Layer ReLU223
I0816 16:04:03.896014 20404 net.cpp:425] ReLU223 <- InnerProduct95
I0816 16:04:03.896026 20404 net.cpp:386] ReLU223 -> InnerProduct95 (in-place)
I0816 16:04:03.896037 20404 net.cpp:141] Setting up ReLU223
I0816 16:04:03.896044 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:03.896050 20404 net.cpp:156] Memory required for data: 2862190800
I0816 16:04:03.896055 20404 layer_factory.hpp:77] Creating layer InnerProduct96
I0816 16:04:03.896065 20404 net.cpp:91] Creating Layer InnerProduct96
I0816 16:04:03.896071 20404 net.cpp:425] InnerProduct96 <- InnerProduct95
I0816 16:04:03.896087 20404 net.cpp:399] InnerProduct96 -> InnerProduct96
I0816 16:04:03.896498 20404 net.cpp:141] Setting up InnerProduct96
I0816 16:04:03.896508 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:03.896517 20404 net.cpp:156] Memory required for data: 2862242000
I0816 16:04:03.896522 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:03.896530 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:03.896536 20404 layer_factory.hpp:77] Creating layer ReLU224
I0816 16:04:03.896544 20404 net.cpp:91] Creating Layer ReLU224
I0816 16:04:03.896550 20404 net.cpp:425] ReLU224 <- InnerProduct96
I0816 16:04:03.896561 20404 net.cpp:386] ReLU224 -> InnerProduct96 (in-place)
I0816 16:04:03.896570 20404 net.cpp:141] Setting up ReLU224
I0816 16:04:03.896577 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:03.896582 20404 net.cpp:156] Memory required for data: 2862293200
I0816 16:04:03.896589 20404 layer_factory.hpp:77] Creating layer dt15
I0816 16:04:03.896597 20404 net.cpp:91] Creating Layer dt15
I0816 16:04:03.896603 20404 net.cpp:425] dt15 <- InnerProduct96
I0816 16:04:03.896613 20404 net.cpp:399] dt15 -> dt15
I0816 16:04:03.896775 20404 net.cpp:141] Setting up dt15
I0816 16:04:03.896785 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:03.896790 20404 net.cpp:156] Memory required for data: 2862293600
I0816 16:04:03.896796 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:03.896803 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:03.896809 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:03.896823 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:03.896831 20404 net.cpp:425] conv1 <- p2_p2_0_split_7
I0816 16:04:03.896842 20404 net.cpp:399] conv1 -> Convolution161
I0816 16:04:03.899711 20404 net.cpp:141] Setting up conv1
I0816 16:04:03.899734 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.899744 20404 net.cpp:156] Memory required for data: 2872124000
I0816 16:04:03.899760 20404 layer_factory.hpp:77] Creating layer ReLU225
I0816 16:04:03.899775 20404 net.cpp:91] Creating Layer ReLU225
I0816 16:04:03.899790 20404 net.cpp:425] ReLU225 <- Convolution161
I0816 16:04:03.899801 20404 net.cpp:386] ReLU225 -> Convolution161 (in-place)
I0816 16:04:03.899822 20404 net.cpp:141] Setting up ReLU225
I0816 16:04:03.899837 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.899845 20404 net.cpp:156] Memory required for data: 2881954400
I0816 16:04:03.899853 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:03.899883 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:03.899894 20404 net.cpp:425] norm1 <- Convolution161
I0816 16:04:03.899911 20404 net.cpp:399] norm1 -> LRN65
I0816 16:04:03.899974 20404 net.cpp:141] Setting up norm1
I0816 16:04:03.899986 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:03.899994 20404 net.cpp:156] Memory required for data: 2891784800
I0816 16:04:03.900003 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:03.900017 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:03.900024 20404 net.cpp:425] pool1 <- LRN65
I0816 16:04:03.900033 20404 net.cpp:399] pool1 -> Pooling97
I0816 16:04:03.900096 20404 net.cpp:141] Setting up pool1
I0816 16:04:03.900104 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:03.900110 20404 net.cpp:156] Memory required for data: 2894242400
I0816 16:04:03.900115 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:03.900131 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:03.900137 20404 net.cpp:425] conv2 <- Pooling97
I0816 16:04:03.900149 20404 net.cpp:399] conv2 -> Convolution162
I0816 16:04:03.915663 20404 net.cpp:141] Setting up conv2
I0816 16:04:03.915693 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.915699 20404 net.cpp:156] Memory required for data: 2900796000
I0816 16:04:03.915709 20404 layer_factory.hpp:77] Creating layer ReLU226
I0816 16:04:03.915719 20404 net.cpp:91] Creating Layer ReLU226
I0816 16:04:03.915726 20404 net.cpp:425] ReLU226 <- Convolution162
I0816 16:04:03.915737 20404 net.cpp:386] ReLU226 -> Convolution162 (in-place)
I0816 16:04:03.915760 20404 net.cpp:141] Setting up ReLU226
I0816 16:04:03.915768 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.915774 20404 net.cpp:156] Memory required for data: 2907349600
I0816 16:04:03.915781 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:03.915791 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:03.915797 20404 net.cpp:425] norm2 <- Convolution162
I0816 16:04:03.915807 20404 net.cpp:399] norm2 -> LRN66
I0816 16:04:03.915868 20404 net.cpp:141] Setting up norm2
I0816 16:04:03.915877 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:03.915882 20404 net.cpp:156] Memory required for data: 2913903200
I0816 16:04:03.915889 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:03.915896 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:03.915904 20404 net.cpp:425] pool2 <- LRN66
I0816 16:04:03.915911 20404 net.cpp:399] pool2 -> Pooling98
I0816 16:04:03.915976 20404 net.cpp:141] Setting up pool2
I0816 16:04:03.915985 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:03.915990 20404 net.cpp:156] Memory required for data: 2915541600
I0816 16:04:03.915997 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:03.916010 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:03.916019 20404 net.cpp:425] conv3 <- Pooling98
I0816 16:04:03.916029 20404 net.cpp:399] conv3 -> Convolution163
I0816 16:04:03.959727 20404 net.cpp:141] Setting up conv3
I0816 16:04:03.959753 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.959760 20404 net.cpp:156] Memory required for data: 2917999200
I0816 16:04:03.959774 20404 layer_factory.hpp:77] Creating layer ReLU227
I0816 16:04:03.959786 20404 net.cpp:91] Creating Layer ReLU227
I0816 16:04:03.959797 20404 net.cpp:425] ReLU227 <- Convolution163
I0816 16:04:03.959807 20404 net.cpp:386] ReLU227 -> Convolution163 (in-place)
I0816 16:04:03.959822 20404 net.cpp:141] Setting up ReLU227
I0816 16:04:03.959836 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.959843 20404 net.cpp:156] Memory required for data: 2920456800
I0816 16:04:03.959851 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:03.959872 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:03.959882 20404 net.cpp:425] conv4 <- Convolution163
I0816 16:04:03.959895 20404 net.cpp:399] conv4 -> Convolution164
I0816 16:04:03.992995 20404 net.cpp:141] Setting up conv4
I0816 16:04:03.993021 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.993047 20404 net.cpp:156] Memory required for data: 2922914400
I0816 16:04:03.993060 20404 layer_factory.hpp:77] Creating layer ReLU228
I0816 16:04:03.993073 20404 net.cpp:91] Creating Layer ReLU228
I0816 16:04:03.993089 20404 net.cpp:425] ReLU228 <- Convolution164
I0816 16:04:03.993105 20404 net.cpp:386] ReLU228 -> Convolution164 (in-place)
I0816 16:04:03.993121 20404 net.cpp:141] Setting up ReLU228
I0816 16:04:03.993136 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:03.993146 20404 net.cpp:156] Memory required for data: 2925372000
I0816 16:04:03.993155 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:03.993173 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:03.993185 20404 net.cpp:425] conv5 <- Convolution164
I0816 16:04:03.993198 20404 net.cpp:399] conv5 -> Convolution165
I0816 16:04:04.015609 20404 net.cpp:141] Setting up conv5
I0816 16:04:04.015635 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.015642 20404 net.cpp:156] Memory required for data: 2927010400
I0816 16:04:04.015656 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:04.015693 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:04.015707 20404 net.cpp:425] pool5 <- Convolution165
I0816 16:04:04.015724 20404 net.cpp:399] pool5 -> Pooling99
I0816 16:04:04.015800 20404 net.cpp:141] Setting up pool5
I0816 16:04:04.015817 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:04.015828 20404 net.cpp:156] Memory required for data: 2927420000
I0816 16:04:04.015836 20404 layer_factory.hpp:77] Creating layer InnerProduct97
I0816 16:04:04.015869 20404 net.cpp:91] Creating Layer InnerProduct97
I0816 16:04:04.015882 20404 net.cpp:425] InnerProduct97 <- Pooling99
I0816 16:04:04.015898 20404 net.cpp:399] InnerProduct97 -> InnerProduct97
I0816 16:04:04.018678 20404 net.cpp:141] Setting up InnerProduct97
I0816 16:04:04.018698 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.018707 20404 net.cpp:156] Memory required for data: 2927522400
I0816 16:04:04.018717 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:04.018730 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:04.018738 20404 layer_factory.hpp:77] Creating layer ReLU229
I0816 16:04:04.018749 20404 net.cpp:91] Creating Layer ReLU229
I0816 16:04:04.018756 20404 net.cpp:425] ReLU229 <- InnerProduct97
I0816 16:04:04.018767 20404 net.cpp:386] ReLU229 -> InnerProduct97 (in-place)
I0816 16:04:04.018779 20404 net.cpp:141] Setting up ReLU229
I0816 16:04:04.018787 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.018792 20404 net.cpp:156] Memory required for data: 2927624800
I0816 16:04:04.018798 20404 layer_factory.hpp:77] Creating layer InnerProduct98
I0816 16:04:04.018808 20404 net.cpp:91] Creating Layer InnerProduct98
I0816 16:04:04.018815 20404 net.cpp:425] InnerProduct98 <- InnerProduct97
I0816 16:04:04.018827 20404 net.cpp:399] InnerProduct98 -> InnerProduct98
I0816 16:04:04.019537 20404 net.cpp:141] Setting up InnerProduct98
I0816 16:04:04.019553 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.019562 20404 net.cpp:156] Memory required for data: 2927727200
I0816 16:04:04.019569 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:04.019603 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:04.019615 20404 layer_factory.hpp:77] Creating layer ReLU230
I0816 16:04:04.019629 20404 net.cpp:91] Creating Layer ReLU230
I0816 16:04:04.019644 20404 net.cpp:425] ReLU230 <- InnerProduct98
I0816 16:04:04.019654 20404 net.cpp:386] ReLU230 -> InnerProduct98 (in-place)
I0816 16:04:04.019671 20404 net.cpp:141] Setting up ReLU230
I0816 16:04:04.019686 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.019721 20404 net.cpp:156] Memory required for data: 2927829600
I0816 16:04:04.019731 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:04.019748 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:04.019773 20404 net.cpp:425] conv1 <- c17
I0816 16:04:04.019791 20404 net.cpp:399] conv1 -> Convolution166
I0816 16:04:04.021890 20404 net.cpp:141] Setting up conv1
I0816 16:04:04.021904 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.021913 20404 net.cpp:156] Memory required for data: 2937660000
I0816 16:04:04.021925 20404 layer_factory.hpp:77] Creating layer ReLU231
I0816 16:04:04.021940 20404 net.cpp:91] Creating Layer ReLU231
I0816 16:04:04.021951 20404 net.cpp:425] ReLU231 <- Convolution166
I0816 16:04:04.021965 20404 net.cpp:386] ReLU231 -> Convolution166 (in-place)
I0816 16:04:04.021982 20404 net.cpp:141] Setting up ReLU231
I0816 16:04:04.021996 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.022006 20404 net.cpp:156] Memory required for data: 2947490400
I0816 16:04:04.022016 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:04.022033 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:04.022045 20404 net.cpp:425] norm1 <- Convolution166
I0816 16:04:04.022059 20404 net.cpp:399] norm1 -> LRN67
I0816 16:04:04.022120 20404 net.cpp:141] Setting up norm1
I0816 16:04:04.022132 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.022140 20404 net.cpp:156] Memory required for data: 2957320800
I0816 16:04:04.022148 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:04.022166 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:04.022176 20404 net.cpp:425] pool1 <- LRN67
I0816 16:04:04.022191 20404 net.cpp:399] pool1 -> Pooling100
I0816 16:04:04.022256 20404 net.cpp:141] Setting up pool1
I0816 16:04:04.022269 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:04.022279 20404 net.cpp:156] Memory required for data: 2959778400
I0816 16:04:04.022284 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:04.022299 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:04.022305 20404 net.cpp:425] conv2 <- Pooling100
I0816 16:04:04.022317 20404 net.cpp:399] conv2 -> Convolution167
I0816 16:04:04.038230 20404 net.cpp:141] Setting up conv2
I0816 16:04:04.038264 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.038269 20404 net.cpp:156] Memory required for data: 2966332000
I0816 16:04:04.038280 20404 layer_factory.hpp:77] Creating layer ReLU232
I0816 16:04:04.038290 20404 net.cpp:91] Creating Layer ReLU232
I0816 16:04:04.038297 20404 net.cpp:425] ReLU232 <- Convolution167
I0816 16:04:04.038319 20404 net.cpp:386] ReLU232 -> Convolution167 (in-place)
I0816 16:04:04.038331 20404 net.cpp:141] Setting up ReLU232
I0816 16:04:04.038338 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.038344 20404 net.cpp:156] Memory required for data: 2972885600
I0816 16:04:04.038350 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:04.038359 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:04.038365 20404 net.cpp:425] norm2 <- Convolution167
I0816 16:04:04.038378 20404 net.cpp:399] norm2 -> LRN68
I0816 16:04:04.038426 20404 net.cpp:141] Setting up norm2
I0816 16:04:04.038436 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.038442 20404 net.cpp:156] Memory required for data: 2979439200
I0816 16:04:04.038447 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:04.038458 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:04.038471 20404 net.cpp:425] pool2 <- LRN68
I0816 16:04:04.038483 20404 net.cpp:399] pool2 -> Pooling101
I0816 16:04:04.038542 20404 net.cpp:141] Setting up pool2
I0816 16:04:04.038554 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.038561 20404 net.cpp:156] Memory required for data: 2981077600
I0816 16:04:04.038573 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:04.038588 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:04.038594 20404 net.cpp:425] conv3 <- Pooling101
I0816 16:04:04.038606 20404 net.cpp:399] conv3 -> Convolution168
I0816 16:04:04.082461 20404 net.cpp:141] Setting up conv3
I0816 16:04:04.082494 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.082502 20404 net.cpp:156] Memory required for data: 2983535200
I0816 16:04:04.082567 20404 layer_factory.hpp:77] Creating layer ReLU233
I0816 16:04:04.082594 20404 net.cpp:91] Creating Layer ReLU233
I0816 16:04:04.082626 20404 net.cpp:425] ReLU233 <- Convolution168
I0816 16:04:04.082648 20404 net.cpp:386] ReLU233 -> Convolution168 (in-place)
I0816 16:04:04.082666 20404 net.cpp:141] Setting up ReLU233
I0816 16:04:04.082680 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.082707 20404 net.cpp:156] Memory required for data: 2985992800
I0816 16:04:04.082720 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:04.082739 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:04.082751 20404 net.cpp:425] conv4 <- Convolution168
I0816 16:04:04.082765 20404 net.cpp:399] conv4 -> Convolution169
I0816 16:04:04.115836 20404 net.cpp:141] Setting up conv4
I0816 16:04:04.115864 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.115871 20404 net.cpp:156] Memory required for data: 2988450400
I0816 16:04:04.115898 20404 layer_factory.hpp:77] Creating layer ReLU234
I0816 16:04:04.115916 20404 net.cpp:91] Creating Layer ReLU234
I0816 16:04:04.115929 20404 net.cpp:425] ReLU234 <- Convolution169
I0816 16:04:04.115972 20404 net.cpp:386] ReLU234 -> Convolution169 (in-place)
I0816 16:04:04.115993 20404 net.cpp:141] Setting up ReLU234
I0816 16:04:04.116004 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.116032 20404 net.cpp:156] Memory required for data: 2990908000
I0816 16:04:04.116044 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:04.116070 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:04.116082 20404 net.cpp:425] conv5 <- Convolution169
I0816 16:04:04.116099 20404 net.cpp:399] conv5 -> Convolution170
I0816 16:04:04.138085 20404 net.cpp:141] Setting up conv5
I0816 16:04:04.138146 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.138175 20404 net.cpp:156] Memory required for data: 2992546400
I0816 16:04:04.138195 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:04.138208 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:04.138239 20404 net.cpp:425] pool5 <- Convolution170
I0816 16:04:04.138258 20404 net.cpp:399] pool5 -> Pooling102
I0816 16:04:04.138341 20404 net.cpp:141] Setting up pool5
I0816 16:04:04.138355 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:04.138362 20404 net.cpp:156] Memory required for data: 2992956000
I0816 16:04:04.138370 20404 layer_factory.hpp:77] Creating layer InnerProduct99
I0816 16:04:04.138403 20404 net.cpp:91] Creating Layer InnerProduct99
I0816 16:04:04.138417 20404 net.cpp:425] InnerProduct99 <- Pooling102
I0816 16:04:04.138430 20404 net.cpp:399] InnerProduct99 -> InnerProduct99
I0816 16:04:04.141240 20404 net.cpp:141] Setting up InnerProduct99
I0816 16:04:04.141263 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.141271 20404 net.cpp:156] Memory required for data: 2993058400
I0816 16:04:04.141281 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:04.141317 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:04.141330 20404 layer_factory.hpp:77] Creating layer ReLU235
I0816 16:04:04.141342 20404 net.cpp:91] Creating Layer ReLU235
I0816 16:04:04.141355 20404 net.cpp:425] ReLU235 <- InnerProduct99
I0816 16:04:04.141371 20404 net.cpp:386] ReLU235 -> InnerProduct99 (in-place)
I0816 16:04:04.141387 20404 net.cpp:141] Setting up ReLU235
I0816 16:04:04.141402 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.141428 20404 net.cpp:156] Memory required for data: 2993160800
I0816 16:04:04.141439 20404 layer_factory.hpp:77] Creating layer InnerProduct100
I0816 16:04:04.141456 20404 net.cpp:91] Creating Layer InnerProduct100
I0816 16:04:04.141469 20404 net.cpp:425] InnerProduct100 <- InnerProduct99
I0816 16:04:04.141485 20404 net.cpp:399] InnerProduct100 -> InnerProduct100
I0816 16:04:04.142163 20404 net.cpp:141] Setting up InnerProduct100
I0816 16:04:04.142179 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.142185 20404 net.cpp:156] Memory required for data: 2993263200
I0816 16:04:04.142238 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:04.142251 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:04.142259 20404 layer_factory.hpp:77] Creating layer ReLU236
I0816 16:04:04.142289 20404 net.cpp:91] Creating Layer ReLU236
I0816 16:04:04.142300 20404 net.cpp:425] ReLU236 <- InnerProduct100
I0816 16:04:04.142312 20404 net.cpp:386] ReLU236 -> InnerProduct100 (in-place)
I0816 16:04:04.142326 20404 net.cpp:141] Setting up ReLU236
I0816 16:04:04.142339 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.142366 20404 net.cpp:156] Memory required for data: 2993365600
I0816 16:04:04.142376 20404 layer_factory.hpp:77] Creating layer Concat17
I0816 16:04:04.142387 20404 net.cpp:91] Creating Layer Concat17
I0816 16:04:04.142397 20404 net.cpp:425] Concat17 <- InnerProduct98
I0816 16:04:04.142426 20404 net.cpp:425] Concat17 <- InnerProduct100
I0816 16:04:04.142442 20404 net.cpp:399] Concat17 -> Concat17
I0816 16:04:04.142484 20404 net.cpp:141] Setting up Concat17
I0816 16:04:04.142498 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:04.142508 20404 net.cpp:156] Memory required for data: 2993570400
I0816 16:04:04.142518 20404 layer_factory.hpp:77] Creating layer InnerProduct101
I0816 16:04:04.142532 20404 net.cpp:91] Creating Layer InnerProduct101
I0816 16:04:04.142542 20404 net.cpp:425] InnerProduct101 <- Concat17
I0816 16:04:04.142555 20404 net.cpp:399] InnerProduct101 -> InnerProduct101
I0816 16:04:04.143723 20404 net.cpp:141] Setting up InnerProduct101
I0816 16:04:04.143736 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.143743 20404 net.cpp:156] Memory required for data: 2993672800
I0816 16:04:04.143751 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:04.143782 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:04.143792 20404 layer_factory.hpp:77] Creating layer ReLU237
I0816 16:04:04.143803 20404 net.cpp:91] Creating Layer ReLU237
I0816 16:04:04.143828 20404 net.cpp:425] ReLU237 <- InnerProduct101
I0816 16:04:04.143842 20404 net.cpp:386] ReLU237 -> InnerProduct101 (in-place)
I0816 16:04:04.143872 20404 net.cpp:141] Setting up ReLU237
I0816 16:04:04.143885 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.143893 20404 net.cpp:156] Memory required for data: 2993775200
I0816 16:04:04.143918 20404 layer_factory.hpp:77] Creating layer InnerProduct102
I0816 16:04:04.143936 20404 net.cpp:91] Creating Layer InnerProduct102
I0816 16:04:04.143949 20404 net.cpp:425] InnerProduct102 <- InnerProduct101
I0816 16:04:04.143960 20404 net.cpp:399] InnerProduct102 -> InnerProduct102
I0816 16:04:04.144359 20404 net.cpp:141] Setting up InnerProduct102
I0816 16:04:04.144372 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:04.144379 20404 net.cpp:156] Memory required for data: 2993826400
I0816 16:04:04.144407 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:04.144419 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:04.144428 20404 layer_factory.hpp:77] Creating layer ReLU238
I0816 16:04:04.144443 20404 net.cpp:91] Creating Layer ReLU238
I0816 16:04:04.144454 20404 net.cpp:425] ReLU238 <- InnerProduct102
I0816 16:04:04.144464 20404 net.cpp:386] ReLU238 -> InnerProduct102 (in-place)
I0816 16:04:04.144479 20404 net.cpp:141] Setting up ReLU238
I0816 16:04:04.144492 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:04.144501 20404 net.cpp:156] Memory required for data: 2993877600
I0816 16:04:04.144510 20404 layer_factory.hpp:77] Creating layer dt16
I0816 16:04:04.144522 20404 net.cpp:91] Creating Layer dt16
I0816 16:04:04.144533 20404 net.cpp:425] dt16 <- InnerProduct102
I0816 16:04:04.144547 20404 net.cpp:399] dt16 -> dt16
I0816 16:04:04.144693 20404 net.cpp:141] Setting up dt16
I0816 16:04:04.144706 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:04.144727 20404 net.cpp:156] Memory required for data: 2993878000
I0816 16:04:04.144736 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:04.144747 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:04.144757 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:04.144776 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:04.144788 20404 net.cpp:425] conv1 <- p2_p2_0_split_8
I0816 16:04:04.144801 20404 net.cpp:399] conv1 -> Convolution171
I0816 16:04:04.147436 20404 net.cpp:141] Setting up conv1
I0816 16:04:04.147459 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.147467 20404 net.cpp:156] Memory required for data: 3003708400
I0816 16:04:04.147482 20404 layer_factory.hpp:77] Creating layer ReLU239
I0816 16:04:04.147495 20404 net.cpp:91] Creating Layer ReLU239
I0816 16:04:04.147503 20404 net.cpp:425] ReLU239 <- Convolution171
I0816 16:04:04.147514 20404 net.cpp:386] ReLU239 -> Convolution171 (in-place)
I0816 16:04:04.147527 20404 net.cpp:141] Setting up ReLU239
I0816 16:04:04.147537 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.147545 20404 net.cpp:156] Memory required for data: 3013538800
I0816 16:04:04.147552 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:04.147567 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:04.147575 20404 net.cpp:425] norm1 <- Convolution171
I0816 16:04:04.147588 20404 net.cpp:399] norm1 -> LRN69
I0816 16:04:04.147639 20404 net.cpp:141] Setting up norm1
I0816 16:04:04.147651 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.147658 20404 net.cpp:156] Memory required for data: 3023369200
I0816 16:04:04.147665 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:04.147680 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:04.147687 20404 net.cpp:425] pool1 <- LRN69
I0816 16:04:04.147699 20404 net.cpp:399] pool1 -> Pooling103
I0816 16:04:04.147756 20404 net.cpp:141] Setting up pool1
I0816 16:04:04.147768 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:04.147775 20404 net.cpp:156] Memory required for data: 3025826800
I0816 16:04:04.147783 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:04.147800 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:04.147810 20404 net.cpp:425] conv2 <- Pooling103
I0816 16:04:04.147827 20404 net.cpp:399] conv2 -> Convolution172
I0816 16:04:04.163255 20404 net.cpp:141] Setting up conv2
I0816 16:04:04.163280 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.163288 20404 net.cpp:156] Memory required for data: 3032380400
I0816 16:04:04.163302 20404 layer_factory.hpp:77] Creating layer ReLU240
I0816 16:04:04.163329 20404 net.cpp:91] Creating Layer ReLU240
I0816 16:04:04.163338 20404 net.cpp:425] ReLU240 <- Convolution172
I0816 16:04:04.163349 20404 net.cpp:386] ReLU240 -> Convolution172 (in-place)
I0816 16:04:04.163363 20404 net.cpp:141] Setting up ReLU240
I0816 16:04:04.163373 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.163388 20404 net.cpp:156] Memory required for data: 3038934000
I0816 16:04:04.163398 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:04.163413 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:04.163420 20404 net.cpp:425] norm2 <- Convolution172
I0816 16:04:04.163432 20404 net.cpp:399] norm2 -> LRN70
I0816 16:04:04.163492 20404 net.cpp:141] Setting up norm2
I0816 16:04:04.163506 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.163514 20404 net.cpp:156] Memory required for data: 3045487600
I0816 16:04:04.163522 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:04.163532 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:04.163540 20404 net.cpp:425] pool2 <- LRN70
I0816 16:04:04.163554 20404 net.cpp:399] pool2 -> Pooling104
I0816 16:04:04.163614 20404 net.cpp:141] Setting up pool2
I0816 16:04:04.163627 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.163635 20404 net.cpp:156] Memory required for data: 3047126000
I0816 16:04:04.163658 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:04.163681 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:04.163694 20404 net.cpp:425] conv3 <- Pooling104
I0816 16:04:04.163708 20404 net.cpp:399] conv3 -> Convolution173
I0816 16:04:04.207540 20404 net.cpp:141] Setting up conv3
I0816 16:04:04.207571 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.207590 20404 net.cpp:156] Memory required for data: 3049583600
I0816 16:04:04.207607 20404 layer_factory.hpp:77] Creating layer ReLU241
I0816 16:04:04.207622 20404 net.cpp:91] Creating Layer ReLU241
I0816 16:04:04.207633 20404 net.cpp:425] ReLU241 <- Convolution173
I0816 16:04:04.207646 20404 net.cpp:386] ReLU241 -> Convolution173 (in-place)
I0816 16:04:04.207672 20404 net.cpp:141] Setting up ReLU241
I0816 16:04:04.207682 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.207690 20404 net.cpp:156] Memory required for data: 3052041200
I0816 16:04:04.207697 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:04.207718 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:04.207726 20404 net.cpp:425] conv4 <- Convolution173
I0816 16:04:04.207743 20404 net.cpp:399] conv4 -> Convolution174
I0816 16:04:04.240624 20404 net.cpp:141] Setting up conv4
I0816 16:04:04.240653 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.240671 20404 net.cpp:156] Memory required for data: 3054498800
I0816 16:04:04.240686 20404 layer_factory.hpp:77] Creating layer ReLU242
I0816 16:04:04.240703 20404 net.cpp:91] Creating Layer ReLU242
I0816 16:04:04.240715 20404 net.cpp:425] ReLU242 <- Convolution174
I0816 16:04:04.240732 20404 net.cpp:386] ReLU242 -> Convolution174 (in-place)
I0816 16:04:04.240751 20404 net.cpp:141] Setting up ReLU242
I0816 16:04:04.240761 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.240768 20404 net.cpp:156] Memory required for data: 3056956400
I0816 16:04:04.240777 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:04.240803 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:04.240816 20404 net.cpp:425] conv5 <- Convolution174
I0816 16:04:04.240834 20404 net.cpp:399] conv5 -> Convolution175
I0816 16:04:04.262979 20404 net.cpp:141] Setting up conv5
I0816 16:04:04.263015 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.263022 20404 net.cpp:156] Memory required for data: 3058594800
I0816 16:04:04.263037 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:04.263052 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:04.263072 20404 net.cpp:425] pool5 <- Convolution175
I0816 16:04:04.263087 20404 net.cpp:399] pool5 -> Pooling105
I0816 16:04:04.263162 20404 net.cpp:141] Setting up pool5
I0816 16:04:04.263177 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:04.263185 20404 net.cpp:156] Memory required for data: 3059004400
I0816 16:04:04.263192 20404 layer_factory.hpp:77] Creating layer InnerProduct103
I0816 16:04:04.263208 20404 net.cpp:91] Creating Layer InnerProduct103
I0816 16:04:04.263216 20404 net.cpp:425] InnerProduct103 <- Pooling105
I0816 16:04:04.263234 20404 net.cpp:399] InnerProduct103 -> InnerProduct103
I0816 16:04:04.266052 20404 net.cpp:141] Setting up InnerProduct103
I0816 16:04:04.266077 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.266084 20404 net.cpp:156] Memory required for data: 3059106800
I0816 16:04:04.266094 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:04.266105 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:04.266113 20404 layer_factory.hpp:77] Creating layer ReLU243
I0816 16:04:04.266125 20404 net.cpp:91] Creating Layer ReLU243
I0816 16:04:04.266135 20404 net.cpp:425] ReLU243 <- InnerProduct103
I0816 16:04:04.266150 20404 net.cpp:386] ReLU243 -> InnerProduct103 (in-place)
I0816 16:04:04.266165 20404 net.cpp:141] Setting up ReLU243
I0816 16:04:04.266175 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.266183 20404 net.cpp:156] Memory required for data: 3059209200
I0816 16:04:04.266206 20404 layer_factory.hpp:77] Creating layer InnerProduct104
I0816 16:04:04.266221 20404 net.cpp:91] Creating Layer InnerProduct104
I0816 16:04:04.266229 20404 net.cpp:425] InnerProduct104 <- InnerProduct103
I0816 16:04:04.266245 20404 net.cpp:399] InnerProduct104 -> InnerProduct104
I0816 16:04:04.266906 20404 net.cpp:141] Setting up InnerProduct104
I0816 16:04:04.266921 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.266929 20404 net.cpp:156] Memory required for data: 3059311600
I0816 16:04:04.266938 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:04.266948 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:04.266957 20404 layer_factory.hpp:77] Creating layer ReLU244
I0816 16:04:04.266969 20404 net.cpp:91] Creating Layer ReLU244
I0816 16:04:04.266978 20404 net.cpp:425] ReLU244 <- InnerProduct104
I0816 16:04:04.266989 20404 net.cpp:386] ReLU244 -> InnerProduct104 (in-place)
I0816 16:04:04.267002 20404 net.cpp:141] Setting up ReLU244
I0816 16:04:04.267011 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.267019 20404 net.cpp:156] Memory required for data: 3059414000
I0816 16:04:04.267026 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:04.267043 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:04.267052 20404 net.cpp:425] conv1 <- c18
I0816 16:04:04.267069 20404 net.cpp:399] conv1 -> Convolution176
I0816 16:04:04.269124 20404 net.cpp:141] Setting up conv1
I0816 16:04:04.269147 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.269152 20404 net.cpp:156] Memory required for data: 3069244400
I0816 16:04:04.269163 20404 layer_factory.hpp:77] Creating layer ReLU245
I0816 16:04:04.269172 20404 net.cpp:91] Creating Layer ReLU245
I0816 16:04:04.269179 20404 net.cpp:425] ReLU245 <- Convolution176
I0816 16:04:04.269188 20404 net.cpp:386] ReLU245 -> Convolution176 (in-place)
I0816 16:04:04.269207 20404 net.cpp:141] Setting up ReLU245
I0816 16:04:04.269214 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.269219 20404 net.cpp:156] Memory required for data: 3079074800
I0816 16:04:04.269225 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:04.269237 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:04.269243 20404 net.cpp:425] norm1 <- Convolution176
I0816 16:04:04.269256 20404 net.cpp:399] norm1 -> LRN71
I0816 16:04:04.269299 20404 net.cpp:141] Setting up norm1
I0816 16:04:04.269315 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.269322 20404 net.cpp:156] Memory required for data: 3088905200
I0816 16:04:04.269330 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:04.269340 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:04.269348 20404 net.cpp:425] pool1 <- LRN71
I0816 16:04:04.269362 20404 net.cpp:399] pool1 -> Pooling106
I0816 16:04:04.269423 20404 net.cpp:141] Setting up pool1
I0816 16:04:04.269443 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:04.269454 20404 net.cpp:156] Memory required for data: 3091362800
I0816 16:04:04.269462 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:04.269480 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:04.269490 20404 net.cpp:425] conv2 <- Pooling106
I0816 16:04:04.269502 20404 net.cpp:399] conv2 -> Convolution177
I0816 16:04:04.284966 20404 net.cpp:141] Setting up conv2
I0816 16:04:04.284987 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.284996 20404 net.cpp:156] Memory required for data: 3097916400
I0816 16:04:04.285020 20404 layer_factory.hpp:77] Creating layer ReLU246
I0816 16:04:04.285035 20404 net.cpp:91] Creating Layer ReLU246
I0816 16:04:04.285045 20404 net.cpp:425] ReLU246 <- Convolution177
I0816 16:04:04.285056 20404 net.cpp:386] ReLU246 -> Convolution177 (in-place)
I0816 16:04:04.285070 20404 net.cpp:141] Setting up ReLU246
I0816 16:04:04.285085 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.285094 20404 net.cpp:156] Memory required for data: 3104470000
I0816 16:04:04.285101 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:04.285130 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:04.285140 20404 net.cpp:425] norm2 <- Convolution177
I0816 16:04:04.285152 20404 net.cpp:399] norm2 -> LRN72
I0816 16:04:04.285212 20404 net.cpp:141] Setting up norm2
I0816 16:04:04.285226 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.285234 20404 net.cpp:156] Memory required for data: 3111023600
I0816 16:04:04.285241 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:04.285253 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:04.285260 20404 net.cpp:425] pool2 <- LRN72
I0816 16:04:04.285274 20404 net.cpp:399] pool2 -> Pooling107
I0816 16:04:04.285331 20404 net.cpp:141] Setting up pool2
I0816 16:04:04.285346 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.285353 20404 net.cpp:156] Memory required for data: 3112662000
I0816 16:04:04.285361 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:04.285383 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:04.285394 20404 net.cpp:425] conv3 <- Pooling107
I0816 16:04:04.285408 20404 net.cpp:399] conv3 -> Convolution178
I0816 16:04:04.329074 20404 net.cpp:141] Setting up conv3
I0816 16:04:04.329104 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.329123 20404 net.cpp:156] Memory required for data: 3115119600
I0816 16:04:04.329139 20404 layer_factory.hpp:77] Creating layer ReLU247
I0816 16:04:04.329154 20404 net.cpp:91] Creating Layer ReLU247
I0816 16:04:04.329164 20404 net.cpp:425] ReLU247 <- Convolution178
I0816 16:04:04.329177 20404 net.cpp:386] ReLU247 -> Convolution178 (in-place)
I0816 16:04:04.329201 20404 net.cpp:141] Setting up ReLU247
I0816 16:04:04.329212 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.329219 20404 net.cpp:156] Memory required for data: 3117577200
I0816 16:04:04.329227 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:04.329252 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:04.329260 20404 net.cpp:425] conv4 <- Convolution178
I0816 16:04:04.329273 20404 net.cpp:399] conv4 -> Convolution179
I0816 16:04:04.362429 20404 net.cpp:141] Setting up conv4
I0816 16:04:04.362462 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.362470 20404 net.cpp:156] Memory required for data: 3120034800
I0816 16:04:04.362486 20404 layer_factory.hpp:77] Creating layer ReLU248
I0816 16:04:04.362500 20404 net.cpp:91] Creating Layer ReLU248
I0816 16:04:04.362510 20404 net.cpp:425] ReLU248 <- Convolution179
I0816 16:04:04.362524 20404 net.cpp:386] ReLU248 -> Convolution179 (in-place)
I0816 16:04:04.362540 20404 net.cpp:141] Setting up ReLU248
I0816 16:04:04.362550 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.362557 20404 net.cpp:156] Memory required for data: 3122492400
I0816 16:04:04.362565 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:04.362586 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:04.362594 20404 net.cpp:425] conv5 <- Convolution179
I0816 16:04:04.362612 20404 net.cpp:399] conv5 -> Convolution180
I0816 16:04:04.384644 20404 net.cpp:141] Setting up conv5
I0816 16:04:04.384667 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.384675 20404 net.cpp:156] Memory required for data: 3124130800
I0816 16:04:04.384699 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:04.384716 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:04.384726 20404 net.cpp:425] pool5 <- Convolution180
I0816 16:04:04.384742 20404 net.cpp:399] pool5 -> Pooling108
I0816 16:04:04.384819 20404 net.cpp:141] Setting up pool5
I0816 16:04:04.384835 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:04.384841 20404 net.cpp:156] Memory required for data: 3124540400
I0816 16:04:04.384848 20404 layer_factory.hpp:77] Creating layer InnerProduct105
I0816 16:04:04.384862 20404 net.cpp:91] Creating Layer InnerProduct105
I0816 16:04:04.384871 20404 net.cpp:425] InnerProduct105 <- Pooling108
I0816 16:04:04.384888 20404 net.cpp:399] InnerProduct105 -> InnerProduct105
I0816 16:04:04.387652 20404 net.cpp:141] Setting up InnerProduct105
I0816 16:04:04.387689 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.387697 20404 net.cpp:156] Memory required for data: 3124642800
I0816 16:04:04.387707 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:04.387718 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:04.387727 20404 layer_factory.hpp:77] Creating layer ReLU249
I0816 16:04:04.387740 20404 net.cpp:91] Creating Layer ReLU249
I0816 16:04:04.387750 20404 net.cpp:425] ReLU249 <- InnerProduct105
I0816 16:04:04.387761 20404 net.cpp:386] ReLU249 -> InnerProduct105 (in-place)
I0816 16:04:04.387775 20404 net.cpp:141] Setting up ReLU249
I0816 16:04:04.387786 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.387794 20404 net.cpp:156] Memory required for data: 3124745200
I0816 16:04:04.387801 20404 layer_factory.hpp:77] Creating layer InnerProduct106
I0816 16:04:04.387814 20404 net.cpp:91] Creating Layer InnerProduct106
I0816 16:04:04.387822 20404 net.cpp:425] InnerProduct106 <- InnerProduct105
I0816 16:04:04.387837 20404 net.cpp:399] InnerProduct106 -> InnerProduct106
I0816 16:04:04.388501 20404 net.cpp:141] Setting up InnerProduct106
I0816 16:04:04.388515 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.388523 20404 net.cpp:156] Memory required for data: 3124847600
I0816 16:04:04.388531 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:04.388540 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:04.388550 20404 layer_factory.hpp:77] Creating layer ReLU250
I0816 16:04:04.388562 20404 net.cpp:91] Creating Layer ReLU250
I0816 16:04:04.388571 20404 net.cpp:425] ReLU250 <- InnerProduct106
I0816 16:04:04.388581 20404 net.cpp:386] ReLU250 -> InnerProduct106 (in-place)
I0816 16:04:04.388594 20404 net.cpp:141] Setting up ReLU250
I0816 16:04:04.388604 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.388612 20404 net.cpp:156] Memory required for data: 3124950000
I0816 16:04:04.388619 20404 layer_factory.hpp:77] Creating layer Concat18
I0816 16:04:04.388630 20404 net.cpp:91] Creating Layer Concat18
I0816 16:04:04.388638 20404 net.cpp:425] Concat18 <- InnerProduct104
I0816 16:04:04.388648 20404 net.cpp:425] Concat18 <- InnerProduct106
I0816 16:04:04.388660 20404 net.cpp:399] Concat18 -> Concat18
I0816 16:04:04.388700 20404 net.cpp:141] Setting up Concat18
I0816 16:04:04.388715 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:04.388721 20404 net.cpp:156] Memory required for data: 3125154800
I0816 16:04:04.388730 20404 layer_factory.hpp:77] Creating layer InnerProduct107
I0816 16:04:04.388741 20404 net.cpp:91] Creating Layer InnerProduct107
I0816 16:04:04.388753 20404 net.cpp:425] InnerProduct107 <- Concat18
I0816 16:04:04.388766 20404 net.cpp:399] InnerProduct107 -> InnerProduct107
I0816 16:04:04.390498 20404 net.cpp:141] Setting up InnerProduct107
I0816 16:04:04.390519 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.390527 20404 net.cpp:156] Memory required for data: 3125257200
I0816 16:04:04.390537 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:04.390547 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:04.390555 20404 layer_factory.hpp:77] Creating layer ReLU251
I0816 16:04:04.390568 20404 net.cpp:91] Creating Layer ReLU251
I0816 16:04:04.390575 20404 net.cpp:425] ReLU251 <- InnerProduct107
I0816 16:04:04.390590 20404 net.cpp:386] ReLU251 -> InnerProduct107 (in-place)
I0816 16:04:04.390605 20404 net.cpp:141] Setting up ReLU251
I0816 16:04:04.390615 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.390622 20404 net.cpp:156] Memory required for data: 3125359600
I0816 16:04:04.390630 20404 layer_factory.hpp:77] Creating layer InnerProduct108
I0816 16:04:04.390643 20404 net.cpp:91] Creating Layer InnerProduct108
I0816 16:04:04.390651 20404 net.cpp:425] InnerProduct108 <- InnerProduct107
I0816 16:04:04.390681 20404 net.cpp:399] InnerProduct108 -> InnerProduct108
I0816 16:04:04.391124 20404 net.cpp:141] Setting up InnerProduct108
I0816 16:04:04.391140 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:04.391149 20404 net.cpp:156] Memory required for data: 3125410800
I0816 16:04:04.391156 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:04.391167 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:04.391175 20404 layer_factory.hpp:77] Creating layer ReLU252
I0816 16:04:04.391185 20404 net.cpp:91] Creating Layer ReLU252
I0816 16:04:04.391193 20404 net.cpp:425] ReLU252 <- InnerProduct108
I0816 16:04:04.391204 20404 net.cpp:386] ReLU252 -> InnerProduct108 (in-place)
I0816 16:04:04.391217 20404 net.cpp:141] Setting up ReLU252
I0816 16:04:04.391227 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:04.391233 20404 net.cpp:156] Memory required for data: 3125462000
I0816 16:04:04.391242 20404 layer_factory.hpp:77] Creating layer dt17
I0816 16:04:04.391253 20404 net.cpp:91] Creating Layer dt17
I0816 16:04:04.391260 20404 net.cpp:425] dt17 <- InnerProduct108
I0816 16:04:04.391285 20404 net.cpp:399] dt17 -> dt17
I0816 16:04:04.391438 20404 net.cpp:141] Setting up dt17
I0816 16:04:04.391453 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:04.391459 20404 net.cpp:156] Memory required for data: 3125462400
I0816 16:04:04.391468 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:04.391477 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:04.391485 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:04.391501 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:04.391510 20404 net.cpp:425] conv1 <- p2_p2_0_split_9
I0816 16:04:04.391525 20404 net.cpp:399] conv1 -> Convolution181
I0816 16:04:04.394201 20404 net.cpp:141] Setting up conv1
I0816 16:04:04.394222 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.394230 20404 net.cpp:156] Memory required for data: 3135292800
I0816 16:04:04.394244 20404 layer_factory.hpp:77] Creating layer ReLU253
I0816 16:04:04.394256 20404 net.cpp:91] Creating Layer ReLU253
I0816 16:04:04.394266 20404 net.cpp:425] ReLU253 <- Convolution181
I0816 16:04:04.394280 20404 net.cpp:386] ReLU253 -> Convolution181 (in-place)
I0816 16:04:04.394294 20404 net.cpp:141] Setting up ReLU253
I0816 16:04:04.394304 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.394312 20404 net.cpp:156] Memory required for data: 3145123200
I0816 16:04:04.394320 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:04.394335 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:04.394342 20404 net.cpp:425] norm1 <- Convolution181
I0816 16:04:04.394356 20404 net.cpp:399] norm1 -> LRN73
I0816 16:04:04.394408 20404 net.cpp:141] Setting up norm1
I0816 16:04:04.394423 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.394429 20404 net.cpp:156] Memory required for data: 3154953600
I0816 16:04:04.394436 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:04.394450 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:04.394459 20404 net.cpp:425] pool1 <- LRN73
I0816 16:04:04.394470 20404 net.cpp:399] pool1 -> Pooling109
I0816 16:04:04.394532 20404 net.cpp:141] Setting up pool1
I0816 16:04:04.394546 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:04.394553 20404 net.cpp:156] Memory required for data: 3157411200
I0816 16:04:04.394561 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:04.394580 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:04.394589 20404 net.cpp:425] conv2 <- Pooling109
I0816 16:04:04.394605 20404 net.cpp:399] conv2 -> Convolution182
I0816 16:04:04.410043 20404 net.cpp:141] Setting up conv2
I0816 16:04:04.410065 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.410073 20404 net.cpp:156] Memory required for data: 3163964800
I0816 16:04:04.410087 20404 layer_factory.hpp:77] Creating layer ReLU254
I0816 16:04:04.410128 20404 net.cpp:91] Creating Layer ReLU254
I0816 16:04:04.410138 20404 net.cpp:425] ReLU254 <- Convolution182
I0816 16:04:04.410150 20404 net.cpp:386] ReLU254 -> Convolution182 (in-place)
I0816 16:04:04.410173 20404 net.cpp:141] Setting up ReLU254
I0816 16:04:04.410184 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.410192 20404 net.cpp:156] Memory required for data: 3170518400
I0816 16:04:04.410199 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:04.410213 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:04.410223 20404 net.cpp:425] norm2 <- Convolution182
I0816 16:04:04.410234 20404 net.cpp:399] norm2 -> LRN74
I0816 16:04:04.410295 20404 net.cpp:141] Setting up norm2
I0816 16:04:04.410310 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.410317 20404 net.cpp:156] Memory required for data: 3177072000
I0816 16:04:04.410325 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:04.410338 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:04.410347 20404 net.cpp:425] pool2 <- LRN74
I0816 16:04:04.410362 20404 net.cpp:399] pool2 -> Pooling110
I0816 16:04:04.410420 20404 net.cpp:141] Setting up pool2
I0816 16:04:04.410434 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.410441 20404 net.cpp:156] Memory required for data: 3178710400
I0816 16:04:04.410449 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:04.410468 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:04.410481 20404 net.cpp:425] conv3 <- Pooling110
I0816 16:04:04.410498 20404 net.cpp:399] conv3 -> Convolution183
I0816 16:04:04.454308 20404 net.cpp:141] Setting up conv3
I0816 16:04:04.454339 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.454349 20404 net.cpp:156] Memory required for data: 3181168000
I0816 16:04:04.454365 20404 layer_factory.hpp:77] Creating layer ReLU255
I0816 16:04:04.454383 20404 net.cpp:91] Creating Layer ReLU255
I0816 16:04:04.454455 20404 net.cpp:425] ReLU255 <- Convolution183
I0816 16:04:04.454473 20404 net.cpp:386] ReLU255 -> Convolution183 (in-place)
I0816 16:04:04.454489 20404 net.cpp:141] Setting up ReLU255
I0816 16:04:04.454500 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.454507 20404 net.cpp:156] Memory required for data: 3183625600
I0816 16:04:04.454515 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:04.454535 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:04.454553 20404 net.cpp:425] conv4 <- Convolution183
I0816 16:04:04.454571 20404 net.cpp:399] conv4 -> Convolution184
I0816 16:04:04.487583 20404 net.cpp:141] Setting up conv4
I0816 16:04:04.487612 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.487622 20404 net.cpp:156] Memory required for data: 3186083200
I0816 16:04:04.487637 20404 layer_factory.hpp:77] Creating layer ReLU256
I0816 16:04:04.487653 20404 net.cpp:91] Creating Layer ReLU256
I0816 16:04:04.487663 20404 net.cpp:425] ReLU256 <- Convolution184
I0816 16:04:04.487680 20404 net.cpp:386] ReLU256 -> Convolution184 (in-place)
I0816 16:04:04.487697 20404 net.cpp:141] Setting up ReLU256
I0816 16:04:04.487707 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.487715 20404 net.cpp:156] Memory required for data: 3188540800
I0816 16:04:04.487722 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:04.487742 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:04.487751 20404 net.cpp:425] conv5 <- Convolution184
I0816 16:04:04.487764 20404 net.cpp:399] conv5 -> Convolution185
I0816 16:04:04.509682 20404 net.cpp:141] Setting up conv5
I0816 16:04:04.509709 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.509717 20404 net.cpp:156] Memory required for data: 3190179200
I0816 16:04:04.509735 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:04.509749 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:04.509758 20404 net.cpp:425] pool5 <- Convolution185
I0816 16:04:04.509776 20404 net.cpp:399] pool5 -> Pooling111
I0816 16:04:04.509843 20404 net.cpp:141] Setting up pool5
I0816 16:04:04.509857 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:04.509886 20404 net.cpp:156] Memory required for data: 3190588800
I0816 16:04:04.509894 20404 layer_factory.hpp:77] Creating layer InnerProduct109
I0816 16:04:04.509912 20404 net.cpp:91] Creating Layer InnerProduct109
I0816 16:04:04.509919 20404 net.cpp:425] InnerProduct109 <- Pooling111
I0816 16:04:04.509937 20404 net.cpp:399] InnerProduct109 -> InnerProduct109
I0816 16:04:04.512701 20404 net.cpp:141] Setting up InnerProduct109
I0816 16:04:04.512722 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.512729 20404 net.cpp:156] Memory required for data: 3190691200
I0816 16:04:04.512739 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:04.512750 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:04.512758 20404 layer_factory.hpp:77] Creating layer ReLU257
I0816 16:04:04.512769 20404 net.cpp:91] Creating Layer ReLU257
I0816 16:04:04.512778 20404 net.cpp:425] ReLU257 <- InnerProduct109
I0816 16:04:04.512794 20404 net.cpp:386] ReLU257 -> InnerProduct109 (in-place)
I0816 16:04:04.512807 20404 net.cpp:141] Setting up ReLU257
I0816 16:04:04.512817 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.512825 20404 net.cpp:156] Memory required for data: 3190793600
I0816 16:04:04.512832 20404 layer_factory.hpp:77] Creating layer InnerProduct110
I0816 16:04:04.512845 20404 net.cpp:91] Creating Layer InnerProduct110
I0816 16:04:04.512852 20404 net.cpp:425] InnerProduct110 <- InnerProduct109
I0816 16:04:04.512868 20404 net.cpp:399] InnerProduct110 -> InnerProduct110
I0816 16:04:04.513581 20404 net.cpp:141] Setting up InnerProduct110
I0816 16:04:04.513623 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.513643 20404 net.cpp:156] Memory required for data: 3190896000
I0816 16:04:04.513658 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:04.513669 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:04.513676 20404 layer_factory.hpp:77] Creating layer ReLU258
I0816 16:04:04.513689 20404 net.cpp:91] Creating Layer ReLU258
I0816 16:04:04.513697 20404 net.cpp:425] ReLU258 <- InnerProduct110
I0816 16:04:04.513710 20404 net.cpp:386] ReLU258 -> InnerProduct110 (in-place)
I0816 16:04:04.513723 20404 net.cpp:141] Setting up ReLU258
I0816 16:04:04.513734 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.513741 20404 net.cpp:156] Memory required for data: 3190998400
I0816 16:04:04.513749 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:04.513770 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:04.513780 20404 net.cpp:425] conv1 <- c19
I0816 16:04:04.513800 20404 net.cpp:399] conv1 -> Convolution186
I0816 16:04:04.515856 20404 net.cpp:141] Setting up conv1
I0816 16:04:04.515872 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.515879 20404 net.cpp:156] Memory required for data: 3200828800
I0816 16:04:04.515893 20404 layer_factory.hpp:77] Creating layer ReLU259
I0816 16:04:04.515908 20404 net.cpp:91] Creating Layer ReLU259
I0816 16:04:04.515918 20404 net.cpp:425] ReLU259 <- Convolution186
I0816 16:04:04.515928 20404 net.cpp:386] ReLU259 -> Convolution186 (in-place)
I0816 16:04:04.515941 20404 net.cpp:141] Setting up ReLU259
I0816 16:04:04.515952 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.515959 20404 net.cpp:156] Memory required for data: 3210659200
I0816 16:04:04.515967 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:04.515985 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:04.515992 20404 net.cpp:425] norm1 <- Convolution186
I0816 16:04:04.516005 20404 net.cpp:399] norm1 -> LRN75
I0816 16:04:04.516062 20404 net.cpp:141] Setting up norm1
I0816 16:04:04.516075 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.516083 20404 net.cpp:156] Memory required for data: 3220489600
I0816 16:04:04.516091 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:04.516118 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:04.516126 20404 net.cpp:425] pool1 <- LRN75
I0816 16:04:04.516141 20404 net.cpp:399] pool1 -> Pooling112
I0816 16:04:04.516201 20404 net.cpp:141] Setting up pool1
I0816 16:04:04.516216 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:04.516223 20404 net.cpp:156] Memory required for data: 3222947200
I0816 16:04:04.516230 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:04.516252 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:04.516259 20404 net.cpp:425] conv2 <- Pooling112
I0816 16:04:04.516273 20404 net.cpp:399] conv2 -> Convolution187
I0816 16:04:04.531754 20404 net.cpp:141] Setting up conv2
I0816 16:04:04.531780 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.531787 20404 net.cpp:156] Memory required for data: 3229500800
I0816 16:04:04.531813 20404 layer_factory.hpp:77] Creating layer ReLU260
I0816 16:04:04.531826 20404 net.cpp:91] Creating Layer ReLU260
I0816 16:04:04.531836 20404 net.cpp:425] ReLU260 <- Convolution187
I0816 16:04:04.531848 20404 net.cpp:386] ReLU260 -> Convolution187 (in-place)
I0816 16:04:04.531862 20404 net.cpp:141] Setting up ReLU260
I0816 16:04:04.531883 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.531890 20404 net.cpp:156] Memory required for data: 3236054400
I0816 16:04:04.531898 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:04.531913 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:04.531921 20404 net.cpp:425] norm2 <- Convolution187
I0816 16:04:04.531935 20404 net.cpp:399] norm2 -> LRN76
I0816 16:04:04.531998 20404 net.cpp:141] Setting up norm2
I0816 16:04:04.532012 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.532019 20404 net.cpp:156] Memory required for data: 3242608000
I0816 16:04:04.532027 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:04.532038 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:04.532047 20404 net.cpp:425] pool2 <- LRN76
I0816 16:04:04.532060 20404 net.cpp:399] pool2 -> Pooling113
I0816 16:04:04.532120 20404 net.cpp:141] Setting up pool2
I0816 16:04:04.532137 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.532145 20404 net.cpp:156] Memory required for data: 3244246400
I0816 16:04:04.532153 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:04.532168 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:04.532176 20404 net.cpp:425] conv3 <- Pooling113
I0816 16:04:04.532194 20404 net.cpp:399] conv3 -> Convolution188
I0816 16:04:04.576045 20404 net.cpp:141] Setting up conv3
I0816 16:04:04.576076 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.576095 20404 net.cpp:156] Memory required for data: 3246704000
I0816 16:04:04.576112 20404 layer_factory.hpp:77] Creating layer ReLU261
I0816 16:04:04.576125 20404 net.cpp:91] Creating Layer ReLU261
I0816 16:04:04.576136 20404 net.cpp:425] ReLU261 <- Convolution188
I0816 16:04:04.576150 20404 net.cpp:386] ReLU261 -> Convolution188 (in-place)
I0816 16:04:04.576175 20404 net.cpp:141] Setting up ReLU261
I0816 16:04:04.576186 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.576195 20404 net.cpp:156] Memory required for data: 3249161600
I0816 16:04:04.576201 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:04.576221 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:04.576231 20404 net.cpp:425] conv4 <- Convolution188
I0816 16:04:04.576246 20404 net.cpp:399] conv4 -> Convolution189
I0816 16:04:04.609267 20404 net.cpp:141] Setting up conv4
I0816 16:04:04.609297 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.609316 20404 net.cpp:156] Memory required for data: 3251619200
I0816 16:04:04.609333 20404 layer_factory.hpp:77] Creating layer ReLU262
I0816 16:04:04.609347 20404 net.cpp:91] Creating Layer ReLU262
I0816 16:04:04.609357 20404 net.cpp:425] ReLU262 <- Convolution189
I0816 16:04:04.609385 20404 net.cpp:386] ReLU262 -> Convolution189 (in-place)
I0816 16:04:04.609401 20404 net.cpp:141] Setting up ReLU262
I0816 16:04:04.609412 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.609438 20404 net.cpp:156] Memory required for data: 3254076800
I0816 16:04:04.609447 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:04.609468 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:04.609477 20404 net.cpp:425] conv5 <- Convolution189
I0816 16:04:04.609491 20404 net.cpp:399] conv5 -> Convolution190
I0816 16:04:04.631412 20404 net.cpp:141] Setting up conv5
I0816 16:04:04.631434 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.631453 20404 net.cpp:156] Memory required for data: 3255715200
I0816 16:04:04.631466 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:04.631480 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:04.631489 20404 net.cpp:425] pool5 <- Convolution190
I0816 16:04:04.631508 20404 net.cpp:399] pool5 -> Pooling114
I0816 16:04:04.631584 20404 net.cpp:141] Setting up pool5
I0816 16:04:04.631598 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:04.631606 20404 net.cpp:156] Memory required for data: 3256124800
I0816 16:04:04.631613 20404 layer_factory.hpp:77] Creating layer InnerProduct111
I0816 16:04:04.631631 20404 net.cpp:91] Creating Layer InnerProduct111
I0816 16:04:04.631639 20404 net.cpp:425] InnerProduct111 <- Pooling114
I0816 16:04:04.631656 20404 net.cpp:399] InnerProduct111 -> InnerProduct111
I0816 16:04:04.634372 20404 net.cpp:141] Setting up InnerProduct111
I0816 16:04:04.634392 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.634399 20404 net.cpp:156] Memory required for data: 3256227200
I0816 16:04:04.634415 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:04.634428 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:04.634436 20404 layer_factory.hpp:77] Creating layer ReLU263
I0816 16:04:04.634448 20404 net.cpp:91] Creating Layer ReLU263
I0816 16:04:04.634456 20404 net.cpp:425] ReLU263 <- InnerProduct111
I0816 16:04:04.634479 20404 net.cpp:386] ReLU263 -> InnerProduct111 (in-place)
I0816 16:04:04.634492 20404 net.cpp:141] Setting up ReLU263
I0816 16:04:04.634503 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.634510 20404 net.cpp:156] Memory required for data: 3256329600
I0816 16:04:04.634518 20404 layer_factory.hpp:77] Creating layer InnerProduct112
I0816 16:04:04.634531 20404 net.cpp:91] Creating Layer InnerProduct112
I0816 16:04:04.634541 20404 net.cpp:425] InnerProduct112 <- InnerProduct111
I0816 16:04:04.634555 20404 net.cpp:399] InnerProduct112 -> InnerProduct112
I0816 16:04:04.635223 20404 net.cpp:141] Setting up InnerProduct112
I0816 16:04:04.635238 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.635246 20404 net.cpp:156] Memory required for data: 3256432000
I0816 16:04:04.635254 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:04.635264 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:04.635282 20404 layer_factory.hpp:77] Creating layer ReLU264
I0816 16:04:04.635291 20404 net.cpp:91] Creating Layer ReLU264
I0816 16:04:04.635300 20404 net.cpp:425] ReLU264 <- InnerProduct112
I0816 16:04:04.635310 20404 net.cpp:386] ReLU264 -> InnerProduct112 (in-place)
I0816 16:04:04.635324 20404 net.cpp:141] Setting up ReLU264
I0816 16:04:04.635334 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.635341 20404 net.cpp:156] Memory required for data: 3256534400
I0816 16:04:04.635349 20404 layer_factory.hpp:77] Creating layer Concat19
I0816 16:04:04.635360 20404 net.cpp:91] Creating Layer Concat19
I0816 16:04:04.635368 20404 net.cpp:425] Concat19 <- InnerProduct110
I0816 16:04:04.635378 20404 net.cpp:425] Concat19 <- InnerProduct112
I0816 16:04:04.635395 20404 net.cpp:399] Concat19 -> Concat19
I0816 16:04:04.635437 20404 net.cpp:141] Setting up Concat19
I0816 16:04:04.635450 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:04.635458 20404 net.cpp:156] Memory required for data: 3256739200
I0816 16:04:04.635467 20404 layer_factory.hpp:77] Creating layer InnerProduct113
I0816 16:04:04.635493 20404 net.cpp:91] Creating Layer InnerProduct113
I0816 16:04:04.635505 20404 net.cpp:425] InnerProduct113 <- Concat19
I0816 16:04:04.635521 20404 net.cpp:399] InnerProduct113 -> InnerProduct113
I0816 16:04:04.636696 20404 net.cpp:141] Setting up InnerProduct113
I0816 16:04:04.636713 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.636720 20404 net.cpp:156] Memory required for data: 3256841600
I0816 16:04:04.636729 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:04.636739 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:04.636746 20404 layer_factory.hpp:77] Creating layer ReLU265
I0816 16:04:04.636757 20404 net.cpp:91] Creating Layer ReLU265
I0816 16:04:04.636766 20404 net.cpp:425] ReLU265 <- InnerProduct113
I0816 16:04:04.636780 20404 net.cpp:386] ReLU265 -> InnerProduct113 (in-place)
I0816 16:04:04.636793 20404 net.cpp:141] Setting up ReLU265
I0816 16:04:04.636802 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.636811 20404 net.cpp:156] Memory required for data: 3256944000
I0816 16:04:04.636817 20404 layer_factory.hpp:77] Creating layer InnerProduct114
I0816 16:04:04.636831 20404 net.cpp:91] Creating Layer InnerProduct114
I0816 16:04:04.636838 20404 net.cpp:425] InnerProduct114 <- InnerProduct113
I0816 16:04:04.636853 20404 net.cpp:399] InnerProduct114 -> InnerProduct114
I0816 16:04:04.637264 20404 net.cpp:141] Setting up InnerProduct114
I0816 16:04:04.637279 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:04.637286 20404 net.cpp:156] Memory required for data: 3256995200
I0816 16:04:04.637295 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:04.637305 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:04.637313 20404 layer_factory.hpp:77] Creating layer ReLU266
I0816 16:04:04.637323 20404 net.cpp:91] Creating Layer ReLU266
I0816 16:04:04.637331 20404 net.cpp:425] ReLU266 <- InnerProduct114
I0816 16:04:04.637342 20404 net.cpp:386] ReLU266 -> InnerProduct114 (in-place)
I0816 16:04:04.637354 20404 net.cpp:141] Setting up ReLU266
I0816 16:04:04.637364 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:04.637372 20404 net.cpp:156] Memory required for data: 3257046400
I0816 16:04:04.637379 20404 layer_factory.hpp:77] Creating layer dt18
I0816 16:04:04.637392 20404 net.cpp:91] Creating Layer dt18
I0816 16:04:04.637399 20404 net.cpp:425] dt18 <- InnerProduct114
I0816 16:04:04.637416 20404 net.cpp:399] dt18 -> dt18
I0816 16:04:04.637563 20404 net.cpp:141] Setting up dt18
I0816 16:04:04.637578 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:04.637585 20404 net.cpp:156] Memory required for data: 3257046800
I0816 16:04:04.637593 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:04.637603 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:04.637611 20404 layer_factory.hpp:77] Creating layer con
I0816 16:04:04.637627 20404 net.cpp:91] Creating Layer con
I0816 16:04:04.637636 20404 net.cpp:425] con <- dt0
I0816 16:04:04.637647 20404 net.cpp:425] con <- dt1
I0816 16:04:04.637657 20404 net.cpp:425] con <- dt2
I0816 16:04:04.637666 20404 net.cpp:425] con <- dt3
I0816 16:04:04.637676 20404 net.cpp:425] con <- dt4
I0816 16:04:04.637686 20404 net.cpp:425] con <- dt5
I0816 16:04:04.637694 20404 net.cpp:425] con <- dt6
I0816 16:04:04.637703 20404 net.cpp:425] con <- dt7
I0816 16:04:04.637712 20404 net.cpp:425] con <- dt8
I0816 16:04:04.637722 20404 net.cpp:425] con <- dt9
I0816 16:04:04.637730 20404 net.cpp:425] con <- dt10
I0816 16:04:04.637739 20404 net.cpp:425] con <- dt11
I0816 16:04:04.637748 20404 net.cpp:425] con <- dt12
I0816 16:04:04.637758 20404 net.cpp:425] con <- dt13
I0816 16:04:04.637765 20404 net.cpp:425] con <- dt14
I0816 16:04:04.637774 20404 net.cpp:425] con <- dt15
I0816 16:04:04.637784 20404 net.cpp:425] con <- dt16
I0816 16:04:04.637794 20404 net.cpp:425] con <- dt17
I0816 16:04:04.637814 20404 net.cpp:425] con <- dt18
I0816 16:04:04.637828 20404 net.cpp:399] con -> con
I0816 16:04:04.637871 20404 net.cpp:141] Setting up con
I0816 16:04:04.637884 20404 net.cpp:148] Top shape: 100 19 (1900)
I0816 16:04:04.637892 20404 net.cpp:156] Memory required for data: 3257054400
I0816 16:04:04.637899 20404 layer_factory.hpp:77] Creating layer r1
I0816 16:04:04.637929 20404 net.cpp:91] Creating Layer r1
I0816 16:04:04.637941 20404 net.cpp:425] r1 <- con
I0816 16:04:04.637954 20404 net.cpp:399] r1 -> r1
I0816 16:04:04.638001 20404 net.cpp:141] Setting up r1
I0816 16:04:04.638015 20404 net.cpp:148] Top shape: 100 1 1 19 (1900)
I0816 16:04:04.638023 20404 net.cpp:156] Memory required for data: 3257062000
I0816 16:04:04.638031 20404 layer_factory.hpp:77] Creating layer p
I0816 16:04:04.638041 20404 net.cpp:91] Creating Layer p
I0816 16:04:04.638049 20404 net.cpp:425] p <- r1
I0816 16:04:04.638064 20404 net.cpp:399] p -> p
I0816 16:04:04.638124 20404 net.cpp:141] Setting up p
I0816 16:04:04.638139 20404 net.cpp:148] Top shape: 100 1 1 1 (100)
I0816 16:04:04.638145 20404 net.cpp:156] Memory required for data: 3257062400
I0816 16:04:04.638154 20404 layer_factory.hpp:77] Creating layer r2
I0816 16:04:04.638166 20404 net.cpp:91] Creating Layer r2
I0816 16:04:04.638175 20404 net.cpp:425] r2 <- p
I0816 16:04:04.638185 20404 net.cpp:399] r2 -> r2
I0816 16:04:04.638222 20404 net.cpp:141] Setting up r2
I0816 16:04:04.638236 20404 net.cpp:148] Top shape: 100 1 1 1 (100)
I0816 16:04:04.638243 20404 net.cpp:156] Memory required for data: 3257062800
I0816 16:04:04.638252 20404 layer_factory.hpp:77] Creating layer padL
I0816 16:04:04.638262 20404 net.cpp:91] Creating Layer padL
I0816 16:04:04.638270 20404 net.cpp:425] padL <- label_data_1_split_1
I0816 16:04:04.638284 20404 net.cpp:399] padL -> padL
I0816 16:04:04.638321 20404 net.cpp:141] Setting up padL
I0816 16:04:04.638334 20404 net.cpp:148] Top shape: 100 1 1 1 (100)
I0816 16:04:04.638341 20404 net.cpp:156] Memory required for data: 3257063200
I0816 16:04:04.638348 20404 layer_factory.hpp:77] Creating layer pad
I0816 16:04:04.638360 20404 net.cpp:91] Creating Layer pad
I0816 16:04:04.638367 20404 net.cpp:425] pad <- r2
I0816 16:04:04.638376 20404 net.cpp:425] pad <- padL
I0816 16:04:04.638387 20404 net.cpp:399] pad -> pad
I0816 16:04:04.638427 20404 net.cpp:141] Setting up pad
I0816 16:04:04.638442 20404 net.cpp:148] Top shape: 100 2 1 1 (200)
I0816 16:04:04.638449 20404 net.cpp:156] Memory required for data: 3257064000
I0816 16:04:04.638456 20404 layer_factory.hpp:77] Creating layer pad_pad_0_split
I0816 16:04:04.638466 20404 net.cpp:91] Creating Layer pad_pad_0_split
I0816 16:04:04.638474 20404 net.cpp:425] pad_pad_0_split <- pad
I0816 16:04:04.638485 20404 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_0
I0816 16:04:04.638499 20404 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_1
I0816 16:04:04.638555 20404 net.cpp:141] Setting up pad_pad_0_split
I0816 16:04:04.638566 20404 net.cpp:148] Top shape: 100 2 1 1 (200)
I0816 16:04:04.638577 20404 net.cpp:148] Top shape: 100 2 1 1 (200)
I0816 16:04:04.638584 20404 net.cpp:156] Memory required for data: 3257065600
I0816 16:04:04.638592 20404 layer_factory.hpp:77] Creating layer loss
I0816 16:04:04.638602 20404 net.cpp:91] Creating Layer loss
I0816 16:04:04.638609 20404 net.cpp:425] loss <- pad_pad_0_split_0
I0816 16:04:04.638619 20404 net.cpp:425] loss <- th_th_0_split_0
I0816 16:04:04.638633 20404 net.cpp:399] loss -> loss
I0816 16:04:04.638676 20404 net.cpp:141] Setting up loss
I0816 16:04:04.638689 20404 net.cpp:148] Top shape: (1)
I0816 16:04:04.638696 20404 net.cpp:151]     with loss weight 1
I0816 16:04:04.638720 20404 net.cpp:156] Memory required for data: 3257065604
I0816 16:04:04.638728 20404 layer_factory.hpp:77] Creating layer accuracy
I0816 16:04:04.638739 20404 net.cpp:91] Creating Layer accuracy
I0816 16:04:04.638747 20404 net.cpp:425] accuracy <- pad_pad_0_split_1
I0816 16:04:04.638757 20404 net.cpp:425] accuracy <- th_th_0_split_1
I0816 16:04:04.638770 20404 net.cpp:399] accuracy -> accuracy
I0816 16:04:04.638798 20404 net.cpp:141] Setting up accuracy
I0816 16:04:04.638811 20404 net.cpp:148] Top shape: (1)
I0816 16:04:04.638818 20404 net.cpp:156] Memory required for data: 3257065608
I0816 16:04:04.638826 20404 net.cpp:219] accuracy does not need backward computation.
I0816 16:04:04.638835 20404 net.cpp:217] loss needs backward computation.
I0816 16:04:04.638847 20404 net.cpp:217] pad_pad_0_split needs backward computation.
I0816 16:04:04.638856 20404 net.cpp:217] pad needs backward computation.
I0816 16:04:04.638865 20404 net.cpp:219] padL does not need backward computation.
I0816 16:04:04.638875 20404 net.cpp:217] r2 needs backward computation.
I0816 16:04:04.638881 20404 net.cpp:217] p needs backward computation.
I0816 16:04:04.638890 20404 net.cpp:217] r1 needs backward computation.
I0816 16:04:04.638897 20404 net.cpp:217] con needs backward computation.
I0816 16:04:04.638911 20404 net.cpp:217] dt18 needs backward computation.
I0816 16:04:04.638918 20404 net.cpp:217] ReLU266 needs backward computation.
I0816 16:04:04.638926 20404 net.cpp:217] InnerProduct114 needs backward computation.
I0816 16:04:04.638934 20404 net.cpp:217] ReLU265 needs backward computation.
I0816 16:04:04.638942 20404 net.cpp:217] InnerProduct113 needs backward computation.
I0816 16:04:04.638950 20404 net.cpp:217] Concat19 needs backward computation.
I0816 16:04:04.638959 20404 net.cpp:217] ReLU264 needs backward computation.
I0816 16:04:04.638967 20404 net.cpp:217] InnerProduct112 needs backward computation.
I0816 16:04:04.638975 20404 net.cpp:217] ReLU263 needs backward computation.
I0816 16:04:04.638983 20404 net.cpp:217] InnerProduct111 needs backward computation.
I0816 16:04:04.638991 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.638999 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.639008 20404 net.cpp:219] ReLU262 does not need backward computation.
I0816 16:04:04.639016 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.639025 20404 net.cpp:219] ReLU261 does not need backward computation.
I0816 16:04:04.639034 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.639042 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.639051 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.639060 20404 net.cpp:219] ReLU260 does not need backward computation.
I0816 16:04:04.639070 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.639078 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.639087 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.639096 20404 net.cpp:219] ReLU259 does not need backward computation.
I0816 16:04:04.639104 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.639113 20404 net.cpp:217] ReLU258 needs backward computation.
I0816 16:04:04.639122 20404 net.cpp:217] InnerProduct110 needs backward computation.
I0816 16:04:04.639129 20404 net.cpp:217] ReLU257 needs backward computation.
I0816 16:04:04.639138 20404 net.cpp:217] InnerProduct109 needs backward computation.
I0816 16:04:04.639147 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.639156 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.639165 20404 net.cpp:219] ReLU256 does not need backward computation.
I0816 16:04:04.639173 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.639183 20404 net.cpp:219] ReLU255 does not need backward computation.
I0816 16:04:04.639190 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.639199 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.639209 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.639217 20404 net.cpp:219] ReLU254 does not need backward computation.
I0816 16:04:04.639225 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.639235 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.639255 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.639264 20404 net.cpp:219] ReLU253 does not need backward computation.
I0816 16:04:04.639284 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.639294 20404 net.cpp:217] dt17 needs backward computation.
I0816 16:04:04.639303 20404 net.cpp:217] ReLU252 needs backward computation.
I0816 16:04:04.639312 20404 net.cpp:217] InnerProduct108 needs backward computation.
I0816 16:04:04.639319 20404 net.cpp:217] ReLU251 needs backward computation.
I0816 16:04:04.639328 20404 net.cpp:217] InnerProduct107 needs backward computation.
I0816 16:04:04.639336 20404 net.cpp:217] Concat18 needs backward computation.
I0816 16:04:04.639345 20404 net.cpp:217] ReLU250 needs backward computation.
I0816 16:04:04.639353 20404 net.cpp:217] InnerProduct106 needs backward computation.
I0816 16:04:04.639361 20404 net.cpp:217] ReLU249 needs backward computation.
I0816 16:04:04.639369 20404 net.cpp:217] InnerProduct105 needs backward computation.
I0816 16:04:04.639379 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.639391 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.639401 20404 net.cpp:219] ReLU248 does not need backward computation.
I0816 16:04:04.639410 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.639418 20404 net.cpp:219] ReLU247 does not need backward computation.
I0816 16:04:04.639426 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.639436 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.639446 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.639454 20404 net.cpp:219] ReLU246 does not need backward computation.
I0816 16:04:04.639462 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.639472 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.639480 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.639489 20404 net.cpp:219] ReLU245 does not need backward computation.
I0816 16:04:04.639497 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.639506 20404 net.cpp:217] ReLU244 needs backward computation.
I0816 16:04:04.639514 20404 net.cpp:217] InnerProduct104 needs backward computation.
I0816 16:04:04.639523 20404 net.cpp:217] ReLU243 needs backward computation.
I0816 16:04:04.639531 20404 net.cpp:217] InnerProduct103 needs backward computation.
I0816 16:04:04.639540 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.639549 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.639559 20404 net.cpp:219] ReLU242 does not need backward computation.
I0816 16:04:04.639566 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.639575 20404 net.cpp:219] ReLU241 does not need backward computation.
I0816 16:04:04.639583 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.639593 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.639602 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.639611 20404 net.cpp:219] ReLU240 does not need backward computation.
I0816 16:04:04.639619 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.639627 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.639636 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.639645 20404 net.cpp:219] ReLU239 does not need backward computation.
I0816 16:04:04.639653 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.639663 20404 net.cpp:217] dt16 needs backward computation.
I0816 16:04:04.639672 20404 net.cpp:217] ReLU238 needs backward computation.
I0816 16:04:04.639680 20404 net.cpp:217] InnerProduct102 needs backward computation.
I0816 16:04:04.639689 20404 net.cpp:217] ReLU237 needs backward computation.
I0816 16:04:04.639698 20404 net.cpp:217] InnerProduct101 needs backward computation.
I0816 16:04:04.639719 20404 net.cpp:217] Concat17 needs backward computation.
I0816 16:04:04.639729 20404 net.cpp:217] ReLU236 needs backward computation.
I0816 16:04:04.639736 20404 net.cpp:217] InnerProduct100 needs backward computation.
I0816 16:04:04.639745 20404 net.cpp:217] ReLU235 needs backward computation.
I0816 16:04:04.639753 20404 net.cpp:217] InnerProduct99 needs backward computation.
I0816 16:04:04.639762 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.639772 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.639781 20404 net.cpp:219] ReLU234 does not need backward computation.
I0816 16:04:04.639789 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.639798 20404 net.cpp:219] ReLU233 does not need backward computation.
I0816 16:04:04.639806 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.639816 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.639824 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.639833 20404 net.cpp:219] ReLU232 does not need backward computation.
I0816 16:04:04.639845 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.639855 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.639864 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.639873 20404 net.cpp:219] ReLU231 does not need backward computation.
I0816 16:04:04.639883 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.639891 20404 net.cpp:217] ReLU230 needs backward computation.
I0816 16:04:04.639899 20404 net.cpp:217] InnerProduct98 needs backward computation.
I0816 16:04:04.639909 20404 net.cpp:217] ReLU229 needs backward computation.
I0816 16:04:04.639917 20404 net.cpp:217] InnerProduct97 needs backward computation.
I0816 16:04:04.639926 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.639935 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.639945 20404 net.cpp:219] ReLU228 does not need backward computation.
I0816 16:04:04.639953 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.639962 20404 net.cpp:219] ReLU227 does not need backward computation.
I0816 16:04:04.639971 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.639981 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.639989 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.639998 20404 net.cpp:219] ReLU226 does not need backward computation.
I0816 16:04:04.640007 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.640019 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.640029 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.640038 20404 net.cpp:219] ReLU225 does not need backward computation.
I0816 16:04:04.640048 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.640056 20404 net.cpp:217] dt15 needs backward computation.
I0816 16:04:04.640065 20404 net.cpp:217] ReLU224 needs backward computation.
I0816 16:04:04.640074 20404 net.cpp:217] InnerProduct96 needs backward computation.
I0816 16:04:04.640084 20404 net.cpp:217] ReLU223 needs backward computation.
I0816 16:04:04.640091 20404 net.cpp:217] InnerProduct95 needs backward computation.
I0816 16:04:04.640100 20404 net.cpp:217] Concat16 needs backward computation.
I0816 16:04:04.640110 20404 net.cpp:217] ReLU222 needs backward computation.
I0816 16:04:04.640117 20404 net.cpp:217] InnerProduct94 needs backward computation.
I0816 16:04:04.640126 20404 net.cpp:217] ReLU221 needs backward computation.
I0816 16:04:04.640135 20404 net.cpp:217] InnerProduct93 needs backward computation.
I0816 16:04:04.640151 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.640159 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.640168 20404 net.cpp:219] ReLU220 does not need backward computation.
I0816 16:04:04.640187 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.640197 20404 net.cpp:219] ReLU219 does not need backward computation.
I0816 16:04:04.640204 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.640213 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.640223 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.640239 20404 net.cpp:219] ReLU218 does not need backward computation.
I0816 16:04:04.640249 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.640257 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.640266 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.640275 20404 net.cpp:219] ReLU217 does not need backward computation.
I0816 16:04:04.640283 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.640298 20404 net.cpp:217] ReLU216 needs backward computation.
I0816 16:04:04.640307 20404 net.cpp:217] InnerProduct92 needs backward computation.
I0816 16:04:04.640316 20404 net.cpp:217] ReLU215 needs backward computation.
I0816 16:04:04.640324 20404 net.cpp:217] InnerProduct91 needs backward computation.
I0816 16:04:04.640333 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.640343 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.640352 20404 net.cpp:219] ReLU214 does not need backward computation.
I0816 16:04:04.640360 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.640370 20404 net.cpp:219] ReLU213 does not need backward computation.
I0816 16:04:04.640378 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.640388 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.640396 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.640405 20404 net.cpp:219] ReLU212 does not need backward computation.
I0816 16:04:04.640414 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.640424 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.640432 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.640442 20404 net.cpp:219] ReLU211 does not need backward computation.
I0816 16:04:04.640450 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.640460 20404 net.cpp:217] dt14 needs backward computation.
I0816 16:04:04.640468 20404 net.cpp:217] ReLU210 needs backward computation.
I0816 16:04:04.640476 20404 net.cpp:217] InnerProduct90 needs backward computation.
I0816 16:04:04.640486 20404 net.cpp:217] ReLU209 needs backward computation.
I0816 16:04:04.640494 20404 net.cpp:217] InnerProduct89 needs backward computation.
I0816 16:04:04.640502 20404 net.cpp:217] Concat15 needs backward computation.
I0816 16:04:04.640512 20404 net.cpp:217] ReLU208 needs backward computation.
I0816 16:04:04.640522 20404 net.cpp:217] InnerProduct88 needs backward computation.
I0816 16:04:04.640530 20404 net.cpp:217] ReLU207 needs backward computation.
I0816 16:04:04.640538 20404 net.cpp:217] InnerProduct87 needs backward computation.
I0816 16:04:04.640548 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.640558 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.640566 20404 net.cpp:219] ReLU206 does not need backward computation.
I0816 16:04:04.640575 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.640584 20404 net.cpp:219] ReLU205 does not need backward computation.
I0816 16:04:04.640594 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.640602 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.640611 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.640620 20404 net.cpp:219] ReLU204 does not need backward computation.
I0816 16:04:04.640630 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.640648 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.640658 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.640668 20404 net.cpp:219] ReLU203 does not need backward computation.
I0816 16:04:04.640676 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.640689 20404 net.cpp:217] ReLU202 needs backward computation.
I0816 16:04:04.640698 20404 net.cpp:217] InnerProduct86 needs backward computation.
I0816 16:04:04.640707 20404 net.cpp:217] ReLU201 needs backward computation.
I0816 16:04:04.640715 20404 net.cpp:217] InnerProduct85 needs backward computation.
I0816 16:04:04.640725 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.640735 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.640745 20404 net.cpp:219] ReLU200 does not need backward computation.
I0816 16:04:04.640753 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.640763 20404 net.cpp:219] ReLU199 does not need backward computation.
I0816 16:04:04.640771 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.640781 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.640789 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.640796 20404 net.cpp:219] ReLU198 does not need backward computation.
I0816 16:04:04.640802 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.640810 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.640817 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.640825 20404 net.cpp:219] ReLU197 does not need backward computation.
I0816 16:04:04.640831 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.640839 20404 net.cpp:217] dt13 needs backward computation.
I0816 16:04:04.640846 20404 net.cpp:217] ReLU196 needs backward computation.
I0816 16:04:04.640852 20404 net.cpp:217] InnerProduct84 needs backward computation.
I0816 16:04:04.640859 20404 net.cpp:217] ReLU195 needs backward computation.
I0816 16:04:04.640866 20404 net.cpp:217] InnerProduct83 needs backward computation.
I0816 16:04:04.640873 20404 net.cpp:217] Concat14 needs backward computation.
I0816 16:04:04.640880 20404 net.cpp:217] ReLU194 needs backward computation.
I0816 16:04:04.640887 20404 net.cpp:217] InnerProduct82 needs backward computation.
I0816 16:04:04.640894 20404 net.cpp:217] ReLU193 needs backward computation.
I0816 16:04:04.640900 20404 net.cpp:217] InnerProduct81 needs backward computation.
I0816 16:04:04.640908 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.640915 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.640923 20404 net.cpp:219] ReLU192 does not need backward computation.
I0816 16:04:04.640929 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.640938 20404 net.cpp:219] ReLU191 does not need backward computation.
I0816 16:04:04.640944 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.640951 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.640959 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.640965 20404 net.cpp:219] ReLU190 does not need backward computation.
I0816 16:04:04.640972 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.640980 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.640986 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.640995 20404 net.cpp:219] ReLU189 does not need backward computation.
I0816 16:04:04.641000 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.641007 20404 net.cpp:217] ReLU188 needs backward computation.
I0816 16:04:04.641014 20404 net.cpp:217] InnerProduct80 needs backward computation.
I0816 16:04:04.641021 20404 net.cpp:217] ReLU187 needs backward computation.
I0816 16:04:04.641027 20404 net.cpp:217] InnerProduct79 needs backward computation.
I0816 16:04:04.641043 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.641050 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.641058 20404 net.cpp:219] ReLU186 does not need backward computation.
I0816 16:04:04.641064 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.641072 20404 net.cpp:219] ReLU185 does not need backward computation.
I0816 16:04:04.641078 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.641085 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.641093 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.641100 20404 net.cpp:219] ReLU184 does not need backward computation.
I0816 16:04:04.641106 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.641113 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.641121 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.641129 20404 net.cpp:219] ReLU183 does not need backward computation.
I0816 16:04:04.641135 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.641144 20404 net.cpp:217] dt12 needs backward computation.
I0816 16:04:04.641149 20404 net.cpp:217] ReLU182 needs backward computation.
I0816 16:04:04.641156 20404 net.cpp:217] InnerProduct78 needs backward computation.
I0816 16:04:04.641163 20404 net.cpp:217] ReLU181 needs backward computation.
I0816 16:04:04.641170 20404 net.cpp:217] InnerProduct77 needs backward computation.
I0816 16:04:04.641176 20404 net.cpp:217] Concat13 needs backward computation.
I0816 16:04:04.641183 20404 net.cpp:217] ReLU180 needs backward computation.
I0816 16:04:04.641191 20404 net.cpp:217] InnerProduct76 needs backward computation.
I0816 16:04:04.641196 20404 net.cpp:217] ReLU179 needs backward computation.
I0816 16:04:04.641203 20404 net.cpp:217] InnerProduct75 needs backward computation.
I0816 16:04:04.641211 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.641217 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.641227 20404 net.cpp:219] ReLU178 does not need backward computation.
I0816 16:04:04.641234 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.641242 20404 net.cpp:219] ReLU177 does not need backward computation.
I0816 16:04:04.641248 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.641255 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.641263 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.641270 20404 net.cpp:219] ReLU176 does not need backward computation.
I0816 16:04:04.641276 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.641284 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.641291 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.641299 20404 net.cpp:219] ReLU175 does not need backward computation.
I0816 16:04:04.641305 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.641312 20404 net.cpp:217] ReLU174 needs backward computation.
I0816 16:04:04.641319 20404 net.cpp:217] InnerProduct74 needs backward computation.
I0816 16:04:04.641326 20404 net.cpp:217] ReLU173 needs backward computation.
I0816 16:04:04.641332 20404 net.cpp:217] InnerProduct73 needs backward computation.
I0816 16:04:04.641340 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.641347 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.641355 20404 net.cpp:219] ReLU172 does not need backward computation.
I0816 16:04:04.641361 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.641368 20404 net.cpp:219] ReLU171 does not need backward computation.
I0816 16:04:04.641374 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.641381 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.641389 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.641405 20404 net.cpp:219] ReLU170 does not need backward computation.
I0816 16:04:04.641412 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.641418 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.641427 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.641433 20404 net.cpp:219] ReLU169 does not need backward computation.
I0816 16:04:04.641440 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.641448 20404 net.cpp:217] dt11 needs backward computation.
I0816 16:04:04.641454 20404 net.cpp:217] ReLU168 needs backward computation.
I0816 16:04:04.641461 20404 net.cpp:217] InnerProduct72 needs backward computation.
I0816 16:04:04.641469 20404 net.cpp:217] ReLU167 needs backward computation.
I0816 16:04:04.641475 20404 net.cpp:217] InnerProduct71 needs backward computation.
I0816 16:04:04.641482 20404 net.cpp:217] Concat12 needs backward computation.
I0816 16:04:04.641490 20404 net.cpp:217] ReLU166 needs backward computation.
I0816 16:04:04.641496 20404 net.cpp:217] InnerProduct70 needs backward computation.
I0816 16:04:04.641504 20404 net.cpp:217] ReLU165 needs backward computation.
I0816 16:04:04.641510 20404 net.cpp:217] InnerProduct69 needs backward computation.
I0816 16:04:04.641517 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.641525 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.641532 20404 net.cpp:219] ReLU164 does not need backward computation.
I0816 16:04:04.641538 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.641546 20404 net.cpp:219] ReLU163 does not need backward computation.
I0816 16:04:04.641552 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.641559 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.641567 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.641574 20404 net.cpp:219] ReLU162 does not need backward computation.
I0816 16:04:04.641582 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.641588 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.641595 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.641602 20404 net.cpp:219] ReLU161 does not need backward computation.
I0816 16:04:04.641609 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.641616 20404 net.cpp:217] ReLU160 needs backward computation.
I0816 16:04:04.641623 20404 net.cpp:217] InnerProduct68 needs backward computation.
I0816 16:04:04.641630 20404 net.cpp:217] ReLU159 needs backward computation.
I0816 16:04:04.641636 20404 net.cpp:217] InnerProduct67 needs backward computation.
I0816 16:04:04.641644 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.641651 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.641659 20404 net.cpp:219] ReLU158 does not need backward computation.
I0816 16:04:04.641664 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.641671 20404 net.cpp:219] ReLU157 does not need backward computation.
I0816 16:04:04.641679 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.641685 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.641693 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.641700 20404 net.cpp:219] ReLU156 does not need backward computation.
I0816 16:04:04.641707 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.641715 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.641723 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.641731 20404 net.cpp:219] ReLU155 does not need backward computation.
I0816 16:04:04.641738 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.641746 20404 net.cpp:217] dt10 needs backward computation.
I0816 16:04:04.641760 20404 net.cpp:217] ReLU154 needs backward computation.
I0816 16:04:04.641767 20404 net.cpp:217] InnerProduct66 needs backward computation.
I0816 16:04:04.641774 20404 net.cpp:217] ReLU153 needs backward computation.
I0816 16:04:04.641782 20404 net.cpp:217] InnerProduct65 needs backward computation.
I0816 16:04:04.641788 20404 net.cpp:217] Concat11 needs backward computation.
I0816 16:04:04.641796 20404 net.cpp:217] ReLU152 needs backward computation.
I0816 16:04:04.641803 20404 net.cpp:217] InnerProduct64 needs backward computation.
I0816 16:04:04.641809 20404 net.cpp:217] ReLU151 needs backward computation.
I0816 16:04:04.641816 20404 net.cpp:217] InnerProduct63 needs backward computation.
I0816 16:04:04.641824 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.641831 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.641839 20404 net.cpp:219] ReLU150 does not need backward computation.
I0816 16:04:04.641845 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.641854 20404 net.cpp:219] ReLU149 does not need backward computation.
I0816 16:04:04.641860 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.641867 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.641875 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.641881 20404 net.cpp:219] ReLU148 does not need backward computation.
I0816 16:04:04.641888 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.641896 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.641902 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.641911 20404 net.cpp:219] ReLU147 does not need backward computation.
I0816 16:04:04.641916 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.641923 20404 net.cpp:217] ReLU146 needs backward computation.
I0816 16:04:04.641930 20404 net.cpp:217] InnerProduct62 needs backward computation.
I0816 16:04:04.641937 20404 net.cpp:217] ReLU145 needs backward computation.
I0816 16:04:04.641943 20404 net.cpp:217] InnerProduct61 needs backward computation.
I0816 16:04:04.641952 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.641958 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.641966 20404 net.cpp:219] ReLU144 does not need backward computation.
I0816 16:04:04.641973 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.641979 20404 net.cpp:219] ReLU143 does not need backward computation.
I0816 16:04:04.641986 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.641993 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.642001 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.642009 20404 net.cpp:219] ReLU142 does not need backward computation.
I0816 16:04:04.642015 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.642022 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.642030 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.642037 20404 net.cpp:219] ReLU141 does not need backward computation.
I0816 16:04:04.642043 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.642050 20404 net.cpp:217] dt9 needs backward computation.
I0816 16:04:04.642058 20404 net.cpp:217] ReLU140 needs backward computation.
I0816 16:04:04.642065 20404 net.cpp:217] InnerProduct60 needs backward computation.
I0816 16:04:04.642071 20404 net.cpp:217] ReLU139 needs backward computation.
I0816 16:04:04.642077 20404 net.cpp:217] InnerProduct59 needs backward computation.
I0816 16:04:04.642084 20404 net.cpp:217] Concat10 needs backward computation.
I0816 16:04:04.642092 20404 net.cpp:217] ReLU138 needs backward computation.
I0816 16:04:04.642098 20404 net.cpp:217] InnerProduct58 needs backward computation.
I0816 16:04:04.642105 20404 net.cpp:217] ReLU137 needs backward computation.
I0816 16:04:04.642120 20404 net.cpp:217] InnerProduct57 needs backward computation.
I0816 16:04:04.642128 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.642135 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.642143 20404 net.cpp:219] ReLU136 does not need backward computation.
I0816 16:04:04.642150 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.642158 20404 net.cpp:219] ReLU135 does not need backward computation.
I0816 16:04:04.642165 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.642173 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.642180 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.642187 20404 net.cpp:219] ReLU134 does not need backward computation.
I0816 16:04:04.642194 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.642202 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.642210 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.642217 20404 net.cpp:219] ReLU133 does not need backward computation.
I0816 16:04:04.642225 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.642231 20404 net.cpp:217] ReLU132 needs backward computation.
I0816 16:04:04.642238 20404 net.cpp:217] InnerProduct56 needs backward computation.
I0816 16:04:04.642248 20404 net.cpp:217] ReLU131 needs backward computation.
I0816 16:04:04.642254 20404 net.cpp:217] InnerProduct55 needs backward computation.
I0816 16:04:04.642262 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.642271 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.642277 20404 net.cpp:219] ReLU130 does not need backward computation.
I0816 16:04:04.642284 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.642292 20404 net.cpp:219] ReLU129 does not need backward computation.
I0816 16:04:04.642298 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.642307 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.642313 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.642321 20404 net.cpp:219] ReLU128 does not need backward computation.
I0816 16:04:04.642328 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.642335 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.642343 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.642350 20404 net.cpp:219] ReLU127 does not need backward computation.
I0816 16:04:04.642356 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.642364 20404 net.cpp:217] dt8 needs backward computation.
I0816 16:04:04.642371 20404 net.cpp:217] ReLU126 needs backward computation.
I0816 16:04:04.642379 20404 net.cpp:217] InnerProduct54 needs backward computation.
I0816 16:04:04.642385 20404 net.cpp:217] ReLU125 needs backward computation.
I0816 16:04:04.642391 20404 net.cpp:217] InnerProduct53 needs backward computation.
I0816 16:04:04.642398 20404 net.cpp:217] Concat9 needs backward computation.
I0816 16:04:04.642406 20404 net.cpp:217] ReLU124 needs backward computation.
I0816 16:04:04.642413 20404 net.cpp:217] InnerProduct52 needs backward computation.
I0816 16:04:04.642419 20404 net.cpp:217] ReLU123 needs backward computation.
I0816 16:04:04.642426 20404 net.cpp:217] InnerProduct51 needs backward computation.
I0816 16:04:04.642434 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.642441 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.642449 20404 net.cpp:219] ReLU122 does not need backward computation.
I0816 16:04:04.642457 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.642464 20404 net.cpp:219] ReLU121 does not need backward computation.
I0816 16:04:04.642470 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.642478 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.642493 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.642501 20404 net.cpp:219] ReLU120 does not need backward computation.
I0816 16:04:04.642508 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.642516 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.642524 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.642530 20404 net.cpp:219] ReLU119 does not need backward computation.
I0816 16:04:04.642537 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.642544 20404 net.cpp:217] ReLU118 needs backward computation.
I0816 16:04:04.642551 20404 net.cpp:217] InnerProduct50 needs backward computation.
I0816 16:04:04.642559 20404 net.cpp:217] ReLU117 needs backward computation.
I0816 16:04:04.642565 20404 net.cpp:217] InnerProduct49 needs backward computation.
I0816 16:04:04.642572 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.642580 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.642587 20404 net.cpp:219] ReLU116 does not need backward computation.
I0816 16:04:04.642594 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.642601 20404 net.cpp:219] ReLU115 does not need backward computation.
I0816 16:04:04.642608 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.642616 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.642623 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.642632 20404 net.cpp:219] ReLU114 does not need backward computation.
I0816 16:04:04.642637 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.642644 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.642652 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.642659 20404 net.cpp:219] ReLU113 does not need backward computation.
I0816 16:04:04.642666 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.642673 20404 net.cpp:217] dt7 needs backward computation.
I0816 16:04:04.642680 20404 net.cpp:217] ReLU112 needs backward computation.
I0816 16:04:04.642688 20404 net.cpp:217] InnerProduct48 needs backward computation.
I0816 16:04:04.642694 20404 net.cpp:217] ReLU111 needs backward computation.
I0816 16:04:04.642700 20404 net.cpp:217] InnerProduct47 needs backward computation.
I0816 16:04:04.642707 20404 net.cpp:217] Concat8 needs backward computation.
I0816 16:04:04.642715 20404 net.cpp:217] ReLU110 needs backward computation.
I0816 16:04:04.642721 20404 net.cpp:217] InnerProduct46 needs backward computation.
I0816 16:04:04.642729 20404 net.cpp:217] ReLU109 needs backward computation.
I0816 16:04:04.642735 20404 net.cpp:217] InnerProduct45 needs backward computation.
I0816 16:04:04.642742 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.642750 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.642760 20404 net.cpp:219] ReLU108 does not need backward computation.
I0816 16:04:04.642767 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.642776 20404 net.cpp:219] ReLU107 does not need backward computation.
I0816 16:04:04.642782 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.642791 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.642798 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.642805 20404 net.cpp:219] ReLU106 does not need backward computation.
I0816 16:04:04.642812 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.642820 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.642828 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.642835 20404 net.cpp:219] ReLU105 does not need backward computation.
I0816 16:04:04.642843 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.642850 20404 net.cpp:217] ReLU104 needs backward computation.
I0816 16:04:04.642865 20404 net.cpp:217] InnerProduct44 needs backward computation.
I0816 16:04:04.642873 20404 net.cpp:217] ReLU103 needs backward computation.
I0816 16:04:04.642879 20404 net.cpp:217] InnerProduct43 needs backward computation.
I0816 16:04:04.642886 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.642894 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.642902 20404 net.cpp:219] ReLU102 does not need backward computation.
I0816 16:04:04.642910 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.642917 20404 net.cpp:219] ReLU101 does not need backward computation.
I0816 16:04:04.642925 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.642932 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.642940 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.642947 20404 net.cpp:219] ReLU100 does not need backward computation.
I0816 16:04:04.642954 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.642961 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.642969 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.642976 20404 net.cpp:219] ReLU99 does not need backward computation.
I0816 16:04:04.642983 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.642992 20404 net.cpp:217] dt6 needs backward computation.
I0816 16:04:04.642998 20404 net.cpp:217] ReLU98 needs backward computation.
I0816 16:04:04.643004 20404 net.cpp:217] InnerProduct42 needs backward computation.
I0816 16:04:04.643013 20404 net.cpp:217] ReLU97 needs backward computation.
I0816 16:04:04.643018 20404 net.cpp:217] InnerProduct41 needs backward computation.
I0816 16:04:04.643025 20404 net.cpp:217] Concat7 needs backward computation.
I0816 16:04:04.643033 20404 net.cpp:217] ReLU96 needs backward computation.
I0816 16:04:04.643039 20404 net.cpp:217] InnerProduct40 needs backward computation.
I0816 16:04:04.643046 20404 net.cpp:217] ReLU95 needs backward computation.
I0816 16:04:04.643052 20404 net.cpp:217] InnerProduct39 needs backward computation.
I0816 16:04:04.643060 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.643069 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.643075 20404 net.cpp:219] ReLU94 does not need backward computation.
I0816 16:04:04.643082 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.643090 20404 net.cpp:219] ReLU93 does not need backward computation.
I0816 16:04:04.643096 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.643105 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.643111 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.643120 20404 net.cpp:219] ReLU92 does not need backward computation.
I0816 16:04:04.643126 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.643133 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.643141 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.643148 20404 net.cpp:219] ReLU91 does not need backward computation.
I0816 16:04:04.643156 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.643163 20404 net.cpp:217] ReLU90 needs backward computation.
I0816 16:04:04.643169 20404 net.cpp:217] InnerProduct38 needs backward computation.
I0816 16:04:04.643177 20404 net.cpp:217] ReLU89 needs backward computation.
I0816 16:04:04.643183 20404 net.cpp:217] InnerProduct37 needs backward computation.
I0816 16:04:04.643190 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.643198 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.643205 20404 net.cpp:219] ReLU88 does not need backward computation.
I0816 16:04:04.643213 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.643220 20404 net.cpp:219] ReLU87 does not need backward computation.
I0816 16:04:04.643235 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.643242 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.643250 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.643257 20404 net.cpp:219] ReLU86 does not need backward computation.
I0816 16:04:04.643265 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.643280 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.643290 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.643298 20404 net.cpp:219] ReLU85 does not need backward computation.
I0816 16:04:04.643311 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.643317 20404 net.cpp:217] dt5 needs backward computation.
I0816 16:04:04.643324 20404 net.cpp:217] ReLU84 needs backward computation.
I0816 16:04:04.643332 20404 net.cpp:217] InnerProduct36 needs backward computation.
I0816 16:04:04.643338 20404 net.cpp:217] ReLU83 needs backward computation.
I0816 16:04:04.643345 20404 net.cpp:217] InnerProduct35 needs backward computation.
I0816 16:04:04.643352 20404 net.cpp:217] Concat6 needs backward computation.
I0816 16:04:04.643407 20404 net.cpp:217] ReLU82 needs backward computation.
I0816 16:04:04.643414 20404 net.cpp:217] InnerProduct34 needs backward computation.
I0816 16:04:04.643421 20404 net.cpp:217] ReLU81 needs backward computation.
I0816 16:04:04.643429 20404 net.cpp:217] InnerProduct33 needs backward computation.
I0816 16:04:04.643435 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.643443 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.643451 20404 net.cpp:219] ReLU80 does not need backward computation.
I0816 16:04:04.643458 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.643466 20404 net.cpp:219] ReLU79 does not need backward computation.
I0816 16:04:04.643473 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.643481 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.643488 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.643496 20404 net.cpp:219] ReLU78 does not need backward computation.
I0816 16:04:04.643503 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.643510 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.643517 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.643525 20404 net.cpp:219] ReLU77 does not need backward computation.
I0816 16:04:04.643532 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.643540 20404 net.cpp:217] ReLU76 needs backward computation.
I0816 16:04:04.643546 20404 net.cpp:217] InnerProduct32 needs backward computation.
I0816 16:04:04.643553 20404 net.cpp:217] ReLU75 needs backward computation.
I0816 16:04:04.643560 20404 net.cpp:217] InnerProduct31 needs backward computation.
I0816 16:04:04.643568 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.643575 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.643584 20404 net.cpp:219] ReLU74 does not need backward computation.
I0816 16:04:04.643590 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.643597 20404 net.cpp:219] ReLU73 does not need backward computation.
I0816 16:04:04.643604 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.643611 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.643620 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.643626 20404 net.cpp:219] ReLU72 does not need backward computation.
I0816 16:04:04.643633 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.643641 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.643648 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.643656 20404 net.cpp:219] ReLU71 does not need backward computation.
I0816 16:04:04.643672 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.643681 20404 net.cpp:217] dt4 needs backward computation.
I0816 16:04:04.643687 20404 net.cpp:217] ReLU70 needs backward computation.
I0816 16:04:04.643694 20404 net.cpp:217] InnerProduct30 needs backward computation.
I0816 16:04:04.643702 20404 net.cpp:217] ReLU69 needs backward computation.
I0816 16:04:04.643707 20404 net.cpp:217] InnerProduct29 needs backward computation.
I0816 16:04:04.643715 20404 net.cpp:217] Concat5 needs backward computation.
I0816 16:04:04.643723 20404 net.cpp:217] ReLU68 needs backward computation.
I0816 16:04:04.643729 20404 net.cpp:217] InnerProduct28 needs backward computation.
I0816 16:04:04.643736 20404 net.cpp:217] ReLU67 needs backward computation.
I0816 16:04:04.643743 20404 net.cpp:217] InnerProduct27 needs backward computation.
I0816 16:04:04.643751 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.643759 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.643766 20404 net.cpp:219] ReLU66 does not need backward computation.
I0816 16:04:04.643772 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.643780 20404 net.cpp:219] ReLU65 does not need backward computation.
I0816 16:04:04.643787 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.643795 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.643801 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.643810 20404 net.cpp:219] ReLU64 does not need backward computation.
I0816 16:04:04.643816 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.643823 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.643831 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.643838 20404 net.cpp:219] ReLU63 does not need backward computation.
I0816 16:04:04.643846 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.643852 20404 net.cpp:217] ReLU62 needs backward computation.
I0816 16:04:04.643859 20404 net.cpp:217] InnerProduct26 needs backward computation.
I0816 16:04:04.643867 20404 net.cpp:217] ReLU61 needs backward computation.
I0816 16:04:04.643872 20404 net.cpp:217] InnerProduct25 needs backward computation.
I0816 16:04:04.643882 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.643890 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.643898 20404 net.cpp:219] ReLU60 does not need backward computation.
I0816 16:04:04.643905 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.643913 20404 net.cpp:219] ReLU59 does not need backward computation.
I0816 16:04:04.643918 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.643926 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.643934 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.643941 20404 net.cpp:219] ReLU58 does not need backward computation.
I0816 16:04:04.643947 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.643955 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.643962 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.643970 20404 net.cpp:219] ReLU57 does not need backward computation.
I0816 16:04:04.643976 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.643985 20404 net.cpp:217] dt3 needs backward computation.
I0816 16:04:04.643990 20404 net.cpp:217] ReLU56 needs backward computation.
I0816 16:04:04.643997 20404 net.cpp:217] InnerProduct24 needs backward computation.
I0816 16:04:04.644004 20404 net.cpp:217] ReLU55 needs backward computation.
I0816 16:04:04.644011 20404 net.cpp:217] InnerProduct23 needs backward computation.
I0816 16:04:04.644017 20404 net.cpp:217] Concat4 needs backward computation.
I0816 16:04:04.644026 20404 net.cpp:217] ReLU54 needs backward computation.
I0816 16:04:04.644039 20404 net.cpp:217] InnerProduct22 needs backward computation.
I0816 16:04:04.644047 20404 net.cpp:217] ReLU53 needs backward computation.
I0816 16:04:04.644052 20404 net.cpp:217] InnerProduct21 needs backward computation.
I0816 16:04:04.644060 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.644068 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.644076 20404 net.cpp:219] ReLU52 does not need backward computation.
I0816 16:04:04.644083 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.644090 20404 net.cpp:219] ReLU51 does not need backward computation.
I0816 16:04:04.644098 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.644105 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.644112 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.644120 20404 net.cpp:219] ReLU50 does not need backward computation.
I0816 16:04:04.644127 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.644134 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.644142 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.644150 20404 net.cpp:219] ReLU49 does not need backward computation.
I0816 16:04:04.644156 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.644165 20404 net.cpp:217] ReLU48 needs backward computation.
I0816 16:04:04.644170 20404 net.cpp:217] InnerProduct20 needs backward computation.
I0816 16:04:04.644177 20404 net.cpp:217] ReLU47 needs backward computation.
I0816 16:04:04.644184 20404 net.cpp:217] InnerProduct19 needs backward computation.
I0816 16:04:04.644191 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.644199 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.644207 20404 net.cpp:219] ReLU46 does not need backward computation.
I0816 16:04:04.644213 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.644222 20404 net.cpp:219] ReLU45 does not need backward computation.
I0816 16:04:04.644227 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.644235 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.644243 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.644249 20404 net.cpp:219] ReLU44 does not need backward computation.
I0816 16:04:04.644256 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.644264 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.644271 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.644279 20404 net.cpp:219] ReLU43 does not need backward computation.
I0816 16:04:04.644285 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.644294 20404 net.cpp:217] dt2 needs backward computation.
I0816 16:04:04.644300 20404 net.cpp:217] ReLU42 needs backward computation.
I0816 16:04:04.644306 20404 net.cpp:217] InnerProduct18 needs backward computation.
I0816 16:04:04.644315 20404 net.cpp:217] ReLU41 needs backward computation.
I0816 16:04:04.644320 20404 net.cpp:217] InnerProduct17 needs backward computation.
I0816 16:04:04.644327 20404 net.cpp:217] Concat3 needs backward computation.
I0816 16:04:04.644335 20404 net.cpp:217] ReLU40 needs backward computation.
I0816 16:04:04.644341 20404 net.cpp:217] InnerProduct16 needs backward computation.
I0816 16:04:04.644348 20404 net.cpp:217] ReLU39 needs backward computation.
I0816 16:04:04.644356 20404 net.cpp:217] InnerProduct15 needs backward computation.
I0816 16:04:04.644362 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.644371 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.644377 20404 net.cpp:219] ReLU38 does not need backward computation.
I0816 16:04:04.644384 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.644394 20404 net.cpp:219] ReLU37 does not need backward computation.
I0816 16:04:04.644409 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.644418 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.644424 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.644433 20404 net.cpp:219] ReLU36 does not need backward computation.
I0816 16:04:04.644439 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.644448 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.644454 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.644462 20404 net.cpp:219] ReLU35 does not need backward computation.
I0816 16:04:04.644469 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.644477 20404 net.cpp:217] ReLU34 needs backward computation.
I0816 16:04:04.644484 20404 net.cpp:217] InnerProduct14 needs backward computation.
I0816 16:04:04.644491 20404 net.cpp:217] ReLU33 needs backward computation.
I0816 16:04:04.644497 20404 net.cpp:217] InnerProduct13 needs backward computation.
I0816 16:04:04.644505 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.644513 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.644520 20404 net.cpp:219] ReLU32 does not need backward computation.
I0816 16:04:04.644527 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.644536 20404 net.cpp:219] ReLU31 does not need backward computation.
I0816 16:04:04.644542 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.644549 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.644557 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.644564 20404 net.cpp:219] ReLU30 does not need backward computation.
I0816 16:04:04.644572 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.644579 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.644587 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.644594 20404 net.cpp:219] ReLU29 does not need backward computation.
I0816 16:04:04.644601 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.644608 20404 net.cpp:217] dt1 needs backward computation.
I0816 16:04:04.644615 20404 net.cpp:217] ReLU28 needs backward computation.
I0816 16:04:04.644623 20404 net.cpp:217] InnerProduct12 needs backward computation.
I0816 16:04:04.644629 20404 net.cpp:217] ReLU27 needs backward computation.
I0816 16:04:04.644635 20404 net.cpp:217] InnerProduct11 needs backward computation.
I0816 16:04:04.644644 20404 net.cpp:217] Concat2 needs backward computation.
I0816 16:04:04.644651 20404 net.cpp:217] ReLU26 needs backward computation.
I0816 16:04:04.644657 20404 net.cpp:217] InnerProduct10 needs backward computation.
I0816 16:04:04.644665 20404 net.cpp:217] ReLU25 needs backward computation.
I0816 16:04:04.644671 20404 net.cpp:217] InnerProduct9 needs backward computation.
I0816 16:04:04.644678 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.644686 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.644695 20404 net.cpp:219] ReLU24 does not need backward computation.
I0816 16:04:04.644701 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.644708 20404 net.cpp:219] ReLU23 does not need backward computation.
I0816 16:04:04.644716 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.644722 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.644731 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.644737 20404 net.cpp:219] ReLU22 does not need backward computation.
I0816 16:04:04.644744 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.644752 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.644758 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.644765 20404 net.cpp:219] ReLU21 does not need backward computation.
I0816 16:04:04.644779 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.644788 20404 net.cpp:217] ReLU20 needs backward computation.
I0816 16:04:04.644794 20404 net.cpp:217] InnerProduct8 needs backward computation.
I0816 16:04:04.644801 20404 net.cpp:217] ReLU19 needs backward computation.
I0816 16:04:04.644809 20404 net.cpp:217] InnerProduct7 needs backward computation.
I0816 16:04:04.644815 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.644822 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.644830 20404 net.cpp:219] ReLU18 does not need backward computation.
I0816 16:04:04.644837 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.644845 20404 net.cpp:219] ReLU17 does not need backward computation.
I0816 16:04:04.644850 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.644857 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.644865 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.644872 20404 net.cpp:219] ReLU16 does not need backward computation.
I0816 16:04:04.644879 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.644886 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.644893 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.644902 20404 net.cpp:219] ReLU15 does not need backward computation.
I0816 16:04:04.644909 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.644917 20404 net.cpp:217] dt0 needs backward computation.
I0816 16:04:04.644924 20404 net.cpp:217] ReLU14 needs backward computation.
I0816 16:04:04.644932 20404 net.cpp:217] InnerProduct6 needs backward computation.
I0816 16:04:04.644937 20404 net.cpp:217] ReLU13 needs backward computation.
I0816 16:04:04.644953 20404 net.cpp:217] InnerProduct5 needs backward computation.
I0816 16:04:04.644958 20404 net.cpp:217] Concat1 needs backward computation.
I0816 16:04:04.644965 20404 net.cpp:217] ReLU12 needs backward computation.
I0816 16:04:04.644973 20404 net.cpp:217] InnerProduct4 needs backward computation.
I0816 16:04:04.644979 20404 net.cpp:217] ReLU11 needs backward computation.
I0816 16:04:04.644985 20404 net.cpp:217] InnerProduct3 needs backward computation.
I0816 16:04:04.644992 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.644999 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.645006 20404 net.cpp:219] ReLU10 does not need backward computation.
I0816 16:04:04.645012 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.645020 20404 net.cpp:219] ReLU9 does not need backward computation.
I0816 16:04:04.645025 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.645033 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.645040 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.645046 20404 net.cpp:219] ReLU8 does not need backward computation.
I0816 16:04:04.645053 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.645061 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.645067 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.645074 20404 net.cpp:219] ReLU7 does not need backward computation.
I0816 16:04:04.645081 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.645088 20404 net.cpp:217] ReLU6 needs backward computation.
I0816 16:04:04.645094 20404 net.cpp:217] InnerProduct2 needs backward computation.
I0816 16:04:04.645102 20404 net.cpp:217] ReLU5 needs backward computation.
I0816 16:04:04.645107 20404 net.cpp:217] InnerProduct1 needs backward computation.
I0816 16:04:04.645114 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:04.645122 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:04.645128 20404 net.cpp:219] ReLU4 does not need backward computation.
I0816 16:04:04.645143 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:04.645150 20404 net.cpp:219] ReLU3 does not need backward computation.
I0816 16:04:04.645156 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:04.645164 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:04.645171 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:04.645179 20404 net.cpp:219] ReLU2 does not need backward computation.
I0816 16:04:04.645185 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:04.645193 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:04.645201 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:04.645208 20404 net.cpp:219] ReLU1 does not need backward computation.
I0816 16:04:04.645215 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:04.645222 20404 net.cpp:219] c29 does not need backward computation.
I0816 16:04:04.645231 20404 net.cpp:219] Input18 does not need backward computation.
I0816 16:04:04.645236 20404 net.cpp:219] c28 does not need backward computation.
I0816 16:04:04.645246 20404 net.cpp:219] Input17 does not need backward computation.
I0816 16:04:04.645251 20404 net.cpp:219] c27 does not need backward computation.
I0816 16:04:04.645259 20404 net.cpp:219] Input16 does not need backward computation.
I0816 16:04:04.645265 20404 net.cpp:219] c26 does not need backward computation.
I0816 16:04:04.645273 20404 net.cpp:219] Input15 does not need backward computation.
I0816 16:04:04.645279 20404 net.cpp:219] c25 does not need backward computation.
I0816 16:04:04.645287 20404 net.cpp:219] Input14 does not need backward computation.
I0816 16:04:04.645293 20404 net.cpp:219] c24 does not need backward computation.
I0816 16:04:04.645301 20404 net.cpp:219] Input13 does not need backward computation.
I0816 16:04:04.645308 20404 net.cpp:219] c23 does not need backward computation.
I0816 16:04:04.645315 20404 net.cpp:219] Input12 does not need backward computation.
I0816 16:04:04.645321 20404 net.cpp:219] c22 does not need backward computation.
I0816 16:04:04.645331 20404 net.cpp:219] Input11 does not need backward computation.
I0816 16:04:04.645339 20404 net.cpp:219] c21 does not need backward computation.
I0816 16:04:04.645346 20404 net.cpp:219] Input10 does not need backward computation.
I0816 16:04:04.645352 20404 net.cpp:219] c19 does not need backward computation.
I0816 16:04:04.645360 20404 net.cpp:219] Input9 does not need backward computation.
I0816 16:04:04.645366 20404 net.cpp:219] c18 does not need backward computation.
I0816 16:04:04.645375 20404 net.cpp:219] Input8 does not need backward computation.
I0816 16:04:04.645380 20404 net.cpp:219] c17 does not need backward computation.
I0816 16:04:04.645390 20404 net.cpp:219] Input7 does not need backward computation.
I0816 16:04:04.645395 20404 net.cpp:219] c16 does not need backward computation.
I0816 16:04:04.645402 20404 net.cpp:219] Input6 does not need backward computation.
I0816 16:04:04.645408 20404 net.cpp:219] c15 does not need backward computation.
I0816 16:04:04.645416 20404 net.cpp:219] Input5 does not need backward computation.
I0816 16:04:04.645422 20404 net.cpp:219] c14 does not need backward computation.
I0816 16:04:04.645431 20404 net.cpp:219] Input4 does not need backward computation.
I0816 16:04:04.645437 20404 net.cpp:219] c13 does not need backward computation.
I0816 16:04:04.645444 20404 net.cpp:219] Input3 does not need backward computation.
I0816 16:04:04.645450 20404 net.cpp:219] c12 does not need backward computation.
I0816 16:04:04.645459 20404 net.cpp:219] Input2 does not need backward computation.
I0816 16:04:04.645464 20404 net.cpp:219] c11 does not need backward computation.
I0816 16:04:04.645473 20404 net.cpp:219] Input1 does not need backward computation.
I0816 16:04:04.645483 20404 net.cpp:219] p2_p2_0_split does not need backward computation.
I0816 16:04:04.645489 20404 net.cpp:219] p2 does not need backward computation.
I0816 16:04:04.645508 20404 net.cpp:219] p1_p1_0_split does not need backward computation.
I0816 16:04:04.645515 20404 net.cpp:219] p1 does not need backward computation.
I0816 16:04:04.645525 20404 net.cpp:219] i2_i1_1_split does not need backward computation.
I0816 16:04:04.645536 20404 net.cpp:219] i1_i1_0_split does not need backward computation.
I0816 16:04:04.645545 20404 net.cpp:219] i1 does not need backward computation.
I0816 16:04:04.645551 20404 net.cpp:219] th_th_0_split does not need backward computation.
I0816 16:04:04.645558 20404 net.cpp:219] th does not need backward computation.
I0816 16:04:04.645565 20404 net.cpp:219] label_data_1_split does not need backward computation.
I0816 16:04:04.645573 20404 net.cpp:219] data does not need backward computation.
I0816 16:04:04.645578 20404 net.cpp:261] This network produces output accuracy
I0816 16:04:04.645584 20404 net.cpp:261] This network produces output loss
I0816 16:04:04.663414 20404 net.cpp:274] Network initialization done.
I0816 16:04:04.700155 20404 solver.cpp:181] Creating test net (#0) specified by test_net file: examples/scene/matchNetTestHingeMini.prototxt
I0816 16:04:04.710832 20404 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0039215689
    mirror: true
    mean_file: "examples/scene/scene_mean.binaryproto"
  }
  data_param {
    source: "examples/scene/test_pairs_1000_pad.lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "th"
  type: "Threshold"
  bottom: "label"
  top: "th"
  threshold_param {
    threshold: 0
  }
}
layer {
  name: "i1"
  type: "Slice"
  bottom: "data"
  top: "i1"
  top: "i2"
  slice_param {
    slice_dim: 1
    slice_point: 3
  }
}
layer {
  name: "p1"
  type: "Pooling"
  bottom: "i1"
  top: "p1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "p2"
  type: "Pooling"
  bottom: "i2"
  top: "p2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input1"
  type: "Input"
  top: "Input1"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c11"
  type: "Crop"
  bottom: "i1"
  bottom: "Input1"
  top: "c11"
  crop_param {
    axis: 2
    offset: 0
    offset: 0
  }
}
layer {
  name: "Input2"
  type: "Input"
  top: "Input2"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c12"
  type: "Crop"
  bottom: "i1"
  bottom: "Input2"
  top: "c12"
  crop_param {
    axis: 2
    offset: 0
    offset: 32
  }
}
layer {
  name: "Input3"
  type: "Input"
  top: "Input3"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c13"
  type: "Crop"
  bottom: "i1"
  bottom: "Input3"
  top: "c13"
  crop_param {
    axis: 2
    offset: 0
    offset: 64
  }
}
layer {
  name: "Input4"
  type: "Input"
  top: "Input4"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c14"
  type: "Crop"
  bottom: "i1"
  bottom: "Input4"
  top: "c14"
  crop_param {
    axis: 2
    offset: 32
    offset: 0
  }
}
layer {
  name: "Input5"
  type: "Input"
  top: "Input5"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c15"
  type: "Crop"
  bottom: "i1"
  bottom: "Input5"
  top: "c15"
  crop_param {
    axis: 2
    offset: 32
    offset: 32
  }
}
layer {
  name: "Input6"
  type: "Input"
  top: "Input6"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c16"
  type: "Crop"
  bottom: "i1"
  bottom: "Input6"
  top: "c16"
  crop_param {
    axis: 2
    offset: 32
    offset: 64
  }
}
layer {
  name: "Input7"
  type: "Input"
  top: "Input7"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c17"
  type: "Crop"
  bottom: "i1"
  bottom: "Input7"
  top: "c17"
  crop_param {
    axis: 2
    offset: 64
    offset: 0
  }
}
layer {
  name: "Input8"
  type: "Input"
  top: "Input8"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c18"
  type: "Crop"
  bottom: "i1"
  bottom: "Input8"
  top: "c18"
  crop_param {
    axis: 2
    offset: 64
    offset: 32
  }
}
layer {
  name: "Input9"
  type: "Input"
  top: "Input9"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c19"
  type: "Crop"
  bottom: "i1"
  bottom: "Input9"
  top: "c19"
  crop_param {
    axis: 2
    offset: 64
    offset: 64
  }
}
layer {
  name: "Input10"
  type: "Input"
  top: "Input10"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c21"
  type: "Crop"
  bottom: "i2"
  bottom: "Input10"
  top: "c21"
  crop_param {
    axis: 2
    offset: 0
    offset: 0
  }
}
layer {
  name: "Input11"
  type: "Input"
  top: "Input11"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c22"
  type: "Crop"
  bottom: "i2"
  bottom: "Input11"
  top: "c22"
  crop_param {
    axis: 2
    offset: 0
    offset: 32
  }
}
layer {
  name: "Input12"
  type: "Input"
  top: "Input12"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c23"
  type: "Crop"
  bottom: "i2"
  bottom: "Input12"
  top: "c23"
  crop_param {
    axis: 2
    offset: 0
    offset: 64
  }
}
layer {
  name: "Input13"
  type: "Input"
  top: "Input13"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c24"
  type: "Crop"
  bottom: "i2"
  bottom: "Input13"
  top: "c24"
  crop_param {
    axis: 2
    offset: 32
    offset: 0
  }
}
layer {
  name: "Input14"
  type: "Input"
  top: "Input14"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c25"
  type: "Crop"
  bottom: "i2"
  bottom: "Input14"
  top: "c25"
  crop_param {
    axis: 2
    offset: 32
    offset: 32
  }
}
layer {
  name: "Input15"
  type: "Input"
  top: "Input15"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c26"
  type: "Crop"
  bottom: "i2"
  bottom: "Input15"
  top: "c26"
  crop_param {
    axis: 2
    offset: 32
    offset: 64
  }
}
layer {
  name: "Input16"
  type: "Input"
  top: "Input16"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c27"
  type: "Crop"
  bottom: "i2"
  bottom: "Input16"
  top: "c27"
  crop_param {
    axis: 2
    offset: 64
    offset: 0
  }
}
layer {
  name: "Input17"
  type: "Input"
  top: "Input17"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c28"
  type: "Crop"
  bottom: "i2"
  bottom: "Input17"
  top: "c28"
  crop_param {
    axis: 2
    offset: 64
    offset: 32
  }
}
layer {
  name: "Input18"
  type: "Input"
  top: "Input18"
  include {
    phase: TEST
  }
  input_param {
    shape {
      dim: 100
      dim: 3
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "c29"
  type: "Crop"
  bottom: "i2"
  bottom: "Input18"
  top: "c29"
  crop_param {
    axis: 2
    offset: 64
    offset: 64
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "Convolution1"
  top: "LRN1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "LRN1"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Pooling1"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "Convolution2"
  top: "LRN2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "LRN2"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Pooling2"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Convolution3"
  top: "Convolution3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution3"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "Convolution5"
  top: "Pooling3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling3"
  top: "InnerProduct1"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "InnerProduct1"
  top: "InnerProduct1"
}
layer {
  name: "InnerProduct2"
  type: "InnerProduct"
  bottom: "InnerProduct1"
  top: "InnerProduct2"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "InnerProduct2"
  top: "InnerProduct2"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "p2"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "Convolution6"
  top: "LRN3"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "LRN3"
  top: "Pooling4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Pooling4"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution7"
  top: "Convolution7"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "Convolution7"
  top: "LRN4"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "LRN4"
  top: "Pooling5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Pooling5"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "Convolution10"
  top: "Pooling6"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "InnerProduct3"
  type: "InnerProduct"
  bottom: "Pooling6"
  top: "InnerProduct3"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "InnerProduct3"
  top: "InnerProduct3"
}
layer {
  name: "InnerProduct4"
  type: "InnerProduct"
  bottom: "InnerProduct3"
  top: "InnerProduct4"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "InnerProduct4"
  top: "InnerProduct4"
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "InnerProduct2"
  bottom: "InnerProduct4"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct5"
  type: "InnerProduct"
  bottom: "Concat1"
  top: "InnerProduct5"
  param {
    name: "fc8_w"
    lr_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "InnerProduct5"
  top: "InnerProduct5"
}
layer {
  name: "InnerProduct6"
  type: "InnerProduct"
  bottom: "InnerProduct5"
  top: "InnerProduct6"
  param {
    name: "fc9_w"
    lr_mult: 1
  }
  param {
    name: "fc9_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "InnerProduct6"
  top: "InnerProduct6"
}
layer {
  name: "dt0"
  type: "InnerProduct"
  bottom: "InnerProduct6"
  top: "dt0"
  param {
    name: "fc10_w"
    lr_mult: 1
  }
  param {
    name: "fc10_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "Convolution11"
  top: "LRN5"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "LRN5"
  top: "Pooling7"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Pooling7"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "Convolution12"
  top: "LRN6"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "LRN6"
  top: "Pooling8"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Pooling8"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "Convolution15"
  top: "Pooling9"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "InnerProduct7"
  type: "InnerProduct"
  bottom: "Pooling9"
  top: "InnerProduct7"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "InnerProduct7"
  top: "InnerProduct7"
}
layer {
  name: "InnerProduct8"
  type: "InnerProduct"
  bottom: "InnerProduct7"
  top: "InnerProduct8"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "InnerProduct8"
  top: "InnerProduct8"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "c21"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "Convolution16"
  top: "LRN7"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "LRN7"
  top: "Pooling10"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Pooling10"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "Convolution17"
  top: "LRN8"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "LRN8"
  top: "Pooling11"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Pooling11"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "Convolution20"
  top: "Pooling12"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "InnerProduct9"
  type: "InnerProduct"
  bottom: "Pooling12"
  top: "InnerProduct9"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "InnerProduct9"
  top: "InnerProduct9"
}
layer {
  name: "InnerProduct10"
  type: "InnerProduct"
  bottom: "InnerProduct9"
  top: "InnerProduct10"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "InnerProduct10"
  top: "InnerProduct10"
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "InnerProduct8"
  bottom: "InnerProduct10"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "InnerProduct11"
  type: "InnerProduct"
  bottom: "Concat2"
  top: "InnerProduct11"
  param {
    name: "fc8_w"
    lr_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "InnerProduct11"
  top: "InnerProduct11"
}
layer {
  name: "InnerProduct12"
  type: "InnerProduct"
  bottom: "InnerProduct11"
  top: "InnerProduct12"
  param {
    name: "fc9_w"
    lr_mult: 1
  }
  param {
    name: "fc9_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "InnerProduct12"
  top: "InnerProduct12"
}
layer {
  name: "dt1"
  type: "InnerProduct"
  bottom: "InnerProduct12"
  top: "dt1"
  param {
    name: "fc10_w"
    lr_mult: 1
  }
  param {
    name: "fc10_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "p1"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    group: 1
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "Convolution21"
  top: "LRN9"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "LRN9"
  top: "Pooling13"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "Pooling13"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "Convolution22"
  top: "LRN10"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "LRN10"
  top: "Pooling14"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "Pooling14"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "Convolution25"
  top: "Pooling15"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "InnerProduct13"
  type: "InnerProduct"
  bottom: "Pooling15"
  top: "InnerProduct13"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "InnerProduct13"
  top: "InnerProduct13"
}
layer {
  name: "InnerProduct14"
  type: "InnerProduct"
  bottom: "InnerProduct13"
  top: "InnerProduct14"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "InnerProduct14"
  top: "InnerProduct14"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "c22"
  top:
I0816 16:04:04.716125 20404 layer_factory.hpp:77] Creating layer data
I0816 16:04:04.716296 20404 net.cpp:91] Creating Layer data
I0816 16:04:04.716306 20404 net.cpp:399] data -> data
I0816 16:04:04.716322 20404 net.cpp:399] data -> label
I0816 16:04:04.716336 20404 data_transformer.cpp:25] Loading mean file from: examples/scene/scene_mean.binaryproto
I0816 16:04:04.717582 20416 db_lmdb.cpp:35] Opened lmdb examples/scene/test_pairs_1000_pad.lmdb
I0816 16:04:04.718736 20404 data_layer.cpp:41] output data size: 100,6,128,128
I0816 16:04:04.818240 20404 net.cpp:141] Setting up data
I0816 16:04:04.818279 20404 net.cpp:148] Top shape: 100 6 128 128 (9830400)
I0816 16:04:04.818287 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:04:04.818295 20404 net.cpp:156] Memory required for data: 39322000
I0816 16:04:04.818305 20404 layer_factory.hpp:77] Creating layer label_data_1_split
I0816 16:04:04.818322 20404 net.cpp:91] Creating Layer label_data_1_split
I0816 16:04:04.818331 20404 net.cpp:425] label_data_1_split <- label
I0816 16:04:04.818342 20404 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0816 16:04:04.818361 20404 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0816 16:04:04.818537 20404 net.cpp:141] Setting up label_data_1_split
I0816 16:04:04.818548 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:04:04.818557 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:04:04.818563 20404 net.cpp:156] Memory required for data: 39322800
I0816 16:04:04.818570 20404 layer_factory.hpp:77] Creating layer th
I0816 16:04:04.818583 20404 net.cpp:91] Creating Layer th
I0816 16:04:04.818589 20404 net.cpp:425] th <- label_data_1_split_0
I0816 16:04:04.818635 20404 net.cpp:399] th -> th
I0816 16:04:04.818683 20404 net.cpp:141] Setting up th
I0816 16:04:04.818693 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:04:04.818701 20404 net.cpp:156] Memory required for data: 39323200
I0816 16:04:04.818707 20404 layer_factory.hpp:77] Creating layer th_th_0_split
I0816 16:04:04.818717 20404 net.cpp:91] Creating Layer th_th_0_split
I0816 16:04:04.818722 20404 net.cpp:425] th_th_0_split <- th
I0816 16:04:04.818732 20404 net.cpp:399] th_th_0_split -> th_th_0_split_0
I0816 16:04:04.818743 20404 net.cpp:399] th_th_0_split -> th_th_0_split_1
I0816 16:04:04.818853 20404 net.cpp:141] Setting up th_th_0_split
I0816 16:04:04.818863 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:04:04.818871 20404 net.cpp:148] Top shape: 100 (100)
I0816 16:04:04.818878 20404 net.cpp:156] Memory required for data: 39324000
I0816 16:04:04.818884 20404 layer_factory.hpp:77] Creating layer i1
I0816 16:04:04.818898 20404 net.cpp:91] Creating Layer i1
I0816 16:04:04.818907 20404 net.cpp:425] i1 <- data
I0816 16:04:04.818918 20404 net.cpp:399] i1 -> i1
I0816 16:04:04.818931 20404 net.cpp:399] i1 -> i2
I0816 16:04:04.819008 20404 net.cpp:141] Setting up i1
I0816 16:04:04.819017 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819026 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819033 20404 net.cpp:156] Memory required for data: 78645600
I0816 16:04:04.819039 20404 layer_factory.hpp:77] Creating layer i1_i1_0_split
I0816 16:04:04.819051 20404 net.cpp:91] Creating Layer i1_i1_0_split
I0816 16:04:04.819057 20404 net.cpp:425] i1_i1_0_split <- i1
I0816 16:04:04.819067 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_0
I0816 16:04:04.819080 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_1
I0816 16:04:04.819093 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_2
I0816 16:04:04.819106 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_3
I0816 16:04:04.819118 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_4
I0816 16:04:04.819131 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_5
I0816 16:04:04.819144 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_6
I0816 16:04:04.819156 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_7
I0816 16:04:04.819171 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_8
I0816 16:04:04.819185 20404 net.cpp:399] i1_i1_0_split -> i1_i1_0_split_9
I0816 16:04:04.819460 20404 net.cpp:141] Setting up i1_i1_0_split
I0816 16:04:04.819473 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819480 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819489 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819499 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819506 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819515 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819524 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819532 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819541 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819550 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.819555 20404 net.cpp:156] Memory required for data: 275253600
I0816 16:04:04.819561 20404 layer_factory.hpp:77] Creating layer i2_i1_1_split
I0816 16:04:04.819572 20404 net.cpp:91] Creating Layer i2_i1_1_split
I0816 16:04:04.819579 20404 net.cpp:425] i2_i1_1_split <- i2
I0816 16:04:04.819591 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_0
I0816 16:04:04.819603 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_1
I0816 16:04:04.819617 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_2
I0816 16:04:04.819630 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_3
I0816 16:04:04.819643 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_4
I0816 16:04:04.819656 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_5
I0816 16:04:04.819676 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_6
I0816 16:04:04.819689 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_7
I0816 16:04:04.819718 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_8
I0816 16:04:04.819732 20404 net.cpp:399] i2_i1_1_split -> i2_i1_1_split_9
I0816 16:04:04.820083 20404 net.cpp:141] Setting up i2_i1_1_split
I0816 16:04:04.820096 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.820106 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.820116 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.820125 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.820137 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.820145 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.820157 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.820168 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.820179 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.820188 20404 net.cpp:148] Top shape: 100 3 128 128 (4915200)
I0816 16:04:04.820194 20404 net.cpp:156] Memory required for data: 471861600
I0816 16:04:04.820205 20404 layer_factory.hpp:77] Creating layer p1
I0816 16:04:04.820230 20404 net.cpp:91] Creating Layer p1
I0816 16:04:04.820236 20404 net.cpp:425] p1 <- i1_i1_0_split_0
I0816 16:04:04.820250 20404 net.cpp:399] p1 -> p1
I0816 16:04:04.826200 20404 net.cpp:141] Setting up p1
I0816 16:04:04.826222 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826231 20404 net.cpp:156] Memory required for data: 476776800
I0816 16:04:04.826239 20404 layer_factory.hpp:77] Creating layer p1_p1_0_split
I0816 16:04:04.826261 20404 net.cpp:91] Creating Layer p1_p1_0_split
I0816 16:04:04.826270 20404 net.cpp:425] p1_p1_0_split <- p1
I0816 16:04:04.826284 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_0
I0816 16:04:04.826303 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_1
I0816 16:04:04.826321 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_2
I0816 16:04:04.826344 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_3
I0816 16:04:04.826359 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_4
I0816 16:04:04.826372 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_5
I0816 16:04:04.826385 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_6
I0816 16:04:04.826398 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_7
I0816 16:04:04.826411 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_8
I0816 16:04:04.826429 20404 net.cpp:399] p1_p1_0_split -> p1_p1_0_split_9
I0816 16:04:04.826731 20404 net.cpp:141] Setting up p1_p1_0_split
I0816 16:04:04.826743 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826750 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826759 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826766 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826773 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826781 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826787 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826794 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826802 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826809 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826814 20404 net.cpp:156] Memory required for data: 525928800
I0816 16:04:04.826820 20404 layer_factory.hpp:77] Creating layer p2
I0816 16:04:04.826831 20404 net.cpp:91] Creating Layer p2
I0816 16:04:04.826838 20404 net.cpp:425] p2 <- i2_i1_1_split_0
I0816 16:04:04.826848 20404 net.cpp:399] p2 -> p2
I0816 16:04:04.826879 20404 net.cpp:141] Setting up p2
I0816 16:04:04.826886 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.826892 20404 net.cpp:156] Memory required for data: 530844000
I0816 16:04:04.826897 20404 layer_factory.hpp:77] Creating layer p2_p2_0_split
I0816 16:04:04.826907 20404 net.cpp:91] Creating Layer p2_p2_0_split
I0816 16:04:04.826913 20404 net.cpp:425] p2_p2_0_split <- p2
I0816 16:04:04.826923 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_0
I0816 16:04:04.826956 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_1
I0816 16:04:04.826968 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_2
I0816 16:04:04.826982 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_3
I0816 16:04:04.826992 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_4
I0816 16:04:04.827004 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_5
I0816 16:04:04.827015 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_6
I0816 16:04:04.827026 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_7
I0816 16:04:04.827038 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_8
I0816 16:04:04.827049 20404 net.cpp:399] p2_p2_0_split -> p2_p2_0_split_9
I0816 16:04:04.827239 20404 net.cpp:141] Setting up p2_p2_0_split
I0816 16:04:04.827246 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827253 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827261 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827268 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827287 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827296 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827303 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827311 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827317 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827325 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827330 20404 net.cpp:156] Memory required for data: 579996000
I0816 16:04:04.827337 20404 layer_factory.hpp:77] Creating layer Input1
I0816 16:04:04.827347 20404 net.cpp:91] Creating Layer Input1
I0816 16:04:04.827355 20404 net.cpp:399] Input1 -> Input1
I0816 16:04:04.827388 20404 net.cpp:141] Setting up Input1
I0816 16:04:04.827395 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827400 20404 net.cpp:156] Memory required for data: 584911200
I0816 16:04:04.827406 20404 layer_factory.hpp:77] Creating layer c11
I0816 16:04:04.827415 20404 net.cpp:91] Creating Layer c11
I0816 16:04:04.827421 20404 net.cpp:425] c11 <- i1_i1_0_split_1
I0816 16:04:04.827430 20404 net.cpp:425] c11 <- Input1
I0816 16:04:04.827438 20404 net.cpp:399] c11 -> c11
I0816 16:04:04.827469 20404 net.cpp:141] Setting up c11
I0816 16:04:04.827476 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827481 20404 net.cpp:156] Memory required for data: 589826400
I0816 16:04:04.827488 20404 layer_factory.hpp:77] Creating layer Input2
I0816 16:04:04.827497 20404 net.cpp:91] Creating Layer Input2
I0816 16:04:04.827504 20404 net.cpp:399] Input2 -> Input2
I0816 16:04:04.827534 20404 net.cpp:141] Setting up Input2
I0816 16:04:04.827541 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827548 20404 net.cpp:156] Memory required for data: 594741600
I0816 16:04:04.827553 20404 layer_factory.hpp:77] Creating layer c12
I0816 16:04:04.827561 20404 net.cpp:91] Creating Layer c12
I0816 16:04:04.827566 20404 net.cpp:425] c12 <- i1_i1_0_split_2
I0816 16:04:04.827574 20404 net.cpp:425] c12 <- Input2
I0816 16:04:04.827582 20404 net.cpp:399] c12 -> c12
I0816 16:04:04.827611 20404 net.cpp:141] Setting up c12
I0816 16:04:04.827620 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827625 20404 net.cpp:156] Memory required for data: 599656800
I0816 16:04:04.827630 20404 layer_factory.hpp:77] Creating layer Input3
I0816 16:04:04.827638 20404 net.cpp:91] Creating Layer Input3
I0816 16:04:04.827646 20404 net.cpp:399] Input3 -> Input3
I0816 16:04:04.827674 20404 net.cpp:141] Setting up Input3
I0816 16:04:04.827682 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827687 20404 net.cpp:156] Memory required for data: 604572000
I0816 16:04:04.827692 20404 layer_factory.hpp:77] Creating layer c13
I0816 16:04:04.827703 20404 net.cpp:91] Creating Layer c13
I0816 16:04:04.827709 20404 net.cpp:425] c13 <- i1_i1_0_split_3
I0816 16:04:04.827718 20404 net.cpp:425] c13 <- Input3
I0816 16:04:04.827726 20404 net.cpp:399] c13 -> c13
I0816 16:04:04.827755 20404 net.cpp:141] Setting up c13
I0816 16:04:04.827772 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827778 20404 net.cpp:156] Memory required for data: 609487200
I0816 16:04:04.827783 20404 layer_factory.hpp:77] Creating layer Input4
I0816 16:04:04.827792 20404 net.cpp:91] Creating Layer Input4
I0816 16:04:04.827800 20404 net.cpp:399] Input4 -> Input4
I0816 16:04:04.827828 20404 net.cpp:141] Setting up Input4
I0816 16:04:04.827836 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827841 20404 net.cpp:156] Memory required for data: 614402400
I0816 16:04:04.827847 20404 layer_factory.hpp:77] Creating layer c14
I0816 16:04:04.827855 20404 net.cpp:91] Creating Layer c14
I0816 16:04:04.827860 20404 net.cpp:425] c14 <- i1_i1_0_split_4
I0816 16:04:04.827868 20404 net.cpp:425] c14 <- Input4
I0816 16:04:04.827877 20404 net.cpp:399] c14 -> c14
I0816 16:04:04.827906 20404 net.cpp:141] Setting up c14
I0816 16:04:04.827914 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827919 20404 net.cpp:156] Memory required for data: 619317600
I0816 16:04:04.827924 20404 layer_factory.hpp:77] Creating layer Input5
I0816 16:04:04.827934 20404 net.cpp:91] Creating Layer Input5
I0816 16:04:04.827941 20404 net.cpp:399] Input5 -> Input5
I0816 16:04:04.827971 20404 net.cpp:141] Setting up Input5
I0816 16:04:04.827980 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.827985 20404 net.cpp:156] Memory required for data: 624232800
I0816 16:04:04.827989 20404 layer_factory.hpp:77] Creating layer c15
I0816 16:04:04.827998 20404 net.cpp:91] Creating Layer c15
I0816 16:04:04.828004 20404 net.cpp:425] c15 <- i1_i1_0_split_5
I0816 16:04:04.828011 20404 net.cpp:425] c15 <- Input5
I0816 16:04:04.828021 20404 net.cpp:399] c15 -> c15
I0816 16:04:04.828050 20404 net.cpp:141] Setting up c15
I0816 16:04:04.828058 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828063 20404 net.cpp:156] Memory required for data: 629148000
I0816 16:04:04.828068 20404 layer_factory.hpp:77] Creating layer Input6
I0816 16:04:04.828078 20404 net.cpp:91] Creating Layer Input6
I0816 16:04:04.828084 20404 net.cpp:399] Input6 -> Input6
I0816 16:04:04.828112 20404 net.cpp:141] Setting up Input6
I0816 16:04:04.828120 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828125 20404 net.cpp:156] Memory required for data: 634063200
I0816 16:04:04.828131 20404 layer_factory.hpp:77] Creating layer c16
I0816 16:04:04.828140 20404 net.cpp:91] Creating Layer c16
I0816 16:04:04.828145 20404 net.cpp:425] c16 <- i1_i1_0_split_6
I0816 16:04:04.828152 20404 net.cpp:425] c16 <- Input6
I0816 16:04:04.828161 20404 net.cpp:399] c16 -> c16
I0816 16:04:04.828191 20404 net.cpp:141] Setting up c16
I0816 16:04:04.828198 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828203 20404 net.cpp:156] Memory required for data: 638978400
I0816 16:04:04.828209 20404 layer_factory.hpp:77] Creating layer Input7
I0816 16:04:04.828217 20404 net.cpp:91] Creating Layer Input7
I0816 16:04:04.828224 20404 net.cpp:399] Input7 -> Input7
I0816 16:04:04.828253 20404 net.cpp:141] Setting up Input7
I0816 16:04:04.828260 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828266 20404 net.cpp:156] Memory required for data: 643893600
I0816 16:04:04.828271 20404 layer_factory.hpp:77] Creating layer c17
I0816 16:04:04.828279 20404 net.cpp:91] Creating Layer c17
I0816 16:04:04.828285 20404 net.cpp:425] c17 <- i1_i1_0_split_7
I0816 16:04:04.828292 20404 net.cpp:425] c17 <- Input7
I0816 16:04:04.828301 20404 net.cpp:399] c17 -> c17
I0816 16:04:04.828339 20404 net.cpp:141] Setting up c17
I0816 16:04:04.828348 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828353 20404 net.cpp:156] Memory required for data: 648808800
I0816 16:04:04.828359 20404 layer_factory.hpp:77] Creating layer Input8
I0816 16:04:04.828367 20404 net.cpp:91] Creating Layer Input8
I0816 16:04:04.828374 20404 net.cpp:399] Input8 -> Input8
I0816 16:04:04.828404 20404 net.cpp:141] Setting up Input8
I0816 16:04:04.828413 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828428 20404 net.cpp:156] Memory required for data: 653724000
I0816 16:04:04.828433 20404 layer_factory.hpp:77] Creating layer c18
I0816 16:04:04.828441 20404 net.cpp:91] Creating Layer c18
I0816 16:04:04.828446 20404 net.cpp:425] c18 <- i1_i1_0_split_8
I0816 16:04:04.828454 20404 net.cpp:425] c18 <- Input8
I0816 16:04:04.828464 20404 net.cpp:399] c18 -> c18
I0816 16:04:04.828493 20404 net.cpp:141] Setting up c18
I0816 16:04:04.828501 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828506 20404 net.cpp:156] Memory required for data: 658639200
I0816 16:04:04.828511 20404 layer_factory.hpp:77] Creating layer Input9
I0816 16:04:04.828521 20404 net.cpp:91] Creating Layer Input9
I0816 16:04:04.828527 20404 net.cpp:399] Input9 -> Input9
I0816 16:04:04.828557 20404 net.cpp:141] Setting up Input9
I0816 16:04:04.828564 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828570 20404 net.cpp:156] Memory required for data: 663554400
I0816 16:04:04.828575 20404 layer_factory.hpp:77] Creating layer c19
I0816 16:04:04.828583 20404 net.cpp:91] Creating Layer c19
I0816 16:04:04.828589 20404 net.cpp:425] c19 <- i1_i1_0_split_9
I0816 16:04:04.828598 20404 net.cpp:425] c19 <- Input9
I0816 16:04:04.828606 20404 net.cpp:399] c19 -> c19
I0816 16:04:04.828635 20404 net.cpp:141] Setting up c19
I0816 16:04:04.828644 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828649 20404 net.cpp:156] Memory required for data: 668469600
I0816 16:04:04.828654 20404 layer_factory.hpp:77] Creating layer Input10
I0816 16:04:04.828662 20404 net.cpp:91] Creating Layer Input10
I0816 16:04:04.828670 20404 net.cpp:399] Input10 -> Input10
I0816 16:04:04.828704 20404 net.cpp:141] Setting up Input10
I0816 16:04:04.828714 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828722 20404 net.cpp:156] Memory required for data: 673384800
I0816 16:04:04.828730 20404 layer_factory.hpp:77] Creating layer c21
I0816 16:04:04.828743 20404 net.cpp:91] Creating Layer c21
I0816 16:04:04.828750 20404 net.cpp:425] c21 <- i2_i1_1_split_1
I0816 16:04:04.828760 20404 net.cpp:425] c21 <- Input10
I0816 16:04:04.828769 20404 net.cpp:399] c21 -> c21
I0816 16:04:04.828801 20404 net.cpp:141] Setting up c21
I0816 16:04:04.828809 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828814 20404 net.cpp:156] Memory required for data: 678300000
I0816 16:04:04.828820 20404 layer_factory.hpp:77] Creating layer Input11
I0816 16:04:04.828830 20404 net.cpp:91] Creating Layer Input11
I0816 16:04:04.828836 20404 net.cpp:399] Input11 -> Input11
I0816 16:04:04.828866 20404 net.cpp:141] Setting up Input11
I0816 16:04:04.828873 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828879 20404 net.cpp:156] Memory required for data: 683215200
I0816 16:04:04.828884 20404 layer_factory.hpp:77] Creating layer c22
I0816 16:04:04.828897 20404 net.cpp:91] Creating Layer c22
I0816 16:04:04.828903 20404 net.cpp:425] c22 <- i2_i1_1_split_2
I0816 16:04:04.828912 20404 net.cpp:425] c22 <- Input11
I0816 16:04:04.828920 20404 net.cpp:399] c22 -> c22
I0816 16:04:04.828951 20404 net.cpp:141] Setting up c22
I0816 16:04:04.828958 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.828964 20404 net.cpp:156] Memory required for data: 688130400
I0816 16:04:04.828969 20404 layer_factory.hpp:77] Creating layer Input12
I0816 16:04:04.828977 20404 net.cpp:91] Creating Layer Input12
I0816 16:04:04.828984 20404 net.cpp:399] Input12 -> Input12
I0816 16:04:04.829015 20404 net.cpp:141] Setting up Input12
I0816 16:04:04.829021 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829026 20404 net.cpp:156] Memory required for data: 693045600
I0816 16:04:04.829032 20404 layer_factory.hpp:77] Creating layer c23
I0816 16:04:04.829041 20404 net.cpp:91] Creating Layer c23
I0816 16:04:04.829046 20404 net.cpp:425] c23 <- i2_i1_1_split_3
I0816 16:04:04.829054 20404 net.cpp:425] c23 <- Input12
I0816 16:04:04.829062 20404 net.cpp:399] c23 -> c23
I0816 16:04:04.829092 20404 net.cpp:141] Setting up c23
I0816 16:04:04.829108 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829114 20404 net.cpp:156] Memory required for data: 697960800
I0816 16:04:04.829119 20404 layer_factory.hpp:77] Creating layer Input13
I0816 16:04:04.829128 20404 net.cpp:91] Creating Layer Input13
I0816 16:04:04.829135 20404 net.cpp:399] Input13 -> Input13
I0816 16:04:04.829164 20404 net.cpp:141] Setting up Input13
I0816 16:04:04.829172 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829177 20404 net.cpp:156] Memory required for data: 702876000
I0816 16:04:04.829183 20404 layer_factory.hpp:77] Creating layer c24
I0816 16:04:04.829191 20404 net.cpp:91] Creating Layer c24
I0816 16:04:04.829197 20404 net.cpp:425] c24 <- i2_i1_1_split_4
I0816 16:04:04.829205 20404 net.cpp:425] c24 <- Input13
I0816 16:04:04.829213 20404 net.cpp:399] c24 -> c24
I0816 16:04:04.829243 20404 net.cpp:141] Setting up c24
I0816 16:04:04.829251 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829255 20404 net.cpp:156] Memory required for data: 707791200
I0816 16:04:04.829262 20404 layer_factory.hpp:77] Creating layer Input14
I0816 16:04:04.829269 20404 net.cpp:91] Creating Layer Input14
I0816 16:04:04.829277 20404 net.cpp:399] Input14 -> Input14
I0816 16:04:04.829306 20404 net.cpp:141] Setting up Input14
I0816 16:04:04.829313 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829319 20404 net.cpp:156] Memory required for data: 712706400
I0816 16:04:04.829324 20404 layer_factory.hpp:77] Creating layer c25
I0816 16:04:04.829332 20404 net.cpp:91] Creating Layer c25
I0816 16:04:04.829339 20404 net.cpp:425] c25 <- i2_i1_1_split_5
I0816 16:04:04.829346 20404 net.cpp:425] c25 <- Input14
I0816 16:04:04.829355 20404 net.cpp:399] c25 -> c25
I0816 16:04:04.829385 20404 net.cpp:141] Setting up c25
I0816 16:04:04.829392 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829397 20404 net.cpp:156] Memory required for data: 717621600
I0816 16:04:04.829402 20404 layer_factory.hpp:77] Creating layer Input15
I0816 16:04:04.829411 20404 net.cpp:91] Creating Layer Input15
I0816 16:04:04.829418 20404 net.cpp:399] Input15 -> Input15
I0816 16:04:04.829447 20404 net.cpp:141] Setting up Input15
I0816 16:04:04.829454 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829460 20404 net.cpp:156] Memory required for data: 722536800
I0816 16:04:04.829465 20404 layer_factory.hpp:77] Creating layer c26
I0816 16:04:04.829473 20404 net.cpp:91] Creating Layer c26
I0816 16:04:04.829479 20404 net.cpp:425] c26 <- i2_i1_1_split_6
I0816 16:04:04.829488 20404 net.cpp:425] c26 <- Input15
I0816 16:04:04.829495 20404 net.cpp:399] c26 -> c26
I0816 16:04:04.829525 20404 net.cpp:141] Setting up c26
I0816 16:04:04.829533 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829538 20404 net.cpp:156] Memory required for data: 727452000
I0816 16:04:04.829543 20404 layer_factory.hpp:77] Creating layer Input16
I0816 16:04:04.829552 20404 net.cpp:91] Creating Layer Input16
I0816 16:04:04.829560 20404 net.cpp:399] Input16 -> Input16
I0816 16:04:04.829588 20404 net.cpp:141] Setting up Input16
I0816 16:04:04.829596 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829602 20404 net.cpp:156] Memory required for data: 732367200
I0816 16:04:04.829607 20404 layer_factory.hpp:77] Creating layer c27
I0816 16:04:04.829614 20404 net.cpp:91] Creating Layer c27
I0816 16:04:04.829620 20404 net.cpp:425] c27 <- i2_i1_1_split_7
I0816 16:04:04.829627 20404 net.cpp:425] c27 <- Input16
I0816 16:04:04.829637 20404 net.cpp:399] c27 -> c27
I0816 16:04:04.829666 20404 net.cpp:141] Setting up c27
I0816 16:04:04.829674 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829679 20404 net.cpp:156] Memory required for data: 737282400
I0816 16:04:04.829685 20404 layer_factory.hpp:77] Creating layer Input17
I0816 16:04:04.829694 20404 net.cpp:91] Creating Layer Input17
I0816 16:04:04.829701 20404 net.cpp:399] Input17 -> Input17
I0816 16:04:04.829731 20404 net.cpp:141] Setting up Input17
I0816 16:04:04.829740 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829753 20404 net.cpp:156] Memory required for data: 742197600
I0816 16:04:04.829758 20404 layer_factory.hpp:77] Creating layer c28
I0816 16:04:04.829767 20404 net.cpp:91] Creating Layer c28
I0816 16:04:04.829773 20404 net.cpp:425] c28 <- i2_i1_1_split_8
I0816 16:04:04.829780 20404 net.cpp:425] c28 <- Input17
I0816 16:04:04.829789 20404 net.cpp:399] c28 -> c28
I0816 16:04:04.829819 20404 net.cpp:141] Setting up c28
I0816 16:04:04.829828 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829833 20404 net.cpp:156] Memory required for data: 747112800
I0816 16:04:04.829838 20404 layer_factory.hpp:77] Creating layer Input18
I0816 16:04:04.829846 20404 net.cpp:91] Creating Layer Input18
I0816 16:04:04.829854 20404 net.cpp:399] Input18 -> Input18
I0816 16:04:04.829884 20404 net.cpp:141] Setting up Input18
I0816 16:04:04.829890 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829896 20404 net.cpp:156] Memory required for data: 752028000
I0816 16:04:04.829901 20404 layer_factory.hpp:77] Creating layer c29
I0816 16:04:04.829910 20404 net.cpp:91] Creating Layer c29
I0816 16:04:04.829916 20404 net.cpp:425] c29 <- i2_i1_1_split_9
I0816 16:04:04.829922 20404 net.cpp:425] c29 <- Input18
I0816 16:04:04.829931 20404 net.cpp:399] c29 -> c29
I0816 16:04:04.829960 20404 net.cpp:141] Setting up c29
I0816 16:04:04.829968 20404 net.cpp:148] Top shape: 100 3 64 64 (1228800)
I0816 16:04:04.829973 20404 net.cpp:156] Memory required for data: 756943200
I0816 16:04:04.829978 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:04.829993 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:04.829999 20404 net.cpp:425] conv1 <- p1_p1_0_split_0
I0816 16:04:04.830009 20404 net.cpp:399] conv1 -> Convolution1
I0816 16:04:04.832090 20404 net.cpp:141] Setting up conv1
I0816 16:04:04.832099 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.832105 20404 net.cpp:156] Memory required for data: 766773600
I0816 16:04:04.832120 20404 layer_factory.hpp:77] Creating layer ReLU1
I0816 16:04:04.832129 20404 net.cpp:91] Creating Layer ReLU1
I0816 16:04:04.832135 20404 net.cpp:425] ReLU1 <- Convolution1
I0816 16:04:04.832144 20404 net.cpp:386] ReLU1 -> Convolution1 (in-place)
I0816 16:04:04.832154 20404 net.cpp:141] Setting up ReLU1
I0816 16:04:04.832161 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.832167 20404 net.cpp:156] Memory required for data: 776604000
I0816 16:04:04.832172 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:04.832182 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:04.832188 20404 net.cpp:425] norm1 <- Convolution1
I0816 16:04:04.832197 20404 net.cpp:399] norm1 -> LRN1
I0816 16:04:04.832240 20404 net.cpp:141] Setting up norm1
I0816 16:04:04.832247 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.832253 20404 net.cpp:156] Memory required for data: 786434400
I0816 16:04:04.832258 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:04.832267 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:04.832273 20404 net.cpp:425] pool1 <- LRN1
I0816 16:04:04.832283 20404 net.cpp:399] pool1 -> Pooling1
I0816 16:04:04.832330 20404 net.cpp:141] Setting up pool1
I0816 16:04:04.832337 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:04.832343 20404 net.cpp:156] Memory required for data: 788892000
I0816 16:04:04.832348 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:04.832360 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:04.832367 20404 net.cpp:425] conv2 <- Pooling1
I0816 16:04:04.832376 20404 net.cpp:399] conv2 -> Convolution2
I0816 16:04:04.848261 20404 net.cpp:141] Setting up conv2
I0816 16:04:04.848289 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.848294 20404 net.cpp:156] Memory required for data: 795445600
I0816 16:04:04.848311 20404 layer_factory.hpp:77] Creating layer ReLU2
I0816 16:04:04.848323 20404 net.cpp:91] Creating Layer ReLU2
I0816 16:04:04.848331 20404 net.cpp:425] ReLU2 <- Convolution2
I0816 16:04:04.848341 20404 net.cpp:386] ReLU2 -> Convolution2 (in-place)
I0816 16:04:04.848378 20404 net.cpp:141] Setting up ReLU2
I0816 16:04:04.848387 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.848392 20404 net.cpp:156] Memory required for data: 801999200
I0816 16:04:04.848397 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:04.848407 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:04.848413 20404 net.cpp:425] norm2 <- Convolution2
I0816 16:04:04.848423 20404 net.cpp:399] norm2 -> LRN2
I0816 16:04:04.848474 20404 net.cpp:141] Setting up norm2
I0816 16:04:04.848482 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.848487 20404 net.cpp:156] Memory required for data: 808552800
I0816 16:04:04.848493 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:04.848503 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:04.848510 20404 net.cpp:425] pool2 <- LRN2
I0816 16:04:04.848518 20404 net.cpp:399] pool2 -> Pooling2
I0816 16:04:04.848569 20404 net.cpp:141] Setting up pool2
I0816 16:04:04.848577 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.848582 20404 net.cpp:156] Memory required for data: 810191200
I0816 16:04:04.848587 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:04.848603 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:04.848608 20404 net.cpp:425] conv3 <- Pooling2
I0816 16:04:04.848619 20404 net.cpp:399] conv3 -> Convolution3
I0816 16:04:04.894007 20404 net.cpp:141] Setting up conv3
I0816 16:04:04.894037 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.894044 20404 net.cpp:156] Memory required for data: 812648800
I0816 16:04:04.894063 20404 layer_factory.hpp:77] Creating layer ReLU3
I0816 16:04:04.894078 20404 net.cpp:91] Creating Layer ReLU3
I0816 16:04:04.894088 20404 net.cpp:425] ReLU3 <- Convolution3
I0816 16:04:04.894098 20404 net.cpp:386] ReLU3 -> Convolution3 (in-place)
I0816 16:04:04.894112 20404 net.cpp:141] Setting up ReLU3
I0816 16:04:04.894119 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.894125 20404 net.cpp:156] Memory required for data: 815106400
I0816 16:04:04.894130 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:04.894145 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:04.894152 20404 net.cpp:425] conv4 <- Convolution3
I0816 16:04:04.894163 20404 net.cpp:399] conv4 -> Convolution4
I0816 16:04:04.928115 20404 net.cpp:141] Setting up conv4
I0816 16:04:04.928148 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.928154 20404 net.cpp:156] Memory required for data: 817564000
I0816 16:04:04.928169 20404 layer_factory.hpp:77] Creating layer ReLU4
I0816 16:04:04.928184 20404 net.cpp:91] Creating Layer ReLU4
I0816 16:04:04.928194 20404 net.cpp:425] ReLU4 <- Convolution4
I0816 16:04:04.928205 20404 net.cpp:386] ReLU4 -> Convolution4 (in-place)
I0816 16:04:04.928220 20404 net.cpp:141] Setting up ReLU4
I0816 16:04:04.928226 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:04.928232 20404 net.cpp:156] Memory required for data: 820021600
I0816 16:04:04.928237 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:04.928254 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:04.928261 20404 net.cpp:425] conv5 <- Convolution4
I0816 16:04:04.928272 20404 net.cpp:399] conv5 -> Convolution5
I0816 16:04:04.951068 20404 net.cpp:141] Setting up conv5
I0816 16:04:04.951107 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.951114 20404 net.cpp:156] Memory required for data: 821660000
I0816 16:04:04.951140 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:04.951158 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:04.951174 20404 net.cpp:425] pool5 <- Convolution5
I0816 16:04:04.951189 20404 net.cpp:399] pool5 -> Pooling3
I0816 16:04:04.951297 20404 net.cpp:141] Setting up pool5
I0816 16:04:04.951311 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:04.951319 20404 net.cpp:156] Memory required for data: 822069600
I0816 16:04:04.951326 20404 layer_factory.hpp:77] Creating layer InnerProduct1
I0816 16:04:04.951344 20404 net.cpp:91] Creating Layer InnerProduct1
I0816 16:04:04.951375 20404 net.cpp:425] InnerProduct1 <- Pooling3
I0816 16:04:04.951390 20404 net.cpp:399] InnerProduct1 -> InnerProduct1
I0816 16:04:04.954365 20404 net.cpp:141] Setting up InnerProduct1
I0816 16:04:04.954391 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.954398 20404 net.cpp:156] Memory required for data: 822172000
I0816 16:04:04.954411 20404 layer_factory.hpp:77] Creating layer ReLU5
I0816 16:04:04.954423 20404 net.cpp:91] Creating Layer ReLU5
I0816 16:04:04.954432 20404 net.cpp:425] ReLU5 <- InnerProduct1
I0816 16:04:04.954444 20404 net.cpp:386] ReLU5 -> InnerProduct1 (in-place)
I0816 16:04:04.954458 20404 net.cpp:141] Setting up ReLU5
I0816 16:04:04.954468 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.954476 20404 net.cpp:156] Memory required for data: 822274400
I0816 16:04:04.954483 20404 layer_factory.hpp:77] Creating layer InnerProduct2
I0816 16:04:04.954498 20404 net.cpp:91] Creating Layer InnerProduct2
I0816 16:04:04.954505 20404 net.cpp:425] InnerProduct2 <- InnerProduct1
I0816 16:04:04.954519 20404 net.cpp:399] InnerProduct2 -> InnerProduct2
I0816 16:04:04.955217 20404 net.cpp:141] Setting up InnerProduct2
I0816 16:04:04.955265 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.955282 20404 net.cpp:156] Memory required for data: 822376800
I0816 16:04:04.955294 20404 layer_factory.hpp:77] Creating layer ReLU6
I0816 16:04:04.955327 20404 net.cpp:91] Creating Layer ReLU6
I0816 16:04:04.955338 20404 net.cpp:425] ReLU6 <- InnerProduct2
I0816 16:04:04.955350 20404 net.cpp:386] ReLU6 -> InnerProduct2 (in-place)
I0816 16:04:04.955363 20404 net.cpp:141] Setting up ReLU6
I0816 16:04:04.955374 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:04.955380 20404 net.cpp:156] Memory required for data: 822479200
I0816 16:04:04.955389 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:04.955407 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:04.955416 20404 net.cpp:425] conv1 <- p2_p2_0_split_0
I0816 16:04:04.955430 20404 net.cpp:399] conv1 -> Convolution6
I0816 16:04:04.957506 20404 net.cpp:141] Setting up conv1
I0816 16:04:04.957523 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.957531 20404 net.cpp:156] Memory required for data: 832309600
I0816 16:04:04.957545 20404 layer_factory.hpp:77] Creating layer ReLU7
I0816 16:04:04.957556 20404 net.cpp:91] Creating Layer ReLU7
I0816 16:04:04.957566 20404 net.cpp:425] ReLU7 <- Convolution6
I0816 16:04:04.957576 20404 net.cpp:386] ReLU7 -> Convolution6 (in-place)
I0816 16:04:04.957589 20404 net.cpp:141] Setting up ReLU7
I0816 16:04:04.957599 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.957607 20404 net.cpp:156] Memory required for data: 842140000
I0816 16:04:04.957615 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:04.957626 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:04.957634 20404 net.cpp:425] norm1 <- Convolution6
I0816 16:04:04.957648 20404 net.cpp:399] norm1 -> LRN3
I0816 16:04:04.957698 20404 net.cpp:141] Setting up norm1
I0816 16:04:04.957712 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:04.957720 20404 net.cpp:156] Memory required for data: 851970400
I0816 16:04:04.957727 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:04.957738 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:04.957746 20404 net.cpp:425] pool1 <- LRN3
I0816 16:04:04.957757 20404 net.cpp:399] pool1 -> Pooling4
I0816 16:04:04.957815 20404 net.cpp:141] Setting up pool1
I0816 16:04:04.957828 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:04.957836 20404 net.cpp:156] Memory required for data: 854428000
I0816 16:04:04.957844 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:04.957859 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:04.957867 20404 net.cpp:425] conv2 <- Pooling4
I0816 16:04:04.957880 20404 net.cpp:399] conv2 -> Convolution7
I0816 16:04:04.973933 20404 net.cpp:141] Setting up conv2
I0816 16:04:04.973973 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.974011 20404 net.cpp:156] Memory required for data: 860981600
I0816 16:04:04.974041 20404 layer_factory.hpp:77] Creating layer ReLU8
I0816 16:04:04.974057 20404 net.cpp:91] Creating Layer ReLU8
I0816 16:04:04.974069 20404 net.cpp:425] ReLU8 <- Convolution7
I0816 16:04:04.974082 20404 net.cpp:386] ReLU8 -> Convolution7 (in-place)
I0816 16:04:04.974100 20404 net.cpp:141] Setting up ReLU8
I0816 16:04:04.974149 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.974185 20404 net.cpp:156] Memory required for data: 867535200
I0816 16:04:04.974197 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:04.974211 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:04.974220 20404 net.cpp:425] norm2 <- Convolution7
I0816 16:04:04.974234 20404 net.cpp:399] norm2 -> LRN4
I0816 16:04:04.974298 20404 net.cpp:141] Setting up norm2
I0816 16:04:04.974313 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:04.974319 20404 net.cpp:156] Memory required for data: 874088800
I0816 16:04:04.974326 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:04.974339 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:04.974347 20404 net.cpp:425] pool2 <- LRN4
I0816 16:04:04.974359 20404 net.cpp:399] pool2 -> Pooling5
I0816 16:04:04.974417 20404 net.cpp:141] Setting up pool2
I0816 16:04:04.974431 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:04.974438 20404 net.cpp:156] Memory required for data: 875727200
I0816 16:04:04.974445 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:04.974463 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:04.974473 20404 net.cpp:425] conv3 <- Pooling5
I0816 16:04:04.974488 20404 net.cpp:399] conv3 -> Convolution8
I0816 16:04:05.019775 20404 net.cpp:141] Setting up conv3
I0816 16:04:05.019811 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.019830 20404 net.cpp:156] Memory required for data: 878184800
I0816 16:04:05.019847 20404 layer_factory.hpp:77] Creating layer ReLU9
I0816 16:04:05.019863 20404 net.cpp:91] Creating Layer ReLU9
I0816 16:04:05.019875 20404 net.cpp:425] ReLU9 <- Convolution8
I0816 16:04:05.019898 20404 net.cpp:386] ReLU9 -> Convolution8 (in-place)
I0816 16:04:05.019914 20404 net.cpp:141] Setting up ReLU9
I0816 16:04:05.019924 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.019932 20404 net.cpp:156] Memory required for data: 880642400
I0816 16:04:05.019940 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:05.019958 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:05.019966 20404 net.cpp:425] conv4 <- Convolution8
I0816 16:04:05.019979 20404 net.cpp:399] conv4 -> Convolution9
I0816 16:04:05.052968 20404 net.cpp:141] Setting up conv4
I0816 16:04:05.052996 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.053014 20404 net.cpp:156] Memory required for data: 883100000
I0816 16:04:05.053030 20404 layer_factory.hpp:77] Creating layer ReLU10
I0816 16:04:05.053043 20404 net.cpp:91] Creating Layer ReLU10
I0816 16:04:05.053053 20404 net.cpp:425] ReLU10 <- Convolution9
I0816 16:04:05.053066 20404 net.cpp:386] ReLU10 -> Convolution9 (in-place)
I0816 16:04:05.053083 20404 net.cpp:141] Setting up ReLU10
I0816 16:04:05.053093 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.053102 20404 net.cpp:156] Memory required for data: 885557600
I0816 16:04:05.053109 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:05.053127 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:05.053134 20404 net.cpp:425] conv5 <- Convolution9
I0816 16:04:05.053148 20404 net.cpp:399] conv5 -> Convolution10
I0816 16:04:05.075340 20404 net.cpp:141] Setting up conv5
I0816 16:04:05.075364 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.075383 20404 net.cpp:156] Memory required for data: 887196000
I0816 16:04:05.075399 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:05.075414 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:05.075424 20404 net.cpp:425] pool5 <- Convolution10
I0816 16:04:05.075448 20404 net.cpp:399] pool5 -> Pooling6
I0816 16:04:05.075515 20404 net.cpp:141] Setting up pool5
I0816 16:04:05.075548 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:05.075556 20404 net.cpp:156] Memory required for data: 887605600
I0816 16:04:05.075563 20404 layer_factory.hpp:77] Creating layer InnerProduct3
I0816 16:04:05.075578 20404 net.cpp:91] Creating Layer InnerProduct3
I0816 16:04:05.075587 20404 net.cpp:425] InnerProduct3 <- Pooling6
I0816 16:04:05.075600 20404 net.cpp:399] InnerProduct3 -> InnerProduct3
I0816 16:04:05.078322 20404 net.cpp:141] Setting up InnerProduct3
I0816 16:04:05.078342 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.078351 20404 net.cpp:156] Memory required for data: 887708000
I0816 16:04:05.078366 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:05.078375 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:05.078383 20404 layer_factory.hpp:77] Creating layer ReLU11
I0816 16:04:05.078395 20404 net.cpp:91] Creating Layer ReLU11
I0816 16:04:05.078403 20404 net.cpp:425] ReLU11 <- InnerProduct3
I0816 16:04:05.078423 20404 net.cpp:386] ReLU11 -> InnerProduct3 (in-place)
I0816 16:04:05.078436 20404 net.cpp:141] Setting up ReLU11
I0816 16:04:05.078447 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.078454 20404 net.cpp:156] Memory required for data: 887810400
I0816 16:04:05.078462 20404 layer_factory.hpp:77] Creating layer InnerProduct4
I0816 16:04:05.078475 20404 net.cpp:91] Creating Layer InnerProduct4
I0816 16:04:05.078483 20404 net.cpp:425] InnerProduct4 <- InnerProduct3
I0816 16:04:05.078496 20404 net.cpp:399] InnerProduct4 -> InnerProduct4
I0816 16:04:05.079161 20404 net.cpp:141] Setting up InnerProduct4
I0816 16:04:05.079176 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.079188 20404 net.cpp:156] Memory required for data: 887912800
I0816 16:04:05.079196 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:05.079206 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:05.079215 20404 layer_factory.hpp:77] Creating layer ReLU12
I0816 16:04:05.079224 20404 net.cpp:91] Creating Layer ReLU12
I0816 16:04:05.079233 20404 net.cpp:425] ReLU12 <- InnerProduct4
I0816 16:04:05.079247 20404 net.cpp:386] ReLU12 -> InnerProduct4 (in-place)
I0816 16:04:05.079259 20404 net.cpp:141] Setting up ReLU12
I0816 16:04:05.079270 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.079284 20404 net.cpp:156] Memory required for data: 888015200
I0816 16:04:05.079293 20404 layer_factory.hpp:77] Creating layer Concat1
I0816 16:04:05.079304 20404 net.cpp:91] Creating Layer Concat1
I0816 16:04:05.079313 20404 net.cpp:425] Concat1 <- InnerProduct2
I0816 16:04:05.079324 20404 net.cpp:425] Concat1 <- InnerProduct4
I0816 16:04:05.079335 20404 net.cpp:399] Concat1 -> Concat1
I0816 16:04:05.079373 20404 net.cpp:141] Setting up Concat1
I0816 16:04:05.079387 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:05.079394 20404 net.cpp:156] Memory required for data: 888220000
I0816 16:04:05.079401 20404 layer_factory.hpp:77] Creating layer InnerProduct5
I0816 16:04:05.079414 20404 net.cpp:91] Creating Layer InnerProduct5
I0816 16:04:05.079422 20404 net.cpp:425] InnerProduct5 <- Concat1
I0816 16:04:05.079435 20404 net.cpp:399] InnerProduct5 -> InnerProduct5
I0816 16:04:05.080602 20404 net.cpp:141] Setting up InnerProduct5
I0816 16:04:05.080616 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.080623 20404 net.cpp:156] Memory required for data: 888322400
I0816 16:04:05.080636 20404 layer_factory.hpp:77] Creating layer ReLU13
I0816 16:04:05.080646 20404 net.cpp:91] Creating Layer ReLU13
I0816 16:04:05.080654 20404 net.cpp:425] ReLU13 <- InnerProduct5
I0816 16:04:05.080664 20404 net.cpp:386] ReLU13 -> InnerProduct5 (in-place)
I0816 16:04:05.080677 20404 net.cpp:141] Setting up ReLU13
I0816 16:04:05.080698 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.080705 20404 net.cpp:156] Memory required for data: 888424800
I0816 16:04:05.080732 20404 layer_factory.hpp:77] Creating layer InnerProduct6
I0816 16:04:05.080746 20404 net.cpp:91] Creating Layer InnerProduct6
I0816 16:04:05.080754 20404 net.cpp:425] InnerProduct6 <- InnerProduct5
I0816 16:04:05.080767 20404 net.cpp:399] InnerProduct6 -> InnerProduct6
I0816 16:04:05.081172 20404 net.cpp:141] Setting up InnerProduct6
I0816 16:04:05.081187 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:05.081194 20404 net.cpp:156] Memory required for data: 888476000
I0816 16:04:05.081205 20404 layer_factory.hpp:77] Creating layer ReLU14
I0816 16:04:05.081217 20404 net.cpp:91] Creating Layer ReLU14
I0816 16:04:05.081224 20404 net.cpp:425] ReLU14 <- InnerProduct6
I0816 16:04:05.081235 20404 net.cpp:386] ReLU14 -> InnerProduct6 (in-place)
I0816 16:04:05.081248 20404 net.cpp:141] Setting up ReLU14
I0816 16:04:05.081259 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:05.081266 20404 net.cpp:156] Memory required for data: 888527200
I0816 16:04:05.081274 20404 layer_factory.hpp:77] Creating layer dt0
I0816 16:04:05.081286 20404 net.cpp:91] Creating Layer dt0
I0816 16:04:05.081295 20404 net.cpp:425] dt0 <- InnerProduct6
I0816 16:04:05.081307 20404 net.cpp:399] dt0 -> dt0
I0816 16:04:05.081455 20404 net.cpp:141] Setting up dt0
I0816 16:04:05.081470 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:05.081476 20404 net.cpp:156] Memory required for data: 888527600
I0816 16:04:05.081501 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:05.081521 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:05.081532 20404 net.cpp:425] conv1 <- p1_p1_0_split_1
I0816 16:04:05.081545 20404 net.cpp:399] conv1 -> Convolution11
I0816 16:04:05.083552 20404 net.cpp:141] Setting up conv1
I0816 16:04:05.083567 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.083575 20404 net.cpp:156] Memory required for data: 898358000
I0816 16:04:05.083588 20404 layer_factory.hpp:77] Creating layer ReLU15
I0816 16:04:05.083598 20404 net.cpp:91] Creating Layer ReLU15
I0816 16:04:05.083607 20404 net.cpp:425] ReLU15 <- Convolution11
I0816 16:04:05.083617 20404 net.cpp:386] ReLU15 -> Convolution11 (in-place)
I0816 16:04:05.083631 20404 net.cpp:141] Setting up ReLU15
I0816 16:04:05.083641 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.083647 20404 net.cpp:156] Memory required for data: 908188400
I0816 16:04:05.083654 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:05.083667 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:05.083674 20404 net.cpp:425] norm1 <- Convolution11
I0816 16:04:05.083686 20404 net.cpp:399] norm1 -> LRN5
I0816 16:04:05.083737 20404 net.cpp:141] Setting up norm1
I0816 16:04:05.083750 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.083758 20404 net.cpp:156] Memory required for data: 918018800
I0816 16:04:05.083765 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:05.083776 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:05.083784 20404 net.cpp:425] pool1 <- LRN5
I0816 16:04:05.083796 20404 net.cpp:399] pool1 -> Pooling7
I0816 16:04:05.083851 20404 net.cpp:141] Setting up pool1
I0816 16:04:05.083864 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:05.083871 20404 net.cpp:156] Memory required for data: 920476400
I0816 16:04:05.083879 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:05.083894 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:05.083902 20404 net.cpp:425] conv2 <- Pooling7
I0816 16:04:05.083915 20404 net.cpp:399] conv2 -> Convolution12
I0816 16:04:05.099462 20404 net.cpp:141] Setting up conv2
I0816 16:04:05.099490 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.099498 20404 net.cpp:156] Memory required for data: 927030000
I0816 16:04:05.099516 20404 layer_factory.hpp:77] Creating layer ReLU16
I0816 16:04:05.099529 20404 net.cpp:91] Creating Layer ReLU16
I0816 16:04:05.099539 20404 net.cpp:425] ReLU16 <- Convolution12
I0816 16:04:05.099552 20404 net.cpp:386] ReLU16 -> Convolution12 (in-place)
I0816 16:04:05.099566 20404 net.cpp:141] Setting up ReLU16
I0816 16:04:05.099601 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.099611 20404 net.cpp:156] Memory required for data: 933583600
I0816 16:04:05.099618 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:05.099630 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:05.099642 20404 net.cpp:425] norm2 <- Convolution12
I0816 16:04:05.099654 20404 net.cpp:399] norm2 -> LRN6
I0816 16:04:05.099731 20404 net.cpp:141] Setting up norm2
I0816 16:04:05.099745 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.099756 20404 net.cpp:156] Memory required for data: 940137200
I0816 16:04:05.099763 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:05.099776 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:05.099784 20404 net.cpp:425] pool2 <- LRN6
I0816 16:04:05.099799 20404 net.cpp:399] pool2 -> Pooling8
I0816 16:04:05.099872 20404 net.cpp:141] Setting up pool2
I0816 16:04:05.099886 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.099894 20404 net.cpp:156] Memory required for data: 941775600
I0816 16:04:05.099901 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:05.099925 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:05.099936 20404 net.cpp:425] conv3 <- Pooling8
I0816 16:04:05.099949 20404 net.cpp:399] conv3 -> Convolution13
I0816 16:04:05.144142 20404 net.cpp:141] Setting up conv3
I0816 16:04:05.144181 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.144188 20404 net.cpp:156] Memory required for data: 944233200
I0816 16:04:05.144201 20404 layer_factory.hpp:77] Creating layer ReLU17
I0816 16:04:05.144214 20404 net.cpp:91] Creating Layer ReLU17
I0816 16:04:05.144223 20404 net.cpp:425] ReLU17 <- Convolution13
I0816 16:04:05.144242 20404 net.cpp:386] ReLU17 -> Convolution13 (in-place)
I0816 16:04:05.144254 20404 net.cpp:141] Setting up ReLU17
I0816 16:04:05.144263 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.144268 20404 net.cpp:156] Memory required for data: 946690800
I0816 16:04:05.144273 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:05.144290 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:05.144296 20404 net.cpp:425] conv4 <- Convolution13
I0816 16:04:05.144309 20404 net.cpp:399] conv4 -> Convolution14
I0816 16:04:05.177357 20404 net.cpp:141] Setting up conv4
I0816 16:04:05.177392 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.177398 20404 net.cpp:156] Memory required for data: 949148400
I0816 16:04:05.177410 20404 layer_factory.hpp:77] Creating layer ReLU18
I0816 16:04:05.177424 20404 net.cpp:91] Creating Layer ReLU18
I0816 16:04:05.177433 20404 net.cpp:425] ReLU18 <- Convolution14
I0816 16:04:05.177450 20404 net.cpp:386] ReLU18 -> Convolution14 (in-place)
I0816 16:04:05.177462 20404 net.cpp:141] Setting up ReLU18
I0816 16:04:05.177470 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.177476 20404 net.cpp:156] Memory required for data: 951606000
I0816 16:04:05.177482 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:05.177497 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:05.177505 20404 net.cpp:425] conv5 <- Convolution14
I0816 16:04:05.177520 20404 net.cpp:399] conv5 -> Convolution15
I0816 16:04:05.199722 20404 net.cpp:141] Setting up conv5
I0816 16:04:05.199754 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.199760 20404 net.cpp:156] Memory required for data: 953244400
I0816 16:04:05.199772 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:05.199784 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:05.199791 20404 net.cpp:425] pool5 <- Convolution15
I0816 16:04:05.199815 20404 net.cpp:399] pool5 -> Pooling9
I0816 16:04:05.199875 20404 net.cpp:141] Setting up pool5
I0816 16:04:05.199894 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:05.199901 20404 net.cpp:156] Memory required for data: 953654000
I0816 16:04:05.199908 20404 layer_factory.hpp:77] Creating layer InnerProduct7
I0816 16:04:05.199923 20404 net.cpp:91] Creating Layer InnerProduct7
I0816 16:04:05.199930 20404 net.cpp:425] InnerProduct7 <- Pooling9
I0816 16:04:05.199975 20404 net.cpp:399] InnerProduct7 -> InnerProduct7
I0816 16:04:05.202728 20404 net.cpp:141] Setting up InnerProduct7
I0816 16:04:05.202757 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.202764 20404 net.cpp:156] Memory required for data: 953756400
I0816 16:04:05.202771 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:05.202780 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:05.202785 20404 layer_factory.hpp:77] Creating layer ReLU19
I0816 16:04:05.202795 20404 net.cpp:91] Creating Layer ReLU19
I0816 16:04:05.202800 20404 net.cpp:425] ReLU19 <- InnerProduct7
I0816 16:04:05.202817 20404 net.cpp:386] ReLU19 -> InnerProduct7 (in-place)
I0816 16:04:05.202831 20404 net.cpp:141] Setting up ReLU19
I0816 16:04:05.202838 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.202843 20404 net.cpp:156] Memory required for data: 953858800
I0816 16:04:05.202849 20404 layer_factory.hpp:77] Creating layer InnerProduct8
I0816 16:04:05.202862 20404 net.cpp:91] Creating Layer InnerProduct8
I0816 16:04:05.202870 20404 net.cpp:425] InnerProduct8 <- InnerProduct7
I0816 16:04:05.202883 20404 net.cpp:399] InnerProduct8 -> InnerProduct8
I0816 16:04:05.203583 20404 net.cpp:141] Setting up InnerProduct8
I0816 16:04:05.203593 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.203599 20404 net.cpp:156] Memory required for data: 953961200
I0816 16:04:05.203606 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:05.203613 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:05.203620 20404 layer_factory.hpp:77] Creating layer ReLU20
I0816 16:04:05.203629 20404 net.cpp:91] Creating Layer ReLU20
I0816 16:04:05.203634 20404 net.cpp:425] ReLU20 <- InnerProduct8
I0816 16:04:05.203647 20404 net.cpp:386] ReLU20 -> InnerProduct8 (in-place)
I0816 16:04:05.203660 20404 net.cpp:141] Setting up ReLU20
I0816 16:04:05.203670 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.203676 20404 net.cpp:156] Memory required for data: 954063600
I0816 16:04:05.203683 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:05.203702 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:05.203711 20404 net.cpp:425] conv1 <- c21
I0816 16:04:05.203724 20404 net.cpp:399] conv1 -> Convolution16
I0816 16:04:05.205786 20404 net.cpp:141] Setting up conv1
I0816 16:04:05.205806 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.205811 20404 net.cpp:156] Memory required for data: 963894000
I0816 16:04:05.205821 20404 layer_factory.hpp:77] Creating layer ReLU21
I0816 16:04:05.205832 20404 net.cpp:91] Creating Layer ReLU21
I0816 16:04:05.205838 20404 net.cpp:425] ReLU21 <- Convolution16
I0816 16:04:05.205847 20404 net.cpp:386] ReLU21 -> Convolution16 (in-place)
I0816 16:04:05.205857 20404 net.cpp:141] Setting up ReLU21
I0816 16:04:05.205871 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.205876 20404 net.cpp:156] Memory required for data: 973724400
I0816 16:04:05.205885 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:05.205898 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:05.205904 20404 net.cpp:425] norm1 <- Convolution16
I0816 16:04:05.205915 20404 net.cpp:399] norm1 -> LRN7
I0816 16:04:05.206012 20404 net.cpp:141] Setting up norm1
I0816 16:04:05.206023 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.206032 20404 net.cpp:156] Memory required for data: 983554800
I0816 16:04:05.206038 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:05.206054 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:05.206063 20404 net.cpp:425] pool1 <- LRN7
I0816 16:04:05.206074 20404 net.cpp:399] pool1 -> Pooling10
I0816 16:04:05.206138 20404 net.cpp:141] Setting up pool1
I0816 16:04:05.206146 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:05.206154 20404 net.cpp:156] Memory required for data: 986012400
I0816 16:04:05.206161 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:05.206189 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:05.206197 20404 net.cpp:425] conv2 <- Pooling10
I0816 16:04:05.206207 20404 net.cpp:399] conv2 -> Convolution17
I0816 16:04:05.221866 20404 net.cpp:141] Setting up conv2
I0816 16:04:05.221885 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.221891 20404 net.cpp:156] Memory required for data: 992566000
I0816 16:04:05.221904 20404 layer_factory.hpp:77] Creating layer ReLU22
I0816 16:04:05.221915 20404 net.cpp:91] Creating Layer ReLU22
I0816 16:04:05.221925 20404 net.cpp:425] ReLU22 <- Convolution17
I0816 16:04:05.221940 20404 net.cpp:386] ReLU22 -> Convolution17 (in-place)
I0816 16:04:05.221952 20404 net.cpp:141] Setting up ReLU22
I0816 16:04:05.221962 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.221971 20404 net.cpp:156] Memory required for data: 999119600
I0816 16:04:05.221977 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:05.221990 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:05.221998 20404 net.cpp:425] norm2 <- Convolution17
I0816 16:04:05.222010 20404 net.cpp:399] norm2 -> LRN8
I0816 16:04:05.222077 20404 net.cpp:141] Setting up norm2
I0816 16:04:05.222091 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.222098 20404 net.cpp:156] Memory required for data: 1005673200
I0816 16:04:05.222105 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:05.222116 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:05.222124 20404 net.cpp:425] pool2 <- LRN8
I0816 16:04:05.222134 20404 net.cpp:399] pool2 -> Pooling11
I0816 16:04:05.222203 20404 net.cpp:141] Setting up pool2
I0816 16:04:05.222214 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.222221 20404 net.cpp:156] Memory required for data: 1007311600
I0816 16:04:05.222229 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:05.222251 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:05.222259 20404 net.cpp:425] conv3 <- Pooling11
I0816 16:04:05.222275 20404 net.cpp:399] conv3 -> Convolution18
I0816 16:04:05.266176 20404 net.cpp:141] Setting up conv3
I0816 16:04:05.266218 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.266225 20404 net.cpp:156] Memory required for data: 1009769200
I0816 16:04:05.266238 20404 layer_factory.hpp:77] Creating layer ReLU23
I0816 16:04:05.266250 20404 net.cpp:91] Creating Layer ReLU23
I0816 16:04:05.266268 20404 net.cpp:425] ReLU23 <- Convolution18
I0816 16:04:05.266278 20404 net.cpp:386] ReLU23 -> Convolution18 (in-place)
I0816 16:04:05.266295 20404 net.cpp:141] Setting up ReLU23
I0816 16:04:05.266304 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.266309 20404 net.cpp:156] Memory required for data: 1012226800
I0816 16:04:05.266314 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:05.266336 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:05.266345 20404 net.cpp:425] conv4 <- Convolution18
I0816 16:04:05.266361 20404 net.cpp:399] conv4 -> Convolution19
I0816 16:04:05.299527 20404 net.cpp:141] Setting up conv4
I0816 16:04:05.299566 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.299571 20404 net.cpp:156] Memory required for data: 1014684400
I0816 16:04:05.299584 20404 layer_factory.hpp:77] Creating layer ReLU24
I0816 16:04:05.299597 20404 net.cpp:91] Creating Layer ReLU24
I0816 16:04:05.299604 20404 net.cpp:425] ReLU24 <- Convolution19
I0816 16:04:05.299624 20404 net.cpp:386] ReLU24 -> Convolution19 (in-place)
I0816 16:04:05.299638 20404 net.cpp:141] Setting up ReLU24
I0816 16:04:05.299645 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.299651 20404 net.cpp:156] Memory required for data: 1017142000
I0816 16:04:05.299656 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:05.299674 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:05.299681 20404 net.cpp:425] conv5 <- Convolution19
I0816 16:04:05.299698 20404 net.cpp:399] conv5 -> Convolution20
I0816 16:04:05.322151 20404 net.cpp:141] Setting up conv5
I0816 16:04:05.322188 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.322214 20404 net.cpp:156] Memory required for data: 1018780400
I0816 16:04:05.322228 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:05.322248 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:05.322257 20404 net.cpp:425] pool5 <- Convolution20
I0816 16:04:05.322271 20404 net.cpp:399] pool5 -> Pooling12
I0816 16:04:05.322346 20404 net.cpp:141] Setting up pool5
I0816 16:04:05.322356 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:05.322363 20404 net.cpp:156] Memory required for data: 1019190000
I0816 16:04:05.322371 20404 layer_factory.hpp:77] Creating layer InnerProduct9
I0816 16:04:05.322386 20404 net.cpp:91] Creating Layer InnerProduct9
I0816 16:04:05.322393 20404 net.cpp:425] InnerProduct9 <- Pooling12
I0816 16:04:05.322407 20404 net.cpp:399] InnerProduct9 -> InnerProduct9
I0816 16:04:05.325268 20404 net.cpp:141] Setting up InnerProduct9
I0816 16:04:05.325297 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.325304 20404 net.cpp:156] Memory required for data: 1019292400
I0816 16:04:05.325312 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:05.325320 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:05.325326 20404 layer_factory.hpp:77] Creating layer ReLU25
I0816 16:04:05.325338 20404 net.cpp:91] Creating Layer ReLU25
I0816 16:04:05.325353 20404 net.cpp:425] ReLU25 <- InnerProduct9
I0816 16:04:05.325362 20404 net.cpp:386] ReLU25 -> InnerProduct9 (in-place)
I0816 16:04:05.325377 20404 net.cpp:141] Setting up ReLU25
I0816 16:04:05.325384 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.325390 20404 net.cpp:156] Memory required for data: 1019394800
I0816 16:04:05.325397 20404 layer_factory.hpp:77] Creating layer InnerProduct10
I0816 16:04:05.325413 20404 net.cpp:91] Creating Layer InnerProduct10
I0816 16:04:05.325422 20404 net.cpp:425] InnerProduct10 <- InnerProduct9
I0816 16:04:05.325434 20404 net.cpp:399] InnerProduct10 -> InnerProduct10
I0816 16:04:05.326130 20404 net.cpp:141] Setting up InnerProduct10
I0816 16:04:05.326141 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.326146 20404 net.cpp:156] Memory required for data: 1019497200
I0816 16:04:05.326153 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:05.326160 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:05.326167 20404 layer_factory.hpp:77] Creating layer ReLU26
I0816 16:04:05.326174 20404 net.cpp:91] Creating Layer ReLU26
I0816 16:04:05.326184 20404 net.cpp:425] ReLU26 <- InnerProduct10
I0816 16:04:05.326195 20404 net.cpp:386] ReLU26 -> InnerProduct10 (in-place)
I0816 16:04:05.326206 20404 net.cpp:141] Setting up ReLU26
I0816 16:04:05.326216 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.326223 20404 net.cpp:156] Memory required for data: 1019599600
I0816 16:04:05.326231 20404 layer_factory.hpp:77] Creating layer Concat2
I0816 16:04:05.326244 20404 net.cpp:91] Creating Layer Concat2
I0816 16:04:05.326253 20404 net.cpp:425] Concat2 <- InnerProduct8
I0816 16:04:05.326262 20404 net.cpp:425] Concat2 <- InnerProduct10
I0816 16:04:05.326274 20404 net.cpp:399] Concat2 -> Concat2
I0816 16:04:05.326318 20404 net.cpp:141] Setting up Concat2
I0816 16:04:05.326328 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:05.326335 20404 net.cpp:156] Memory required for data: 1019804400
I0816 16:04:05.326344 20404 layer_factory.hpp:77] Creating layer InnerProduct11
I0816 16:04:05.326357 20404 net.cpp:91] Creating Layer InnerProduct11
I0816 16:04:05.326365 20404 net.cpp:425] InnerProduct11 <- Concat2
I0816 16:04:05.326377 20404 net.cpp:399] InnerProduct11 -> InnerProduct11
I0816 16:04:05.328181 20404 net.cpp:141] Setting up InnerProduct11
I0816 16:04:05.328209 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.328215 20404 net.cpp:156] Memory required for data: 1019906800
I0816 16:04:05.328223 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:05.328246 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:05.328253 20404 layer_factory.hpp:77] Creating layer ReLU27
I0816 16:04:05.328263 20404 net.cpp:91] Creating Layer ReLU27
I0816 16:04:05.328269 20404 net.cpp:425] ReLU27 <- InnerProduct11
I0816 16:04:05.328279 20404 net.cpp:386] ReLU27 -> InnerProduct11 (in-place)
I0816 16:04:05.328290 20404 net.cpp:141] Setting up ReLU27
I0816 16:04:05.328297 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.328306 20404 net.cpp:156] Memory required for data: 1020009200
I0816 16:04:05.328313 20404 layer_factory.hpp:77] Creating layer InnerProduct12
I0816 16:04:05.328372 20404 net.cpp:91] Creating Layer InnerProduct12
I0816 16:04:05.328379 20404 net.cpp:425] InnerProduct12 <- InnerProduct11
I0816 16:04:05.328397 20404 net.cpp:399] InnerProduct12 -> InnerProduct12
I0816 16:04:05.328807 20404 net.cpp:141] Setting up InnerProduct12
I0816 16:04:05.328819 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:05.328826 20404 net.cpp:156] Memory required for data: 1020060400
I0816 16:04:05.328856 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:05.328865 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:05.328871 20404 layer_factory.hpp:77] Creating layer ReLU28
I0816 16:04:05.328881 20404 net.cpp:91] Creating Layer ReLU28
I0816 16:04:05.328886 20404 net.cpp:425] ReLU28 <- InnerProduct12
I0816 16:04:05.328896 20404 net.cpp:386] ReLU28 -> InnerProduct12 (in-place)
I0816 16:04:05.328905 20404 net.cpp:141] Setting up ReLU28
I0816 16:04:05.328912 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:05.328917 20404 net.cpp:156] Memory required for data: 1020111600
I0816 16:04:05.328923 20404 layer_factory.hpp:77] Creating layer dt1
I0816 16:04:05.328935 20404 net.cpp:91] Creating Layer dt1
I0816 16:04:05.328941 20404 net.cpp:425] dt1 <- InnerProduct12
I0816 16:04:05.328953 20404 net.cpp:399] dt1 -> dt1
I0816 16:04:05.329100 20404 net.cpp:141] Setting up dt1
I0816 16:04:05.329110 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:05.329118 20404 net.cpp:156] Memory required for data: 1020112000
I0816 16:04:05.329125 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:05.329131 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:05.329138 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:05.329154 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:05.329160 20404 net.cpp:425] conv1 <- p1_p1_0_split_2
I0816 16:04:05.329170 20404 net.cpp:399] conv1 -> Convolution21
I0816 16:04:05.331198 20404 net.cpp:141] Setting up conv1
I0816 16:04:05.331219 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.331224 20404 net.cpp:156] Memory required for data: 1029942400
I0816 16:04:05.331234 20404 layer_factory.hpp:77] Creating layer ReLU29
I0816 16:04:05.331243 20404 net.cpp:91] Creating Layer ReLU29
I0816 16:04:05.331248 20404 net.cpp:425] ReLU29 <- Convolution21
I0816 16:04:05.331256 20404 net.cpp:386] ReLU29 -> Convolution21 (in-place)
I0816 16:04:05.331265 20404 net.cpp:141] Setting up ReLU29
I0816 16:04:05.331286 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.331295 20404 net.cpp:156] Memory required for data: 1039772800
I0816 16:04:05.331301 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:05.331312 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:05.331320 20404 net.cpp:425] norm1 <- Convolution21
I0816 16:04:05.331331 20404 net.cpp:399] norm1 -> LRN9
I0816 16:04:05.331378 20404 net.cpp:141] Setting up norm1
I0816 16:04:05.331385 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.331392 20404 net.cpp:156] Memory required for data: 1049603200
I0816 16:04:05.331398 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:05.331405 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:05.331424 20404 net.cpp:425] pool1 <- LRN9
I0816 16:04:05.331436 20404 net.cpp:399] pool1 -> Pooling13
I0816 16:04:05.331493 20404 net.cpp:141] Setting up pool1
I0816 16:04:05.331501 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:05.331506 20404 net.cpp:156] Memory required for data: 1052060800
I0816 16:04:05.331512 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:05.331526 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:05.331533 20404 net.cpp:425] conv2 <- Pooling13
I0816 16:04:05.331543 20404 net.cpp:399] conv2 -> Convolution22
I0816 16:04:05.347304 20404 net.cpp:141] Setting up conv2
I0816 16:04:05.347329 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.347337 20404 net.cpp:156] Memory required for data: 1058614400
I0816 16:04:05.347348 20404 layer_factory.hpp:77] Creating layer ReLU30
I0816 16:04:05.347359 20404 net.cpp:91] Creating Layer ReLU30
I0816 16:04:05.347368 20404 net.cpp:425] ReLU30 <- Convolution22
I0816 16:04:05.347383 20404 net.cpp:386] ReLU30 -> Convolution22 (in-place)
I0816 16:04:05.347398 20404 net.cpp:141] Setting up ReLU30
I0816 16:04:05.347407 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.347414 20404 net.cpp:156] Memory required for data: 1065168000
I0816 16:04:05.347421 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:05.347432 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:05.347440 20404 net.cpp:425] norm2 <- Convolution22
I0816 16:04:05.347452 20404 net.cpp:399] norm2 -> LRN10
I0816 16:04:05.347527 20404 net.cpp:141] Setting up norm2
I0816 16:04:05.347537 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.347544 20404 net.cpp:156] Memory required for data: 1071721600
I0816 16:04:05.347551 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:05.347564 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:05.347573 20404 net.cpp:425] pool2 <- LRN10
I0816 16:04:05.347584 20404 net.cpp:399] pool2 -> Pooling14
I0816 16:04:05.347654 20404 net.cpp:141] Setting up pool2
I0816 16:04:05.347666 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.347672 20404 net.cpp:156] Memory required for data: 1073360000
I0816 16:04:05.347679 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:05.347697 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:05.347707 20404 net.cpp:425] conv3 <- Pooling14
I0816 16:04:05.347720 20404 net.cpp:399] conv3 -> Convolution23
I0816 16:04:05.392143 20404 net.cpp:141] Setting up conv3
I0816 16:04:05.392185 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.392192 20404 net.cpp:156] Memory required for data: 1075817600
I0816 16:04:05.392205 20404 layer_factory.hpp:77] Creating layer ReLU31
I0816 16:04:05.392220 20404 net.cpp:91] Creating Layer ReLU31
I0816 16:04:05.392240 20404 net.cpp:425] ReLU31 <- Convolution23
I0816 16:04:05.392252 20404 net.cpp:386] ReLU31 -> Convolution23 (in-place)
I0816 16:04:05.392266 20404 net.cpp:141] Setting up ReLU31
I0816 16:04:05.392274 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.392279 20404 net.cpp:156] Memory required for data: 1078275200
I0816 16:04:05.392285 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:05.392302 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:05.392309 20404 net.cpp:425] conv4 <- Convolution23
I0816 16:04:05.392319 20404 net.cpp:399] conv4 -> Convolution24
I0816 16:04:05.425302 20404 net.cpp:141] Setting up conv4
I0816 16:04:05.425331 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.425340 20404 net.cpp:156] Memory required for data: 1080732800
I0816 16:04:05.425366 20404 layer_factory.hpp:77] Creating layer ReLU32
I0816 16:04:05.425392 20404 net.cpp:91] Creating Layer ReLU32
I0816 16:04:05.425408 20404 net.cpp:425] ReLU32 <- Convolution24
I0816 16:04:05.425431 20404 net.cpp:386] ReLU32 -> Convolution24 (in-place)
I0816 16:04:05.425448 20404 net.cpp:141] Setting up ReLU32
I0816 16:04:05.425459 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.425467 20404 net.cpp:156] Memory required for data: 1083190400
I0816 16:04:05.425493 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:05.425514 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:05.425528 20404 net.cpp:425] conv5 <- Convolution24
I0816 16:04:05.425544 20404 net.cpp:399] conv5 -> Convolution25
I0816 16:04:05.448145 20404 net.cpp:141] Setting up conv5
I0816 16:04:05.448185 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.448205 20404 net.cpp:156] Memory required for data: 1084828800
I0816 16:04:05.448221 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:05.448238 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:05.448251 20404 net.cpp:425] pool5 <- Convolution25
I0816 16:04:05.448276 20404 net.cpp:399] pool5 -> Pooling15
I0816 16:04:05.448351 20404 net.cpp:141] Setting up pool5
I0816 16:04:05.448365 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:05.448374 20404 net.cpp:156] Memory required for data: 1085238400
I0816 16:04:05.448380 20404 layer_factory.hpp:77] Creating layer InnerProduct13
I0816 16:04:05.448397 20404 net.cpp:91] Creating Layer InnerProduct13
I0816 16:04:05.448406 20404 net.cpp:425] InnerProduct13 <- Pooling15
I0816 16:04:05.448421 20404 net.cpp:399] InnerProduct13 -> InnerProduct13
I0816 16:04:05.451207 20404 net.cpp:141] Setting up InnerProduct13
I0816 16:04:05.451228 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.451246 20404 net.cpp:156] Memory required for data: 1085340800
I0816 16:04:05.451254 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:05.451264 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:05.451278 20404 layer_factory.hpp:77] Creating layer ReLU33
I0816 16:04:05.451293 20404 net.cpp:91] Creating Layer ReLU33
I0816 16:04:05.451308 20404 net.cpp:425] ReLU33 <- InnerProduct13
I0816 16:04:05.451323 20404 net.cpp:386] ReLU33 -> InnerProduct13 (in-place)
I0816 16:04:05.451336 20404 net.cpp:141] Setting up ReLU33
I0816 16:04:05.451347 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.451354 20404 net.cpp:156] Memory required for data: 1085443200
I0816 16:04:05.451362 20404 layer_factory.hpp:77] Creating layer InnerProduct14
I0816 16:04:05.451375 20404 net.cpp:91] Creating Layer InnerProduct14
I0816 16:04:05.451383 20404 net.cpp:425] InnerProduct14 <- InnerProduct13
I0816 16:04:05.451400 20404 net.cpp:399] InnerProduct14 -> InnerProduct14
I0816 16:04:05.452085 20404 net.cpp:141] Setting up InnerProduct14
I0816 16:04:05.452098 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.452116 20404 net.cpp:156] Memory required for data: 1085545600
I0816 16:04:05.452124 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:05.452134 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:05.452142 20404 layer_factory.hpp:77] Creating layer ReLU34
I0816 16:04:05.452155 20404 net.cpp:91] Creating Layer ReLU34
I0816 16:04:05.452164 20404 net.cpp:425] ReLU34 <- InnerProduct14
I0816 16:04:05.452175 20404 net.cpp:386] ReLU34 -> InnerProduct14 (in-place)
I0816 16:04:05.452188 20404 net.cpp:141] Setting up ReLU34
I0816 16:04:05.452199 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.452206 20404 net.cpp:156] Memory required for data: 1085648000
I0816 16:04:05.452214 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:05.452231 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:05.452240 20404 net.cpp:425] conv1 <- c22
I0816 16:04:05.452257 20404 net.cpp:399] conv1 -> Convolution26
I0816 16:04:05.454298 20404 net.cpp:141] Setting up conv1
I0816 16:04:05.454313 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.454330 20404 net.cpp:156] Memory required for data: 1095478400
I0816 16:04:05.454344 20404 layer_factory.hpp:77] Creating layer ReLU35
I0816 16:04:05.454355 20404 net.cpp:91] Creating Layer ReLU35
I0816 16:04:05.454362 20404 net.cpp:425] ReLU35 <- Convolution26
I0816 16:04:05.454373 20404 net.cpp:386] ReLU35 -> Convolution26 (in-place)
I0816 16:04:05.454418 20404 net.cpp:141] Setting up ReLU35
I0816 16:04:05.454429 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.454437 20404 net.cpp:156] Memory required for data: 1105308800
I0816 16:04:05.454444 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:05.454460 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:05.454468 20404 net.cpp:425] norm1 <- Convolution26
I0816 16:04:05.454484 20404 net.cpp:399] norm1 -> LRN11
I0816 16:04:05.454540 20404 net.cpp:141] Setting up norm1
I0816 16:04:05.454555 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.454562 20404 net.cpp:156] Memory required for data: 1115139200
I0816 16:04:05.454571 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:05.454581 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:05.454591 20404 net.cpp:425] pool1 <- LRN11
I0816 16:04:05.454603 20404 net.cpp:399] pool1 -> Pooling16
I0816 16:04:05.454666 20404 net.cpp:141] Setting up pool1
I0816 16:04:05.454680 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:05.454687 20404 net.cpp:156] Memory required for data: 1117596800
I0816 16:04:05.454695 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:05.454712 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:05.454720 20404 net.cpp:425] conv2 <- Pooling16
I0816 16:04:05.454736 20404 net.cpp:399] conv2 -> Convolution27
I0816 16:04:05.470417 20404 net.cpp:141] Setting up conv2
I0816 16:04:05.470446 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.470463 20404 net.cpp:156] Memory required for data: 1124150400
I0816 16:04:05.470479 20404 layer_factory.hpp:77] Creating layer ReLU36
I0816 16:04:05.470492 20404 net.cpp:91] Creating Layer ReLU36
I0816 16:04:05.470502 20404 net.cpp:425] ReLU36 <- Convolution27
I0816 16:04:05.470523 20404 net.cpp:386] ReLU36 -> Convolution27 (in-place)
I0816 16:04:05.470541 20404 net.cpp:141] Setting up ReLU36
I0816 16:04:05.470551 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.470559 20404 net.cpp:156] Memory required for data: 1130704000
I0816 16:04:05.470566 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:05.470578 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:05.470587 20404 net.cpp:425] norm2 <- Convolution27
I0816 16:04:05.470602 20404 net.cpp:399] norm2 -> LRN12
I0816 16:04:05.470665 20404 net.cpp:141] Setting up norm2
I0816 16:04:05.470680 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.470688 20404 net.cpp:156] Memory required for data: 1137257600
I0816 16:04:05.470695 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:05.470710 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:05.470718 20404 net.cpp:425] pool2 <- LRN12
I0816 16:04:05.470731 20404 net.cpp:399] pool2 -> Pooling17
I0816 16:04:05.470795 20404 net.cpp:141] Setting up pool2
I0816 16:04:05.470809 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.470818 20404 net.cpp:156] Memory required for data: 1138896000
I0816 16:04:05.470824 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:05.470846 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:05.470855 20404 net.cpp:425] conv3 <- Pooling17
I0816 16:04:05.470872 20404 net.cpp:399] conv3 -> Convolution28
I0816 16:04:05.515215 20404 net.cpp:141] Setting up conv3
I0816 16:04:05.515251 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.515270 20404 net.cpp:156] Memory required for data: 1141353600
I0816 16:04:05.515308 20404 layer_factory.hpp:77] Creating layer ReLU37
I0816 16:04:05.515326 20404 net.cpp:91] Creating Layer ReLU37
I0816 16:04:05.515347 20404 net.cpp:425] ReLU37 <- Convolution28
I0816 16:04:05.515363 20404 net.cpp:386] ReLU37 -> Convolution28 (in-place)
I0816 16:04:05.515382 20404 net.cpp:141] Setting up ReLU37
I0816 16:04:05.515393 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.515399 20404 net.cpp:156] Memory required for data: 1143811200
I0816 16:04:05.515408 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:05.515425 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:05.515457 20404 net.cpp:425] conv4 <- Convolution28
I0816 16:04:05.515477 20404 net.cpp:399] conv4 -> Convolution29
I0816 16:04:05.548458 20404 net.cpp:141] Setting up conv4
I0816 16:04:05.548488 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.548506 20404 net.cpp:156] Memory required for data: 1146268800
I0816 16:04:05.548522 20404 layer_factory.hpp:77] Creating layer ReLU38
I0816 16:04:05.548537 20404 net.cpp:91] Creating Layer ReLU38
I0816 16:04:05.548547 20404 net.cpp:425] ReLU38 <- Convolution29
I0816 16:04:05.548578 20404 net.cpp:386] ReLU38 -> Convolution29 (in-place)
I0816 16:04:05.548601 20404 net.cpp:141] Setting up ReLU38
I0816 16:04:05.548614 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.548621 20404 net.cpp:156] Memory required for data: 1148726400
I0816 16:04:05.548629 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:05.548650 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:05.548660 20404 net.cpp:425] conv5 <- Convolution29
I0816 16:04:05.548673 20404 net.cpp:399] conv5 -> Convolution30
I0816 16:04:05.570914 20404 net.cpp:141] Setting up conv5
I0816 16:04:05.570938 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.570946 20404 net.cpp:156] Memory required for data: 1150364800
I0816 16:04:05.570969 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:05.570984 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:05.570994 20404 net.cpp:425] pool5 <- Convolution30
I0816 16:04:05.571012 20404 net.cpp:399] pool5 -> Pooling18
I0816 16:04:05.571089 20404 net.cpp:141] Setting up pool5
I0816 16:04:05.571104 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:05.571110 20404 net.cpp:156] Memory required for data: 1150774400
I0816 16:04:05.571117 20404 layer_factory.hpp:77] Creating layer InnerProduct15
I0816 16:04:05.571135 20404 net.cpp:91] Creating Layer InnerProduct15
I0816 16:04:05.571143 20404 net.cpp:425] InnerProduct15 <- Pooling18
I0816 16:04:05.571161 20404 net.cpp:399] InnerProduct15 -> InnerProduct15
I0816 16:04:05.573900 20404 net.cpp:141] Setting up InnerProduct15
I0816 16:04:05.573922 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.573930 20404 net.cpp:156] Memory required for data: 1150876800
I0816 16:04:05.573947 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:05.573957 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:05.573966 20404 layer_factory.hpp:77] Creating layer ReLU39
I0816 16:04:05.573976 20404 net.cpp:91] Creating Layer ReLU39
I0816 16:04:05.573985 20404 net.cpp:425] ReLU39 <- InnerProduct15
I0816 16:04:05.574007 20404 net.cpp:386] ReLU39 -> InnerProduct15 (in-place)
I0816 16:04:05.574020 20404 net.cpp:141] Setting up ReLU39
I0816 16:04:05.574031 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.574038 20404 net.cpp:156] Memory required for data: 1150979200
I0816 16:04:05.574046 20404 layer_factory.hpp:77] Creating layer InnerProduct16
I0816 16:04:05.574062 20404 net.cpp:91] Creating Layer InnerProduct16
I0816 16:04:05.574071 20404 net.cpp:425] InnerProduct16 <- InnerProduct15
I0816 16:04:05.574086 20404 net.cpp:399] InnerProduct16 -> InnerProduct16
I0816 16:04:05.574765 20404 net.cpp:141] Setting up InnerProduct16
I0816 16:04:05.574780 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.574795 20404 net.cpp:156] Memory required for data: 1151081600
I0816 16:04:05.574805 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:05.574813 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:05.574821 20404 layer_factory.hpp:77] Creating layer ReLU40
I0816 16:04:05.574832 20404 net.cpp:91] Creating Layer ReLU40
I0816 16:04:05.574841 20404 net.cpp:425] ReLU40 <- InnerProduct16
I0816 16:04:05.574853 20404 net.cpp:386] ReLU40 -> InnerProduct16 (in-place)
I0816 16:04:05.574867 20404 net.cpp:141] Setting up ReLU40
I0816 16:04:05.574877 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.574903 20404 net.cpp:156] Memory required for data: 1151184000
I0816 16:04:05.574910 20404 layer_factory.hpp:77] Creating layer Concat3
I0816 16:04:05.574921 20404 net.cpp:91] Creating Layer Concat3
I0816 16:04:05.574929 20404 net.cpp:425] Concat3 <- InnerProduct14
I0816 16:04:05.574939 20404 net.cpp:425] Concat3 <- InnerProduct16
I0816 16:04:05.574952 20404 net.cpp:399] Concat3 -> Concat3
I0816 16:04:05.574995 20404 net.cpp:141] Setting up Concat3
I0816 16:04:05.575011 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:05.575017 20404 net.cpp:156] Memory required for data: 1151388800
I0816 16:04:05.575026 20404 layer_factory.hpp:77] Creating layer InnerProduct17
I0816 16:04:05.575042 20404 net.cpp:91] Creating Layer InnerProduct17
I0816 16:04:05.575049 20404 net.cpp:425] InnerProduct17 <- Concat3
I0816 16:04:05.575062 20404 net.cpp:399] InnerProduct17 -> InnerProduct17
I0816 16:04:05.576247 20404 net.cpp:141] Setting up InnerProduct17
I0816 16:04:05.576262 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.576280 20404 net.cpp:156] Memory required for data: 1151491200
I0816 16:04:05.576288 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:05.576298 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:05.576306 20404 layer_factory.hpp:77] Creating layer ReLU41
I0816 16:04:05.576316 20404 net.cpp:91] Creating Layer ReLU41
I0816 16:04:05.576324 20404 net.cpp:425] ReLU41 <- InnerProduct17
I0816 16:04:05.576344 20404 net.cpp:386] ReLU41 -> InnerProduct17 (in-place)
I0816 16:04:05.576356 20404 net.cpp:141] Setting up ReLU41
I0816 16:04:05.576366 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.576373 20404 net.cpp:156] Memory required for data: 1151593600
I0816 16:04:05.576381 20404 layer_factory.hpp:77] Creating layer InnerProduct18
I0816 16:04:05.576393 20404 net.cpp:91] Creating Layer InnerProduct18
I0816 16:04:05.576400 20404 net.cpp:425] InnerProduct18 <- InnerProduct17
I0816 16:04:05.576416 20404 net.cpp:399] InnerProduct18 -> InnerProduct18
I0816 16:04:05.576835 20404 net.cpp:141] Setting up InnerProduct18
I0816 16:04:05.576853 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:05.576861 20404 net.cpp:156] Memory required for data: 1151644800
I0816 16:04:05.576870 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:05.576879 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:05.576887 20404 layer_factory.hpp:77] Creating layer ReLU42
I0816 16:04:05.576899 20404 net.cpp:91] Creating Layer ReLU42
I0816 16:04:05.576906 20404 net.cpp:425] ReLU42 <- InnerProduct18
I0816 16:04:05.576917 20404 net.cpp:386] ReLU42 -> InnerProduct18 (in-place)
I0816 16:04:05.576930 20404 net.cpp:141] Setting up ReLU42
I0816 16:04:05.576941 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:05.576947 20404 net.cpp:156] Memory required for data: 1151696000
I0816 16:04:05.576954 20404 layer_factory.hpp:77] Creating layer dt2
I0816 16:04:05.576967 20404 net.cpp:91] Creating Layer dt2
I0816 16:04:05.576974 20404 net.cpp:425] dt2 <- InnerProduct18
I0816 16:04:05.576988 20404 net.cpp:399] dt2 -> dt2
I0816 16:04:05.577153 20404 net.cpp:141] Setting up dt2
I0816 16:04:05.577167 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:05.577175 20404 net.cpp:156] Memory required for data: 1151696400
I0816 16:04:05.577183 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:05.577193 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:05.577201 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:05.577220 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:05.577234 20404 net.cpp:425] conv1 <- p1_p1_0_split_3
I0816 16:04:05.577249 20404 net.cpp:399] conv1 -> Convolution31
I0816 16:04:05.579282 20404 net.cpp:141] Setting up conv1
I0816 16:04:05.579298 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.579322 20404 net.cpp:156] Memory required for data: 1161526800
I0816 16:04:05.579337 20404 layer_factory.hpp:77] Creating layer ReLU43
I0816 16:04:05.579347 20404 net.cpp:91] Creating Layer ReLU43
I0816 16:04:05.579355 20404 net.cpp:425] ReLU43 <- Convolution31
I0816 16:04:05.579366 20404 net.cpp:386] ReLU43 -> Convolution31 (in-place)
I0816 16:04:05.579381 20404 net.cpp:141] Setting up ReLU43
I0816 16:04:05.579391 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.579398 20404 net.cpp:156] Memory required for data: 1171357200
I0816 16:04:05.579406 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:05.579417 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:05.579427 20404 net.cpp:425] norm1 <- Convolution31
I0816 16:04:05.579438 20404 net.cpp:399] norm1 -> LRN13
I0816 16:04:05.579496 20404 net.cpp:141] Setting up norm1
I0816 16:04:05.579509 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.579516 20404 net.cpp:156] Memory required for data: 1181187600
I0816 16:04:05.579524 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:05.579535 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:05.579542 20404 net.cpp:425] pool1 <- LRN13
I0816 16:04:05.579555 20404 net.cpp:399] pool1 -> Pooling19
I0816 16:04:05.579614 20404 net.cpp:141] Setting up pool1
I0816 16:04:05.579628 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:05.579635 20404 net.cpp:156] Memory required for data: 1183645200
I0816 16:04:05.579643 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:05.579661 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:05.579674 20404 net.cpp:425] conv2 <- Pooling19
I0816 16:04:05.579689 20404 net.cpp:399] conv2 -> Convolution32
I0816 16:04:05.595381 20404 net.cpp:141] Setting up conv2
I0816 16:04:05.595407 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.595425 20404 net.cpp:156] Memory required for data: 1190198800
I0816 16:04:05.595440 20404 layer_factory.hpp:77] Creating layer ReLU44
I0816 16:04:05.595453 20404 net.cpp:91] Creating Layer ReLU44
I0816 16:04:05.595463 20404 net.cpp:425] ReLU44 <- Convolution32
I0816 16:04:05.595474 20404 net.cpp:386] ReLU44 -> Convolution32 (in-place)
I0816 16:04:05.595499 20404 net.cpp:141] Setting up ReLU44
I0816 16:04:05.595509 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.595516 20404 net.cpp:156] Memory required for data: 1196752400
I0816 16:04:05.595523 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:05.595540 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:05.595547 20404 net.cpp:425] norm2 <- Convolution32
I0816 16:04:05.595563 20404 net.cpp:399] norm2 -> LRN14
I0816 16:04:05.595628 20404 net.cpp:141] Setting up norm2
I0816 16:04:05.595643 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.595649 20404 net.cpp:156] Memory required for data: 1203306000
I0816 16:04:05.595657 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:05.595670 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:05.595679 20404 net.cpp:425] pool2 <- LRN14
I0816 16:04:05.595691 20404 net.cpp:399] pool2 -> Pooling20
I0816 16:04:05.595758 20404 net.cpp:141] Setting up pool2
I0816 16:04:05.595772 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.595780 20404 net.cpp:156] Memory required for data: 1204944400
I0816 16:04:05.595788 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:05.595806 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:05.595815 20404 net.cpp:425] conv3 <- Pooling20
I0816 16:04:05.595831 20404 net.cpp:399] conv3 -> Convolution33
I0816 16:04:05.639869 20404 net.cpp:141] Setting up conv3
I0816 16:04:05.639904 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.639914 20404 net.cpp:156] Memory required for data: 1207402000
I0816 16:04:05.639938 20404 layer_factory.hpp:77] Creating layer ReLU45
I0816 16:04:05.639955 20404 net.cpp:91] Creating Layer ReLU45
I0816 16:04:05.639969 20404 net.cpp:425] ReLU45 <- Convolution33
I0816 16:04:05.639992 20404 net.cpp:386] ReLU45 -> Convolution33 (in-place)
I0816 16:04:05.640028 20404 net.cpp:141] Setting up ReLU45
I0816 16:04:05.640043 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.640051 20404 net.cpp:156] Memory required for data: 1209859600
I0816 16:04:05.640059 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:05.640080 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:05.640094 20404 net.cpp:425] conv4 <- Convolution33
I0816 16:04:05.640108 20404 net.cpp:399] conv4 -> Convolution34
I0816 16:04:05.673413 20404 net.cpp:141] Setting up conv4
I0816 16:04:05.673447 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.673456 20404 net.cpp:156] Memory required for data: 1212317200
I0816 16:04:05.673472 20404 layer_factory.hpp:77] Creating layer ReLU46
I0816 16:04:05.673498 20404 net.cpp:91] Creating Layer ReLU46
I0816 16:04:05.673509 20404 net.cpp:425] ReLU46 <- Convolution34
I0816 16:04:05.673523 20404 net.cpp:386] ReLU46 -> Convolution34 (in-place)
I0816 16:04:05.673538 20404 net.cpp:141] Setting up ReLU46
I0816 16:04:05.673548 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.673555 20404 net.cpp:156] Memory required for data: 1214774800
I0816 16:04:05.673563 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:05.673584 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:05.673593 20404 net.cpp:425] conv5 <- Convolution34
I0816 16:04:05.673609 20404 net.cpp:399] conv5 -> Convolution35
I0816 16:04:05.696352 20404 net.cpp:141] Setting up conv5
I0816 16:04:05.696383 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.696403 20404 net.cpp:156] Memory required for data: 1216413200
I0816 16:04:05.696420 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:05.696441 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:05.696455 20404 net.cpp:425] pool5 <- Convolution35
I0816 16:04:05.696478 20404 net.cpp:399] pool5 -> Pooling21
I0816 16:04:05.696560 20404 net.cpp:141] Setting up pool5
I0816 16:04:05.696574 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:05.696583 20404 net.cpp:156] Memory required for data: 1216822800
I0816 16:04:05.696589 20404 layer_factory.hpp:77] Creating layer InnerProduct19
I0816 16:04:05.696606 20404 net.cpp:91] Creating Layer InnerProduct19
I0816 16:04:05.696615 20404 net.cpp:425] InnerProduct19 <- Pooling21
I0816 16:04:05.696629 20404 net.cpp:399] InnerProduct19 -> InnerProduct19
I0816 16:04:05.699478 20404 net.cpp:141] Setting up InnerProduct19
I0816 16:04:05.699499 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.699517 20404 net.cpp:156] Memory required for data: 1216925200
I0816 16:04:05.699528 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:05.699538 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:05.699547 20404 layer_factory.hpp:77] Creating layer ReLU47
I0816 16:04:05.699558 20404 net.cpp:91] Creating Layer ReLU47
I0816 16:04:05.699566 20404 net.cpp:425] ReLU47 <- InnerProduct19
I0816 16:04:05.699591 20404 net.cpp:386] ReLU47 -> InnerProduct19 (in-place)
I0816 16:04:05.699606 20404 net.cpp:141] Setting up ReLU47
I0816 16:04:05.699616 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.699623 20404 net.cpp:156] Memory required for data: 1217027600
I0816 16:04:05.699630 20404 layer_factory.hpp:77] Creating layer InnerProduct20
I0816 16:04:05.699643 20404 net.cpp:91] Creating Layer InnerProduct20
I0816 16:04:05.699651 20404 net.cpp:425] InnerProduct20 <- InnerProduct19
I0816 16:04:05.699666 20404 net.cpp:399] InnerProduct20 -> InnerProduct20
I0816 16:04:05.700351 20404 net.cpp:141] Setting up InnerProduct20
I0816 16:04:05.700366 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.700374 20404 net.cpp:156] Memory required for data: 1217130000
I0816 16:04:05.700382 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:05.700392 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:05.700399 20404 layer_factory.hpp:77] Creating layer ReLU48
I0816 16:04:05.700428 20404 net.cpp:91] Creating Layer ReLU48
I0816 16:04:05.700436 20404 net.cpp:425] ReLU48 <- InnerProduct20
I0816 16:04:05.700446 20404 net.cpp:386] ReLU48 -> InnerProduct20 (in-place)
I0816 16:04:05.700459 20404 net.cpp:141] Setting up ReLU48
I0816 16:04:05.700470 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.700477 20404 net.cpp:156] Memory required for data: 1217232400
I0816 16:04:05.700485 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:05.700506 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:05.700515 20404 net.cpp:425] conv1 <- c23
I0816 16:04:05.700532 20404 net.cpp:399] conv1 -> Convolution36
I0816 16:04:05.702623 20404 net.cpp:141] Setting up conv1
I0816 16:04:05.702639 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.702647 20404 net.cpp:156] Memory required for data: 1227062800
I0816 16:04:05.702661 20404 layer_factory.hpp:77] Creating layer ReLU49
I0816 16:04:05.702672 20404 net.cpp:91] Creating Layer ReLU49
I0816 16:04:05.702680 20404 net.cpp:425] ReLU49 <- Convolution36
I0816 16:04:05.702692 20404 net.cpp:386] ReLU49 -> Convolution36 (in-place)
I0816 16:04:05.702704 20404 net.cpp:141] Setting up ReLU49
I0816 16:04:05.702714 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.702721 20404 net.cpp:156] Memory required for data: 1236893200
I0816 16:04:05.702729 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:05.702744 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:05.702752 20404 net.cpp:425] norm1 <- Convolution36
I0816 16:04:05.702764 20404 net.cpp:399] norm1 -> LRN15
I0816 16:04:05.702823 20404 net.cpp:141] Setting up norm1
I0816 16:04:05.702836 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.702844 20404 net.cpp:156] Memory required for data: 1246723600
I0816 16:04:05.702852 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:05.702862 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:05.702870 20404 net.cpp:425] pool1 <- LRN15
I0816 16:04:05.702884 20404 net.cpp:399] pool1 -> Pooling22
I0816 16:04:05.702946 20404 net.cpp:141] Setting up pool1
I0816 16:04:05.702960 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:05.702967 20404 net.cpp:156] Memory required for data: 1249181200
I0816 16:04:05.702975 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:05.702996 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:05.703004 20404 net.cpp:425] conv2 <- Pooling22
I0816 16:04:05.703017 20404 net.cpp:399] conv2 -> Convolution37
I0816 16:04:05.718691 20404 net.cpp:141] Setting up conv2
I0816 16:04:05.718714 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.718732 20404 net.cpp:156] Memory required for data: 1255734800
I0816 16:04:05.718747 20404 layer_factory.hpp:77] Creating layer ReLU50
I0816 16:04:05.718760 20404 net.cpp:91] Creating Layer ReLU50
I0816 16:04:05.718770 20404 net.cpp:425] ReLU50 <- Convolution37
I0816 16:04:05.718781 20404 net.cpp:386] ReLU50 -> Convolution37 (in-place)
I0816 16:04:05.718806 20404 net.cpp:141] Setting up ReLU50
I0816 16:04:05.718816 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.718822 20404 net.cpp:156] Memory required for data: 1262288400
I0816 16:04:05.718830 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:05.718845 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:05.718854 20404 net.cpp:425] norm2 <- Convolution37
I0816 16:04:05.718869 20404 net.cpp:399] norm2 -> LRN16
I0816 16:04:05.718933 20404 net.cpp:141] Setting up norm2
I0816 16:04:05.718947 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.718955 20404 net.cpp:156] Memory required for data: 1268842000
I0816 16:04:05.718962 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:05.718976 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:05.718984 20404 net.cpp:425] pool2 <- LRN16
I0816 16:04:05.718997 20404 net.cpp:399] pool2 -> Pooling23
I0816 16:04:05.719063 20404 net.cpp:141] Setting up pool2
I0816 16:04:05.719077 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.719105 20404 net.cpp:156] Memory required for data: 1270480400
I0816 16:04:05.719113 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:05.719132 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:05.719141 20404 net.cpp:425] conv3 <- Pooling23
I0816 16:04:05.719157 20404 net.cpp:399] conv3 -> Convolution38
I0816 16:04:05.762943 20404 net.cpp:141] Setting up conv3
I0816 16:04:05.762974 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.762991 20404 net.cpp:156] Memory required for data: 1272938000
I0816 16:04:05.763007 20404 layer_factory.hpp:77] Creating layer ReLU51
I0816 16:04:05.763022 20404 net.cpp:91] Creating Layer ReLU51
I0816 16:04:05.763033 20404 net.cpp:425] ReLU51 <- Convolution38
I0816 16:04:05.763058 20404 net.cpp:386] ReLU51 -> Convolution38 (in-place)
I0816 16:04:05.763075 20404 net.cpp:141] Setting up ReLU51
I0816 16:04:05.763087 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.763093 20404 net.cpp:156] Memory required for data: 1275395600
I0816 16:04:05.763101 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:05.763121 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:05.763135 20404 net.cpp:425] conv4 <- Convolution38
I0816 16:04:05.763149 20404 net.cpp:399] conv4 -> Convolution39
I0816 16:04:05.796087 20404 net.cpp:141] Setting up conv4
I0816 16:04:05.796115 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.796134 20404 net.cpp:156] Memory required for data: 1277853200
I0816 16:04:05.796150 20404 layer_factory.hpp:77] Creating layer ReLU52
I0816 16:04:05.796167 20404 net.cpp:91] Creating Layer ReLU52
I0816 16:04:05.796178 20404 net.cpp:425] ReLU52 <- Convolution39
I0816 16:04:05.796200 20404 net.cpp:386] ReLU52 -> Convolution39 (in-place)
I0816 16:04:05.796216 20404 net.cpp:141] Setting up ReLU52
I0816 16:04:05.796226 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.796234 20404 net.cpp:156] Memory required for data: 1280310800
I0816 16:04:05.796241 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:05.796262 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:05.796269 20404 net.cpp:425] conv5 <- Convolution39
I0816 16:04:05.796286 20404 net.cpp:399] conv5 -> Convolution40
I0816 16:04:05.818473 20404 net.cpp:141] Setting up conv5
I0816 16:04:05.818497 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.818514 20404 net.cpp:156] Memory required for data: 1281949200
I0816 16:04:05.818531 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:05.818548 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:05.818558 20404 net.cpp:425] pool5 <- Convolution40
I0816 16:04:05.818579 20404 net.cpp:399] pool5 -> Pooling24
I0816 16:04:05.818655 20404 net.cpp:141] Setting up pool5
I0816 16:04:05.818670 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:05.818677 20404 net.cpp:156] Memory required for data: 1282358800
I0816 16:04:05.818684 20404 layer_factory.hpp:77] Creating layer InnerProduct21
I0816 16:04:05.818701 20404 net.cpp:91] Creating Layer InnerProduct21
I0816 16:04:05.818711 20404 net.cpp:425] InnerProduct21 <- Pooling24
I0816 16:04:05.818724 20404 net.cpp:399] InnerProduct21 -> InnerProduct21
I0816 16:04:05.821496 20404 net.cpp:141] Setting up InnerProduct21
I0816 16:04:05.821514 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.821522 20404 net.cpp:156] Memory required for data: 1282461200
I0816 16:04:05.821538 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:05.821548 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:05.821557 20404 layer_factory.hpp:77] Creating layer ReLU53
I0816 16:04:05.821568 20404 net.cpp:91] Creating Layer ReLU53
I0816 16:04:05.821576 20404 net.cpp:425] ReLU53 <- InnerProduct21
I0816 16:04:05.821600 20404 net.cpp:386] ReLU53 -> InnerProduct21 (in-place)
I0816 16:04:05.821615 20404 net.cpp:141] Setting up ReLU53
I0816 16:04:05.821625 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.821633 20404 net.cpp:156] Memory required for data: 1282563600
I0816 16:04:05.821657 20404 layer_factory.hpp:77] Creating layer InnerProduct22
I0816 16:04:05.821671 20404 net.cpp:91] Creating Layer InnerProduct22
I0816 16:04:05.821678 20404 net.cpp:425] InnerProduct22 <- InnerProduct21
I0816 16:04:05.821696 20404 net.cpp:399] InnerProduct22 -> InnerProduct22
I0816 16:04:05.822387 20404 net.cpp:141] Setting up InnerProduct22
I0816 16:04:05.822402 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.822409 20404 net.cpp:156] Memory required for data: 1282666000
I0816 16:04:05.822463 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:05.822477 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:05.822485 20404 layer_factory.hpp:77] Creating layer ReLU54
I0816 16:04:05.822496 20404 net.cpp:91] Creating Layer ReLU54
I0816 16:04:05.822504 20404 net.cpp:425] ReLU54 <- InnerProduct22
I0816 16:04:05.822520 20404 net.cpp:386] ReLU54 -> InnerProduct22 (in-place)
I0816 16:04:05.822532 20404 net.cpp:141] Setting up ReLU54
I0816 16:04:05.822543 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.822551 20404 net.cpp:156] Memory required for data: 1282768400
I0816 16:04:05.822557 20404 layer_factory.hpp:77] Creating layer Concat4
I0816 16:04:05.822568 20404 net.cpp:91] Creating Layer Concat4
I0816 16:04:05.822577 20404 net.cpp:425] Concat4 <- InnerProduct20
I0816 16:04:05.822587 20404 net.cpp:425] Concat4 <- InnerProduct22
I0816 16:04:05.822600 20404 net.cpp:399] Concat4 -> Concat4
I0816 16:04:05.822643 20404 net.cpp:141] Setting up Concat4
I0816 16:04:05.822657 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:05.822665 20404 net.cpp:156] Memory required for data: 1282973200
I0816 16:04:05.822672 20404 layer_factory.hpp:77] Creating layer InnerProduct23
I0816 16:04:05.822687 20404 net.cpp:91] Creating Layer InnerProduct23
I0816 16:04:05.822695 20404 net.cpp:425] InnerProduct23 <- Concat4
I0816 16:04:05.822708 20404 net.cpp:399] InnerProduct23 -> InnerProduct23
I0816 16:04:05.824491 20404 net.cpp:141] Setting up InnerProduct23
I0816 16:04:05.824512 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.824520 20404 net.cpp:156] Memory required for data: 1283075600
I0816 16:04:05.824529 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:05.824539 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:05.824548 20404 layer_factory.hpp:77] Creating layer ReLU55
I0816 16:04:05.824559 20404 net.cpp:91] Creating Layer ReLU55
I0816 16:04:05.824568 20404 net.cpp:425] ReLU55 <- InnerProduct23
I0816 16:04:05.824580 20404 net.cpp:386] ReLU55 -> InnerProduct23 (in-place)
I0816 16:04:05.824594 20404 net.cpp:141] Setting up ReLU55
I0816 16:04:05.824604 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.824611 20404 net.cpp:156] Memory required for data: 1283178000
I0816 16:04:05.824620 20404 layer_factory.hpp:77] Creating layer InnerProduct24
I0816 16:04:05.824635 20404 net.cpp:91] Creating Layer InnerProduct24
I0816 16:04:05.824643 20404 net.cpp:425] InnerProduct24 <- InnerProduct23
I0816 16:04:05.824656 20404 net.cpp:399] InnerProduct24 -> InnerProduct24
I0816 16:04:05.825076 20404 net.cpp:141] Setting up InnerProduct24
I0816 16:04:05.825091 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:05.825098 20404 net.cpp:156] Memory required for data: 1283229200
I0816 16:04:05.825108 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:05.825116 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:05.825124 20404 layer_factory.hpp:77] Creating layer ReLU56
I0816 16:04:05.825134 20404 net.cpp:91] Creating Layer ReLU56
I0816 16:04:05.825142 20404 net.cpp:425] ReLU56 <- InnerProduct24
I0816 16:04:05.825153 20404 net.cpp:386] ReLU56 -> InnerProduct24 (in-place)
I0816 16:04:05.825165 20404 net.cpp:141] Setting up ReLU56
I0816 16:04:05.825191 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:05.825197 20404 net.cpp:156] Memory required for data: 1283280400
I0816 16:04:05.825206 20404 layer_factory.hpp:77] Creating layer dt3
I0816 16:04:05.825217 20404 net.cpp:91] Creating Layer dt3
I0816 16:04:05.825225 20404 net.cpp:425] dt3 <- InnerProduct24
I0816 16:04:05.825242 20404 net.cpp:399] dt3 -> dt3
I0816 16:04:05.825407 20404 net.cpp:141] Setting up dt3
I0816 16:04:05.825422 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:05.825429 20404 net.cpp:156] Memory required for data: 1283280800
I0816 16:04:05.825438 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:05.825446 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:05.825454 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:05.825475 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:05.825486 20404 net.cpp:425] conv1 <- p1_p1_0_split_4
I0816 16:04:05.825500 20404 net.cpp:399] conv1 -> Convolution41
I0816 16:04:05.827617 20404 net.cpp:141] Setting up conv1
I0816 16:04:05.827632 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.827641 20404 net.cpp:156] Memory required for data: 1293111200
I0816 16:04:05.827653 20404 layer_factory.hpp:77] Creating layer ReLU57
I0816 16:04:05.827667 20404 net.cpp:91] Creating Layer ReLU57
I0816 16:04:05.827675 20404 net.cpp:425] ReLU57 <- Convolution41
I0816 16:04:05.827687 20404 net.cpp:386] ReLU57 -> Convolution41 (in-place)
I0816 16:04:05.827699 20404 net.cpp:141] Setting up ReLU57
I0816 16:04:05.827709 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.827718 20404 net.cpp:156] Memory required for data: 1302941600
I0816 16:04:05.827724 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:05.827735 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:05.827744 20404 net.cpp:425] norm1 <- Convolution41
I0816 16:04:05.827759 20404 net.cpp:399] norm1 -> LRN17
I0816 16:04:05.827816 20404 net.cpp:141] Setting up norm1
I0816 16:04:05.827829 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.827837 20404 net.cpp:156] Memory required for data: 1312772000
I0816 16:04:05.827844 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:05.827858 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:05.827867 20404 net.cpp:425] pool1 <- LRN17
I0816 16:04:05.827878 20404 net.cpp:399] pool1 -> Pooling25
I0816 16:04:05.827945 20404 net.cpp:141] Setting up pool1
I0816 16:04:05.827960 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:05.827966 20404 net.cpp:156] Memory required for data: 1315229600
I0816 16:04:05.827973 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:05.827991 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:05.827999 20404 net.cpp:425] conv2 <- Pooling25
I0816 16:04:05.828016 20404 net.cpp:399] conv2 -> Convolution42
I0816 16:04:05.843495 20404 net.cpp:141] Setting up conv2
I0816 16:04:05.843518 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.843526 20404 net.cpp:156] Memory required for data: 1321783200
I0816 16:04:05.843551 20404 layer_factory.hpp:77] Creating layer ReLU58
I0816 16:04:05.843564 20404 net.cpp:91] Creating Layer ReLU58
I0816 16:04:05.843574 20404 net.cpp:425] ReLU58 <- Convolution42
I0816 16:04:05.843587 20404 net.cpp:386] ReLU58 -> Convolution42 (in-place)
I0816 16:04:05.843602 20404 net.cpp:141] Setting up ReLU58
I0816 16:04:05.843618 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.843626 20404 net.cpp:156] Memory required for data: 1328336800
I0816 16:04:05.843632 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:05.843647 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:05.843655 20404 net.cpp:425] norm2 <- Convolution42
I0816 16:04:05.843667 20404 net.cpp:399] norm2 -> LRN18
I0816 16:04:05.843737 20404 net.cpp:141] Setting up norm2
I0816 16:04:05.843752 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.843760 20404 net.cpp:156] Memory required for data: 1334890400
I0816 16:04:05.843783 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:05.843796 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:05.843803 20404 net.cpp:425] pool2 <- LRN18
I0816 16:04:05.843814 20404 net.cpp:399] pool2 -> Pooling26
I0816 16:04:05.843883 20404 net.cpp:141] Setting up pool2
I0816 16:04:05.843897 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.843904 20404 net.cpp:156] Memory required for data: 1336528800
I0816 16:04:05.843912 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:05.843930 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:05.843945 20404 net.cpp:425] conv3 <- Pooling26
I0816 16:04:05.843958 20404 net.cpp:399] conv3 -> Convolution43
I0816 16:04:05.887709 20404 net.cpp:141] Setting up conv3
I0816 16:04:05.887739 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.887748 20404 net.cpp:156] Memory required for data: 1338986400
I0816 16:04:05.887764 20404 layer_factory.hpp:77] Creating layer ReLU59
I0816 16:04:05.887779 20404 net.cpp:91] Creating Layer ReLU59
I0816 16:04:05.887790 20404 net.cpp:425] ReLU59 <- Convolution43
I0816 16:04:05.887802 20404 net.cpp:386] ReLU59 -> Convolution43 (in-place)
I0816 16:04:05.887819 20404 net.cpp:141] Setting up ReLU59
I0816 16:04:05.887830 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.887836 20404 net.cpp:156] Memory required for data: 1341444000
I0816 16:04:05.887845 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:05.887864 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:05.887872 20404 net.cpp:425] conv4 <- Convolution43
I0816 16:04:05.887892 20404 net.cpp:399] conv4 -> Convolution44
I0816 16:04:05.921012 20404 net.cpp:141] Setting up conv4
I0816 16:04:05.921042 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.921051 20404 net.cpp:156] Memory required for data: 1343901600
I0816 16:04:05.921066 20404 layer_factory.hpp:77] Creating layer ReLU60
I0816 16:04:05.921080 20404 net.cpp:91] Creating Layer ReLU60
I0816 16:04:05.921092 20404 net.cpp:425] ReLU60 <- Convolution44
I0816 16:04:05.921108 20404 net.cpp:386] ReLU60 -> Convolution44 (in-place)
I0816 16:04:05.921123 20404 net.cpp:141] Setting up ReLU60
I0816 16:04:05.921133 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:05.921140 20404 net.cpp:156] Memory required for data: 1346359200
I0816 16:04:05.921149 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:05.921169 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:05.921178 20404 net.cpp:425] conv5 <- Convolution44
I0816 16:04:05.921191 20404 net.cpp:399] conv5 -> Convolution45
I0816 16:04:05.943375 20404 net.cpp:141] Setting up conv5
I0816 16:04:05.943404 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.943423 20404 net.cpp:156] Memory required for data: 1347997600
I0816 16:04:05.943439 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:05.943454 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:05.943464 20404 net.cpp:425] pool5 <- Convolution45
I0816 16:04:05.943490 20404 net.cpp:399] pool5 -> Pooling27
I0816 16:04:05.943563 20404 net.cpp:141] Setting up pool5
I0816 16:04:05.943580 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:05.943588 20404 net.cpp:156] Memory required for data: 1348407200
I0816 16:04:05.943595 20404 layer_factory.hpp:77] Creating layer InnerProduct25
I0816 16:04:05.943610 20404 net.cpp:91] Creating Layer InnerProduct25
I0816 16:04:05.943619 20404 net.cpp:425] InnerProduct25 <- Pooling27
I0816 16:04:05.943635 20404 net.cpp:399] InnerProduct25 -> InnerProduct25
I0816 16:04:05.946429 20404 net.cpp:141] Setting up InnerProduct25
I0816 16:04:05.946449 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.946456 20404 net.cpp:156] Memory required for data: 1348509600
I0816 16:04:05.946466 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:05.946477 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:05.946485 20404 layer_factory.hpp:77] Creating layer ReLU61
I0816 16:04:05.946521 20404 net.cpp:91] Creating Layer ReLU61
I0816 16:04:05.946530 20404 net.cpp:425] ReLU61 <- InnerProduct25
I0816 16:04:05.946542 20404 net.cpp:386] ReLU61 -> InnerProduct25 (in-place)
I0816 16:04:05.946557 20404 net.cpp:141] Setting up ReLU61
I0816 16:04:05.946568 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.946575 20404 net.cpp:156] Memory required for data: 1348612000
I0816 16:04:05.946583 20404 layer_factory.hpp:77] Creating layer InnerProduct26
I0816 16:04:05.946599 20404 net.cpp:91] Creating Layer InnerProduct26
I0816 16:04:05.946606 20404 net.cpp:425] InnerProduct26 <- InnerProduct25
I0816 16:04:05.946619 20404 net.cpp:399] InnerProduct26 -> InnerProduct26
I0816 16:04:05.947334 20404 net.cpp:141] Setting up InnerProduct26
I0816 16:04:05.947348 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.947361 20404 net.cpp:156] Memory required for data: 1348714400
I0816 16:04:05.947371 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:05.947379 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:05.947387 20404 layer_factory.hpp:77] Creating layer ReLU62
I0816 16:04:05.947398 20404 net.cpp:91] Creating Layer ReLU62
I0816 16:04:05.947407 20404 net.cpp:425] ReLU62 <- InnerProduct26
I0816 16:04:05.947422 20404 net.cpp:386] ReLU62 -> InnerProduct26 (in-place)
I0816 16:04:05.947434 20404 net.cpp:141] Setting up ReLU62
I0816 16:04:05.947444 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:05.947453 20404 net.cpp:156] Memory required for data: 1348816800
I0816 16:04:05.947459 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:05.947477 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:05.947486 20404 net.cpp:425] conv1 <- c24
I0816 16:04:05.947501 20404 net.cpp:399] conv1 -> Convolution46
I0816 16:04:05.949548 20404 net.cpp:141] Setting up conv1
I0816 16:04:05.949563 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.949569 20404 net.cpp:156] Memory required for data: 1358647200
I0816 16:04:05.949584 20404 layer_factory.hpp:77] Creating layer ReLU63
I0816 16:04:05.949607 20404 net.cpp:91] Creating Layer ReLU63
I0816 16:04:05.949615 20404 net.cpp:425] ReLU63 <- Convolution46
I0816 16:04:05.949625 20404 net.cpp:386] ReLU63 -> Convolution46 (in-place)
I0816 16:04:05.949638 20404 net.cpp:141] Setting up ReLU63
I0816 16:04:05.949647 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.949663 20404 net.cpp:156] Memory required for data: 1368477600
I0816 16:04:05.949671 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:05.949682 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:05.949690 20404 net.cpp:425] norm1 <- Convolution46
I0816 16:04:05.949707 20404 net.cpp:399] norm1 -> LRN19
I0816 16:04:05.949764 20404 net.cpp:141] Setting up norm1
I0816 16:04:05.949779 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:05.949785 20404 net.cpp:156] Memory required for data: 1378308000
I0816 16:04:05.949792 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:05.949806 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:05.949815 20404 net.cpp:425] pool1 <- LRN19
I0816 16:04:05.949826 20404 net.cpp:399] pool1 -> Pooling28
I0816 16:04:05.949892 20404 net.cpp:141] Setting up pool1
I0816 16:04:05.949906 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:05.949914 20404 net.cpp:156] Memory required for data: 1380765600
I0816 16:04:05.949921 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:05.949939 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:05.949946 20404 net.cpp:425] conv2 <- Pooling28
I0816 16:04:05.949962 20404 net.cpp:399] conv2 -> Convolution47
I0816 16:04:05.965564 20404 net.cpp:141] Setting up conv2
I0816 16:04:05.965589 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.965607 20404 net.cpp:156] Memory required for data: 1387319200
I0816 16:04:05.965621 20404 layer_factory.hpp:77] Creating layer ReLU64
I0816 16:04:05.965634 20404 net.cpp:91] Creating Layer ReLU64
I0816 16:04:05.965661 20404 net.cpp:425] ReLU64 <- Convolution47
I0816 16:04:05.965685 20404 net.cpp:386] ReLU64 -> Convolution47 (in-place)
I0816 16:04:05.965701 20404 net.cpp:141] Setting up ReLU64
I0816 16:04:05.965713 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.965719 20404 net.cpp:156] Memory required for data: 1393872800
I0816 16:04:05.965728 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:05.965741 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:05.965750 20404 net.cpp:425] norm2 <- Convolution47
I0816 16:04:05.965764 20404 net.cpp:399] norm2 -> LRN20
I0816 16:04:05.965833 20404 net.cpp:141] Setting up norm2
I0816 16:04:05.965847 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:05.965855 20404 net.cpp:156] Memory required for data: 1400426400
I0816 16:04:05.965863 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:05.965874 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:05.965883 20404 net.cpp:425] pool2 <- LRN20
I0816 16:04:05.965898 20404 net.cpp:399] pool2 -> Pooling29
I0816 16:04:05.965963 20404 net.cpp:141] Setting up pool2
I0816 16:04:05.965977 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:05.965984 20404 net.cpp:156] Memory required for data: 1402064800
I0816 16:04:05.965992 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:05.966017 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:05.966025 20404 net.cpp:425] conv3 <- Pooling29
I0816 16:04:05.966038 20404 net.cpp:399] conv3 -> Convolution48
I0816 16:04:06.009888 20404 net.cpp:141] Setting up conv3
I0816 16:04:06.009918 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.009938 20404 net.cpp:156] Memory required for data: 1404522400
I0816 16:04:06.009953 20404 layer_factory.hpp:77] Creating layer ReLU65
I0816 16:04:06.009968 20404 net.cpp:91] Creating Layer ReLU65
I0816 16:04:06.009979 20404 net.cpp:425] ReLU65 <- Convolution48
I0816 16:04:06.010001 20404 net.cpp:386] ReLU65 -> Convolution48 (in-place)
I0816 16:04:06.010016 20404 net.cpp:141] Setting up ReLU65
I0816 16:04:06.010027 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.010035 20404 net.cpp:156] Memory required for data: 1406980000
I0816 16:04:06.010042 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:06.010063 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:06.010072 20404 net.cpp:425] conv4 <- Convolution48
I0816 16:04:06.010088 20404 net.cpp:399] conv4 -> Convolution49
I0816 16:04:06.043074 20404 net.cpp:141] Setting up conv4
I0816 16:04:06.043104 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.043123 20404 net.cpp:156] Memory required for data: 1409437600
I0816 16:04:06.043139 20404 layer_factory.hpp:77] Creating layer ReLU66
I0816 16:04:06.043153 20404 net.cpp:91] Creating Layer ReLU66
I0816 16:04:06.043162 20404 net.cpp:425] ReLU66 <- Convolution49
I0816 16:04:06.043180 20404 net.cpp:386] ReLU66 -> Convolution49 (in-place)
I0816 16:04:06.043205 20404 net.cpp:141] Setting up ReLU66
I0816 16:04:06.043215 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.043222 20404 net.cpp:156] Memory required for data: 1411895200
I0816 16:04:06.043231 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:06.043251 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:06.043259 20404 net.cpp:425] conv5 <- Convolution49
I0816 16:04:06.043284 20404 net.cpp:399] conv5 -> Convolution50
I0816 16:04:06.065471 20404 net.cpp:141] Setting up conv5
I0816 16:04:06.065500 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.065518 20404 net.cpp:156] Memory required for data: 1413533600
I0816 16:04:06.065534 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:06.065548 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:06.065558 20404 net.cpp:425] pool5 <- Convolution50
I0816 16:04:06.065585 20404 net.cpp:399] pool5 -> Pooling30
I0816 16:04:06.065659 20404 net.cpp:141] Setting up pool5
I0816 16:04:06.065677 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:06.065685 20404 net.cpp:156] Memory required for data: 1413943200
I0816 16:04:06.065712 20404 layer_factory.hpp:77] Creating layer InnerProduct27
I0816 16:04:06.065726 20404 net.cpp:91] Creating Layer InnerProduct27
I0816 16:04:06.065734 20404 net.cpp:425] InnerProduct27 <- Pooling30
I0816 16:04:06.065752 20404 net.cpp:399] InnerProduct27 -> InnerProduct27
I0816 16:04:06.068536 20404 net.cpp:141] Setting up InnerProduct27
I0816 16:04:06.068557 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.068574 20404 net.cpp:156] Memory required for data: 1414045600
I0816 16:04:06.068585 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:06.068595 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:06.068603 20404 layer_factory.hpp:77] Creating layer ReLU67
I0816 16:04:06.068619 20404 net.cpp:91] Creating Layer ReLU67
I0816 16:04:06.068629 20404 net.cpp:425] ReLU67 <- InnerProduct27
I0816 16:04:06.068645 20404 net.cpp:386] ReLU67 -> InnerProduct27 (in-place)
I0816 16:04:06.068660 20404 net.cpp:141] Setting up ReLU67
I0816 16:04:06.068670 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.068676 20404 net.cpp:156] Memory required for data: 1414148000
I0816 16:04:06.068684 20404 layer_factory.hpp:77] Creating layer InnerProduct28
I0816 16:04:06.068701 20404 net.cpp:91] Creating Layer InnerProduct28
I0816 16:04:06.068709 20404 net.cpp:425] InnerProduct28 <- InnerProduct27
I0816 16:04:06.068722 20404 net.cpp:399] InnerProduct28 -> InnerProduct28
I0816 16:04:06.069417 20404 net.cpp:141] Setting up InnerProduct28
I0816 16:04:06.069432 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.069439 20404 net.cpp:156] Memory required for data: 1414250400
I0816 16:04:06.069447 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:06.069458 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:06.069465 20404 layer_factory.hpp:77] Creating layer ReLU68
I0816 16:04:06.069475 20404 net.cpp:91] Creating Layer ReLU68
I0816 16:04:06.069483 20404 net.cpp:425] ReLU68 <- InnerProduct28
I0816 16:04:06.069494 20404 net.cpp:386] ReLU68 -> InnerProduct28 (in-place)
I0816 16:04:06.069506 20404 net.cpp:141] Setting up ReLU68
I0816 16:04:06.069516 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.069525 20404 net.cpp:156] Memory required for data: 1414352800
I0816 16:04:06.069531 20404 layer_factory.hpp:77] Creating layer Concat5
I0816 16:04:06.069545 20404 net.cpp:91] Creating Layer Concat5
I0816 16:04:06.069555 20404 net.cpp:425] Concat5 <- InnerProduct26
I0816 16:04:06.069566 20404 net.cpp:425] Concat5 <- InnerProduct28
I0816 16:04:06.069577 20404 net.cpp:399] Concat5 -> Concat5
I0816 16:04:06.069618 20404 net.cpp:141] Setting up Concat5
I0816 16:04:06.069633 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:06.069639 20404 net.cpp:156] Memory required for data: 1414557600
I0816 16:04:06.069648 20404 layer_factory.hpp:77] Creating layer InnerProduct29
I0816 16:04:06.069659 20404 net.cpp:91] Creating Layer InnerProduct29
I0816 16:04:06.069667 20404 net.cpp:425] InnerProduct29 <- Concat5
I0816 16:04:06.069682 20404 net.cpp:399] InnerProduct29 -> InnerProduct29
I0816 16:04:06.070884 20404 net.cpp:141] Setting up InnerProduct29
I0816 16:04:06.070900 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.070907 20404 net.cpp:156] Memory required for data: 1414660000
I0816 16:04:06.070916 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:06.070925 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:06.070933 20404 layer_factory.hpp:77] Creating layer ReLU69
I0816 16:04:06.070945 20404 net.cpp:91] Creating Layer ReLU69
I0816 16:04:06.070953 20404 net.cpp:425] ReLU69 <- InnerProduct29
I0816 16:04:06.070968 20404 net.cpp:386] ReLU69 -> InnerProduct29 (in-place)
I0816 16:04:06.070982 20404 net.cpp:141] Setting up ReLU69
I0816 16:04:06.070993 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.071019 20404 net.cpp:156] Memory required for data: 1414762400
I0816 16:04:06.071027 20404 layer_factory.hpp:77] Creating layer InnerProduct30
I0816 16:04:06.071039 20404 net.cpp:91] Creating Layer InnerProduct30
I0816 16:04:06.071048 20404 net.cpp:425] InnerProduct30 <- InnerProduct29
I0816 16:04:06.071064 20404 net.cpp:399] InnerProduct30 -> InnerProduct30
I0816 16:04:06.071516 20404 net.cpp:141] Setting up InnerProduct30
I0816 16:04:06.071532 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:06.071539 20404 net.cpp:156] Memory required for data: 1414813600
I0816 16:04:06.071548 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:06.071558 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:06.071566 20404 layer_factory.hpp:77] Creating layer ReLU70
I0816 16:04:06.071576 20404 net.cpp:91] Creating Layer ReLU70
I0816 16:04:06.071584 20404 net.cpp:425] ReLU70 <- InnerProduct30
I0816 16:04:06.071595 20404 net.cpp:386] ReLU70 -> InnerProduct30 (in-place)
I0816 16:04:06.071607 20404 net.cpp:141] Setting up ReLU70
I0816 16:04:06.071617 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:06.071625 20404 net.cpp:156] Memory required for data: 1414864800
I0816 16:04:06.071632 20404 layer_factory.hpp:77] Creating layer dt4
I0816 16:04:06.071722 20404 net.cpp:91] Creating Layer dt4
I0816 16:04:06.071734 20404 net.cpp:425] dt4 <- InnerProduct30
I0816 16:04:06.071748 20404 net.cpp:399] dt4 -> dt4
I0816 16:04:06.071933 20404 net.cpp:141] Setting up dt4
I0816 16:04:06.071949 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:06.071956 20404 net.cpp:156] Memory required for data: 1414865200
I0816 16:04:06.071964 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:06.071972 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:06.071980 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:06.072000 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:06.072010 20404 net.cpp:425] conv1 <- p1_p1_0_split_5
I0816 16:04:06.072027 20404 net.cpp:399] conv1 -> Convolution51
I0816 16:04:06.074200 20404 net.cpp:141] Setting up conv1
I0816 16:04:06.074213 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.074218 20404 net.cpp:156] Memory required for data: 1424695600
I0816 16:04:06.074229 20404 layer_factory.hpp:77] Creating layer ReLU71
I0816 16:04:06.074237 20404 net.cpp:91] Creating Layer ReLU71
I0816 16:04:06.074244 20404 net.cpp:425] ReLU71 <- Convolution51
I0816 16:04:06.074254 20404 net.cpp:386] ReLU71 -> Convolution51 (in-place)
I0816 16:04:06.074264 20404 net.cpp:141] Setting up ReLU71
I0816 16:04:06.074271 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.074276 20404 net.cpp:156] Memory required for data: 1434526000
I0816 16:04:06.074282 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:06.074293 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:06.074300 20404 net.cpp:425] norm1 <- Convolution51
I0816 16:04:06.074311 20404 net.cpp:399] norm1 -> LRN21
I0816 16:04:06.074379 20404 net.cpp:141] Setting up norm1
I0816 16:04:06.074398 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.074406 20404 net.cpp:156] Memory required for data: 1444356400
I0816 16:04:06.074414 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:06.074426 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:06.074465 20404 net.cpp:425] pool1 <- LRN21
I0816 16:04:06.074486 20404 net.cpp:399] pool1 -> Pooling31
I0816 16:04:06.074555 20404 net.cpp:141] Setting up pool1
I0816 16:04:06.074569 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:06.074578 20404 net.cpp:156] Memory required for data: 1446814000
I0816 16:04:06.074584 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:06.074605 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:06.074615 20404 net.cpp:425] conv2 <- Pooling31
I0816 16:04:06.074628 20404 net.cpp:399] conv2 -> Convolution52
I0816 16:04:06.090389 20404 net.cpp:141] Setting up conv2
I0816 16:04:06.090415 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.090422 20404 net.cpp:156] Memory required for data: 1453367600
I0816 16:04:06.090443 20404 layer_factory.hpp:77] Creating layer ReLU72
I0816 16:04:06.090456 20404 net.cpp:91] Creating Layer ReLU72
I0816 16:04:06.090466 20404 net.cpp:425] ReLU72 <- Convolution52
I0816 16:04:06.090478 20404 net.cpp:386] ReLU72 -> Convolution52 (in-place)
I0816 16:04:06.090493 20404 net.cpp:141] Setting up ReLU72
I0816 16:04:06.090503 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.090510 20404 net.cpp:156] Memory required for data: 1459921200
I0816 16:04:06.090518 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:06.090533 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:06.090543 20404 net.cpp:425] norm2 <- Convolution52
I0816 16:04:06.090558 20404 net.cpp:399] norm2 -> LRN22
I0816 16:04:06.090623 20404 net.cpp:141] Setting up norm2
I0816 16:04:06.090637 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.090646 20404 net.cpp:156] Memory required for data: 1466474800
I0816 16:04:06.090652 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:06.090667 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:06.090675 20404 net.cpp:425] pool2 <- LRN22
I0816 16:04:06.090687 20404 net.cpp:399] pool2 -> Pooling32
I0816 16:04:06.090755 20404 net.cpp:141] Setting up pool2
I0816 16:04:06.090770 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.090776 20404 net.cpp:156] Memory required for data: 1468113200
I0816 16:04:06.090783 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:06.090802 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:06.090811 20404 net.cpp:425] conv3 <- Pooling32
I0816 16:04:06.090827 20404 net.cpp:399] conv3 -> Convolution53
I0816 16:04:06.134565 20404 net.cpp:141] Setting up conv3
I0816 16:04:06.134595 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.134603 20404 net.cpp:156] Memory required for data: 1470570800
I0816 16:04:06.134620 20404 layer_factory.hpp:77] Creating layer ReLU73
I0816 16:04:06.134639 20404 net.cpp:91] Creating Layer ReLU73
I0816 16:04:06.134649 20404 net.cpp:425] ReLU73 <- Convolution53
I0816 16:04:06.134665 20404 net.cpp:386] ReLU73 -> Convolution53 (in-place)
I0816 16:04:06.134680 20404 net.cpp:141] Setting up ReLU73
I0816 16:04:06.134690 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.134697 20404 net.cpp:156] Memory required for data: 1473028400
I0816 16:04:06.134706 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:06.134727 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:06.134734 20404 net.cpp:425] conv4 <- Convolution53
I0816 16:04:06.134748 20404 net.cpp:399] conv4 -> Convolution54
I0816 16:04:06.167872 20404 net.cpp:141] Setting up conv4
I0816 16:04:06.167906 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.167917 20404 net.cpp:156] Memory required for data: 1475486000
I0816 16:04:06.167932 20404 layer_factory.hpp:77] Creating layer ReLU74
I0816 16:04:06.167950 20404 net.cpp:91] Creating Layer ReLU74
I0816 16:04:06.167963 20404 net.cpp:425] ReLU74 <- Convolution54
I0816 16:04:06.167978 20404 net.cpp:386] ReLU74 -> Convolution54 (in-place)
I0816 16:04:06.167992 20404 net.cpp:141] Setting up ReLU74
I0816 16:04:06.168004 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.168011 20404 net.cpp:156] Memory required for data: 1477943600
I0816 16:04:06.168018 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:06.168037 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:06.168045 20404 net.cpp:425] conv5 <- Convolution54
I0816 16:04:06.168062 20404 net.cpp:399] conv5 -> Convolution55
I0816 16:04:06.190263 20404 net.cpp:141] Setting up conv5
I0816 16:04:06.190290 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.190309 20404 net.cpp:156] Memory required for data: 1479582000
I0816 16:04:06.190325 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:06.190345 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:06.190382 20404 net.cpp:425] pool5 <- Convolution55
I0816 16:04:06.190398 20404 net.cpp:399] pool5 -> Pooling33
I0816 16:04:06.190476 20404 net.cpp:141] Setting up pool5
I0816 16:04:06.190491 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:06.190500 20404 net.cpp:156] Memory required for data: 1479991600
I0816 16:04:06.190506 20404 layer_factory.hpp:77] Creating layer InnerProduct31
I0816 16:04:06.190524 20404 net.cpp:91] Creating Layer InnerProduct31
I0816 16:04:06.190532 20404 net.cpp:425] InnerProduct31 <- Pooling33
I0816 16:04:06.190547 20404 net.cpp:399] InnerProduct31 -> InnerProduct31
I0816 16:04:06.193351 20404 net.cpp:141] Setting up InnerProduct31
I0816 16:04:06.193372 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.193389 20404 net.cpp:156] Memory required for data: 1480094000
I0816 16:04:06.193399 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:06.193409 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:06.193418 20404 layer_factory.hpp:77] Creating layer ReLU75
I0816 16:04:06.193430 20404 net.cpp:91] Creating Layer ReLU75
I0816 16:04:06.193439 20404 net.cpp:425] ReLU75 <- InnerProduct31
I0816 16:04:06.193454 20404 net.cpp:386] ReLU75 -> InnerProduct31 (in-place)
I0816 16:04:06.193469 20404 net.cpp:141] Setting up ReLU75
I0816 16:04:06.193478 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.193486 20404 net.cpp:156] Memory required for data: 1480196400
I0816 16:04:06.193495 20404 layer_factory.hpp:77] Creating layer InnerProduct32
I0816 16:04:06.193506 20404 net.cpp:91] Creating Layer InnerProduct32
I0816 16:04:06.193514 20404 net.cpp:425] InnerProduct32 <- InnerProduct31
I0816 16:04:06.193529 20404 net.cpp:399] InnerProduct32 -> InnerProduct32
I0816 16:04:06.194236 20404 net.cpp:141] Setting up InnerProduct32
I0816 16:04:06.194250 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.194263 20404 net.cpp:156] Memory required for data: 1480298800
I0816 16:04:06.194272 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:06.194280 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:06.194289 20404 layer_factory.hpp:77] Creating layer ReLU76
I0816 16:04:06.194298 20404 net.cpp:91] Creating Layer ReLU76
I0816 16:04:06.194306 20404 net.cpp:425] ReLU76 <- InnerProduct32
I0816 16:04:06.194319 20404 net.cpp:386] ReLU76 -> InnerProduct32 (in-place)
I0816 16:04:06.194336 20404 net.cpp:141] Setting up ReLU76
I0816 16:04:06.194345 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.194353 20404 net.cpp:156] Memory required for data: 1480401200
I0816 16:04:06.194360 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:06.194381 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:06.194391 20404 net.cpp:425] conv1 <- c25
I0816 16:04:06.194406 20404 net.cpp:399] conv1 -> Convolution56
I0816 16:04:06.196530 20404 net.cpp:141] Setting up conv1
I0816 16:04:06.196547 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.196554 20404 net.cpp:156] Memory required for data: 1490231600
I0816 16:04:06.196568 20404 layer_factory.hpp:77] Creating layer ReLU77
I0816 16:04:06.196583 20404 net.cpp:91] Creating Layer ReLU77
I0816 16:04:06.196591 20404 net.cpp:425] ReLU77 <- Convolution56
I0816 16:04:06.196602 20404 net.cpp:386] ReLU77 -> Convolution56 (in-place)
I0816 16:04:06.196616 20404 net.cpp:141] Setting up ReLU77
I0816 16:04:06.196626 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.196633 20404 net.cpp:156] Memory required for data: 1500062000
I0816 16:04:06.196641 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:06.196655 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:06.196663 20404 net.cpp:425] norm1 <- Convolution56
I0816 16:04:06.196676 20404 net.cpp:399] norm1 -> LRN23
I0816 16:04:06.196743 20404 net.cpp:141] Setting up norm1
I0816 16:04:06.196756 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.196782 20404 net.cpp:156] Memory required for data: 1509892400
I0816 16:04:06.196790 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:06.196800 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:06.196810 20404 net.cpp:425] pool1 <- LRN23
I0816 16:04:06.196823 20404 net.cpp:399] pool1 -> Pooling34
I0816 16:04:06.196890 20404 net.cpp:141] Setting up pool1
I0816 16:04:06.196904 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:06.196913 20404 net.cpp:156] Memory required for data: 1512350000
I0816 16:04:06.196919 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:06.196939 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:06.196949 20404 net.cpp:425] conv2 <- Pooling34
I0816 16:04:06.196961 20404 net.cpp:399] conv2 -> Convolution57
I0816 16:04:06.212662 20404 net.cpp:141] Setting up conv2
I0816 16:04:06.212687 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.212705 20404 net.cpp:156] Memory required for data: 1518903600
I0816 16:04:06.212721 20404 layer_factory.hpp:77] Creating layer ReLU78
I0816 16:04:06.212735 20404 net.cpp:91] Creating Layer ReLU78
I0816 16:04:06.212745 20404 net.cpp:425] ReLU78 <- Convolution57
I0816 16:04:06.212757 20404 net.cpp:386] ReLU78 -> Convolution57 (in-place)
I0816 16:04:06.212780 20404 net.cpp:141] Setting up ReLU78
I0816 16:04:06.212791 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.212800 20404 net.cpp:156] Memory required for data: 1525457200
I0816 16:04:06.212806 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:06.212821 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:06.212831 20404 net.cpp:425] norm2 <- Convolution57
I0816 16:04:06.212843 20404 net.cpp:399] norm2 -> LRN24
I0816 16:04:06.212913 20404 net.cpp:141] Setting up norm2
I0816 16:04:06.212927 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.212934 20404 net.cpp:156] Memory required for data: 1532010800
I0816 16:04:06.212941 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:06.212956 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:06.212965 20404 net.cpp:425] pool2 <- LRN24
I0816 16:04:06.212977 20404 net.cpp:399] pool2 -> Pooling35
I0816 16:04:06.213047 20404 net.cpp:141] Setting up pool2
I0816 16:04:06.213060 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.213068 20404 net.cpp:156] Memory required for data: 1533649200
I0816 16:04:06.213074 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:06.213095 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:06.213104 20404 net.cpp:425] conv3 <- Pooling35
I0816 16:04:06.213121 20404 net.cpp:399] conv3 -> Convolution58
I0816 16:04:06.257406 20404 net.cpp:141] Setting up conv3
I0816 16:04:06.257441 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.257460 20404 net.cpp:156] Memory required for data: 1536106800
I0816 16:04:06.257478 20404 layer_factory.hpp:77] Creating layer ReLU79
I0816 16:04:06.257493 20404 net.cpp:91] Creating Layer ReLU79
I0816 16:04:06.257505 20404 net.cpp:425] ReLU79 <- Convolution58
I0816 16:04:06.257532 20404 net.cpp:386] ReLU79 -> Convolution58 (in-place)
I0816 16:04:06.257550 20404 net.cpp:141] Setting up ReLU79
I0816 16:04:06.257566 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.257575 20404 net.cpp:156] Memory required for data: 1538564400
I0816 16:04:06.257581 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:06.257602 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:06.257616 20404 net.cpp:425] conv4 <- Convolution58
I0816 16:04:06.257628 20404 net.cpp:399] conv4 -> Convolution59
I0816 16:04:06.290899 20404 net.cpp:141] Setting up conv4
I0816 16:04:06.290928 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.290937 20404 net.cpp:156] Memory required for data: 1541022000
I0816 16:04:06.290953 20404 layer_factory.hpp:77] Creating layer ReLU80
I0816 16:04:06.290977 20404 net.cpp:91] Creating Layer ReLU80
I0816 16:04:06.290989 20404 net.cpp:425] ReLU80 <- Convolution59
I0816 16:04:06.291002 20404 net.cpp:386] ReLU80 -> Convolution59 (in-place)
I0816 16:04:06.291039 20404 net.cpp:141] Setting up ReLU80
I0816 16:04:06.291054 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.291061 20404 net.cpp:156] Memory required for data: 1543479600
I0816 16:04:06.291069 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:06.291090 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:06.291098 20404 net.cpp:425] conv5 <- Convolution59
I0816 16:04:06.291115 20404 net.cpp:399] conv5 -> Convolution60
I0816 16:04:06.313338 20404 net.cpp:141] Setting up conv5
I0816 16:04:06.313361 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.313380 20404 net.cpp:156] Memory required for data: 1545118000
I0816 16:04:06.313400 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:06.313418 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:06.313428 20404 net.cpp:425] pool5 <- Convolution60
I0816 16:04:06.313451 20404 net.cpp:399] pool5 -> Pooling36
I0816 16:04:06.313539 20404 net.cpp:141] Setting up pool5
I0816 16:04:06.313552 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:06.313560 20404 net.cpp:156] Memory required for data: 1545527600
I0816 16:04:06.313568 20404 layer_factory.hpp:77] Creating layer InnerProduct33
I0816 16:04:06.313585 20404 net.cpp:91] Creating Layer InnerProduct33
I0816 16:04:06.313593 20404 net.cpp:425] InnerProduct33 <- Pooling36
I0816 16:04:06.313611 20404 net.cpp:399] InnerProduct33 -> InnerProduct33
I0816 16:04:06.316396 20404 net.cpp:141] Setting up InnerProduct33
I0816 16:04:06.316421 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.316436 20404 net.cpp:156] Memory required for data: 1545630000
I0816 16:04:06.316445 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:06.316455 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:06.316463 20404 layer_factory.hpp:77] Creating layer ReLU81
I0816 16:04:06.316475 20404 net.cpp:91] Creating Layer ReLU81
I0816 16:04:06.316483 20404 net.cpp:425] ReLU81 <- InnerProduct33
I0816 16:04:06.316505 20404 net.cpp:386] ReLU81 -> InnerProduct33 (in-place)
I0816 16:04:06.316519 20404 net.cpp:141] Setting up ReLU81
I0816 16:04:06.316529 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.316536 20404 net.cpp:156] Memory required for data: 1545732400
I0816 16:04:06.316545 20404 layer_factory.hpp:77] Creating layer InnerProduct34
I0816 16:04:06.316557 20404 net.cpp:91] Creating Layer InnerProduct34
I0816 16:04:06.316565 20404 net.cpp:425] InnerProduct34 <- InnerProduct33
I0816 16:04:06.316581 20404 net.cpp:399] InnerProduct34 -> InnerProduct34
I0816 16:04:06.317327 20404 net.cpp:141] Setting up InnerProduct34
I0816 16:04:06.317342 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.317348 20404 net.cpp:156] Memory required for data: 1545834800
I0816 16:04:06.317358 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:06.317368 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:06.317375 20404 layer_factory.hpp:77] Creating layer ReLU82
I0816 16:04:06.317389 20404 net.cpp:91] Creating Layer ReLU82
I0816 16:04:06.317399 20404 net.cpp:425] ReLU82 <- InnerProduct34
I0816 16:04:06.317409 20404 net.cpp:386] ReLU82 -> InnerProduct34 (in-place)
I0816 16:04:06.317421 20404 net.cpp:141] Setting up ReLU82
I0816 16:04:06.317431 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.317440 20404 net.cpp:156] Memory required for data: 1545937200
I0816 16:04:06.317446 20404 layer_factory.hpp:77] Creating layer Concat6
I0816 16:04:06.317458 20404 net.cpp:91] Creating Layer Concat6
I0816 16:04:06.317466 20404 net.cpp:425] Concat6 <- InnerProduct32
I0816 16:04:06.317476 20404 net.cpp:425] Concat6 <- InnerProduct34
I0816 16:04:06.317489 20404 net.cpp:399] Concat6 -> Concat6
I0816 16:04:06.317541 20404 net.cpp:141] Setting up Concat6
I0816 16:04:06.317555 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:06.317581 20404 net.cpp:156] Memory required for data: 1546142000
I0816 16:04:06.317589 20404 layer_factory.hpp:77] Creating layer InnerProduct35
I0816 16:04:06.317605 20404 net.cpp:91] Creating Layer InnerProduct35
I0816 16:04:06.317613 20404 net.cpp:425] InnerProduct35 <- Concat6
I0816 16:04:06.317631 20404 net.cpp:399] InnerProduct35 -> InnerProduct35
I0816 16:04:06.319491 20404 net.cpp:141] Setting up InnerProduct35
I0816 16:04:06.319512 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.319520 20404 net.cpp:156] Memory required for data: 1546244400
I0816 16:04:06.319530 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:06.319540 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:06.319548 20404 layer_factory.hpp:77] Creating layer ReLU83
I0816 16:04:06.319561 20404 net.cpp:91] Creating Layer ReLU83
I0816 16:04:06.319569 20404 net.cpp:425] ReLU83 <- InnerProduct35
I0816 16:04:06.319581 20404 net.cpp:386] ReLU83 -> InnerProduct35 (in-place)
I0816 16:04:06.319594 20404 net.cpp:141] Setting up ReLU83
I0816 16:04:06.319604 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.319612 20404 net.cpp:156] Memory required for data: 1546346800
I0816 16:04:06.319619 20404 layer_factory.hpp:77] Creating layer InnerProduct36
I0816 16:04:06.319635 20404 net.cpp:91] Creating Layer InnerProduct36
I0816 16:04:06.319643 20404 net.cpp:425] InnerProduct36 <- InnerProduct35
I0816 16:04:06.319659 20404 net.cpp:399] InnerProduct36 -> InnerProduct36
I0816 16:04:06.320183 20404 net.cpp:141] Setting up InnerProduct36
I0816 16:04:06.320201 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:06.320209 20404 net.cpp:156] Memory required for data: 1546398000
I0816 16:04:06.320221 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:06.320230 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:06.320240 20404 layer_factory.hpp:77] Creating layer ReLU84
I0816 16:04:06.320252 20404 net.cpp:91] Creating Layer ReLU84
I0816 16:04:06.320262 20404 net.cpp:425] ReLU84 <- InnerProduct36
I0816 16:04:06.320273 20404 net.cpp:386] ReLU84 -> InnerProduct36 (in-place)
I0816 16:04:06.320296 20404 net.cpp:141] Setting up ReLU84
I0816 16:04:06.320307 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:06.320315 20404 net.cpp:156] Memory required for data: 1546449200
I0816 16:04:06.320323 20404 layer_factory.hpp:77] Creating layer dt5
I0816 16:04:06.320336 20404 net.cpp:91] Creating Layer dt5
I0816 16:04:06.320346 20404 net.cpp:425] dt5 <- InnerProduct36
I0816 16:04:06.320366 20404 net.cpp:399] dt5 -> dt5
I0816 16:04:06.320652 20404 net.cpp:141] Setting up dt5
I0816 16:04:06.320667 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:06.320674 20404 net.cpp:156] Memory required for data: 1546449600
I0816 16:04:06.320683 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:06.320693 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:06.320703 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:06.320724 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:06.320735 20404 net.cpp:425] conv1 <- p1_p1_0_split_6
I0816 16:04:06.320749 20404 net.cpp:399] conv1 -> Convolution61
I0816 16:04:06.323006 20404 net.cpp:141] Setting up conv1
I0816 16:04:06.323024 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.323031 20404 net.cpp:156] Memory required for data: 1556280000
I0816 16:04:06.323046 20404 layer_factory.hpp:77] Creating layer ReLU85
I0816 16:04:06.323057 20404 net.cpp:91] Creating Layer ReLU85
I0816 16:04:06.323065 20404 net.cpp:425] ReLU85 <- Convolution61
I0816 16:04:06.323081 20404 net.cpp:386] ReLU85 -> Convolution61 (in-place)
I0816 16:04:06.323094 20404 net.cpp:141] Setting up ReLU85
I0816 16:04:06.323104 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.323112 20404 net.cpp:156] Memory required for data: 1566110400
I0816 16:04:06.323133 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:06.323145 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:06.323153 20404 net.cpp:425] norm1 <- Convolution61
I0816 16:04:06.323170 20404 net.cpp:399] norm1 -> LRN25
I0816 16:04:06.323328 20404 net.cpp:141] Setting up norm1
I0816 16:04:06.323348 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.323355 20404 net.cpp:156] Memory required for data: 1575940800
I0816 16:04:06.323364 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:06.323374 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:06.323382 20404 net.cpp:425] pool1 <- LRN25
I0816 16:04:06.323397 20404 net.cpp:399] pool1 -> Pooling37
I0816 16:04:06.323477 20404 net.cpp:141] Setting up pool1
I0816 16:04:06.323494 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:06.323503 20404 net.cpp:156] Memory required for data: 1578398400
I0816 16:04:06.323509 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:06.323524 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:06.323532 20404 net.cpp:425] conv2 <- Pooling37
I0816 16:04:06.323550 20404 net.cpp:399] conv2 -> Convolution62
I0816 16:04:06.339424 20404 net.cpp:141] Setting up conv2
I0816 16:04:06.339448 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.339457 20404 net.cpp:156] Memory required for data: 1584952000
I0816 16:04:06.339475 20404 layer_factory.hpp:77] Creating layer ReLU86
I0816 16:04:06.339488 20404 net.cpp:91] Creating Layer ReLU86
I0816 16:04:06.339498 20404 net.cpp:425] ReLU86 <- Convolution62
I0816 16:04:06.339514 20404 net.cpp:386] ReLU86 -> Convolution62 (in-place)
I0816 16:04:06.339529 20404 net.cpp:141] Setting up ReLU86
I0816 16:04:06.339539 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.339545 20404 net.cpp:156] Memory required for data: 1591505600
I0816 16:04:06.339553 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:06.339565 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:06.339573 20404 net.cpp:425] norm2 <- Convolution62
I0816 16:04:06.339588 20404 net.cpp:399] norm2 -> LRN26
I0816 16:04:06.339669 20404 net.cpp:141] Setting up norm2
I0816 16:04:06.339684 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.339691 20404 net.cpp:156] Memory required for data: 1598059200
I0816 16:04:06.339699 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:06.339712 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:06.339720 20404 net.cpp:425] pool2 <- LRN26
I0816 16:04:06.339732 20404 net.cpp:399] pool2 -> Pooling38
I0816 16:04:06.339818 20404 net.cpp:141] Setting up pool2
I0816 16:04:06.339833 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.339839 20404 net.cpp:156] Memory required for data: 1599697600
I0816 16:04:06.339848 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:06.339867 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:06.339875 20404 net.cpp:425] conv3 <- Pooling38
I0816 16:04:06.339892 20404 net.cpp:399] conv3 -> Convolution63
I0816 16:04:06.384124 20404 net.cpp:141] Setting up conv3
I0816 16:04:06.384155 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.384165 20404 net.cpp:156] Memory required for data: 1602155200
I0816 16:04:06.384181 20404 layer_factory.hpp:77] Creating layer ReLU87
I0816 16:04:06.384202 20404 net.cpp:91] Creating Layer ReLU87
I0816 16:04:06.384214 20404 net.cpp:425] ReLU87 <- Convolution63
I0816 16:04:06.384227 20404 net.cpp:386] ReLU87 -> Convolution63 (in-place)
I0816 16:04:06.384244 20404 net.cpp:141] Setting up ReLU87
I0816 16:04:06.384254 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.384263 20404 net.cpp:156] Memory required for data: 1604612800
I0816 16:04:06.384269 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:06.384290 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:06.384299 20404 net.cpp:425] conv4 <- Convolution63
I0816 16:04:06.384315 20404 net.cpp:399] conv4 -> Convolution64
I0816 16:04:06.417762 20404 net.cpp:141] Setting up conv4
I0816 16:04:06.417814 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.417834 20404 net.cpp:156] Memory required for data: 1607070400
I0816 16:04:06.417850 20404 layer_factory.hpp:77] Creating layer ReLU88
I0816 16:04:06.417865 20404 net.cpp:91] Creating Layer ReLU88
I0816 16:04:06.417876 20404 net.cpp:425] ReLU88 <- Convolution64
I0816 16:04:06.417898 20404 net.cpp:386] ReLU88 -> Convolution64 (in-place)
I0816 16:04:06.417914 20404 net.cpp:141] Setting up ReLU88
I0816 16:04:06.417925 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.417932 20404 net.cpp:156] Memory required for data: 1609528000
I0816 16:04:06.417940 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:06.417958 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:06.417966 20404 net.cpp:425] conv5 <- Convolution64
I0816 16:04:06.417984 20404 net.cpp:399] conv5 -> Convolution65
I0816 16:04:06.440189 20404 net.cpp:141] Setting up conv5
I0816 16:04:06.440214 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.440222 20404 net.cpp:156] Memory required for data: 1611166400
I0816 16:04:06.440237 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:06.440254 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:06.440264 20404 net.cpp:425] pool5 <- Convolution65
I0816 16:04:06.440282 20404 net.cpp:399] pool5 -> Pooling39
I0816 16:04:06.440383 20404 net.cpp:141] Setting up pool5
I0816 16:04:06.440398 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:06.440405 20404 net.cpp:156] Memory required for data: 1611576000
I0816 16:04:06.440413 20404 layer_factory.hpp:77] Creating layer InnerProduct37
I0816 16:04:06.440430 20404 net.cpp:91] Creating Layer InnerProduct37
I0816 16:04:06.440438 20404 net.cpp:425] InnerProduct37 <- Pooling39
I0816 16:04:06.440455 20404 net.cpp:399] InnerProduct37 -> InnerProduct37
I0816 16:04:06.443264 20404 net.cpp:141] Setting up InnerProduct37
I0816 16:04:06.443295 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.443303 20404 net.cpp:156] Memory required for data: 1611678400
I0816 16:04:06.443313 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:06.443323 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:06.443332 20404 layer_factory.hpp:77] Creating layer ReLU89
I0816 16:04:06.443344 20404 net.cpp:91] Creating Layer ReLU89
I0816 16:04:06.443353 20404 net.cpp:425] ReLU89 <- InnerProduct37
I0816 16:04:06.443364 20404 net.cpp:386] ReLU89 -> InnerProduct37 (in-place)
I0816 16:04:06.443378 20404 net.cpp:141] Setting up ReLU89
I0816 16:04:06.443388 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.443397 20404 net.cpp:156] Memory required for data: 1611780800
I0816 16:04:06.443403 20404 layer_factory.hpp:77] Creating layer InnerProduct38
I0816 16:04:06.443416 20404 net.cpp:91] Creating Layer InnerProduct38
I0816 16:04:06.443424 20404 net.cpp:425] InnerProduct38 <- InnerProduct37
I0816 16:04:06.443440 20404 net.cpp:399] InnerProduct38 -> InnerProduct38
I0816 16:04:06.444216 20404 net.cpp:141] Setting up InnerProduct38
I0816 16:04:06.444231 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.444238 20404 net.cpp:156] Memory required for data: 1611883200
I0816 16:04:06.444247 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:06.444257 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:06.444265 20404 layer_factory.hpp:77] Creating layer ReLU90
I0816 16:04:06.444279 20404 net.cpp:91] Creating Layer ReLU90
I0816 16:04:06.444288 20404 net.cpp:425] ReLU90 <- InnerProduct38
I0816 16:04:06.444298 20404 net.cpp:386] ReLU90 -> InnerProduct38 (in-place)
I0816 16:04:06.444313 20404 net.cpp:141] Setting up ReLU90
I0816 16:04:06.444322 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.444329 20404 net.cpp:156] Memory required for data: 1611985600
I0816 16:04:06.444337 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:06.444353 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:06.444378 20404 net.cpp:425] conv1 <- c26
I0816 16:04:06.444396 20404 net.cpp:399] conv1 -> Convolution66
I0816 16:04:06.446712 20404 net.cpp:141] Setting up conv1
I0816 16:04:06.446727 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.446743 20404 net.cpp:156] Memory required for data: 1621816000
I0816 16:04:06.446758 20404 layer_factory.hpp:77] Creating layer ReLU91
I0816 16:04:06.446768 20404 net.cpp:91] Creating Layer ReLU91
I0816 16:04:06.446776 20404 net.cpp:425] ReLU91 <- Convolution66
I0816 16:04:06.446786 20404 net.cpp:386] ReLU91 -> Convolution66 (in-place)
I0816 16:04:06.446806 20404 net.cpp:141] Setting up ReLU91
I0816 16:04:06.446817 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.446825 20404 net.cpp:156] Memory required for data: 1631646400
I0816 16:04:06.446831 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:06.446843 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:06.446852 20404 net.cpp:425] norm1 <- Convolution66
I0816 16:04:06.446867 20404 net.cpp:399] norm1 -> LRN27
I0816 16:04:06.446957 20404 net.cpp:141] Setting up norm1
I0816 16:04:06.446970 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.446979 20404 net.cpp:156] Memory required for data: 1641476800
I0816 16:04:06.446985 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:06.447000 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:06.447007 20404 net.cpp:425] pool1 <- LRN27
I0816 16:04:06.447019 20404 net.cpp:399] pool1 -> Pooling40
I0816 16:04:06.447113 20404 net.cpp:141] Setting up pool1
I0816 16:04:06.447126 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:06.447134 20404 net.cpp:156] Memory required for data: 1643934400
I0816 16:04:06.447141 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:06.447160 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:06.447168 20404 net.cpp:425] conv2 <- Pooling40
I0816 16:04:06.447181 20404 net.cpp:399] conv2 -> Convolution67
I0816 16:04:06.462832 20404 net.cpp:141] Setting up conv2
I0816 16:04:06.462857 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.462865 20404 net.cpp:156] Memory required for data: 1650488000
I0816 16:04:06.462889 20404 layer_factory.hpp:77] Creating layer ReLU92
I0816 16:04:06.462903 20404 net.cpp:91] Creating Layer ReLU92
I0816 16:04:06.462911 20404 net.cpp:425] ReLU92 <- Convolution67
I0816 16:04:06.462923 20404 net.cpp:386] ReLU92 -> Convolution67 (in-place)
I0816 16:04:06.462935 20404 net.cpp:141] Setting up ReLU92
I0816 16:04:06.462952 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.462960 20404 net.cpp:156] Memory required for data: 1657041600
I0816 16:04:06.462966 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:06.462982 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:06.462991 20404 net.cpp:425] norm2 <- Convolution67
I0816 16:04:06.463003 20404 net.cpp:399] norm2 -> LRN28
I0816 16:04:06.463682 20404 net.cpp:141] Setting up norm2
I0816 16:04:06.463706 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.463713 20404 net.cpp:156] Memory required for data: 1663595200
I0816 16:04:06.463721 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:06.463732 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:06.463742 20404 net.cpp:425] pool2 <- LRN28
I0816 16:04:06.463753 20404 net.cpp:399] pool2 -> Pooling41
I0816 16:04:06.463822 20404 net.cpp:141] Setting up pool2
I0816 16:04:06.463836 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.463843 20404 net.cpp:156] Memory required for data: 1665233600
I0816 16:04:06.463850 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:06.463870 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:06.463877 20404 net.cpp:425] conv3 <- Pooling41
I0816 16:04:06.463896 20404 net.cpp:399] conv3 -> Convolution68
I0816 16:04:06.507630 20404 net.cpp:141] Setting up conv3
I0816 16:04:06.507664 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.507683 20404 net.cpp:156] Memory required for data: 1667691200
I0816 16:04:06.507716 20404 layer_factory.hpp:77] Creating layer ReLU93
I0816 16:04:06.507731 20404 net.cpp:91] Creating Layer ReLU93
I0816 16:04:06.507752 20404 net.cpp:425] ReLU93 <- Convolution68
I0816 16:04:06.507766 20404 net.cpp:386] ReLU93 -> Convolution68 (in-place)
I0816 16:04:06.507781 20404 net.cpp:141] Setting up ReLU93
I0816 16:04:06.507796 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.507803 20404 net.cpp:156] Memory required for data: 1670148800
I0816 16:04:06.507812 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:06.507832 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:06.507840 20404 net.cpp:425] conv4 <- Convolution68
I0816 16:04:06.507858 20404 net.cpp:399] conv4 -> Convolution69
I0816 16:04:06.541028 20404 net.cpp:141] Setting up conv4
I0816 16:04:06.541057 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.541075 20404 net.cpp:156] Memory required for data: 1672606400
I0816 16:04:06.541091 20404 layer_factory.hpp:77] Creating layer ReLU94
I0816 16:04:06.541105 20404 net.cpp:91] Creating Layer ReLU94
I0816 16:04:06.541116 20404 net.cpp:425] ReLU94 <- Convolution69
I0816 16:04:06.541142 20404 net.cpp:386] ReLU94 -> Convolution69 (in-place)
I0816 16:04:06.541159 20404 net.cpp:141] Setting up ReLU94
I0816 16:04:06.541169 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.541177 20404 net.cpp:156] Memory required for data: 1675064000
I0816 16:04:06.541183 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:06.541200 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:06.541209 20404 net.cpp:425] conv5 <- Convolution69
I0816 16:04:06.541226 20404 net.cpp:399] conv5 -> Convolution70
I0816 16:04:06.563336 20404 net.cpp:141] Setting up conv5
I0816 16:04:06.563359 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.563377 20404 net.cpp:156] Memory required for data: 1676702400
I0816 16:04:06.563391 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:06.563410 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:06.563419 20404 net.cpp:425] pool5 <- Convolution70
I0816 16:04:06.563441 20404 net.cpp:399] pool5 -> Pooling42
I0816 16:04:06.563510 20404 net.cpp:141] Setting up pool5
I0816 16:04:06.563524 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:06.563532 20404 net.cpp:156] Memory required for data: 1677112000
I0816 16:04:06.563540 20404 layer_factory.hpp:77] Creating layer InnerProduct39
I0816 16:04:06.563556 20404 net.cpp:91] Creating Layer InnerProduct39
I0816 16:04:06.563565 20404 net.cpp:425] InnerProduct39 <- Pooling42
I0816 16:04:06.563580 20404 net.cpp:399] InnerProduct39 -> InnerProduct39
I0816 16:04:06.566340 20404 net.cpp:141] Setting up InnerProduct39
I0816 16:04:06.566361 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.566370 20404 net.cpp:156] Memory required for data: 1677214400
I0816 16:04:06.566380 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:06.566390 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:06.566397 20404 layer_factory.hpp:77] Creating layer ReLU95
I0816 16:04:06.566411 20404 net.cpp:91] Creating Layer ReLU95
I0816 16:04:06.566421 20404 net.cpp:425] ReLU95 <- InnerProduct39
I0816 16:04:06.566432 20404 net.cpp:386] ReLU95 -> InnerProduct39 (in-place)
I0816 16:04:06.566447 20404 net.cpp:141] Setting up ReLU95
I0816 16:04:06.566457 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.566464 20404 net.cpp:156] Memory required for data: 1677316800
I0816 16:04:06.566471 20404 layer_factory.hpp:77] Creating layer InnerProduct40
I0816 16:04:06.566486 20404 net.cpp:91] Creating Layer InnerProduct40
I0816 16:04:06.566495 20404 net.cpp:425] InnerProduct40 <- InnerProduct39
I0816 16:04:06.566507 20404 net.cpp:399] InnerProduct40 -> InnerProduct40
I0816 16:04:06.567203 20404 net.cpp:141] Setting up InnerProduct40
I0816 16:04:06.567219 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.567225 20404 net.cpp:156] Memory required for data: 1677419200
I0816 16:04:06.567252 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:06.567262 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:06.567276 20404 layer_factory.hpp:77] Creating layer ReLU96
I0816 16:04:06.567288 20404 net.cpp:91] Creating Layer ReLU96
I0816 16:04:06.567296 20404 net.cpp:425] ReLU96 <- InnerProduct40
I0816 16:04:06.567307 20404 net.cpp:386] ReLU96 -> InnerProduct40 (in-place)
I0816 16:04:06.567320 20404 net.cpp:141] Setting up ReLU96
I0816 16:04:06.567330 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.567338 20404 net.cpp:156] Memory required for data: 1677521600
I0816 16:04:06.567347 20404 layer_factory.hpp:77] Creating layer Concat7
I0816 16:04:06.567358 20404 net.cpp:91] Creating Layer Concat7
I0816 16:04:06.567365 20404 net.cpp:425] Concat7 <- InnerProduct38
I0816 16:04:06.567375 20404 net.cpp:425] Concat7 <- InnerProduct40
I0816 16:04:06.567392 20404 net.cpp:399] Concat7 -> Concat7
I0816 16:04:06.567430 20404 net.cpp:141] Setting up Concat7
I0816 16:04:06.567447 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:06.567454 20404 net.cpp:156] Memory required for data: 1677726400
I0816 16:04:06.567462 20404 layer_factory.hpp:77] Creating layer InnerProduct41
I0816 16:04:06.567474 20404 net.cpp:91] Creating Layer InnerProduct41
I0816 16:04:06.567482 20404 net.cpp:425] InnerProduct41 <- Concat7
I0816 16:04:06.567498 20404 net.cpp:399] InnerProduct41 -> InnerProduct41
I0816 16:04:06.568675 20404 net.cpp:141] Setting up InnerProduct41
I0816 16:04:06.568689 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.568697 20404 net.cpp:156] Memory required for data: 1677828800
I0816 16:04:06.568706 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:06.568716 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:06.568723 20404 layer_factory.hpp:77] Creating layer ReLU97
I0816 16:04:06.568734 20404 net.cpp:91] Creating Layer ReLU97
I0816 16:04:06.568742 20404 net.cpp:425] ReLU97 <- InnerProduct41
I0816 16:04:06.568753 20404 net.cpp:386] ReLU97 -> InnerProduct41 (in-place)
I0816 16:04:06.568766 20404 net.cpp:141] Setting up ReLU97
I0816 16:04:06.568776 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.568783 20404 net.cpp:156] Memory required for data: 1677931200
I0816 16:04:06.568791 20404 layer_factory.hpp:77] Creating layer InnerProduct42
I0816 16:04:06.568806 20404 net.cpp:91] Creating Layer InnerProduct42
I0816 16:04:06.568814 20404 net.cpp:425] InnerProduct42 <- InnerProduct41
I0816 16:04:06.568830 20404 net.cpp:399] InnerProduct42 -> InnerProduct42
I0816 16:04:06.569257 20404 net.cpp:141] Setting up InnerProduct42
I0816 16:04:06.569270 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:06.569278 20404 net.cpp:156] Memory required for data: 1677982400
I0816 16:04:06.569286 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:06.569296 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:06.569304 20404 layer_factory.hpp:77] Creating layer ReLU98
I0816 16:04:06.569315 20404 net.cpp:91] Creating Layer ReLU98
I0816 16:04:06.569324 20404 net.cpp:425] ReLU98 <- InnerProduct42
I0816 16:04:06.569334 20404 net.cpp:386] ReLU98 -> InnerProduct42 (in-place)
I0816 16:04:06.569345 20404 net.cpp:141] Setting up ReLU98
I0816 16:04:06.569355 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:06.569363 20404 net.cpp:156] Memory required for data: 1678033600
I0816 16:04:06.569370 20404 layer_factory.hpp:77] Creating layer dt6
I0816 16:04:06.569382 20404 net.cpp:91] Creating Layer dt6
I0816 16:04:06.569391 20404 net.cpp:425] dt6 <- InnerProduct42
I0816 16:04:06.569406 20404 net.cpp:399] dt6 -> dt6
I0816 16:04:06.569561 20404 net.cpp:141] Setting up dt6
I0816 16:04:06.569574 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:06.569582 20404 net.cpp:156] Memory required for data: 1678034000
I0816 16:04:06.569605 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:06.569615 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:06.569623 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:06.569638 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:06.569648 20404 net.cpp:425] conv1 <- p1_p1_0_split_7
I0816 16:04:06.569661 20404 net.cpp:399] conv1 -> Convolution71
I0816 16:04:06.571727 20404 net.cpp:141] Setting up conv1
I0816 16:04:06.571748 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.571755 20404 net.cpp:156] Memory required for data: 1687864400
I0816 16:04:06.571769 20404 layer_factory.hpp:77] Creating layer ReLU99
I0816 16:04:06.571780 20404 net.cpp:91] Creating Layer ReLU99
I0816 16:04:06.571789 20404 net.cpp:425] ReLU99 <- Convolution71
I0816 16:04:06.571799 20404 net.cpp:386] ReLU99 -> Convolution71 (in-place)
I0816 16:04:06.571811 20404 net.cpp:141] Setting up ReLU99
I0816 16:04:06.571821 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.571830 20404 net.cpp:156] Memory required for data: 1697694800
I0816 16:04:06.571836 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:06.571851 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:06.571861 20404 net.cpp:425] norm1 <- Convolution71
I0816 16:04:06.571873 20404 net.cpp:399] norm1 -> LRN29
I0816 16:04:06.571925 20404 net.cpp:141] Setting up norm1
I0816 16:04:06.571939 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.571946 20404 net.cpp:156] Memory required for data: 1707525200
I0816 16:04:06.571954 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:06.571969 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:06.571976 20404 net.cpp:425] pool1 <- LRN29
I0816 16:04:06.571987 20404 net.cpp:399] pool1 -> Pooling43
I0816 16:04:06.572058 20404 net.cpp:141] Setting up pool1
I0816 16:04:06.572072 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:06.572078 20404 net.cpp:156] Memory required for data: 1709982800
I0816 16:04:06.572087 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:06.572103 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:06.572118 20404 net.cpp:425] conv2 <- Pooling43
I0816 16:04:06.572134 20404 net.cpp:399] conv2 -> Convolution72
I0816 16:04:06.587898 20404 net.cpp:141] Setting up conv2
I0816 16:04:06.587923 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.587931 20404 net.cpp:156] Memory required for data: 1716536400
I0816 16:04:06.587950 20404 layer_factory.hpp:77] Creating layer ReLU100
I0816 16:04:06.587966 20404 net.cpp:91] Creating Layer ReLU100
I0816 16:04:06.587977 20404 net.cpp:425] ReLU100 <- Convolution72
I0816 16:04:06.587990 20404 net.cpp:386] ReLU100 -> Convolution72 (in-place)
I0816 16:04:06.588003 20404 net.cpp:141] Setting up ReLU100
I0816 16:04:06.588014 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.588021 20404 net.cpp:156] Memory required for data: 1723090000
I0816 16:04:06.588029 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:06.588043 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:06.588052 20404 net.cpp:425] norm2 <- Convolution72
I0816 16:04:06.588064 20404 net.cpp:399] norm2 -> LRN30
I0816 16:04:06.588129 20404 net.cpp:141] Setting up norm2
I0816 16:04:06.588143 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.588150 20404 net.cpp:156] Memory required for data: 1729643600
I0816 16:04:06.588157 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:06.588168 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:06.588176 20404 net.cpp:425] pool2 <- LRN30
I0816 16:04:06.588191 20404 net.cpp:399] pool2 -> Pooling44
I0816 16:04:06.588250 20404 net.cpp:141] Setting up pool2
I0816 16:04:06.588263 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.588270 20404 net.cpp:156] Memory required for data: 1731282000
I0816 16:04:06.588279 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:06.588302 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:06.588328 20404 net.cpp:425] conv3 <- Pooling44
I0816 16:04:06.588343 20404 net.cpp:399] conv3 -> Convolution73
I0816 16:04:06.632282 20404 net.cpp:141] Setting up conv3
I0816 16:04:06.632315 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.632324 20404 net.cpp:156] Memory required for data: 1733739600
I0816 16:04:06.632341 20404 layer_factory.hpp:77] Creating layer ReLU101
I0816 16:04:06.632356 20404 net.cpp:91] Creating Layer ReLU101
I0816 16:04:06.632369 20404 net.cpp:425] ReLU101 <- Convolution73
I0816 16:04:06.632381 20404 net.cpp:386] ReLU101 -> Convolution73 (in-place)
I0816 16:04:06.632398 20404 net.cpp:141] Setting up ReLU101
I0816 16:04:06.632414 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.632422 20404 net.cpp:156] Memory required for data: 1736197200
I0816 16:04:06.632431 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:06.632452 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:06.632464 20404 net.cpp:425] conv4 <- Convolution73
I0816 16:04:06.632482 20404 net.cpp:399] conv4 -> Convolution74
I0816 16:04:06.665524 20404 net.cpp:141] Setting up conv4
I0816 16:04:06.665555 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.665565 20404 net.cpp:156] Memory required for data: 1738654800
I0816 16:04:06.665580 20404 layer_factory.hpp:77] Creating layer ReLU102
I0816 16:04:06.665598 20404 net.cpp:91] Creating Layer ReLU102
I0816 16:04:06.665611 20404 net.cpp:425] ReLU102 <- Convolution74
I0816 16:04:06.665624 20404 net.cpp:386] ReLU102 -> Convolution74 (in-place)
I0816 16:04:06.665639 20404 net.cpp:141] Setting up ReLU102
I0816 16:04:06.665652 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.665658 20404 net.cpp:156] Memory required for data: 1741112400
I0816 16:04:06.665666 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:06.665688 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:06.665696 20404 net.cpp:425] conv5 <- Convolution74
I0816 16:04:06.665714 20404 net.cpp:399] conv5 -> Convolution75
I0816 16:04:06.687691 20404 net.cpp:141] Setting up conv5
I0816 16:04:06.687714 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.687732 20404 net.cpp:156] Memory required for data: 1742750800
I0816 16:04:06.687747 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:06.687760 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:06.687773 20404 net.cpp:425] pool5 <- Convolution75
I0816 16:04:06.687788 20404 net.cpp:399] pool5 -> Pooling45
I0816 16:04:06.687866 20404 net.cpp:141] Setting up pool5
I0816 16:04:06.687880 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:06.687888 20404 net.cpp:156] Memory required for data: 1743160400
I0816 16:04:06.687896 20404 layer_factory.hpp:77] Creating layer InnerProduct43
I0816 16:04:06.687909 20404 net.cpp:91] Creating Layer InnerProduct43
I0816 16:04:06.687917 20404 net.cpp:425] InnerProduct43 <- Pooling45
I0816 16:04:06.687934 20404 net.cpp:399] InnerProduct43 -> InnerProduct43
I0816 16:04:06.690672 20404 net.cpp:141] Setting up InnerProduct43
I0816 16:04:06.690693 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.690701 20404 net.cpp:156] Memory required for data: 1743262800
I0816 16:04:06.690711 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:06.690722 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:06.690731 20404 layer_factory.hpp:77] Creating layer ReLU103
I0816 16:04:06.690742 20404 net.cpp:91] Creating Layer ReLU103
I0816 16:04:06.690752 20404 net.cpp:425] ReLU103 <- InnerProduct43
I0816 16:04:06.690762 20404 net.cpp:386] ReLU103 -> InnerProduct43 (in-place)
I0816 16:04:06.690779 20404 net.cpp:141] Setting up ReLU103
I0816 16:04:06.690789 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.690798 20404 net.cpp:156] Memory required for data: 1743365200
I0816 16:04:06.690804 20404 layer_factory.hpp:77] Creating layer InnerProduct44
I0816 16:04:06.690817 20404 net.cpp:91] Creating Layer InnerProduct44
I0816 16:04:06.690842 20404 net.cpp:425] InnerProduct44 <- InnerProduct43
I0816 16:04:06.690855 20404 net.cpp:399] InnerProduct44 -> InnerProduct44
I0816 16:04:06.691566 20404 net.cpp:141] Setting up InnerProduct44
I0816 16:04:06.691582 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.691591 20404 net.cpp:156] Memory required for data: 1743467600
I0816 16:04:06.691598 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:06.691608 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:06.691617 20404 layer_factory.hpp:77] Creating layer ReLU104
I0816 16:04:06.691627 20404 net.cpp:91] Creating Layer ReLU104
I0816 16:04:06.691635 20404 net.cpp:425] ReLU104 <- InnerProduct44
I0816 16:04:06.691646 20404 net.cpp:386] ReLU104 -> InnerProduct44 (in-place)
I0816 16:04:06.691658 20404 net.cpp:141] Setting up ReLU104
I0816 16:04:06.691668 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.691675 20404 net.cpp:156] Memory required for data: 1743570000
I0816 16:04:06.691682 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:06.691702 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:06.691711 20404 net.cpp:425] conv1 <- c27
I0816 16:04:06.691725 20404 net.cpp:399] conv1 -> Convolution76
I0816 16:04:06.693816 20404 net.cpp:141] Setting up conv1
I0816 16:04:06.693835 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.693842 20404 net.cpp:156] Memory required for data: 1753400400
I0816 16:04:06.693856 20404 layer_factory.hpp:77] Creating layer ReLU105
I0816 16:04:06.693867 20404 net.cpp:91] Creating Layer ReLU105
I0816 16:04:06.693876 20404 net.cpp:425] ReLU105 <- Convolution76
I0816 16:04:06.693887 20404 net.cpp:386] ReLU105 -> Convolution76 (in-place)
I0816 16:04:06.693900 20404 net.cpp:141] Setting up ReLU105
I0816 16:04:06.693912 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.693918 20404 net.cpp:156] Memory required for data: 1763230800
I0816 16:04:06.693928 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:06.693944 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:06.693953 20404 net.cpp:425] norm1 <- Convolution76
I0816 16:04:06.693965 20404 net.cpp:399] norm1 -> LRN31
I0816 16:04:06.694026 20404 net.cpp:141] Setting up norm1
I0816 16:04:06.694041 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.694048 20404 net.cpp:156] Memory required for data: 1773061200
I0816 16:04:06.694056 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:06.694070 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:06.694079 20404 net.cpp:425] pool1 <- LRN31
I0816 16:04:06.694090 20404 net.cpp:399] pool1 -> Pooling46
I0816 16:04:06.694154 20404 net.cpp:141] Setting up pool1
I0816 16:04:06.694169 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:06.694175 20404 net.cpp:156] Memory required for data: 1775518800
I0816 16:04:06.694183 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:06.694201 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:06.694211 20404 net.cpp:425] conv2 <- Pooling46
I0816 16:04:06.694226 20404 net.cpp:399] conv2 -> Convolution77
I0816 16:04:06.709724 20404 net.cpp:141] Setting up conv2
I0816 16:04:06.709748 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.709755 20404 net.cpp:156] Memory required for data: 1782072400
I0816 16:04:06.709780 20404 layer_factory.hpp:77] Creating layer ReLU106
I0816 16:04:06.709796 20404 net.cpp:91] Creating Layer ReLU106
I0816 16:04:06.709806 20404 net.cpp:425] ReLU106 <- Convolution77
I0816 16:04:06.709818 20404 net.cpp:386] ReLU106 -> Convolution77 (in-place)
I0816 16:04:06.709833 20404 net.cpp:141] Setting up ReLU106
I0816 16:04:06.709849 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.709856 20404 net.cpp:156] Memory required for data: 1788626000
I0816 16:04:06.709864 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:06.709878 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:06.709887 20404 net.cpp:425] norm2 <- Convolution77
I0816 16:04:06.709915 20404 net.cpp:399] norm2 -> LRN32
I0816 16:04:06.709980 20404 net.cpp:141] Setting up norm2
I0816 16:04:06.709995 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.710001 20404 net.cpp:156] Memory required for data: 1795179600
I0816 16:04:06.710008 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:06.710019 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:06.710027 20404 net.cpp:425] pool2 <- LRN32
I0816 16:04:06.710041 20404 net.cpp:399] pool2 -> Pooling47
I0816 16:04:06.710103 20404 net.cpp:141] Setting up pool2
I0816 16:04:06.710116 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.710124 20404 net.cpp:156] Memory required for data: 1796818000
I0816 16:04:06.710131 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:06.710153 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:06.710165 20404 net.cpp:425] conv3 <- Pooling47
I0816 16:04:06.710180 20404 net.cpp:399] conv3 -> Convolution78
I0816 16:04:06.754391 20404 net.cpp:141] Setting up conv3
I0816 16:04:06.754422 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.754431 20404 net.cpp:156] Memory required for data: 1799275600
I0816 16:04:06.754560 20404 layer_factory.hpp:77] Creating layer ReLU107
I0816 16:04:06.754578 20404 net.cpp:91] Creating Layer ReLU107
I0816 16:04:06.754590 20404 net.cpp:425] ReLU107 <- Convolution78
I0816 16:04:06.754603 20404 net.cpp:386] ReLU107 -> Convolution78 (in-place)
I0816 16:04:06.754619 20404 net.cpp:141] Setting up ReLU107
I0816 16:04:06.754633 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.754642 20404 net.cpp:156] Memory required for data: 1801733200
I0816 16:04:06.754649 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:06.754667 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:06.754675 20404 net.cpp:425] conv4 <- Convolution78
I0816 16:04:06.754693 20404 net.cpp:399] conv4 -> Convolution79
I0816 16:04:06.787668 20404 net.cpp:141] Setting up conv4
I0816 16:04:06.787696 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.787714 20404 net.cpp:156] Memory required for data: 1804190800
I0816 16:04:06.787730 20404 layer_factory.hpp:77] Creating layer ReLU108
I0816 16:04:06.787744 20404 net.cpp:91] Creating Layer ReLU108
I0816 16:04:06.787755 20404 net.cpp:425] ReLU108 <- Convolution79
I0816 16:04:06.787776 20404 net.cpp:386] ReLU108 -> Convolution79 (in-place)
I0816 16:04:06.787792 20404 net.cpp:141] Setting up ReLU108
I0816 16:04:06.787802 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.787811 20404 net.cpp:156] Memory required for data: 1806648400
I0816 16:04:06.787818 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:06.787838 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:06.787847 20404 net.cpp:425] conv5 <- Convolution79
I0816 16:04:06.787859 20404 net.cpp:399] conv5 -> Convolution80
I0816 16:04:06.809870 20404 net.cpp:141] Setting up conv5
I0816 16:04:06.809892 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.809911 20404 net.cpp:156] Memory required for data: 1808286800
I0816 16:04:06.809926 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:06.809940 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:06.809949 20404 net.cpp:425] pool5 <- Convolution80
I0816 16:04:06.809973 20404 net.cpp:399] pool5 -> Pooling48
I0816 16:04:06.810042 20404 net.cpp:141] Setting up pool5
I0816 16:04:06.810057 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:06.810065 20404 net.cpp:156] Memory required for data: 1808696400
I0816 16:04:06.810072 20404 layer_factory.hpp:77] Creating layer InnerProduct45
I0816 16:04:06.810091 20404 net.cpp:91] Creating Layer InnerProduct45
I0816 16:04:06.810098 20404 net.cpp:425] InnerProduct45 <- Pooling48
I0816 16:04:06.810117 20404 net.cpp:399] InnerProduct45 -> InnerProduct45
I0816 16:04:06.812855 20404 net.cpp:141] Setting up InnerProduct45
I0816 16:04:06.812875 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.812893 20404 net.cpp:156] Memory required for data: 1808798800
I0816 16:04:06.812922 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:06.812932 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:06.812939 20404 layer_factory.hpp:77] Creating layer ReLU109
I0816 16:04:06.812958 20404 net.cpp:91] Creating Layer ReLU109
I0816 16:04:06.812968 20404 net.cpp:425] ReLU109 <- InnerProduct45
I0816 16:04:06.812979 20404 net.cpp:386] ReLU109 -> InnerProduct45 (in-place)
I0816 16:04:06.812994 20404 net.cpp:141] Setting up ReLU109
I0816 16:04:06.813004 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.813010 20404 net.cpp:156] Memory required for data: 1808901200
I0816 16:04:06.813019 20404 layer_factory.hpp:77] Creating layer InnerProduct46
I0816 16:04:06.813033 20404 net.cpp:91] Creating Layer InnerProduct46
I0816 16:04:06.813042 20404 net.cpp:425] InnerProduct46 <- InnerProduct45
I0816 16:04:06.813057 20404 net.cpp:399] InnerProduct46 -> InnerProduct46
I0816 16:04:06.813758 20404 net.cpp:141] Setting up InnerProduct46
I0816 16:04:06.813772 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.813781 20404 net.cpp:156] Memory required for data: 1809003600
I0816 16:04:06.813789 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:06.813798 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:06.813807 20404 layer_factory.hpp:77] Creating layer ReLU110
I0816 16:04:06.813817 20404 net.cpp:91] Creating Layer ReLU110
I0816 16:04:06.813825 20404 net.cpp:425] ReLU110 <- InnerProduct46
I0816 16:04:06.813837 20404 net.cpp:386] ReLU110 -> InnerProduct46 (in-place)
I0816 16:04:06.813848 20404 net.cpp:141] Setting up ReLU110
I0816 16:04:06.813858 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.813866 20404 net.cpp:156] Memory required for data: 1809106000
I0816 16:04:06.813874 20404 layer_factory.hpp:77] Creating layer Concat8
I0816 16:04:06.813885 20404 net.cpp:91] Creating Layer Concat8
I0816 16:04:06.813894 20404 net.cpp:425] Concat8 <- InnerProduct44
I0816 16:04:06.813904 20404 net.cpp:425] Concat8 <- InnerProduct46
I0816 16:04:06.813916 20404 net.cpp:399] Concat8 -> Concat8
I0816 16:04:06.813958 20404 net.cpp:141] Setting up Concat8
I0816 16:04:06.813972 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:06.813980 20404 net.cpp:156] Memory required for data: 1809310800
I0816 16:04:06.813987 20404 layer_factory.hpp:77] Creating layer InnerProduct47
I0816 16:04:06.814002 20404 net.cpp:91] Creating Layer InnerProduct47
I0816 16:04:06.814010 20404 net.cpp:425] InnerProduct47 <- Concat8
I0816 16:04:06.814028 20404 net.cpp:399] InnerProduct47 -> InnerProduct47
I0816 16:04:06.815788 20404 net.cpp:141] Setting up InnerProduct47
I0816 16:04:06.815809 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.815817 20404 net.cpp:156] Memory required for data: 1809413200
I0816 16:04:06.815826 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:06.815836 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:06.815845 20404 layer_factory.hpp:77] Creating layer ReLU111
I0816 16:04:06.815856 20404 net.cpp:91] Creating Layer ReLU111
I0816 16:04:06.815865 20404 net.cpp:425] ReLU111 <- InnerProduct47
I0816 16:04:06.815881 20404 net.cpp:386] ReLU111 -> InnerProduct47 (in-place)
I0816 16:04:06.815893 20404 net.cpp:141] Setting up ReLU111
I0816 16:04:06.815903 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.815910 20404 net.cpp:156] Memory required for data: 1809515600
I0816 16:04:06.815918 20404 layer_factory.hpp:77] Creating layer InnerProduct48
I0816 16:04:06.815930 20404 net.cpp:91] Creating Layer InnerProduct48
I0816 16:04:06.815938 20404 net.cpp:425] InnerProduct48 <- InnerProduct47
I0816 16:04:06.815953 20404 net.cpp:399] InnerProduct48 -> InnerProduct48
I0816 16:04:06.816390 20404 net.cpp:141] Setting up InnerProduct48
I0816 16:04:06.816404 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:06.816429 20404 net.cpp:156] Memory required for data: 1809566800
I0816 16:04:06.816438 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:06.816448 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:06.816457 20404 layer_factory.hpp:77] Creating layer ReLU112
I0816 16:04:06.816468 20404 net.cpp:91] Creating Layer ReLU112
I0816 16:04:06.816475 20404 net.cpp:425] ReLU112 <- InnerProduct48
I0816 16:04:06.816489 20404 net.cpp:386] ReLU112 -> InnerProduct48 (in-place)
I0816 16:04:06.816503 20404 net.cpp:141] Setting up ReLU112
I0816 16:04:06.816512 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:06.816520 20404 net.cpp:156] Memory required for data: 1809618000
I0816 16:04:06.816527 20404 layer_factory.hpp:77] Creating layer dt7
I0816 16:04:06.816540 20404 net.cpp:91] Creating Layer dt7
I0816 16:04:06.816547 20404 net.cpp:425] dt7 <- InnerProduct48
I0816 16:04:06.816561 20404 net.cpp:399] dt7 -> dt7
I0816 16:04:06.816723 20404 net.cpp:141] Setting up dt7
I0816 16:04:06.816738 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:06.816745 20404 net.cpp:156] Memory required for data: 1809618400
I0816 16:04:06.816753 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:06.816763 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:06.816771 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:06.816787 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:06.816797 20404 net.cpp:425] conv1 <- p1_p1_0_split_8
I0816 16:04:06.816814 20404 net.cpp:399] conv1 -> Convolution81
I0816 16:04:06.818966 20404 net.cpp:141] Setting up conv1
I0816 16:04:06.818985 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.818994 20404 net.cpp:156] Memory required for data: 1819448800
I0816 16:04:06.819007 20404 layer_factory.hpp:77] Creating layer ReLU113
I0816 16:04:06.819022 20404 net.cpp:91] Creating Layer ReLU113
I0816 16:04:06.819031 20404 net.cpp:425] ReLU113 <- Convolution81
I0816 16:04:06.819042 20404 net.cpp:386] ReLU113 -> Convolution81 (in-place)
I0816 16:04:06.819056 20404 net.cpp:141] Setting up ReLU113
I0816 16:04:06.819066 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.819073 20404 net.cpp:156] Memory required for data: 1829279200
I0816 16:04:06.819082 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:06.819095 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:06.819103 20404 net.cpp:425] norm1 <- Convolution81
I0816 16:04:06.819116 20404 net.cpp:399] norm1 -> LRN33
I0816 16:04:06.819172 20404 net.cpp:141] Setting up norm1
I0816 16:04:06.819188 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.819196 20404 net.cpp:156] Memory required for data: 1839109600
I0816 16:04:06.819203 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:06.819214 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:06.819222 20404 net.cpp:425] pool1 <- LRN33
I0816 16:04:06.819234 20404 net.cpp:399] pool1 -> Pooling49
I0816 16:04:06.819304 20404 net.cpp:141] Setting up pool1
I0816 16:04:06.819317 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:06.819325 20404 net.cpp:156] Memory required for data: 1841567200
I0816 16:04:06.819332 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:06.819350 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:06.819360 20404 net.cpp:425] conv2 <- Pooling49
I0816 16:04:06.819375 20404 net.cpp:399] conv2 -> Convolution82
I0816 16:04:06.834764 20404 net.cpp:141] Setting up conv2
I0816 16:04:06.834787 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.834795 20404 net.cpp:156] Memory required for data: 1848120800
I0816 16:04:06.834820 20404 layer_factory.hpp:77] Creating layer ReLU114
I0816 16:04:06.834831 20404 net.cpp:91] Creating Layer ReLU114
I0816 16:04:06.834841 20404 net.cpp:425] ReLU114 <- Convolution82
I0816 16:04:06.834852 20404 net.cpp:386] ReLU114 -> Convolution82 (in-place)
I0816 16:04:06.834892 20404 net.cpp:141] Setting up ReLU114
I0816 16:04:06.834904 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.834913 20404 net.cpp:156] Memory required for data: 1854674400
I0816 16:04:06.834919 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:06.834934 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:06.834942 20404 net.cpp:425] norm2 <- Convolution82
I0816 16:04:06.834955 20404 net.cpp:399] norm2 -> LRN34
I0816 16:04:06.835022 20404 net.cpp:141] Setting up norm2
I0816 16:04:06.835036 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.835044 20404 net.cpp:156] Memory required for data: 1861228000
I0816 16:04:06.835052 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:06.835062 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:06.835070 20404 net.cpp:425] pool2 <- LRN34
I0816 16:04:06.835085 20404 net.cpp:399] pool2 -> Pooling50
I0816 16:04:06.835149 20404 net.cpp:141] Setting up pool2
I0816 16:04:06.835165 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.835172 20404 net.cpp:156] Memory required for data: 1862866400
I0816 16:04:06.835180 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:06.835194 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:06.835203 20404 net.cpp:425] conv3 <- Pooling50
I0816 16:04:06.835219 20404 net.cpp:399] conv3 -> Convolution83
I0816 16:04:06.879124 20404 net.cpp:141] Setting up conv3
I0816 16:04:06.879165 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.879174 20404 net.cpp:156] Memory required for data: 1865324000
I0816 16:04:06.879191 20404 layer_factory.hpp:77] Creating layer ReLU115
I0816 16:04:06.879209 20404 net.cpp:91] Creating Layer ReLU115
I0816 16:04:06.879221 20404 net.cpp:425] ReLU115 <- Convolution83
I0816 16:04:06.879235 20404 net.cpp:386] ReLU115 -> Convolution83 (in-place)
I0816 16:04:06.879251 20404 net.cpp:141] Setting up ReLU115
I0816 16:04:06.879261 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.879269 20404 net.cpp:156] Memory required for data: 1867781600
I0816 16:04:06.879282 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:06.879304 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:06.879312 20404 net.cpp:425] conv4 <- Convolution83
I0816 16:04:06.879330 20404 net.cpp:399] conv4 -> Convolution84
I0816 16:04:06.912365 20404 net.cpp:141] Setting up conv4
I0816 16:04:06.912396 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.912405 20404 net.cpp:156] Memory required for data: 1870239200
I0816 16:04:06.912418 20404 layer_factory.hpp:77] Creating layer ReLU116
I0816 16:04:06.912431 20404 net.cpp:91] Creating Layer ReLU116
I0816 16:04:06.912442 20404 net.cpp:425] ReLU116 <- Convolution84
I0816 16:04:06.912459 20404 net.cpp:386] ReLU116 -> Convolution84 (in-place)
I0816 16:04:06.912475 20404 net.cpp:141] Setting up ReLU116
I0816 16:04:06.912485 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:06.912493 20404 net.cpp:156] Memory required for data: 1872696800
I0816 16:04:06.912500 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:06.912519 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:06.912534 20404 net.cpp:425] conv5 <- Convolution84
I0816 16:04:06.912549 20404 net.cpp:399] conv5 -> Convolution85
I0816 16:04:06.934597 20404 net.cpp:141] Setting up conv5
I0816 16:04:06.934623 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.934641 20404 net.cpp:156] Memory required for data: 1874335200
I0816 16:04:06.934658 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:06.934672 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:06.934684 20404 net.cpp:425] pool5 <- Convolution85
I0816 16:04:06.934711 20404 net.cpp:399] pool5 -> Pooling51
I0816 16:04:06.934783 20404 net.cpp:141] Setting up pool5
I0816 16:04:06.934798 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:06.934805 20404 net.cpp:156] Memory required for data: 1874744800
I0816 16:04:06.934813 20404 layer_factory.hpp:77] Creating layer InnerProduct49
I0816 16:04:06.934847 20404 net.cpp:91] Creating Layer InnerProduct49
I0816 16:04:06.934857 20404 net.cpp:425] InnerProduct49 <- Pooling51
I0816 16:04:06.934875 20404 net.cpp:399] InnerProduct49 -> InnerProduct49
I0816 16:04:06.937690 20404 net.cpp:141] Setting up InnerProduct49
I0816 16:04:06.937712 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.937721 20404 net.cpp:156] Memory required for data: 1874847200
I0816 16:04:06.937731 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:06.937741 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:06.937750 20404 layer_factory.hpp:77] Creating layer ReLU117
I0816 16:04:06.937762 20404 net.cpp:91] Creating Layer ReLU117
I0816 16:04:06.937772 20404 net.cpp:425] ReLU117 <- InnerProduct49
I0816 16:04:06.937783 20404 net.cpp:386] ReLU117 -> InnerProduct49 (in-place)
I0816 16:04:06.937798 20404 net.cpp:141] Setting up ReLU117
I0816 16:04:06.937808 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.937815 20404 net.cpp:156] Memory required for data: 1874949600
I0816 16:04:06.937822 20404 layer_factory.hpp:77] Creating layer InnerProduct50
I0816 16:04:06.937839 20404 net.cpp:91] Creating Layer InnerProduct50
I0816 16:04:06.937847 20404 net.cpp:425] InnerProduct50 <- InnerProduct49
I0816 16:04:06.937863 20404 net.cpp:399] InnerProduct50 -> InnerProduct50
I0816 16:04:06.938570 20404 net.cpp:141] Setting up InnerProduct50
I0816 16:04:06.938585 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.938591 20404 net.cpp:156] Memory required for data: 1875052000
I0816 16:04:06.938601 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:06.938609 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:06.938617 20404 layer_factory.hpp:77] Creating layer ReLU118
I0816 16:04:06.938628 20404 net.cpp:91] Creating Layer ReLU118
I0816 16:04:06.938637 20404 net.cpp:425] ReLU118 <- InnerProduct50
I0816 16:04:06.938647 20404 net.cpp:386] ReLU118 -> InnerProduct50 (in-place)
I0816 16:04:06.938660 20404 net.cpp:141] Setting up ReLU118
I0816 16:04:06.938670 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:06.938678 20404 net.cpp:156] Memory required for data: 1875154400
I0816 16:04:06.938685 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:06.938704 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:06.938714 20404 net.cpp:425] conv1 <- c28
I0816 16:04:06.938730 20404 net.cpp:399] conv1 -> Convolution86
I0816 16:04:06.940907 20404 net.cpp:141] Setting up conv1
I0816 16:04:06.940923 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.940929 20404 net.cpp:156] Memory required for data: 1884984800
I0816 16:04:06.940943 20404 layer_factory.hpp:77] Creating layer ReLU119
I0816 16:04:06.940953 20404 net.cpp:91] Creating Layer ReLU119
I0816 16:04:06.940960 20404 net.cpp:425] ReLU119 <- Convolution86
I0816 16:04:06.940969 20404 net.cpp:386] ReLU119 -> Convolution86 (in-place)
I0816 16:04:06.940980 20404 net.cpp:141] Setting up ReLU119
I0816 16:04:06.940989 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.940994 20404 net.cpp:156] Memory required for data: 1894815200
I0816 16:04:06.940999 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:06.941010 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:06.941017 20404 net.cpp:425] norm1 <- Convolution86
I0816 16:04:06.941027 20404 net.cpp:399] norm1 -> LRN35
I0816 16:04:06.941076 20404 net.cpp:141] Setting up norm1
I0816 16:04:06.941087 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:06.941093 20404 net.cpp:156] Memory required for data: 1904645600
I0816 16:04:06.941099 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:06.941107 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:06.941113 20404 net.cpp:425] pool1 <- LRN35
I0816 16:04:06.941123 20404 net.cpp:399] pool1 -> Pooling52
I0816 16:04:06.941179 20404 net.cpp:141] Setting up pool1
I0816 16:04:06.941189 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:06.941208 20404 net.cpp:156] Memory required for data: 1907103200
I0816 16:04:06.941215 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:06.941228 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:06.941244 20404 net.cpp:425] conv2 <- Pooling52
I0816 16:04:06.941260 20404 net.cpp:399] conv2 -> Convolution87
I0816 16:04:06.956835 20404 net.cpp:141] Setting up conv2
I0816 16:04:06.956863 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.956871 20404 net.cpp:156] Memory required for data: 1913656800
I0816 16:04:06.956897 20404 layer_factory.hpp:77] Creating layer ReLU120
I0816 16:04:06.956912 20404 net.cpp:91] Creating Layer ReLU120
I0816 16:04:06.956921 20404 net.cpp:425] ReLU120 <- Convolution87
I0816 16:04:06.956933 20404 net.cpp:386] ReLU120 -> Convolution87 (in-place)
I0816 16:04:06.956959 20404 net.cpp:141] Setting up ReLU120
I0816 16:04:06.956969 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.956975 20404 net.cpp:156] Memory required for data: 1920210400
I0816 16:04:06.956984 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:06.956998 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:06.957007 20404 net.cpp:425] norm2 <- Convolution87
I0816 16:04:06.957021 20404 net.cpp:399] norm2 -> LRN36
I0816 16:04:06.957088 20404 net.cpp:141] Setting up norm2
I0816 16:04:06.957103 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:06.957109 20404 net.cpp:156] Memory required for data: 1926764000
I0816 16:04:06.957118 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:06.957128 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:06.957136 20404 net.cpp:425] pool2 <- LRN36
I0816 16:04:06.957151 20404 net.cpp:399] pool2 -> Pooling53
I0816 16:04:06.957212 20404 net.cpp:141] Setting up pool2
I0816 16:04:06.957229 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:06.957237 20404 net.cpp:156] Memory required for data: 1928402400
I0816 16:04:06.957244 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:06.957259 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:06.957267 20404 net.cpp:425] conv3 <- Pooling53
I0816 16:04:06.957285 20404 net.cpp:399] conv3 -> Convolution88
I0816 16:04:07.001103 20404 net.cpp:141] Setting up conv3
I0816 16:04:07.001134 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.001153 20404 net.cpp:156] Memory required for data: 1930860000
I0816 16:04:07.001169 20404 layer_factory.hpp:77] Creating layer ReLU121
I0816 16:04:07.001183 20404 net.cpp:91] Creating Layer ReLU121
I0816 16:04:07.001195 20404 net.cpp:425] ReLU121 <- Convolution88
I0816 16:04:07.001209 20404 net.cpp:386] ReLU121 -> Convolution88 (in-place)
I0816 16:04:07.001233 20404 net.cpp:141] Setting up ReLU121
I0816 16:04:07.001243 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.001250 20404 net.cpp:156] Memory required for data: 1933317600
I0816 16:04:07.001258 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:07.001279 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:07.001287 20404 net.cpp:425] conv4 <- Convolution88
I0816 16:04:07.001304 20404 net.cpp:399] conv4 -> Convolution89
I0816 16:04:07.034449 20404 net.cpp:141] Setting up conv4
I0816 16:04:07.034483 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.034492 20404 net.cpp:156] Memory required for data: 1935775200
I0816 16:04:07.034510 20404 layer_factory.hpp:77] Creating layer ReLU122
I0816 16:04:07.034525 20404 net.cpp:91] Creating Layer ReLU122
I0816 16:04:07.034538 20404 net.cpp:425] ReLU122 <- Convolution89
I0816 16:04:07.034560 20404 net.cpp:386] ReLU122 -> Convolution89 (in-place)
I0816 16:04:07.034577 20404 net.cpp:141] Setting up ReLU122
I0816 16:04:07.034590 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.034598 20404 net.cpp:156] Memory required for data: 1938232800
I0816 16:04:07.034605 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:07.034626 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:07.034636 20404 net.cpp:425] conv5 <- Convolution89
I0816 16:04:07.034667 20404 net.cpp:399] conv5 -> Convolution90
I0816 16:04:07.056820 20404 net.cpp:141] Setting up conv5
I0816 16:04:07.056844 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.056852 20404 net.cpp:156] Memory required for data: 1939871200
I0816 16:04:07.056874 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:07.056887 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:07.056897 20404 net.cpp:425] pool5 <- Convolution90
I0816 16:04:07.056915 20404 net.cpp:399] pool5 -> Pooling54
I0816 16:04:07.056991 20404 net.cpp:141] Setting up pool5
I0816 16:04:07.057006 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:07.057013 20404 net.cpp:156] Memory required for data: 1940280800
I0816 16:04:07.057021 20404 layer_factory.hpp:77] Creating layer InnerProduct51
I0816 16:04:07.057039 20404 net.cpp:91] Creating Layer InnerProduct51
I0816 16:04:07.057047 20404 net.cpp:425] InnerProduct51 <- Pooling54
I0816 16:04:07.057065 20404 net.cpp:399] InnerProduct51 -> InnerProduct51
I0816 16:04:07.059777 20404 net.cpp:141] Setting up InnerProduct51
I0816 16:04:07.059798 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.059805 20404 net.cpp:156] Memory required for data: 1940383200
I0816 16:04:07.059823 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:07.059833 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:07.059840 20404 layer_factory.hpp:77] Creating layer ReLU123
I0816 16:04:07.059852 20404 net.cpp:91] Creating Layer ReLU123
I0816 16:04:07.059860 20404 net.cpp:425] ReLU123 <- InnerProduct51
I0816 16:04:07.059872 20404 net.cpp:386] ReLU123 -> InnerProduct51 (in-place)
I0816 16:04:07.059892 20404 net.cpp:141] Setting up ReLU123
I0816 16:04:07.059902 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.059909 20404 net.cpp:156] Memory required for data: 1940485600
I0816 16:04:07.059917 20404 layer_factory.hpp:77] Creating layer InnerProduct52
I0816 16:04:07.059933 20404 net.cpp:91] Creating Layer InnerProduct52
I0816 16:04:07.059942 20404 net.cpp:425] InnerProduct52 <- InnerProduct51
I0816 16:04:07.059957 20404 net.cpp:399] InnerProduct52 -> InnerProduct52
I0816 16:04:07.060658 20404 net.cpp:141] Setting up InnerProduct52
I0816 16:04:07.060672 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.060689 20404 net.cpp:156] Memory required for data: 1940588000
I0816 16:04:07.060698 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:07.060708 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:07.060716 20404 layer_factory.hpp:77] Creating layer ReLU124
I0816 16:04:07.060726 20404 net.cpp:91] Creating Layer ReLU124
I0816 16:04:07.060734 20404 net.cpp:425] ReLU124 <- InnerProduct52
I0816 16:04:07.060747 20404 net.cpp:386] ReLU124 -> InnerProduct52 (in-place)
I0816 16:04:07.060760 20404 net.cpp:141] Setting up ReLU124
I0816 16:04:07.060770 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.060778 20404 net.cpp:156] Memory required for data: 1940690400
I0816 16:04:07.060786 20404 layer_factory.hpp:77] Creating layer Concat9
I0816 16:04:07.060797 20404 net.cpp:91] Creating Layer Concat9
I0816 16:04:07.060806 20404 net.cpp:425] Concat9 <- InnerProduct50
I0816 16:04:07.060817 20404 net.cpp:425] Concat9 <- InnerProduct52
I0816 16:04:07.060829 20404 net.cpp:399] Concat9 -> Concat9
I0816 16:04:07.060873 20404 net.cpp:141] Setting up Concat9
I0816 16:04:07.060886 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:07.060894 20404 net.cpp:156] Memory required for data: 1940895200
I0816 16:04:07.060901 20404 layer_factory.hpp:77] Creating layer InnerProduct53
I0816 16:04:07.060915 20404 net.cpp:91] Creating Layer InnerProduct53
I0816 16:04:07.060925 20404 net.cpp:425] InnerProduct53 <- Concat9
I0816 16:04:07.060936 20404 net.cpp:399] InnerProduct53 -> InnerProduct53
I0816 16:04:07.062114 20404 net.cpp:141] Setting up InnerProduct53
I0816 16:04:07.062142 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.062150 20404 net.cpp:156] Memory required for data: 1940997600
I0816 16:04:07.062158 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:07.062168 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:07.062176 20404 layer_factory.hpp:77] Creating layer ReLU125
I0816 16:04:07.062187 20404 net.cpp:91] Creating Layer ReLU125
I0816 16:04:07.062196 20404 net.cpp:425] ReLU125 <- InnerProduct53
I0816 16:04:07.062206 20404 net.cpp:386] ReLU125 -> InnerProduct53 (in-place)
I0816 16:04:07.062219 20404 net.cpp:141] Setting up ReLU125
I0816 16:04:07.062229 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.062237 20404 net.cpp:156] Memory required for data: 1941100000
I0816 16:04:07.062244 20404 layer_factory.hpp:77] Creating layer InnerProduct54
I0816 16:04:07.062257 20404 net.cpp:91] Creating Layer InnerProduct54
I0816 16:04:07.062264 20404 net.cpp:425] InnerProduct54 <- InnerProduct53
I0816 16:04:07.062281 20404 net.cpp:399] InnerProduct54 -> InnerProduct54
I0816 16:04:07.062718 20404 net.cpp:141] Setting up InnerProduct54
I0816 16:04:07.062732 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:07.062741 20404 net.cpp:156] Memory required for data: 1941151200
I0816 16:04:07.062749 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:07.062758 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:07.062767 20404 layer_factory.hpp:77] Creating layer ReLU126
I0816 16:04:07.062777 20404 net.cpp:91] Creating Layer ReLU126
I0816 16:04:07.062785 20404 net.cpp:425] ReLU126 <- InnerProduct54
I0816 16:04:07.062796 20404 net.cpp:386] ReLU126 -> InnerProduct54 (in-place)
I0816 16:04:07.062808 20404 net.cpp:141] Setting up ReLU126
I0816 16:04:07.062819 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:07.062825 20404 net.cpp:156] Memory required for data: 1941202400
I0816 16:04:07.062834 20404 layer_factory.hpp:77] Creating layer dt8
I0816 16:04:07.062845 20404 net.cpp:91] Creating Layer dt8
I0816 16:04:07.062854 20404 net.cpp:425] dt8 <- InnerProduct54
I0816 16:04:07.062868 20404 net.cpp:399] dt8 -> dt8
I0816 16:04:07.063045 20404 net.cpp:141] Setting up dt8
I0816 16:04:07.063084 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:07.063112 20404 net.cpp:156] Memory required for data: 1941202800
I0816 16:04:07.063140 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:07.063169 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:07.063199 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:07.063237 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:07.063251 20404 net.cpp:425] conv1 <- p1_p1_0_split_9
I0816 16:04:07.063264 20404 net.cpp:399] conv1 -> Convolution91
I0816 16:04:07.065389 20404 net.cpp:141] Setting up conv1
I0816 16:04:07.065407 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.065415 20404 net.cpp:156] Memory required for data: 1951033200
I0816 16:04:07.065429 20404 layer_factory.hpp:77] Creating layer ReLU127
I0816 16:04:07.065441 20404 net.cpp:91] Creating Layer ReLU127
I0816 16:04:07.065449 20404 net.cpp:425] ReLU127 <- Convolution91
I0816 16:04:07.065461 20404 net.cpp:386] ReLU127 -> Convolution91 (in-place)
I0816 16:04:07.065476 20404 net.cpp:141] Setting up ReLU127
I0816 16:04:07.065487 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.065495 20404 net.cpp:156] Memory required for data: 1960863600
I0816 16:04:07.065501 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:07.065513 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:07.065521 20404 net.cpp:425] norm1 <- Convolution91
I0816 16:04:07.065534 20404 net.cpp:399] norm1 -> LRN37
I0816 16:04:07.065600 20404 net.cpp:141] Setting up norm1
I0816 16:04:07.065613 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.065637 20404 net.cpp:156] Memory required for data: 1970694000
I0816 16:04:07.065645 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:07.065656 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:07.065665 20404 net.cpp:425] pool1 <- LRN37
I0816 16:04:07.065680 20404 net.cpp:399] pool1 -> Pooling55
I0816 16:04:07.065742 20404 net.cpp:141] Setting up pool1
I0816 16:04:07.065757 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:07.065765 20404 net.cpp:156] Memory required for data: 1973151600
I0816 16:04:07.065773 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:07.065793 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:07.065801 20404 net.cpp:425] conv2 <- Pooling55
I0816 16:04:07.065815 20404 net.cpp:399] conv2 -> Convolution92
I0816 16:04:07.081269 20404 net.cpp:141] Setting up conv2
I0816 16:04:07.081291 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.081300 20404 net.cpp:156] Memory required for data: 1979705200
I0816 16:04:07.081323 20404 layer_factory.hpp:77] Creating layer ReLU128
I0816 16:04:07.081336 20404 net.cpp:91] Creating Layer ReLU128
I0816 16:04:07.081346 20404 net.cpp:425] ReLU128 <- Convolution92
I0816 16:04:07.081357 20404 net.cpp:386] ReLU128 -> Convolution92 (in-place)
I0816 16:04:07.081370 20404 net.cpp:141] Setting up ReLU128
I0816 16:04:07.081387 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.081394 20404 net.cpp:156] Memory required for data: 1986258800
I0816 16:04:07.081403 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:07.081416 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:07.081425 20404 net.cpp:425] norm2 <- Convolution92
I0816 16:04:07.081440 20404 net.cpp:399] norm2 -> LRN38
I0816 16:04:07.081506 20404 net.cpp:141] Setting up norm2
I0816 16:04:07.081521 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.081528 20404 net.cpp:156] Memory required for data: 1992812400
I0816 16:04:07.081535 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:07.081548 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:07.081557 20404 net.cpp:425] pool2 <- LRN38
I0816 16:04:07.081569 20404 net.cpp:399] pool2 -> Pooling56
I0816 16:04:07.081634 20404 net.cpp:141] Setting up pool2
I0816 16:04:07.081648 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.081655 20404 net.cpp:156] Memory required for data: 1994450800
I0816 16:04:07.081663 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:07.081681 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:07.081691 20404 net.cpp:425] conv3 <- Pooling56
I0816 16:04:07.081707 20404 net.cpp:399] conv3 -> Convolution93
I0816 16:04:07.125701 20404 net.cpp:141] Setting up conv3
I0816 16:04:07.125736 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.125756 20404 net.cpp:156] Memory required for data: 1996908400
I0816 16:04:07.125773 20404 layer_factory.hpp:77] Creating layer ReLU129
I0816 16:04:07.125788 20404 net.cpp:91] Creating Layer ReLU129
I0816 16:04:07.125803 20404 net.cpp:425] ReLU129 <- Convolution93
I0816 16:04:07.125826 20404 net.cpp:386] ReLU129 -> Convolution93 (in-place)
I0816 16:04:07.125844 20404 net.cpp:141] Setting up ReLU129
I0816 16:04:07.125854 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.125861 20404 net.cpp:156] Memory required for data: 1999366000
I0816 16:04:07.125869 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:07.125890 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:07.125905 20404 net.cpp:425] conv4 <- Convolution93
I0816 16:04:07.125918 20404 net.cpp:399] conv4 -> Convolution94
I0816 16:04:07.159204 20404 net.cpp:141] Setting up conv4
I0816 16:04:07.159235 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.159245 20404 net.cpp:156] Memory required for data: 2001823600
I0816 16:04:07.159261 20404 layer_factory.hpp:77] Creating layer ReLU130
I0816 16:04:07.159296 20404 net.cpp:91] Creating Layer ReLU130
I0816 16:04:07.159308 20404 net.cpp:425] ReLU130 <- Convolution94
I0816 16:04:07.159322 20404 net.cpp:386] ReLU130 -> Convolution94 (in-place)
I0816 16:04:07.159355 20404 net.cpp:141] Setting up ReLU130
I0816 16:04:07.159368 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.159378 20404 net.cpp:156] Memory required for data: 2004281200
I0816 16:04:07.159385 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:07.159405 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:07.159416 20404 net.cpp:425] conv5 <- Convolution94
I0816 16:04:07.159433 20404 net.cpp:399] conv5 -> Convolution95
I0816 16:04:07.181519 20404 net.cpp:141] Setting up conv5
I0816 16:04:07.181542 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.181550 20404 net.cpp:156] Memory required for data: 2005919600
I0816 16:04:07.181574 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:07.181592 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:07.181602 20404 net.cpp:425] pool5 <- Convolution95
I0816 16:04:07.181617 20404 net.cpp:399] pool5 -> Pooling57
I0816 16:04:07.181695 20404 net.cpp:141] Setting up pool5
I0816 16:04:07.181710 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:07.181716 20404 net.cpp:156] Memory required for data: 2006329200
I0816 16:04:07.181725 20404 layer_factory.hpp:77] Creating layer InnerProduct55
I0816 16:04:07.181742 20404 net.cpp:91] Creating Layer InnerProduct55
I0816 16:04:07.181751 20404 net.cpp:425] InnerProduct55 <- Pooling57
I0816 16:04:07.181766 20404 net.cpp:399] InnerProduct55 -> InnerProduct55
I0816 16:04:07.184494 20404 net.cpp:141] Setting up InnerProduct55
I0816 16:04:07.184514 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.184530 20404 net.cpp:156] Memory required for data: 2006431600
I0816 16:04:07.184540 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:07.184551 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:07.184558 20404 layer_factory.hpp:77] Creating layer ReLU131
I0816 16:04:07.184568 20404 net.cpp:91] Creating Layer ReLU131
I0816 16:04:07.184578 20404 net.cpp:425] ReLU131 <- InnerProduct55
I0816 16:04:07.184599 20404 net.cpp:386] ReLU131 -> InnerProduct55 (in-place)
I0816 16:04:07.184613 20404 net.cpp:141] Setting up ReLU131
I0816 16:04:07.184623 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.184631 20404 net.cpp:156] Memory required for data: 2006534000
I0816 16:04:07.184638 20404 layer_factory.hpp:77] Creating layer InnerProduct56
I0816 16:04:07.184653 20404 net.cpp:91] Creating Layer InnerProduct56
I0816 16:04:07.184660 20404 net.cpp:425] InnerProduct56 <- InnerProduct55
I0816 16:04:07.184675 20404 net.cpp:399] InnerProduct56 -> InnerProduct56
I0816 16:04:07.185382 20404 net.cpp:141] Setting up InnerProduct56
I0816 16:04:07.185396 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.185405 20404 net.cpp:156] Memory required for data: 2006636400
I0816 16:04:07.185413 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:07.185422 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:07.185431 20404 layer_factory.hpp:77] Creating layer ReLU132
I0816 16:04:07.185441 20404 net.cpp:91] Creating Layer ReLU132
I0816 16:04:07.185449 20404 net.cpp:425] ReLU132 <- InnerProduct56
I0816 16:04:07.185461 20404 net.cpp:386] ReLU132 -> InnerProduct56 (in-place)
I0816 16:04:07.185473 20404 net.cpp:141] Setting up ReLU132
I0816 16:04:07.185482 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.185489 20404 net.cpp:156] Memory required for data: 2006738800
I0816 16:04:07.185497 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:07.185516 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:07.185526 20404 net.cpp:425] conv1 <- c29
I0816 16:04:07.185544 20404 net.cpp:399] conv1 -> Convolution96
I0816 16:04:07.187700 20404 net.cpp:141] Setting up conv1
I0816 16:04:07.187719 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.187727 20404 net.cpp:156] Memory required for data: 2016569200
I0816 16:04:07.187741 20404 layer_factory.hpp:77] Creating layer ReLU133
I0816 16:04:07.187767 20404 net.cpp:91] Creating Layer ReLU133
I0816 16:04:07.187777 20404 net.cpp:425] ReLU133 <- Convolution96
I0816 16:04:07.187788 20404 net.cpp:386] ReLU133 -> Convolution96 (in-place)
I0816 16:04:07.187803 20404 net.cpp:141] Setting up ReLU133
I0816 16:04:07.187813 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.187819 20404 net.cpp:156] Memory required for data: 2026399600
I0816 16:04:07.187827 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:07.187841 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:07.187850 20404 net.cpp:425] norm1 <- Convolution96
I0816 16:04:07.187863 20404 net.cpp:399] norm1 -> LRN39
I0816 16:04:07.187922 20404 net.cpp:141] Setting up norm1
I0816 16:04:07.187937 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.187944 20404 net.cpp:156] Memory required for data: 2036230000
I0816 16:04:07.187952 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:07.187963 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:07.187970 20404 net.cpp:425] pool1 <- LRN39
I0816 16:04:07.187984 20404 net.cpp:399] pool1 -> Pooling58
I0816 16:04:07.188046 20404 net.cpp:141] Setting up pool1
I0816 16:04:07.188060 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:07.188066 20404 net.cpp:156] Memory required for data: 2038687600
I0816 16:04:07.188073 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:07.188097 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:07.188109 20404 net.cpp:425] conv2 <- Pooling58
I0816 16:04:07.188122 20404 net.cpp:399] conv2 -> Convolution97
I0816 16:04:07.203891 20404 net.cpp:141] Setting up conv2
I0816 16:04:07.203915 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.203933 20404 net.cpp:156] Memory required for data: 2045241200
I0816 16:04:07.203946 20404 layer_factory.hpp:77] Creating layer ReLU134
I0816 16:04:07.203959 20404 net.cpp:91] Creating Layer ReLU134
I0816 16:04:07.203969 20404 net.cpp:425] ReLU134 <- Convolution97
I0816 16:04:07.203980 20404 net.cpp:386] ReLU134 -> Convolution97 (in-place)
I0816 16:04:07.204004 20404 net.cpp:141] Setting up ReLU134
I0816 16:04:07.204013 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.204021 20404 net.cpp:156] Memory required for data: 2051794800
I0816 16:04:07.204030 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:07.204043 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:07.204053 20404 net.cpp:425] norm2 <- Convolution97
I0816 16:04:07.204069 20404 net.cpp:399] norm2 -> LRN40
I0816 16:04:07.204134 20404 net.cpp:141] Setting up norm2
I0816 16:04:07.204149 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.204155 20404 net.cpp:156] Memory required for data: 2058348400
I0816 16:04:07.204164 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:07.204177 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:07.204185 20404 net.cpp:425] pool2 <- LRN40
I0816 16:04:07.204197 20404 net.cpp:399] pool2 -> Pooling59
I0816 16:04:07.204264 20404 net.cpp:141] Setting up pool2
I0816 16:04:07.204278 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.204285 20404 net.cpp:156] Memory required for data: 2059986800
I0816 16:04:07.204293 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:07.204313 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:07.204326 20404 net.cpp:425] conv3 <- Pooling59
I0816 16:04:07.204342 20404 net.cpp:399] conv3 -> Convolution98
I0816 16:04:07.248147 20404 net.cpp:141] Setting up conv3
I0816 16:04:07.248178 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.248196 20404 net.cpp:156] Memory required for data: 2062444400
I0816 16:04:07.248214 20404 layer_factory.hpp:77] Creating layer ReLU135
I0816 16:04:07.248227 20404 net.cpp:91] Creating Layer ReLU135
I0816 16:04:07.248239 20404 net.cpp:425] ReLU135 <- Convolution98
I0816 16:04:07.248265 20404 net.cpp:386] ReLU135 -> Convolution98 (in-place)
I0816 16:04:07.248281 20404 net.cpp:141] Setting up ReLU135
I0816 16:04:07.248292 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.248320 20404 net.cpp:156] Memory required for data: 2064902000
I0816 16:04:07.248329 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:07.248349 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:07.248358 20404 net.cpp:425] conv4 <- Convolution98
I0816 16:04:07.248373 20404 net.cpp:399] conv4 -> Convolution99
I0816 16:04:07.281689 20404 net.cpp:141] Setting up conv4
I0816 16:04:07.281718 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.281736 20404 net.cpp:156] Memory required for data: 2067359600
I0816 16:04:07.281752 20404 layer_factory.hpp:77] Creating layer ReLU136
I0816 16:04:07.281770 20404 net.cpp:91] Creating Layer ReLU136
I0816 16:04:07.281781 20404 net.cpp:425] ReLU136 <- Convolution99
I0816 16:04:07.281803 20404 net.cpp:386] ReLU136 -> Convolution99 (in-place)
I0816 16:04:07.281819 20404 net.cpp:141] Setting up ReLU136
I0816 16:04:07.281831 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.281837 20404 net.cpp:156] Memory required for data: 2069817200
I0816 16:04:07.281846 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:07.281865 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:07.281873 20404 net.cpp:425] conv5 <- Convolution99
I0816 16:04:07.281890 20404 net.cpp:399] conv5 -> Convolution100
I0816 16:04:07.303925 20404 net.cpp:141] Setting up conv5
I0816 16:04:07.303948 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.303956 20404 net.cpp:156] Memory required for data: 2071455600
I0816 16:04:07.303978 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:07.303997 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:07.304006 20404 net.cpp:425] pool5 <- Convolution100
I0816 16:04:07.304021 20404 net.cpp:399] pool5 -> Pooling60
I0816 16:04:07.304102 20404 net.cpp:141] Setting up pool5
I0816 16:04:07.304116 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:07.304123 20404 net.cpp:156] Memory required for data: 2071865200
I0816 16:04:07.304131 20404 layer_factory.hpp:77] Creating layer InnerProduct57
I0816 16:04:07.304148 20404 net.cpp:91] Creating Layer InnerProduct57
I0816 16:04:07.304157 20404 net.cpp:425] InnerProduct57 <- Pooling60
I0816 16:04:07.304172 20404 net.cpp:399] InnerProduct57 -> InnerProduct57
I0816 16:04:07.306885 20404 net.cpp:141] Setting up InnerProduct57
I0816 16:04:07.306906 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.306923 20404 net.cpp:156] Memory required for data: 2071967600
I0816 16:04:07.306933 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:07.306943 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:07.306951 20404 layer_factory.hpp:77] Creating layer ReLU137
I0816 16:04:07.306962 20404 net.cpp:91] Creating Layer ReLU137
I0816 16:04:07.306972 20404 net.cpp:425] ReLU137 <- InnerProduct57
I0816 16:04:07.306996 20404 net.cpp:386] ReLU137 -> InnerProduct57 (in-place)
I0816 16:04:07.307010 20404 net.cpp:141] Setting up ReLU137
I0816 16:04:07.307020 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.307027 20404 net.cpp:156] Memory required for data: 2072070000
I0816 16:04:07.307035 20404 layer_factory.hpp:77] Creating layer InnerProduct58
I0816 16:04:07.307049 20404 net.cpp:91] Creating Layer InnerProduct58
I0816 16:04:07.307057 20404 net.cpp:425] InnerProduct58 <- InnerProduct57
I0816 16:04:07.307072 20404 net.cpp:399] InnerProduct58 -> InnerProduct58
I0816 16:04:07.307796 20404 net.cpp:141] Setting up InnerProduct58
I0816 16:04:07.307809 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.307817 20404 net.cpp:156] Memory required for data: 2072172400
I0816 16:04:07.307829 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:07.307839 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:07.307847 20404 layer_factory.hpp:77] Creating layer ReLU138
I0816 16:04:07.307857 20404 net.cpp:91] Creating Layer ReLU138
I0816 16:04:07.307885 20404 net.cpp:425] ReLU138 <- InnerProduct58
I0816 16:04:07.307898 20404 net.cpp:386] ReLU138 -> InnerProduct58 (in-place)
I0816 16:04:07.307910 20404 net.cpp:141] Setting up ReLU138
I0816 16:04:07.307920 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.307929 20404 net.cpp:156] Memory required for data: 2072274800
I0816 16:04:07.307935 20404 layer_factory.hpp:77] Creating layer Concat10
I0816 16:04:07.307948 20404 net.cpp:91] Creating Layer Concat10
I0816 16:04:07.307956 20404 net.cpp:425] Concat10 <- InnerProduct56
I0816 16:04:07.307966 20404 net.cpp:425] Concat10 <- InnerProduct58
I0816 16:04:07.307981 20404 net.cpp:399] Concat10 -> Concat10
I0816 16:04:07.308024 20404 net.cpp:141] Setting up Concat10
I0816 16:04:07.308038 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:07.308046 20404 net.cpp:156] Memory required for data: 2072479600
I0816 16:04:07.308053 20404 layer_factory.hpp:77] Creating layer InnerProduct59
I0816 16:04:07.308065 20404 net.cpp:91] Creating Layer InnerProduct59
I0816 16:04:07.308073 20404 net.cpp:425] InnerProduct59 <- Concat10
I0816 16:04:07.308090 20404 net.cpp:399] InnerProduct59 -> InnerProduct59
I0816 16:04:07.309844 20404 net.cpp:141] Setting up InnerProduct59
I0816 16:04:07.309865 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.309872 20404 net.cpp:156] Memory required for data: 2072582000
I0816 16:04:07.309882 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:07.309892 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:07.309900 20404 layer_factory.hpp:77] Creating layer ReLU139
I0816 16:04:07.309916 20404 net.cpp:91] Creating Layer ReLU139
I0816 16:04:07.309926 20404 net.cpp:425] ReLU139 <- InnerProduct59
I0816 16:04:07.309937 20404 net.cpp:386] ReLU139 -> InnerProduct59 (in-place)
I0816 16:04:07.309952 20404 net.cpp:141] Setting up ReLU139
I0816 16:04:07.309962 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.309969 20404 net.cpp:156] Memory required for data: 2072684400
I0816 16:04:07.309976 20404 layer_factory.hpp:77] Creating layer InnerProduct60
I0816 16:04:07.309989 20404 net.cpp:91] Creating Layer InnerProduct60
I0816 16:04:07.309998 20404 net.cpp:425] InnerProduct60 <- InnerProduct59
I0816 16:04:07.310014 20404 net.cpp:399] InnerProduct60 -> InnerProduct60
I0816 16:04:07.310482 20404 net.cpp:141] Setting up InnerProduct60
I0816 16:04:07.310524 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:07.310552 20404 net.cpp:156] Memory required for data: 2072735600
I0816 16:04:07.310581 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:07.310612 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:07.310641 20404 layer_factory.hpp:77] Creating layer ReLU140
I0816 16:04:07.310673 20404 net.cpp:91] Creating Layer ReLU140
I0816 16:04:07.310701 20404 net.cpp:425] ReLU140 <- InnerProduct60
I0816 16:04:07.310717 20404 net.cpp:386] ReLU140 -> InnerProduct60 (in-place)
I0816 16:04:07.310731 20404 net.cpp:141] Setting up ReLU140
I0816 16:04:07.310741 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:07.310750 20404 net.cpp:156] Memory required for data: 2072786800
I0816 16:04:07.310756 20404 layer_factory.hpp:77] Creating layer dt9
I0816 16:04:07.310770 20404 net.cpp:91] Creating Layer dt9
I0816 16:04:07.310777 20404 net.cpp:425] dt9 <- InnerProduct60
I0816 16:04:07.310791 20404 net.cpp:399] dt9 -> dt9
I0816 16:04:07.310961 20404 net.cpp:141] Setting up dt9
I0816 16:04:07.310976 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:07.310984 20404 net.cpp:156] Memory required for data: 2072787200
I0816 16:04:07.310992 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:07.311002 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:07.311010 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:07.311030 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:07.311058 20404 net.cpp:425] conv1 <- p2_p2_0_split_1
I0816 16:04:07.311072 20404 net.cpp:399] conv1 -> Convolution101
I0816 16:04:07.313200 20404 net.cpp:141] Setting up conv1
I0816 16:04:07.313215 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.313223 20404 net.cpp:156] Memory required for data: 2082617600
I0816 16:04:07.313237 20404 layer_factory.hpp:77] Creating layer ReLU141
I0816 16:04:07.313247 20404 net.cpp:91] Creating Layer ReLU141
I0816 16:04:07.313256 20404 net.cpp:425] ReLU141 <- Convolution101
I0816 16:04:07.313266 20404 net.cpp:386] ReLU141 -> Convolution101 (in-place)
I0816 16:04:07.313279 20404 net.cpp:141] Setting up ReLU141
I0816 16:04:07.313289 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.313297 20404 net.cpp:156] Memory required for data: 2092448000
I0816 16:04:07.313304 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:07.313319 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:07.313328 20404 net.cpp:425] norm1 <- Convolution101
I0816 16:04:07.313340 20404 net.cpp:399] norm1 -> LRN41
I0816 16:04:07.313400 20404 net.cpp:141] Setting up norm1
I0816 16:04:07.313413 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.313421 20404 net.cpp:156] Memory required for data: 2102278400
I0816 16:04:07.313428 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:07.313438 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:07.313447 20404 net.cpp:425] pool1 <- LRN41
I0816 16:04:07.313462 20404 net.cpp:399] pool1 -> Pooling61
I0816 16:04:07.313524 20404 net.cpp:141] Setting up pool1
I0816 16:04:07.313539 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:07.313545 20404 net.cpp:156] Memory required for data: 2104736000
I0816 16:04:07.313552 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:07.313575 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:07.313586 20404 net.cpp:425] conv2 <- Pooling61
I0816 16:04:07.313601 20404 net.cpp:399] conv2 -> Convolution102
I0816 16:04:07.329177 20404 net.cpp:141] Setting up conv2
I0816 16:04:07.329201 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.329210 20404 net.cpp:156] Memory required for data: 2111289600
I0816 16:04:07.329236 20404 layer_factory.hpp:77] Creating layer ReLU142
I0816 16:04:07.329248 20404 net.cpp:91] Creating Layer ReLU142
I0816 16:04:07.329257 20404 net.cpp:425] ReLU142 <- Convolution102
I0816 16:04:07.329269 20404 net.cpp:386] ReLU142 -> Convolution102 (in-place)
I0816 16:04:07.329283 20404 net.cpp:141] Setting up ReLU142
I0816 16:04:07.329299 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.329306 20404 net.cpp:156] Memory required for data: 2117843200
I0816 16:04:07.329314 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:07.329329 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:07.329337 20404 net.cpp:425] norm2 <- Convolution102
I0816 16:04:07.329354 20404 net.cpp:399] norm2 -> LRN42
I0816 16:04:07.329418 20404 net.cpp:141] Setting up norm2
I0816 16:04:07.329432 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.329440 20404 net.cpp:156] Memory required for data: 2124396800
I0816 16:04:07.329447 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:07.329460 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:07.329469 20404 net.cpp:425] pool2 <- LRN42
I0816 16:04:07.329480 20404 net.cpp:399] pool2 -> Pooling62
I0816 16:04:07.329548 20404 net.cpp:141] Setting up pool2
I0816 16:04:07.329562 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.329571 20404 net.cpp:156] Memory required for data: 2126035200
I0816 16:04:07.329577 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:07.329596 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:07.329604 20404 net.cpp:425] conv3 <- Pooling62
I0816 16:04:07.329620 20404 net.cpp:399] conv3 -> Convolution103
I0816 16:04:07.373486 20404 net.cpp:141] Setting up conv3
I0816 16:04:07.373518 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.373538 20404 net.cpp:156] Memory required for data: 2128492800
I0816 16:04:07.373574 20404 layer_factory.hpp:77] Creating layer ReLU143
I0816 16:04:07.373591 20404 net.cpp:91] Creating Layer ReLU143
I0816 16:04:07.373610 20404 net.cpp:425] ReLU143 <- Convolution103
I0816 16:04:07.373625 20404 net.cpp:386] ReLU143 -> Convolution103 (in-place)
I0816 16:04:07.373647 20404 net.cpp:141] Setting up ReLU143
I0816 16:04:07.373661 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.373667 20404 net.cpp:156] Memory required for data: 2130950400
I0816 16:04:07.373675 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:07.373697 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:07.373706 20404 net.cpp:425] conv4 <- Convolution103
I0816 16:04:07.373720 20404 net.cpp:399] conv4 -> Convolution104
I0816 16:04:07.406985 20404 net.cpp:141] Setting up conv4
I0816 16:04:07.407013 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.407021 20404 net.cpp:156] Memory required for data: 2133408000
I0816 16:04:07.407037 20404 layer_factory.hpp:77] Creating layer ReLU144
I0816 16:04:07.407055 20404 net.cpp:91] Creating Layer ReLU144
I0816 16:04:07.407066 20404 net.cpp:425] ReLU144 <- Convolution104
I0816 16:04:07.407078 20404 net.cpp:386] ReLU144 -> Convolution104 (in-place)
I0816 16:04:07.407094 20404 net.cpp:141] Setting up ReLU144
I0816 16:04:07.407104 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.407112 20404 net.cpp:156] Memory required for data: 2135865600
I0816 16:04:07.407119 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:07.407140 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:07.407148 20404 net.cpp:425] conv5 <- Convolution104
I0816 16:04:07.407165 20404 net.cpp:399] conv5 -> Convolution105
I0816 16:04:07.429301 20404 net.cpp:141] Setting up conv5
I0816 16:04:07.429324 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.429333 20404 net.cpp:156] Memory required for data: 2137504000
I0816 16:04:07.429348 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:07.429370 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:07.429380 20404 net.cpp:425] pool5 <- Convolution105
I0816 16:04:07.429394 20404 net.cpp:399] pool5 -> Pooling63
I0816 16:04:07.429467 20404 net.cpp:141] Setting up pool5
I0816 16:04:07.429482 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:07.429489 20404 net.cpp:156] Memory required for data: 2137913600
I0816 16:04:07.429497 20404 layer_factory.hpp:77] Creating layer InnerProduct61
I0816 16:04:07.429514 20404 net.cpp:91] Creating Layer InnerProduct61
I0816 16:04:07.429522 20404 net.cpp:425] InnerProduct61 <- Pooling63
I0816 16:04:07.429538 20404 net.cpp:399] InnerProduct61 -> InnerProduct61
I0816 16:04:07.432267 20404 net.cpp:141] Setting up InnerProduct61
I0816 16:04:07.432288 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.432306 20404 net.cpp:156] Memory required for data: 2138016000
I0816 16:04:07.432314 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:07.432324 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:07.432332 20404 layer_factory.hpp:77] Creating layer ReLU145
I0816 16:04:07.432348 20404 net.cpp:91] Creating Layer ReLU145
I0816 16:04:07.432355 20404 net.cpp:425] ReLU145 <- InnerProduct61
I0816 16:04:07.432374 20404 net.cpp:386] ReLU145 -> InnerProduct61 (in-place)
I0816 16:04:07.432387 20404 net.cpp:141] Setting up ReLU145
I0816 16:04:07.432397 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.432405 20404 net.cpp:156] Memory required for data: 2138118400
I0816 16:04:07.432412 20404 layer_factory.hpp:77] Creating layer InnerProduct62
I0816 16:04:07.432428 20404 net.cpp:91] Creating Layer InnerProduct62
I0816 16:04:07.432437 20404 net.cpp:425] InnerProduct62 <- InnerProduct61
I0816 16:04:07.432449 20404 net.cpp:399] InnerProduct62 -> InnerProduct62
I0816 16:04:07.433171 20404 net.cpp:141] Setting up InnerProduct62
I0816 16:04:07.433185 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.433223 20404 net.cpp:156] Memory required for data: 2138220800
I0816 16:04:07.433231 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:07.433241 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:07.433249 20404 layer_factory.hpp:77] Creating layer ReLU146
I0816 16:04:07.433260 20404 net.cpp:91] Creating Layer ReLU146
I0816 16:04:07.433269 20404 net.cpp:425] ReLU146 <- InnerProduct62
I0816 16:04:07.433279 20404 net.cpp:386] ReLU146 -> InnerProduct62 (in-place)
I0816 16:04:07.433291 20404 net.cpp:141] Setting up ReLU146
I0816 16:04:07.433301 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.433310 20404 net.cpp:156] Memory required for data: 2138323200
I0816 16:04:07.433317 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:07.433339 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:07.433348 20404 net.cpp:425] conv1 <- c11
I0816 16:04:07.433362 20404 net.cpp:399] conv1 -> Convolution106
I0816 16:04:07.435470 20404 net.cpp:141] Setting up conv1
I0816 16:04:07.435485 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.435493 20404 net.cpp:156] Memory required for data: 2148153600
I0816 16:04:07.435506 20404 layer_factory.hpp:77] Creating layer ReLU147
I0816 16:04:07.435518 20404 net.cpp:91] Creating Layer ReLU147
I0816 16:04:07.435526 20404 net.cpp:425] ReLU147 <- Convolution106
I0816 16:04:07.435540 20404 net.cpp:386] ReLU147 -> Convolution106 (in-place)
I0816 16:04:07.435554 20404 net.cpp:141] Setting up ReLU147
I0816 16:04:07.435564 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.435571 20404 net.cpp:156] Memory required for data: 2157984000
I0816 16:04:07.435578 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:07.435590 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:07.435598 20404 net.cpp:425] norm1 <- Convolution106
I0816 16:04:07.435614 20404 net.cpp:399] norm1 -> LRN43
I0816 16:04:07.435670 20404 net.cpp:141] Setting up norm1
I0816 16:04:07.435684 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.435691 20404 net.cpp:156] Memory required for data: 2167814400
I0816 16:04:07.435698 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:07.435712 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:07.435721 20404 net.cpp:425] pool1 <- LRN43
I0816 16:04:07.435732 20404 net.cpp:399] pool1 -> Pooling64
I0816 16:04:07.435811 20404 net.cpp:141] Setting up pool1
I0816 16:04:07.435848 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:07.435876 20404 net.cpp:156] Memory required for data: 2170272000
I0816 16:04:07.435904 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:07.435941 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:07.435969 20404 net.cpp:425] conv2 <- Pooling64
I0816 16:04:07.436002 20404 net.cpp:399] conv2 -> Convolution107
I0816 16:04:07.451766 20404 net.cpp:141] Setting up conv2
I0816 16:04:07.451788 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.451797 20404 net.cpp:156] Memory required for data: 2176825600
I0816 16:04:07.451808 20404 layer_factory.hpp:77] Creating layer ReLU148
I0816 16:04:07.451819 20404 net.cpp:91] Creating Layer ReLU148
I0816 16:04:07.451828 20404 net.cpp:425] ReLU148 <- Convolution107
I0816 16:04:07.451838 20404 net.cpp:386] ReLU148 -> Convolution107 (in-place)
I0816 16:04:07.451848 20404 net.cpp:141] Setting up ReLU148
I0816 16:04:07.451856 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.451863 20404 net.cpp:156] Memory required for data: 2183379200
I0816 16:04:07.451867 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:07.451880 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:07.451886 20404 net.cpp:425] norm2 <- Convolution107
I0816 16:04:07.451899 20404 net.cpp:399] norm2 -> LRN44
I0816 16:04:07.451956 20404 net.cpp:141] Setting up norm2
I0816 16:04:07.451967 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.451974 20404 net.cpp:156] Memory required for data: 2189932800
I0816 16:04:07.451997 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:07.452008 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:07.452014 20404 net.cpp:425] pool2 <- LRN44
I0816 16:04:07.452024 20404 net.cpp:399] pool2 -> Pooling65
I0816 16:04:07.452083 20404 net.cpp:141] Setting up pool2
I0816 16:04:07.452093 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.452101 20404 net.cpp:156] Memory required for data: 2191571200
I0816 16:04:07.452107 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:07.452121 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:07.452128 20404 net.cpp:425] conv3 <- Pooling65
I0816 16:04:07.452141 20404 net.cpp:399] conv3 -> Convolution108
I0816 16:04:07.495960 20404 net.cpp:141] Setting up conv3
I0816 16:04:07.495987 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.495995 20404 net.cpp:156] Memory required for data: 2194028800
I0816 16:04:07.496007 20404 layer_factory.hpp:77] Creating layer ReLU149
I0816 16:04:07.496021 20404 net.cpp:91] Creating Layer ReLU149
I0816 16:04:07.496031 20404 net.cpp:425] ReLU149 <- Convolution108
I0816 16:04:07.496040 20404 net.cpp:386] ReLU149 -> Convolution108 (in-place)
I0816 16:04:07.496063 20404 net.cpp:141] Setting up ReLU149
I0816 16:04:07.496075 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.496083 20404 net.cpp:156] Memory required for data: 2196486400
I0816 16:04:07.496090 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:07.496111 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:07.496120 20404 net.cpp:425] conv4 <- Convolution108
I0816 16:04:07.496134 20404 net.cpp:399] conv4 -> Convolution109
I0816 16:04:07.529252 20404 net.cpp:141] Setting up conv4
I0816 16:04:07.529279 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.529287 20404 net.cpp:156] Memory required for data: 2198944000
I0816 16:04:07.529305 20404 layer_factory.hpp:77] Creating layer ReLU150
I0816 16:04:07.529322 20404 net.cpp:91] Creating Layer ReLU150
I0816 16:04:07.529335 20404 net.cpp:425] ReLU150 <- Convolution109
I0816 16:04:07.529347 20404 net.cpp:386] ReLU150 -> Convolution109 (in-place)
I0816 16:04:07.529362 20404 net.cpp:141] Setting up ReLU150
I0816 16:04:07.529372 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.529381 20404 net.cpp:156] Memory required for data: 2201401600
I0816 16:04:07.529388 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:07.529407 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:07.529417 20404 net.cpp:425] conv5 <- Convolution109
I0816 16:04:07.529433 20404 net.cpp:399] conv5 -> Convolution110
I0816 16:04:07.551477 20404 net.cpp:141] Setting up conv5
I0816 16:04:07.551501 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.551509 20404 net.cpp:156] Memory required for data: 2203040000
I0816 16:04:07.551524 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:07.551548 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:07.551558 20404 net.cpp:425] pool5 <- Convolution110
I0816 16:04:07.551571 20404 net.cpp:399] pool5 -> Pooling66
I0816 16:04:07.551645 20404 net.cpp:141] Setting up pool5
I0816 16:04:07.551658 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:07.551666 20404 net.cpp:156] Memory required for data: 2203449600
I0816 16:04:07.551673 20404 layer_factory.hpp:77] Creating layer InnerProduct63
I0816 16:04:07.551690 20404 net.cpp:91] Creating Layer InnerProduct63
I0816 16:04:07.551699 20404 net.cpp:425] InnerProduct63 <- Pooling66
I0816 16:04:07.551713 20404 net.cpp:399] InnerProduct63 -> InnerProduct63
I0816 16:04:07.554424 20404 net.cpp:141] Setting up InnerProduct63
I0816 16:04:07.554443 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.554461 20404 net.cpp:156] Memory required for data: 2203552000
I0816 16:04:07.554471 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:07.554481 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:07.554488 20404 layer_factory.hpp:77] Creating layer ReLU151
I0816 16:04:07.554533 20404 net.cpp:91] Creating Layer ReLU151
I0816 16:04:07.554543 20404 net.cpp:425] ReLU151 <- InnerProduct63
I0816 16:04:07.554554 20404 net.cpp:386] ReLU151 -> InnerProduct63 (in-place)
I0816 16:04:07.554569 20404 net.cpp:141] Setting up ReLU151
I0816 16:04:07.554579 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.554586 20404 net.cpp:156] Memory required for data: 2203654400
I0816 16:04:07.554594 20404 layer_factory.hpp:77] Creating layer InnerProduct64
I0816 16:04:07.554610 20404 net.cpp:91] Creating Layer InnerProduct64
I0816 16:04:07.554617 20404 net.cpp:425] InnerProduct64 <- InnerProduct63
I0816 16:04:07.554630 20404 net.cpp:399] InnerProduct64 -> InnerProduct64
I0816 16:04:07.555357 20404 net.cpp:141] Setting up InnerProduct64
I0816 16:04:07.555372 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.555380 20404 net.cpp:156] Memory required for data: 2203756800
I0816 16:04:07.555388 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:07.555398 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:07.555407 20404 layer_factory.hpp:77] Creating layer ReLU152
I0816 16:04:07.555418 20404 net.cpp:91] Creating Layer ReLU152
I0816 16:04:07.555425 20404 net.cpp:425] ReLU152 <- InnerProduct64
I0816 16:04:07.555436 20404 net.cpp:386] ReLU152 -> InnerProduct64 (in-place)
I0816 16:04:07.555449 20404 net.cpp:141] Setting up ReLU152
I0816 16:04:07.555459 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.555466 20404 net.cpp:156] Memory required for data: 2203859200
I0816 16:04:07.555474 20404 layer_factory.hpp:77] Creating layer Concat11
I0816 16:04:07.555485 20404 net.cpp:91] Creating Layer Concat11
I0816 16:04:07.555493 20404 net.cpp:425] Concat11 <- InnerProduct62
I0816 16:04:07.555503 20404 net.cpp:425] Concat11 <- InnerProduct64
I0816 16:04:07.555521 20404 net.cpp:399] Concat11 -> Concat11
I0816 16:04:07.555564 20404 net.cpp:141] Setting up Concat11
I0816 16:04:07.555577 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:07.555585 20404 net.cpp:156] Memory required for data: 2204064000
I0816 16:04:07.555593 20404 layer_factory.hpp:77] Creating layer InnerProduct65
I0816 16:04:07.555604 20404 net.cpp:91] Creating Layer InnerProduct65
I0816 16:04:07.555613 20404 net.cpp:425] InnerProduct65 <- Concat11
I0816 16:04:07.555629 20404 net.cpp:399] InnerProduct65 -> InnerProduct65
I0816 16:04:07.556885 20404 net.cpp:141] Setting up InnerProduct65
I0816 16:04:07.556931 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.556958 20404 net.cpp:156] Memory required for data: 2204166400
I0816 16:04:07.556988 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:07.557016 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:07.557044 20404 layer_factory.hpp:77] Creating layer ReLU153
I0816 16:04:07.557073 20404 net.cpp:91] Creating Layer ReLU153
I0816 16:04:07.557101 20404 net.cpp:425] ReLU153 <- InnerProduct65
I0816 16:04:07.557134 20404 net.cpp:386] ReLU153 -> InnerProduct65 (in-place)
I0816 16:04:07.557169 20404 net.cpp:141] Setting up ReLU153
I0816 16:04:07.557183 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.557191 20404 net.cpp:156] Memory required for data: 2204268800
I0816 16:04:07.557199 20404 layer_factory.hpp:77] Creating layer InnerProduct66
I0816 16:04:07.557211 20404 net.cpp:91] Creating Layer InnerProduct66
I0816 16:04:07.557220 20404 net.cpp:425] InnerProduct66 <- InnerProduct65
I0816 16:04:07.557236 20404 net.cpp:399] InnerProduct66 -> InnerProduct66
I0816 16:04:07.557703 20404 net.cpp:141] Setting up InnerProduct66
I0816 16:04:07.557718 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:07.557725 20404 net.cpp:156] Memory required for data: 2204320000
I0816 16:04:07.557734 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:07.557744 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:07.557767 20404 layer_factory.hpp:77] Creating layer ReLU154
I0816 16:04:07.557780 20404 net.cpp:91] Creating Layer ReLU154
I0816 16:04:07.557787 20404 net.cpp:425] ReLU154 <- InnerProduct66
I0816 16:04:07.557798 20404 net.cpp:386] ReLU154 -> InnerProduct66 (in-place)
I0816 16:04:07.557811 20404 net.cpp:141] Setting up ReLU154
I0816 16:04:07.557821 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:07.557827 20404 net.cpp:156] Memory required for data: 2204371200
I0816 16:04:07.557835 20404 layer_factory.hpp:77] Creating layer dt10
I0816 16:04:07.557850 20404 net.cpp:91] Creating Layer dt10
I0816 16:04:07.557858 20404 net.cpp:425] dt10 <- InnerProduct66
I0816 16:04:07.557871 20404 net.cpp:399] dt10 -> dt10
I0816 16:04:07.558035 20404 net.cpp:141] Setting up dt10
I0816 16:04:07.558050 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:07.558058 20404 net.cpp:156] Memory required for data: 2204371600
I0816 16:04:07.558066 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:07.558076 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:07.558084 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:07.558099 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:07.558109 20404 net.cpp:425] conv1 <- p2_p2_0_split_2
I0816 16:04:07.558125 20404 net.cpp:399] conv1 -> Convolution111
I0816 16:04:07.560255 20404 net.cpp:141] Setting up conv1
I0816 16:04:07.560271 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.560277 20404 net.cpp:156] Memory required for data: 2214202000
I0816 16:04:07.560292 20404 layer_factory.hpp:77] Creating layer ReLU155
I0816 16:04:07.560302 20404 net.cpp:91] Creating Layer ReLU155
I0816 16:04:07.560310 20404 net.cpp:425] ReLU155 <- Convolution111
I0816 16:04:07.560322 20404 net.cpp:386] ReLU155 -> Convolution111 (in-place)
I0816 16:04:07.560334 20404 net.cpp:141] Setting up ReLU155
I0816 16:04:07.560343 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.560351 20404 net.cpp:156] Memory required for data: 2224032400
I0816 16:04:07.560359 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:07.560374 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:07.560382 20404 net.cpp:425] norm1 <- Convolution111
I0816 16:04:07.560395 20404 net.cpp:399] norm1 -> LRN45
I0816 16:04:07.560452 20404 net.cpp:141] Setting up norm1
I0816 16:04:07.560467 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.560473 20404 net.cpp:156] Memory required for data: 2233862800
I0816 16:04:07.560482 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:07.560645 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:07.560657 20404 net.cpp:425] pool1 <- LRN45
I0816 16:04:07.560669 20404 net.cpp:399] pool1 -> Pooling67
I0816 16:04:07.560732 20404 net.cpp:141] Setting up pool1
I0816 16:04:07.560746 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:07.560753 20404 net.cpp:156] Memory required for data: 2236320400
I0816 16:04:07.560761 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:07.560780 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:07.560788 20404 net.cpp:425] conv2 <- Pooling67
I0816 16:04:07.560803 20404 net.cpp:399] conv2 -> Convolution112
I0816 16:04:07.576442 20404 net.cpp:141] Setting up conv2
I0816 16:04:07.576464 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.576473 20404 net.cpp:156] Memory required for data: 2242874000
I0816 16:04:07.576493 20404 layer_factory.hpp:77] Creating layer ReLU156
I0816 16:04:07.576509 20404 net.cpp:91] Creating Layer ReLU156
I0816 16:04:07.576519 20404 net.cpp:425] ReLU156 <- Convolution112
I0816 16:04:07.576531 20404 net.cpp:386] ReLU156 -> Convolution112 (in-place)
I0816 16:04:07.576546 20404 net.cpp:141] Setting up ReLU156
I0816 16:04:07.576556 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.576563 20404 net.cpp:156] Memory required for data: 2249427600
I0816 16:04:07.576572 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:07.576602 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:07.576611 20404 net.cpp:425] norm2 <- Convolution112
I0816 16:04:07.576623 20404 net.cpp:399] norm2 -> LRN46
I0816 16:04:07.576692 20404 net.cpp:141] Setting up norm2
I0816 16:04:07.576707 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.576714 20404 net.cpp:156] Memory required for data: 2255981200
I0816 16:04:07.576722 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:07.576733 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:07.576741 20404 net.cpp:425] pool2 <- LRN46
I0816 16:04:07.576756 20404 net.cpp:399] pool2 -> Pooling68
I0816 16:04:07.576822 20404 net.cpp:141] Setting up pool2
I0816 16:04:07.576834 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.576843 20404 net.cpp:156] Memory required for data: 2257619600
I0816 16:04:07.576849 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:07.576870 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:07.576882 20404 net.cpp:425] conv3 <- Pooling68
I0816 16:04:07.576895 20404 net.cpp:399] conv3 -> Convolution113
I0816 16:04:07.621042 20404 net.cpp:141] Setting up conv3
I0816 16:04:07.621071 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.621090 20404 net.cpp:156] Memory required for data: 2260077200
I0816 16:04:07.621107 20404 layer_factory.hpp:77] Creating layer ReLU157
I0816 16:04:07.621122 20404 net.cpp:91] Creating Layer ReLU157
I0816 16:04:07.621134 20404 net.cpp:425] ReLU157 <- Convolution113
I0816 16:04:07.621146 20404 net.cpp:386] ReLU157 -> Convolution113 (in-place)
I0816 16:04:07.621170 20404 net.cpp:141] Setting up ReLU157
I0816 16:04:07.621181 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.621188 20404 net.cpp:156] Memory required for data: 2262534800
I0816 16:04:07.621196 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:07.621217 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:07.621232 20404 net.cpp:425] conv4 <- Convolution113
I0816 16:04:07.621248 20404 net.cpp:399] conv4 -> Convolution114
I0816 16:04:07.654368 20404 net.cpp:141] Setting up conv4
I0816 16:04:07.654399 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.654408 20404 net.cpp:156] Memory required for data: 2264992400
I0816 16:04:07.654424 20404 layer_factory.hpp:77] Creating layer ReLU158
I0816 16:04:07.654443 20404 net.cpp:91] Creating Layer ReLU158
I0816 16:04:07.654455 20404 net.cpp:425] ReLU158 <- Convolution114
I0816 16:04:07.654467 20404 net.cpp:386] ReLU158 -> Convolution114 (in-place)
I0816 16:04:07.654484 20404 net.cpp:141] Setting up ReLU158
I0816 16:04:07.654495 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.654502 20404 net.cpp:156] Memory required for data: 2267450000
I0816 16:04:07.654510 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:07.654530 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:07.654538 20404 net.cpp:425] conv5 <- Convolution114
I0816 16:04:07.654552 20404 net.cpp:399] conv5 -> Convolution115
I0816 16:04:07.676641 20404 net.cpp:141] Setting up conv5
I0816 16:04:07.676664 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.676672 20404 net.cpp:156] Memory required for data: 2269088400
I0816 16:04:07.676697 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:07.676709 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:07.676718 20404 net.cpp:425] pool5 <- Convolution115
I0816 16:04:07.676738 20404 net.cpp:399] pool5 -> Pooling69
I0816 16:04:07.676815 20404 net.cpp:141] Setting up pool5
I0816 16:04:07.676833 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:07.676841 20404 net.cpp:156] Memory required for data: 2269498000
I0816 16:04:07.676848 20404 layer_factory.hpp:77] Creating layer InnerProduct67
I0816 16:04:07.676862 20404 net.cpp:91] Creating Layer InnerProduct67
I0816 16:04:07.676872 20404 net.cpp:425] InnerProduct67 <- Pooling69
I0816 16:04:07.676889 20404 net.cpp:399] InnerProduct67 -> InnerProduct67
I0816 16:04:07.679687 20404 net.cpp:141] Setting up InnerProduct67
I0816 16:04:07.679728 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.679735 20404 net.cpp:156] Memory required for data: 2269600400
I0816 16:04:07.679746 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:07.679756 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:07.679764 20404 layer_factory.hpp:77] Creating layer ReLU159
I0816 16:04:07.679777 20404 net.cpp:91] Creating Layer ReLU159
I0816 16:04:07.679786 20404 net.cpp:425] ReLU159 <- InnerProduct67
I0816 16:04:07.679803 20404 net.cpp:386] ReLU159 -> InnerProduct67 (in-place)
I0816 16:04:07.679817 20404 net.cpp:141] Setting up ReLU159
I0816 16:04:07.679828 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.679836 20404 net.cpp:156] Memory required for data: 2269702800
I0816 16:04:07.679843 20404 layer_factory.hpp:77] Creating layer InnerProduct68
I0816 16:04:07.679857 20404 net.cpp:91] Creating Layer InnerProduct68
I0816 16:04:07.679864 20404 net.cpp:425] InnerProduct68 <- InnerProduct67
I0816 16:04:07.679880 20404 net.cpp:399] InnerProduct68 -> InnerProduct68
I0816 16:04:07.680598 20404 net.cpp:141] Setting up InnerProduct68
I0816 16:04:07.680613 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.680620 20404 net.cpp:156] Memory required for data: 2269805200
I0816 16:04:07.680629 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:07.680639 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:07.680647 20404 layer_factory.hpp:77] Creating layer ReLU160
I0816 16:04:07.680657 20404 net.cpp:91] Creating Layer ReLU160
I0816 16:04:07.680665 20404 net.cpp:425] ReLU160 <- InnerProduct68
I0816 16:04:07.680680 20404 net.cpp:386] ReLU160 -> InnerProduct68 (in-place)
I0816 16:04:07.680692 20404 net.cpp:141] Setting up ReLU160
I0816 16:04:07.680702 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.680709 20404 net.cpp:156] Memory required for data: 2269907600
I0816 16:04:07.680717 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:07.680733 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:07.680742 20404 net.cpp:425] conv1 <- c12
I0816 16:04:07.680755 20404 net.cpp:399] conv1 -> Convolution116
I0816 16:04:07.682888 20404 net.cpp:141] Setting up conv1
I0816 16:04:07.682905 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.682914 20404 net.cpp:156] Memory required for data: 2279738000
I0816 16:04:07.682927 20404 layer_factory.hpp:77] Creating layer ReLU161
I0816 16:04:07.682939 20404 net.cpp:91] Creating Layer ReLU161
I0816 16:04:07.682946 20404 net.cpp:425] ReLU161 <- Convolution116
I0816 16:04:07.682957 20404 net.cpp:386] ReLU161 -> Convolution116 (in-place)
I0816 16:04:07.682971 20404 net.cpp:141] Setting up ReLU161
I0816 16:04:07.682981 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.682989 20404 net.cpp:156] Memory required for data: 2289568400
I0816 16:04:07.682997 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:07.683012 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:07.683022 20404 net.cpp:425] norm1 <- Convolution116
I0816 16:04:07.683034 20404 net.cpp:399] norm1 -> LRN47
I0816 16:04:07.683095 20404 net.cpp:141] Setting up norm1
I0816 16:04:07.683109 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.683116 20404 net.cpp:156] Memory required for data: 2299398800
I0816 16:04:07.683125 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:07.683135 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:07.683143 20404 net.cpp:425] pool1 <- LRN47
I0816 16:04:07.683157 20404 net.cpp:399] pool1 -> Pooling70
I0816 16:04:07.683223 20404 net.cpp:141] Setting up pool1
I0816 16:04:07.683240 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:07.683248 20404 net.cpp:156] Memory required for data: 2301856400
I0816 16:04:07.683255 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:07.683276 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:07.683300 20404 net.cpp:425] conv2 <- Pooling70
I0816 16:04:07.683317 20404 net.cpp:399] conv2 -> Convolution117
I0816 16:04:07.698935 20404 net.cpp:141] Setting up conv2
I0816 16:04:07.698956 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.698964 20404 net.cpp:156] Memory required for data: 2308410000
I0816 16:04:07.698989 20404 layer_factory.hpp:77] Creating layer ReLU162
I0816 16:04:07.699007 20404 net.cpp:91] Creating Layer ReLU162
I0816 16:04:07.699017 20404 net.cpp:425] ReLU162 <- Convolution117
I0816 16:04:07.699028 20404 net.cpp:386] ReLU162 -> Convolution117 (in-place)
I0816 16:04:07.699041 20404 net.cpp:141] Setting up ReLU162
I0816 16:04:07.699060 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.699069 20404 net.cpp:156] Memory required for data: 2314963600
I0816 16:04:07.699075 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:07.699090 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:07.699098 20404 net.cpp:425] norm2 <- Convolution117
I0816 16:04:07.699111 20404 net.cpp:399] norm2 -> LRN48
I0816 16:04:07.699182 20404 net.cpp:141] Setting up norm2
I0816 16:04:07.699195 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.699203 20404 net.cpp:156] Memory required for data: 2321517200
I0816 16:04:07.699210 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:07.699221 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:07.699229 20404 net.cpp:425] pool2 <- LRN48
I0816 16:04:07.699244 20404 net.cpp:399] pool2 -> Pooling71
I0816 16:04:07.699318 20404 net.cpp:141] Setting up pool2
I0816 16:04:07.699332 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.699339 20404 net.cpp:156] Memory required for data: 2323155600
I0816 16:04:07.699347 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:07.699370 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:07.699379 20404 net.cpp:425] conv3 <- Pooling71
I0816 16:04:07.699393 20404 net.cpp:399] conv3 -> Convolution118
I0816 16:04:07.743086 20404 net.cpp:141] Setting up conv3
I0816 16:04:07.743118 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.743136 20404 net.cpp:156] Memory required for data: 2325613200
I0816 16:04:07.743154 20404 layer_factory.hpp:77] Creating layer ReLU163
I0816 16:04:07.743167 20404 net.cpp:91] Creating Layer ReLU163
I0816 16:04:07.743178 20404 net.cpp:425] ReLU163 <- Convolution118
I0816 16:04:07.743192 20404 net.cpp:386] ReLU163 -> Convolution118 (in-place)
I0816 16:04:07.743216 20404 net.cpp:141] Setting up ReLU163
I0816 16:04:07.743227 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.743234 20404 net.cpp:156] Memory required for data: 2328070800
I0816 16:04:07.743242 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:07.743263 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:07.743275 20404 net.cpp:425] conv4 <- Convolution118
I0816 16:04:07.743294 20404 net.cpp:399] conv4 -> Convolution119
I0816 16:04:07.776572 20404 net.cpp:141] Setting up conv4
I0816 16:04:07.776603 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.776612 20404 net.cpp:156] Memory required for data: 2330528400
I0816 16:04:07.776628 20404 layer_factory.hpp:77] Creating layer ReLU164
I0816 16:04:07.776646 20404 net.cpp:91] Creating Layer ReLU164
I0816 16:04:07.776657 20404 net.cpp:425] ReLU164 <- Convolution119
I0816 16:04:07.776670 20404 net.cpp:386] ReLU164 -> Convolution119 (in-place)
I0816 16:04:07.776687 20404 net.cpp:141] Setting up ReLU164
I0816 16:04:07.776698 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.776706 20404 net.cpp:156] Memory required for data: 2332986000
I0816 16:04:07.776715 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:07.776746 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:07.776754 20404 net.cpp:425] conv5 <- Convolution119
I0816 16:04:07.776768 20404 net.cpp:399] conv5 -> Convolution120
I0816 16:04:07.798828 20404 net.cpp:141] Setting up conv5
I0816 16:04:07.798852 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.798861 20404 net.cpp:156] Memory required for data: 2334624400
I0816 16:04:07.798902 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:07.798915 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:07.798926 20404 net.cpp:425] pool5 <- Convolution120
I0816 16:04:07.798952 20404 net.cpp:399] pool5 -> Pooling72
I0816 16:04:07.799024 20404 net.cpp:141] Setting up pool5
I0816 16:04:07.799041 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:07.799049 20404 net.cpp:156] Memory required for data: 2335034000
I0816 16:04:07.799057 20404 layer_factory.hpp:77] Creating layer InnerProduct69
I0816 16:04:07.799070 20404 net.cpp:91] Creating Layer InnerProduct69
I0816 16:04:07.799078 20404 net.cpp:425] InnerProduct69 <- Pooling72
I0816 16:04:07.799096 20404 net.cpp:399] InnerProduct69 -> InnerProduct69
I0816 16:04:07.801831 20404 net.cpp:141] Setting up InnerProduct69
I0816 16:04:07.801851 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.801868 20404 net.cpp:156] Memory required for data: 2335136400
I0816 16:04:07.801878 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:07.801888 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:07.801895 20404 layer_factory.hpp:77] Creating layer ReLU165
I0816 16:04:07.801908 20404 net.cpp:91] Creating Layer ReLU165
I0816 16:04:07.801916 20404 net.cpp:425] ReLU165 <- InnerProduct69
I0816 16:04:07.801939 20404 net.cpp:386] ReLU165 -> InnerProduct69 (in-place)
I0816 16:04:07.801954 20404 net.cpp:141] Setting up ReLU165
I0816 16:04:07.801964 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.801971 20404 net.cpp:156] Memory required for data: 2335238800
I0816 16:04:07.801980 20404 layer_factory.hpp:77] Creating layer InnerProduct70
I0816 16:04:07.801992 20404 net.cpp:91] Creating Layer InnerProduct70
I0816 16:04:07.802000 20404 net.cpp:425] InnerProduct70 <- InnerProduct69
I0816 16:04:07.802017 20404 net.cpp:399] InnerProduct70 -> InnerProduct70
I0816 16:04:07.802739 20404 net.cpp:141] Setting up InnerProduct70
I0816 16:04:07.802754 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.802762 20404 net.cpp:156] Memory required for data: 2335341200
I0816 16:04:07.802770 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:07.802780 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:07.802788 20404 layer_factory.hpp:77] Creating layer ReLU166
I0816 16:04:07.802801 20404 net.cpp:91] Creating Layer ReLU166
I0816 16:04:07.802810 20404 net.cpp:425] ReLU166 <- InnerProduct70
I0816 16:04:07.802821 20404 net.cpp:386] ReLU166 -> InnerProduct70 (in-place)
I0816 16:04:07.802834 20404 net.cpp:141] Setting up ReLU166
I0816 16:04:07.802845 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.802851 20404 net.cpp:156] Memory required for data: 2335443600
I0816 16:04:07.802860 20404 layer_factory.hpp:77] Creating layer Concat12
I0816 16:04:07.802871 20404 net.cpp:91] Creating Layer Concat12
I0816 16:04:07.802880 20404 net.cpp:425] Concat12 <- InnerProduct68
I0816 16:04:07.802889 20404 net.cpp:425] Concat12 <- InnerProduct70
I0816 16:04:07.802901 20404 net.cpp:399] Concat12 -> Concat12
I0816 16:04:07.802944 20404 net.cpp:141] Setting up Concat12
I0816 16:04:07.802958 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:07.802965 20404 net.cpp:156] Memory required for data: 2335648400
I0816 16:04:07.802973 20404 layer_factory.hpp:77] Creating layer InnerProduct71
I0816 16:04:07.802988 20404 net.cpp:91] Creating Layer InnerProduct71
I0816 16:04:07.802996 20404 net.cpp:425] InnerProduct71 <- Concat12
I0816 16:04:07.803011 20404 net.cpp:399] InnerProduct71 -> InnerProduct71
I0816 16:04:07.804801 20404 net.cpp:141] Setting up InnerProduct71
I0816 16:04:07.804823 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.804832 20404 net.cpp:156] Memory required for data: 2335750800
I0816 16:04:07.804842 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:07.804867 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:07.804877 20404 layer_factory.hpp:77] Creating layer ReLU167
I0816 16:04:07.804888 20404 net.cpp:91] Creating Layer ReLU167
I0816 16:04:07.804898 20404 net.cpp:425] ReLU167 <- InnerProduct71
I0816 16:04:07.804913 20404 net.cpp:386] ReLU167 -> InnerProduct71 (in-place)
I0816 16:04:07.804927 20404 net.cpp:141] Setting up ReLU167
I0816 16:04:07.804939 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.804945 20404 net.cpp:156] Memory required for data: 2335853200
I0816 16:04:07.804954 20404 layer_factory.hpp:77] Creating layer InnerProduct72
I0816 16:04:07.804965 20404 net.cpp:91] Creating Layer InnerProduct72
I0816 16:04:07.804975 20404 net.cpp:425] InnerProduct72 <- InnerProduct71
I0816 16:04:07.804989 20404 net.cpp:399] InnerProduct72 -> InnerProduct72
I0816 16:04:07.805440 20404 net.cpp:141] Setting up InnerProduct72
I0816 16:04:07.805455 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:07.805464 20404 net.cpp:156] Memory required for data: 2335904400
I0816 16:04:07.805471 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:07.805480 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:07.805488 20404 layer_factory.hpp:77] Creating layer ReLU168
I0816 16:04:07.805500 20404 net.cpp:91] Creating Layer ReLU168
I0816 16:04:07.805507 20404 net.cpp:425] ReLU168 <- InnerProduct72
I0816 16:04:07.805518 20404 net.cpp:386] ReLU168 -> InnerProduct72 (in-place)
I0816 16:04:07.805531 20404 net.cpp:141] Setting up ReLU168
I0816 16:04:07.805541 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:07.805548 20404 net.cpp:156] Memory required for data: 2335955600
I0816 16:04:07.805555 20404 layer_factory.hpp:77] Creating layer dt11
I0816 16:04:07.805567 20404 net.cpp:91] Creating Layer dt11
I0816 16:04:07.805575 20404 net.cpp:425] dt11 <- InnerProduct72
I0816 16:04:07.805593 20404 net.cpp:399] dt11 -> dt11
I0816 16:04:07.805763 20404 net.cpp:141] Setting up dt11
I0816 16:04:07.805776 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:07.805783 20404 net.cpp:156] Memory required for data: 2335956000
I0816 16:04:07.805793 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:07.805801 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:07.805809 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:07.805830 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:07.805840 20404 net.cpp:425] conv1 <- p2_p2_0_split_3
I0816 16:04:07.805853 20404 net.cpp:399] conv1 -> Convolution121
I0816 16:04:07.808033 20404 net.cpp:141] Setting up conv1
I0816 16:04:07.808053 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.808061 20404 net.cpp:156] Memory required for data: 2345786400
I0816 16:04:07.808075 20404 layer_factory.hpp:77] Creating layer ReLU169
I0816 16:04:07.808086 20404 net.cpp:91] Creating Layer ReLU169
I0816 16:04:07.808094 20404 net.cpp:425] ReLU169 <- Convolution121
I0816 16:04:07.808105 20404 net.cpp:386] ReLU169 -> Convolution121 (in-place)
I0816 16:04:07.808120 20404 net.cpp:141] Setting up ReLU169
I0816 16:04:07.808130 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.808137 20404 net.cpp:156] Memory required for data: 2355616800
I0816 16:04:07.808145 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:07.808159 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:07.808168 20404 net.cpp:425] norm1 <- Convolution121
I0816 16:04:07.808182 20404 net.cpp:399] norm1 -> LRN49
I0816 16:04:07.808240 20404 net.cpp:141] Setting up norm1
I0816 16:04:07.808254 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.808261 20404 net.cpp:156] Memory required for data: 2365447200
I0816 16:04:07.808269 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:07.808284 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:07.808291 20404 net.cpp:425] pool1 <- LRN49
I0816 16:04:07.808320 20404 net.cpp:399] pool1 -> Pooling73
I0816 16:04:07.808385 20404 net.cpp:141] Setting up pool1
I0816 16:04:07.808399 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:07.808408 20404 net.cpp:156] Memory required for data: 2367904800
I0816 16:04:07.808414 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:07.808432 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:07.808441 20404 net.cpp:425] conv2 <- Pooling73
I0816 16:04:07.808457 20404 net.cpp:399] conv2 -> Convolution122
I0816 16:04:07.824030 20404 net.cpp:141] Setting up conv2
I0816 16:04:07.824054 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.824062 20404 net.cpp:156] Memory required for data: 2374458400
I0816 16:04:07.824086 20404 layer_factory.hpp:77] Creating layer ReLU170
I0816 16:04:07.824102 20404 net.cpp:91] Creating Layer ReLU170
I0816 16:04:07.824112 20404 net.cpp:425] ReLU170 <- Convolution122
I0816 16:04:07.824123 20404 net.cpp:386] ReLU170 -> Convolution122 (in-place)
I0816 16:04:07.824137 20404 net.cpp:141] Setting up ReLU170
I0816 16:04:07.824156 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.824162 20404 net.cpp:156] Memory required for data: 2381012000
I0816 16:04:07.824170 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:07.824184 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:07.824193 20404 net.cpp:425] norm2 <- Convolution122
I0816 16:04:07.824205 20404 net.cpp:399] norm2 -> LRN50
I0816 16:04:07.824276 20404 net.cpp:141] Setting up norm2
I0816 16:04:07.824290 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.824298 20404 net.cpp:156] Memory required for data: 2387565600
I0816 16:04:07.824306 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:07.824316 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:07.824324 20404 net.cpp:425] pool2 <- LRN50
I0816 16:04:07.824340 20404 net.cpp:399] pool2 -> Pooling74
I0816 16:04:07.824405 20404 net.cpp:141] Setting up pool2
I0816 16:04:07.824419 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.824426 20404 net.cpp:156] Memory required for data: 2389204000
I0816 16:04:07.824434 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:07.824456 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:07.824468 20404 net.cpp:425] conv3 <- Pooling74
I0816 16:04:07.824481 20404 net.cpp:399] conv3 -> Convolution123
I0816 16:04:07.868351 20404 net.cpp:141] Setting up conv3
I0816 16:04:07.868381 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.868389 20404 net.cpp:156] Memory required for data: 2391661600
I0816 16:04:07.868407 20404 layer_factory.hpp:77] Creating layer ReLU171
I0816 16:04:07.868422 20404 net.cpp:91] Creating Layer ReLU171
I0816 16:04:07.868432 20404 net.cpp:425] ReLU171 <- Convolution123
I0816 16:04:07.868443 20404 net.cpp:386] ReLU171 -> Convolution123 (in-place)
I0816 16:04:07.868458 20404 net.cpp:141] Setting up ReLU171
I0816 16:04:07.868469 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.868476 20404 net.cpp:156] Memory required for data: 2394119200
I0816 16:04:07.868484 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:07.868507 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:07.868522 20404 net.cpp:425] conv4 <- Convolution123
I0816 16:04:07.868536 20404 net.cpp:399] conv4 -> Convolution124
I0816 16:04:07.901628 20404 net.cpp:141] Setting up conv4
I0816 16:04:07.901659 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.901669 20404 net.cpp:156] Memory required for data: 2396576800
I0816 16:04:07.901705 20404 layer_factory.hpp:77] Creating layer ReLU172
I0816 16:04:07.901727 20404 net.cpp:91] Creating Layer ReLU172
I0816 16:04:07.901742 20404 net.cpp:425] ReLU172 <- Convolution124
I0816 16:04:07.901756 20404 net.cpp:386] ReLU172 -> Convolution124 (in-place)
I0816 16:04:07.901772 20404 net.cpp:141] Setting up ReLU172
I0816 16:04:07.901782 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.901790 20404 net.cpp:156] Memory required for data: 2399034400
I0816 16:04:07.901818 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:07.901841 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:07.901854 20404 net.cpp:425] conv5 <- Convolution124
I0816 16:04:07.901873 20404 net.cpp:399] conv5 -> Convolution125
I0816 16:04:07.924149 20404 net.cpp:141] Setting up conv5
I0816 16:04:07.924177 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.924196 20404 net.cpp:156] Memory required for data: 2400672800
I0816 16:04:07.924211 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:07.924231 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:07.924240 20404 net.cpp:425] pool5 <- Convolution125
I0816 16:04:07.924266 20404 net.cpp:399] pool5 -> Pooling75
I0816 16:04:07.924343 20404 net.cpp:141] Setting up pool5
I0816 16:04:07.924357 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:07.924365 20404 net.cpp:156] Memory required for data: 2401082400
I0816 16:04:07.924372 20404 layer_factory.hpp:77] Creating layer InnerProduct73
I0816 16:04:07.924387 20404 net.cpp:91] Creating Layer InnerProduct73
I0816 16:04:07.924396 20404 net.cpp:425] InnerProduct73 <- Pooling75
I0816 16:04:07.924414 20404 net.cpp:399] InnerProduct73 -> InnerProduct73
I0816 16:04:07.927237 20404 net.cpp:141] Setting up InnerProduct73
I0816 16:04:07.927258 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.927265 20404 net.cpp:156] Memory required for data: 2401184800
I0816 16:04:07.927292 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:07.927304 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:07.927312 20404 layer_factory.hpp:77] Creating layer ReLU173
I0816 16:04:07.927327 20404 net.cpp:91] Creating Layer ReLU173
I0816 16:04:07.927337 20404 net.cpp:425] ReLU173 <- InnerProduct73
I0816 16:04:07.927350 20404 net.cpp:386] ReLU173 -> InnerProduct73 (in-place)
I0816 16:04:07.927364 20404 net.cpp:141] Setting up ReLU173
I0816 16:04:07.927374 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.927382 20404 net.cpp:156] Memory required for data: 2401287200
I0816 16:04:07.927391 20404 layer_factory.hpp:77] Creating layer InnerProduct74
I0816 16:04:07.927404 20404 net.cpp:91] Creating Layer InnerProduct74
I0816 16:04:07.927412 20404 net.cpp:425] InnerProduct74 <- InnerProduct73
I0816 16:04:07.927428 20404 net.cpp:399] InnerProduct74 -> InnerProduct74
I0816 16:04:07.928921 20404 net.cpp:141] Setting up InnerProduct74
I0816 16:04:07.928947 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.928957 20404 net.cpp:156] Memory required for data: 2401389600
I0816 16:04:07.928968 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:07.928979 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:07.928988 20404 layer_factory.hpp:77] Creating layer ReLU174
I0816 16:04:07.929003 20404 net.cpp:91] Creating Layer ReLU174
I0816 16:04:07.929015 20404 net.cpp:425] ReLU174 <- InnerProduct74
I0816 16:04:07.929034 20404 net.cpp:386] ReLU174 -> InnerProduct74 (in-place)
I0816 16:04:07.929052 20404 net.cpp:141] Setting up ReLU174
I0816 16:04:07.929065 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:07.929074 20404 net.cpp:156] Memory required for data: 2401492000
I0816 16:04:07.929082 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:07.929105 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:07.929118 20404 net.cpp:425] conv1 <- c13
I0816 16:04:07.929132 20404 net.cpp:399] conv1 -> Convolution126
I0816 16:04:07.931324 20404 net.cpp:141] Setting up conv1
I0816 16:04:07.931337 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.931344 20404 net.cpp:156] Memory required for data: 2411322400
I0816 16:04:07.931354 20404 layer_factory.hpp:77] Creating layer ReLU175
I0816 16:04:07.931362 20404 net.cpp:91] Creating Layer ReLU175
I0816 16:04:07.931370 20404 net.cpp:425] ReLU175 <- Convolution126
I0816 16:04:07.931380 20404 net.cpp:386] ReLU175 -> Convolution126 (in-place)
I0816 16:04:07.931408 20404 net.cpp:141] Setting up ReLU175
I0816 16:04:07.931416 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.931421 20404 net.cpp:156] Memory required for data: 2421152800
I0816 16:04:07.931427 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:07.931438 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:07.931445 20404 net.cpp:425] norm1 <- Convolution126
I0816 16:04:07.931454 20404 net.cpp:399] norm1 -> LRN51
I0816 16:04:07.931509 20404 net.cpp:141] Setting up norm1
I0816 16:04:07.931524 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:07.931530 20404 net.cpp:156] Memory required for data: 2430983200
I0816 16:04:07.931538 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:07.931552 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:07.931561 20404 net.cpp:425] pool1 <- LRN51
I0816 16:04:07.931572 20404 net.cpp:399] pool1 -> Pooling76
I0816 16:04:07.931644 20404 net.cpp:141] Setting up pool1
I0816 16:04:07.931658 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:07.931665 20404 net.cpp:156] Memory required for data: 2433440800
I0816 16:04:07.931673 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:07.931691 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:07.931700 20404 net.cpp:425] conv2 <- Pooling76
I0816 16:04:07.931716 20404 net.cpp:399] conv2 -> Convolution127
I0816 16:04:07.947324 20404 net.cpp:141] Setting up conv2
I0816 16:04:07.947347 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.947356 20404 net.cpp:156] Memory required for data: 2439994400
I0816 16:04:07.947371 20404 layer_factory.hpp:77] Creating layer ReLU176
I0816 16:04:07.947389 20404 net.cpp:91] Creating Layer ReLU176
I0816 16:04:07.947398 20404 net.cpp:425] ReLU176 <- Convolution127
I0816 16:04:07.947410 20404 net.cpp:386] ReLU176 -> Convolution127 (in-place)
I0816 16:04:07.947424 20404 net.cpp:141] Setting up ReLU176
I0816 16:04:07.947434 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.947443 20404 net.cpp:156] Memory required for data: 2446548000
I0816 16:04:07.947449 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:07.947464 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:07.947474 20404 net.cpp:425] norm2 <- Convolution127
I0816 16:04:07.947485 20404 net.cpp:399] norm2 -> LRN52
I0816 16:04:07.947553 20404 net.cpp:141] Setting up norm2
I0816 16:04:07.947567 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:07.947576 20404 net.cpp:156] Memory required for data: 2453101600
I0816 16:04:07.947582 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:07.947597 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:07.947605 20404 net.cpp:425] pool2 <- LRN52
I0816 16:04:07.947619 20404 net.cpp:399] pool2 -> Pooling77
I0816 16:04:07.947686 20404 net.cpp:141] Setting up pool2
I0816 16:04:07.947701 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:07.947708 20404 net.cpp:156] Memory required for data: 2454740000
I0816 16:04:07.947715 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:07.947734 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:07.947742 20404 net.cpp:425] conv3 <- Pooling77
I0816 16:04:07.947760 20404 net.cpp:399] conv3 -> Convolution128
I0816 16:04:07.991588 20404 net.cpp:141] Setting up conv3
I0816 16:04:07.991619 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.991638 20404 net.cpp:156] Memory required for data: 2457197600
I0816 16:04:07.991655 20404 layer_factory.hpp:77] Creating layer ReLU177
I0816 16:04:07.991673 20404 net.cpp:91] Creating Layer ReLU177
I0816 16:04:07.991684 20404 net.cpp:425] ReLU177 <- Convolution128
I0816 16:04:07.991708 20404 net.cpp:386] ReLU177 -> Convolution128 (in-place)
I0816 16:04:07.991724 20404 net.cpp:141] Setting up ReLU177
I0816 16:04:07.991734 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:07.991741 20404 net.cpp:156] Memory required for data: 2459655200
I0816 16:04:07.991749 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:07.991768 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:07.991796 20404 net.cpp:425] conv4 <- Convolution128
I0816 16:04:07.991816 20404 net.cpp:399] conv4 -> Convolution129
I0816 16:04:08.025105 20404 net.cpp:141] Setting up conv4
I0816 16:04:08.025135 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.025154 20404 net.cpp:156] Memory required for data: 2462112800
I0816 16:04:08.025171 20404 layer_factory.hpp:77] Creating layer ReLU178
I0816 16:04:08.025185 20404 net.cpp:91] Creating Layer ReLU178
I0816 16:04:08.025197 20404 net.cpp:425] ReLU178 <- Convolution129
I0816 16:04:08.025223 20404 net.cpp:386] ReLU178 -> Convolution129 (in-place)
I0816 16:04:08.025239 20404 net.cpp:141] Setting up ReLU178
I0816 16:04:08.025254 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.025262 20404 net.cpp:156] Memory required for data: 2464570400
I0816 16:04:08.025270 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:08.025291 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:08.025305 20404 net.cpp:425] conv5 <- Convolution129
I0816 16:04:08.025319 20404 net.cpp:399] conv5 -> Convolution130
I0816 16:04:08.047560 20404 net.cpp:141] Setting up conv5
I0816 16:04:08.047585 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.047593 20404 net.cpp:156] Memory required for data: 2466208800
I0816 16:04:08.047612 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:08.047626 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:08.047636 20404 net.cpp:425] pool5 <- Convolution130
I0816 16:04:08.047655 20404 net.cpp:399] pool5 -> Pooling78
I0816 16:04:08.047729 20404 net.cpp:141] Setting up pool5
I0816 16:04:08.047744 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:08.047751 20404 net.cpp:156] Memory required for data: 2466618400
I0816 16:04:08.047758 20404 layer_factory.hpp:77] Creating layer InnerProduct75
I0816 16:04:08.047776 20404 net.cpp:91] Creating Layer InnerProduct75
I0816 16:04:08.047785 20404 net.cpp:425] InnerProduct75 <- Pooling78
I0816 16:04:08.047804 20404 net.cpp:399] InnerProduct75 -> InnerProduct75
I0816 16:04:08.050654 20404 net.cpp:141] Setting up InnerProduct75
I0816 16:04:08.050675 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.050683 20404 net.cpp:156] Memory required for data: 2466720800
I0816 16:04:08.050693 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:08.050704 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:08.050712 20404 layer_factory.hpp:77] Creating layer ReLU179
I0816 16:04:08.050724 20404 net.cpp:91] Creating Layer ReLU179
I0816 16:04:08.050732 20404 net.cpp:425] ReLU179 <- InnerProduct75
I0816 16:04:08.050747 20404 net.cpp:386] ReLU179 -> InnerProduct75 (in-place)
I0816 16:04:08.050762 20404 net.cpp:141] Setting up ReLU179
I0816 16:04:08.050772 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.050779 20404 net.cpp:156] Memory required for data: 2466823200
I0816 16:04:08.050786 20404 layer_factory.hpp:77] Creating layer InnerProduct76
I0816 16:04:08.050799 20404 net.cpp:91] Creating Layer InnerProduct76
I0816 16:04:08.050808 20404 net.cpp:425] InnerProduct76 <- InnerProduct75
I0816 16:04:08.050823 20404 net.cpp:399] InnerProduct76 -> InnerProduct76
I0816 16:04:08.051599 20404 net.cpp:141] Setting up InnerProduct76
I0816 16:04:08.051656 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.051683 20404 net.cpp:156] Memory required for data: 2466925600
I0816 16:04:08.051714 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:08.051745 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:08.051774 20404 layer_factory.hpp:77] Creating layer ReLU180
I0816 16:04:08.051805 20404 net.cpp:91] Creating Layer ReLU180
I0816 16:04:08.051839 20404 net.cpp:425] ReLU180 <- InnerProduct76
I0816 16:04:08.051869 20404 net.cpp:386] ReLU180 -> InnerProduct76 (in-place)
I0816 16:04:08.051904 20404 net.cpp:141] Setting up ReLU180
I0816 16:04:08.051949 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.051975 20404 net.cpp:156] Memory required for data: 2467028000
I0816 16:04:08.051986 20404 layer_factory.hpp:77] Creating layer Concat13
I0816 16:04:08.052000 20404 net.cpp:91] Creating Layer Concat13
I0816 16:04:08.052008 20404 net.cpp:425] Concat13 <- InnerProduct74
I0816 16:04:08.052019 20404 net.cpp:425] Concat13 <- InnerProduct76
I0816 16:04:08.052037 20404 net.cpp:399] Concat13 -> Concat13
I0816 16:04:08.052083 20404 net.cpp:141] Setting up Concat13
I0816 16:04:08.052103 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:08.052110 20404 net.cpp:156] Memory required for data: 2467232800
I0816 16:04:08.052119 20404 layer_factory.hpp:77] Creating layer InnerProduct77
I0816 16:04:08.052130 20404 net.cpp:91] Creating Layer InnerProduct77
I0816 16:04:08.052139 20404 net.cpp:425] InnerProduct77 <- Concat13
I0816 16:04:08.052155 20404 net.cpp:399] InnerProduct77 -> InnerProduct77
I0816 16:04:08.053349 20404 net.cpp:141] Setting up InnerProduct77
I0816 16:04:08.053364 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.053371 20404 net.cpp:156] Memory required for data: 2467335200
I0816 16:04:08.053380 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:08.053390 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:08.053397 20404 layer_factory.hpp:77] Creating layer ReLU181
I0816 16:04:08.053408 20404 net.cpp:91] Creating Layer ReLU181
I0816 16:04:08.053416 20404 net.cpp:425] ReLU181 <- InnerProduct77
I0816 16:04:08.053428 20404 net.cpp:386] ReLU181 -> InnerProduct77 (in-place)
I0816 16:04:08.053441 20404 net.cpp:141] Setting up ReLU181
I0816 16:04:08.053450 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.053458 20404 net.cpp:156] Memory required for data: 2467437600
I0816 16:04:08.053465 20404 layer_factory.hpp:77] Creating layer InnerProduct78
I0816 16:04:08.053480 20404 net.cpp:91] Creating Layer InnerProduct78
I0816 16:04:08.053489 20404 net.cpp:425] InnerProduct78 <- InnerProduct77
I0816 16:04:08.053504 20404 net.cpp:399] InnerProduct78 -> InnerProduct78
I0816 16:04:08.053926 20404 net.cpp:141] Setting up InnerProduct78
I0816 16:04:08.053941 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:08.053948 20404 net.cpp:156] Memory required for data: 2467488800
I0816 16:04:08.053959 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:08.053969 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:08.053977 20404 layer_factory.hpp:77] Creating layer ReLU182
I0816 16:04:08.053988 20404 net.cpp:91] Creating Layer ReLU182
I0816 16:04:08.053997 20404 net.cpp:425] ReLU182 <- InnerProduct78
I0816 16:04:08.054006 20404 net.cpp:386] ReLU182 -> InnerProduct78 (in-place)
I0816 16:04:08.054019 20404 net.cpp:141] Setting up ReLU182
I0816 16:04:08.054029 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:08.054036 20404 net.cpp:156] Memory required for data: 2467540000
I0816 16:04:08.054044 20404 layer_factory.hpp:77] Creating layer dt12
I0816 16:04:08.054056 20404 net.cpp:91] Creating Layer dt12
I0816 16:04:08.054064 20404 net.cpp:425] dt12 <- InnerProduct78
I0816 16:04:08.054081 20404 net.cpp:399] dt12 -> dt12
I0816 16:04:08.054265 20404 net.cpp:141] Setting up dt12
I0816 16:04:08.054278 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:08.054286 20404 net.cpp:156] Memory required for data: 2467540400
I0816 16:04:08.054293 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:08.054303 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:08.054311 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:08.054338 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:08.054348 20404 net.cpp:425] conv1 <- p2_p2_0_split_4
I0816 16:04:08.054363 20404 net.cpp:399] conv1 -> Convolution131
I0816 16:04:08.056479 20404 net.cpp:141] Setting up conv1
I0816 16:04:08.056506 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.056514 20404 net.cpp:156] Memory required for data: 2477370800
I0816 16:04:08.056529 20404 layer_factory.hpp:77] Creating layer ReLU183
I0816 16:04:08.056540 20404 net.cpp:91] Creating Layer ReLU183
I0816 16:04:08.056547 20404 net.cpp:425] ReLU183 <- Convolution131
I0816 16:04:08.056561 20404 net.cpp:386] ReLU183 -> Convolution131 (in-place)
I0816 16:04:08.056574 20404 net.cpp:141] Setting up ReLU183
I0816 16:04:08.056584 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.056592 20404 net.cpp:156] Memory required for data: 2487201200
I0816 16:04:08.056599 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:08.056612 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:08.056619 20404 net.cpp:425] norm1 <- Convolution131
I0816 16:04:08.056637 20404 net.cpp:399] norm1 -> LRN53
I0816 16:04:08.056697 20404 net.cpp:141] Setting up norm1
I0816 16:04:08.056711 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.056718 20404 net.cpp:156] Memory required for data: 2497031600
I0816 16:04:08.056725 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:08.056740 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:08.056748 20404 net.cpp:425] pool1 <- LRN53
I0816 16:04:08.056761 20404 net.cpp:399] pool1 -> Pooling79
I0816 16:04:08.056829 20404 net.cpp:141] Setting up pool1
I0816 16:04:08.056843 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:08.056851 20404 net.cpp:156] Memory required for data: 2499489200
I0816 16:04:08.056859 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:08.056876 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:08.056885 20404 net.cpp:425] conv2 <- Pooling79
I0816 16:04:08.056897 20404 net.cpp:399] conv2 -> Convolution132
I0816 16:04:08.072408 20404 net.cpp:141] Setting up conv2
I0816 16:04:08.072430 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.072438 20404 net.cpp:156] Memory required for data: 2506042800
I0816 16:04:08.072461 20404 layer_factory.hpp:77] Creating layer ReLU184
I0816 16:04:08.072474 20404 net.cpp:91] Creating Layer ReLU184
I0816 16:04:08.072482 20404 net.cpp:425] ReLU184 <- Convolution132
I0816 16:04:08.072494 20404 net.cpp:386] ReLU184 -> Convolution132 (in-place)
I0816 16:04:08.072507 20404 net.cpp:141] Setting up ReLU184
I0816 16:04:08.072523 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.072530 20404 net.cpp:156] Memory required for data: 2512596400
I0816 16:04:08.072538 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:08.072552 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:08.072561 20404 net.cpp:425] norm2 <- Convolution132
I0816 16:04:08.072576 20404 net.cpp:399] norm2 -> LRN54
I0816 16:04:08.072644 20404 net.cpp:141] Setting up norm2
I0816 16:04:08.072659 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.072666 20404 net.cpp:156] Memory required for data: 2519150000
I0816 16:04:08.072674 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:08.072688 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:08.072696 20404 net.cpp:425] pool2 <- LRN54
I0816 16:04:08.072707 20404 net.cpp:399] pool2 -> Pooling80
I0816 16:04:08.072777 20404 net.cpp:141] Setting up pool2
I0816 16:04:08.072791 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.072798 20404 net.cpp:156] Memory required for data: 2520788400
I0816 16:04:08.072806 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:08.072824 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:08.072832 20404 net.cpp:425] conv3 <- Pooling80
I0816 16:04:08.072849 20404 net.cpp:399] conv3 -> Convolution133
I0816 16:04:08.116672 20404 net.cpp:141] Setting up conv3
I0816 16:04:08.116740 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.116752 20404 net.cpp:156] Memory required for data: 2523246000
I0816 16:04:08.116770 20404 layer_factory.hpp:77] Creating layer ReLU185
I0816 16:04:08.116787 20404 net.cpp:91] Creating Layer ReLU185
I0816 16:04:08.116799 20404 net.cpp:425] ReLU185 <- Convolution133
I0816 16:04:08.116832 20404 net.cpp:386] ReLU185 -> Convolution133 (in-place)
I0816 16:04:08.116848 20404 net.cpp:141] Setting up ReLU185
I0816 16:04:08.116861 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.116868 20404 net.cpp:156] Memory required for data: 2525703600
I0816 16:04:08.116876 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:08.116897 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:08.116906 20404 net.cpp:425] conv4 <- Convolution133
I0816 16:04:08.116920 20404 net.cpp:399] conv4 -> Convolution134
I0816 16:04:08.150260 20404 net.cpp:141] Setting up conv4
I0816 16:04:08.150291 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.150300 20404 net.cpp:156] Memory required for data: 2528161200
I0816 16:04:08.150316 20404 layer_factory.hpp:77] Creating layer ReLU186
I0816 16:04:08.150336 20404 net.cpp:91] Creating Layer ReLU186
I0816 16:04:08.150347 20404 net.cpp:425] ReLU186 <- Convolution134
I0816 16:04:08.150360 20404 net.cpp:386] ReLU186 -> Convolution134 (in-place)
I0816 16:04:08.150377 20404 net.cpp:141] Setting up ReLU186
I0816 16:04:08.150387 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.150393 20404 net.cpp:156] Memory required for data: 2530618800
I0816 16:04:08.150401 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:08.150421 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:08.150430 20404 net.cpp:425] conv5 <- Convolution134
I0816 16:04:08.150447 20404 net.cpp:399] conv5 -> Convolution135
I0816 16:04:08.172561 20404 net.cpp:141] Setting up conv5
I0816 16:04:08.172583 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.172591 20404 net.cpp:156] Memory required for data: 2532257200
I0816 16:04:08.172606 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:08.172634 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:08.172644 20404 net.cpp:425] pool5 <- Convolution135
I0816 16:04:08.172659 20404 net.cpp:399] pool5 -> Pooling81
I0816 16:04:08.172735 20404 net.cpp:141] Setting up pool5
I0816 16:04:08.172750 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:08.172757 20404 net.cpp:156] Memory required for data: 2532666800
I0816 16:04:08.172765 20404 layer_factory.hpp:77] Creating layer InnerProduct79
I0816 16:04:08.172781 20404 net.cpp:91] Creating Layer InnerProduct79
I0816 16:04:08.172791 20404 net.cpp:425] InnerProduct79 <- Pooling81
I0816 16:04:08.172806 20404 net.cpp:399] InnerProduct79 -> InnerProduct79
I0816 16:04:08.175652 20404 net.cpp:141] Setting up InnerProduct79
I0816 16:04:08.175678 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.175685 20404 net.cpp:156] Memory required for data: 2532769200
I0816 16:04:08.175696 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:08.175709 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:08.175719 20404 layer_factory.hpp:77] Creating layer ReLU187
I0816 16:04:08.175735 20404 net.cpp:91] Creating Layer ReLU187
I0816 16:04:08.175791 20404 net.cpp:425] ReLU187 <- InnerProduct79
I0816 16:04:08.175809 20404 net.cpp:386] ReLU187 -> InnerProduct79 (in-place)
I0816 16:04:08.175827 20404 net.cpp:141] Setting up ReLU187
I0816 16:04:08.175837 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.175874 20404 net.cpp:156] Memory required for data: 2532871600
I0816 16:04:08.175887 20404 layer_factory.hpp:77] Creating layer InnerProduct80
I0816 16:04:08.175904 20404 net.cpp:91] Creating Layer InnerProduct80
I0816 16:04:08.175915 20404 net.cpp:425] InnerProduct80 <- InnerProduct79
I0816 16:04:08.175928 20404 net.cpp:399] InnerProduct80 -> InnerProduct80
I0816 16:04:08.177325 20404 net.cpp:141] Setting up InnerProduct80
I0816 16:04:08.177362 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.177368 20404 net.cpp:156] Memory required for data: 2532974000
I0816 16:04:08.177376 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:08.177399 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:08.177407 20404 layer_factory.hpp:77] Creating layer ReLU188
I0816 16:04:08.177429 20404 net.cpp:91] Creating Layer ReLU188
I0816 16:04:08.177436 20404 net.cpp:425] ReLU188 <- InnerProduct80
I0816 16:04:08.177445 20404 net.cpp:386] ReLU188 -> InnerProduct80 (in-place)
I0816 16:04:08.177456 20404 net.cpp:141] Setting up ReLU188
I0816 16:04:08.177464 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.177469 20404 net.cpp:156] Memory required for data: 2533076400
I0816 16:04:08.177474 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:08.177490 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:08.177497 20404 net.cpp:425] conv1 <- c14
I0816 16:04:08.177510 20404 net.cpp:399] conv1 -> Convolution136
I0816 16:04:08.179613 20404 net.cpp:141] Setting up conv1
I0816 16:04:08.179630 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.179638 20404 net.cpp:156] Memory required for data: 2542906800
I0816 16:04:08.179652 20404 layer_factory.hpp:77] Creating layer ReLU189
I0816 16:04:08.179662 20404 net.cpp:91] Creating Layer ReLU189
I0816 16:04:08.179672 20404 net.cpp:425] ReLU189 <- Convolution136
I0816 16:04:08.179682 20404 net.cpp:386] ReLU189 -> Convolution136 (in-place)
I0816 16:04:08.179695 20404 net.cpp:141] Setting up ReLU189
I0816 16:04:08.179705 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.179713 20404 net.cpp:156] Memory required for data: 2552737200
I0816 16:04:08.179720 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:08.179735 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:08.179744 20404 net.cpp:425] norm1 <- Convolution136
I0816 16:04:08.179757 20404 net.cpp:399] norm1 -> LRN55
I0816 16:04:08.179818 20404 net.cpp:141] Setting up norm1
I0816 16:04:08.179831 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.179839 20404 net.cpp:156] Memory required for data: 2562567600
I0816 16:04:08.179847 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:08.179862 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:08.179869 20404 net.cpp:425] pool1 <- LRN55
I0816 16:04:08.179884 20404 net.cpp:399] pool1 -> Pooling82
I0816 16:04:08.179952 20404 net.cpp:141] Setting up pool1
I0816 16:04:08.179966 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:08.179973 20404 net.cpp:156] Memory required for data: 2565025200
I0816 16:04:08.179980 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:08.179998 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:08.180006 20404 net.cpp:425] conv2 <- Pooling82
I0816 16:04:08.180022 20404 net.cpp:399] conv2 -> Convolution137
I0816 16:04:08.195549 20404 net.cpp:141] Setting up conv2
I0816 16:04:08.195571 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.195580 20404 net.cpp:156] Memory required for data: 2571578800
I0816 16:04:08.195595 20404 layer_factory.hpp:77] Creating layer ReLU190
I0816 16:04:08.195611 20404 net.cpp:91] Creating Layer ReLU190
I0816 16:04:08.195621 20404 net.cpp:425] ReLU190 <- Convolution137
I0816 16:04:08.195632 20404 net.cpp:386] ReLU190 -> Convolution137 (in-place)
I0816 16:04:08.195646 20404 net.cpp:141] Setting up ReLU190
I0816 16:04:08.195657 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.195663 20404 net.cpp:156] Memory required for data: 2578132400
I0816 16:04:08.195672 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:08.195686 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:08.195694 20404 net.cpp:425] norm2 <- Convolution137
I0816 16:04:08.195708 20404 net.cpp:399] norm2 -> LRN56
I0816 16:04:08.195778 20404 net.cpp:141] Setting up norm2
I0816 16:04:08.195793 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.195801 20404 net.cpp:156] Memory required for data: 2584686000
I0816 16:04:08.195808 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:08.195819 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:08.195827 20404 net.cpp:425] pool2 <- LRN56
I0816 16:04:08.195844 20404 net.cpp:399] pool2 -> Pooling83
I0816 16:04:08.195932 20404 net.cpp:141] Setting up pool2
I0816 16:04:08.195946 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.195953 20404 net.cpp:156] Memory required for data: 2586324400
I0816 16:04:08.195960 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:08.195983 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:08.195996 20404 net.cpp:425] conv3 <- Pooling83
I0816 16:04:08.196009 20404 net.cpp:399] conv3 -> Convolution138
I0816 16:04:08.239981 20404 net.cpp:141] Setting up conv3
I0816 16:04:08.240011 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.240031 20404 net.cpp:156] Memory required for data: 2588782000
I0816 16:04:08.240047 20404 layer_factory.hpp:77] Creating layer ReLU191
I0816 16:04:08.240061 20404 net.cpp:91] Creating Layer ReLU191
I0816 16:04:08.240073 20404 net.cpp:425] ReLU191 <- Convolution138
I0816 16:04:08.240087 20404 net.cpp:386] ReLU191 -> Convolution138 (in-place)
I0816 16:04:08.240110 20404 net.cpp:141] Setting up ReLU191
I0816 16:04:08.240121 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.240128 20404 net.cpp:156] Memory required for data: 2591239600
I0816 16:04:08.240135 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:08.240159 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:08.240166 20404 net.cpp:425] conv4 <- Convolution138
I0816 16:04:08.240180 20404 net.cpp:399] conv4 -> Convolution139
I0816 16:04:08.273433 20404 net.cpp:141] Setting up conv4
I0816 16:04:08.273465 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.273473 20404 net.cpp:156] Memory required for data: 2593697200
I0816 16:04:08.273489 20404 layer_factory.hpp:77] Creating layer ReLU192
I0816 16:04:08.273504 20404 net.cpp:91] Creating Layer ReLU192
I0816 16:04:08.273514 20404 net.cpp:425] ReLU192 <- Convolution139
I0816 16:04:08.273526 20404 net.cpp:386] ReLU192 -> Convolution139 (in-place)
I0816 16:04:08.273541 20404 net.cpp:141] Setting up ReLU192
I0816 16:04:08.273551 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.273558 20404 net.cpp:156] Memory required for data: 2596154800
I0816 16:04:08.273566 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:08.273586 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:08.273596 20404 net.cpp:425] conv5 <- Convolution139
I0816 16:04:08.273612 20404 net.cpp:399] conv5 -> Convolution140
I0816 16:04:08.295784 20404 net.cpp:141] Setting up conv5
I0816 16:04:08.295809 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.295825 20404 net.cpp:156] Memory required for data: 2597793200
I0816 16:04:08.295840 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:08.295858 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:08.295867 20404 net.cpp:425] pool5 <- Convolution140
I0816 16:04:08.295882 20404 net.cpp:399] pool5 -> Pooling84
I0816 16:04:08.295967 20404 net.cpp:141] Setting up pool5
I0816 16:04:08.295982 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:08.295989 20404 net.cpp:156] Memory required for data: 2598202800
I0816 16:04:08.295997 20404 layer_factory.hpp:77] Creating layer InnerProduct81
I0816 16:04:08.296010 20404 net.cpp:91] Creating Layer InnerProduct81
I0816 16:04:08.296020 20404 net.cpp:425] InnerProduct81 <- Pooling84
I0816 16:04:08.296036 20404 net.cpp:399] InnerProduct81 -> InnerProduct81
I0816 16:04:08.298822 20404 net.cpp:141] Setting up InnerProduct81
I0816 16:04:08.298843 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.298851 20404 net.cpp:156] Memory required for data: 2598305200
I0816 16:04:08.298864 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:08.298874 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:08.298882 20404 layer_factory.hpp:77] Creating layer ReLU193
I0816 16:04:08.298897 20404 net.cpp:91] Creating Layer ReLU193
I0816 16:04:08.298905 20404 net.cpp:425] ReLU193 <- InnerProduct81
I0816 16:04:08.298923 20404 net.cpp:386] ReLU193 -> InnerProduct81 (in-place)
I0816 16:04:08.298955 20404 net.cpp:141] Setting up ReLU193
I0816 16:04:08.298966 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.298974 20404 net.cpp:156] Memory required for data: 2598407600
I0816 16:04:08.298981 20404 layer_factory.hpp:77] Creating layer InnerProduct82
I0816 16:04:08.298993 20404 net.cpp:91] Creating Layer InnerProduct82
I0816 16:04:08.299002 20404 net.cpp:425] InnerProduct82 <- InnerProduct81
I0816 16:04:08.299017 20404 net.cpp:399] InnerProduct82 -> InnerProduct82
I0816 16:04:08.299732 20404 net.cpp:141] Setting up InnerProduct82
I0816 16:04:08.299747 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.299756 20404 net.cpp:156] Memory required for data: 2598510000
I0816 16:04:08.299763 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:08.299773 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:08.299782 20404 layer_factory.hpp:77] Creating layer ReLU194
I0816 16:04:08.299793 20404 net.cpp:91] Creating Layer ReLU194
I0816 16:04:08.299801 20404 net.cpp:425] ReLU194 <- InnerProduct82
I0816 16:04:08.299813 20404 net.cpp:386] ReLU194 -> InnerProduct82 (in-place)
I0816 16:04:08.299825 20404 net.cpp:141] Setting up ReLU194
I0816 16:04:08.299835 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.299842 20404 net.cpp:156] Memory required for data: 2598612400
I0816 16:04:08.299850 20404 layer_factory.hpp:77] Creating layer Concat14
I0816 16:04:08.299861 20404 net.cpp:91] Creating Layer Concat14
I0816 16:04:08.299870 20404 net.cpp:425] Concat14 <- InnerProduct80
I0816 16:04:08.299880 20404 net.cpp:425] Concat14 <- InnerProduct82
I0816 16:04:08.299892 20404 net.cpp:399] Concat14 -> Concat14
I0816 16:04:08.299937 20404 net.cpp:141] Setting up Concat14
I0816 16:04:08.299952 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:08.299958 20404 net.cpp:156] Memory required for data: 2598817200
I0816 16:04:08.299967 20404 layer_factory.hpp:77] Creating layer InnerProduct83
I0816 16:04:08.299983 20404 net.cpp:91] Creating Layer InnerProduct83
I0816 16:04:08.299990 20404 net.cpp:425] InnerProduct83 <- Concat14
I0816 16:04:08.300004 20404 net.cpp:399] InnerProduct83 -> InnerProduct83
I0816 16:04:08.301795 20404 net.cpp:141] Setting up InnerProduct83
I0816 16:04:08.301817 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.301826 20404 net.cpp:156] Memory required for data: 2598919600
I0816 16:04:08.301836 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:08.301846 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:08.301853 20404 layer_factory.hpp:77] Creating layer ReLU195
I0816 16:04:08.301865 20404 net.cpp:91] Creating Layer ReLU195
I0816 16:04:08.301875 20404 net.cpp:425] ReLU195 <- InnerProduct83
I0816 16:04:08.301889 20404 net.cpp:386] ReLU195 -> InnerProduct83 (in-place)
I0816 16:04:08.301904 20404 net.cpp:141] Setting up ReLU195
I0816 16:04:08.301914 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.301921 20404 net.cpp:156] Memory required for data: 2599022000
I0816 16:04:08.301928 20404 layer_factory.hpp:77] Creating layer InnerProduct84
I0816 16:04:08.301941 20404 net.cpp:91] Creating Layer InnerProduct84
I0816 16:04:08.301950 20404 net.cpp:425] InnerProduct84 <- InnerProduct83
I0816 16:04:08.301965 20404 net.cpp:399] InnerProduct84 -> InnerProduct84
I0816 16:04:08.302397 20404 net.cpp:141] Setting up InnerProduct84
I0816 16:04:08.302412 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:08.302419 20404 net.cpp:156] Memory required for data: 2599073200
I0816 16:04:08.302428 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:08.302438 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:08.302446 20404 layer_factory.hpp:77] Creating layer ReLU196
I0816 16:04:08.302456 20404 net.cpp:91] Creating Layer ReLU196
I0816 16:04:08.302481 20404 net.cpp:425] ReLU196 <- InnerProduct84
I0816 16:04:08.302492 20404 net.cpp:386] ReLU196 -> InnerProduct84 (in-place)
I0816 16:04:08.302505 20404 net.cpp:141] Setting up ReLU196
I0816 16:04:08.302515 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:08.302523 20404 net.cpp:156] Memory required for data: 2599124400
I0816 16:04:08.302531 20404 layer_factory.hpp:77] Creating layer dt13
I0816 16:04:08.302542 20404 net.cpp:91] Creating Layer dt13
I0816 16:04:08.302551 20404 net.cpp:425] dt13 <- InnerProduct84
I0816 16:04:08.302568 20404 net.cpp:399] dt13 -> dt13
I0816 16:04:08.302752 20404 net.cpp:141] Setting up dt13
I0816 16:04:08.302767 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:08.302774 20404 net.cpp:156] Memory required for data: 2599124800
I0816 16:04:08.302783 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:08.302793 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:08.302800 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:08.302816 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:08.302825 20404 net.cpp:425] conv1 <- p2_p2_0_split_5
I0816 16:04:08.302839 20404 net.cpp:399] conv1 -> Convolution141
I0816 16:04:08.304966 20404 net.cpp:141] Setting up conv1
I0816 16:04:08.304985 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.304992 20404 net.cpp:156] Memory required for data: 2608955200
I0816 16:04:08.305006 20404 layer_factory.hpp:77] Creating layer ReLU197
I0816 16:04:08.305017 20404 net.cpp:91] Creating Layer ReLU197
I0816 16:04:08.305025 20404 net.cpp:425] ReLU197 <- Convolution141
I0816 16:04:08.305037 20404 net.cpp:386] ReLU197 -> Convolution141 (in-place)
I0816 16:04:08.305048 20404 net.cpp:141] Setting up ReLU197
I0816 16:04:08.305058 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.305066 20404 net.cpp:156] Memory required for data: 2618785600
I0816 16:04:08.305073 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:08.305088 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:08.305096 20404 net.cpp:425] norm1 <- Convolution141
I0816 16:04:08.305109 20404 net.cpp:399] norm1 -> LRN57
I0816 16:04:08.305171 20404 net.cpp:141] Setting up norm1
I0816 16:04:08.305184 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.305191 20404 net.cpp:156] Memory required for data: 2628616000
I0816 16:04:08.305198 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:08.305212 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:08.305220 20404 net.cpp:425] pool1 <- LRN57
I0816 16:04:08.305233 20404 net.cpp:399] pool1 -> Pooling85
I0816 16:04:08.305304 20404 net.cpp:141] Setting up pool1
I0816 16:04:08.305317 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:08.305325 20404 net.cpp:156] Memory required for data: 2631073600
I0816 16:04:08.305331 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:08.305349 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:08.305358 20404 net.cpp:425] conv2 <- Pooling85
I0816 16:04:08.305373 20404 net.cpp:399] conv2 -> Convolution142
I0816 16:04:08.321097 20404 net.cpp:141] Setting up conv2
I0816 16:04:08.321120 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.321128 20404 net.cpp:156] Memory required for data: 2637627200
I0816 16:04:08.321142 20404 layer_factory.hpp:77] Creating layer ReLU198
I0816 16:04:08.321166 20404 net.cpp:91] Creating Layer ReLU198
I0816 16:04:08.321176 20404 net.cpp:425] ReLU198 <- Convolution142
I0816 16:04:08.321187 20404 net.cpp:386] ReLU198 -> Convolution142 (in-place)
I0816 16:04:08.321200 20404 net.cpp:141] Setting up ReLU198
I0816 16:04:08.321220 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.321228 20404 net.cpp:156] Memory required for data: 2644180800
I0816 16:04:08.321235 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:08.321250 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:08.321259 20404 net.cpp:425] norm2 <- Convolution142
I0816 16:04:08.321271 20404 net.cpp:399] norm2 -> LRN58
I0816 16:04:08.321359 20404 net.cpp:141] Setting up norm2
I0816 16:04:08.321373 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.321382 20404 net.cpp:156] Memory required for data: 2650734400
I0816 16:04:08.321388 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:08.321399 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:08.321408 20404 net.cpp:425] pool2 <- LRN58
I0816 16:04:08.321424 20404 net.cpp:399] pool2 -> Pooling86
I0816 16:04:08.321493 20404 net.cpp:141] Setting up pool2
I0816 16:04:08.321507 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.321514 20404 net.cpp:156] Memory required for data: 2652372800
I0816 16:04:08.321521 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:08.321544 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:08.321557 20404 net.cpp:425] conv3 <- Pooling86
I0816 16:04:08.321569 20404 net.cpp:399] conv3 -> Convolution143
I0816 16:04:08.365671 20404 net.cpp:141] Setting up conv3
I0816 16:04:08.365756 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.365787 20404 net.cpp:156] Memory required for data: 2654830400
I0816 16:04:08.365828 20404 layer_factory.hpp:77] Creating layer ReLU199
I0816 16:04:08.365864 20404 net.cpp:91] Creating Layer ReLU199
I0816 16:04:08.365897 20404 net.cpp:425] ReLU199 <- Convolution143
I0816 16:04:08.365933 20404 net.cpp:386] ReLU199 -> Convolution143 (in-place)
I0816 16:04:08.365973 20404 net.cpp:141] Setting up ReLU199
I0816 16:04:08.366004 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.366032 20404 net.cpp:156] Memory required for data: 2657288000
I0816 16:04:08.366060 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:08.366122 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:08.366186 20404 net.cpp:425] conv4 <- Convolution143
I0816 16:04:08.366255 20404 net.cpp:399] conv4 -> Convolution144
I0816 16:04:08.399690 20404 net.cpp:141] Setting up conv4
I0816 16:04:08.399729 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.399735 20404 net.cpp:156] Memory required for data: 2659745600
I0816 16:04:08.399749 20404 layer_factory.hpp:77] Creating layer ReLU200
I0816 16:04:08.399763 20404 net.cpp:91] Creating Layer ReLU200
I0816 16:04:08.399780 20404 net.cpp:425] ReLU200 <- Convolution144
I0816 16:04:08.399791 20404 net.cpp:386] ReLU200 -> Convolution144 (in-place)
I0816 16:04:08.399803 20404 net.cpp:141] Setting up ReLU200
I0816 16:04:08.399811 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.399817 20404 net.cpp:156] Memory required for data: 2662203200
I0816 16:04:08.399822 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:08.399838 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:08.399844 20404 net.cpp:425] conv5 <- Convolution144
I0816 16:04:08.399857 20404 net.cpp:399] conv5 -> Convolution145
I0816 16:04:08.422018 20404 net.cpp:141] Setting up conv5
I0816 16:04:08.422047 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.422055 20404 net.cpp:156] Memory required for data: 2663841600
I0816 16:04:08.422065 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:08.422076 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:08.422086 20404 net.cpp:425] pool5 <- Convolution145
I0816 16:04:08.422104 20404 net.cpp:399] pool5 -> Pooling87
I0816 16:04:08.422173 20404 net.cpp:141] Setting up pool5
I0816 16:04:08.422181 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:08.422186 20404 net.cpp:156] Memory required for data: 2664251200
I0816 16:04:08.422193 20404 layer_factory.hpp:77] Creating layer InnerProduct85
I0816 16:04:08.422204 20404 net.cpp:91] Creating Layer InnerProduct85
I0816 16:04:08.422209 20404 net.cpp:425] InnerProduct85 <- Pooling87
I0816 16:04:08.422224 20404 net.cpp:399] InnerProduct85 -> InnerProduct85
I0816 16:04:08.425000 20404 net.cpp:141] Setting up InnerProduct85
I0816 16:04:08.425020 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.425029 20404 net.cpp:156] Memory required for data: 2664353600
I0816 16:04:08.425038 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:08.425065 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:08.425074 20404 layer_factory.hpp:77] Creating layer ReLU201
I0816 16:04:08.425086 20404 net.cpp:91] Creating Layer ReLU201
I0816 16:04:08.425096 20404 net.cpp:425] ReLU201 <- InnerProduct85
I0816 16:04:08.425109 20404 net.cpp:386] ReLU201 -> InnerProduct85 (in-place)
I0816 16:04:08.425123 20404 net.cpp:141] Setting up ReLU201
I0816 16:04:08.425134 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.425142 20404 net.cpp:156] Memory required for data: 2664456000
I0816 16:04:08.425148 20404 layer_factory.hpp:77] Creating layer InnerProduct86
I0816 16:04:08.425161 20404 net.cpp:91] Creating Layer InnerProduct86
I0816 16:04:08.425169 20404 net.cpp:425] InnerProduct86 <- InnerProduct85
I0816 16:04:08.425185 20404 net.cpp:399] InnerProduct86 -> InnerProduct86
I0816 16:04:08.426499 20404 net.cpp:141] Setting up InnerProduct86
I0816 16:04:08.426522 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.426530 20404 net.cpp:156] Memory required for data: 2664558400
I0816 16:04:08.426540 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:08.426551 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:08.426559 20404 layer_factory.hpp:77] Creating layer ReLU202
I0816 16:04:08.426570 20404 net.cpp:91] Creating Layer ReLU202
I0816 16:04:08.426580 20404 net.cpp:425] ReLU202 <- InnerProduct86
I0816 16:04:08.426591 20404 net.cpp:386] ReLU202 -> InnerProduct86 (in-place)
I0816 16:04:08.426606 20404 net.cpp:141] Setting up ReLU202
I0816 16:04:08.426616 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.426623 20404 net.cpp:156] Memory required for data: 2664660800
I0816 16:04:08.426631 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:08.426651 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:08.426661 20404 net.cpp:425] conv1 <- c15
I0816 16:04:08.426674 20404 net.cpp:399] conv1 -> Convolution146
I0816 16:04:08.428913 20404 net.cpp:141] Setting up conv1
I0816 16:04:08.428937 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.428946 20404 net.cpp:156] Memory required for data: 2674491200
I0816 16:04:08.428957 20404 layer_factory.hpp:77] Creating layer ReLU203
I0816 16:04:08.428967 20404 net.cpp:91] Creating Layer ReLU203
I0816 16:04:08.428975 20404 net.cpp:425] ReLU203 <- Convolution146
I0816 16:04:08.428987 20404 net.cpp:386] ReLU203 -> Convolution146 (in-place)
I0816 16:04:08.428999 20404 net.cpp:141] Setting up ReLU203
I0816 16:04:08.429008 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.429013 20404 net.cpp:156] Memory required for data: 2684321600
I0816 16:04:08.429019 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:08.429030 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:08.429045 20404 net.cpp:425] norm1 <- Convolution146
I0816 16:04:08.429057 20404 net.cpp:399] norm1 -> LRN59
I0816 16:04:08.429114 20404 net.cpp:141] Setting up norm1
I0816 16:04:08.429124 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.429132 20404 net.cpp:156] Memory required for data: 2694152000
I0816 16:04:08.429137 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:08.429149 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:08.429155 20404 net.cpp:425] pool1 <- LRN59
I0816 16:04:08.429165 20404 net.cpp:399] pool1 -> Pooling88
I0816 16:04:08.429227 20404 net.cpp:141] Setting up pool1
I0816 16:04:08.429237 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:08.429244 20404 net.cpp:156] Memory required for data: 2696609600
I0816 16:04:08.429249 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:08.429262 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:08.429276 20404 net.cpp:425] conv2 <- Pooling88
I0816 16:04:08.429291 20404 net.cpp:399] conv2 -> Convolution147
I0816 16:04:08.444782 20404 net.cpp:141] Setting up conv2
I0816 16:04:08.444802 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.444839 20404 net.cpp:156] Memory required for data: 2703163200
I0816 16:04:08.444854 20404 layer_factory.hpp:77] Creating layer ReLU204
I0816 16:04:08.444869 20404 net.cpp:91] Creating Layer ReLU204
I0816 16:04:08.444878 20404 net.cpp:425] ReLU204 <- Convolution147
I0816 16:04:08.444890 20404 net.cpp:386] ReLU204 -> Convolution147 (in-place)
I0816 16:04:08.444911 20404 net.cpp:141] Setting up ReLU204
I0816 16:04:08.444922 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.444929 20404 net.cpp:156] Memory required for data: 2709716800
I0816 16:04:08.444937 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:08.444948 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:08.444957 20404 net.cpp:425] norm2 <- Convolution147
I0816 16:04:08.444972 20404 net.cpp:399] norm2 -> LRN60
I0816 16:04:08.445042 20404 net.cpp:141] Setting up norm2
I0816 16:04:08.445056 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.445065 20404 net.cpp:156] Memory required for data: 2716270400
I0816 16:04:08.445071 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:08.445086 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:08.445094 20404 net.cpp:425] pool2 <- LRN60
I0816 16:04:08.445108 20404 net.cpp:399] pool2 -> Pooling89
I0816 16:04:08.445179 20404 net.cpp:141] Setting up pool2
I0816 16:04:08.445194 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.445200 20404 net.cpp:156] Memory required for data: 2717908800
I0816 16:04:08.445209 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:08.445228 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:08.445240 20404 net.cpp:425] conv3 <- Pooling89
I0816 16:04:08.445256 20404 net.cpp:399] conv3 -> Convolution148
I0816 16:04:08.489326 20404 net.cpp:141] Setting up conv3
I0816 16:04:08.489359 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.489378 20404 net.cpp:156] Memory required for data: 2720366400
I0816 16:04:08.489395 20404 layer_factory.hpp:77] Creating layer ReLU205
I0816 16:04:08.489414 20404 net.cpp:91] Creating Layer ReLU205
I0816 16:04:08.489426 20404 net.cpp:425] ReLU205 <- Convolution148
I0816 16:04:08.489449 20404 net.cpp:386] ReLU205 -> Convolution148 (in-place)
I0816 16:04:08.489465 20404 net.cpp:141] Setting up ReLU205
I0816 16:04:08.489475 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.489482 20404 net.cpp:156] Memory required for data: 2722824000
I0816 16:04:08.489490 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:08.489511 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:08.489519 20404 net.cpp:425] conv4 <- Convolution148
I0816 16:04:08.489537 20404 net.cpp:399] conv4 -> Convolution149
I0816 16:04:08.522852 20404 net.cpp:141] Setting up conv4
I0816 16:04:08.522884 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.522902 20404 net.cpp:156] Memory required for data: 2725281600
I0816 16:04:08.522918 20404 layer_factory.hpp:77] Creating layer ReLU206
I0816 16:04:08.522934 20404 net.cpp:91] Creating Layer ReLU206
I0816 16:04:08.522945 20404 net.cpp:425] ReLU206 <- Convolution149
I0816 16:04:08.522970 20404 net.cpp:386] ReLU206 -> Convolution149 (in-place)
I0816 16:04:08.522994 20404 net.cpp:141] Setting up ReLU206
I0816 16:04:08.523005 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.523013 20404 net.cpp:156] Memory required for data: 2727739200
I0816 16:04:08.523021 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:08.523042 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:08.523051 20404 net.cpp:425] conv5 <- Convolution149
I0816 16:04:08.523066 20404 net.cpp:399] conv5 -> Convolution150
I0816 16:04:08.545163 20404 net.cpp:141] Setting up conv5
I0816 16:04:08.545186 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.545194 20404 net.cpp:156] Memory required for data: 2729377600
I0816 16:04:08.545215 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:08.545228 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:08.545238 20404 net.cpp:425] pool5 <- Convolution150
I0816 16:04:08.545280 20404 net.cpp:399] pool5 -> Pooling90
I0816 16:04:08.545356 20404 net.cpp:141] Setting up pool5
I0816 16:04:08.545372 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:08.545379 20404 net.cpp:156] Memory required for data: 2729787200
I0816 16:04:08.545387 20404 layer_factory.hpp:77] Creating layer InnerProduct87
I0816 16:04:08.545403 20404 net.cpp:91] Creating Layer InnerProduct87
I0816 16:04:08.545413 20404 net.cpp:425] InnerProduct87 <- Pooling90
I0816 16:04:08.545433 20404 net.cpp:399] InnerProduct87 -> InnerProduct87
I0816 16:04:08.548197 20404 net.cpp:141] Setting up InnerProduct87
I0816 16:04:08.548218 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.548233 20404 net.cpp:156] Memory required for data: 2729889600
I0816 16:04:08.548243 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:08.548254 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:08.548261 20404 layer_factory.hpp:77] Creating layer ReLU207
I0816 16:04:08.548274 20404 net.cpp:91] Creating Layer ReLU207
I0816 16:04:08.548282 20404 net.cpp:425] ReLU207 <- InnerProduct87
I0816 16:04:08.548293 20404 net.cpp:386] ReLU207 -> InnerProduct87 (in-place)
I0816 16:04:08.548307 20404 net.cpp:141] Setting up ReLU207
I0816 16:04:08.548317 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.548326 20404 net.cpp:156] Memory required for data: 2729992000
I0816 16:04:08.548332 20404 layer_factory.hpp:77] Creating layer InnerProduct88
I0816 16:04:08.548348 20404 net.cpp:91] Creating Layer InnerProduct88
I0816 16:04:08.548357 20404 net.cpp:425] InnerProduct88 <- InnerProduct87
I0816 16:04:08.548373 20404 net.cpp:399] InnerProduct88 -> InnerProduct88
I0816 16:04:08.549072 20404 net.cpp:141] Setting up InnerProduct88
I0816 16:04:08.549088 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.549094 20404 net.cpp:156] Memory required for data: 2730094400
I0816 16:04:08.549103 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:08.549113 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:08.549120 20404 layer_factory.hpp:77] Creating layer ReLU208
I0816 16:04:08.549131 20404 net.cpp:91] Creating Layer ReLU208
I0816 16:04:08.549139 20404 net.cpp:425] ReLU208 <- InnerProduct88
I0816 16:04:08.549150 20404 net.cpp:386] ReLU208 -> InnerProduct88 (in-place)
I0816 16:04:08.549162 20404 net.cpp:141] Setting up ReLU208
I0816 16:04:08.549172 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.549180 20404 net.cpp:156] Memory required for data: 2730196800
I0816 16:04:08.549186 20404 layer_factory.hpp:77] Creating layer Concat15
I0816 16:04:08.549198 20404 net.cpp:91] Creating Layer Concat15
I0816 16:04:08.549206 20404 net.cpp:425] Concat15 <- InnerProduct86
I0816 16:04:08.549217 20404 net.cpp:425] Concat15 <- InnerProduct88
I0816 16:04:08.549233 20404 net.cpp:399] Concat15 -> Concat15
I0816 16:04:08.549275 20404 net.cpp:141] Setting up Concat15
I0816 16:04:08.549293 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:08.549300 20404 net.cpp:156] Memory required for data: 2730401600
I0816 16:04:08.549307 20404 layer_factory.hpp:77] Creating layer InnerProduct89
I0816 16:04:08.549319 20404 net.cpp:91] Creating Layer InnerProduct89
I0816 16:04:08.549327 20404 net.cpp:425] InnerProduct89 <- Concat15
I0816 16:04:08.549342 20404 net.cpp:399] InnerProduct89 -> InnerProduct89
I0816 16:04:08.550612 20404 net.cpp:141] Setting up InnerProduct89
I0816 16:04:08.550657 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.550684 20404 net.cpp:156] Memory required for data: 2730504000
I0816 16:04:08.550712 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:08.550750 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:08.550778 20404 layer_factory.hpp:77] Creating layer ReLU209
I0816 16:04:08.550822 20404 net.cpp:91] Creating Layer ReLU209
I0816 16:04:08.550851 20404 net.cpp:425] ReLU209 <- InnerProduct89
I0816 16:04:08.550881 20404 net.cpp:386] ReLU209 -> InnerProduct89 (in-place)
I0816 16:04:08.550900 20404 net.cpp:141] Setting up ReLU209
I0816 16:04:08.550911 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.550918 20404 net.cpp:156] Memory required for data: 2730606400
I0816 16:04:08.550926 20404 layer_factory.hpp:77] Creating layer InnerProduct90
I0816 16:04:08.550942 20404 net.cpp:91] Creating Layer InnerProduct90
I0816 16:04:08.550951 20404 net.cpp:425] InnerProduct90 <- InnerProduct89
I0816 16:04:08.550967 20404 net.cpp:399] InnerProduct90 -> InnerProduct90
I0816 16:04:08.551415 20404 net.cpp:141] Setting up InnerProduct90
I0816 16:04:08.551430 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:08.551437 20404 net.cpp:156] Memory required for data: 2730657600
I0816 16:04:08.551446 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:08.551455 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:08.551465 20404 layer_factory.hpp:77] Creating layer ReLU210
I0816 16:04:08.551475 20404 net.cpp:91] Creating Layer ReLU210
I0816 16:04:08.551482 20404 net.cpp:425] ReLU210 <- InnerProduct90
I0816 16:04:08.551493 20404 net.cpp:386] ReLU210 -> InnerProduct90 (in-place)
I0816 16:04:08.551506 20404 net.cpp:141] Setting up ReLU210
I0816 16:04:08.551515 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:08.551523 20404 net.cpp:156] Memory required for data: 2730708800
I0816 16:04:08.551530 20404 layer_factory.hpp:77] Creating layer dt14
I0816 16:04:08.551543 20404 net.cpp:91] Creating Layer dt14
I0816 16:04:08.551551 20404 net.cpp:425] dt14 <- InnerProduct90
I0816 16:04:08.551568 20404 net.cpp:399] dt14 -> dt14
I0816 16:04:08.551748 20404 net.cpp:141] Setting up dt14
I0816 16:04:08.551762 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:08.551770 20404 net.cpp:156] Memory required for data: 2730709200
I0816 16:04:08.551779 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:08.551787 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:08.551796 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:08.551815 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:08.551829 20404 net.cpp:425] conv1 <- p2_p2_0_split_6
I0816 16:04:08.551843 20404 net.cpp:399] conv1 -> Convolution151
I0816 16:04:08.554020 20404 net.cpp:141] Setting up conv1
I0816 16:04:08.554039 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.554046 20404 net.cpp:156] Memory required for data: 2740539600
I0816 16:04:08.554061 20404 layer_factory.hpp:77] Creating layer ReLU211
I0816 16:04:08.554074 20404 net.cpp:91] Creating Layer ReLU211
I0816 16:04:08.554081 20404 net.cpp:425] ReLU211 <- Convolution151
I0816 16:04:08.554096 20404 net.cpp:386] ReLU211 -> Convolution151 (in-place)
I0816 16:04:08.554111 20404 net.cpp:141] Setting up ReLU211
I0816 16:04:08.554121 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.554128 20404 net.cpp:156] Memory required for data: 2750370000
I0816 16:04:08.554136 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:08.554147 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:08.554155 20404 net.cpp:425] norm1 <- Convolution151
I0816 16:04:08.554172 20404 net.cpp:399] norm1 -> LRN61
I0816 16:04:08.554235 20404 net.cpp:141] Setting up norm1
I0816 16:04:08.554250 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.554257 20404 net.cpp:156] Memory required for data: 2760200400
I0816 16:04:08.554265 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:08.554275 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:08.554283 20404 net.cpp:425] pool1 <- LRN61
I0816 16:04:08.554298 20404 net.cpp:399] pool1 -> Pooling91
I0816 16:04:08.554373 20404 net.cpp:141] Setting up pool1
I0816 16:04:08.554385 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:08.554410 20404 net.cpp:156] Memory required for data: 2762658000
I0816 16:04:08.554419 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:08.554436 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:08.554445 20404 net.cpp:425] conv2 <- Pooling91
I0816 16:04:08.554458 20404 net.cpp:399] conv2 -> Convolution152
I0816 16:04:08.570592 20404 net.cpp:141] Setting up conv2
I0816 16:04:08.570617 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.570626 20404 net.cpp:156] Memory required for data: 2769211600
I0816 16:04:08.570823 20404 layer_factory.hpp:77] Creating layer ReLU212
I0816 16:04:08.570839 20404 net.cpp:91] Creating Layer ReLU212
I0816 16:04:08.570849 20404 net.cpp:425] ReLU212 <- Convolution152
I0816 16:04:08.570861 20404 net.cpp:386] ReLU212 -> Convolution152 (in-place)
I0816 16:04:08.570876 20404 net.cpp:141] Setting up ReLU212
I0816 16:04:08.570886 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.570894 20404 net.cpp:156] Memory required for data: 2775765200
I0816 16:04:08.570901 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:08.570912 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:08.570920 20404 net.cpp:425] norm2 <- Convolution152
I0816 16:04:08.570932 20404 net.cpp:399] norm2 -> LRN62
I0816 16:04:08.570993 20404 net.cpp:141] Setting up norm2
I0816 16:04:08.571007 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.571015 20404 net.cpp:156] Memory required for data: 2782318800
I0816 16:04:08.571022 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:08.571033 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:08.571040 20404 net.cpp:425] pool2 <- LRN62
I0816 16:04:08.571055 20404 net.cpp:399] pool2 -> Pooling92
I0816 16:04:08.571257 20404 net.cpp:141] Setting up pool2
I0816 16:04:08.571291 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.571300 20404 net.cpp:156] Memory required for data: 2783957200
I0816 16:04:08.571306 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:08.571326 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:08.571334 20404 net.cpp:425] conv3 <- Pooling92
I0816 16:04:08.571348 20404 net.cpp:399] conv3 -> Convolution153
I0816 16:04:08.615141 20404 net.cpp:141] Setting up conv3
I0816 16:04:08.615250 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.615260 20404 net.cpp:156] Memory required for data: 2786414800
I0816 16:04:08.615283 20404 layer_factory.hpp:77] Creating layer ReLU213
I0816 16:04:08.615299 20404 net.cpp:91] Creating Layer ReLU213
I0816 16:04:08.615311 20404 net.cpp:425] ReLU213 <- Convolution153
I0816 16:04:08.615324 20404 net.cpp:386] ReLU213 -> Convolution153 (in-place)
I0816 16:04:08.615340 20404 net.cpp:141] Setting up ReLU213
I0816 16:04:08.615351 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.615360 20404 net.cpp:156] Memory required for data: 2788872400
I0816 16:04:08.615366 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:08.615389 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:08.615402 20404 net.cpp:425] conv4 <- Convolution153
I0816 16:04:08.615428 20404 net.cpp:399] conv4 -> Convolution154
I0816 16:04:08.648478 20404 net.cpp:141] Setting up conv4
I0816 16:04:08.648511 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.648520 20404 net.cpp:156] Memory required for data: 2791330000
I0816 16:04:08.648541 20404 layer_factory.hpp:77] Creating layer ReLU214
I0816 16:04:08.648557 20404 net.cpp:91] Creating Layer ReLU214
I0816 16:04:08.648569 20404 net.cpp:425] ReLU214 <- Convolution154
I0816 16:04:08.648586 20404 net.cpp:386] ReLU214 -> Convolution154 (in-place)
I0816 16:04:08.648602 20404 net.cpp:141] Setting up ReLU214
I0816 16:04:08.648612 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.648619 20404 net.cpp:156] Memory required for data: 2793787600
I0816 16:04:08.648627 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:08.648648 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:08.648658 20404 net.cpp:425] conv5 <- Convolution154
I0816 16:04:08.648691 20404 net.cpp:399] conv5 -> Convolution155
I0816 16:04:08.670743 20404 net.cpp:141] Setting up conv5
I0816 16:04:08.670766 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.670774 20404 net.cpp:156] Memory required for data: 2795426000
I0816 16:04:08.670797 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:08.670810 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:08.670819 20404 net.cpp:425] pool5 <- Convolution155
I0816 16:04:08.670838 20404 net.cpp:399] pool5 -> Pooling93
I0816 16:04:08.670912 20404 net.cpp:141] Setting up pool5
I0816 16:04:08.670927 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:08.670933 20404 net.cpp:156] Memory required for data: 2795835600
I0816 16:04:08.670940 20404 layer_factory.hpp:77] Creating layer InnerProduct91
I0816 16:04:08.670958 20404 net.cpp:91] Creating Layer InnerProduct91
I0816 16:04:08.670965 20404 net.cpp:425] InnerProduct91 <- Pooling93
I0816 16:04:08.670982 20404 net.cpp:399] InnerProduct91 -> InnerProduct91
I0816 16:04:08.673773 20404 net.cpp:141] Setting up InnerProduct91
I0816 16:04:08.673795 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.673804 20404 net.cpp:156] Memory required for data: 2795938000
I0816 16:04:08.673815 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:08.673825 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:08.673832 20404 layer_factory.hpp:77] Creating layer ReLU215
I0816 16:04:08.673844 20404 net.cpp:91] Creating Layer ReLU215
I0816 16:04:08.673853 20404 net.cpp:425] ReLU215 <- InnerProduct91
I0816 16:04:08.673868 20404 net.cpp:386] ReLU215 -> InnerProduct91 (in-place)
I0816 16:04:08.673883 20404 net.cpp:141] Setting up ReLU215
I0816 16:04:08.673893 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.673902 20404 net.cpp:156] Memory required for data: 2796040400
I0816 16:04:08.673908 20404 layer_factory.hpp:77] Creating layer InnerProduct92
I0816 16:04:08.673921 20404 net.cpp:91] Creating Layer InnerProduct92
I0816 16:04:08.673929 20404 net.cpp:425] InnerProduct92 <- InnerProduct91
I0816 16:04:08.673945 20404 net.cpp:399] InnerProduct92 -> InnerProduct92
I0816 16:04:08.675212 20404 net.cpp:141] Setting up InnerProduct92
I0816 16:04:08.675232 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.675241 20404 net.cpp:156] Memory required for data: 2796142800
I0816 16:04:08.675251 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:08.675261 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:08.675269 20404 layer_factory.hpp:77] Creating layer ReLU216
I0816 16:04:08.675287 20404 net.cpp:91] Creating Layer ReLU216
I0816 16:04:08.675297 20404 net.cpp:425] ReLU216 <- InnerProduct92
I0816 16:04:08.675308 20404 net.cpp:386] ReLU216 -> InnerProduct92 (in-place)
I0816 16:04:08.675323 20404 net.cpp:141] Setting up ReLU216
I0816 16:04:08.675333 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.675339 20404 net.cpp:156] Memory required for data: 2796245200
I0816 16:04:08.675348 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:08.675370 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:08.675379 20404 net.cpp:425] conv1 <- c16
I0816 16:04:08.675393 20404 net.cpp:399] conv1 -> Convolution156
I0816 16:04:08.677469 20404 net.cpp:141] Setting up conv1
I0816 16:04:08.677489 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.677497 20404 net.cpp:156] Memory required for data: 2806075600
I0816 16:04:08.677511 20404 layer_factory.hpp:77] Creating layer ReLU217
I0816 16:04:08.677525 20404 net.cpp:91] Creating Layer ReLU217
I0816 16:04:08.677533 20404 net.cpp:425] ReLU217 <- Convolution156
I0816 16:04:08.677547 20404 net.cpp:386] ReLU217 -> Convolution156 (in-place)
I0816 16:04:08.677562 20404 net.cpp:141] Setting up ReLU217
I0816 16:04:08.677572 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.677580 20404 net.cpp:156] Memory required for data: 2815906000
I0816 16:04:08.677603 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:08.677615 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:08.677625 20404 net.cpp:425] norm1 <- Convolution156
I0816 16:04:08.677641 20404 net.cpp:399] norm1 -> LRN63
I0816 16:04:08.677698 20404 net.cpp:141] Setting up norm1
I0816 16:04:08.677712 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.677721 20404 net.cpp:156] Memory required for data: 2825736400
I0816 16:04:08.677727 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:08.677742 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:08.677750 20404 net.cpp:425] pool1 <- LRN63
I0816 16:04:08.677763 20404 net.cpp:399] pool1 -> Pooling94
I0816 16:04:08.677824 20404 net.cpp:141] Setting up pool1
I0816 16:04:08.677837 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:08.677845 20404 net.cpp:156] Memory required for data: 2828194000
I0816 16:04:08.677852 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:08.677871 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:08.677881 20404 net.cpp:425] conv2 <- Pooling94
I0816 16:04:08.677893 20404 net.cpp:399] conv2 -> Convolution157
I0816 16:04:08.693269 20404 net.cpp:141] Setting up conv2
I0816 16:04:08.693291 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.693300 20404 net.cpp:156] Memory required for data: 2834747600
I0816 16:04:08.693325 20404 layer_factory.hpp:77] Creating layer ReLU218
I0816 16:04:08.693336 20404 net.cpp:91] Creating Layer ReLU218
I0816 16:04:08.693346 20404 net.cpp:425] ReLU218 <- Convolution157
I0816 16:04:08.693361 20404 net.cpp:386] ReLU218 -> Convolution157 (in-place)
I0816 16:04:08.693374 20404 net.cpp:141] Setting up ReLU218
I0816 16:04:08.693394 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.693402 20404 net.cpp:156] Memory required for data: 2841301200
I0816 16:04:08.693409 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:08.693423 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:08.693433 20404 net.cpp:425] norm2 <- Convolution157
I0816 16:04:08.693445 20404 net.cpp:399] norm2 -> LRN64
I0816 16:04:08.693508 20404 net.cpp:141] Setting up norm2
I0816 16:04:08.693526 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.693533 20404 net.cpp:156] Memory required for data: 2847854800
I0816 16:04:08.693541 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:08.693552 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:08.693559 20404 net.cpp:425] pool2 <- LRN64
I0816 16:04:08.693572 20404 net.cpp:399] pool2 -> Pooling95
I0816 16:04:08.693634 20404 net.cpp:141] Setting up pool2
I0816 16:04:08.693646 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.693655 20404 net.cpp:156] Memory required for data: 2849493200
I0816 16:04:08.693661 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:08.693681 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:08.693691 20404 net.cpp:425] conv3 <- Pooling95
I0816 16:04:08.693706 20404 net.cpp:399] conv3 -> Convolution158
I0816 16:04:08.737565 20404 net.cpp:141] Setting up conv3
I0816 16:04:08.737599 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.737617 20404 net.cpp:156] Memory required for data: 2851950800
I0816 16:04:08.737635 20404 layer_factory.hpp:77] Creating layer ReLU219
I0816 16:04:08.737649 20404 net.cpp:91] Creating Layer ReLU219
I0816 16:04:08.737661 20404 net.cpp:425] ReLU219 <- Convolution158
I0816 16:04:08.737679 20404 net.cpp:386] ReLU219 -> Convolution158 (in-place)
I0816 16:04:08.737697 20404 net.cpp:141] Setting up ReLU219
I0816 16:04:08.737709 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.737715 20404 net.cpp:156] Memory required for data: 2854408400
I0816 16:04:08.737723 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:08.737743 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:08.737752 20404 net.cpp:425] conv4 <- Convolution158
I0816 16:04:08.737769 20404 net.cpp:399] conv4 -> Convolution159
I0816 16:04:08.770820 20404 net.cpp:141] Setting up conv4
I0816 16:04:08.770872 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.770881 20404 net.cpp:156] Memory required for data: 2856866000
I0816 16:04:08.770898 20404 layer_factory.hpp:77] Creating layer ReLU220
I0816 16:04:08.770912 20404 net.cpp:91] Creating Layer ReLU220
I0816 16:04:08.770922 20404 net.cpp:425] ReLU220 <- Convolution159
I0816 16:04:08.770938 20404 net.cpp:386] ReLU220 -> Convolution159 (in-place)
I0816 16:04:08.770953 20404 net.cpp:141] Setting up ReLU220
I0816 16:04:08.770963 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.770972 20404 net.cpp:156] Memory required for data: 2859323600
I0816 16:04:08.770979 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:08.770997 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:08.771005 20404 net.cpp:425] conv5 <- Convolution159
I0816 16:04:08.771028 20404 net.cpp:399] conv5 -> Convolution160
I0816 16:04:08.793017 20404 net.cpp:141] Setting up conv5
I0816 16:04:08.793040 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.793047 20404 net.cpp:156] Memory required for data: 2860962000
I0816 16:04:08.793071 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:08.793084 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:08.793093 20404 net.cpp:425] pool5 <- Convolution160
I0816 16:04:08.793112 20404 net.cpp:399] pool5 -> Pooling96
I0816 16:04:08.793185 20404 net.cpp:141] Setting up pool5
I0816 16:04:08.793200 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:08.793208 20404 net.cpp:156] Memory required for data: 2861371600
I0816 16:04:08.793215 20404 layer_factory.hpp:77] Creating layer InnerProduct93
I0816 16:04:08.793232 20404 net.cpp:91] Creating Layer InnerProduct93
I0816 16:04:08.793241 20404 net.cpp:425] InnerProduct93 <- Pooling96
I0816 16:04:08.793256 20404 net.cpp:399] InnerProduct93 -> InnerProduct93
I0816 16:04:08.795984 20404 net.cpp:141] Setting up InnerProduct93
I0816 16:04:08.796003 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.796011 20404 net.cpp:156] Memory required for data: 2861474000
I0816 16:04:08.796030 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:08.796041 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:08.796048 20404 layer_factory.hpp:77] Creating layer ReLU221
I0816 16:04:08.796059 20404 net.cpp:91] Creating Layer ReLU221
I0816 16:04:08.796068 20404 net.cpp:425] ReLU221 <- InnerProduct93
I0816 16:04:08.796090 20404 net.cpp:386] ReLU221 -> InnerProduct93 (in-place)
I0816 16:04:08.796105 20404 net.cpp:141] Setting up ReLU221
I0816 16:04:08.796115 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.796123 20404 net.cpp:156] Memory required for data: 2861576400
I0816 16:04:08.796130 20404 layer_factory.hpp:77] Creating layer InnerProduct94
I0816 16:04:08.796144 20404 net.cpp:91] Creating Layer InnerProduct94
I0816 16:04:08.796151 20404 net.cpp:425] InnerProduct94 <- InnerProduct93
I0816 16:04:08.796166 20404 net.cpp:399] InnerProduct94 -> InnerProduct94
I0816 16:04:08.796838 20404 net.cpp:141] Setting up InnerProduct94
I0816 16:04:08.796851 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.796869 20404 net.cpp:156] Memory required for data: 2861678800
I0816 16:04:08.796877 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:08.796886 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:08.796895 20404 layer_factory.hpp:77] Creating layer ReLU222
I0816 16:04:08.796905 20404 net.cpp:91] Creating Layer ReLU222
I0816 16:04:08.796913 20404 net.cpp:425] ReLU222 <- InnerProduct94
I0816 16:04:08.796928 20404 net.cpp:386] ReLU222 -> InnerProduct94 (in-place)
I0816 16:04:08.796941 20404 net.cpp:141] Setting up ReLU222
I0816 16:04:08.796952 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.796958 20404 net.cpp:156] Memory required for data: 2861781200
I0816 16:04:08.796967 20404 layer_factory.hpp:77] Creating layer Concat16
I0816 16:04:08.796994 20404 net.cpp:91] Creating Layer Concat16
I0816 16:04:08.797003 20404 net.cpp:425] Concat16 <- InnerProduct92
I0816 16:04:08.797013 20404 net.cpp:425] Concat16 <- InnerProduct94
I0816 16:04:08.797029 20404 net.cpp:399] Concat16 -> Concat16
I0816 16:04:08.797067 20404 net.cpp:141] Setting up Concat16
I0816 16:04:08.797081 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:08.797089 20404 net.cpp:156] Memory required for data: 2861986000
I0816 16:04:08.797096 20404 layer_factory.hpp:77] Creating layer InnerProduct95
I0816 16:04:08.797113 20404 net.cpp:91] Creating Layer InnerProduct95
I0816 16:04:08.797122 20404 net.cpp:425] InnerProduct95 <- Concat16
I0816 16:04:08.797137 20404 net.cpp:399] InnerProduct95 -> InnerProduct95
I0816 16:04:08.798879 20404 net.cpp:141] Setting up InnerProduct95
I0816 16:04:08.798902 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.798909 20404 net.cpp:156] Memory required for data: 2862088400
I0816 16:04:08.798918 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:08.798929 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:08.798938 20404 layer_factory.hpp:77] Creating layer ReLU223
I0816 16:04:08.798949 20404 net.cpp:91] Creating Layer ReLU223
I0816 16:04:08.798957 20404 net.cpp:425] ReLU223 <- InnerProduct95
I0816 16:04:08.798969 20404 net.cpp:386] ReLU223 -> InnerProduct95 (in-place)
I0816 16:04:08.798982 20404 net.cpp:141] Setting up ReLU223
I0816 16:04:08.798992 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.799000 20404 net.cpp:156] Memory required for data: 2862190800
I0816 16:04:08.799007 20404 layer_factory.hpp:77] Creating layer InnerProduct96
I0816 16:04:08.799023 20404 net.cpp:91] Creating Layer InnerProduct96
I0816 16:04:08.799031 20404 net.cpp:425] InnerProduct96 <- InnerProduct95
I0816 16:04:08.799046 20404 net.cpp:399] InnerProduct96 -> InnerProduct96
I0816 16:04:08.799477 20404 net.cpp:141] Setting up InnerProduct96
I0816 16:04:08.799494 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:08.799501 20404 net.cpp:156] Memory required for data: 2862242000
I0816 16:04:08.799510 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:08.799520 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:08.799528 20404 layer_factory.hpp:77] Creating layer ReLU224
I0816 16:04:08.799538 20404 net.cpp:91] Creating Layer ReLU224
I0816 16:04:08.799547 20404 net.cpp:425] ReLU224 <- InnerProduct96
I0816 16:04:08.799558 20404 net.cpp:386] ReLU224 -> InnerProduct96 (in-place)
I0816 16:04:08.799571 20404 net.cpp:141] Setting up ReLU224
I0816 16:04:08.799582 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:08.799588 20404 net.cpp:156] Memory required for data: 2862293200
I0816 16:04:08.799597 20404 layer_factory.hpp:77] Creating layer dt15
I0816 16:04:08.799607 20404 net.cpp:91] Creating Layer dt15
I0816 16:04:08.799615 20404 net.cpp:425] dt15 <- InnerProduct96
I0816 16:04:08.799633 20404 net.cpp:399] dt15 -> dt15
I0816 16:04:08.799824 20404 net.cpp:141] Setting up dt15
I0816 16:04:08.799866 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:08.799880 20404 net.cpp:156] Memory required for data: 2862293600
I0816 16:04:08.799890 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:08.799898 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:08.799907 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:08.799929 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:08.799942 20404 net.cpp:425] conv1 <- p2_p2_0_split_7
I0816 16:04:08.799957 20404 net.cpp:399] conv1 -> Convolution161
I0816 16:04:08.802034 20404 net.cpp:141] Setting up conv1
I0816 16:04:08.802052 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.802060 20404 net.cpp:156] Memory required for data: 2872124000
I0816 16:04:08.802090 20404 layer_factory.hpp:77] Creating layer ReLU225
I0816 16:04:08.802105 20404 net.cpp:91] Creating Layer ReLU225
I0816 16:04:08.802114 20404 net.cpp:425] ReLU225 <- Convolution161
I0816 16:04:08.802129 20404 net.cpp:386] ReLU225 -> Convolution161 (in-place)
I0816 16:04:08.802141 20404 net.cpp:141] Setting up ReLU225
I0816 16:04:08.802152 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.802160 20404 net.cpp:156] Memory required for data: 2881954400
I0816 16:04:08.802166 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:08.802178 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:08.802186 20404 net.cpp:425] norm1 <- Convolution161
I0816 16:04:08.802203 20404 net.cpp:399] norm1 -> LRN65
I0816 16:04:08.802258 20404 net.cpp:141] Setting up norm1
I0816 16:04:08.802270 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.802278 20404 net.cpp:156] Memory required for data: 2891784800
I0816 16:04:08.802285 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:08.802296 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:08.802304 20404 net.cpp:425] pool1 <- LRN65
I0816 16:04:08.802320 20404 net.cpp:399] pool1 -> Pooling97
I0816 16:04:08.802379 20404 net.cpp:141] Setting up pool1
I0816 16:04:08.802392 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:08.802399 20404 net.cpp:156] Memory required for data: 2894242400
I0816 16:04:08.802407 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:08.802426 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:08.802438 20404 net.cpp:425] conv2 <- Pooling97
I0816 16:04:08.802451 20404 net.cpp:399] conv2 -> Convolution162
I0816 16:04:08.818055 20404 net.cpp:141] Setting up conv2
I0816 16:04:08.818078 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.818085 20404 net.cpp:156] Memory required for data: 2900796000
I0816 16:04:08.818099 20404 layer_factory.hpp:77] Creating layer ReLU226
I0816 16:04:08.818120 20404 net.cpp:91] Creating Layer ReLU226
I0816 16:04:08.818130 20404 net.cpp:425] ReLU226 <- Convolution162
I0816 16:04:08.818145 20404 net.cpp:386] ReLU226 -> Convolution162 (in-place)
I0816 16:04:08.818158 20404 net.cpp:141] Setting up ReLU226
I0816 16:04:08.818174 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.818182 20404 net.cpp:156] Memory required for data: 2907349600
I0816 16:04:08.818191 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:08.818202 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:08.818209 20404 net.cpp:425] norm2 <- Convolution162
I0816 16:04:08.818225 20404 net.cpp:399] norm2 -> LRN66
I0816 16:04:08.818287 20404 net.cpp:141] Setting up norm2
I0816 16:04:08.818302 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.818310 20404 net.cpp:156] Memory required for data: 2913903200
I0816 16:04:08.818316 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:08.818330 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:08.818338 20404 net.cpp:425] pool2 <- LRN66
I0816 16:04:08.818351 20404 net.cpp:399] pool2 -> Pooling98
I0816 16:04:08.818415 20404 net.cpp:141] Setting up pool2
I0816 16:04:08.818429 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.818436 20404 net.cpp:156] Memory required for data: 2915541600
I0816 16:04:08.818444 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:08.818464 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:08.818475 20404 net.cpp:425] conv3 <- Pooling98
I0816 16:04:08.818491 20404 net.cpp:399] conv3 -> Convolution163
I0816 16:04:08.862252 20404 net.cpp:141] Setting up conv3
I0816 16:04:08.862282 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.862300 20404 net.cpp:156] Memory required for data: 2917999200
I0816 16:04:08.862318 20404 layer_factory.hpp:77] Creating layer ReLU227
I0816 16:04:08.862334 20404 net.cpp:91] Creating Layer ReLU227
I0816 16:04:08.862344 20404 net.cpp:425] ReLU227 <- Convolution163
I0816 16:04:08.862359 20404 net.cpp:386] ReLU227 -> Convolution163 (in-place)
I0816 16:04:08.862382 20404 net.cpp:141] Setting up ReLU227
I0816 16:04:08.862414 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.862422 20404 net.cpp:156] Memory required for data: 2920456800
I0816 16:04:08.862431 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:08.862450 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:08.862462 20404 net.cpp:425] conv4 <- Convolution163
I0816 16:04:08.862483 20404 net.cpp:399] conv4 -> Convolution164
I0816 16:04:08.895478 20404 net.cpp:141] Setting up conv4
I0816 16:04:08.895516 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.895525 20404 net.cpp:156] Memory required for data: 2922914400
I0816 16:04:08.895541 20404 layer_factory.hpp:77] Creating layer ReLU228
I0816 16:04:08.895555 20404 net.cpp:91] Creating Layer ReLU228
I0816 16:04:08.895566 20404 net.cpp:425] ReLU228 <- Convolution164
I0816 16:04:08.895581 20404 net.cpp:386] ReLU228 -> Convolution164 (in-place)
I0816 16:04:08.895597 20404 net.cpp:141] Setting up ReLU228
I0816 16:04:08.895612 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.895620 20404 net.cpp:156] Memory required for data: 2925372000
I0816 16:04:08.895627 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:08.895644 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:08.895653 20404 net.cpp:425] conv5 <- Convolution164
I0816 16:04:08.895675 20404 net.cpp:399] conv5 -> Convolution165
I0816 16:04:08.917968 20404 net.cpp:141] Setting up conv5
I0816 16:04:08.917990 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.917999 20404 net.cpp:156] Memory required for data: 2927010400
I0816 16:04:08.918020 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:08.918038 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:08.918047 20404 net.cpp:425] pool5 <- Convolution165
I0816 16:04:08.918063 20404 net.cpp:399] pool5 -> Pooling99
I0816 16:04:08.918141 20404 net.cpp:141] Setting up pool5
I0816 16:04:08.918155 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:08.918162 20404 net.cpp:156] Memory required for data: 2927420000
I0816 16:04:08.918170 20404 layer_factory.hpp:77] Creating layer InnerProduct97
I0816 16:04:08.918187 20404 net.cpp:91] Creating Layer InnerProduct97
I0816 16:04:08.918195 20404 net.cpp:425] InnerProduct97 <- Pooling99
I0816 16:04:08.918210 20404 net.cpp:399] InnerProduct97 -> InnerProduct97
I0816 16:04:08.920972 20404 net.cpp:141] Setting up InnerProduct97
I0816 16:04:08.920994 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.921001 20404 net.cpp:156] Memory required for data: 2927522400
I0816 16:04:08.921011 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:08.921021 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:08.921030 20404 layer_factory.hpp:77] Creating layer ReLU229
I0816 16:04:08.921044 20404 net.cpp:91] Creating Layer ReLU229
I0816 16:04:08.921053 20404 net.cpp:425] ReLU229 <- InnerProduct97
I0816 16:04:08.921064 20404 net.cpp:386] ReLU229 -> InnerProduct97 (in-place)
I0816 16:04:08.921078 20404 net.cpp:141] Setting up ReLU229
I0816 16:04:08.921088 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.921097 20404 net.cpp:156] Memory required for data: 2927624800
I0816 16:04:08.921104 20404 layer_factory.hpp:77] Creating layer InnerProduct98
I0816 16:04:08.921119 20404 net.cpp:91] Creating Layer InnerProduct98
I0816 16:04:08.921128 20404 net.cpp:425] InnerProduct98 <- InnerProduct97
I0816 16:04:08.921141 20404 net.cpp:399] InnerProduct98 -> InnerProduct98
I0816 16:04:08.922394 20404 net.cpp:141] Setting up InnerProduct98
I0816 16:04:08.922415 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.922423 20404 net.cpp:156] Memory required for data: 2927727200
I0816 16:04:08.922432 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:08.922442 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:08.922451 20404 layer_factory.hpp:77] Creating layer ReLU230
I0816 16:04:08.922466 20404 net.cpp:91] Creating Layer ReLU230
I0816 16:04:08.922492 20404 net.cpp:425] ReLU230 <- InnerProduct98
I0816 16:04:08.922503 20404 net.cpp:386] ReLU230 -> InnerProduct98 (in-place)
I0816 16:04:08.922518 20404 net.cpp:141] Setting up ReLU230
I0816 16:04:08.922528 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:08.922535 20404 net.cpp:156] Memory required for data: 2927829600
I0816 16:04:08.922543 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:08.922562 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:08.922570 20404 net.cpp:425] conv1 <- c17
I0816 16:04:08.922590 20404 net.cpp:399] conv1 -> Convolution166
I0816 16:04:08.924655 20404 net.cpp:141] Setting up conv1
I0816 16:04:08.924677 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.924685 20404 net.cpp:156] Memory required for data: 2937660000
I0816 16:04:08.924700 20404 layer_factory.hpp:77] Creating layer ReLU231
I0816 16:04:08.924710 20404 net.cpp:91] Creating Layer ReLU231
I0816 16:04:08.924718 20404 net.cpp:425] ReLU231 <- Convolution166
I0816 16:04:08.924729 20404 net.cpp:386] ReLU231 -> Convolution166 (in-place)
I0816 16:04:08.924742 20404 net.cpp:141] Setting up ReLU231
I0816 16:04:08.924752 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.924760 20404 net.cpp:156] Memory required for data: 2947490400
I0816 16:04:08.924767 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:08.924783 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:08.924792 20404 net.cpp:425] norm1 <- Convolution166
I0816 16:04:08.924805 20404 net.cpp:399] norm1 -> LRN67
I0816 16:04:08.924921 20404 net.cpp:141] Setting up norm1
I0816 16:04:08.924934 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:08.924942 20404 net.cpp:156] Memory required for data: 2957320800
I0816 16:04:08.924949 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:08.924962 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:08.924969 20404 net.cpp:425] pool1 <- LRN67
I0816 16:04:08.924984 20404 net.cpp:399] pool1 -> Pooling100
I0816 16:04:08.925045 20404 net.cpp:141] Setting up pool1
I0816 16:04:08.925062 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:08.925070 20404 net.cpp:156] Memory required for data: 2959778400
I0816 16:04:08.925077 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:08.925092 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:08.925101 20404 net.cpp:425] conv2 <- Pooling100
I0816 16:04:08.925117 20404 net.cpp:399] conv2 -> Convolution167
I0816 16:04:08.940606 20404 net.cpp:141] Setting up conv2
I0816 16:04:08.940629 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.940637 20404 net.cpp:156] Memory required for data: 2966332000
I0816 16:04:08.940661 20404 layer_factory.hpp:77] Creating layer ReLU232
I0816 16:04:08.940673 20404 net.cpp:91] Creating Layer ReLU232
I0816 16:04:08.940682 20404 net.cpp:425] ReLU232 <- Convolution167
I0816 16:04:08.940695 20404 net.cpp:386] ReLU232 -> Convolution167 (in-place)
I0816 16:04:08.940708 20404 net.cpp:141] Setting up ReLU232
I0816 16:04:08.940726 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.940734 20404 net.cpp:156] Memory required for data: 2972885600
I0816 16:04:08.940742 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:08.940757 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:08.940764 20404 net.cpp:425] norm2 <- Convolution167
I0816 16:04:08.940778 20404 net.cpp:399] norm2 -> LRN68
I0816 16:04:08.940842 20404 net.cpp:141] Setting up norm2
I0816 16:04:08.940856 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:08.940863 20404 net.cpp:156] Memory required for data: 2979439200
I0816 16:04:08.940871 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:08.940881 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:08.940889 20404 net.cpp:425] pool2 <- LRN68
I0816 16:04:08.940904 20404 net.cpp:399] pool2 -> Pooling101
I0816 16:04:08.940968 20404 net.cpp:141] Setting up pool2
I0816 16:04:08.940984 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:08.940990 20404 net.cpp:156] Memory required for data: 2981077600
I0816 16:04:08.941018 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:08.941037 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:08.941048 20404 net.cpp:425] conv3 <- Pooling101
I0816 16:04:08.941061 20404 net.cpp:399] conv3 -> Convolution168
I0816 16:04:08.984951 20404 net.cpp:141] Setting up conv3
I0816 16:04:08.984982 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.984999 20404 net.cpp:156] Memory required for data: 2983535200
I0816 16:04:08.985016 20404 layer_factory.hpp:77] Creating layer ReLU233
I0816 16:04:08.985030 20404 net.cpp:91] Creating Layer ReLU233
I0816 16:04:08.985043 20404 net.cpp:425] ReLU233 <- Convolution168
I0816 16:04:08.985059 20404 net.cpp:386] ReLU233 -> Convolution168 (in-place)
I0816 16:04:08.985083 20404 net.cpp:141] Setting up ReLU233
I0816 16:04:08.985095 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:08.985101 20404 net.cpp:156] Memory required for data: 2985992800
I0816 16:04:08.985110 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:08.985129 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:08.985138 20404 net.cpp:425] conv4 <- Convolution168
I0816 16:04:08.985152 20404 net.cpp:399] conv4 -> Convolution169
I0816 16:04:09.018481 20404 net.cpp:141] Setting up conv4
I0816 16:04:09.018510 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.018518 20404 net.cpp:156] Memory required for data: 2988450400
I0816 16:04:09.018534 20404 layer_factory.hpp:77] Creating layer ReLU234
I0816 16:04:09.018548 20404 net.cpp:91] Creating Layer ReLU234
I0816 16:04:09.018558 20404 net.cpp:425] ReLU234 <- Convolution169
I0816 16:04:09.018571 20404 net.cpp:386] ReLU234 -> Convolution169 (in-place)
I0816 16:04:09.018586 20404 net.cpp:141] Setting up ReLU234
I0816 16:04:09.018596 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.018604 20404 net.cpp:156] Memory required for data: 2990908000
I0816 16:04:09.018611 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:09.018630 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:09.018640 20404 net.cpp:425] conv5 <- Convolution169
I0816 16:04:09.018656 20404 net.cpp:399] conv5 -> Convolution170
I0816 16:04:09.040660 20404 net.cpp:141] Setting up conv5
I0816 16:04:09.040683 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:09.040691 20404 net.cpp:156] Memory required for data: 2992546400
I0816 16:04:09.040714 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:09.040730 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:09.040740 20404 net.cpp:425] pool5 <- Convolution170
I0816 16:04:09.040755 20404 net.cpp:399] pool5 -> Pooling102
I0816 16:04:09.040840 20404 net.cpp:141] Setting up pool5
I0816 16:04:09.040885 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:09.040913 20404 net.cpp:156] Memory required for data: 2992956000
I0816 16:04:09.040940 20404 layer_factory.hpp:77] Creating layer InnerProduct99
I0816 16:04:09.040974 20404 net.cpp:91] Creating Layer InnerProduct99
I0816 16:04:09.041002 20404 net.cpp:425] InnerProduct99 <- Pooling102
I0816 16:04:09.041040 20404 net.cpp:399] InnerProduct99 -> InnerProduct99
I0816 16:04:09.043869 20404 net.cpp:141] Setting up InnerProduct99
I0816 16:04:09.043905 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.043911 20404 net.cpp:156] Memory required for data: 2993058400
I0816 16:04:09.043921 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:09.043931 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:09.043937 20404 layer_factory.hpp:77] Creating layer ReLU235
I0816 16:04:09.043949 20404 net.cpp:91] Creating Layer ReLU235
I0816 16:04:09.043964 20404 net.cpp:425] ReLU235 <- InnerProduct99
I0816 16:04:09.043974 20404 net.cpp:386] ReLU235 -> InnerProduct99 (in-place)
I0816 16:04:09.043987 20404 net.cpp:141] Setting up ReLU235
I0816 16:04:09.043997 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.044003 20404 net.cpp:156] Memory required for data: 2993160800
I0816 16:04:09.044031 20404 layer_factory.hpp:77] Creating layer InnerProduct100
I0816 16:04:09.044042 20404 net.cpp:91] Creating Layer InnerProduct100
I0816 16:04:09.044049 20404 net.cpp:425] InnerProduct100 <- InnerProduct99
I0816 16:04:09.044062 20404 net.cpp:399] InnerProduct100 -> InnerProduct100
I0816 16:04:09.044780 20404 net.cpp:141] Setting up InnerProduct100
I0816 16:04:09.044826 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.044852 20404 net.cpp:156] Memory required for data: 2993263200
I0816 16:04:09.044881 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:09.044912 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:09.044942 20404 layer_factory.hpp:77] Creating layer ReLU236
I0816 16:04:09.044975 20404 net.cpp:91] Creating Layer ReLU236
I0816 16:04:09.044988 20404 net.cpp:425] ReLU236 <- InnerProduct100
I0816 16:04:09.045001 20404 net.cpp:386] ReLU236 -> InnerProduct100 (in-place)
I0816 16:04:09.045016 20404 net.cpp:141] Setting up ReLU236
I0816 16:04:09.045025 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.045033 20404 net.cpp:156] Memory required for data: 2993365600
I0816 16:04:09.045042 20404 layer_factory.hpp:77] Creating layer Concat17
I0816 16:04:09.045053 20404 net.cpp:91] Creating Layer Concat17
I0816 16:04:09.045061 20404 net.cpp:425] Concat17 <- InnerProduct98
I0816 16:04:09.045071 20404 net.cpp:425] Concat17 <- InnerProduct100
I0816 16:04:09.045084 20404 net.cpp:399] Concat17 -> Concat17
I0816 16:04:09.045131 20404 net.cpp:141] Setting up Concat17
I0816 16:04:09.045145 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:09.045152 20404 net.cpp:156] Memory required for data: 2993570400
I0816 16:04:09.045161 20404 layer_factory.hpp:77] Creating layer InnerProduct101
I0816 16:04:09.045176 20404 net.cpp:91] Creating Layer InnerProduct101
I0816 16:04:09.045186 20404 net.cpp:425] InnerProduct101 <- Concat17
I0816 16:04:09.045198 20404 net.cpp:399] InnerProduct101 -> InnerProduct101
I0816 16:04:09.046381 20404 net.cpp:141] Setting up InnerProduct101
I0816 16:04:09.046396 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.046403 20404 net.cpp:156] Memory required for data: 2993672800
I0816 16:04:09.046412 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:09.046422 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:09.046430 20404 layer_factory.hpp:77] Creating layer ReLU237
I0816 16:04:09.046440 20404 net.cpp:91] Creating Layer ReLU237
I0816 16:04:09.046449 20404 net.cpp:425] ReLU237 <- InnerProduct101
I0816 16:04:09.046460 20404 net.cpp:386] ReLU237 -> InnerProduct101 (in-place)
I0816 16:04:09.046473 20404 net.cpp:141] Setting up ReLU237
I0816 16:04:09.046483 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.046491 20404 net.cpp:156] Memory required for data: 2993775200
I0816 16:04:09.046499 20404 layer_factory.hpp:77] Creating layer InnerProduct102
I0816 16:04:09.046511 20404 net.cpp:91] Creating Layer InnerProduct102
I0816 16:04:09.046519 20404 net.cpp:425] InnerProduct102 <- InnerProduct101
I0816 16:04:09.046535 20404 net.cpp:399] InnerProduct102 -> InnerProduct102
I0816 16:04:09.046938 20404 net.cpp:141] Setting up InnerProduct102
I0816 16:04:09.046952 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:09.046960 20404 net.cpp:156] Memory required for data: 2993826400
I0816 16:04:09.046968 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:09.046978 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:09.046989 20404 layer_factory.hpp:77] Creating layer ReLU238
I0816 16:04:09.047003 20404 net.cpp:91] Creating Layer ReLU238
I0816 16:04:09.047011 20404 net.cpp:425] ReLU238 <- InnerProduct102
I0816 16:04:09.047022 20404 net.cpp:386] ReLU238 -> InnerProduct102 (in-place)
I0816 16:04:09.047035 20404 net.cpp:141] Setting up ReLU238
I0816 16:04:09.047065 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:09.047072 20404 net.cpp:156] Memory required for data: 2993877600
I0816 16:04:09.047080 20404 layer_factory.hpp:77] Creating layer dt16
I0816 16:04:09.047091 20404 net.cpp:91] Creating Layer dt16
I0816 16:04:09.047099 20404 net.cpp:425] dt16 <- InnerProduct102
I0816 16:04:09.047113 20404 net.cpp:399] dt16 -> dt16
I0816 16:04:09.047333 20404 net.cpp:141] Setting up dt16
I0816 16:04:09.047348 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:09.047355 20404 net.cpp:156] Memory required for data: 2993878000
I0816 16:04:09.047363 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:09.047374 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:09.047381 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:09.047401 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:09.047415 20404 net.cpp:425] conv1 <- p2_p2_0_split_8
I0816 16:04:09.047430 20404 net.cpp:399] conv1 -> Convolution171
I0816 16:04:09.049489 20404 net.cpp:141] Setting up conv1
I0816 16:04:09.049504 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.049512 20404 net.cpp:156] Memory required for data: 3003708400
I0816 16:04:09.049526 20404 layer_factory.hpp:77] Creating layer ReLU239
I0816 16:04:09.049540 20404 net.cpp:91] Creating Layer ReLU239
I0816 16:04:09.049549 20404 net.cpp:425] ReLU239 <- Convolution171
I0816 16:04:09.049561 20404 net.cpp:386] ReLU239 -> Convolution171 (in-place)
I0816 16:04:09.049573 20404 net.cpp:141] Setting up ReLU239
I0816 16:04:09.049583 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.049592 20404 net.cpp:156] Memory required for data: 3013538800
I0816 16:04:09.049598 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:09.049612 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:09.049621 20404 net.cpp:425] norm1 <- Convolution171
I0816 16:04:09.049634 20404 net.cpp:399] norm1 -> LRN69
I0816 16:04:09.049690 20404 net.cpp:141] Setting up norm1
I0816 16:04:09.049705 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.049711 20404 net.cpp:156] Memory required for data: 3023369200
I0816 16:04:09.049720 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:09.049731 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:09.049738 20404 net.cpp:425] pool1 <- LRN69
I0816 16:04:09.049749 20404 net.cpp:399] pool1 -> Pooling103
I0816 16:04:09.049813 20404 net.cpp:141] Setting up pool1
I0816 16:04:09.049828 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:09.049834 20404 net.cpp:156] Memory required for data: 3025826800
I0816 16:04:09.049841 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:09.049860 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:09.049868 20404 net.cpp:425] conv2 <- Pooling103
I0816 16:04:09.049885 20404 net.cpp:399] conv2 -> Convolution172
I0816 16:04:09.065394 20404 net.cpp:141] Setting up conv2
I0816 16:04:09.065415 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.065423 20404 net.cpp:156] Memory required for data: 3032380400
I0816 16:04:09.065438 20404 layer_factory.hpp:77] Creating layer ReLU240
I0816 16:04:09.065459 20404 net.cpp:91] Creating Layer ReLU240
I0816 16:04:09.065469 20404 net.cpp:425] ReLU240 <- Convolution172
I0816 16:04:09.065480 20404 net.cpp:386] ReLU240 -> Convolution172 (in-place)
I0816 16:04:09.065495 20404 net.cpp:141] Setting up ReLU240
I0816 16:04:09.065510 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.065518 20404 net.cpp:156] Memory required for data: 3038934000
I0816 16:04:09.065526 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:09.065539 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:09.065548 20404 net.cpp:425] norm2 <- Convolution172
I0816 16:04:09.065560 20404 net.cpp:399] norm2 -> LRN70
I0816 16:04:09.065624 20404 net.cpp:141] Setting up norm2
I0816 16:04:09.065639 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.065646 20404 net.cpp:156] Memory required for data: 3045487600
I0816 16:04:09.065670 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:09.065685 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:09.065693 20404 net.cpp:425] pool2 <- LRN70
I0816 16:04:09.065708 20404 net.cpp:399] pool2 -> Pooling104
I0816 16:04:09.065768 20404 net.cpp:141] Setting up pool2
I0816 16:04:09.065783 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:09.065790 20404 net.cpp:156] Memory required for data: 3047126000
I0816 16:04:09.065798 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:09.065817 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:09.065829 20404 net.cpp:425] conv3 <- Pooling104
I0816 16:04:09.065845 20404 net.cpp:399] conv3 -> Convolution173
I0816 16:04:09.109825 20404 net.cpp:141] Setting up conv3
I0816 16:04:09.109858 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.109866 20404 net.cpp:156] Memory required for data: 3049583600
I0816 16:04:09.109884 20404 layer_factory.hpp:77] Creating layer ReLU241
I0816 16:04:09.109902 20404 net.cpp:91] Creating Layer ReLU241
I0816 16:04:09.109915 20404 net.cpp:425] ReLU241 <- Convolution173
I0816 16:04:09.109928 20404 net.cpp:386] ReLU241 -> Convolution173 (in-place)
I0816 16:04:09.109944 20404 net.cpp:141] Setting up ReLU241
I0816 16:04:09.109959 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.109967 20404 net.cpp:156] Memory required for data: 3052041200
I0816 16:04:09.109975 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:09.109995 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:09.110004 20404 net.cpp:425] conv4 <- Convolution173
I0816 16:04:09.110021 20404 net.cpp:399] conv4 -> Convolution174
I0816 16:04:09.143113 20404 net.cpp:141] Setting up conv4
I0816 16:04:09.143143 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.143162 20404 net.cpp:156] Memory required for data: 3054498800
I0816 16:04:09.143179 20404 layer_factory.hpp:77] Creating layer ReLU242
I0816 16:04:09.143193 20404 net.cpp:91] Creating Layer ReLU242
I0816 16:04:09.143205 20404 net.cpp:425] ReLU242 <- Convolution174
I0816 16:04:09.143231 20404 net.cpp:386] ReLU242 -> Convolution174 (in-place)
I0816 16:04:09.143249 20404 net.cpp:141] Setting up ReLU242
I0816 16:04:09.143260 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.143266 20404 net.cpp:156] Memory required for data: 3056956400
I0816 16:04:09.143278 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:09.143299 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:09.143308 20404 net.cpp:425] conv5 <- Convolution174
I0816 16:04:09.143321 20404 net.cpp:399] conv5 -> Convolution175
I0816 16:04:09.165364 20404 net.cpp:141] Setting up conv5
I0816 16:04:09.165387 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:09.165395 20404 net.cpp:156] Memory required for data: 3058594800
I0816 16:04:09.165411 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:09.165426 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:09.165434 20404 net.cpp:425] pool5 <- Convolution175
I0816 16:04:09.165452 20404 net.cpp:399] pool5 -> Pooling105
I0816 16:04:09.165519 20404 net.cpp:141] Setting up pool5
I0816 16:04:09.165534 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:09.165540 20404 net.cpp:156] Memory required for data: 3059004400
I0816 16:04:09.165549 20404 layer_factory.hpp:77] Creating layer InnerProduct103
I0816 16:04:09.165565 20404 net.cpp:91] Creating Layer InnerProduct103
I0816 16:04:09.165573 20404 net.cpp:425] InnerProduct103 <- Pooling105
I0816 16:04:09.165592 20404 net.cpp:399] InnerProduct103 -> InnerProduct103
I0816 16:04:09.168360 20404 net.cpp:141] Setting up InnerProduct103
I0816 16:04:09.168390 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.168397 20404 net.cpp:156] Memory required for data: 3059106800
I0816 16:04:09.168407 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:09.168417 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:09.168444 20404 layer_factory.hpp:77] Creating layer ReLU243
I0816 16:04:09.168457 20404 net.cpp:91] Creating Layer ReLU243
I0816 16:04:09.168465 20404 net.cpp:425] ReLU243 <- InnerProduct103
I0816 16:04:09.168480 20404 net.cpp:386] ReLU243 -> InnerProduct103 (in-place)
I0816 16:04:09.168548 20404 net.cpp:141] Setting up ReLU243
I0816 16:04:09.168558 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.168566 20404 net.cpp:156] Memory required for data: 3059209200
I0816 16:04:09.168573 20404 layer_factory.hpp:77] Creating layer InnerProduct104
I0816 16:04:09.168587 20404 net.cpp:91] Creating Layer InnerProduct104
I0816 16:04:09.168596 20404 net.cpp:425] InnerProduct104 <- InnerProduct103
I0816 16:04:09.168612 20404 net.cpp:399] InnerProduct104 -> InnerProduct104
I0816 16:04:09.169888 20404 net.cpp:141] Setting up InnerProduct104
I0816 16:04:09.169909 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.169916 20404 net.cpp:156] Memory required for data: 3059311600
I0816 16:04:09.169926 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:09.169936 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:09.169945 20404 layer_factory.hpp:77] Creating layer ReLU244
I0816 16:04:09.169956 20404 net.cpp:91] Creating Layer ReLU244
I0816 16:04:09.169965 20404 net.cpp:425] ReLU244 <- InnerProduct104
I0816 16:04:09.169976 20404 net.cpp:386] ReLU244 -> InnerProduct104 (in-place)
I0816 16:04:09.169991 20404 net.cpp:141] Setting up ReLU244
I0816 16:04:09.170001 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.170008 20404 net.cpp:156] Memory required for data: 3059414000
I0816 16:04:09.170016 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:09.170038 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:09.170048 20404 net.cpp:425] conv1 <- c18
I0816 16:04:09.170063 20404 net.cpp:399] conv1 -> Convolution176
I0816 16:04:09.172163 20404 net.cpp:141] Setting up conv1
I0816 16:04:09.172178 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.172186 20404 net.cpp:156] Memory required for data: 3069244400
I0816 16:04:09.172200 20404 layer_factory.hpp:77] Creating layer ReLU245
I0816 16:04:09.172211 20404 net.cpp:91] Creating Layer ReLU245
I0816 16:04:09.172224 20404 net.cpp:425] ReLU245 <- Convolution176
I0816 16:04:09.172240 20404 net.cpp:386] ReLU245 -> Convolution176 (in-place)
I0816 16:04:09.172253 20404 net.cpp:141] Setting up ReLU245
I0816 16:04:09.172263 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.172271 20404 net.cpp:156] Memory required for data: 3079074800
I0816 16:04:09.172278 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:09.172291 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:09.172299 20404 net.cpp:425] norm1 <- Convolution176
I0816 16:04:09.172314 20404 net.cpp:399] norm1 -> LRN71
I0816 16:04:09.172370 20404 net.cpp:141] Setting up norm1
I0816 16:04:09.172384 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.172391 20404 net.cpp:156] Memory required for data: 3088905200
I0816 16:04:09.172399 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:09.172410 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:09.172417 20404 net.cpp:425] pool1 <- LRN71
I0816 16:04:09.172433 20404 net.cpp:399] pool1 -> Pooling106
I0816 16:04:09.172497 20404 net.cpp:141] Setting up pool1
I0816 16:04:09.172511 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:09.172519 20404 net.cpp:156] Memory required for data: 3091362800
I0816 16:04:09.172526 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:09.172544 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:09.172552 20404 net.cpp:425] conv2 <- Pooling106
I0816 16:04:09.172565 20404 net.cpp:399] conv2 -> Convolution177
I0816 16:04:09.187938 20404 net.cpp:141] Setting up conv2
I0816 16:04:09.187958 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.187966 20404 net.cpp:156] Memory required for data: 3097916400
I0816 16:04:09.188006 20404 layer_factory.hpp:77] Creating layer ReLU246
I0816 16:04:09.188019 20404 net.cpp:91] Creating Layer ReLU246
I0816 16:04:09.188029 20404 net.cpp:425] ReLU246 <- Convolution177
I0816 16:04:09.188042 20404 net.cpp:386] ReLU246 -> Convolution177 (in-place)
I0816 16:04:09.188066 20404 net.cpp:141] Setting up ReLU246
I0816 16:04:09.188081 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.188088 20404 net.cpp:156] Memory required for data: 3104470000
I0816 16:04:09.188096 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:09.188107 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:09.188115 20404 net.cpp:425] norm2 <- Convolution177
I0816 16:04:09.188132 20404 net.cpp:399] norm2 -> LRN72
I0816 16:04:09.188195 20404 net.cpp:141] Setting up norm2
I0816 16:04:09.188212 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.188220 20404 net.cpp:156] Memory required for data: 3111023600
I0816 16:04:09.188227 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:09.188238 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:09.188246 20404 net.cpp:425] pool2 <- LRN72
I0816 16:04:09.188258 20404 net.cpp:399] pool2 -> Pooling107
I0816 16:04:09.188324 20404 net.cpp:141] Setting up pool2
I0816 16:04:09.188338 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:09.188345 20404 net.cpp:156] Memory required for data: 3112662000
I0816 16:04:09.188354 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:09.188371 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:09.188385 20404 net.cpp:425] conv3 <- Pooling107
I0816 16:04:09.188400 20404 net.cpp:399] conv3 -> Convolution178
I0816 16:04:09.232102 20404 net.cpp:141] Setting up conv3
I0816 16:04:09.232136 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.232154 20404 net.cpp:156] Memory required for data: 3115119600
I0816 16:04:09.232172 20404 layer_factory.hpp:77] Creating layer ReLU247
I0816 16:04:09.232185 20404 net.cpp:91] Creating Layer ReLU247
I0816 16:04:09.232197 20404 net.cpp:425] ReLU247 <- Convolution178
I0816 16:04:09.232218 20404 net.cpp:386] ReLU247 -> Convolution178 (in-place)
I0816 16:04:09.232234 20404 net.cpp:141] Setting up ReLU247
I0816 16:04:09.232244 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.232251 20404 net.cpp:156] Memory required for data: 3117577200
I0816 16:04:09.232259 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:09.232280 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:09.232295 20404 net.cpp:425] conv4 <- Convolution178
I0816 16:04:09.232311 20404 net.cpp:399] conv4 -> Convolution179
I0816 16:04:09.265632 20404 net.cpp:141] Setting up conv4
I0816 16:04:09.265661 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.265673 20404 net.cpp:156] Memory required for data: 3120034800
I0816 16:04:09.265691 20404 layer_factory.hpp:77] Creating layer ReLU248
I0816 16:04:09.265704 20404 net.cpp:91] Creating Layer ReLU248
I0816 16:04:09.265717 20404 net.cpp:425] ReLU248 <- Convolution179
I0816 16:04:09.265732 20404 net.cpp:386] ReLU248 -> Convolution179 (in-place)
I0816 16:04:09.265748 20404 net.cpp:141] Setting up ReLU248
I0816 16:04:09.265758 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.265766 20404 net.cpp:156] Memory required for data: 3122492400
I0816 16:04:09.265774 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:09.265790 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:09.265799 20404 net.cpp:425] conv5 <- Convolution179
I0816 16:04:09.265815 20404 net.cpp:399] conv5 -> Convolution180
I0816 16:04:09.287839 20404 net.cpp:141] Setting up conv5
I0816 16:04:09.287861 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:09.287869 20404 net.cpp:156] Memory required for data: 3124130800
I0816 16:04:09.287894 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:09.287912 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:09.287922 20404 net.cpp:425] pool5 <- Convolution180
I0816 16:04:09.287950 20404 net.cpp:399] pool5 -> Pooling108
I0816 16:04:09.288022 20404 net.cpp:141] Setting up pool5
I0816 16:04:09.288053 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:09.288061 20404 net.cpp:156] Memory required for data: 3124540400
I0816 16:04:09.288069 20404 layer_factory.hpp:77] Creating layer InnerProduct105
I0816 16:04:09.288085 20404 net.cpp:91] Creating Layer InnerProduct105
I0816 16:04:09.288094 20404 net.cpp:425] InnerProduct105 <- Pooling108
I0816 16:04:09.288108 20404 net.cpp:399] InnerProduct105 -> InnerProduct105
I0816 16:04:09.290864 20404 net.cpp:141] Setting up InnerProduct105
I0816 16:04:09.290885 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.290894 20404 net.cpp:156] Memory required for data: 3124642800
I0816 16:04:09.290904 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:09.290915 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:09.290922 20404 layer_factory.hpp:77] Creating layer ReLU249
I0816 16:04:09.290935 20404 net.cpp:91] Creating Layer ReLU249
I0816 16:04:09.290943 20404 net.cpp:425] ReLU249 <- InnerProduct105
I0816 16:04:09.290954 20404 net.cpp:386] ReLU249 -> InnerProduct105 (in-place)
I0816 16:04:09.290968 20404 net.cpp:141] Setting up ReLU249
I0816 16:04:09.290978 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.290985 20404 net.cpp:156] Memory required for data: 3124745200
I0816 16:04:09.290993 20404 layer_factory.hpp:77] Creating layer InnerProduct106
I0816 16:04:09.291008 20404 net.cpp:91] Creating Layer InnerProduct106
I0816 16:04:09.291016 20404 net.cpp:425] InnerProduct106 <- InnerProduct105
I0816 16:04:09.291029 20404 net.cpp:399] InnerProduct106 -> InnerProduct106
I0816 16:04:09.291724 20404 net.cpp:141] Setting up InnerProduct106
I0816 16:04:09.291741 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.291749 20404 net.cpp:156] Memory required for data: 3124847600
I0816 16:04:09.291757 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:09.291767 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:09.291775 20404 layer_factory.hpp:77] Creating layer ReLU250
I0816 16:04:09.291786 20404 net.cpp:91] Creating Layer ReLU250
I0816 16:04:09.291795 20404 net.cpp:425] ReLU250 <- InnerProduct106
I0816 16:04:09.291810 20404 net.cpp:386] ReLU250 -> InnerProduct106 (in-place)
I0816 16:04:09.291823 20404 net.cpp:141] Setting up ReLU250
I0816 16:04:09.291833 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.291841 20404 net.cpp:156] Memory required for data: 3124950000
I0816 16:04:09.291847 20404 layer_factory.hpp:77] Creating layer Concat18
I0816 16:04:09.291860 20404 net.cpp:91] Creating Layer Concat18
I0816 16:04:09.291868 20404 net.cpp:425] Concat18 <- InnerProduct104
I0816 16:04:09.291878 20404 net.cpp:425] Concat18 <- InnerProduct106
I0816 16:04:09.291895 20404 net.cpp:399] Concat18 -> Concat18
I0816 16:04:09.291936 20404 net.cpp:141] Setting up Concat18
I0816 16:04:09.291949 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:09.291957 20404 net.cpp:156] Memory required for data: 3125154800
I0816 16:04:09.291965 20404 layer_factory.hpp:77] Creating layer InnerProduct107
I0816 16:04:09.291980 20404 net.cpp:91] Creating Layer InnerProduct107
I0816 16:04:09.291988 20404 net.cpp:425] InnerProduct107 <- Concat18
I0816 16:04:09.292003 20404 net.cpp:399] InnerProduct107 -> InnerProduct107
I0816 16:04:09.293884 20404 net.cpp:141] Setting up InnerProduct107
I0816 16:04:09.293905 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.293915 20404 net.cpp:156] Memory required for data: 3125257200
I0816 16:04:09.293925 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:09.293936 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:09.293943 20404 layer_factory.hpp:77] Creating layer ReLU251
I0816 16:04:09.293956 20404 net.cpp:91] Creating Layer ReLU251
I0816 16:04:09.293965 20404 net.cpp:425] ReLU251 <- InnerProduct107
I0816 16:04:09.293992 20404 net.cpp:386] ReLU251 -> InnerProduct107 (in-place)
I0816 16:04:09.294008 20404 net.cpp:141] Setting up ReLU251
I0816 16:04:09.294018 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.294026 20404 net.cpp:156] Memory required for data: 3125359600
I0816 16:04:09.294034 20404 layer_factory.hpp:77] Creating layer InnerProduct108
I0816 16:04:09.294050 20404 net.cpp:91] Creating Layer InnerProduct108
I0816 16:04:09.294059 20404 net.cpp:425] InnerProduct108 <- InnerProduct107
I0816 16:04:09.294072 20404 net.cpp:399] InnerProduct108 -> InnerProduct108
I0816 16:04:09.294487 20404 net.cpp:141] Setting up InnerProduct108
I0816 16:04:09.294502 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:09.294510 20404 net.cpp:156] Memory required for data: 3125410800
I0816 16:04:09.294519 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:09.294531 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:09.294538 20404 layer_factory.hpp:77] Creating layer ReLU252
I0816 16:04:09.294548 20404 net.cpp:91] Creating Layer ReLU252
I0816 16:04:09.294556 20404 net.cpp:425] ReLU252 <- InnerProduct108
I0816 16:04:09.294569 20404 net.cpp:386] ReLU252 -> InnerProduct108 (in-place)
I0816 16:04:09.294581 20404 net.cpp:141] Setting up ReLU252
I0816 16:04:09.294591 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:09.294598 20404 net.cpp:156] Memory required for data: 3125462000
I0816 16:04:09.294606 20404 layer_factory.hpp:77] Creating layer dt17
I0816 16:04:09.294618 20404 net.cpp:91] Creating Layer dt17
I0816 16:04:09.294626 20404 net.cpp:425] dt17 <- InnerProduct108
I0816 16:04:09.294644 20404 net.cpp:399] dt17 -> dt17
I0816 16:04:09.294809 20404 net.cpp:141] Setting up dt17
I0816 16:04:09.294823 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:09.294831 20404 net.cpp:156] Memory required for data: 3125462400
I0816 16:04:09.294839 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:09.294848 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:09.294857 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:09.294878 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:09.294888 20404 net.cpp:425] conv1 <- p2_p2_0_split_9
I0816 16:04:09.294903 20404 net.cpp:399] conv1 -> Convolution181
I0816 16:04:09.297039 20404 net.cpp:141] Setting up conv1
I0816 16:04:09.297052 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.297060 20404 net.cpp:156] Memory required for data: 3135292800
I0816 16:04:09.297075 20404 layer_factory.hpp:77] Creating layer ReLU253
I0816 16:04:09.297086 20404 net.cpp:91] Creating Layer ReLU253
I0816 16:04:09.297094 20404 net.cpp:425] ReLU253 <- Convolution181
I0816 16:04:09.297108 20404 net.cpp:386] ReLU253 -> Convolution181 (in-place)
I0816 16:04:09.297122 20404 net.cpp:141] Setting up ReLU253
I0816 16:04:09.297133 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.297142 20404 net.cpp:156] Memory required for data: 3145123200
I0816 16:04:09.297150 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:09.297163 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:09.297173 20404 net.cpp:425] norm1 <- Convolution181
I0816 16:04:09.297185 20404 net.cpp:399] norm1 -> LRN73
I0816 16:04:09.297247 20404 net.cpp:141] Setting up norm1
I0816 16:04:09.297261 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.297269 20404 net.cpp:156] Memory required for data: 3154953600
I0816 16:04:09.297276 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:09.297287 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:09.297296 20404 net.cpp:425] pool1 <- LRN73
I0816 16:04:09.297310 20404 net.cpp:399] pool1 -> Pooling109
I0816 16:04:09.297375 20404 net.cpp:141] Setting up pool1
I0816 16:04:09.297389 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:09.297396 20404 net.cpp:156] Memory required for data: 3157411200
I0816 16:04:09.297420 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:09.297442 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:09.297456 20404 net.cpp:425] conv2 <- Pooling109
I0816 16:04:09.297468 20404 net.cpp:399] conv2 -> Convolution182
I0816 16:04:09.312948 20404 net.cpp:141] Setting up conv2
I0816 16:04:09.312969 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.312978 20404 net.cpp:156] Memory required for data: 3163964800
I0816 16:04:09.313001 20404 layer_factory.hpp:77] Creating layer ReLU254
I0816 16:04:09.313014 20404 net.cpp:91] Creating Layer ReLU254
I0816 16:04:09.313022 20404 net.cpp:425] ReLU254 <- Convolution182
I0816 16:04:09.313033 20404 net.cpp:386] ReLU254 -> Convolution182 (in-place)
I0816 16:04:09.313047 20404 net.cpp:141] Setting up ReLU254
I0816 16:04:09.313067 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.313076 20404 net.cpp:156] Memory required for data: 3170518400
I0816 16:04:09.313082 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:09.313097 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:09.313105 20404 net.cpp:425] norm2 <- Convolution182
I0816 16:04:09.313120 20404 net.cpp:399] norm2 -> LRN74
I0816 16:04:09.313184 20404 net.cpp:141] Setting up norm2
I0816 16:04:09.313199 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.313206 20404 net.cpp:156] Memory required for data: 3177072000
I0816 16:04:09.313215 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:09.313227 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:09.313235 20404 net.cpp:425] pool2 <- LRN74
I0816 16:04:09.313247 20404 net.cpp:399] pool2 -> Pooling110
I0816 16:04:09.313313 20404 net.cpp:141] Setting up pool2
I0816 16:04:09.313326 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:09.313334 20404 net.cpp:156] Memory required for data: 3178710400
I0816 16:04:09.313341 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:09.313360 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:09.313372 20404 net.cpp:425] conv3 <- Pooling110
I0816 16:04:09.313390 20404 net.cpp:399] conv3 -> Convolution183
I0816 16:04:09.357275 20404 net.cpp:141] Setting up conv3
I0816 16:04:09.357305 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.357313 20404 net.cpp:156] Memory required for data: 3181168000
I0816 16:04:09.357331 20404 layer_factory.hpp:77] Creating layer ReLU255
I0816 16:04:09.357349 20404 net.cpp:91] Creating Layer ReLU255
I0816 16:04:09.357362 20404 net.cpp:425] ReLU255 <- Convolution183
I0816 16:04:09.357374 20404 net.cpp:386] ReLU255 -> Convolution183 (in-place)
I0816 16:04:09.357391 20404 net.cpp:141] Setting up ReLU255
I0816 16:04:09.357401 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.357409 20404 net.cpp:156] Memory required for data: 3183625600
I0816 16:04:09.357417 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:09.357437 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:09.357446 20404 net.cpp:425] conv4 <- Convolution183
I0816 16:04:09.357460 20404 net.cpp:399] conv4 -> Convolution184
I0816 16:04:09.390769 20404 net.cpp:141] Setting up conv4
I0816 16:04:09.390801 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.390810 20404 net.cpp:156] Memory required for data: 3186083200
I0816 16:04:09.390828 20404 layer_factory.hpp:77] Creating layer ReLU256
I0816 16:04:09.390846 20404 net.cpp:91] Creating Layer ReLU256
I0816 16:04:09.390858 20404 net.cpp:425] ReLU256 <- Convolution184
I0816 16:04:09.390872 20404 net.cpp:386] ReLU256 -> Convolution184 (in-place)
I0816 16:04:09.390888 20404 net.cpp:141] Setting up ReLU256
I0816 16:04:09.390898 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.390907 20404 net.cpp:156] Memory required for data: 3188540800
I0816 16:04:09.390913 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:09.390933 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:09.390943 20404 net.cpp:425] conv5 <- Convolution184
I0816 16:04:09.390960 20404 net.cpp:399] conv5 -> Convolution185
I0816 16:04:09.412977 20404 net.cpp:141] Setting up conv5
I0816 16:04:09.413018 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:09.413038 20404 net.cpp:156] Memory required for data: 3190179200
I0816 16:04:09.413051 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:09.413069 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:09.413079 20404 net.cpp:425] pool5 <- Convolution185
I0816 16:04:09.413094 20404 net.cpp:399] pool5 -> Pooling111
I0816 16:04:09.413174 20404 net.cpp:141] Setting up pool5
I0816 16:04:09.413188 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:09.413594 20404 net.cpp:156] Memory required for data: 3190588800
I0816 16:04:09.413602 20404 layer_factory.hpp:77] Creating layer InnerProduct109
I0816 16:04:09.413619 20404 net.cpp:91] Creating Layer InnerProduct109
I0816 16:04:09.413628 20404 net.cpp:425] InnerProduct109 <- Pooling111
I0816 16:04:09.413643 20404 net.cpp:399] InnerProduct109 -> InnerProduct109
I0816 16:04:09.416532 20404 net.cpp:141] Setting up InnerProduct109
I0816 16:04:09.416553 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.416563 20404 net.cpp:156] Memory required for data: 3190691200
I0816 16:04:09.416573 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:09.416584 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:09.416591 20404 layer_factory.hpp:77] Creating layer ReLU257
I0816 16:04:09.416607 20404 net.cpp:91] Creating Layer ReLU257
I0816 16:04:09.416617 20404 net.cpp:425] ReLU257 <- InnerProduct109
I0816 16:04:09.416630 20404 net.cpp:386] ReLU257 -> InnerProduct109 (in-place)
I0816 16:04:09.416643 20404 net.cpp:141] Setting up ReLU257
I0816 16:04:09.416653 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.416661 20404 net.cpp:156] Memory required for data: 3190793600
I0816 16:04:09.416668 20404 layer_factory.hpp:77] Creating layer InnerProduct110
I0816 16:04:09.416684 20404 net.cpp:91] Creating Layer InnerProduct110
I0816 16:04:09.416692 20404 net.cpp:425] InnerProduct110 <- InnerProduct109
I0816 16:04:09.416705 20404 net.cpp:399] InnerProduct110 -> InnerProduct110
I0816 16:04:09.417990 20404 net.cpp:141] Setting up InnerProduct110
I0816 16:04:09.418011 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.418020 20404 net.cpp:156] Memory required for data: 3190896000
I0816 16:04:09.418030 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:09.418040 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:09.418048 20404 layer_factory.hpp:77] Creating layer ReLU258
I0816 16:04:09.418063 20404 net.cpp:91] Creating Layer ReLU258
I0816 16:04:09.418072 20404 net.cpp:425] ReLU258 <- InnerProduct110
I0816 16:04:09.418083 20404 net.cpp:386] ReLU258 -> InnerProduct110 (in-place)
I0816 16:04:09.418097 20404 net.cpp:141] Setting up ReLU258
I0816 16:04:09.418107 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.418115 20404 net.cpp:156] Memory required for data: 3190998400
I0816 16:04:09.418123 20404 layer_factory.hpp:77] Creating layer conv1
I0816 16:04:09.418143 20404 net.cpp:91] Creating Layer conv1
I0816 16:04:09.418151 20404 net.cpp:425] conv1 <- c19
I0816 16:04:09.418170 20404 net.cpp:399] conv1 -> Convolution186
I0816 16:04:09.420255 20404 net.cpp:141] Setting up conv1
I0816 16:04:09.420271 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.420279 20404 net.cpp:156] Memory required for data: 3200828800
I0816 16:04:09.420292 20404 layer_factory.hpp:77] Creating layer ReLU259
I0816 16:04:09.420303 20404 net.cpp:91] Creating Layer ReLU259
I0816 16:04:09.420312 20404 net.cpp:425] ReLU259 <- Convolution186
I0816 16:04:09.420323 20404 net.cpp:386] ReLU259 -> Convolution186 (in-place)
I0816 16:04:09.420337 20404 net.cpp:141] Setting up ReLU259
I0816 16:04:09.420347 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.420354 20404 net.cpp:156] Memory required for data: 3210659200
I0816 16:04:09.420363 20404 layer_factory.hpp:77] Creating layer norm1
I0816 16:04:09.420377 20404 net.cpp:91] Creating Layer norm1
I0816 16:04:09.420387 20404 net.cpp:425] norm1 <- Convolution186
I0816 16:04:09.420400 20404 net.cpp:399] norm1 -> LRN75
I0816 16:04:09.420457 20404 net.cpp:141] Setting up norm1
I0816 16:04:09.420472 20404 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I0816 16:04:09.420480 20404 net.cpp:156] Memory required for data: 3220489600
I0816 16:04:09.420487 20404 layer_factory.hpp:77] Creating layer pool1
I0816 16:04:09.420503 20404 net.cpp:91] Creating Layer pool1
I0816 16:04:09.420511 20404 net.cpp:425] pool1 <- LRN75
I0816 16:04:09.420544 20404 net.cpp:399] pool1 -> Pooling112
I0816 16:04:09.420611 20404 net.cpp:141] Setting up pool1
I0816 16:04:09.420625 20404 net.cpp:148] Top shape: 100 96 8 8 (614400)
I0816 16:04:09.420632 20404 net.cpp:156] Memory required for data: 3222947200
I0816 16:04:09.420640 20404 layer_factory.hpp:77] Creating layer conv2
I0816 16:04:09.420658 20404 net.cpp:91] Creating Layer conv2
I0816 16:04:09.420666 20404 net.cpp:425] conv2 <- Pooling112
I0816 16:04:09.420682 20404 net.cpp:399] conv2 -> Convolution187
I0816 16:04:09.436141 20404 net.cpp:141] Setting up conv2
I0816 16:04:09.436164 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.436172 20404 net.cpp:156] Memory required for data: 3229500800
I0816 16:04:09.436195 20404 layer_factory.hpp:77] Creating layer ReLU260
I0816 16:04:09.436211 20404 net.cpp:91] Creating Layer ReLU260
I0816 16:04:09.436221 20404 net.cpp:425] ReLU260 <- Convolution187
I0816 16:04:09.436233 20404 net.cpp:386] ReLU260 -> Convolution187 (in-place)
I0816 16:04:09.436246 20404 net.cpp:141] Setting up ReLU260
I0816 16:04:09.436267 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.436275 20404 net.cpp:156] Memory required for data: 3236054400
I0816 16:04:09.436281 20404 layer_factory.hpp:77] Creating layer norm2
I0816 16:04:09.436296 20404 net.cpp:91] Creating Layer norm2
I0816 16:04:09.436305 20404 net.cpp:425] norm2 <- Convolution187
I0816 16:04:09.436317 20404 net.cpp:399] norm2 -> LRN76
I0816 16:04:09.436384 20404 net.cpp:141] Setting up norm2
I0816 16:04:09.436398 20404 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0816 16:04:09.436405 20404 net.cpp:156] Memory required for data: 3242608000
I0816 16:04:09.436413 20404 layer_factory.hpp:77] Creating layer pool2
I0816 16:04:09.436424 20404 net.cpp:91] Creating Layer pool2
I0816 16:04:09.436431 20404 net.cpp:425] pool2 <- LRN76
I0816 16:04:09.436446 20404 net.cpp:399] pool2 -> Pooling113
I0816 16:04:09.436511 20404 net.cpp:141] Setting up pool2
I0816 16:04:09.436524 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:09.436532 20404 net.cpp:156] Memory required for data: 3244246400
I0816 16:04:09.436540 20404 layer_factory.hpp:77] Creating layer conv3
I0816 16:04:09.436563 20404 net.cpp:91] Creating Layer conv3
I0816 16:04:09.436573 20404 net.cpp:425] conv3 <- Pooling113
I0816 16:04:09.436586 20404 net.cpp:399] conv3 -> Convolution188
I0816 16:04:09.480654 20404 net.cpp:141] Setting up conv3
I0816 16:04:09.480685 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.480695 20404 net.cpp:156] Memory required for data: 3246704000
I0816 16:04:09.480718 20404 layer_factory.hpp:77] Creating layer ReLU261
I0816 16:04:09.480734 20404 net.cpp:91] Creating Layer ReLU261
I0816 16:04:09.480746 20404 net.cpp:425] ReLU261 <- Convolution188
I0816 16:04:09.480763 20404 net.cpp:386] ReLU261 -> Convolution188 (in-place)
I0816 16:04:09.480788 20404 net.cpp:141] Setting up ReLU261
I0816 16:04:09.480803 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.480811 20404 net.cpp:156] Memory required for data: 3249161600
I0816 16:04:09.480818 20404 layer_factory.hpp:77] Creating layer conv4
I0816 16:04:09.480839 20404 net.cpp:91] Creating Layer conv4
I0816 16:04:09.480849 20404 net.cpp:425] conv4 <- Convolution188
I0816 16:04:09.480862 20404 net.cpp:399] conv4 -> Convolution189
I0816 16:04:09.513937 20404 net.cpp:141] Setting up conv4
I0816 16:04:09.513967 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.513975 20404 net.cpp:156] Memory required for data: 3251619200
I0816 16:04:09.513993 20404 layer_factory.hpp:77] Creating layer ReLU262
I0816 16:04:09.514006 20404 net.cpp:91] Creating Layer ReLU262
I0816 16:04:09.514017 20404 net.cpp:425] ReLU262 <- Convolution189
I0816 16:04:09.514029 20404 net.cpp:386] ReLU262 -> Convolution189 (in-place)
I0816 16:04:09.514045 20404 net.cpp:141] Setting up ReLU262
I0816 16:04:09.514055 20404 net.cpp:148] Top shape: 100 384 4 4 (614400)
I0816 16:04:09.514063 20404 net.cpp:156] Memory required for data: 3254076800
I0816 16:04:09.514093 20404 layer_factory.hpp:77] Creating layer conv5
I0816 16:04:09.514120 20404 net.cpp:91] Creating Layer conv5
I0816 16:04:09.514134 20404 net.cpp:425] conv5 <- Convolution189
I0816 16:04:09.514152 20404 net.cpp:399] conv5 -> Convolution190
I0816 16:04:09.536280 20404 net.cpp:141] Setting up conv5
I0816 16:04:09.536304 20404 net.cpp:148] Top shape: 100 256 4 4 (409600)
I0816 16:04:09.536312 20404 net.cpp:156] Memory required for data: 3255715200
I0816 16:04:09.536327 20404 layer_factory.hpp:77] Creating layer pool5
I0816 16:04:09.536345 20404 net.cpp:91] Creating Layer pool5
I0816 16:04:09.536355 20404 net.cpp:425] pool5 <- Convolution190
I0816 16:04:09.536370 20404 net.cpp:399] pool5 -> Pooling114
I0816 16:04:09.536442 20404 net.cpp:141] Setting up pool5
I0816 16:04:09.536456 20404 net.cpp:148] Top shape: 100 256 2 2 (102400)
I0816 16:04:09.536463 20404 net.cpp:156] Memory required for data: 3256124800
I0816 16:04:09.536470 20404 layer_factory.hpp:77] Creating layer InnerProduct111
I0816 16:04:09.536484 20404 net.cpp:91] Creating Layer InnerProduct111
I0816 16:04:09.536492 20404 net.cpp:425] InnerProduct111 <- Pooling114
I0816 16:04:09.536511 20404 net.cpp:399] InnerProduct111 -> InnerProduct111
I0816 16:04:09.539263 20404 net.cpp:141] Setting up InnerProduct111
I0816 16:04:09.539290 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.539299 20404 net.cpp:156] Memory required for data: 3256227200
I0816 16:04:09.539309 20404 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'InnerProduct1', param index 0
I0816 16:04:09.539319 20404 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'InnerProduct1', param index 1
I0816 16:04:09.539329 20404 layer_factory.hpp:77] Creating layer ReLU263
I0816 16:04:09.539342 20404 net.cpp:91] Creating Layer ReLU263
I0816 16:04:09.539352 20404 net.cpp:425] ReLU263 <- InnerProduct111
I0816 16:04:09.539363 20404 net.cpp:386] ReLU263 -> InnerProduct111 (in-place)
I0816 16:04:09.539378 20404 net.cpp:141] Setting up ReLU263
I0816 16:04:09.539387 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.539396 20404 net.cpp:156] Memory required for data: 3256329600
I0816 16:04:09.539403 20404 layer_factory.hpp:77] Creating layer InnerProduct112
I0816 16:04:09.539415 20404 net.cpp:91] Creating Layer InnerProduct112
I0816 16:04:09.539424 20404 net.cpp:425] InnerProduct112 <- InnerProduct111
I0816 16:04:09.539440 20404 net.cpp:399] InnerProduct112 -> InnerProduct112
I0816 16:04:09.540127 20404 net.cpp:141] Setting up InnerProduct112
I0816 16:04:09.540143 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.540150 20404 net.cpp:156] Memory required for data: 3256432000
I0816 16:04:09.540163 20404 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'InnerProduct2', param index 0
I0816 16:04:09.540174 20404 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'InnerProduct2', param index 1
I0816 16:04:09.540181 20404 layer_factory.hpp:77] Creating layer ReLU264
I0816 16:04:09.540191 20404 net.cpp:91] Creating Layer ReLU264
I0816 16:04:09.540200 20404 net.cpp:425] ReLU264 <- InnerProduct112
I0816 16:04:09.540210 20404 net.cpp:386] ReLU264 -> InnerProduct112 (in-place)
I0816 16:04:09.540223 20404 net.cpp:141] Setting up ReLU264
I0816 16:04:09.540233 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.540241 20404 net.cpp:156] Memory required for data: 3256534400
I0816 16:04:09.540248 20404 layer_factory.hpp:77] Creating layer Concat19
I0816 16:04:09.540259 20404 net.cpp:91] Creating Layer Concat19
I0816 16:04:09.540268 20404 net.cpp:425] Concat19 <- InnerProduct110
I0816 16:04:09.540278 20404 net.cpp:425] Concat19 <- InnerProduct112
I0816 16:04:09.540292 20404 net.cpp:399] Concat19 -> Concat19
I0816 16:04:09.540341 20404 net.cpp:141] Setting up Concat19
I0816 16:04:09.540385 20404 net.cpp:148] Top shape: 100 512 (51200)
I0816 16:04:09.540396 20404 net.cpp:156] Memory required for data: 3256739200
I0816 16:04:09.540405 20404 layer_factory.hpp:77] Creating layer InnerProduct113
I0816 16:04:09.540421 20404 net.cpp:91] Creating Layer InnerProduct113
I0816 16:04:09.540446 20404 net.cpp:425] InnerProduct113 <- Concat19
I0816 16:04:09.540462 20404 net.cpp:399] InnerProduct113 -> InnerProduct113
I0816 16:04:09.541656 20404 net.cpp:141] Setting up InnerProduct113
I0816 16:04:09.541672 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.541681 20404 net.cpp:156] Memory required for data: 3256841600
I0816 16:04:09.541689 20404 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'InnerProduct5', param index 0
I0816 16:04:09.541699 20404 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'InnerProduct5', param index 1
I0816 16:04:09.541707 20404 layer_factory.hpp:77] Creating layer ReLU265
I0816 16:04:09.541718 20404 net.cpp:91] Creating Layer ReLU265
I0816 16:04:09.541728 20404 net.cpp:425] ReLU265 <- InnerProduct113
I0816 16:04:09.541738 20404 net.cpp:386] ReLU265 -> InnerProduct113 (in-place)
I0816 16:04:09.541751 20404 net.cpp:141] Setting up ReLU265
I0816 16:04:09.541762 20404 net.cpp:148] Top shape: 100 256 (25600)
I0816 16:04:09.541769 20404 net.cpp:156] Memory required for data: 3256944000
I0816 16:04:09.541777 20404 layer_factory.hpp:77] Creating layer InnerProduct114
I0816 16:04:09.541790 20404 net.cpp:91] Creating Layer InnerProduct114
I0816 16:04:09.541797 20404 net.cpp:425] InnerProduct114 <- InnerProduct113
I0816 16:04:09.541813 20404 net.cpp:399] InnerProduct114 -> InnerProduct114
I0816 16:04:09.542230 20404 net.cpp:141] Setting up InnerProduct114
I0816 16:04:09.542246 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:09.542253 20404 net.cpp:156] Memory required for data: 3256995200
I0816 16:04:09.542263 20404 net.cpp:484] Sharing parameters 'fc9_w' owned by layer 'InnerProduct6', param index 0
I0816 16:04:09.542273 20404 net.cpp:484] Sharing parameters 'fc9_b' owned by layer 'InnerProduct6', param index 1
I0816 16:04:09.542280 20404 layer_factory.hpp:77] Creating layer ReLU266
I0816 16:04:09.542294 20404 net.cpp:91] Creating Layer ReLU266
I0816 16:04:09.542301 20404 net.cpp:425] ReLU266 <- InnerProduct114
I0816 16:04:09.542314 20404 net.cpp:386] ReLU266 -> InnerProduct114 (in-place)
I0816 16:04:09.542325 20404 net.cpp:141] Setting up ReLU266
I0816 16:04:09.542335 20404 net.cpp:148] Top shape: 100 128 (12800)
I0816 16:04:09.542342 20404 net.cpp:156] Memory required for data: 3257046400
I0816 16:04:09.542351 20404 layer_factory.hpp:77] Creating layer dt18
I0816 16:04:09.542361 20404 net.cpp:91] Creating Layer dt18
I0816 16:04:09.542371 20404 net.cpp:425] dt18 <- InnerProduct114
I0816 16:04:09.542383 20404 net.cpp:399] dt18 -> dt18
I0816 16:04:09.542551 20404 net.cpp:141] Setting up dt18
I0816 16:04:09.542564 20404 net.cpp:148] Top shape: 100 1 (100)
I0816 16:04:09.542572 20404 net.cpp:156] Memory required for data: 3257046800
I0816 16:04:09.542580 20404 net.cpp:484] Sharing parameters 'fc10_w' owned by layer 'dt0', param index 0
I0816 16:04:09.542589 20404 net.cpp:484] Sharing parameters 'fc10_b' owned by layer 'dt0', param index 1
I0816 16:04:09.542598 20404 layer_factory.hpp:77] Creating layer con
I0816 16:04:09.542611 20404 net.cpp:91] Creating Layer con
I0816 16:04:09.542620 20404 net.cpp:425] con <- dt0
I0816 16:04:09.542630 20404 net.cpp:425] con <- dt1
I0816 16:04:09.542640 20404 net.cpp:425] con <- dt2
I0816 16:04:09.542650 20404 net.cpp:425] con <- dt3
I0816 16:04:09.542660 20404 net.cpp:425] con <- dt4
I0816 16:04:09.542670 20404 net.cpp:425] con <- dt5
I0816 16:04:09.542680 20404 net.cpp:425] con <- dt6
I0816 16:04:09.542690 20404 net.cpp:425] con <- dt7
I0816 16:04:09.542698 20404 net.cpp:425] con <- dt8
I0816 16:04:09.542707 20404 net.cpp:425] con <- dt9
I0816 16:04:09.542716 20404 net.cpp:425] con <- dt10
I0816 16:04:09.542726 20404 net.cpp:425] con <- dt11
I0816 16:04:09.542734 20404 net.cpp:425] con <- dt12
I0816 16:04:09.542742 20404 net.cpp:425] con <- dt13
I0816 16:04:09.542752 20404 net.cpp:425] con <- dt14
I0816 16:04:09.542759 20404 net.cpp:425] con <- dt15
I0816 16:04:09.542768 20404 net.cpp:425] con <- dt16
I0816 16:04:09.542780 20404 net.cpp:425] con <- dt17
I0816 16:04:09.542789 20404 net.cpp:425] con <- dt18
I0816 16:04:09.542817 20404 net.cpp:399] con -> con
I0816 16:04:09.542863 20404 net.cpp:141] Setting up con
I0816 16:04:09.542876 20404 net.cpp:148] Top shape: 100 19 (1900)
I0816 16:04:09.542882 20404 net.cpp:156] Memory required for data: 3257054400
I0816 16:04:09.542891 20404 layer_factory.hpp:77] Creating layer r1
I0816 16:04:09.542903 20404 net.cpp:91] Creating Layer r1
I0816 16:04:09.542912 20404 net.cpp:425] r1 <- con
I0816 16:04:09.542923 20404 net.cpp:399] r1 -> r1
I0816 16:04:09.542969 20404 net.cpp:141] Setting up r1
I0816 16:04:09.542981 20404 net.cpp:148] Top shape: 100 1 1 19 (1900)
I0816 16:04:09.542989 20404 net.cpp:156] Memory required for data: 3257062000
I0816 16:04:09.542997 20404 layer_factory.hpp:77] Creating layer p
I0816 16:04:09.543010 20404 net.cpp:91] Creating Layer p
I0816 16:04:09.543018 20404 net.cpp:425] p <- r1
I0816 16:04:09.543030 20404 net.cpp:399] p -> p
I0816 16:04:09.543103 20404 net.cpp:141] Setting up p
I0816 16:04:09.543138 20404 net.cpp:148] Top shape: 100 1 1 1 (100)
I0816 16:04:09.543148 20404 net.cpp:156] Memory required for data: 3257062400
I0816 16:04:09.543156 20404 layer_factory.hpp:77] Creating layer r2
I0816 16:04:09.543167 20404 net.cpp:91] Creating Layer r2
I0816 16:04:09.543175 20404 net.cpp:425] r2 <- p
I0816 16:04:09.543190 20404 net.cpp:399] r2 -> r2
I0816 16:04:09.543232 20404 net.cpp:141] Setting up r2
I0816 16:04:09.543246 20404 net.cpp:148] Top shape: 100 1 1 1 (100)
I0816 16:04:09.543252 20404 net.cpp:156] Memory required for data: 3257062800
I0816 16:04:09.543261 20404 layer_factory.hpp:77] Creating layer padL
I0816 16:04:09.543277 20404 net.cpp:91] Creating Layer padL
I0816 16:04:09.543287 20404 net.cpp:425] padL <- label_data_1_split_1
I0816 16:04:09.543298 20404 net.cpp:399] padL -> padL
I0816 16:04:09.543354 20404 net.cpp:141] Setting up padL
I0816 16:04:09.543366 20404 net.cpp:148] Top shape: 100 1 1 1 (100)
I0816 16:04:09.543375 20404 net.cpp:156] Memory required for data: 3257063200
I0816 16:04:09.543381 20404 layer_factory.hpp:77] Creating layer pad
I0816 16:04:09.543392 20404 net.cpp:91] Creating Layer pad
I0816 16:04:09.543401 20404 net.cpp:425] pad <- r2
I0816 16:04:09.543409 20404 net.cpp:425] pad <- padL
I0816 16:04:09.543424 20404 net.cpp:399] pad -> pad
I0816 16:04:09.543462 20404 net.cpp:141] Setting up pad
I0816 16:04:09.543475 20404 net.cpp:148] Top shape: 100 2 1 1 (200)
I0816 16:04:09.543483 20404 net.cpp:156] Memory required for data: 3257064000
I0816 16:04:09.543489 20404 layer_factory.hpp:77] Creating layer pad_pad_0_split
I0816 16:04:09.543503 20404 net.cpp:91] Creating Layer pad_pad_0_split
I0816 16:04:09.543511 20404 net.cpp:425] pad_pad_0_split <- pad
I0816 16:04:09.543522 20404 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_0
I0816 16:04:09.543539 20404 net.cpp:399] pad_pad_0_split -> pad_pad_0_split_1
I0816 16:04:09.543598 20404 net.cpp:141] Setting up pad_pad_0_split
I0816 16:04:09.543612 20404 net.cpp:148] Top shape: 100 2 1 1 (200)
I0816 16:04:09.543622 20404 net.cpp:148] Top shape: 100 2 1 1 (200)
I0816 16:04:09.543628 20404 net.cpp:156] Memory required for data: 3257065600
I0816 16:04:09.543635 20404 layer_factory.hpp:77] Creating layer loss
I0816 16:04:09.543647 20404 net.cpp:91] Creating Layer loss
I0816 16:04:09.543653 20404 net.cpp:425] loss <- pad_pad_0_split_0
I0816 16:04:09.543663 20404 net.cpp:425] loss <- th_th_0_split_0
I0816 16:04:09.543678 20404 net.cpp:399] loss -> loss
I0816 16:04:09.543720 20404 net.cpp:141] Setting up loss
I0816 16:04:09.543733 20404 net.cpp:148] Top shape: (1)
I0816 16:04:09.543740 20404 net.cpp:151]     with loss weight 1
I0816 16:04:09.543758 20404 net.cpp:156] Memory required for data: 3257065604
I0816 16:04:09.543766 20404 layer_factory.hpp:77] Creating layer accuracy
I0816 16:04:09.543777 20404 net.cpp:91] Creating Layer accuracy
I0816 16:04:09.543786 20404 net.cpp:425] accuracy <- pad_pad_0_split_1
I0816 16:04:09.543795 20404 net.cpp:425] accuracy <- th_th_0_split_1
I0816 16:04:09.543808 20404 net.cpp:399] accuracy -> accuracy
I0816 16:04:09.543825 20404 net.cpp:141] Setting up accuracy
I0816 16:04:09.543848 20404 net.cpp:148] Top shape: (1)
I0816 16:04:09.543856 20404 net.cpp:156] Memory required for data: 3257065608
I0816 16:04:09.543864 20404 net.cpp:219] accuracy does not need backward computation.
I0816 16:04:09.543874 20404 net.cpp:217] loss needs backward computation.
I0816 16:04:09.543882 20404 net.cpp:217] pad_pad_0_split needs backward computation.
I0816 16:04:09.543890 20404 net.cpp:217] pad needs backward computation.
I0816 16:04:09.543900 20404 net.cpp:219] padL does not need backward computation.
I0816 16:04:09.543907 20404 net.cpp:217] r2 needs backward computation.
I0816 16:04:09.543915 20404 net.cpp:217] p needs backward computation.
I0816 16:04:09.543923 20404 net.cpp:217] r1 needs backward computation.
I0816 16:04:09.543931 20404 net.cpp:217] con needs backward computation.
I0816 16:04:09.543944 20404 net.cpp:217] dt18 needs backward computation.
I0816 16:04:09.543952 20404 net.cpp:217] ReLU266 needs backward computation.
I0816 16:04:09.543961 20404 net.cpp:217] InnerProduct114 needs backward computation.
I0816 16:04:09.543968 20404 net.cpp:217] ReLU265 needs backward computation.
I0816 16:04:09.543975 20404 net.cpp:217] InnerProduct113 needs backward computation.
I0816 16:04:09.543990 20404 net.cpp:217] Concat19 needs backward computation.
I0816 16:04:09.543998 20404 net.cpp:217] ReLU264 needs backward computation.
I0816 16:04:09.544006 20404 net.cpp:217] InnerProduct112 needs backward computation.
I0816 16:04:09.544013 20404 net.cpp:217] ReLU263 needs backward computation.
I0816 16:04:09.544021 20404 net.cpp:217] InnerProduct111 needs backward computation.
I0816 16:04:09.544029 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.544041 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.544051 20404 net.cpp:219] ReLU262 does not need backward computation.
I0816 16:04:09.544059 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.544067 20404 net.cpp:219] ReLU261 does not need backward computation.
I0816 16:04:09.544075 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.544085 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.544093 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.544102 20404 net.cpp:219] ReLU260 does not need backward computation.
I0816 16:04:09.544109 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.544118 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.544127 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.544137 20404 net.cpp:219] ReLU259 does not need backward computation.
I0816 16:04:09.544143 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.544152 20404 net.cpp:217] ReLU258 needs backward computation.
I0816 16:04:09.544160 20404 net.cpp:217] InnerProduct110 needs backward computation.
I0816 16:04:09.544168 20404 net.cpp:217] ReLU257 needs backward computation.
I0816 16:04:09.544176 20404 net.cpp:217] InnerProduct109 needs backward computation.
I0816 16:04:09.544185 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.544194 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.544203 20404 net.cpp:219] ReLU256 does not need backward computation.
I0816 16:04:09.544210 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.544219 20404 net.cpp:219] ReLU255 does not need backward computation.
I0816 16:04:09.544227 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.544235 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.544245 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.544253 20404 net.cpp:219] ReLU254 does not need backward computation.
I0816 16:04:09.544260 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.544270 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.544278 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.544297 20404 net.cpp:219] ReLU253 does not need backward computation.
I0816 16:04:09.544306 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.544314 20404 net.cpp:217] dt17 needs backward computation.
I0816 16:04:09.544322 20404 net.cpp:217] ReLU252 needs backward computation.
I0816 16:04:09.544330 20404 net.cpp:217] InnerProduct108 needs backward computation.
I0816 16:04:09.544339 20404 net.cpp:217] ReLU251 needs backward computation.
I0816 16:04:09.544348 20404 net.cpp:217] InnerProduct107 needs backward computation.
I0816 16:04:09.544355 20404 net.cpp:217] Concat18 needs backward computation.
I0816 16:04:09.544364 20404 net.cpp:217] ReLU250 needs backward computation.
I0816 16:04:09.544373 20404 net.cpp:217] InnerProduct106 needs backward computation.
I0816 16:04:09.544380 20404 net.cpp:217] ReLU249 needs backward computation.
I0816 16:04:09.544389 20404 net.cpp:217] InnerProduct105 needs backward computation.
I0816 16:04:09.544397 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.544406 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.544415 20404 net.cpp:219] ReLU248 does not need backward computation.
I0816 16:04:09.544423 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.544431 20404 net.cpp:219] ReLU247 does not need backward computation.
I0816 16:04:09.544440 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.544448 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.544457 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.544467 20404 net.cpp:219] ReLU246 does not need backward computation.
I0816 16:04:09.544476 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.544483 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.544492 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.544502 20404 net.cpp:219] ReLU245 does not need backward computation.
I0816 16:04:09.544509 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.544517 20404 net.cpp:217] ReLU244 needs backward computation.
I0816 16:04:09.544525 20404 net.cpp:217] InnerProduct104 needs backward computation.
I0816 16:04:09.544534 20404 net.cpp:217] ReLU243 needs backward computation.
I0816 16:04:09.544543 20404 net.cpp:217] InnerProduct103 needs backward computation.
I0816 16:04:09.544551 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.544560 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.544569 20404 net.cpp:219] ReLU242 does not need backward computation.
I0816 16:04:09.544577 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.544585 20404 net.cpp:219] ReLU241 does not need backward computation.
I0816 16:04:09.544594 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.544602 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.544611 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.544620 20404 net.cpp:219] ReLU240 does not need backward computation.
I0816 16:04:09.544627 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.544641 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.544651 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.544659 20404 net.cpp:219] ReLU239 does not need backward computation.
I0816 16:04:09.544668 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.544677 20404 net.cpp:217] dt16 needs backward computation.
I0816 16:04:09.544685 20404 net.cpp:217] ReLU238 needs backward computation.
I0816 16:04:09.544693 20404 net.cpp:217] InnerProduct102 needs backward computation.
I0816 16:04:09.544703 20404 net.cpp:217] ReLU237 needs backward computation.
I0816 16:04:09.544710 20404 net.cpp:217] InnerProduct101 needs backward computation.
I0816 16:04:09.544718 20404 net.cpp:217] Concat17 needs backward computation.
I0816 16:04:09.544739 20404 net.cpp:217] ReLU236 needs backward computation.
I0816 16:04:09.544749 20404 net.cpp:217] InnerProduct100 needs backward computation.
I0816 16:04:09.544756 20404 net.cpp:217] ReLU235 needs backward computation.
I0816 16:04:09.544765 20404 net.cpp:217] InnerProduct99 needs backward computation.
I0816 16:04:09.544775 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.544783 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.544792 20404 net.cpp:219] ReLU234 does not need backward computation.
I0816 16:04:09.544800 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.544809 20404 net.cpp:219] ReLU233 does not need backward computation.
I0816 16:04:09.544816 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.544826 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.544836 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.544843 20404 net.cpp:219] ReLU232 does not need backward computation.
I0816 16:04:09.544852 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.544860 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.544869 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.544878 20404 net.cpp:219] ReLU231 does not need backward computation.
I0816 16:04:09.544886 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.544895 20404 net.cpp:217] ReLU230 needs backward computation.
I0816 16:04:09.544903 20404 net.cpp:217] InnerProduct98 needs backward computation.
I0816 16:04:09.544912 20404 net.cpp:217] ReLU229 needs backward computation.
I0816 16:04:09.544920 20404 net.cpp:217] InnerProduct97 needs backward computation.
I0816 16:04:09.544929 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.544939 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.544946 20404 net.cpp:219] ReLU228 does not need backward computation.
I0816 16:04:09.544955 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.544963 20404 net.cpp:219] ReLU227 does not need backward computation.
I0816 16:04:09.544971 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.544981 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.544989 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.544998 20404 net.cpp:219] ReLU226 does not need backward computation.
I0816 16:04:09.545006 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.545016 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.545024 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.545033 20404 net.cpp:219] ReLU225 does not need backward computation.
I0816 16:04:09.545042 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.545050 20404 net.cpp:217] dt15 needs backward computation.
I0816 16:04:09.545059 20404 net.cpp:217] ReLU224 needs backward computation.
I0816 16:04:09.545068 20404 net.cpp:217] InnerProduct96 needs backward computation.
I0816 16:04:09.545075 20404 net.cpp:217] ReLU223 needs backward computation.
I0816 16:04:09.545084 20404 net.cpp:217] InnerProduct95 needs backward computation.
I0816 16:04:09.545090 20404 net.cpp:217] Concat16 needs backward computation.
I0816 16:04:09.545097 20404 net.cpp:217] ReLU222 needs backward computation.
I0816 16:04:09.545104 20404 net.cpp:217] InnerProduct94 needs backward computation.
I0816 16:04:09.545110 20404 net.cpp:217] ReLU221 needs backward computation.
I0816 16:04:09.545117 20404 net.cpp:217] InnerProduct93 needs backward computation.
I0816 16:04:09.545125 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.545131 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.545138 20404 net.cpp:219] ReLU220 does not need backward computation.
I0816 16:04:09.545152 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.545159 20404 net.cpp:219] ReLU219 does not need backward computation.
I0816 16:04:09.545166 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.545173 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.545179 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.545186 20404 net.cpp:219] ReLU218 does not need backward computation.
I0816 16:04:09.545193 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.545200 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.545207 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.545214 20404 net.cpp:219] ReLU217 does not need backward computation.
I0816 16:04:09.545220 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.545230 20404 net.cpp:217] ReLU216 needs backward computation.
I0816 16:04:09.545236 20404 net.cpp:217] InnerProduct92 needs backward computation.
I0816 16:04:09.545243 20404 net.cpp:217] ReLU215 needs backward computation.
I0816 16:04:09.545249 20404 net.cpp:217] InnerProduct91 needs backward computation.
I0816 16:04:09.545256 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.545264 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.545270 20404 net.cpp:219] ReLU214 does not need backward computation.
I0816 16:04:09.545276 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.545284 20404 net.cpp:219] ReLU213 does not need backward computation.
I0816 16:04:09.545289 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.545296 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.545303 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.545310 20404 net.cpp:219] ReLU212 does not need backward computation.
I0816 16:04:09.545317 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.545323 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.545331 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.545337 20404 net.cpp:219] ReLU211 does not need backward computation.
I0816 16:04:09.545344 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.545351 20404 net.cpp:217] dt14 needs backward computation.
I0816 16:04:09.545357 20404 net.cpp:217] ReLU210 needs backward computation.
I0816 16:04:09.545363 20404 net.cpp:217] InnerProduct90 needs backward computation.
I0816 16:04:09.545370 20404 net.cpp:217] ReLU209 needs backward computation.
I0816 16:04:09.545377 20404 net.cpp:217] InnerProduct89 needs backward computation.
I0816 16:04:09.545383 20404 net.cpp:217] Concat15 needs backward computation.
I0816 16:04:09.545390 20404 net.cpp:217] ReLU208 needs backward computation.
I0816 16:04:09.545397 20404 net.cpp:217] InnerProduct88 needs backward computation.
I0816 16:04:09.545403 20404 net.cpp:217] ReLU207 needs backward computation.
I0816 16:04:09.545408 20404 net.cpp:217] InnerProduct87 needs backward computation.
I0816 16:04:09.545415 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.545423 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.545430 20404 net.cpp:219] ReLU206 does not need backward computation.
I0816 16:04:09.545436 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.545444 20404 net.cpp:219] ReLU205 does not need backward computation.
I0816 16:04:09.545449 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.545456 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.545464 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.545471 20404 net.cpp:219] ReLU204 does not need backward computation.
I0816 16:04:09.545477 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.545485 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.545500 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.545507 20404 net.cpp:219] ReLU203 does not need backward computation.
I0816 16:04:09.545513 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.545521 20404 net.cpp:217] ReLU202 needs backward computation.
I0816 16:04:09.545526 20404 net.cpp:217] InnerProduct86 needs backward computation.
I0816 16:04:09.545533 20404 net.cpp:217] ReLU201 needs backward computation.
I0816 16:04:09.545539 20404 net.cpp:217] InnerProduct85 needs backward computation.
I0816 16:04:09.545547 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.545553 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.545560 20404 net.cpp:219] ReLU200 does not need backward computation.
I0816 16:04:09.545567 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.545574 20404 net.cpp:219] ReLU199 does not need backward computation.
I0816 16:04:09.545580 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.545588 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.545594 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.545601 20404 net.cpp:219] ReLU198 does not need backward computation.
I0816 16:04:09.545608 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.545614 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.545621 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.545629 20404 net.cpp:219] ReLU197 does not need backward computation.
I0816 16:04:09.545634 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.545641 20404 net.cpp:217] dt13 needs backward computation.
I0816 16:04:09.545649 20404 net.cpp:217] ReLU196 needs backward computation.
I0816 16:04:09.545655 20404 net.cpp:217] InnerProduct84 needs backward computation.
I0816 16:04:09.545661 20404 net.cpp:217] ReLU195 needs backward computation.
I0816 16:04:09.545667 20404 net.cpp:217] InnerProduct83 needs backward computation.
I0816 16:04:09.545673 20404 net.cpp:217] Concat14 needs backward computation.
I0816 16:04:09.545680 20404 net.cpp:217] ReLU194 needs backward computation.
I0816 16:04:09.545686 20404 net.cpp:217] InnerProduct82 needs backward computation.
I0816 16:04:09.545693 20404 net.cpp:217] ReLU193 needs backward computation.
I0816 16:04:09.545699 20404 net.cpp:217] InnerProduct81 needs backward computation.
I0816 16:04:09.545706 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.545716 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.545723 20404 net.cpp:219] ReLU192 does not need backward computation.
I0816 16:04:09.545729 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.545737 20404 net.cpp:219] ReLU191 does not need backward computation.
I0816 16:04:09.545743 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.545750 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.545758 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.545765 20404 net.cpp:219] ReLU190 does not need backward computation.
I0816 16:04:09.545771 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.545778 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.545785 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.545792 20404 net.cpp:219] ReLU189 does not need backward computation.
I0816 16:04:09.545799 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.545806 20404 net.cpp:217] ReLU188 needs backward computation.
I0816 16:04:09.545812 20404 net.cpp:217] InnerProduct80 needs backward computation.
I0816 16:04:09.545819 20404 net.cpp:217] ReLU187 needs backward computation.
I0816 16:04:09.545825 20404 net.cpp:217] InnerProduct79 needs backward computation.
I0816 16:04:09.545832 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.545847 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.545855 20404 net.cpp:219] ReLU186 does not need backward computation.
I0816 16:04:09.545861 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.545867 20404 net.cpp:219] ReLU185 does not need backward computation.
I0816 16:04:09.545873 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.545881 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.545887 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.545894 20404 net.cpp:219] ReLU184 does not need backward computation.
I0816 16:04:09.545902 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.545908 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.545915 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.545922 20404 net.cpp:219] ReLU183 does not need backward computation.
I0816 16:04:09.545928 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.545935 20404 net.cpp:217] dt12 needs backward computation.
I0816 16:04:09.545943 20404 net.cpp:217] ReLU182 needs backward computation.
I0816 16:04:09.545948 20404 net.cpp:217] InnerProduct78 needs backward computation.
I0816 16:04:09.545955 20404 net.cpp:217] ReLU181 needs backward computation.
I0816 16:04:09.545961 20404 net.cpp:217] InnerProduct77 needs backward computation.
I0816 16:04:09.545969 20404 net.cpp:217] Concat13 needs backward computation.
I0816 16:04:09.545975 20404 net.cpp:217] ReLU180 needs backward computation.
I0816 16:04:09.545981 20404 net.cpp:217] InnerProduct76 needs backward computation.
I0816 16:04:09.545989 20404 net.cpp:217] ReLU179 needs backward computation.
I0816 16:04:09.545994 20404 net.cpp:217] InnerProduct75 needs backward computation.
I0816 16:04:09.546001 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.546008 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.546015 20404 net.cpp:219] ReLU178 does not need backward computation.
I0816 16:04:09.546021 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.546028 20404 net.cpp:219] ReLU177 does not need backward computation.
I0816 16:04:09.546035 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.546041 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.546049 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.546056 20404 net.cpp:219] ReLU176 does not need backward computation.
I0816 16:04:09.546062 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.546071 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.546077 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.546084 20404 net.cpp:219] ReLU175 does not need backward computation.
I0816 16:04:09.546090 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.546097 20404 net.cpp:217] ReLU174 needs backward computation.
I0816 16:04:09.546104 20404 net.cpp:217] InnerProduct74 needs backward computation.
I0816 16:04:09.546111 20404 net.cpp:217] ReLU173 needs backward computation.
I0816 16:04:09.546118 20404 net.cpp:217] InnerProduct73 needs backward computation.
I0816 16:04:09.546124 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.546131 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.546139 20404 net.cpp:219] ReLU172 does not need backward computation.
I0816 16:04:09.546144 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.546151 20404 net.cpp:219] ReLU171 does not need backward computation.
I0816 16:04:09.546157 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.546165 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.546172 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.546186 20404 net.cpp:219] ReLU170 does not need backward computation.
I0816 16:04:09.546192 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.546202 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.546210 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.546216 20404 net.cpp:219] ReLU169 does not need backward computation.
I0816 16:04:09.546223 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.546231 20404 net.cpp:217] dt11 needs backward computation.
I0816 16:04:09.546237 20404 net.cpp:217] ReLU168 needs backward computation.
I0816 16:04:09.546243 20404 net.cpp:217] InnerProduct72 needs backward computation.
I0816 16:04:09.546250 20404 net.cpp:217] ReLU167 needs backward computation.
I0816 16:04:09.546257 20404 net.cpp:217] InnerProduct71 needs backward computation.
I0816 16:04:09.546263 20404 net.cpp:217] Concat12 needs backward computation.
I0816 16:04:09.546270 20404 net.cpp:217] ReLU166 needs backward computation.
I0816 16:04:09.546277 20404 net.cpp:217] InnerProduct70 needs backward computation.
I0816 16:04:09.546283 20404 net.cpp:217] ReLU165 needs backward computation.
I0816 16:04:09.546289 20404 net.cpp:217] InnerProduct69 needs backward computation.
I0816 16:04:09.546298 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.546304 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.546311 20404 net.cpp:219] ReLU164 does not need backward computation.
I0816 16:04:09.546317 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.546324 20404 net.cpp:219] ReLU163 does not need backward computation.
I0816 16:04:09.546330 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.546337 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.546345 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.546352 20404 net.cpp:219] ReLU162 does not need backward computation.
I0816 16:04:09.546358 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.546365 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.546372 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.546380 20404 net.cpp:219] ReLU161 does not need backward computation.
I0816 16:04:09.546386 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.546393 20404 net.cpp:217] ReLU160 needs backward computation.
I0816 16:04:09.546399 20404 net.cpp:217] InnerProduct68 needs backward computation.
I0816 16:04:09.546406 20404 net.cpp:217] ReLU159 needs backward computation.
I0816 16:04:09.546422 20404 net.cpp:217] InnerProduct67 needs backward computation.
I0816 16:04:09.546428 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.546435 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.546442 20404 net.cpp:219] ReLU158 does not need backward computation.
I0816 16:04:09.546448 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.546455 20404 net.cpp:219] ReLU157 does not need backward computation.
I0816 16:04:09.546463 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.546469 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.546488 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.546494 20404 net.cpp:219] ReLU156 does not need backward computation.
I0816 16:04:09.546501 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.546509 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.546515 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.546524 20404 net.cpp:219] ReLU155 does not need backward computation.
I0816 16:04:09.546530 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.546537 20404 net.cpp:217] dt10 needs backward computation.
I0816 16:04:09.546545 20404 net.cpp:217] ReLU154 needs backward computation.
I0816 16:04:09.546558 20404 net.cpp:217] InnerProduct66 needs backward computation.
I0816 16:04:09.546566 20404 net.cpp:217] ReLU153 needs backward computation.
I0816 16:04:09.546572 20404 net.cpp:217] InnerProduct65 needs backward computation.
I0816 16:04:09.546578 20404 net.cpp:217] Concat11 needs backward computation.
I0816 16:04:09.546586 20404 net.cpp:217] ReLU152 needs backward computation.
I0816 16:04:09.546592 20404 net.cpp:217] InnerProduct64 needs backward computation.
I0816 16:04:09.546599 20404 net.cpp:217] ReLU151 needs backward computation.
I0816 16:04:09.546605 20404 net.cpp:217] InnerProduct63 needs backward computation.
I0816 16:04:09.546613 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.546620 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.546627 20404 net.cpp:219] ReLU150 does not need backward computation.
I0816 16:04:09.546633 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.546641 20404 net.cpp:219] ReLU149 does not need backward computation.
I0816 16:04:09.546648 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.546654 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.546661 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.546669 20404 net.cpp:219] ReLU148 does not need backward computation.
I0816 16:04:09.546675 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.546684 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.546690 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.546697 20404 net.cpp:219] ReLU147 does not need backward computation.
I0816 16:04:09.546703 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.546713 20404 net.cpp:217] ReLU146 needs backward computation.
I0816 16:04:09.546720 20404 net.cpp:217] InnerProduct62 needs backward computation.
I0816 16:04:09.546727 20404 net.cpp:217] ReLU145 needs backward computation.
I0816 16:04:09.546733 20404 net.cpp:217] InnerProduct61 needs backward computation.
I0816 16:04:09.546741 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.546748 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.546756 20404 net.cpp:219] ReLU144 does not need backward computation.
I0816 16:04:09.546762 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.546769 20404 net.cpp:219] ReLU143 does not need backward computation.
I0816 16:04:09.546777 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.546783 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.546792 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.546798 20404 net.cpp:219] ReLU142 does not need backward computation.
I0816 16:04:09.546804 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.546813 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.546820 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.546828 20404 net.cpp:219] ReLU141 does not need backward computation.
I0816 16:04:09.546834 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.546841 20404 net.cpp:217] dt9 needs backward computation.
I0816 16:04:09.546849 20404 net.cpp:217] ReLU140 needs backward computation.
I0816 16:04:09.546855 20404 net.cpp:217] InnerProduct60 needs backward computation.
I0816 16:04:09.546861 20404 net.cpp:217] ReLU139 needs backward computation.
I0816 16:04:09.546867 20404 net.cpp:217] InnerProduct59 needs backward computation.
I0816 16:04:09.546875 20404 net.cpp:217] Concat10 needs backward computation.
I0816 16:04:09.546882 20404 net.cpp:217] ReLU138 needs backward computation.
I0816 16:04:09.546888 20404 net.cpp:217] InnerProduct58 needs backward computation.
I0816 16:04:09.546895 20404 net.cpp:217] ReLU137 needs backward computation.
I0816 16:04:09.546902 20404 net.cpp:217] InnerProduct57 needs backward computation.
I0816 16:04:09.546916 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.546924 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.546932 20404 net.cpp:219] ReLU136 does not need backward computation.
I0816 16:04:09.546939 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.546947 20404 net.cpp:219] ReLU135 does not need backward computation.
I0816 16:04:09.546954 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.546962 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.546968 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.546977 20404 net.cpp:219] ReLU134 does not need backward computation.
I0816 16:04:09.546983 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.546990 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.547000 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.547008 20404 net.cpp:219] ReLU133 does not need backward computation.
I0816 16:04:09.547014 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.547021 20404 net.cpp:217] ReLU132 needs backward computation.
I0816 16:04:09.547029 20404 net.cpp:217] InnerProduct56 needs backward computation.
I0816 16:04:09.547035 20404 net.cpp:217] ReLU131 needs backward computation.
I0816 16:04:09.547041 20404 net.cpp:217] InnerProduct55 needs backward computation.
I0816 16:04:09.547049 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.547056 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.547063 20404 net.cpp:219] ReLU130 does not need backward computation.
I0816 16:04:09.547070 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.547078 20404 net.cpp:219] ReLU129 does not need backward computation.
I0816 16:04:09.547086 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.547092 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.547101 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.547107 20404 net.cpp:219] ReLU128 does not need backward computation.
I0816 16:04:09.547114 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.547122 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.547128 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.547137 20404 net.cpp:219] ReLU127 does not need backward computation.
I0816 16:04:09.547142 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.547150 20404 net.cpp:217] dt8 needs backward computation.
I0816 16:04:09.547158 20404 net.cpp:217] ReLU126 needs backward computation.
I0816 16:04:09.547164 20404 net.cpp:217] InnerProduct54 needs backward computation.
I0816 16:04:09.547170 20404 net.cpp:217] ReLU125 needs backward computation.
I0816 16:04:09.547178 20404 net.cpp:217] InnerProduct53 needs backward computation.
I0816 16:04:09.547184 20404 net.cpp:217] Concat9 needs backward computation.
I0816 16:04:09.547191 20404 net.cpp:217] ReLU124 needs backward computation.
I0816 16:04:09.547197 20404 net.cpp:217] InnerProduct52 needs backward computation.
I0816 16:04:09.547204 20404 net.cpp:217] ReLU123 needs backward computation.
I0816 16:04:09.547211 20404 net.cpp:217] InnerProduct51 needs backward computation.
I0816 16:04:09.547219 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.547225 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.547235 20404 net.cpp:219] ReLU122 does not need backward computation.
I0816 16:04:09.547242 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.547250 20404 net.cpp:219] ReLU121 does not need backward computation.
I0816 16:04:09.547257 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.547264 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.547281 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.547299 20404 net.cpp:219] ReLU120 does not need backward computation.
I0816 16:04:09.547307 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.547313 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.547322 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.547328 20404 net.cpp:219] ReLU119 does not need backward computation.
I0816 16:04:09.547335 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.547343 20404 net.cpp:217] ReLU118 needs backward computation.
I0816 16:04:09.547349 20404 net.cpp:217] InnerProduct50 needs backward computation.
I0816 16:04:09.547356 20404 net.cpp:217] ReLU117 needs backward computation.
I0816 16:04:09.547363 20404 net.cpp:217] InnerProduct49 needs backward computation.
I0816 16:04:09.547370 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.547377 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.547385 20404 net.cpp:219] ReLU116 does not need backward computation.
I0816 16:04:09.547392 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.547399 20404 net.cpp:219] ReLU115 does not need backward computation.
I0816 16:04:09.547406 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.547413 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.547420 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.547428 20404 net.cpp:219] ReLU114 does not need backward computation.
I0816 16:04:09.547435 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.547442 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.547451 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.547457 20404 net.cpp:219] ReLU113 does not need backward computation.
I0816 16:04:09.547464 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.547472 20404 net.cpp:217] dt7 needs backward computation.
I0816 16:04:09.547479 20404 net.cpp:217] ReLU112 needs backward computation.
I0816 16:04:09.547485 20404 net.cpp:217] InnerProduct48 needs backward computation.
I0816 16:04:09.547492 20404 net.cpp:217] ReLU111 needs backward computation.
I0816 16:04:09.547498 20404 net.cpp:217] InnerProduct47 needs backward computation.
I0816 16:04:09.547505 20404 net.cpp:217] Concat8 needs backward computation.
I0816 16:04:09.547513 20404 net.cpp:217] ReLU110 needs backward computation.
I0816 16:04:09.547519 20404 net.cpp:217] InnerProduct46 needs backward computation.
I0816 16:04:09.547526 20404 net.cpp:217] ReLU109 needs backward computation.
I0816 16:04:09.547533 20404 net.cpp:217] InnerProduct45 needs backward computation.
I0816 16:04:09.547540 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.547549 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.547555 20404 net.cpp:219] ReLU108 does not need backward computation.
I0816 16:04:09.547562 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.547569 20404 net.cpp:219] ReLU107 does not need backward computation.
I0816 16:04:09.547576 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.547583 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.547591 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.547598 20404 net.cpp:219] ReLU106 does not need backward computation.
I0816 16:04:09.547605 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.547613 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.547621 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.547627 20404 net.cpp:219] ReLU105 does not need backward computation.
I0816 16:04:09.547634 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.547642 20404 net.cpp:217] ReLU104 needs backward computation.
I0816 16:04:09.547648 20404 net.cpp:217] InnerProduct44 needs backward computation.
I0816 16:04:09.547665 20404 net.cpp:217] ReLU103 needs backward computation.
I0816 16:04:09.547672 20404 net.cpp:217] InnerProduct43 needs backward computation.
I0816 16:04:09.547679 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.547688 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.547694 20404 net.cpp:219] ReLU102 does not need backward computation.
I0816 16:04:09.547709 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.547716 20404 net.cpp:219] ReLU101 does not need backward computation.
I0816 16:04:09.547724 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.547730 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.547739 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.547745 20404 net.cpp:219] ReLU100 does not need backward computation.
I0816 16:04:09.547751 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.547760 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.547768 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.547776 20404 net.cpp:219] ReLU99 does not need backward computation.
I0816 16:04:09.547783 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.547791 20404 net.cpp:217] dt6 needs backward computation.
I0816 16:04:09.547797 20404 net.cpp:217] ReLU98 needs backward computation.
I0816 16:04:09.547803 20404 net.cpp:217] InnerProduct42 needs backward computation.
I0816 16:04:09.547811 20404 net.cpp:217] ReLU97 needs backward computation.
I0816 16:04:09.547816 20404 net.cpp:217] InnerProduct41 needs backward computation.
I0816 16:04:09.547823 20404 net.cpp:217] Concat7 needs backward computation.
I0816 16:04:09.547832 20404 net.cpp:217] ReLU96 needs backward computation.
I0816 16:04:09.547837 20404 net.cpp:217] InnerProduct40 needs backward computation.
I0816 16:04:09.547844 20404 net.cpp:217] ReLU95 needs backward computation.
I0816 16:04:09.547850 20404 net.cpp:217] InnerProduct39 needs backward computation.
I0816 16:04:09.547858 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.547865 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.547873 20404 net.cpp:219] ReLU94 does not need backward computation.
I0816 16:04:09.547879 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.547886 20404 net.cpp:219] ReLU93 does not need backward computation.
I0816 16:04:09.547894 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.547900 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.547907 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.547915 20404 net.cpp:219] ReLU92 does not need backward computation.
I0816 16:04:09.547921 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.547930 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.547935 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.547943 20404 net.cpp:219] ReLU91 does not need backward computation.
I0816 16:04:09.547950 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.547957 20404 net.cpp:217] ReLU90 needs backward computation.
I0816 16:04:09.547963 20404 net.cpp:217] InnerProduct38 needs backward computation.
I0816 16:04:09.547971 20404 net.cpp:217] ReLU89 needs backward computation.
I0816 16:04:09.547976 20404 net.cpp:217] InnerProduct37 needs backward computation.
I0816 16:04:09.547983 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.547991 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.547998 20404 net.cpp:219] ReLU88 does not need backward computation.
I0816 16:04:09.548005 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.548013 20404 net.cpp:219] ReLU87 does not need backward computation.
I0816 16:04:09.548020 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.548034 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.548043 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.548049 20404 net.cpp:219] ReLU86 does not need backward computation.
I0816 16:04:09.548056 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.548063 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.548070 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.548077 20404 net.cpp:219] ReLU85 does not need backward computation.
I0816 16:04:09.548084 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.548091 20404 net.cpp:217] dt5 needs backward computation.
I0816 16:04:09.548099 20404 net.cpp:217] ReLU84 needs backward computation.
I0816 16:04:09.548105 20404 net.cpp:217] InnerProduct36 needs backward computation.
I0816 16:04:09.548111 20404 net.cpp:217] ReLU83 needs backward computation.
I0816 16:04:09.548118 20404 net.cpp:217] InnerProduct35 needs backward computation.
I0816 16:04:09.548125 20404 net.cpp:217] Concat6 needs backward computation.
I0816 16:04:09.548131 20404 net.cpp:217] ReLU82 needs backward computation.
I0816 16:04:09.548138 20404 net.cpp:217] InnerProduct34 needs backward computation.
I0816 16:04:09.548144 20404 net.cpp:217] ReLU81 needs backward computation.
I0816 16:04:09.548151 20404 net.cpp:217] InnerProduct33 needs backward computation.
I0816 16:04:09.548158 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.548166 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.548172 20404 net.cpp:219] ReLU80 does not need backward computation.
I0816 16:04:09.548179 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.548187 20404 net.cpp:219] ReLU79 does not need backward computation.
I0816 16:04:09.548193 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.548200 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.548207 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.548215 20404 net.cpp:219] ReLU78 does not need backward computation.
I0816 16:04:09.548223 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.548229 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.548236 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.548243 20404 net.cpp:219] ReLU77 does not need backward computation.
I0816 16:04:09.548249 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.548257 20404 net.cpp:217] ReLU76 needs backward computation.
I0816 16:04:09.548264 20404 net.cpp:217] InnerProduct32 needs backward computation.
I0816 16:04:09.548272 20404 net.cpp:217] ReLU75 needs backward computation.
I0816 16:04:09.548280 20404 net.cpp:217] InnerProduct31 needs backward computation.
I0816 16:04:09.548286 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.548295 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.548301 20404 net.cpp:219] ReLU74 does not need backward computation.
I0816 16:04:09.548308 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.548316 20404 net.cpp:219] ReLU73 does not need backward computation.
I0816 16:04:09.548322 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.548329 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.548336 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.548344 20404 net.cpp:219] ReLU72 does not need backward computation.
I0816 16:04:09.548351 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.548357 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.548364 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.548372 20404 net.cpp:219] ReLU71 does not need backward computation.
I0816 16:04:09.548387 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.548393 20404 net.cpp:217] dt4 needs backward computation.
I0816 16:04:09.548400 20404 net.cpp:217] ReLU70 needs backward computation.
I0816 16:04:09.548408 20404 net.cpp:217] InnerProduct30 needs backward computation.
I0816 16:04:09.548413 20404 net.cpp:217] ReLU69 needs backward computation.
I0816 16:04:09.548420 20404 net.cpp:217] InnerProduct29 needs backward computation.
I0816 16:04:09.548426 20404 net.cpp:217] Concat5 needs backward computation.
I0816 16:04:09.548434 20404 net.cpp:217] ReLU68 needs backward computation.
I0816 16:04:09.548440 20404 net.cpp:217] InnerProduct28 needs backward computation.
I0816 16:04:09.548447 20404 net.cpp:217] ReLU67 needs backward computation.
I0816 16:04:09.548454 20404 net.cpp:217] InnerProduct27 needs backward computation.
I0816 16:04:09.548460 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.548468 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.548475 20404 net.cpp:219] ReLU66 does not need backward computation.
I0816 16:04:09.548482 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.548490 20404 net.cpp:219] ReLU65 does not need backward computation.
I0816 16:04:09.548496 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.548502 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.548511 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.548517 20404 net.cpp:219] ReLU64 does not need backward computation.
I0816 16:04:09.548523 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.548530 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.548537 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.548545 20404 net.cpp:219] ReLU63 does not need backward computation.
I0816 16:04:09.548552 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.548559 20404 net.cpp:217] ReLU62 needs backward computation.
I0816 16:04:09.548565 20404 net.cpp:217] InnerProduct26 needs backward computation.
I0816 16:04:09.548573 20404 net.cpp:217] ReLU61 needs backward computation.
I0816 16:04:09.548578 20404 net.cpp:217] InnerProduct25 needs backward computation.
I0816 16:04:09.548586 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.548593 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.548600 20404 net.cpp:219] ReLU60 does not need backward computation.
I0816 16:04:09.548607 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.548614 20404 net.cpp:219] ReLU59 does not need backward computation.
I0816 16:04:09.548621 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.548629 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.548636 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.548643 20404 net.cpp:219] ReLU58 does not need backward computation.
I0816 16:04:09.548650 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.548657 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.548665 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.548671 20404 net.cpp:219] ReLU57 does not need backward computation.
I0816 16:04:09.548678 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.548686 20404 net.cpp:217] dt3 needs backward computation.
I0816 16:04:09.548692 20404 net.cpp:217] ReLU56 needs backward computation.
I0816 16:04:09.548699 20404 net.cpp:217] InnerProduct24 needs backward computation.
I0816 16:04:09.548705 20404 net.cpp:217] ReLU55 needs backward computation.
I0816 16:04:09.548712 20404 net.cpp:217] InnerProduct23 needs backward computation.
I0816 16:04:09.548718 20404 net.cpp:217] Concat4 needs backward computation.
I0816 16:04:09.548725 20404 net.cpp:217] ReLU54 needs backward computation.
I0816 16:04:09.548732 20404 net.cpp:217] InnerProduct22 needs backward computation.
I0816 16:04:09.548746 20404 net.cpp:217] ReLU53 needs backward computation.
I0816 16:04:09.548753 20404 net.cpp:217] InnerProduct21 needs backward computation.
I0816 16:04:09.548759 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.548768 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.548776 20404 net.cpp:219] ReLU52 does not need backward computation.
I0816 16:04:09.548784 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.548790 20404 net.cpp:219] ReLU51 does not need backward computation.
I0816 16:04:09.548797 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.548804 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.548812 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.548820 20404 net.cpp:219] ReLU50 does not need backward computation.
I0816 16:04:09.548826 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.548833 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.548840 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.548848 20404 net.cpp:219] ReLU49 does not need backward computation.
I0816 16:04:09.548854 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.548862 20404 net.cpp:217] ReLU48 needs backward computation.
I0816 16:04:09.548868 20404 net.cpp:217] InnerProduct20 needs backward computation.
I0816 16:04:09.548876 20404 net.cpp:217] ReLU47 needs backward computation.
I0816 16:04:09.548882 20404 net.cpp:217] InnerProduct19 needs backward computation.
I0816 16:04:09.548889 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.548897 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.548904 20404 net.cpp:219] ReLU46 does not need backward computation.
I0816 16:04:09.548912 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.548918 20404 net.cpp:219] ReLU45 does not need backward computation.
I0816 16:04:09.548924 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.548931 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.548939 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.548946 20404 net.cpp:219] ReLU44 does not need backward computation.
I0816 16:04:09.548954 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.548960 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.548967 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.548975 20404 net.cpp:219] ReLU43 does not need backward computation.
I0816 16:04:09.548982 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.548990 20404 net.cpp:217] dt2 needs backward computation.
I0816 16:04:09.548996 20404 net.cpp:217] ReLU42 needs backward computation.
I0816 16:04:09.549003 20404 net.cpp:217] InnerProduct18 needs backward computation.
I0816 16:04:09.549010 20404 net.cpp:217] ReLU41 needs backward computation.
I0816 16:04:09.549016 20404 net.cpp:217] InnerProduct17 needs backward computation.
I0816 16:04:09.549022 20404 net.cpp:217] Concat3 needs backward computation.
I0816 16:04:09.549031 20404 net.cpp:217] ReLU40 needs backward computation.
I0816 16:04:09.549036 20404 net.cpp:217] InnerProduct16 needs backward computation.
I0816 16:04:09.549043 20404 net.cpp:217] ReLU39 needs backward computation.
I0816 16:04:09.549049 20404 net.cpp:217] InnerProduct15 needs backward computation.
I0816 16:04:09.549057 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.549064 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.549072 20404 net.cpp:219] ReLU38 does not need backward computation.
I0816 16:04:09.549078 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.549087 20404 net.cpp:219] ReLU37 does not need backward computation.
I0816 16:04:09.549093 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.549108 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.549114 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.549123 20404 net.cpp:219] ReLU36 does not need backward computation.
I0816 16:04:09.549129 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.549136 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.549144 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.549150 20404 net.cpp:219] ReLU35 does not need backward computation.
I0816 16:04:09.549157 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.549165 20404 net.cpp:217] ReLU34 needs backward computation.
I0816 16:04:09.549170 20404 net.cpp:217] InnerProduct14 needs backward computation.
I0816 16:04:09.549177 20404 net.cpp:217] ReLU33 needs backward computation.
I0816 16:04:09.549183 20404 net.cpp:217] InnerProduct13 needs backward computation.
I0816 16:04:09.549190 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.549198 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.549206 20404 net.cpp:219] ReLU32 does not need backward computation.
I0816 16:04:09.549212 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.549219 20404 net.cpp:219] ReLU31 does not need backward computation.
I0816 16:04:09.549226 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.549233 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.549240 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.549248 20404 net.cpp:219] ReLU30 does not need backward computation.
I0816 16:04:09.549254 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.549263 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.549271 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.549279 20404 net.cpp:219] ReLU29 does not need backward computation.
I0816 16:04:09.549286 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.549293 20404 net.cpp:217] dt1 needs backward computation.
I0816 16:04:09.549300 20404 net.cpp:217] ReLU28 needs backward computation.
I0816 16:04:09.549306 20404 net.cpp:217] InnerProduct12 needs backward computation.
I0816 16:04:09.549314 20404 net.cpp:217] ReLU27 needs backward computation.
I0816 16:04:09.549319 20404 net.cpp:217] InnerProduct11 needs backward computation.
I0816 16:04:09.549326 20404 net.cpp:217] Concat2 needs backward computation.
I0816 16:04:09.549335 20404 net.cpp:217] ReLU26 needs backward computation.
I0816 16:04:09.549340 20404 net.cpp:217] InnerProduct10 needs backward computation.
I0816 16:04:09.549347 20404 net.cpp:217] ReLU25 needs backward computation.
I0816 16:04:09.549353 20404 net.cpp:217] InnerProduct9 needs backward computation.
I0816 16:04:09.549360 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.549368 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.549376 20404 net.cpp:219] ReLU24 does not need backward computation.
I0816 16:04:09.549382 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.549389 20404 net.cpp:219] ReLU23 does not need backward computation.
I0816 16:04:09.549396 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.549403 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.549410 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.549417 20404 net.cpp:219] ReLU22 does not need backward computation.
I0816 16:04:09.549424 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.549432 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.549438 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.549445 20404 net.cpp:219] ReLU21 does not need backward computation.
I0816 16:04:09.549459 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.549466 20404 net.cpp:217] ReLU20 needs backward computation.
I0816 16:04:09.549474 20404 net.cpp:217] InnerProduct8 needs backward computation.
I0816 16:04:09.549479 20404 net.cpp:217] ReLU19 needs backward computation.
I0816 16:04:09.549486 20404 net.cpp:217] InnerProduct7 needs backward computation.
I0816 16:04:09.549494 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.549500 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.549507 20404 net.cpp:219] ReLU18 does not need backward computation.
I0816 16:04:09.549513 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.549520 20404 net.cpp:219] ReLU17 does not need backward computation.
I0816 16:04:09.549526 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.549533 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.549540 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.549547 20404 net.cpp:219] ReLU16 does not need backward computation.
I0816 16:04:09.549553 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.549561 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.549567 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.549574 20404 net.cpp:219] ReLU15 does not need backward computation.
I0816 16:04:09.549581 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.549587 20404 net.cpp:217] dt0 needs backward computation.
I0816 16:04:09.549594 20404 net.cpp:217] ReLU14 needs backward computation.
I0816 16:04:09.549600 20404 net.cpp:217] InnerProduct6 needs backward computation.
I0816 16:04:09.549607 20404 net.cpp:217] ReLU13 needs backward computation.
I0816 16:04:09.549613 20404 net.cpp:217] InnerProduct5 needs backward computation.
I0816 16:04:09.549619 20404 net.cpp:217] Concat1 needs backward computation.
I0816 16:04:09.549628 20404 net.cpp:217] ReLU12 needs backward computation.
I0816 16:04:09.549633 20404 net.cpp:217] InnerProduct4 needs backward computation.
I0816 16:04:09.549640 20404 net.cpp:217] ReLU11 needs backward computation.
I0816 16:04:09.549648 20404 net.cpp:217] InnerProduct3 needs backward computation.
I0816 16:04:09.549654 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.549661 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.549669 20404 net.cpp:219] ReLU10 does not need backward computation.
I0816 16:04:09.549675 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.549682 20404 net.cpp:219] ReLU9 does not need backward computation.
I0816 16:04:09.549688 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.549696 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.549703 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.549710 20404 net.cpp:219] ReLU8 does not need backward computation.
I0816 16:04:09.549716 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.549724 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.549731 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.549737 20404 net.cpp:219] ReLU7 does not need backward computation.
I0816 16:04:09.549743 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.549751 20404 net.cpp:217] ReLU6 needs backward computation.
I0816 16:04:09.549757 20404 net.cpp:217] InnerProduct2 needs backward computation.
I0816 16:04:09.549764 20404 net.cpp:217] ReLU5 needs backward computation.
I0816 16:04:09.549770 20404 net.cpp:217] InnerProduct1 needs backward computation.
I0816 16:04:09.549780 20404 net.cpp:219] pool5 does not need backward computation.
I0816 16:04:09.549787 20404 net.cpp:219] conv5 does not need backward computation.
I0816 16:04:09.549794 20404 net.cpp:219] ReLU4 does not need backward computation.
I0816 16:04:09.549801 20404 net.cpp:219] conv4 does not need backward computation.
I0816 16:04:09.549815 20404 net.cpp:219] ReLU3 does not need backward computation.
I0816 16:04:09.549823 20404 net.cpp:219] conv3 does not need backward computation.
I0816 16:04:09.549830 20404 net.cpp:219] pool2 does not need backward computation.
I0816 16:04:09.549837 20404 net.cpp:219] norm2 does not need backward computation.
I0816 16:04:09.549845 20404 net.cpp:219] ReLU2 does not need backward computation.
I0816 16:04:09.549851 20404 net.cpp:219] conv2 does not need backward computation.
I0816 16:04:09.549860 20404 net.cpp:219] pool1 does not need backward computation.
I0816 16:04:09.549866 20404 net.cpp:219] norm1 does not need backward computation.
I0816 16:04:09.549873 20404 net.cpp:219] ReLU1 does not need backward computation.
I0816 16:04:09.549880 20404 net.cpp:219] conv1 does not need backward computation.
I0816 16:04:09.549887 20404 net.cpp:219] c29 does not need backward computation.
I0816 16:04:09.549896 20404 net.cpp:219] Input18 does not need backward computation.
I0816 16:04:09.549902 20404 net.cpp:219] c28 does not need backward computation.
I0816 16:04:09.549911 20404 net.cpp:219] Input17 does not need backward computation.
I0816 16:04:09.549916 20404 net.cpp:219] c27 does not need backward computation.
I0816 16:04:09.549926 20404 net.cpp:219] Input16 does not need backward computation.
I0816 16:04:09.549932 20404 net.cpp:219] c26 does not need backward computation.
I0816 16:04:09.549939 20404 net.cpp:219] Input15 does not need backward computation.
I0816 16:04:09.549947 20404 net.cpp:219] c25 does not need backward computation.
I0816 16:04:09.549954 20404 net.cpp:219] Input14 does not need backward computation.
I0816 16:04:09.549960 20404 net.cpp:219] c24 does not need backward computation.
I0816 16:04:09.549968 20404 net.cpp:219] Input13 does not need backward computation.
I0816 16:04:09.549974 20404 net.cpp:219] c23 does not need backward computation.
I0816 16:04:09.549983 20404 net.cpp:219] Input12 does not need backward computation.
I0816 16:04:09.549988 20404 net.cpp:219] c22 does not need backward computation.
I0816 16:04:09.549996 20404 net.cpp:219] Input11 does not need backward computation.
I0816 16:04:09.550003 20404 net.cpp:219] c21 does not need backward computation.
I0816 16:04:09.550010 20404 net.cpp:219] Input10 does not need backward computation.
I0816 16:04:09.550016 20404 net.cpp:219] c19 does not need backward computation.
I0816 16:04:09.550025 20404 net.cpp:219] Input9 does not need backward computation.
I0816 16:04:09.550031 20404 net.cpp:219] c18 does not need backward computation.
I0816 16:04:09.550040 20404 net.cpp:219] Input8 does not need backward computation.
I0816 16:04:09.550045 20404 net.cpp:219] c17 does not need backward computation.
I0816 16:04:09.550055 20404 net.cpp:219] Input7 does not need backward computation.
I0816 16:04:09.550060 20404 net.cpp:219] c16 does not need backward computation.
I0816 16:04:09.550068 20404 net.cpp:219] Input6 does not need backward computation.
I0816 16:04:09.550074 20404 net.cpp:219] c15 does not need backward computation.
I0816 16:04:09.550082 20404 net.cpp:219] Input5 does not need backward computation.
I0816 16:04:09.550087 20404 net.cpp:219] c14 does not need backward computation.
I0816 16:04:09.550096 20404 net.cpp:219] Input4 does not need backward computation.
I0816 16:04:09.550101 20404 net.cpp:219] c13 does not need backward computation.
I0816 16:04:09.550112 20404 net.cpp:219] Input3 does not need backward computation.
I0816 16:04:09.550118 20404 net.cpp:219] c12 does not need backward computation.
I0816 16:04:09.550127 20404 net.cpp:219] Input2 does not need backward computation.
I0816 16:04:09.550132 20404 net.cpp:219] c11 does not need backward computation.
I0816 16:04:09.550142 20404 net.cpp:219] Input1 does not need backward computation.
I0816 16:04:09.550151 20404 net.cpp:219] p2_p2_0_split does not need backward computation.
I0816 16:04:09.550158 20404 net.cpp:219] p2 does not need backward computation.
I0816 16:04:09.550169 20404 net.cpp:219] p1_p1_0_split does not need backward computation.
I0816 16:04:09.550184 20404 net.cpp:219] p1 does not need backward computation.
I0816 16:04:09.550195 20404 net.cpp:219] i2_i1_1_split does not need backward computation.
I0816 16:04:09.550206 20404 net.cpp:219] i1_i1_0_split does not need backward computation.
I0816 16:04:09.550215 20404 net.cpp:219] i1 does not need backward computation.
I0816 16:04:09.550221 20404 net.cpp:219] th_th_0_split does not need backward computation.
I0816 16:04:09.550228 20404 net.cpp:219] th does not need backward computation.
I0816 16:04:09.550235 20404 net.cpp:219] label_data_1_split does not need backward computation.
I0816 16:04:09.550243 20404 net.cpp:219] data does not need backward computation.
I0816 16:04:09.550248 20404 net.cpp:261] This network produces output accuracy
I0816 16:04:09.550254 20404 net.cpp:261] This network produces output loss
I0816 16:04:09.567456 20404 net.cpp:274] Network initialization done.
I0816 16:04:09.573161 20404 solver.cpp:60] Solver scaffolding done.
I0816 16:04:09.597966 20404 caffe.cpp:129] Finetuning from /home/shaogangwang/Downloads/placesCNN_upgraded/places205CNN_iter_300000_upgraded.caffemodel
I0816 16:04:39.165657 20404 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/shaogangwang/Downloads/placesCNN_upgraded/places205CNN_iter_300000_upgraded.caffemodel
I0816 16:04:54.778568 20404 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0816 16:04:54.788710 20404 net.cpp:752] Ignoring source layer relu1
I0816 16:04:54.789170 20404 net.cpp:752] Ignoring source layer relu2
I0816 16:04:54.790413 20404 net.cpp:752] Ignoring source layer relu3
I0816 16:04:54.791340 20404 net.cpp:752] Ignoring source layer relu4
I0816 16:04:54.791971 20404 net.cpp:752] Ignoring source layer relu5
I0816 16:04:54.791993 20404 net.cpp:752] Ignoring source layer fc6
I0816 16:04:54.792007 20404 net.cpp:752] Ignoring source layer relu6
I0816 16:04:54.792026 20404 net.cpp:752] Ignoring source layer drop6
I0816 16:04:54.792037 20404 net.cpp:752] Ignoring source layer fc7
I0816 16:04:54.792048 20404 net.cpp:752] Ignoring source layer relu7
I0816 16:04:54.792062 20404 net.cpp:752] Ignoring source layer drop7
I0816 16:04:54.792071 20404 net.cpp:752] Ignoring source layer fc8
I0816 16:05:12.969535 20404 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/shaogangwang/Downloads/placesCNN_upgraded/places205CNN_iter_300000_upgraded.caffemodel
I0816 16:05:31.663653 20404 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0816 16:05:31.673732 20404 net.cpp:752] Ignoring source layer relu1
I0816 16:05:31.674195 20404 net.cpp:752] Ignoring source layer relu2
I0816 16:05:31.675474 20404 net.cpp:752] Ignoring source layer relu3
I0816 16:05:31.676391 20404 net.cpp:752] Ignoring source layer relu4
I0816 16:05:31.677098 20404 net.cpp:752] Ignoring source layer relu5
I0816 16:05:31.677124 20404 net.cpp:752] Ignoring source layer fc6
I0816 16:05:31.677139 20404 net.cpp:752] Ignoring source layer relu6
I0816 16:05:31.677157 20404 net.cpp:752] Ignoring source layer drop6
I0816 16:05:31.677170 20404 net.cpp:752] Ignoring source layer fc7
I0816 16:05:31.677186 20404 net.cpp:752] Ignoring source layer relu7
I0816 16:05:31.677201 20404 net.cpp:752] Ignoring source layer drop7
I0816 16:05:31.677213 20404 net.cpp:752] Ignoring source layer fc8
I0816 16:05:31.699353 20404 caffe.cpp:219] Starting Optimization
I0816 16:05:31.699383 20404 solver.cpp:279] Solving 
I0816 16:05:31.699393 20404 solver.cpp:280] Learning Rate Policy: inv
I0816 16:05:31.741140 20404 solver.cpp:337] Iteration 0, Testing net (#0)
I0816 16:06:06.062942 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 16:06:06.063144 20404 solver.cpp:404]     Test net output #1: loss = 1.02064 (* 1 = 1.02064 loss)
I0816 16:06:09.681680 20404 solver.cpp:228] Iteration 0, loss = 1.01244
I0816 16:06:09.681723 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:06:09.681740 20404 solver.cpp:244]     Train net output #1: loss = 1.01244 (* 1 = 1.01244 loss)
I0816 16:06:09.681757 20404 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0816 16:06:44.435820 20404 solver.cpp:228] Iteration 10, loss = 1.00144
I0816 16:06:44.435906 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:06:44.435935 20404 solver.cpp:244]     Train net output #1: loss = 1.00144 (* 1 = 1.00144 loss)
I0816 16:06:44.435950 20404 sgd_solver.cpp:106] Iteration 10, lr = 0.000999251
I0816 16:07:19.214154 20404 solver.cpp:228] Iteration 20, loss = 0.981622
I0816 16:07:19.214323 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:07:19.214339 20404 solver.cpp:244]     Train net output #1: loss = 0.981622 (* 1 = 0.981622 loss)
I0816 16:07:19.214350 20404 sgd_solver.cpp:106] Iteration 20, lr = 0.000998503
I0816 16:07:53.997443 20404 solver.cpp:228] Iteration 30, loss = 0.962346
I0816 16:07:53.997609 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:07:53.997624 20404 solver.cpp:244]     Train net output #1: loss = 0.962346 (* 1 = 0.962346 loss)
I0816 16:07:53.997637 20404 sgd_solver.cpp:106] Iteration 30, lr = 0.000997756
I0816 16:08:25.311326 20404 solver.cpp:337] Iteration 40, Testing net (#0)
I0816 16:08:59.842736 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 16:08:59.842903 20404 solver.cpp:404]     Test net output #1: loss = 0.897518 (* 1 = 0.897518 loss)
I0816 16:09:03.309672 20404 solver.cpp:228] Iteration 40, loss = 0.94297
I0816 16:09:03.309720 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:09:03.309733 20404 solver.cpp:244]     Train net output #1: loss = 0.94297 (* 1 = 0.94297 loss)
I0816 16:09:03.309746 20404 sgd_solver.cpp:106] Iteration 40, lr = 0.000997011
I0816 16:09:38.085944 20404 solver.cpp:228] Iteration 50, loss = 0.922515
I0816 16:09:38.086127 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:09:38.086143 20404 solver.cpp:244]     Train net output #1: loss = 0.922515 (* 1 = 0.922515 loss)
I0816 16:09:38.086154 20404 sgd_solver.cpp:106] Iteration 50, lr = 0.000996266
I0816 16:10:12.892663 20404 solver.cpp:228] Iteration 60, loss = 0.900728
I0816 16:10:12.892835 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:10:12.892850 20404 solver.cpp:244]     Train net output #1: loss = 0.900728 (* 1 = 0.900728 loss)
I0816 16:10:12.892863 20404 sgd_solver.cpp:106] Iteration 60, lr = 0.000995524
I0816 16:10:47.692893 20404 solver.cpp:228] Iteration 70, loss = 0.87687
I0816 16:10:47.693068 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:10:47.693083 20404 solver.cpp:244]     Train net output #1: loss = 0.87687 (* 1 = 0.87687 loss)
I0816 16:10:47.693095 20404 sgd_solver.cpp:106] Iteration 70, lr = 0.000994782
I0816 16:11:19.013799 20404 solver.cpp:337] Iteration 80, Testing net (#0)
I0816 16:11:53.587615 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 16:11:53.587788 20404 solver.cpp:404]     Test net output #1: loss = 0.727834 (* 1 = 0.727834 loss)
I0816 16:11:57.053948 20404 solver.cpp:228] Iteration 80, loss = 0.850303
I0816 16:11:57.053999 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:11:57.054013 20404 solver.cpp:244]     Train net output #1: loss = 0.850303 (* 1 = 0.850303 loss)
I0816 16:11:57.054024 20404 sgd_solver.cpp:106] Iteration 80, lr = 0.000994042
I0816 16:12:31.849402 20404 solver.cpp:228] Iteration 90, loss = 0.82017
I0816 16:12:31.849616 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:12:31.849632 20404 solver.cpp:244]     Train net output #1: loss = 0.82017 (* 1 = 0.82017 loss)
I0816 16:12:31.849643 20404 sgd_solver.cpp:106] Iteration 90, lr = 0.000993303
I0816 16:13:06.662701 20404 solver.cpp:228] Iteration 100, loss = 0.83677
I0816 16:13:06.662885 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:13:06.662900 20404 solver.cpp:244]     Train net output #1: loss = 0.83677 (* 1 = 0.83677 loss)
I0816 16:13:06.662912 20404 sgd_solver.cpp:106] Iteration 100, lr = 0.000992565
I0816 16:13:41.468881 20404 solver.cpp:228] Iteration 110, loss = 0.824994
I0816 16:13:41.469048 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:13:41.469063 20404 solver.cpp:244]     Train net output #1: loss = 0.824994 (* 1 = 0.824994 loss)
I0816 16:13:41.469075 20404 sgd_solver.cpp:106] Iteration 110, lr = 0.000991829
I0816 16:14:12.798126 20404 solver.cpp:337] Iteration 120, Testing net (#0)
I0816 16:14:47.355321 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 16:14:47.355495 20404 solver.cpp:404]     Test net output #1: loss = 0.671922 (* 1 = 0.671922 loss)
I0816 16:14:50.817215 20404 solver.cpp:228] Iteration 120, loss = 0.823189
I0816 16:14:50.817263 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:14:50.817277 20404 solver.cpp:244]     Train net output #1: loss = 0.823189 (* 1 = 0.823189 loss)
I0816 16:14:50.817289 20404 sgd_solver.cpp:106] Iteration 120, lr = 0.000991094
I0816 16:15:25.620930 20404 solver.cpp:228] Iteration 130, loss = 0.823268
I0816 16:15:25.621107 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:15:25.621125 20404 solver.cpp:244]     Train net output #1: loss = 0.823268 (* 1 = 0.823268 loss)
I0816 16:15:25.621139 20404 sgd_solver.cpp:106] Iteration 130, lr = 0.00099036
I0816 16:16:00.416628 20404 solver.cpp:228] Iteration 140, loss = 0.820211
I0816 16:16:00.416802 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:16:00.416821 20404 solver.cpp:244]     Train net output #1: loss = 0.820211 (* 1 = 0.820211 loss)
I0816 16:16:00.416834 20404 sgd_solver.cpp:106] Iteration 140, lr = 0.000989627
I0816 16:16:35.217950 20404 solver.cpp:228] Iteration 150, loss = 0.821406
I0816 16:16:35.218130 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:16:35.218148 20404 solver.cpp:244]     Train net output #1: loss = 0.821406 (* 1 = 0.821406 loss)
I0816 16:16:35.218163 20404 sgd_solver.cpp:106] Iteration 150, lr = 0.000988896
I0816 16:17:06.536000 20404 solver.cpp:337] Iteration 160, Testing net (#0)
I0816 16:17:41.099138 20404 solver.cpp:404]     Test net output #0: accuracy = 0.911
I0816 16:17:41.099331 20404 solver.cpp:404]     Test net output #1: loss = 0.670033 (* 1 = 0.670033 loss)
I0816 16:17:44.560462 20404 solver.cpp:228] Iteration 160, loss = 0.820741
I0816 16:17:44.560511 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:17:44.560525 20404 solver.cpp:244]     Train net output #1: loss = 0.820741 (* 1 = 0.820741 loss)
I0816 16:17:44.560536 20404 sgd_solver.cpp:106] Iteration 160, lr = 0.000988166
I0816 16:18:19.363160 20404 solver.cpp:228] Iteration 170, loss = 0.820275
I0816 16:18:19.363333 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:18:19.363348 20404 solver.cpp:244]     Train net output #1: loss = 0.820275 (* 1 = 0.820275 loss)
I0816 16:18:19.363361 20404 sgd_solver.cpp:106] Iteration 170, lr = 0.000987437
I0816 16:18:54.163694 20404 solver.cpp:228] Iteration 180, loss = 0.820294
I0816 16:18:54.163784 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:18:54.163800 20404 solver.cpp:244]     Train net output #1: loss = 0.820294 (* 1 = 0.820294 loss)
I0816 16:18:54.163812 20404 sgd_solver.cpp:106] Iteration 180, lr = 0.000986709
I0816 16:19:28.919771 20404 solver.cpp:228] Iteration 190, loss = 0.820147
I0816 16:19:28.919961 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:19:28.919976 20404 solver.cpp:244]     Train net output #1: loss = 0.820147 (* 1 = 0.820147 loss)
I0816 16:19:28.919989 20404 sgd_solver.cpp:106] Iteration 190, lr = 0.000985983
I0816 16:20:00.257377 20404 solver.cpp:337] Iteration 200, Testing net (#0)
I0816 16:20:34.796605 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 16:20:34.796790 20404 solver.cpp:404]     Test net output #1: loss = 0.670211 (* 1 = 0.670211 loss)
I0816 16:20:38.257184 20404 solver.cpp:228] Iteration 200, loss = 0.82105
I0816 16:20:38.257237 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:20:38.257251 20404 solver.cpp:244]     Train net output #1: loss = 0.82105 (* 1 = 0.82105 loss)
I0816 16:20:38.257263 20404 sgd_solver.cpp:106] Iteration 200, lr = 0.000985258
I0816 16:21:13.033262 20404 solver.cpp:228] Iteration 210, loss = 0.820157
I0816 16:21:13.033345 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:21:13.033360 20404 solver.cpp:244]     Train net output #1: loss = 0.820157 (* 1 = 0.820157 loss)
I0816 16:21:13.033371 20404 sgd_solver.cpp:106] Iteration 210, lr = 0.000984534
I0816 16:21:47.821589 20404 solver.cpp:228] Iteration 220, loss = 0.820637
I0816 16:21:47.821763 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:21:47.821779 20404 solver.cpp:244]     Train net output #1: loss = 0.820637 (* 1 = 0.820637 loss)
I0816 16:21:47.821791 20404 sgd_solver.cpp:106] Iteration 220, lr = 0.000983811
I0816 16:22:22.623821 20404 solver.cpp:228] Iteration 230, loss = 0.821862
I0816 16:22:22.623996 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:22:22.624011 20404 solver.cpp:244]     Train net output #1: loss = 0.821862 (* 1 = 0.821862 loss)
I0816 16:22:22.624024 20404 sgd_solver.cpp:106] Iteration 230, lr = 0.00098309
I0816 16:22:53.967218 20404 solver.cpp:337] Iteration 240, Testing net (#0)
I0816 16:23:28.505381 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 16:23:28.505551 20404 solver.cpp:404]     Test net output #1: loss = 0.670836 (* 1 = 0.670836 loss)
I0816 16:23:31.969755 20404 solver.cpp:228] Iteration 240, loss = 0.820147
I0816 16:23:31.969805 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:23:31.969818 20404 solver.cpp:244]     Train net output #1: loss = 0.820147 (* 1 = 0.820147 loss)
I0816 16:23:31.969830 20404 sgd_solver.cpp:106] Iteration 240, lr = 0.00098237
I0816 16:24:06.747970 20404 solver.cpp:228] Iteration 250, loss = 0.820917
I0816 16:24:06.748148 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:24:06.748163 20404 solver.cpp:244]     Train net output #1: loss = 0.820917 (* 1 = 0.820917 loss)
I0816 16:24:06.748175 20404 sgd_solver.cpp:106] Iteration 250, lr = 0.000981651
I0816 16:24:41.551187 20404 solver.cpp:228] Iteration 260, loss = 0.820282
I0816 16:24:41.551363 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:24:41.551378 20404 solver.cpp:244]     Train net output #1: loss = 0.820282 (* 1 = 0.820282 loss)
I0816 16:24:41.551391 20404 sgd_solver.cpp:106] Iteration 260, lr = 0.000980933
I0816 16:25:16.347057 20404 solver.cpp:228] Iteration 270, loss = 0.820486
I0816 16:25:16.347163 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:25:16.347179 20404 solver.cpp:244]     Train net output #1: loss = 0.820486 (* 1 = 0.820486 loss)
I0816 16:25:16.347192 20404 sgd_solver.cpp:106] Iteration 270, lr = 0.000980217
I0816 16:25:47.682018 20404 solver.cpp:337] Iteration 280, Testing net (#0)
I0816 16:26:22.235314 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 16:26:22.235489 20404 solver.cpp:404]     Test net output #1: loss = 0.670442 (* 1 = 0.670442 loss)
I0816 16:26:25.699390 20404 solver.cpp:228] Iteration 280, loss = 0.820237
I0816 16:26:25.699435 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:26:25.699452 20404 solver.cpp:244]     Train net output #1: loss = 0.820237 (* 1 = 0.820237 loss)
I0816 16:26:25.699467 20404 sgd_solver.cpp:106] Iteration 280, lr = 0.000979502
I0816 16:27:00.507488 20404 solver.cpp:228] Iteration 290, loss = 0.820539
I0816 16:27:00.507700 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:27:00.507719 20404 solver.cpp:244]     Train net output #1: loss = 0.820539 (* 1 = 0.820539 loss)
I0816 16:27:00.507735 20404 sgd_solver.cpp:106] Iteration 290, lr = 0.000978788
I0816 16:27:35.327157 20404 solver.cpp:228] Iteration 300, loss = 0.821437
I0816 16:27:35.327281 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:27:35.327301 20404 solver.cpp:244]     Train net output #1: loss = 0.821437 (* 1 = 0.821437 loss)
I0816 16:27:35.327316 20404 sgd_solver.cpp:106] Iteration 300, lr = 0.000978075
I0816 16:28:10.129058 20404 solver.cpp:228] Iteration 310, loss = 0.821939
I0816 16:28:10.129241 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:28:10.129261 20404 solver.cpp:244]     Train net output #1: loss = 0.821939 (* 1 = 0.821939 loss)
I0816 16:28:10.129276 20404 sgd_solver.cpp:106] Iteration 310, lr = 0.000977363
I0816 16:28:41.432051 20404 solver.cpp:337] Iteration 320, Testing net (#0)
I0816 16:29:15.989773 20404 solver.cpp:404]     Test net output #0: accuracy = 0.994
I0816 16:29:15.989953 20404 solver.cpp:404]     Test net output #1: loss = 0.670078 (* 1 = 0.670078 loss)
I0816 16:29:19.452265 20404 solver.cpp:228] Iteration 320, loss = 0.820709
I0816 16:29:19.452313 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:29:19.452342 20404 solver.cpp:244]     Train net output #1: loss = 0.820709 (* 1 = 0.820709 loss)
I0816 16:29:19.452358 20404 sgd_solver.cpp:106] Iteration 320, lr = 0.000976653
I0816 16:29:54.231598 20404 solver.cpp:228] Iteration 330, loss = 0.820399
I0816 16:29:54.231788 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:29:54.231804 20404 solver.cpp:244]     Train net output #1: loss = 0.820399 (* 1 = 0.820399 loss)
I0816 16:29:54.231817 20404 sgd_solver.cpp:106] Iteration 330, lr = 0.000975944
I0816 16:30:29.037024 20404 solver.cpp:228] Iteration 340, loss = 0.8212
I0816 16:30:29.037205 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:30:29.037225 20404 solver.cpp:244]     Train net output #1: loss = 0.8212 (* 1 = 0.8212 loss)
I0816 16:30:29.037240 20404 sgd_solver.cpp:106] Iteration 340, lr = 0.000975236
I0816 16:31:03.844811 20404 solver.cpp:228] Iteration 350, loss = 0.820145
I0816 16:31:03.844985 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:31:03.845000 20404 solver.cpp:244]     Train net output #1: loss = 0.820145 (* 1 = 0.820145 loss)
I0816 16:31:03.845013 20404 sgd_solver.cpp:106] Iteration 350, lr = 0.000974529
I0816 16:31:35.185006 20404 solver.cpp:337] Iteration 360, Testing net (#0)
I0816 16:32:09.745617 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 16:32:09.745724 20404 solver.cpp:404]     Test net output #1: loss = 0.670178 (* 1 = 0.670178 loss)
I0816 16:32:13.211980 20404 solver.cpp:228] Iteration 360, loss = 0.821048
I0816 16:32:13.212023 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:32:13.212040 20404 solver.cpp:244]     Train net output #1: loss = 0.821048 (* 1 = 0.821048 loss)
I0816 16:32:13.212064 20404 sgd_solver.cpp:106] Iteration 360, lr = 0.000973823
I0816 16:32:47.993633 20404 solver.cpp:228] Iteration 370, loss = 0.820032
I0816 16:32:47.993816 20404 solver.cpp:244]     Train net output #0: accuracy = 0.81
I0816 16:32:47.993831 20404 solver.cpp:244]     Train net output #1: loss = 0.820032 (* 1 = 0.820032 loss)
I0816 16:32:47.993844 20404 sgd_solver.cpp:106] Iteration 370, lr = 0.000973119
I0816 16:33:22.804337 20404 solver.cpp:228] Iteration 380, loss = 0.820648
I0816 16:33:22.804515 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:33:22.804530 20404 solver.cpp:244]     Train net output #1: loss = 0.820648 (* 1 = 0.820648 loss)
I0816 16:33:22.804543 20404 sgd_solver.cpp:106] Iteration 380, lr = 0.000972416
I0816 16:33:57.614446 20404 solver.cpp:228] Iteration 390, loss = 0.820241
I0816 16:33:57.614658 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:33:57.614675 20404 solver.cpp:244]     Train net output #1: loss = 0.820241 (* 1 = 0.820241 loss)
I0816 16:33:57.614688 20404 sgd_solver.cpp:106] Iteration 390, lr = 0.000971714
I0816 16:34:28.960351 20404 solver.cpp:337] Iteration 400, Testing net (#0)
I0816 16:35:03.479117 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 16:35:03.479301 20404 solver.cpp:404]     Test net output #1: loss = 0.672091 (* 1 = 0.672091 loss)
I0816 16:35:06.941421 20404 solver.cpp:228] Iteration 400, loss = 0.820832
I0816 16:35:06.941463 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:35:06.941481 20404 solver.cpp:244]     Train net output #1: loss = 0.820832 (* 1 = 0.820832 loss)
I0816 16:35:06.941506 20404 sgd_solver.cpp:106] Iteration 400, lr = 0.000971013
I0816 16:35:41.726213 20404 solver.cpp:228] Iteration 410, loss = 0.82126
I0816 16:35:41.726388 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:35:41.726407 20404 solver.cpp:244]     Train net output #1: loss = 0.82126 (* 1 = 0.82126 loss)
I0816 16:35:41.726421 20404 sgd_solver.cpp:106] Iteration 410, lr = 0.000970313
I0816 16:36:16.517545 20404 solver.cpp:228] Iteration 420, loss = 0.820253
I0816 16:36:16.517731 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:36:16.517751 20404 solver.cpp:244]     Train net output #1: loss = 0.820253 (* 1 = 0.820253 loss)
I0816 16:36:16.517765 20404 sgd_solver.cpp:106] Iteration 420, lr = 0.000969615
I0816 16:36:51.306046 20404 solver.cpp:228] Iteration 430, loss = 0.82092
I0816 16:36:51.306226 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:36:51.306241 20404 solver.cpp:244]     Train net output #1: loss = 0.82092 (* 1 = 0.82092 loss)
I0816 16:36:51.306254 20404 sgd_solver.cpp:106] Iteration 430, lr = 0.000968918
I0816 16:37:22.651509 20404 solver.cpp:337] Iteration 440, Testing net (#0)
I0816 16:37:57.176097 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 16:37:57.176275 20404 solver.cpp:404]     Test net output #1: loss = 0.670108 (* 1 = 0.670108 loss)
I0816 16:38:00.638418 20404 solver.cpp:228] Iteration 440, loss = 0.820979
I0816 16:38:00.638464 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:38:00.638483 20404 solver.cpp:244]     Train net output #1: loss = 0.820979 (* 1 = 0.820979 loss)
I0816 16:38:00.638499 20404 sgd_solver.cpp:106] Iteration 440, lr = 0.000968221
I0816 16:38:35.401458 20404 solver.cpp:228] Iteration 450, loss = 0.820045
I0816 16:38:35.401636 20404 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0816 16:38:35.401654 20404 solver.cpp:244]     Train net output #1: loss = 0.820045 (* 1 = 0.820045 loss)
I0816 16:38:35.401669 20404 sgd_solver.cpp:106] Iteration 450, lr = 0.000967526
I0816 16:39:10.183850 20404 solver.cpp:228] Iteration 460, loss = 0.820646
I0816 16:39:10.183960 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:39:10.183975 20404 solver.cpp:244]     Train net output #1: loss = 0.820646 (* 1 = 0.820646 loss)
I0816 16:39:10.183987 20404 sgd_solver.cpp:106] Iteration 460, lr = 0.000966833
I0816 16:39:44.976584 20404 solver.cpp:228] Iteration 470, loss = 0.820815
I0816 16:39:44.976768 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:39:44.976783 20404 solver.cpp:244]     Train net output #1: loss = 0.820815 (* 1 = 0.820815 loss)
I0816 16:39:44.976795 20404 sgd_solver.cpp:106] Iteration 470, lr = 0.00096614
I0816 16:40:16.310636 20404 solver.cpp:337] Iteration 480, Testing net (#0)
I0816 16:40:50.851475 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 16:40:50.851650 20404 solver.cpp:404]     Test net output #1: loss = 0.670993 (* 1 = 0.670993 loss)
I0816 16:40:54.317399 20404 solver.cpp:228] Iteration 480, loss = 0.822107
I0816 16:40:54.317451 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:40:54.317464 20404 solver.cpp:244]     Train net output #1: loss = 0.822107 (* 1 = 0.822107 loss)
I0816 16:40:54.317476 20404 sgd_solver.cpp:106] Iteration 480, lr = 0.000965448
I0816 16:41:29.123821 20404 solver.cpp:228] Iteration 490, loss = 0.820127
I0816 16:41:29.124037 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:41:29.124053 20404 solver.cpp:244]     Train net output #1: loss = 0.820127 (* 1 = 0.820127 loss)
I0816 16:41:29.124065 20404 sgd_solver.cpp:106] Iteration 490, lr = 0.000964758
I0816 16:42:03.933395 20404 solver.cpp:228] Iteration 500, loss = 0.821671
I0816 16:42:03.933506 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:42:03.933522 20404 solver.cpp:244]     Train net output #1: loss = 0.821671 (* 1 = 0.821671 loss)
I0816 16:42:03.933534 20404 sgd_solver.cpp:106] Iteration 500, lr = 0.000964069
I0816 16:42:38.721173 20404 solver.cpp:228] Iteration 510, loss = 0.82035
I0816 16:42:38.721349 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:42:38.721364 20404 solver.cpp:244]     Train net output #1: loss = 0.82035 (* 1 = 0.82035 loss)
I0816 16:42:38.721376 20404 sgd_solver.cpp:106] Iteration 510, lr = 0.000963381
I0816 16:43:10.059695 20404 solver.cpp:337] Iteration 520, Testing net (#0)
I0816 16:43:44.603276 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 16:43:44.603363 20404 solver.cpp:404]     Test net output #1: loss = 0.671489 (* 1 = 0.671489 loss)
I0816 16:43:48.066165 20404 solver.cpp:228] Iteration 520, loss = 0.820479
I0816 16:43:48.066215 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:43:48.066228 20404 solver.cpp:244]     Train net output #1: loss = 0.820479 (* 1 = 0.820479 loss)
I0816 16:43:48.066239 20404 sgd_solver.cpp:106] Iteration 520, lr = 0.000962694
I0816 16:44:22.858595 20404 solver.cpp:228] Iteration 530, loss = 0.820192
I0816 16:44:22.858777 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:44:22.858791 20404 solver.cpp:244]     Train net output #1: loss = 0.820192 (* 1 = 0.820192 loss)
I0816 16:44:22.858804 20404 sgd_solver.cpp:106] Iteration 530, lr = 0.000962008
I0816 16:44:57.670996 20404 solver.cpp:228] Iteration 540, loss = 0.820276
I0816 16:44:57.671175 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:44:57.671190 20404 solver.cpp:244]     Train net output #1: loss = 0.820276 (* 1 = 0.820276 loss)
I0816 16:44:57.671203 20404 sgd_solver.cpp:106] Iteration 540, lr = 0.000961324
I0816 16:45:32.472648 20404 solver.cpp:228] Iteration 550, loss = 0.822025
I0816 16:45:32.472754 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:45:32.472769 20404 solver.cpp:244]     Train net output #1: loss = 0.822025 (* 1 = 0.822025 loss)
I0816 16:45:32.472781 20404 sgd_solver.cpp:106] Iteration 550, lr = 0.00096064
I0816 16:46:03.812188 20404 solver.cpp:337] Iteration 560, Testing net (#0)
I0816 16:46:38.358764 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 16:46:38.358929 20404 solver.cpp:404]     Test net output #1: loss = 0.670366 (* 1 = 0.670366 loss)
I0816 16:46:41.823271 20404 solver.cpp:228] Iteration 560, loss = 0.821341
I0816 16:46:41.823325 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:46:41.823339 20404 solver.cpp:244]     Train net output #1: loss = 0.821341 (* 1 = 0.821341 loss)
I0816 16:46:41.823350 20404 sgd_solver.cpp:106] Iteration 560, lr = 0.000959958
I0816 16:47:16.615741 20404 solver.cpp:228] Iteration 570, loss = 0.821434
I0816 16:47:16.615926 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:47:16.615944 20404 solver.cpp:244]     Train net output #1: loss = 0.821434 (* 1 = 0.821434 loss)
I0816 16:47:16.615958 20404 sgd_solver.cpp:106] Iteration 570, lr = 0.000959276
I0816 16:47:51.411240 20404 solver.cpp:228] Iteration 580, loss = 0.821804
I0816 16:47:51.411428 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:47:51.411448 20404 solver.cpp:244]     Train net output #1: loss = 0.821804 (* 1 = 0.821804 loss)
I0816 16:47:51.411463 20404 sgd_solver.cpp:106] Iteration 580, lr = 0.000958596
I0816 16:48:26.188019 20404 solver.cpp:228] Iteration 590, loss = 0.822267
I0816 16:48:26.188241 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:48:26.188256 20404 solver.cpp:244]     Train net output #1: loss = 0.822267 (* 1 = 0.822267 loss)
I0816 16:48:26.188268 20404 sgd_solver.cpp:106] Iteration 590, lr = 0.000957917
I0816 16:48:57.523392 20404 solver.cpp:337] Iteration 600, Testing net (#0)
I0816 16:49:32.100344 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 16:49:32.100527 20404 solver.cpp:404]     Test net output #1: loss = 0.670118 (* 1 = 0.670118 loss)
I0816 16:49:35.564960 20404 solver.cpp:228] Iteration 600, loss = 0.821048
I0816 16:49:35.565004 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:49:35.565022 20404 solver.cpp:244]     Train net output #1: loss = 0.821048 (* 1 = 0.821048 loss)
I0816 16:49:35.565047 20404 sgd_solver.cpp:106] Iteration 600, lr = 0.00095724
I0816 16:50:10.353121 20404 solver.cpp:228] Iteration 610, loss = 0.820479
I0816 16:50:10.353301 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:50:10.353315 20404 solver.cpp:244]     Train net output #1: loss = 0.820479 (* 1 = 0.820479 loss)
I0816 16:50:10.353327 20404 sgd_solver.cpp:106] Iteration 610, lr = 0.000956563
I0816 16:50:45.149562 20404 solver.cpp:228] Iteration 620, loss = 0.82078
I0816 16:50:45.149740 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:50:45.149756 20404 solver.cpp:244]     Train net output #1: loss = 0.82078 (* 1 = 0.82078 loss)
I0816 16:50:45.149768 20404 sgd_solver.cpp:106] Iteration 620, lr = 0.000955887
I0816 16:51:19.938638 20404 solver.cpp:228] Iteration 630, loss = 0.821205
I0816 16:51:19.938825 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:51:19.938840 20404 solver.cpp:244]     Train net output #1: loss = 0.821205 (* 1 = 0.821205 loss)
I0816 16:51:19.938853 20404 sgd_solver.cpp:106] Iteration 630, lr = 0.000955213
I0816 16:51:51.256129 20404 solver.cpp:337] Iteration 640, Testing net (#0)
I0816 16:52:25.818742 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 16:52:25.818918 20404 solver.cpp:404]     Test net output #1: loss = 0.670565 (* 1 = 0.670565 loss)
I0816 16:52:29.284889 20404 solver.cpp:228] Iteration 640, loss = 0.820183
I0816 16:52:29.284940 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:52:29.284955 20404 solver.cpp:244]     Train net output #1: loss = 0.820183 (* 1 = 0.820183 loss)
I0816 16:52:29.284965 20404 sgd_solver.cpp:106] Iteration 640, lr = 0.000954539
I0816 16:53:04.058243 20404 solver.cpp:228] Iteration 650, loss = 0.820615
I0816 16:53:04.058419 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:53:04.058434 20404 solver.cpp:244]     Train net output #1: loss = 0.820615 (* 1 = 0.820615 loss)
I0816 16:53:04.058446 20404 sgd_solver.cpp:106] Iteration 650, lr = 0.000953867
I0816 16:53:38.869812 20404 solver.cpp:228] Iteration 660, loss = 0.821906
I0816 16:53:38.869983 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:53:38.869998 20404 solver.cpp:244]     Train net output #1: loss = 0.821906 (* 1 = 0.821906 loss)
I0816 16:53:38.870010 20404 sgd_solver.cpp:106] Iteration 660, lr = 0.000953196
I0816 16:54:13.686615 20404 solver.cpp:228] Iteration 670, loss = 0.823449
I0816 16:54:13.686796 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:54:13.686810 20404 solver.cpp:244]     Train net output #1: loss = 0.823449 (* 1 = 0.823449 loss)
I0816 16:54:13.686823 20404 sgd_solver.cpp:106] Iteration 670, lr = 0.000952526
I0816 16:54:45.017320 20404 solver.cpp:337] Iteration 680, Testing net (#0)
I0816 16:55:19.567185 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 16:55:19.567360 20404 solver.cpp:404]     Test net output #1: loss = 0.671281 (* 1 = 0.671281 loss)
I0816 16:55:23.031059 20404 solver.cpp:228] Iteration 680, loss = 0.820331
I0816 16:55:23.031110 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:55:23.031122 20404 solver.cpp:244]     Train net output #1: loss = 0.820331 (* 1 = 0.820331 loss)
I0816 16:55:23.031134 20404 sgd_solver.cpp:106] Iteration 680, lr = 0.000951857
I0816 16:55:57.826475 20404 solver.cpp:228] Iteration 690, loss = 0.820138
I0816 16:55:57.826689 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:55:57.826705 20404 solver.cpp:244]     Train net output #1: loss = 0.820138 (* 1 = 0.820138 loss)
I0816 16:55:57.826719 20404 sgd_solver.cpp:106] Iteration 690, lr = 0.000951189
I0816 16:56:32.635735 20404 solver.cpp:228] Iteration 700, loss = 0.820544
I0816 16:56:32.635928 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:56:32.635947 20404 solver.cpp:244]     Train net output #1: loss = 0.820544 (* 1 = 0.820544 loss)
I0816 16:56:32.635962 20404 sgd_solver.cpp:106] Iteration 700, lr = 0.000950522
I0816 16:57:07.434473 20404 solver.cpp:228] Iteration 710, loss = 0.820437
I0816 16:57:07.434659 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:57:07.434674 20404 solver.cpp:244]     Train net output #1: loss = 0.820437 (* 1 = 0.820437 loss)
I0816 16:57:07.434685 20404 sgd_solver.cpp:106] Iteration 710, lr = 0.000949856
I0816 16:57:38.774137 20404 solver.cpp:337] Iteration 720, Testing net (#0)
I0816 16:58:13.340910 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 16:58:13.341091 20404 solver.cpp:404]     Test net output #1: loss = 0.670656 (* 1 = 0.670656 loss)
I0816 16:58:16.797894 20404 solver.cpp:228] Iteration 720, loss = 0.820089
I0816 16:58:16.797937 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:58:16.797963 20404 solver.cpp:244]     Train net output #1: loss = 0.820089 (* 1 = 0.820089 loss)
I0816 16:58:16.797979 20404 sgd_solver.cpp:106] Iteration 720, lr = 0.000949192
I0816 16:58:51.568639 20404 solver.cpp:228] Iteration 730, loss = 0.82022
I0816 16:58:51.568821 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 16:58:51.568841 20404 solver.cpp:244]     Train net output #1: loss = 0.82022 (* 1 = 0.82022 loss)
I0816 16:58:51.568856 20404 sgd_solver.cpp:106] Iteration 730, lr = 0.000948528
I0816 16:59:26.363466 20404 solver.cpp:228] Iteration 740, loss = 0.820389
I0816 16:59:26.363651 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 16:59:26.363669 20404 solver.cpp:244]     Train net output #1: loss = 0.820389 (* 1 = 0.820389 loss)
I0816 16:59:26.363684 20404 sgd_solver.cpp:106] Iteration 740, lr = 0.000947866
I0816 17:00:01.168532 20404 solver.cpp:228] Iteration 750, loss = 0.821797
I0816 17:00:01.168709 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:00:01.168730 20404 solver.cpp:244]     Train net output #1: loss = 0.821797 (* 1 = 0.821797 loss)
I0816 17:00:01.168746 20404 sgd_solver.cpp:106] Iteration 750, lr = 0.000947204
I0816 17:00:32.482730 20404 solver.cpp:337] Iteration 760, Testing net (#0)
I0816 17:01:07.046891 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 17:01:07.046994 20404 solver.cpp:404]     Test net output #1: loss = 0.671632 (* 1 = 0.671632 loss)
I0816 17:01:10.511277 20404 solver.cpp:228] Iteration 760, loss = 0.823002
I0816 17:01:10.511328 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:01:10.511343 20404 solver.cpp:244]     Train net output #1: loss = 0.823002 (* 1 = 0.823002 loss)
I0816 17:01:10.511354 20404 sgd_solver.cpp:106] Iteration 760, lr = 0.000946544
I0816 17:01:45.321169 20404 solver.cpp:228] Iteration 770, loss = 0.822999
I0816 17:01:45.321354 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:01:45.321370 20404 solver.cpp:244]     Train net output #1: loss = 0.822999 (* 1 = 0.822999 loss)
I0816 17:01:45.321383 20404 sgd_solver.cpp:106] Iteration 770, lr = 0.000945885
I0816 17:02:20.124207 20404 solver.cpp:228] Iteration 780, loss = 0.822569
I0816 17:02:20.124388 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:02:20.124405 20404 solver.cpp:244]     Train net output #1: loss = 0.822569 (* 1 = 0.822569 loss)
I0816 17:02:20.124418 20404 sgd_solver.cpp:106] Iteration 780, lr = 0.000945227
I0816 17:02:54.917950 20404 solver.cpp:228] Iteration 790, loss = 0.821998
I0816 17:02:54.918179 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:02:54.918197 20404 solver.cpp:244]     Train net output #1: loss = 0.821998 (* 1 = 0.821998 loss)
I0816 17:02:54.918228 20404 sgd_solver.cpp:106] Iteration 790, lr = 0.00094457
I0816 17:03:26.243041 20404 solver.cpp:337] Iteration 800, Testing net (#0)
I0816 17:04:00.788136 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 17:04:00.788305 20404 solver.cpp:404]     Test net output #1: loss = 0.670279 (* 1 = 0.670279 loss)
I0816 17:04:04.249274 20404 solver.cpp:228] Iteration 800, loss = 0.820598
I0816 17:04:04.249322 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:04:04.249336 20404 solver.cpp:244]     Train net output #1: loss = 0.820598 (* 1 = 0.820598 loss)
I0816 17:04:04.249348 20404 sgd_solver.cpp:106] Iteration 800, lr = 0.000943913
I0816 17:04:39.571401 20404 solver.cpp:228] Iteration 810, loss = 0.821178
I0816 17:04:39.571588 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:04:39.571604 20404 solver.cpp:244]     Train net output #1: loss = 0.821178 (* 1 = 0.821178 loss)
I0816 17:04:39.571615 20404 sgd_solver.cpp:106] Iteration 810, lr = 0.000943259
I0816 17:05:14.457710 20404 solver.cpp:228] Iteration 820, loss = 0.82323
I0816 17:05:14.457875 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:05:14.457895 20404 solver.cpp:244]     Train net output #1: loss = 0.82323 (* 1 = 0.82323 loss)
I0816 17:05:14.457908 20404 sgd_solver.cpp:106] Iteration 820, lr = 0.000942605
I0816 17:05:49.346696 20404 solver.cpp:228] Iteration 830, loss = 0.820795
I0816 17:05:49.346875 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:05:49.346895 20404 solver.cpp:244]     Train net output #1: loss = 0.820795 (* 1 = 0.820795 loss)
I0816 17:05:49.346910 20404 sgd_solver.cpp:106] Iteration 830, lr = 0.000941952
I0816 17:06:20.760774 20404 solver.cpp:337] Iteration 840, Testing net (#0)
I0816 17:06:55.385468 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 17:06:55.385644 20404 solver.cpp:404]     Test net output #1: loss = 0.670297 (* 1 = 0.670297 loss)
I0816 17:06:58.860642 20404 solver.cpp:228] Iteration 840, loss = 0.821344
I0816 17:06:58.860693 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:06:58.860707 20404 solver.cpp:244]     Train net output #1: loss = 0.821344 (* 1 = 0.821344 loss)
I0816 17:06:58.860718 20404 sgd_solver.cpp:106] Iteration 840, lr = 0.0009413
I0816 17:07:33.737947 20404 solver.cpp:228] Iteration 850, loss = 0.821903
I0816 17:07:33.738126 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:07:33.738140 20404 solver.cpp:244]     Train net output #1: loss = 0.821903 (* 1 = 0.821903 loss)
I0816 17:07:33.738152 20404 sgd_solver.cpp:106] Iteration 850, lr = 0.000940649
I0816 17:08:08.644873 20404 solver.cpp:228] Iteration 860, loss = 0.823151
I0816 17:08:08.644984 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:08:08.645004 20404 solver.cpp:244]     Train net output #1: loss = 0.823151 (* 1 = 0.823151 loss)
I0816 17:08:08.645017 20404 sgd_solver.cpp:106] Iteration 860, lr = 0.00094
I0816 17:08:43.551666 20404 solver.cpp:228] Iteration 870, loss = 0.821095
I0816 17:08:43.551750 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:08:43.551769 20404 solver.cpp:244]     Train net output #1: loss = 0.821095 (* 1 = 0.821095 loss)
I0816 17:08:43.551792 20404 sgd_solver.cpp:106] Iteration 870, lr = 0.000939351
I0816 17:09:14.961179 20404 solver.cpp:337] Iteration 880, Testing net (#0)
I0816 17:09:49.595610 20404 solver.cpp:404]     Test net output #0: accuracy = 0.936
I0816 17:09:49.595789 20404 solver.cpp:404]     Test net output #1: loss = 0.670041 (* 1 = 0.670041 loss)
I0816 17:09:53.068238 20404 solver.cpp:228] Iteration 880, loss = 0.820941
I0816 17:09:53.068289 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:09:53.068302 20404 solver.cpp:244]     Train net output #1: loss = 0.820941 (* 1 = 0.820941 loss)
I0816 17:09:53.068315 20404 sgd_solver.cpp:106] Iteration 880, lr = 0.000938703
I0816 17:10:27.955742 20404 solver.cpp:228] Iteration 890, loss = 0.820357
I0816 17:10:27.955955 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:10:27.955973 20404 solver.cpp:244]     Train net output #1: loss = 0.820357 (* 1 = 0.820357 loss)
I0816 17:10:27.955987 20404 sgd_solver.cpp:106] Iteration 890, lr = 0.000938057
I0816 17:11:02.846961 20404 solver.cpp:228] Iteration 900, loss = 0.820263
I0816 17:11:02.847141 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:11:02.847162 20404 solver.cpp:244]     Train net output #1: loss = 0.820263 (* 1 = 0.820263 loss)
I0816 17:11:02.847177 20404 sgd_solver.cpp:106] Iteration 900, lr = 0.000937411
I0816 17:11:37.712590 20404 solver.cpp:228] Iteration 910, loss = 0.82154
I0816 17:11:37.712765 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:11:37.712780 20404 solver.cpp:244]     Train net output #1: loss = 0.82154 (* 1 = 0.82154 loss)
I0816 17:11:37.712792 20404 sgd_solver.cpp:106] Iteration 910, lr = 0.000936767
I0816 17:12:09.124739 20404 solver.cpp:337] Iteration 920, Testing net (#0)
I0816 17:12:43.777245 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 17:12:43.777410 20404 solver.cpp:404]     Test net output #1: loss = 0.670695 (* 1 = 0.670695 loss)
I0816 17:12:47.251152 20404 solver.cpp:228] Iteration 920, loss = 0.821826
I0816 17:12:47.251199 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:12:47.251212 20404 solver.cpp:244]     Train net output #1: loss = 0.821826 (* 1 = 0.821826 loss)
I0816 17:12:47.251224 20404 sgd_solver.cpp:106] Iteration 920, lr = 0.000936123
I0816 17:13:22.133137 20404 solver.cpp:228] Iteration 930, loss = 0.820053
I0816 17:13:22.133257 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0816 17:13:22.133272 20404 solver.cpp:244]     Train net output #1: loss = 0.820053 (* 1 = 0.820053 loss)
I0816 17:13:22.133285 20404 sgd_solver.cpp:106] Iteration 930, lr = 0.000935481
I0816 17:13:57.049276 20404 solver.cpp:228] Iteration 940, loss = 0.820222
I0816 17:13:57.049456 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:13:57.049471 20404 solver.cpp:244]     Train net output #1: loss = 0.820222 (* 1 = 0.820222 loss)
I0816 17:13:57.049484 20404 sgd_solver.cpp:106] Iteration 940, lr = 0.000934839
I0816 17:14:31.949661 20404 solver.cpp:228] Iteration 950, loss = 0.820116
I0816 17:14:31.949827 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:14:31.949843 20404 solver.cpp:244]     Train net output #1: loss = 0.820116 (* 1 = 0.820116 loss)
I0816 17:14:31.949856 20404 sgd_solver.cpp:106] Iteration 950, lr = 0.000934199
I0816 17:15:03.374816 20404 solver.cpp:337] Iteration 960, Testing net (#0)
I0816 17:15:37.999241 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 17:15:37.999430 20404 solver.cpp:404]     Test net output #1: loss = 0.670781 (* 1 = 0.670781 loss)
I0816 17:15:41.478828 20404 solver.cpp:228] Iteration 960, loss = 0.820044
I0816 17:15:41.478878 20404 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0816 17:15:41.478893 20404 solver.cpp:244]     Train net output #1: loss = 0.820044 (* 1 = 0.820044 loss)
I0816 17:15:41.478904 20404 sgd_solver.cpp:106] Iteration 960, lr = 0.00093356
I0816 17:16:16.350066 20404 solver.cpp:228] Iteration 970, loss = 0.821468
I0816 17:16:16.350255 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:16:16.350275 20404 solver.cpp:244]     Train net output #1: loss = 0.821468 (* 1 = 0.821468 loss)
I0816 17:16:16.350289 20404 sgd_solver.cpp:106] Iteration 970, lr = 0.000932921
I0816 17:16:51.234743 20404 solver.cpp:228] Iteration 980, loss = 0.820477
I0816 17:16:51.234915 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:16:51.234930 20404 solver.cpp:244]     Train net output #1: loss = 0.820477 (* 1 = 0.820477 loss)
I0816 17:16:51.234942 20404 sgd_solver.cpp:106] Iteration 980, lr = 0.000932284
I0816 17:17:26.121146 20404 solver.cpp:228] Iteration 990, loss = 0.820435
I0816 17:17:26.121361 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:17:26.121377 20404 solver.cpp:244]     Train net output #1: loss = 0.820435 (* 1 = 0.820435 loss)
I0816 17:17:26.121389 20404 sgd_solver.cpp:106] Iteration 990, lr = 0.000931648
I0816 17:17:57.515818 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_1000.caffemodel
I0816 17:18:30.186053 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_1000.solverstate
I0816 17:18:31.828136 20404 solver.cpp:337] Iteration 1000, Testing net (#0)
I0816 17:19:06.465648 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 17:19:06.465819 20404 solver.cpp:404]     Test net output #1: loss = 0.671734 (* 1 = 0.671734 loss)
I0816 17:19:09.937404 20404 solver.cpp:228] Iteration 1000, loss = 0.820566
I0816 17:19:09.937454 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:19:09.937469 20404 solver.cpp:244]     Train net output #1: loss = 0.820566 (* 1 = 0.820566 loss)
I0816 17:19:09.937480 20404 sgd_solver.cpp:106] Iteration 1000, lr = 0.000931013
I0816 17:19:44.815652 20404 solver.cpp:228] Iteration 1010, loss = 0.821225
I0816 17:19:44.815820 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:19:44.815835 20404 solver.cpp:244]     Train net output #1: loss = 0.821225 (* 1 = 0.821225 loss)
I0816 17:19:44.815847 20404 sgd_solver.cpp:106] Iteration 1010, lr = 0.000930378
I0816 17:20:19.706429 20404 solver.cpp:228] Iteration 1020, loss = 0.820184
I0816 17:20:19.706609 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:20:19.706624 20404 solver.cpp:244]     Train net output #1: loss = 0.820184 (* 1 = 0.820184 loss)
I0816 17:20:19.706637 20404 sgd_solver.cpp:106] Iteration 1020, lr = 0.000929745
I0816 17:20:54.580458 20404 solver.cpp:228] Iteration 1030, loss = 0.821075
I0816 17:20:54.580636 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:20:54.580651 20404 solver.cpp:244]     Train net output #1: loss = 0.821075 (* 1 = 0.821075 loss)
I0816 17:20:54.580663 20404 sgd_solver.cpp:106] Iteration 1030, lr = 0.000929113
I0816 17:21:26.001781 20404 solver.cpp:337] Iteration 1040, Testing net (#0)
I0816 17:22:00.635854 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 17:22:00.636018 20404 solver.cpp:404]     Test net output #1: loss = 0.670233 (* 1 = 0.670233 loss)
I0816 17:22:04.112076 20404 solver.cpp:228] Iteration 1040, loss = 0.820682
I0816 17:22:04.112126 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:22:04.112140 20404 solver.cpp:244]     Train net output #1: loss = 0.820682 (* 1 = 0.820682 loss)
I0816 17:22:04.112152 20404 sgd_solver.cpp:106] Iteration 1040, lr = 0.000928481
I0816 17:22:39.003587 20404 solver.cpp:228] Iteration 1050, loss = 0.821207
I0816 17:22:39.003767 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:22:39.003785 20404 solver.cpp:244]     Train net output #1: loss = 0.821207 (* 1 = 0.821207 loss)
I0816 17:22:39.003798 20404 sgd_solver.cpp:106] Iteration 1050, lr = 0.000927851
I0816 17:23:13.918005 20404 solver.cpp:228] Iteration 1060, loss = 0.823256
I0816 17:23:13.918100 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:23:13.918115 20404 solver.cpp:244]     Train net output #1: loss = 0.823256 (* 1 = 0.823256 loss)
I0816 17:23:13.918128 20404 sgd_solver.cpp:106] Iteration 1060, lr = 0.000927222
I0816 17:23:48.790185 20404 solver.cpp:228] Iteration 1070, loss = 0.820891
I0816 17:23:48.790370 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:23:48.790385 20404 solver.cpp:244]     Train net output #1: loss = 0.820891 (* 1 = 0.820891 loss)
I0816 17:23:48.790398 20404 sgd_solver.cpp:106] Iteration 1070, lr = 0.000926594
I0816 17:24:20.187672 20404 solver.cpp:337] Iteration 1080, Testing net (#0)
I0816 17:24:54.841207 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 17:24:54.841387 20404 solver.cpp:404]     Test net output #1: loss = 0.670355 (* 1 = 0.670355 loss)
I0816 17:24:58.322764 20404 solver.cpp:228] Iteration 1080, loss = 0.821437
I0816 17:24:58.322814 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:24:58.322829 20404 solver.cpp:244]     Train net output #1: loss = 0.821437 (* 1 = 0.821437 loss)
I0816 17:24:58.322839 20404 sgd_solver.cpp:106] Iteration 1080, lr = 0.000925966
I0816 17:25:33.230684 20404 solver.cpp:228] Iteration 1090, loss = 0.820565
I0816 17:25:33.230859 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:25:33.230875 20404 solver.cpp:244]     Train net output #1: loss = 0.820565 (* 1 = 0.820565 loss)
I0816 17:25:33.230887 20404 sgd_solver.cpp:106] Iteration 1090, lr = 0.00092534
I0816 17:26:08.120121 20404 solver.cpp:228] Iteration 1100, loss = 0.820278
I0816 17:26:08.120292 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:26:08.120307 20404 solver.cpp:244]     Train net output #1: loss = 0.820278 (* 1 = 0.820278 loss)
I0816 17:26:08.120319 20404 sgd_solver.cpp:106] Iteration 1100, lr = 0.000924715
I0816 17:26:42.989727 20404 solver.cpp:228] Iteration 1110, loss = 0.820236
I0816 17:26:42.989899 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:26:42.989914 20404 solver.cpp:244]     Train net output #1: loss = 0.820236 (* 1 = 0.820236 loss)
I0816 17:26:42.989926 20404 sgd_solver.cpp:106] Iteration 1110, lr = 0.00092409
I0816 17:27:14.383709 20404 solver.cpp:337] Iteration 1120, Testing net (#0)
I0816 17:27:49.029001 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 17:27:49.029186 20404 solver.cpp:404]     Test net output #1: loss = 0.670779 (* 1 = 0.670779 loss)
I0816 17:27:52.512826 20404 solver.cpp:228] Iteration 1120, loss = 0.821981
I0816 17:27:52.512871 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:27:52.512887 20404 solver.cpp:244]     Train net output #1: loss = 0.821981 (* 1 = 0.821981 loss)
I0816 17:27:52.512902 20404 sgd_solver.cpp:106] Iteration 1120, lr = 0.000923467
I0816 17:28:27.389080 20404 solver.cpp:228] Iteration 1130, loss = 0.82135
I0816 17:28:27.389259 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:28:27.389277 20404 solver.cpp:244]     Train net output #1: loss = 0.82135 (* 1 = 0.82135 loss)
I0816 17:28:27.389292 20404 sgd_solver.cpp:106] Iteration 1130, lr = 0.000922845
I0816 17:29:02.300343 20404 solver.cpp:228] Iteration 1140, loss = 0.821452
I0816 17:29:02.300534 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:29:02.300551 20404 solver.cpp:244]     Train net output #1: loss = 0.821452 (* 1 = 0.821452 loss)
I0816 17:29:02.300567 20404 sgd_solver.cpp:106] Iteration 1140, lr = 0.000922223
I0816 17:29:37.195181 20404 solver.cpp:228] Iteration 1150, loss = 0.821808
I0816 17:29:37.195369 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:29:37.195385 20404 solver.cpp:244]     Train net output #1: loss = 0.821808 (* 1 = 0.821808 loss)
I0816 17:29:37.195397 20404 sgd_solver.cpp:106] Iteration 1150, lr = 0.000921603
I0816 17:30:08.628298 20404 solver.cpp:337] Iteration 1160, Testing net (#0)
I0816 17:30:43.264660 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 17:30:43.264840 20404 solver.cpp:404]     Test net output #1: loss = 0.670496 (* 1 = 0.670496 loss)
I0816 17:30:46.734575 20404 solver.cpp:228] Iteration 1160, loss = 0.821646
I0816 17:30:46.734627 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:30:46.734640 20404 solver.cpp:244]     Train net output #1: loss = 0.821646 (* 1 = 0.821646 loss)
I0816 17:30:46.734652 20404 sgd_solver.cpp:106] Iteration 1160, lr = 0.000920984
I0816 17:31:21.598300 20404 solver.cpp:228] Iteration 1170, loss = 0.821268
I0816 17:31:21.598533 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:31:21.598549 20404 solver.cpp:244]     Train net output #1: loss = 0.821268 (* 1 = 0.821268 loss)
I0816 17:31:21.598562 20404 sgd_solver.cpp:106] Iteration 1170, lr = 0.000920365
I0816 17:31:56.490479 20404 solver.cpp:228] Iteration 1180, loss = 0.822248
I0816 17:31:56.490674 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:31:56.490689 20404 solver.cpp:244]     Train net output #1: loss = 0.822248 (* 1 = 0.822248 loss)
I0816 17:31:56.490700 20404 sgd_solver.cpp:106] Iteration 1180, lr = 0.000919748
I0816 17:32:31.369936 20404 solver.cpp:228] Iteration 1190, loss = 0.821096
I0816 17:32:31.370029 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:32:31.370044 20404 solver.cpp:244]     Train net output #1: loss = 0.821096 (* 1 = 0.821096 loss)
I0816 17:32:31.370056 20404 sgd_solver.cpp:106] Iteration 1190, lr = 0.000919131
I0816 17:33:02.795302 20404 solver.cpp:337] Iteration 1200, Testing net (#0)
I0816 17:33:37.437927 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 17:33:37.438105 20404 solver.cpp:404]     Test net output #1: loss = 0.671149 (* 1 = 0.671149 loss)
I0816 17:33:40.917711 20404 solver.cpp:228] Iteration 1200, loss = 0.820214
I0816 17:33:40.917763 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:33:40.917778 20404 solver.cpp:244]     Train net output #1: loss = 0.820214 (* 1 = 0.820214 loss)
I0816 17:33:40.917789 20404 sgd_solver.cpp:106] Iteration 1200, lr = 0.000918516
I0816 17:34:15.808406 20404 solver.cpp:228] Iteration 1210, loss = 0.821832
I0816 17:34:15.808583 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:34:15.808600 20404 solver.cpp:244]     Train net output #1: loss = 0.821832 (* 1 = 0.821832 loss)
I0816 17:34:15.808612 20404 sgd_solver.cpp:106] Iteration 1210, lr = 0.000917901
I0816 17:34:50.685925 20404 solver.cpp:228] Iteration 1220, loss = 0.820084
I0816 17:34:50.686028 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:34:50.686043 20404 solver.cpp:244]     Train net output #1: loss = 0.820084 (* 1 = 0.820084 loss)
I0816 17:34:50.686055 20404 sgd_solver.cpp:106] Iteration 1220, lr = 0.000917287
I0816 17:35:25.581138 20404 solver.cpp:228] Iteration 1230, loss = 0.820314
I0816 17:35:25.581312 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:35:25.581327 20404 solver.cpp:244]     Train net output #1: loss = 0.820314 (* 1 = 0.820314 loss)
I0816 17:35:25.581339 20404 sgd_solver.cpp:106] Iteration 1230, lr = 0.000916675
I0816 17:35:56.993983 20404 solver.cpp:337] Iteration 1240, Testing net (#0)
I0816 17:36:31.620947 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 17:36:31.621115 20404 solver.cpp:404]     Test net output #1: loss = 0.670703 (* 1 = 0.670703 loss)
I0816 17:36:35.097244 20404 solver.cpp:228] Iteration 1240, loss = 0.821923
I0816 17:36:35.097296 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:36:35.097311 20404 solver.cpp:244]     Train net output #1: loss = 0.821923 (* 1 = 0.821923 loss)
I0816 17:36:35.097322 20404 sgd_solver.cpp:106] Iteration 1240, lr = 0.000916063
I0816 17:37:09.998037 20404 solver.cpp:228] Iteration 1250, loss = 0.821351
I0816 17:37:09.998220 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:37:09.998234 20404 solver.cpp:244]     Train net output #1: loss = 0.821351 (* 1 = 0.821351 loss)
I0816 17:37:09.998246 20404 sgd_solver.cpp:106] Iteration 1250, lr = 0.000915452
I0816 17:37:44.892462 20404 solver.cpp:228] Iteration 1260, loss = 0.821471
I0816 17:37:44.892644 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:37:44.892658 20404 solver.cpp:244]     Train net output #1: loss = 0.821471 (* 1 = 0.821471 loss)
I0816 17:37:44.892671 20404 sgd_solver.cpp:106] Iteration 1260, lr = 0.000914842
I0816 17:38:19.787024 20404 solver.cpp:228] Iteration 1270, loss = 0.821829
I0816 17:38:19.787201 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:38:19.787215 20404 solver.cpp:244]     Train net output #1: loss = 0.821829 (* 1 = 0.821829 loss)
I0816 17:38:19.787228 20404 sgd_solver.cpp:106] Iteration 1270, lr = 0.000914233
I0816 17:38:51.205474 20404 solver.cpp:337] Iteration 1280, Testing net (#0)
I0816 17:39:25.853960 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 17:39:25.854145 20404 solver.cpp:404]     Test net output #1: loss = 0.670211 (* 1 = 0.670211 loss)
I0816 17:39:29.328090 20404 solver.cpp:228] Iteration 1280, loss = 0.820785
I0816 17:39:29.328141 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:39:29.328155 20404 solver.cpp:244]     Train net output #1: loss = 0.820785 (* 1 = 0.820785 loss)
I0816 17:39:29.328166 20404 sgd_solver.cpp:106] Iteration 1280, lr = 0.000913625
I0816 17:40:04.210850 20404 solver.cpp:228] Iteration 1290, loss = 0.820331
I0816 17:40:04.210947 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:40:04.210960 20404 solver.cpp:244]     Train net output #1: loss = 0.820331 (* 1 = 0.820331 loss)
I0816 17:40:04.210971 20404 sgd_solver.cpp:106] Iteration 1290, lr = 0.000913018
I0816 17:40:39.098362 20404 solver.cpp:228] Iteration 1300, loss = 0.820632
I0816 17:40:39.098536 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:40:39.098551 20404 solver.cpp:244]     Train net output #1: loss = 0.820632 (* 1 = 0.820632 loss)
I0816 17:40:39.098563 20404 sgd_solver.cpp:106] Iteration 1300, lr = 0.000912412
I0816 17:41:13.959779 20404 solver.cpp:228] Iteration 1310, loss = 0.820056
I0816 17:41:13.959955 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0816 17:41:13.959970 20404 solver.cpp:244]     Train net output #1: loss = 0.820056 (* 1 = 0.820056 loss)
I0816 17:41:13.959982 20404 sgd_solver.cpp:106] Iteration 1310, lr = 0.000911807
I0816 17:41:45.398869 20404 solver.cpp:337] Iteration 1320, Testing net (#0)
I0816 17:42:20.059788 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 17:42:20.059965 20404 solver.cpp:404]     Test net output #1: loss = 0.671105 (* 1 = 0.671105 loss)
I0816 17:42:23.537969 20404 solver.cpp:228] Iteration 1320, loss = 0.820165
I0816 17:42:23.538012 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:42:23.538038 20404 solver.cpp:244]     Train net output #1: loss = 0.820165 (* 1 = 0.820165 loss)
I0816 17:42:23.538051 20404 sgd_solver.cpp:106] Iteration 1320, lr = 0.000911203
I0816 17:42:58.392810 20404 solver.cpp:228] Iteration 1330, loss = 0.821584
I0816 17:42:58.392990 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:42:58.393007 20404 solver.cpp:244]     Train net output #1: loss = 0.821584 (* 1 = 0.821584 loss)
I0816 17:42:58.393018 20404 sgd_solver.cpp:106] Iteration 1330, lr = 0.0009106
I0816 17:43:33.283054 20404 solver.cpp:228] Iteration 1340, loss = 0.820236
I0816 17:43:33.283224 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:43:33.283239 20404 solver.cpp:244]     Train net output #1: loss = 0.820236 (* 1 = 0.820236 loss)
I0816 17:43:33.283252 20404 sgd_solver.cpp:106] Iteration 1340, lr = 0.000909997
I0816 17:44:08.169760 20404 solver.cpp:228] Iteration 1350, loss = 0.821712
I0816 17:44:08.169931 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:44:08.169947 20404 solver.cpp:244]     Train net output #1: loss = 0.821712 (* 1 = 0.821712 loss)
I0816 17:44:08.169960 20404 sgd_solver.cpp:106] Iteration 1350, lr = 0.000909396
I0816 17:44:39.563478 20404 solver.cpp:337] Iteration 1360, Testing net (#0)
I0816 17:45:14.194417 20404 solver.cpp:404]     Test net output #0: accuracy = 0.961
I0816 17:45:14.194581 20404 solver.cpp:404]     Test net output #1: loss = 0.670048 (* 1 = 0.670048 loss)
I0816 17:45:17.675812 20404 solver.cpp:228] Iteration 1360, loss = 0.821016
I0816 17:45:17.675861 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:45:17.675875 20404 solver.cpp:244]     Train net output #1: loss = 0.821016 (* 1 = 0.821016 loss)
I0816 17:45:17.675887 20404 sgd_solver.cpp:106] Iteration 1360, lr = 0.000908796
I0816 17:45:52.544750 20404 solver.cpp:228] Iteration 1370, loss = 0.821093
I0816 17:45:52.544966 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:45:52.544982 20404 solver.cpp:244]     Train net output #1: loss = 0.821093 (* 1 = 0.821093 loss)
I0816 17:45:52.544996 20404 sgd_solver.cpp:106] Iteration 1370, lr = 0.000908196
I0816 17:46:27.448689 20404 solver.cpp:228] Iteration 1380, loss = 0.821437
I0816 17:46:27.448871 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:46:27.448886 20404 solver.cpp:244]     Train net output #1: loss = 0.821437 (* 1 = 0.821437 loss)
I0816 17:46:27.448899 20404 sgd_solver.cpp:106] Iteration 1380, lr = 0.000907598
I0816 17:47:02.354853 20404 solver.cpp:228] Iteration 1390, loss = 0.821873
I0816 17:47:02.355031 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:47:02.355046 20404 solver.cpp:244]     Train net output #1: loss = 0.821873 (* 1 = 0.821873 loss)
I0816 17:47:02.355057 20404 sgd_solver.cpp:106] Iteration 1390, lr = 0.000907
I0816 17:47:33.746425 20404 solver.cpp:337] Iteration 1400, Testing net (#0)
I0816 17:48:08.406565 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 17:48:08.406743 20404 solver.cpp:404]     Test net output #1: loss = 0.670259 (* 1 = 0.670259 loss)
I0816 17:48:11.881857 20404 solver.cpp:228] Iteration 1400, loss = 0.820757
I0816 17:48:11.881916 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:48:11.881932 20404 solver.cpp:244]     Train net output #1: loss = 0.820757 (* 1 = 0.820757 loss)
I0816 17:48:11.881943 20404 sgd_solver.cpp:106] Iteration 1400, lr = 0.000906403
I0816 17:48:46.754112 20404 solver.cpp:228] Iteration 1410, loss = 0.820244
I0816 17:48:46.754214 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:48:46.754233 20404 solver.cpp:244]     Train net output #1: loss = 0.820244 (* 1 = 0.820244 loss)
I0816 17:48:46.754248 20404 sgd_solver.cpp:106] Iteration 1410, lr = 0.000905807
I0816 17:49:21.645902 20404 solver.cpp:228] Iteration 1420, loss = 0.820769
I0816 17:49:21.646081 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:49:21.646096 20404 solver.cpp:244]     Train net output #1: loss = 0.820769 (* 1 = 0.820769 loss)
I0816 17:49:21.646108 20404 sgd_solver.cpp:106] Iteration 1420, lr = 0.000905212
I0816 17:49:56.538997 20404 solver.cpp:228] Iteration 1430, loss = 0.821104
I0816 17:49:56.539180 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:49:56.539194 20404 solver.cpp:244]     Train net output #1: loss = 0.821104 (* 1 = 0.821104 loss)
I0816 17:49:56.539206 20404 sgd_solver.cpp:106] Iteration 1430, lr = 0.000904618
I0816 17:50:27.953616 20404 solver.cpp:337] Iteration 1440, Testing net (#0)
I0816 17:51:02.594552 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 17:51:02.594722 20404 solver.cpp:404]     Test net output #1: loss = 0.670711 (* 1 = 0.670711 loss)
I0816 17:51:06.071436 20404 solver.cpp:228] Iteration 1440, loss = 0.820191
I0816 17:51:06.071487 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:51:06.071501 20404 solver.cpp:244]     Train net output #1: loss = 0.820191 (* 1 = 0.820191 loss)
I0816 17:51:06.071513 20404 sgd_solver.cpp:106] Iteration 1440, lr = 0.000904025
I0816 17:51:40.961582 20404 solver.cpp:228] Iteration 1450, loss = 0.820852
I0816 17:51:40.961752 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:51:40.961766 20404 solver.cpp:244]     Train net output #1: loss = 0.820852 (* 1 = 0.820852 loss)
I0816 17:51:40.961778 20404 sgd_solver.cpp:106] Iteration 1450, lr = 0.000903433
I0816 17:52:15.846572 20404 solver.cpp:228] Iteration 1460, loss = 0.821777
I0816 17:52:15.846679 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:52:15.846694 20404 solver.cpp:244]     Train net output #1: loss = 0.821777 (* 1 = 0.821777 loss)
I0816 17:52:15.846706 20404 sgd_solver.cpp:106] Iteration 1460, lr = 0.000902842
I0816 17:52:50.729452 20404 solver.cpp:228] Iteration 1470, loss = 0.820151
I0816 17:52:50.729636 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:52:50.729651 20404 solver.cpp:244]     Train net output #1: loss = 0.820151 (* 1 = 0.820151 loss)
I0816 17:52:50.729663 20404 sgd_solver.cpp:106] Iteration 1470, lr = 0.000902251
I0816 17:53:22.145028 20404 solver.cpp:337] Iteration 1480, Testing net (#0)
I0816 17:53:56.782740 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 17:53:56.782929 20404 solver.cpp:404]     Test net output #1: loss = 0.6706 (* 1 = 0.6706 loss)
I0816 17:54:00.262151 20404 solver.cpp:228] Iteration 1480, loss = 0.821871
I0816 17:54:00.262192 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:54:00.262218 20404 solver.cpp:244]     Train net output #1: loss = 0.821871 (* 1 = 0.821871 loss)
I0816 17:54:00.262233 20404 sgd_solver.cpp:106] Iteration 1480, lr = 0.000901662
I0816 17:54:35.111568 20404 solver.cpp:228] Iteration 1490, loss = 0.821183
I0816 17:54:35.111744 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:54:35.111763 20404 solver.cpp:244]     Train net output #1: loss = 0.821183 (* 1 = 0.821183 loss)
I0816 17:54:35.111778 20404 sgd_solver.cpp:106] Iteration 1490, lr = 0.000901073
I0816 17:55:10.001888 20404 solver.cpp:228] Iteration 1500, loss = 0.821193
I0816 17:55:10.002081 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:55:10.002100 20404 solver.cpp:244]     Train net output #1: loss = 0.821193 (* 1 = 0.821193 loss)
I0816 17:55:10.002116 20404 sgd_solver.cpp:106] Iteration 1500, lr = 0.000900485
I0816 17:55:44.888370 20404 solver.cpp:228] Iteration 1510, loss = 0.821514
I0816 17:55:44.888476 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:55:44.888491 20404 solver.cpp:244]     Train net output #1: loss = 0.821514 (* 1 = 0.821514 loss)
I0816 17:55:44.888502 20404 sgd_solver.cpp:106] Iteration 1510, lr = 0.000899898
I0816 17:56:16.295809 20404 solver.cpp:337] Iteration 1520, Testing net (#0)
I0816 17:56:50.921504 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 17:56:50.921684 20404 solver.cpp:404]     Test net output #1: loss = 0.670669 (* 1 = 0.670669 loss)
I0816 17:56:54.402093 20404 solver.cpp:228] Iteration 1520, loss = 0.821945
I0816 17:56:54.402144 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:56:54.402158 20404 solver.cpp:244]     Train net output #1: loss = 0.821945 (* 1 = 0.821945 loss)
I0816 17:56:54.402169 20404 sgd_solver.cpp:106] Iteration 1520, lr = 0.000899313
I0816 17:57:29.268004 20404 solver.cpp:228] Iteration 1530, loss = 0.82083
I0816 17:57:29.268185 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:57:29.268200 20404 solver.cpp:244]     Train net output #1: loss = 0.82083 (* 1 = 0.82083 loss)
I0816 17:57:29.268213 20404 sgd_solver.cpp:106] Iteration 1530, lr = 0.000898728
I0816 17:58:04.165990 20404 solver.cpp:228] Iteration 1540, loss = 0.820314
I0816 17:58:04.166167 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:58:04.166182 20404 solver.cpp:244]     Train net output #1: loss = 0.820314 (* 1 = 0.820314 loss)
I0816 17:58:04.166194 20404 sgd_solver.cpp:106] Iteration 1540, lr = 0.000898143
I0816 17:58:39.039011 20404 solver.cpp:228] Iteration 1550, loss = 0.820728
I0816 17:58:39.039185 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 17:58:39.039199 20404 solver.cpp:244]     Train net output #1: loss = 0.820728 (* 1 = 0.820728 loss)
I0816 17:58:39.039212 20404 sgd_solver.cpp:106] Iteration 1550, lr = 0.00089756
I0816 17:59:10.440933 20404 solver.cpp:337] Iteration 1560, Testing net (#0)
I0816 17:59:45.068331 20404 solver.cpp:404]     Test net output #0: accuracy = 0.692
I0816 17:59:45.068507 20404 solver.cpp:404]     Test net output #1: loss = 0.670053 (* 1 = 0.670053 loss)
I0816 17:59:48.544067 20404 solver.cpp:228] Iteration 1560, loss = 0.821176
I0816 17:59:48.544119 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 17:59:48.544133 20404 solver.cpp:244]     Train net output #1: loss = 0.821176 (* 1 = 0.821176 loss)
I0816 17:59:48.544147 20404 sgd_solver.cpp:106] Iteration 1560, lr = 0.000896978
I0816 18:00:23.426980 20404 solver.cpp:228] Iteration 1570, loss = 0.820262
I0816 18:00:23.427192 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:00:23.427207 20404 solver.cpp:244]     Train net output #1: loss = 0.820262 (* 1 = 0.820262 loss)
I0816 18:00:23.427219 20404 sgd_solver.cpp:106] Iteration 1570, lr = 0.000896396
I0816 18:00:58.326004 20404 solver.cpp:228] Iteration 1580, loss = 0.820813
I0816 18:00:58.326184 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:00:58.326200 20404 solver.cpp:244]     Train net output #1: loss = 0.820813 (* 1 = 0.820813 loss)
I0816 18:00:58.326211 20404 sgd_solver.cpp:106] Iteration 1580, lr = 0.000895816
I0816 18:01:33.223127 20404 solver.cpp:228] Iteration 1590, loss = 0.820932
I0816 18:01:33.223332 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:01:33.223351 20404 solver.cpp:244]     Train net output #1: loss = 0.820932 (* 1 = 0.820932 loss)
I0816 18:01:33.223362 20404 sgd_solver.cpp:106] Iteration 1590, lr = 0.000895236
I0816 18:02:04.610972 20404 solver.cpp:337] Iteration 1600, Testing net (#0)
I0816 18:02:39.265478 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 18:02:39.265653 20404 solver.cpp:404]     Test net output #1: loss = 0.670864 (* 1 = 0.670864 loss)
I0816 18:02:42.746520 20404 solver.cpp:228] Iteration 1600, loss = 0.820027
I0816 18:02:42.746569 20404 solver.cpp:244]     Train net output #0: accuracy = 0.76
I0816 18:02:42.746583 20404 solver.cpp:244]     Train net output #1: loss = 0.820027 (* 1 = 0.820027 loss)
I0816 18:02:42.746595 20404 sgd_solver.cpp:106] Iteration 1600, lr = 0.000894657
I0816 18:03:17.626986 20404 solver.cpp:228] Iteration 1610, loss = 0.820599
I0816 18:03:17.627151 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:03:17.627166 20404 solver.cpp:244]     Train net output #1: loss = 0.820599 (* 1 = 0.820599 loss)
I0816 18:03:17.627177 20404 sgd_solver.cpp:106] Iteration 1610, lr = 0.000894079
I0816 18:03:52.488955 20404 solver.cpp:228] Iteration 1620, loss = 0.820303
I0816 18:03:52.489137 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:03:52.489156 20404 solver.cpp:244]     Train net output #1: loss = 0.820303 (* 1 = 0.820303 loss)
I0816 18:03:52.489168 20404 sgd_solver.cpp:106] Iteration 1620, lr = 0.000893502
I0816 18:04:27.381364 20404 solver.cpp:228] Iteration 1630, loss = 0.820735
I0816 18:04:27.381544 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:04:27.381559 20404 solver.cpp:244]     Train net output #1: loss = 0.820735 (* 1 = 0.820735 loss)
I0816 18:04:27.381572 20404 sgd_solver.cpp:106] Iteration 1630, lr = 0.000892926
I0816 18:04:58.806402 20404 solver.cpp:337] Iteration 1640, Testing net (#0)
I0816 18:05:33.456928 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 18:05:33.457027 20404 solver.cpp:404]     Test net output #1: loss = 0.671132 (* 1 = 0.671132 loss)
I0816 18:05:36.933539 20404 solver.cpp:228] Iteration 1640, loss = 0.822554
I0816 18:05:36.933593 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:05:36.933607 20404 solver.cpp:244]     Train net output #1: loss = 0.822554 (* 1 = 0.822554 loss)
I0816 18:05:36.933620 20404 sgd_solver.cpp:106] Iteration 1640, lr = 0.00089235
I0816 18:06:11.837764 20404 solver.cpp:228] Iteration 1650, loss = 0.82312
I0816 18:06:11.837878 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:06:11.837898 20404 solver.cpp:244]     Train net output #1: loss = 0.82312 (* 1 = 0.82312 loss)
I0816 18:06:11.837913 20404 sgd_solver.cpp:106] Iteration 1650, lr = 0.000891776
I0816 18:06:46.720859 20404 solver.cpp:228] Iteration 1660, loss = 0.820077
I0816 18:06:46.720968 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:06:46.720983 20404 solver.cpp:244]     Train net output #1: loss = 0.820077 (* 1 = 0.820077 loss)
I0816 18:06:46.720994 20404 sgd_solver.cpp:106] Iteration 1660, lr = 0.000891202
I0816 18:07:21.599967 20404 solver.cpp:228] Iteration 1670, loss = 0.821129
I0816 18:07:21.600180 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:07:21.600198 20404 solver.cpp:244]     Train net output #1: loss = 0.821129 (* 1 = 0.821129 loss)
I0816 18:07:21.600209 20404 sgd_solver.cpp:106] Iteration 1670, lr = 0.000890629
I0816 18:07:53.029732 20404 solver.cpp:337] Iteration 1680, Testing net (#0)
I0816 18:08:27.696125 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 18:08:27.696208 20404 solver.cpp:404]     Test net output #1: loss = 0.671622 (* 1 = 0.671622 loss)
I0816 18:08:31.175787 20404 solver.cpp:228] Iteration 1680, loss = 0.82043
I0816 18:08:31.175840 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:08:31.175853 20404 solver.cpp:244]     Train net output #1: loss = 0.82043 (* 1 = 0.82043 loss)
I0816 18:08:31.175865 20404 sgd_solver.cpp:106] Iteration 1680, lr = 0.000890057
I0816 18:09:06.066180 20404 solver.cpp:228] Iteration 1690, loss = 0.820222
I0816 18:09:06.066364 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:09:06.066378 20404 solver.cpp:244]     Train net output #1: loss = 0.820222 (* 1 = 0.820222 loss)
I0816 18:09:06.066390 20404 sgd_solver.cpp:106] Iteration 1690, lr = 0.000889486
I0816 18:09:40.951025 20404 solver.cpp:228] Iteration 1700, loss = 0.820311
I0816 18:09:40.951205 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:09:40.951241 20404 solver.cpp:244]     Train net output #1: loss = 0.820311 (* 1 = 0.820311 loss)
I0816 18:09:40.951325 20404 sgd_solver.cpp:106] Iteration 1700, lr = 0.000888916
I0816 18:10:15.827721 20404 solver.cpp:228] Iteration 1710, loss = 0.820123
I0816 18:10:15.827898 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:10:15.827914 20404 solver.cpp:244]     Train net output #1: loss = 0.820123 (* 1 = 0.820123 loss)
I0816 18:10:15.827926 20404 sgd_solver.cpp:106] Iteration 1710, lr = 0.000888346
I0816 18:10:47.239073 20404 solver.cpp:337] Iteration 1720, Testing net (#0)
I0816 18:11:21.893997 20404 solver.cpp:404]     Test net output #0: accuracy = 0.996
I0816 18:11:21.894165 20404 solver.cpp:404]     Test net output #1: loss = 0.670082 (* 1 = 0.670082 loss)
I0816 18:11:25.373822 20404 solver.cpp:228] Iteration 1720, loss = 0.821029
I0816 18:11:25.373874 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:11:25.373888 20404 solver.cpp:244]     Train net output #1: loss = 0.821029 (* 1 = 0.821029 loss)
I0816 18:11:25.373900 20404 sgd_solver.cpp:106] Iteration 1720, lr = 0.000887778
I0816 18:12:00.240795 20404 solver.cpp:228] Iteration 1730, loss = 0.820105
I0816 18:12:00.240958 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:12:00.240974 20404 solver.cpp:244]     Train net output #1: loss = 0.820105 (* 1 = 0.820105 loss)
I0816 18:12:00.240988 20404 sgd_solver.cpp:106] Iteration 1730, lr = 0.00088721
I0816 18:12:35.098387 20404 solver.cpp:228] Iteration 1740, loss = 0.820576
I0816 18:12:35.098562 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:12:35.098577 20404 solver.cpp:244]     Train net output #1: loss = 0.820576 (* 1 = 0.820576 loss)
I0816 18:12:35.098589 20404 sgd_solver.cpp:106] Iteration 1740, lr = 0.000886643
I0816 18:13:09.968734 20404 solver.cpp:228] Iteration 1750, loss = 0.821569
I0816 18:13:09.968912 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:13:09.968931 20404 solver.cpp:244]     Train net output #1: loss = 0.821569 (* 1 = 0.821569 loss)
I0816 18:13:09.968945 20404 sgd_solver.cpp:106] Iteration 1750, lr = 0.000886077
I0816 18:13:41.370597 20404 solver.cpp:337] Iteration 1760, Testing net (#0)
I0816 18:14:16.015254 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 18:14:16.015437 20404 solver.cpp:404]     Test net output #1: loss = 0.670223 (* 1 = 0.670223 loss)
I0816 18:14:19.490033 20404 solver.cpp:228] Iteration 1760, loss = 0.821425
I0816 18:14:19.490085 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:14:19.490099 20404 solver.cpp:244]     Train net output #1: loss = 0.821425 (* 1 = 0.821425 loss)
I0816 18:14:19.490111 20404 sgd_solver.cpp:106] Iteration 1760, lr = 0.000885512
I0816 18:14:54.377260 20404 solver.cpp:228] Iteration 1770, loss = 0.820172
I0816 18:14:54.377477 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:14:54.377493 20404 solver.cpp:244]     Train net output #1: loss = 0.820172 (* 1 = 0.820172 loss)
I0816 18:14:54.377506 20404 sgd_solver.cpp:106] Iteration 1770, lr = 0.000884948
I0816 18:15:29.261808 20404 solver.cpp:228] Iteration 1780, loss = 0.820626
I0816 18:15:29.262004 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:15:29.262022 20404 solver.cpp:244]     Train net output #1: loss = 0.820626 (* 1 = 0.820626 loss)
I0816 18:15:29.262034 20404 sgd_solver.cpp:106] Iteration 1780, lr = 0.000884384
I0816 18:16:04.121564 20404 solver.cpp:228] Iteration 1790, loss = 0.820031
I0816 18:16:04.121745 20404 solver.cpp:244]     Train net output #0: accuracy = 0.72
I0816 18:16:04.121760 20404 solver.cpp:244]     Train net output #1: loss = 0.820031 (* 1 = 0.820031 loss)
I0816 18:16:04.121773 20404 sgd_solver.cpp:106] Iteration 1790, lr = 0.000883822
I0816 18:16:35.537613 20404 solver.cpp:337] Iteration 1800, Testing net (#0)
I0816 18:17:10.193284 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 18:17:10.193452 20404 solver.cpp:404]     Test net output #1: loss = 0.670153 (* 1 = 0.670153 loss)
I0816 18:17:13.668321 20404 solver.cpp:228] Iteration 1800, loss = 0.821343
I0816 18:17:13.668375 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:17:13.668388 20404 solver.cpp:244]     Train net output #1: loss = 0.821343 (* 1 = 0.821343 loss)
I0816 18:17:13.668400 20404 sgd_solver.cpp:106] Iteration 1800, lr = 0.00088326
I0816 18:17:48.549834 20404 solver.cpp:228] Iteration 1810, loss = 0.820803
I0816 18:17:48.549947 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:17:48.549965 20404 solver.cpp:244]     Train net output #1: loss = 0.820803 (* 1 = 0.820803 loss)
I0816 18:17:48.549980 20404 sgd_solver.cpp:106] Iteration 1810, lr = 0.000882699
I0816 18:18:23.436112 20404 solver.cpp:228] Iteration 1820, loss = 0.821234
I0816 18:18:23.436293 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:18:23.436307 20404 solver.cpp:244]     Train net output #1: loss = 0.821234 (* 1 = 0.821234 loss)
I0816 18:18:23.436321 20404 sgd_solver.cpp:106] Iteration 1820, lr = 0.000882139
I0816 18:18:58.327522 20404 solver.cpp:228] Iteration 1830, loss = 0.821211
I0816 18:18:58.327708 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:18:58.327723 20404 solver.cpp:244]     Train net output #1: loss = 0.821211 (* 1 = 0.821211 loss)
I0816 18:18:58.327736 20404 sgd_solver.cpp:106] Iteration 1830, lr = 0.000881579
I0816 18:19:29.732847 20404 solver.cpp:337] Iteration 1840, Testing net (#0)
I0816 18:20:04.391741 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 18:20:04.391902 20404 solver.cpp:404]     Test net output #1: loss = 0.670912 (* 1 = 0.670912 loss)
I0816 18:20:07.867050 20404 solver.cpp:228] Iteration 1840, loss = 0.820022
I0816 18:20:07.867091 20404 solver.cpp:244]     Train net output #0: accuracy = 0.87
I0816 18:20:07.867108 20404 solver.cpp:244]     Train net output #1: loss = 0.820022 (* 1 = 0.820022 loss)
I0816 18:20:07.867121 20404 sgd_solver.cpp:106] Iteration 1840, lr = 0.000881021
I0816 18:20:42.722192 20404 solver.cpp:228] Iteration 1850, loss = 0.820112
I0816 18:20:42.722311 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:20:42.722326 20404 solver.cpp:244]     Train net output #1: loss = 0.820112 (* 1 = 0.820112 loss)
I0816 18:20:42.722338 20404 sgd_solver.cpp:106] Iteration 1850, lr = 0.000880463
I0816 18:21:17.594449 20404 solver.cpp:228] Iteration 1860, loss = 0.820474
I0816 18:21:17.594619 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:21:17.594633 20404 solver.cpp:244]     Train net output #1: loss = 0.820474 (* 1 = 0.820474 loss)
I0816 18:21:17.594646 20404 sgd_solver.cpp:106] Iteration 1860, lr = 0.000879906
I0816 18:21:52.484839 20404 solver.cpp:228] Iteration 1870, loss = 0.820902
I0816 18:21:52.484983 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:21:52.485000 20404 solver.cpp:244]     Train net output #1: loss = 0.820902 (* 1 = 0.820902 loss)
I0816 18:21:52.485013 20404 sgd_solver.cpp:106] Iteration 1870, lr = 0.00087935
I0816 18:22:23.880616 20404 solver.cpp:337] Iteration 1880, Testing net (#0)
I0816 18:22:58.499605 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 18:22:58.499783 20404 solver.cpp:404]     Test net output #1: loss = 0.670898 (* 1 = 0.670898 loss)
I0816 18:23:01.979826 20404 solver.cpp:228] Iteration 1880, loss = 0.820024
I0816 18:23:01.979871 20404 solver.cpp:244]     Train net output #0: accuracy = 0.81
I0816 18:23:01.979899 20404 solver.cpp:244]     Train net output #1: loss = 0.820024 (* 1 = 0.820024 loss)
I0816 18:23:01.979918 20404 sgd_solver.cpp:106] Iteration 1880, lr = 0.000878795
I0816 18:23:36.863173 20404 solver.cpp:228] Iteration 1890, loss = 0.8206
I0816 18:23:36.863348 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:23:36.863363 20404 solver.cpp:244]     Train net output #1: loss = 0.8206 (* 1 = 0.8206 loss)
I0816 18:23:36.863375 20404 sgd_solver.cpp:106] Iteration 1890, lr = 0.000878241
I0816 18:24:11.760084 20404 solver.cpp:228] Iteration 1900, loss = 0.820393
I0816 18:24:11.760254 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:24:11.760270 20404 solver.cpp:244]     Train net output #1: loss = 0.820393 (* 1 = 0.820393 loss)
I0816 18:24:11.760283 20404 sgd_solver.cpp:106] Iteration 1900, lr = 0.000877687
I0816 18:24:46.646924 20404 solver.cpp:228] Iteration 1910, loss = 0.820529
I0816 18:24:46.647102 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:24:46.647117 20404 solver.cpp:244]     Train net output #1: loss = 0.820529 (* 1 = 0.820529 loss)
I0816 18:24:46.647130 20404 sgd_solver.cpp:106] Iteration 1910, lr = 0.000877135
I0816 18:25:18.050673 20404 solver.cpp:337] Iteration 1920, Testing net (#0)
I0816 18:25:52.705276 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 18:25:52.705451 20404 solver.cpp:404]     Test net output #1: loss = 0.670435 (* 1 = 0.670435 loss)
I0816 18:25:56.180667 20404 solver.cpp:228] Iteration 1920, loss = 0.821719
I0816 18:25:56.180719 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:25:56.180733 20404 solver.cpp:244]     Train net output #1: loss = 0.821719 (* 1 = 0.821719 loss)
I0816 18:25:56.180745 20404 sgd_solver.cpp:106] Iteration 1920, lr = 0.000876583
I0816 18:26:31.062214 20404 solver.cpp:228] Iteration 1930, loss = 0.820061
I0816 18:26:31.062398 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:26:31.062413 20404 solver.cpp:244]     Train net output #1: loss = 0.820061 (* 1 = 0.820061 loss)
I0816 18:26:31.062427 20404 sgd_solver.cpp:106] Iteration 1930, lr = 0.000876031
I0816 18:27:05.958050 20404 solver.cpp:228] Iteration 1940, loss = 0.821662
I0816 18:27:05.958220 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:27:05.958236 20404 solver.cpp:244]     Train net output #1: loss = 0.821662 (* 1 = 0.821662 loss)
I0816 18:27:05.958250 20404 sgd_solver.cpp:106] Iteration 1940, lr = 0.000875481
I0816 18:27:40.838917 20404 solver.cpp:228] Iteration 1950, loss = 0.820113
I0816 18:27:40.839097 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:27:40.839112 20404 solver.cpp:244]     Train net output #1: loss = 0.820113 (* 1 = 0.820113 loss)
I0816 18:27:40.839124 20404 sgd_solver.cpp:106] Iteration 1950, lr = 0.000874932
I0816 18:28:12.261929 20404 solver.cpp:337] Iteration 1960, Testing net (#0)
I0816 18:28:46.915689 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 18:28:46.915858 20404 solver.cpp:404]     Test net output #1: loss = 0.670184 (* 1 = 0.670184 loss)
I0816 18:28:50.389245 20404 solver.cpp:228] Iteration 1960, loss = 0.821406
I0816 18:28:50.389298 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:28:50.389313 20404 solver.cpp:244]     Train net output #1: loss = 0.821406 (* 1 = 0.821406 loss)
I0816 18:28:50.389327 20404 sgd_solver.cpp:106] Iteration 1960, lr = 0.000874383
I0816 18:29:25.275961 20404 solver.cpp:228] Iteration 1970, loss = 0.822899
I0816 18:29:25.276177 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:29:25.276196 20404 solver.cpp:244]     Train net output #1: loss = 0.822899 (* 1 = 0.822899 loss)
I0816 18:29:25.276207 20404 sgd_solver.cpp:106] Iteration 1970, lr = 0.000873835
I0816 18:30:00.171325 20404 solver.cpp:228] Iteration 1980, loss = 0.822677
I0816 18:30:00.171509 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:30:00.171524 20404 solver.cpp:244]     Train net output #1: loss = 0.822677 (* 1 = 0.822677 loss)
I0816 18:30:00.171536 20404 sgd_solver.cpp:106] Iteration 1980, lr = 0.000873288
I0816 18:30:35.041997 20404 solver.cpp:228] Iteration 1990, loss = 0.822634
I0816 18:30:35.042173 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:30:35.042189 20404 solver.cpp:244]     Train net output #1: loss = 0.822634 (* 1 = 0.822634 loss)
I0816 18:30:35.042201 20404 sgd_solver.cpp:106] Iteration 1990, lr = 0.000872742
I0816 18:31:06.457998 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_2000.caffemodel
I0816 18:31:16.450415 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_2000.solverstate
I0816 18:31:18.092239 20404 solver.cpp:337] Iteration 2000, Testing net (#0)
I0816 18:31:52.754631 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 18:31:52.754803 20404 solver.cpp:404]     Test net output #1: loss = 0.671165 (* 1 = 0.671165 loss)
I0816 18:31:56.220424 20404 solver.cpp:228] Iteration 2000, loss = 0.822655
I0816 18:31:56.220468 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:31:56.220482 20404 solver.cpp:244]     Train net output #1: loss = 0.822655 (* 1 = 0.822655 loss)
I0816 18:31:56.220494 20404 sgd_solver.cpp:106] Iteration 2000, lr = 0.000872196
I0816 18:32:31.096626 20404 solver.cpp:228] Iteration 2010, loss = 0.822698
I0816 18:32:31.096809 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:32:31.096825 20404 solver.cpp:244]     Train net output #1: loss = 0.822698 (* 1 = 0.822698 loss)
I0816 18:32:31.096837 20404 sgd_solver.cpp:106] Iteration 2010, lr = 0.000871651
I0816 18:33:05.978602 20404 solver.cpp:228] Iteration 2020, loss = 0.822752
I0816 18:33:05.978770 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:33:05.978785 20404 solver.cpp:244]     Train net output #1: loss = 0.822752 (* 1 = 0.822752 loss)
I0816 18:33:05.978798 20404 sgd_solver.cpp:106] Iteration 2020, lr = 0.000871107
I0816 18:33:40.872843 20404 solver.cpp:228] Iteration 2030, loss = 0.822811
I0816 18:33:40.873026 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:33:40.873045 20404 solver.cpp:244]     Train net output #1: loss = 0.822811 (* 1 = 0.822811 loss)
I0816 18:33:40.873061 20404 sgd_solver.cpp:106] Iteration 2030, lr = 0.000870564
I0816 18:34:12.289495 20404 solver.cpp:337] Iteration 2040, Testing net (#0)
I0816 18:34:46.927595 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 18:34:46.927690 20404 solver.cpp:404]     Test net output #1: loss = 0.671321 (* 1 = 0.671321 loss)
I0816 18:34:50.399838 20404 solver.cpp:228] Iteration 2040, loss = 0.822866
I0816 18:34:50.399894 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:34:50.399909 20404 solver.cpp:244]     Train net output #1: loss = 0.822866 (* 1 = 0.822866 loss)
I0816 18:34:50.399920 20404 sgd_solver.cpp:106] Iteration 2040, lr = 0.000870022
I0816 18:35:25.280069 20404 solver.cpp:228] Iteration 2050, loss = 0.822922
I0816 18:35:25.280261 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:35:25.280280 20404 solver.cpp:244]     Train net output #1: loss = 0.822922 (* 1 = 0.822922 loss)
I0816 18:35:25.280299 20404 sgd_solver.cpp:106] Iteration 2050, lr = 0.00086948
I0816 18:36:00.163914 20404 solver.cpp:228] Iteration 2060, loss = 0.82254
I0816 18:36:00.164052 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:36:00.164072 20404 solver.cpp:244]     Train net output #1: loss = 0.82254 (* 1 = 0.82254 loss)
I0816 18:36:00.164089 20404 sgd_solver.cpp:106] Iteration 2060, lr = 0.00086894
I0816 18:36:35.047345 20404 solver.cpp:228] Iteration 2070, loss = 0.821386
I0816 18:36:35.047461 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:36:35.047477 20404 solver.cpp:244]     Train net output #1: loss = 0.821386 (* 1 = 0.821386 loss)
I0816 18:36:35.047490 20404 sgd_solver.cpp:106] Iteration 2070, lr = 0.0008684
I0816 18:37:06.466323 20404 solver.cpp:337] Iteration 2080, Testing net (#0)
I0816 18:37:41.100906 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 18:37:41.101076 20404 solver.cpp:404]     Test net output #1: loss = 0.671742 (* 1 = 0.671742 loss)
I0816 18:37:44.582834 20404 solver.cpp:228] Iteration 2080, loss = 0.820473
I0816 18:37:44.582881 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:37:44.582901 20404 solver.cpp:244]     Train net output #1: loss = 0.820473 (* 1 = 0.820473 loss)
I0816 18:37:44.582916 20404 sgd_solver.cpp:106] Iteration 2080, lr = 0.00086786
I0816 18:38:19.462860 20404 solver.cpp:228] Iteration 2090, loss = 0.82044
I0816 18:38:19.463038 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:38:19.463055 20404 solver.cpp:244]     Train net output #1: loss = 0.82044 (* 1 = 0.82044 loss)
I0816 18:38:19.463068 20404 sgd_solver.cpp:106] Iteration 2090, lr = 0.000867322
I0816 18:38:54.350028 20404 solver.cpp:228] Iteration 2100, loss = 0.82017
I0816 18:38:54.350209 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:38:54.350225 20404 solver.cpp:244]     Train net output #1: loss = 0.82017 (* 1 = 0.82017 loss)
I0816 18:38:54.350239 20404 sgd_solver.cpp:106] Iteration 2100, lr = 0.000866784
I0816 18:39:29.216382 20404 solver.cpp:228] Iteration 2110, loss = 0.820362
I0816 18:39:29.216562 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:39:29.216578 20404 solver.cpp:244]     Train net output #1: loss = 0.820362 (* 1 = 0.820362 loss)
I0816 18:39:29.216590 20404 sgd_solver.cpp:106] Iteration 2110, lr = 0.000866247
I0816 18:40:00.619544 20404 solver.cpp:337] Iteration 2120, Testing net (#0)
I0816 18:40:35.265949 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 18:40:35.266126 20404 solver.cpp:404]     Test net output #1: loss = 0.671212 (* 1 = 0.671212 loss)
I0816 18:40:38.742650 20404 solver.cpp:228] Iteration 2120, loss = 0.820165
I0816 18:40:38.742704 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:40:38.742718 20404 solver.cpp:244]     Train net output #1: loss = 0.820165 (* 1 = 0.820165 loss)
I0816 18:40:38.742732 20404 sgd_solver.cpp:106] Iteration 2120, lr = 0.000865711
I0816 18:41:13.619727 20404 solver.cpp:228] Iteration 2130, loss = 0.820108
I0816 18:41:13.619822 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:41:13.619838 20404 solver.cpp:244]     Train net output #1: loss = 0.820108 (* 1 = 0.820108 loss)
I0816 18:41:13.619850 20404 sgd_solver.cpp:106] Iteration 2130, lr = 0.000865176
I0816 18:41:48.495157 20404 solver.cpp:228] Iteration 2140, loss = 0.820113
I0816 18:41:48.495261 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:41:48.495281 20404 solver.cpp:244]     Train net output #1: loss = 0.820113 (* 1 = 0.820113 loss)
I0816 18:41:48.495295 20404 sgd_solver.cpp:106] Iteration 2140, lr = 0.000864641
I0816 18:42:23.391194 20404 solver.cpp:228] Iteration 2150, loss = 0.821396
I0816 18:42:23.391376 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:42:23.391391 20404 solver.cpp:244]     Train net output #1: loss = 0.821396 (* 1 = 0.821396 loss)
I0816 18:42:23.391403 20404 sgd_solver.cpp:106] Iteration 2150, lr = 0.000864108
I0816 18:42:54.764639 20404 solver.cpp:337] Iteration 2160, Testing net (#0)
I0816 18:43:29.419147 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 18:43:29.419329 20404 solver.cpp:404]     Test net output #1: loss = 0.671259 (* 1 = 0.671259 loss)
I0816 18:43:32.893895 20404 solver.cpp:228] Iteration 2160, loss = 0.822805
I0816 18:43:32.893949 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:43:32.893962 20404 solver.cpp:244]     Train net output #1: loss = 0.822805 (* 1 = 0.822805 loss)
I0816 18:43:32.893975 20404 sgd_solver.cpp:106] Iteration 2160, lr = 0.000863575
I0816 18:44:07.768395 20404 solver.cpp:228] Iteration 2170, loss = 0.822454
I0816 18:44:07.768561 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:44:07.768578 20404 solver.cpp:244]     Train net output #1: loss = 0.822454 (* 1 = 0.822454 loss)
I0816 18:44:07.768590 20404 sgd_solver.cpp:106] Iteration 2170, lr = 0.000863042
I0816 18:44:42.657001 20404 solver.cpp:228] Iteration 2180, loss = 0.821964
I0816 18:44:42.657179 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:44:42.657196 20404 solver.cpp:244]     Train net output #1: loss = 0.821964 (* 1 = 0.821964 loss)
I0816 18:44:42.657209 20404 sgd_solver.cpp:106] Iteration 2180, lr = 0.000862511
I0816 18:45:17.532614 20404 solver.cpp:228] Iteration 2190, loss = 0.822023
I0816 18:45:17.532732 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:45:17.532748 20404 solver.cpp:244]     Train net output #1: loss = 0.822023 (* 1 = 0.822023 loss)
I0816 18:45:17.532762 20404 sgd_solver.cpp:106] Iteration 2190, lr = 0.00086198
I0816 18:45:48.945364 20404 solver.cpp:337] Iteration 2200, Testing net (#0)
I0816 18:46:23.581707 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 18:46:23.581864 20404 solver.cpp:404]     Test net output #1: loss = 0.670427 (* 1 = 0.670427 loss)
I0816 18:46:27.057317 20404 solver.cpp:228] Iteration 2200, loss = 0.821763
I0816 18:46:27.057366 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:46:27.057385 20404 solver.cpp:244]     Train net output #1: loss = 0.821763 (* 1 = 0.821763 loss)
I0816 18:46:27.057400 20404 sgd_solver.cpp:106] Iteration 2200, lr = 0.00086145
I0816 18:47:01.938699 20404 solver.cpp:228] Iteration 2210, loss = 0.82014
I0816 18:47:01.938875 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:47:01.938894 20404 solver.cpp:244]     Train net output #1: loss = 0.82014 (* 1 = 0.82014 loss)
I0816 18:47:01.938910 20404 sgd_solver.cpp:106] Iteration 2210, lr = 0.000860921
I0816 18:47:36.845903 20404 solver.cpp:228] Iteration 2220, loss = 0.82009
I0816 18:47:36.846154 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:47:36.846174 20404 solver.cpp:244]     Train net output #1: loss = 0.82009 (* 1 = 0.82009 loss)
I0816 18:47:36.846189 20404 sgd_solver.cpp:106] Iteration 2220, lr = 0.000860393
I0816 18:48:11.737851 20404 solver.cpp:228] Iteration 2230, loss = 0.820983
I0816 18:48:11.738042 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:48:11.738062 20404 solver.cpp:244]     Train net output #1: loss = 0.820983 (* 1 = 0.820983 loss)
I0816 18:48:11.738078 20404 sgd_solver.cpp:106] Iteration 2230, lr = 0.000859865
I0816 18:48:43.145916 20404 solver.cpp:337] Iteration 2240, Testing net (#0)
I0816 18:49:17.781549 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 18:49:17.781718 20404 solver.cpp:404]     Test net output #1: loss = 0.670894 (* 1 = 0.670894 loss)
I0816 18:49:21.257141 20404 solver.cpp:228] Iteration 2240, loss = 0.820076
I0816 18:49:21.257192 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:49:21.257207 20404 solver.cpp:244]     Train net output #1: loss = 0.820076 (* 1 = 0.820076 loss)
I0816 18:49:21.257220 20404 sgd_solver.cpp:106] Iteration 2240, lr = 0.000859338
I0816 18:49:56.154037 20404 solver.cpp:228] Iteration 2250, loss = 0.820655
I0816 18:49:56.154225 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:49:56.154244 20404 solver.cpp:244]     Train net output #1: loss = 0.820655 (* 1 = 0.820655 loss)
I0816 18:49:56.154259 20404 sgd_solver.cpp:106] Iteration 2250, lr = 0.000858812
I0816 18:50:31.056350 20404 solver.cpp:228] Iteration 2260, loss = 0.820272
I0816 18:50:31.056557 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:50:31.056572 20404 solver.cpp:244]     Train net output #1: loss = 0.820272 (* 1 = 0.820272 loss)
I0816 18:50:31.056586 20404 sgd_solver.cpp:106] Iteration 2260, lr = 0.000858286
I0816 18:51:05.927561 20404 solver.cpp:228] Iteration 2270, loss = 0.821081
I0816 18:51:05.927737 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:51:05.927754 20404 solver.cpp:244]     Train net output #1: loss = 0.821081 (* 1 = 0.821081 loss)
I0816 18:51:05.927767 20404 sgd_solver.cpp:106] Iteration 2270, lr = 0.000857762
I0816 18:51:37.345360 20404 solver.cpp:337] Iteration 2280, Testing net (#0)
I0816 18:52:12.003592 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 18:52:12.003762 20404 solver.cpp:404]     Test net output #1: loss = 0.670432 (* 1 = 0.670432 loss)
I0816 18:52:15.480942 20404 solver.cpp:228] Iteration 2280, loss = 0.821773
I0816 18:52:15.480994 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:52:15.481009 20404 solver.cpp:244]     Train net output #1: loss = 0.821773 (* 1 = 0.821773 loss)
I0816 18:52:15.481020 20404 sgd_solver.cpp:106] Iteration 2280, lr = 0.000857238
I0816 18:52:50.325749 20404 solver.cpp:228] Iteration 2290, loss = 0.82088
I0816 18:52:50.325935 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:52:50.325951 20404 solver.cpp:244]     Train net output #1: loss = 0.82088 (* 1 = 0.82088 loss)
I0816 18:52:50.325963 20404 sgd_solver.cpp:106] Iteration 2290, lr = 0.000856714
I0816 18:53:25.203228 20404 solver.cpp:228] Iteration 2300, loss = 0.820856
I0816 18:53:25.203418 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:53:25.203433 20404 solver.cpp:244]     Train net output #1: loss = 0.820856 (* 1 = 0.820856 loss)
I0816 18:53:25.203446 20404 sgd_solver.cpp:106] Iteration 2300, lr = 0.000856192
I0816 18:54:00.094408 20404 solver.cpp:228] Iteration 2310, loss = 0.820782
I0816 18:54:00.095520 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:54:00.095540 20404 solver.cpp:244]     Train net output #1: loss = 0.820782 (* 1 = 0.820782 loss)
I0816 18:54:00.095552 20404 sgd_solver.cpp:106] Iteration 2310, lr = 0.00085567
I0816 18:54:31.500011 20404 solver.cpp:337] Iteration 2320, Testing net (#0)
I0816 18:55:06.130018 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 18:55:06.130189 20404 solver.cpp:404]     Test net output #1: loss = 0.670788 (* 1 = 0.670788 loss)
I0816 18:55:09.603346 20404 solver.cpp:228] Iteration 2320, loss = 0.820229
I0816 18:55:09.603396 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:55:09.603410 20404 solver.cpp:244]     Train net output #1: loss = 0.820229 (* 1 = 0.820229 loss)
I0816 18:55:09.603422 20404 sgd_solver.cpp:106] Iteration 2320, lr = 0.000855149
I0816 18:55:44.475597 20404 solver.cpp:228] Iteration 2330, loss = 0.821817
I0816 18:55:44.475776 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:55:44.475792 20404 solver.cpp:244]     Train net output #1: loss = 0.821817 (* 1 = 0.821817 loss)
I0816 18:55:44.475806 20404 sgd_solver.cpp:106] Iteration 2330, lr = 0.000854629
I0816 18:56:19.359832 20404 solver.cpp:228] Iteration 2340, loss = 0.820142
I0816 18:56:19.360019 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 18:56:19.360035 20404 solver.cpp:244]     Train net output #1: loss = 0.820142 (* 1 = 0.820142 loss)
I0816 18:56:19.360049 20404 sgd_solver.cpp:106] Iteration 2340, lr = 0.00085411
I0816 18:56:54.251099 20404 solver.cpp:228] Iteration 2350, loss = 0.821699
I0816 18:56:54.251281 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:56:54.251296 20404 solver.cpp:244]     Train net output #1: loss = 0.821699 (* 1 = 0.821699 loss)
I0816 18:56:54.251309 20404 sgd_solver.cpp:106] Iteration 2350, lr = 0.000853591
I0816 18:57:25.674520 20404 solver.cpp:337] Iteration 2360, Testing net (#0)
I0816 18:58:00.340328 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 18:58:00.340507 20404 solver.cpp:404]     Test net output #1: loss = 0.670157 (* 1 = 0.670157 loss)
I0816 18:58:03.813154 20404 solver.cpp:228] Iteration 2360, loss = 0.821045
I0816 18:58:03.813206 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:58:03.813220 20404 solver.cpp:244]     Train net output #1: loss = 0.821045 (* 1 = 0.821045 loss)
I0816 18:58:03.813233 20404 sgd_solver.cpp:106] Iteration 2360, lr = 0.000853073
I0816 18:58:38.708341 20404 solver.cpp:228] Iteration 2370, loss = 0.821117
I0816 18:58:38.708518 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:58:38.708534 20404 solver.cpp:244]     Train net output #1: loss = 0.821117 (* 1 = 0.821117 loss)
I0816 18:58:38.708546 20404 sgd_solver.cpp:106] Iteration 2370, lr = 0.000852556
I0816 18:59:13.613510 20404 solver.cpp:228] Iteration 2380, loss = 0.821447
I0816 18:59:13.613685 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:59:13.613703 20404 solver.cpp:244]     Train net output #1: loss = 0.821447 (* 1 = 0.821447 loss)
I0816 18:59:13.613716 20404 sgd_solver.cpp:106] Iteration 2380, lr = 0.000852039
I0816 18:59:48.467546 20404 solver.cpp:228] Iteration 2390, loss = 0.821855
I0816 18:59:48.467720 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 18:59:48.467736 20404 solver.cpp:244]     Train net output #1: loss = 0.821855 (* 1 = 0.821855 loss)
I0816 18:59:48.467749 20404 sgd_solver.cpp:106] Iteration 2390, lr = 0.000851523
I0816 19:00:19.884062 20404 solver.cpp:337] Iteration 2400, Testing net (#0)
I0816 19:00:54.507784 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:00:54.507958 20404 solver.cpp:404]     Test net output #1: loss = 0.670324 (* 1 = 0.670324 loss)
I0816 19:00:57.986814 20404 solver.cpp:228] Iteration 2400, loss = 0.820839
I0816 19:00:57.986865 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:00:57.986881 20404 solver.cpp:244]     Train net output #1: loss = 0.820839 (* 1 = 0.820839 loss)
I0816 19:00:57.986892 20404 sgd_solver.cpp:106] Iteration 2400, lr = 0.000851008
I0816 19:01:32.899633 20404 solver.cpp:228] Iteration 2410, loss = 0.820368
I0816 19:01:32.899739 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:01:32.899755 20404 solver.cpp:244]     Train net output #1: loss = 0.820368 (* 1 = 0.820368 loss)
I0816 19:01:32.899767 20404 sgd_solver.cpp:106] Iteration 2410, lr = 0.000850494
I0816 19:02:07.777096 20404 solver.cpp:228] Iteration 2420, loss = 0.820685
I0816 19:02:07.777266 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:02:07.777282 20404 solver.cpp:244]     Train net output #1: loss = 0.820685 (* 1 = 0.820685 loss)
I0816 19:02:07.777294 20404 sgd_solver.cpp:106] Iteration 2420, lr = 0.00084998
I0816 19:02:42.649930 20404 solver.cpp:228] Iteration 2430, loss = 0.821006
I0816 19:02:42.650104 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:02:42.650120 20404 solver.cpp:244]     Train net output #1: loss = 0.821006 (* 1 = 0.821006 loss)
I0816 19:02:42.650132 20404 sgd_solver.cpp:106] Iteration 2430, lr = 0.000849467
I0816 19:03:14.066148 20404 solver.cpp:337] Iteration 2440, Testing net (#0)
I0816 19:03:48.735447 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:03:48.735620 20404 solver.cpp:404]     Test net output #1: loss = 0.670873 (* 1 = 0.670873 loss)
I0816 19:03:52.215497 20404 solver.cpp:228] Iteration 2440, loss = 0.820143
I0816 19:03:52.215550 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:03:52.215564 20404 solver.cpp:244]     Train net output #1: loss = 0.820143 (* 1 = 0.820143 loss)
I0816 19:03:52.215576 20404 sgd_solver.cpp:106] Iteration 2440, lr = 0.000848955
I0816 19:04:27.099514 20404 solver.cpp:228] Iteration 2450, loss = 0.820666
I0816 19:04:27.099692 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:04:27.099709 20404 solver.cpp:244]     Train net output #1: loss = 0.820666 (* 1 = 0.820666 loss)
I0816 19:04:27.099720 20404 sgd_solver.cpp:106] Iteration 2450, lr = 0.000848444
I0816 19:05:01.996136 20404 solver.cpp:228] Iteration 2460, loss = 0.820039
I0816 19:05:01.996341 20404 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0816 19:05:01.996358 20404 solver.cpp:244]     Train net output #1: loss = 0.820039 (* 1 = 0.820039 loss)
I0816 19:05:01.996371 20404 sgd_solver.cpp:106] Iteration 2460, lr = 0.000847933
I0816 19:05:36.883199 20404 solver.cpp:228] Iteration 2470, loss = 0.820416
I0816 19:05:36.883390 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:05:36.883406 20404 solver.cpp:244]     Train net output #1: loss = 0.820416 (* 1 = 0.820416 loss)
I0816 19:05:36.883419 20404 sgd_solver.cpp:106] Iteration 2470, lr = 0.000847423
I0816 19:06:08.279171 20404 solver.cpp:337] Iteration 2480, Testing net (#0)
I0816 19:06:42.942845 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:06:42.943011 20404 solver.cpp:404]     Test net output #1: loss = 0.670137 (* 1 = 0.670137 loss)
I0816 19:06:46.417796 20404 solver.cpp:228] Iteration 2480, loss = 0.821087
I0816 19:06:46.417850 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:06:46.417863 20404 solver.cpp:244]     Train net output #1: loss = 0.821087 (* 1 = 0.821087 loss)
I0816 19:06:46.417876 20404 sgd_solver.cpp:106] Iteration 2480, lr = 0.000846914
I0816 19:07:21.282052 20404 solver.cpp:228] Iteration 2490, loss = 0.821491
I0816 19:07:21.282160 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:07:21.282174 20404 solver.cpp:244]     Train net output #1: loss = 0.821491 (* 1 = 0.821491 loss)
I0816 19:07:21.282186 20404 sgd_solver.cpp:106] Iteration 2490, lr = 0.000846405
I0816 19:07:56.173921 20404 solver.cpp:228] Iteration 2500, loss = 0.820492
I0816 19:07:56.174087 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:07:56.174103 20404 solver.cpp:244]     Train net output #1: loss = 0.820492 (* 1 = 0.820492 loss)
I0816 19:07:56.174114 20404 sgd_solver.cpp:106] Iteration 2500, lr = 0.000845897
I0816 19:08:31.079526 20404 solver.cpp:228] Iteration 2510, loss = 0.820361
I0816 19:08:31.079702 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:08:31.079720 20404 solver.cpp:244]     Train net output #1: loss = 0.820361 (* 1 = 0.820361 loss)
I0816 19:08:31.079732 20404 sgd_solver.cpp:106] Iteration 2510, lr = 0.00084539
I0816 19:09:02.497695 20404 solver.cpp:337] Iteration 2520, Testing net (#0)
I0816 19:09:37.139438 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:09:37.139618 20404 solver.cpp:404]     Test net output #1: loss = 0.670221 (* 1 = 0.670221 loss)
I0816 19:09:40.612478 20404 solver.cpp:228] Iteration 2520, loss = 0.820984
I0816 19:09:40.612529 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:09:40.612545 20404 solver.cpp:244]     Train net output #1: loss = 0.820984 (* 1 = 0.820984 loss)
I0816 19:09:40.612556 20404 sgd_solver.cpp:106] Iteration 2520, lr = 0.000844883
I0816 19:10:15.488296 20404 solver.cpp:228] Iteration 2530, loss = 0.820352
I0816 19:10:15.488487 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:10:15.488502 20404 solver.cpp:244]     Train net output #1: loss = 0.820352 (* 1 = 0.820352 loss)
I0816 19:10:15.488515 20404 sgd_solver.cpp:106] Iteration 2530, lr = 0.000844378
I0816 19:10:50.410871 20404 solver.cpp:228] Iteration 2540, loss = 0.822367
I0816 19:10:50.411048 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:10:50.411063 20404 solver.cpp:244]     Train net output #1: loss = 0.822367 (* 1 = 0.822367 loss)
I0816 19:10:50.411077 20404 sgd_solver.cpp:106] Iteration 2540, lr = 0.000843873
I0816 19:11:25.286039 20404 solver.cpp:228] Iteration 2550, loss = 0.821457
I0816 19:11:25.286222 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:11:25.286239 20404 solver.cpp:244]     Train net output #1: loss = 0.821457 (* 1 = 0.821457 loss)
I0816 19:11:25.286253 20404 sgd_solver.cpp:106] Iteration 2550, lr = 0.000843368
I0816 19:11:56.700871 20404 solver.cpp:337] Iteration 2560, Testing net (#0)
I0816 19:12:31.352571 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:12:31.352752 20404 solver.cpp:404]     Test net output #1: loss = 0.671604 (* 1 = 0.671604 loss)
I0816 19:12:34.830302 20404 solver.cpp:228] Iteration 2560, loss = 0.820364
I0816 19:12:34.830353 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:12:34.830368 20404 solver.cpp:244]     Train net output #1: loss = 0.820364 (* 1 = 0.820364 loss)
I0816 19:12:34.830379 20404 sgd_solver.cpp:106] Iteration 2560, lr = 0.000842865
I0816 19:13:09.713747 20404 solver.cpp:228] Iteration 2570, loss = 0.822149
I0816 19:13:09.713929 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:13:09.713944 20404 solver.cpp:244]     Train net output #1: loss = 0.822149 (* 1 = 0.822149 loss)
I0816 19:13:09.713958 20404 sgd_solver.cpp:106] Iteration 2570, lr = 0.000842362
I0816 19:13:44.612438 20404 solver.cpp:228] Iteration 2580, loss = 0.821178
I0816 19:13:44.612538 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:13:44.612555 20404 solver.cpp:244]     Train net output #1: loss = 0.821178 (* 1 = 0.821178 loss)
I0816 19:13:44.612567 20404 sgd_solver.cpp:106] Iteration 2580, lr = 0.000841859
I0816 19:14:19.505352 20404 solver.cpp:228] Iteration 2590, loss = 0.82019
I0816 19:14:19.505528 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:14:19.505543 20404 solver.cpp:244]     Train net output #1: loss = 0.82019 (* 1 = 0.82019 loss)
I0816 19:14:19.505555 20404 sgd_solver.cpp:106] Iteration 2590, lr = 0.000841358
I0816 19:14:50.913251 20404 solver.cpp:337] Iteration 2600, Testing net (#0)
I0816 19:15:25.578328 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:15:25.578500 20404 solver.cpp:404]     Test net output #1: loss = 0.671842 (* 1 = 0.671842 loss)
I0816 19:15:29.060884 20404 solver.cpp:228] Iteration 2600, loss = 0.8205
I0816 19:15:29.060930 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:15:29.060943 20404 solver.cpp:244]     Train net output #1: loss = 0.8205 (* 1 = 0.8205 loss)
I0816 19:15:29.060958 20404 sgd_solver.cpp:106] Iteration 2600, lr = 0.000840857
I0816 19:16:03.940279 20404 solver.cpp:228] Iteration 2610, loss = 0.820463
I0816 19:16:03.940459 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:16:03.940474 20404 solver.cpp:244]     Train net output #1: loss = 0.820463 (* 1 = 0.820463 loss)
I0816 19:16:03.940485 20404 sgd_solver.cpp:106] Iteration 2610, lr = 0.000840357
I0816 19:16:38.820170 20404 solver.cpp:228] Iteration 2620, loss = 0.820321
I0816 19:16:38.820277 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:16:38.820292 20404 solver.cpp:244]     Train net output #1: loss = 0.820321 (* 1 = 0.820321 loss)
I0816 19:16:38.820305 20404 sgd_solver.cpp:106] Iteration 2620, lr = 0.000839857
I0816 19:17:13.718163 20404 solver.cpp:228] Iteration 2630, loss = 0.820037
I0816 19:17:13.718341 20404 solver.cpp:244]     Train net output #0: accuracy = 0.67
I0816 19:17:13.718356 20404 solver.cpp:244]     Train net output #1: loss = 0.820037 (* 1 = 0.820037 loss)
I0816 19:17:13.718369 20404 sgd_solver.cpp:106] Iteration 2630, lr = 0.000839359
I0816 19:17:45.103970 20404 solver.cpp:337] Iteration 2640, Testing net (#0)
I0816 19:18:19.746592 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:18:19.746767 20404 solver.cpp:404]     Test net output #1: loss = 0.670134 (* 1 = 0.670134 loss)
I0816 19:18:23.222057 20404 solver.cpp:228] Iteration 2640, loss = 0.821089
I0816 19:18:23.222110 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:18:23.222126 20404 solver.cpp:244]     Train net output #1: loss = 0.821089 (* 1 = 0.821089 loss)
I0816 19:18:23.222137 20404 sgd_solver.cpp:106] Iteration 2640, lr = 0.00083886
I0816 19:18:58.120826 20404 solver.cpp:228] Iteration 2650, loss = 0.820534
I0816 19:18:58.121045 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:18:58.121062 20404 solver.cpp:244]     Train net output #1: loss = 0.820534 (* 1 = 0.820534 loss)
I0816 19:18:58.121075 20404 sgd_solver.cpp:106] Iteration 2650, lr = 0.000838363
I0816 19:19:33.012949 20404 solver.cpp:228] Iteration 2660, loss = 0.820117
I0816 19:19:33.013129 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:19:33.013145 20404 solver.cpp:244]     Train net output #1: loss = 0.820117 (* 1 = 0.820117 loss)
I0816 19:19:33.013159 20404 sgd_solver.cpp:106] Iteration 2660, lr = 0.000837866
I0816 19:20:07.907038 20404 solver.cpp:228] Iteration 2670, loss = 0.820187
I0816 19:20:07.907202 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:20:07.907219 20404 solver.cpp:244]     Train net output #1: loss = 0.820187 (* 1 = 0.820187 loss)
I0816 19:20:07.907232 20404 sgd_solver.cpp:106] Iteration 2670, lr = 0.00083737
I0816 19:20:39.305377 20404 solver.cpp:337] Iteration 2680, Testing net (#0)
I0816 19:21:13.960336 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:21:13.960505 20404 solver.cpp:404]     Test net output #1: loss = 0.671263 (* 1 = 0.671263 loss)
I0816 19:21:17.435814 20404 solver.cpp:228] Iteration 2680, loss = 0.820168
I0816 19:21:17.435873 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:21:17.435888 20404 solver.cpp:244]     Train net output #1: loss = 0.820168 (* 1 = 0.820168 loss)
I0816 19:21:17.435901 20404 sgd_solver.cpp:106] Iteration 2680, lr = 0.000836875
I0816 19:21:52.327040 20404 solver.cpp:228] Iteration 2690, loss = 0.820242
I0816 19:21:52.327217 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:21:52.327234 20404 solver.cpp:244]     Train net output #1: loss = 0.820242 (* 1 = 0.820242 loss)
I0816 19:21:52.327247 20404 sgd_solver.cpp:106] Iteration 2690, lr = 0.00083638
I0816 19:22:27.220126 20404 solver.cpp:228] Iteration 2700, loss = 0.820373
I0816 19:22:27.220304 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:22:27.220320 20404 solver.cpp:244]     Train net output #1: loss = 0.820373 (* 1 = 0.820373 loss)
I0816 19:22:27.220333 20404 sgd_solver.cpp:106] Iteration 2700, lr = 0.000835886
I0816 19:23:02.114595 20404 solver.cpp:228] Iteration 2710, loss = 0.821108
I0816 19:23:02.114681 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:23:02.114696 20404 solver.cpp:244]     Train net output #1: loss = 0.821108 (* 1 = 0.821108 loss)
I0816 19:23:02.114707 20404 sgd_solver.cpp:106] Iteration 2710, lr = 0.000835393
I0816 19:23:33.549482 20404 solver.cpp:337] Iteration 2720, Testing net (#0)
I0816 19:24:08.199170 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:24:08.199254 20404 solver.cpp:404]     Test net output #1: loss = 0.671218 (* 1 = 0.671218 loss)
I0816 19:24:11.677748 20404 solver.cpp:228] Iteration 2720, loss = 0.820142
I0816 19:24:11.677798 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:24:11.677812 20404 solver.cpp:244]     Train net output #1: loss = 0.820142 (* 1 = 0.820142 loss)
I0816 19:24:11.677825 20404 sgd_solver.cpp:106] Iteration 2720, lr = 0.0008349
I0816 19:24:46.559964 20404 solver.cpp:228] Iteration 2730, loss = 0.821333
I0816 19:24:46.560139 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:24:46.560155 20404 solver.cpp:244]     Train net output #1: loss = 0.821333 (* 1 = 0.821333 loss)
I0816 19:24:46.560168 20404 sgd_solver.cpp:106] Iteration 2730, lr = 0.000834409
I0816 19:25:21.444609 20404 solver.cpp:228] Iteration 2740, loss = 0.820491
I0816 19:25:21.444782 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:25:21.444798 20404 solver.cpp:244]     Train net output #1: loss = 0.820491 (* 1 = 0.820491 loss)
I0816 19:25:21.444811 20404 sgd_solver.cpp:106] Iteration 2740, lr = 0.000833917
I0816 19:25:56.327260 20404 solver.cpp:228] Iteration 2750, loss = 0.820335
I0816 19:25:56.327440 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:25:56.327455 20404 solver.cpp:244]     Train net output #1: loss = 0.820335 (* 1 = 0.820335 loss)
I0816 19:25:56.327466 20404 sgd_solver.cpp:106] Iteration 2750, lr = 0.000833427
I0816 19:26:27.758285 20404 solver.cpp:337] Iteration 2760, Testing net (#0)
I0816 19:27:02.396412 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:27:02.396589 20404 solver.cpp:404]     Test net output #1: loss = 0.67177 (* 1 = 0.67177 loss)
I0816 19:27:05.873742 20404 solver.cpp:228] Iteration 2760, loss = 0.820448
I0816 19:27:05.873795 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:27:05.873808 20404 solver.cpp:244]     Train net output #1: loss = 0.820448 (* 1 = 0.820448 loss)
I0816 19:27:05.873821 20404 sgd_solver.cpp:106] Iteration 2760, lr = 0.000832937
I0816 19:27:40.729701 20404 solver.cpp:228] Iteration 2770, loss = 0.821174
I0816 19:27:40.729811 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:27:40.729827 20404 solver.cpp:244]     Train net output #1: loss = 0.821174 (* 1 = 0.821174 loss)
I0816 19:27:40.729840 20404 sgd_solver.cpp:106] Iteration 2770, lr = 0.000832447
I0816 19:28:15.588732 20404 solver.cpp:228] Iteration 2780, loss = 0.820076
I0816 19:28:15.588912 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:28:15.588927 20404 solver.cpp:244]     Train net output #1: loss = 0.820076 (* 1 = 0.820076 loss)
I0816 19:28:15.588939 20404 sgd_solver.cpp:106] Iteration 2780, lr = 0.000831959
I0816 19:28:50.477200 20404 solver.cpp:228] Iteration 2790, loss = 0.820967
I0816 19:28:50.477372 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:28:50.477388 20404 solver.cpp:244]     Train net output #1: loss = 0.820967 (* 1 = 0.820967 loss)
I0816 19:28:50.477401 20404 sgd_solver.cpp:106] Iteration 2790, lr = 0.000831471
I0816 19:29:21.888118 20404 solver.cpp:337] Iteration 2800, Testing net (#0)
I0816 19:29:56.546645 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:29:56.546813 20404 solver.cpp:404]     Test net output #1: loss = 0.671157 (* 1 = 0.671157 loss)
I0816 19:30:00.026120 20404 solver.cpp:228] Iteration 2800, loss = 0.820099
I0816 19:30:00.026175 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:30:00.026188 20404 solver.cpp:244]     Train net output #1: loss = 0.820099 (* 1 = 0.820099 loss)
I0816 19:30:00.026201 20404 sgd_solver.cpp:106] Iteration 2800, lr = 0.000830984
I0816 19:30:34.922036 20404 solver.cpp:228] Iteration 2810, loss = 0.82065
I0816 19:30:34.922157 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:30:34.922175 20404 solver.cpp:244]     Train net output #1: loss = 0.82065 (* 1 = 0.82065 loss)
I0816 19:30:34.922191 20404 sgd_solver.cpp:106] Iteration 2810, lr = 0.000830497
I0816 19:31:09.808290 20404 solver.cpp:228] Iteration 2820, loss = 0.820349
I0816 19:31:09.808470 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:31:09.808490 20404 solver.cpp:244]     Train net output #1: loss = 0.820349 (* 1 = 0.820349 loss)
I0816 19:31:09.808506 20404 sgd_solver.cpp:106] Iteration 2820, lr = 0.000830011
I0816 19:31:44.684589 20404 solver.cpp:228] Iteration 2830, loss = 0.821068
I0816 19:31:44.684770 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:31:44.684785 20404 solver.cpp:244]     Train net output #1: loss = 0.821068 (* 1 = 0.821068 loss)
I0816 19:31:44.684798 20404 sgd_solver.cpp:106] Iteration 2830, lr = 0.000829526
I0816 19:32:16.098323 20404 solver.cpp:337] Iteration 2840, Testing net (#0)
I0816 19:32:50.754783 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:32:50.754956 20404 solver.cpp:404]     Test net output #1: loss = 0.67122 (* 1 = 0.67122 loss)
I0816 19:32:54.233162 20404 solver.cpp:228] Iteration 2840, loss = 0.820132
I0816 19:32:54.233216 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:32:54.233229 20404 solver.cpp:244]     Train net output #1: loss = 0.820132 (* 1 = 0.820132 loss)
I0816 19:32:54.233242 20404 sgd_solver.cpp:106] Iteration 2840, lr = 0.000829042
I0816 19:33:29.100018 20404 solver.cpp:228] Iteration 2850, loss = 0.820598
I0816 19:33:29.100152 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:33:29.100168 20404 solver.cpp:244]     Train net output #1: loss = 0.820598 (* 1 = 0.820598 loss)
I0816 19:33:29.100183 20404 sgd_solver.cpp:106] Iteration 2850, lr = 0.000828558
I0816 19:34:03.993981 20404 solver.cpp:228] Iteration 2860, loss = 0.820518
I0816 19:34:03.994086 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:34:03.994101 20404 solver.cpp:244]     Train net output #1: loss = 0.820518 (* 1 = 0.820518 loss)
I0816 19:34:03.994112 20404 sgd_solver.cpp:106] Iteration 2860, lr = 0.000828074
I0816 19:34:38.891453 20404 solver.cpp:228] Iteration 2870, loss = 0.821634
I0816 19:34:38.891636 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:34:38.891652 20404 solver.cpp:244]     Train net output #1: loss = 0.821634 (* 1 = 0.821634 loss)
I0816 19:34:38.891665 20404 sgd_solver.cpp:106] Iteration 2870, lr = 0.000827592
I0816 19:35:10.295153 20404 solver.cpp:337] Iteration 2880, Testing net (#0)
I0816 19:35:44.948252 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:35:44.948424 20404 solver.cpp:404]     Test net output #1: loss = 0.67097 (* 1 = 0.67097 loss)
I0816 19:35:48.425940 20404 solver.cpp:228] Iteration 2880, loss = 0.820055
I0816 19:35:48.425983 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:35:48.426002 20404 solver.cpp:244]     Train net output #1: loss = 0.820055 (* 1 = 0.820055 loss)
I0816 19:35:48.426028 20404 sgd_solver.cpp:106] Iteration 2880, lr = 0.00082711
I0816 19:36:23.322012 20404 solver.cpp:228] Iteration 2890, loss = 0.820688
I0816 19:36:23.322187 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:36:23.322202 20404 solver.cpp:244]     Train net output #1: loss = 0.820688 (* 1 = 0.820688 loss)
I0816 19:36:23.322214 20404 sgd_solver.cpp:106] Iteration 2890, lr = 0.000826628
I0816 19:36:58.213435 20404 solver.cpp:228] Iteration 2900, loss = 0.821019
I0816 19:36:58.213613 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:36:58.213629 20404 solver.cpp:244]     Train net output #1: loss = 0.821019 (* 1 = 0.821019 loss)
I0816 19:36:58.213641 20404 sgd_solver.cpp:106] Iteration 2900, lr = 0.000826148
I0816 19:37:33.112496 20404 solver.cpp:228] Iteration 2910, loss = 0.820344
I0816 19:37:33.112671 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:37:33.112687 20404 solver.cpp:244]     Train net output #1: loss = 0.820344 (* 1 = 0.820344 loss)
I0816 19:37:33.112701 20404 sgd_solver.cpp:106] Iteration 2910, lr = 0.000825668
I0816 19:38:04.505401 20404 solver.cpp:337] Iteration 2920, Testing net (#0)
I0816 19:38:39.157743 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:38:39.157930 20404 solver.cpp:404]     Test net output #1: loss = 0.671023 (* 1 = 0.671023 loss)
I0816 19:38:42.633563 20404 solver.cpp:228] Iteration 2920, loss = 0.820022
I0816 19:38:42.633615 20404 solver.cpp:244]     Train net output #0: accuracy = 0.86
I0816 19:38:42.633628 20404 solver.cpp:244]     Train net output #1: loss = 0.820022 (* 1 = 0.820022 loss)
I0816 19:38:42.633641 20404 sgd_solver.cpp:106] Iteration 2920, lr = 0.000825188
I0816 19:39:17.516998 20404 solver.cpp:228] Iteration 2930, loss = 0.820023
I0816 19:39:17.517170 20404 solver.cpp:244]     Train net output #0: accuracy = 0.86
I0816 19:39:17.517186 20404 solver.cpp:244]     Train net output #1: loss = 0.820023 (* 1 = 0.820023 loss)
I0816 19:39:17.517199 20404 sgd_solver.cpp:106] Iteration 2930, lr = 0.00082471
I0816 19:39:52.396860 20404 solver.cpp:228] Iteration 2940, loss = 0.821433
I0816 19:39:52.396970 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:39:52.396989 20404 solver.cpp:244]     Train net output #1: loss = 0.821433 (* 1 = 0.821433 loss)
I0816 19:39:52.397004 20404 sgd_solver.cpp:106] Iteration 2940, lr = 0.000824232
I0816 19:40:27.286788 20404 solver.cpp:228] Iteration 2950, loss = 0.82047
I0816 19:40:27.287019 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:40:27.287035 20404 solver.cpp:244]     Train net output #1: loss = 0.82047 (* 1 = 0.82047 loss)
I0816 19:40:27.287047 20404 sgd_solver.cpp:106] Iteration 2950, lr = 0.000823754
I0816 19:40:58.698315 20404 solver.cpp:337] Iteration 2960, Testing net (#0)
I0816 19:41:33.317173 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:41:33.317247 20404 solver.cpp:404]     Test net output #1: loss = 0.671364 (* 1 = 0.671364 loss)
I0816 19:41:36.791954 20404 solver.cpp:228] Iteration 2960, loss = 0.820208
I0816 19:41:36.792006 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:41:36.792021 20404 solver.cpp:244]     Train net output #1: loss = 0.820208 (* 1 = 0.820208 loss)
I0816 19:41:36.792033 20404 sgd_solver.cpp:106] Iteration 2960, lr = 0.000823278
I0816 19:42:11.667798 20404 solver.cpp:228] Iteration 2970, loss = 0.820592
I0816 19:42:11.667979 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:42:11.667994 20404 solver.cpp:244]     Train net output #1: loss = 0.820592 (* 1 = 0.820592 loss)
I0816 19:42:11.668007 20404 sgd_solver.cpp:106] Iteration 2970, lr = 0.000822801
I0816 19:42:46.547035 20404 solver.cpp:228] Iteration 2980, loss = 0.820523
I0816 19:42:46.547219 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:42:46.547233 20404 solver.cpp:244]     Train net output #1: loss = 0.820523 (* 1 = 0.820523 loss)
I0816 19:42:46.547246 20404 sgd_solver.cpp:106] Iteration 2980, lr = 0.000822326
I0816 19:43:21.413255 20404 solver.cpp:228] Iteration 2990, loss = 0.820078
I0816 19:43:21.413429 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:43:21.413444 20404 solver.cpp:244]     Train net output #1: loss = 0.820078 (* 1 = 0.820078 loss)
I0816 19:43:21.413456 20404 sgd_solver.cpp:106] Iteration 2990, lr = 0.000821851
I0816 19:43:52.808277 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_3000.caffemodel
I0816 19:44:12.300629 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_3000.solverstate
I0816 19:44:14.057854 20404 solver.cpp:337] Iteration 3000, Testing net (#0)
I0816 19:44:48.689414 20404 solver.cpp:404]     Test net output #0: accuracy = 0.86
I0816 19:44:48.689584 20404 solver.cpp:404]     Test net output #1: loss = 0.670028 (* 1 = 0.670028 loss)
I0816 19:44:52.164191 20404 solver.cpp:228] Iteration 3000, loss = 0.821306
I0816 19:44:52.164247 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:44:52.164261 20404 solver.cpp:244]     Train net output #1: loss = 0.821306 (* 1 = 0.821306 loss)
I0816 19:44:52.164274 20404 sgd_solver.cpp:106] Iteration 3000, lr = 0.000821377
I0816 19:45:27.030311 20404 solver.cpp:228] Iteration 3010, loss = 0.820207
I0816 19:45:27.030495 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:45:27.030511 20404 solver.cpp:244]     Train net output #1: loss = 0.820207 (* 1 = 0.820207 loss)
I0816 19:45:27.030524 20404 sgd_solver.cpp:106] Iteration 3010, lr = 0.000820903
I0816 19:46:01.939048 20404 solver.cpp:228] Iteration 3020, loss = 0.820615
I0816 19:46:01.939227 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:46:01.939244 20404 solver.cpp:244]     Train net output #1: loss = 0.820615 (* 1 = 0.820615 loss)
I0816 19:46:01.939257 20404 sgd_solver.cpp:106] Iteration 3020, lr = 0.00082043
I0816 19:46:36.865000 20404 solver.cpp:228] Iteration 3030, loss = 0.820974
I0816 19:46:36.865177 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:46:36.865193 20404 solver.cpp:244]     Train net output #1: loss = 0.820974 (* 1 = 0.820974 loss)
I0816 19:46:36.865206 20404 sgd_solver.cpp:106] Iteration 3030, lr = 0.000819958
I0816 19:47:08.492599 20404 solver.cpp:337] Iteration 3040, Testing net (#0)
I0816 19:47:43.364651 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:47:43.364825 20404 solver.cpp:404]     Test net output #1: loss = 0.671607 (* 1 = 0.671607 loss)
I0816 19:47:46.866884 20404 solver.cpp:228] Iteration 3040, loss = 0.820339
I0816 19:47:46.866936 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:47:46.866950 20404 solver.cpp:244]     Train net output #1: loss = 0.820339 (* 1 = 0.820339 loss)
I0816 19:47:46.866962 20404 sgd_solver.cpp:106] Iteration 3040, lr = 0.000819487
I0816 19:48:21.978467 20404 solver.cpp:228] Iteration 3050, loss = 0.820451
I0816 19:48:21.978684 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:48:21.978700 20404 solver.cpp:244]     Train net output #1: loss = 0.820451 (* 1 = 0.820451 loss)
I0816 19:48:21.978713 20404 sgd_solver.cpp:106] Iteration 3050, lr = 0.000819015
I0816 19:48:57.101091 20404 solver.cpp:228] Iteration 3060, loss = 0.820649
I0816 19:48:57.101202 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:48:57.101218 20404 solver.cpp:244]     Train net output #1: loss = 0.820649 (* 1 = 0.820649 loss)
I0816 19:48:57.101230 20404 sgd_solver.cpp:106] Iteration 3060, lr = 0.000818545
I0816 19:49:32.189481 20404 solver.cpp:228] Iteration 3070, loss = 0.821598
I0816 19:49:32.189668 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:49:32.189684 20404 solver.cpp:244]     Train net output #1: loss = 0.821598 (* 1 = 0.821598 loss)
I0816 19:49:32.189697 20404 sgd_solver.cpp:106] Iteration 3070, lr = 0.000818075
I0816 19:50:03.789394 20404 solver.cpp:337] Iteration 3080, Testing net (#0)
I0816 19:50:38.669518 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:50:38.669689 20404 solver.cpp:404]     Test net output #1: loss = 0.671052 (* 1 = 0.671052 loss)
I0816 19:50:42.175735 20404 solver.cpp:228] Iteration 3080, loss = 0.820025
I0816 19:50:42.175777 20404 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0816 19:50:42.175792 20404 solver.cpp:244]     Train net output #1: loss = 0.820025 (* 1 = 0.820025 loss)
I0816 19:50:42.175806 20404 sgd_solver.cpp:106] Iteration 3080, lr = 0.000817606
I0816 19:51:17.290709 20404 solver.cpp:228] Iteration 3090, loss = 0.820499
I0816 19:51:17.290875 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:51:17.290891 20404 solver.cpp:244]     Train net output #1: loss = 0.820499 (* 1 = 0.820499 loss)
I0816 19:51:17.290904 20404 sgd_solver.cpp:106] Iteration 3090, lr = 0.000817138
I0816 19:51:52.436174 20404 solver.cpp:228] Iteration 3100, loss = 0.820033
I0816 19:51:52.436354 20404 solver.cpp:244]     Train net output #0: accuracy = 0.68
I0816 19:51:52.436370 20404 solver.cpp:244]     Train net output #1: loss = 0.820033 (* 1 = 0.820033 loss)
I0816 19:51:52.436383 20404 sgd_solver.cpp:106] Iteration 3100, lr = 0.00081667
I0816 19:52:27.533067 20404 solver.cpp:228] Iteration 3110, loss = 0.82111
I0816 19:52:27.533243 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:52:27.533262 20404 solver.cpp:244]     Train net output #1: loss = 0.82111 (* 1 = 0.82111 loss)
I0816 19:52:27.533274 20404 sgd_solver.cpp:106] Iteration 3110, lr = 0.000816203
I0816 19:52:59.136689 20404 solver.cpp:337] Iteration 3120, Testing net (#0)
I0816 19:53:34.013242 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:53:34.013413 20404 solver.cpp:404]     Test net output #1: loss = 0.670569 (* 1 = 0.670569 loss)
I0816 19:53:37.508751 20404 solver.cpp:228] Iteration 3120, loss = 0.820595
I0816 19:53:37.508801 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:53:37.508816 20404 solver.cpp:244]     Train net output #1: loss = 0.820595 (* 1 = 0.820595 loss)
I0816 19:53:37.508828 20404 sgd_solver.cpp:106] Iteration 3120, lr = 0.000815736
I0816 19:54:12.636056 20404 solver.cpp:228] Iteration 3130, loss = 0.821179
I0816 19:54:12.636224 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:54:12.636240 20404 solver.cpp:244]     Train net output #1: loss = 0.821179 (* 1 = 0.821179 loss)
I0816 19:54:12.636252 20404 sgd_solver.cpp:106] Iteration 3130, lr = 0.00081527
I0816 19:54:47.795214 20404 solver.cpp:228] Iteration 3140, loss = 0.820653
I0816 19:54:47.795429 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:54:47.795445 20404 solver.cpp:244]     Train net output #1: loss = 0.820653 (* 1 = 0.820653 loss)
I0816 19:54:47.795461 20404 sgd_solver.cpp:106] Iteration 3140, lr = 0.000814805
I0816 19:55:22.908956 20404 solver.cpp:228] Iteration 3150, loss = 0.820178
I0816 19:55:22.909134 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 19:55:22.909149 20404 solver.cpp:244]     Train net output #1: loss = 0.820178 (* 1 = 0.820178 loss)
I0816 19:55:22.909162 20404 sgd_solver.cpp:106] Iteration 3150, lr = 0.00081434
I0816 19:55:54.530594 20404 solver.cpp:337] Iteration 3160, Testing net (#0)
I0816 19:56:29.423141 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:56:29.423308 20404 solver.cpp:404]     Test net output #1: loss = 0.670549 (* 1 = 0.670549 loss)
I0816 19:56:32.922091 20404 solver.cpp:228] Iteration 3160, loss = 0.820631
I0816 19:56:32.922145 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:56:32.922160 20404 solver.cpp:244]     Train net output #1: loss = 0.820631 (* 1 = 0.820631 loss)
I0816 19:56:32.922173 20404 sgd_solver.cpp:106] Iteration 3160, lr = 0.000813876
I0816 19:57:08.054661 20404 solver.cpp:228] Iteration 3170, loss = 0.82049
I0816 19:57:08.054843 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:57:08.054860 20404 solver.cpp:244]     Train net output #1: loss = 0.82049 (* 1 = 0.82049 loss)
I0816 19:57:08.054872 20404 sgd_solver.cpp:106] Iteration 3170, lr = 0.000813412
I0816 19:57:43.186488 20404 solver.cpp:228] Iteration 3180, loss = 0.821897
I0816 19:57:43.186667 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:57:43.186682 20404 solver.cpp:244]     Train net output #1: loss = 0.821897 (* 1 = 0.821897 loss)
I0816 19:57:43.186696 20404 sgd_solver.cpp:106] Iteration 3180, lr = 0.000812949
I0816 19:58:18.312018 20404 solver.cpp:228] Iteration 3190, loss = 0.820153
I0816 19:58:18.312191 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:58:18.312206 20404 solver.cpp:244]     Train net output #1: loss = 0.820153 (* 1 = 0.820153 loss)
I0816 19:58:18.312219 20404 sgd_solver.cpp:106] Iteration 3190, lr = 0.000812487
I0816 19:58:49.928531 20404 solver.cpp:337] Iteration 3200, Testing net (#0)
I0816 19:59:24.817692 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 19:59:24.817868 20404 solver.cpp:404]     Test net output #1: loss = 0.670354 (* 1 = 0.670354 loss)
I0816 19:59:28.321065 20404 solver.cpp:228] Iteration 3200, loss = 0.820883
I0816 19:59:28.321116 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 19:59:28.321131 20404 solver.cpp:244]     Train net output #1: loss = 0.820883 (* 1 = 0.820883 loss)
I0816 19:59:28.321143 20404 sgd_solver.cpp:106] Iteration 3200, lr = 0.000812025
I0816 20:00:03.432397 20404 solver.cpp:228] Iteration 3210, loss = 0.820811
I0816 20:00:03.432494 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:00:03.432509 20404 solver.cpp:244]     Train net output #1: loss = 0.820811 (* 1 = 0.820811 loss)
I0816 20:00:03.432521 20404 sgd_solver.cpp:106] Iteration 3210, lr = 0.000811564
I0816 20:00:38.543989 20404 solver.cpp:228] Iteration 3220, loss = 0.82046
I0816 20:00:38.544170 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:00:38.544186 20404 solver.cpp:244]     Train net output #1: loss = 0.82046 (* 1 = 0.82046 loss)
I0816 20:00:38.544199 20404 sgd_solver.cpp:106] Iteration 3220, lr = 0.000811104
I0816 20:01:13.675091 20404 solver.cpp:228] Iteration 3230, loss = 0.820026
I0816 20:01:13.675258 20404 solver.cpp:244]     Train net output #0: accuracy = 0.78
I0816 20:01:13.675287 20404 solver.cpp:244]     Train net output #1: loss = 0.820026 (* 1 = 0.820026 loss)
I0816 20:01:13.675299 20404 sgd_solver.cpp:106] Iteration 3230, lr = 0.000810644
I0816 20:01:45.304035 20404 solver.cpp:337] Iteration 3240, Testing net (#0)
I0816 20:02:20.161201 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:02:20.161335 20404 solver.cpp:404]     Test net output #1: loss = 0.671778 (* 1 = 0.671778 loss)
I0816 20:02:23.661552 20404 solver.cpp:228] Iteration 3240, loss = 0.820421
I0816 20:02:23.661602 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:02:23.661617 20404 solver.cpp:244]     Train net output #1: loss = 0.820421 (* 1 = 0.820421 loss)
I0816 20:02:23.661629 20404 sgd_solver.cpp:106] Iteration 3240, lr = 0.000810185
I0816 20:02:58.781204 20404 solver.cpp:228] Iteration 3250, loss = 0.820324
I0816 20:02:58.781390 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:02:58.781406 20404 solver.cpp:244]     Train net output #1: loss = 0.820324 (* 1 = 0.820324 loss)
I0816 20:02:58.781419 20404 sgd_solver.cpp:106] Iteration 3250, lr = 0.000809726
I0816 20:03:33.898000 20404 solver.cpp:228] Iteration 3260, loss = 0.820744
I0816 20:03:33.898174 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:03:33.898190 20404 solver.cpp:244]     Train net output #1: loss = 0.820744 (* 1 = 0.820744 loss)
I0816 20:03:33.898202 20404 sgd_solver.cpp:106] Iteration 3260, lr = 0.000809268
I0816 20:04:09.024065 20404 solver.cpp:228] Iteration 3270, loss = 0.820206
I0816 20:04:09.024226 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:04:09.024241 20404 solver.cpp:244]     Train net output #1: loss = 0.820206 (* 1 = 0.820206 loss)
I0816 20:04:09.024253 20404 sgd_solver.cpp:106] Iteration 3270, lr = 0.000808811
I0816 20:04:40.644915 20404 solver.cpp:337] Iteration 3280, Testing net (#0)
I0816 20:05:15.546568 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:05:15.546746 20404 solver.cpp:404]     Test net output #1: loss = 0.670312 (* 1 = 0.670312 loss)
I0816 20:05:19.052425 20404 solver.cpp:228] Iteration 3280, loss = 0.820947
I0816 20:05:19.052477 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:05:19.052491 20404 solver.cpp:244]     Train net output #1: loss = 0.820947 (* 1 = 0.820947 loss)
I0816 20:05:19.052502 20404 sgd_solver.cpp:106] Iteration 3280, lr = 0.000808354
I0816 20:05:54.165766 20404 solver.cpp:228] Iteration 3290, loss = 0.820153
I0816 20:05:54.165935 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:05:54.165949 20404 solver.cpp:244]     Train net output #1: loss = 0.820153 (* 1 = 0.820153 loss)
I0816 20:05:54.165962 20404 sgd_solver.cpp:106] Iteration 3290, lr = 0.000807898
I0816 20:06:29.306803 20404 solver.cpp:228] Iteration 3300, loss = 0.821412
I0816 20:06:29.306977 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:06:29.306993 20404 solver.cpp:244]     Train net output #1: loss = 0.821412 (* 1 = 0.821412 loss)
I0816 20:06:29.307004 20404 sgd_solver.cpp:106] Iteration 3300, lr = 0.000807442
I0816 20:07:04.444226 20404 solver.cpp:228] Iteration 3310, loss = 0.820168
I0816 20:07:04.444406 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:07:04.444420 20404 solver.cpp:244]     Train net output #1: loss = 0.820168 (* 1 = 0.820168 loss)
I0816 20:07:04.444433 20404 sgd_solver.cpp:106] Iteration 3310, lr = 0.000806987
I0816 20:07:36.052575 20404 solver.cpp:337] Iteration 3320, Testing net (#0)
I0816 20:08:10.928045 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 20:08:10.928218 20404 solver.cpp:404]     Test net output #1: loss = 0.670174 (* 1 = 0.670174 loss)
I0816 20:08:14.431210 20404 solver.cpp:228] Iteration 3320, loss = 0.821572
I0816 20:08:14.431260 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:08:14.431283 20404 solver.cpp:244]     Train net output #1: loss = 0.821572 (* 1 = 0.821572 loss)
I0816 20:08:14.431296 20404 sgd_solver.cpp:106] Iteration 3320, lr = 0.000806532
I0816 20:08:49.558228 20404 solver.cpp:228] Iteration 3330, loss = 0.820996
I0816 20:08:49.558401 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:08:49.558416 20404 solver.cpp:244]     Train net output #1: loss = 0.820996 (* 1 = 0.820996 loss)
I0816 20:08:49.558429 20404 sgd_solver.cpp:106] Iteration 3330, lr = 0.000806079
I0816 20:09:24.694633 20404 solver.cpp:228] Iteration 3340, loss = 0.821079
I0816 20:09:24.694886 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:09:24.694902 20404 solver.cpp:244]     Train net output #1: loss = 0.821079 (* 1 = 0.821079 loss)
I0816 20:09:24.694914 20404 sgd_solver.cpp:106] Iteration 3340, lr = 0.000805625
I0816 20:09:59.821302 20404 solver.cpp:228] Iteration 3350, loss = 0.821393
I0816 20:09:59.821549 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:09:59.821565 20404 solver.cpp:244]     Train net output #1: loss = 0.821393 (* 1 = 0.821393 loss)
I0816 20:09:59.821578 20404 sgd_solver.cpp:106] Iteration 3350, lr = 0.000805173
I0816 20:10:31.445546 20404 solver.cpp:337] Iteration 3360, Testing net (#0)
I0816 20:11:06.316035 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 20:11:06.316195 20404 solver.cpp:404]     Test net output #1: loss = 0.67034 (* 1 = 0.67034 loss)
I0816 20:11:09.812871 20404 solver.cpp:228] Iteration 3360, loss = 0.821784
I0816 20:11:09.812923 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:11:09.812937 20404 solver.cpp:244]     Train net output #1: loss = 0.821784 (* 1 = 0.821784 loss)
I0816 20:11:09.812948 20404 sgd_solver.cpp:106] Iteration 3360, lr = 0.000804721
I0816 20:11:44.908561 20404 solver.cpp:228] Iteration 3370, loss = 0.820845
I0816 20:11:44.908740 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:11:44.908756 20404 solver.cpp:244]     Train net output #1: loss = 0.820845 (* 1 = 0.820845 loss)
I0816 20:11:44.908767 20404 sgd_solver.cpp:106] Iteration 3370, lr = 0.000804269
I0816 20:12:20.020952 20404 solver.cpp:228] Iteration 3380, loss = 0.82042
I0816 20:12:20.021133 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:12:20.021149 20404 solver.cpp:244]     Train net output #1: loss = 0.82042 (* 1 = 0.82042 loss)
I0816 20:12:20.021162 20404 sgd_solver.cpp:106] Iteration 3380, lr = 0.000803818
I0816 20:12:55.124491 20404 solver.cpp:228] Iteration 3390, loss = 0.820394
I0816 20:12:55.124665 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:12:55.124680 20404 solver.cpp:244]     Train net output #1: loss = 0.820394 (* 1 = 0.820394 loss)
I0816 20:12:55.124693 20404 sgd_solver.cpp:106] Iteration 3390, lr = 0.000803368
I0816 20:13:26.752061 20404 solver.cpp:337] Iteration 3400, Testing net (#0)
I0816 20:14:01.645546 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:14:01.645720 20404 solver.cpp:404]     Test net output #1: loss = 0.670678 (* 1 = 0.670678 loss)
I0816 20:14:05.152194 20404 solver.cpp:228] Iteration 3400, loss = 0.820496
I0816 20:14:05.152246 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:14:05.152261 20404 solver.cpp:244]     Train net output #1: loss = 0.820496 (* 1 = 0.820496 loss)
I0816 20:14:05.152272 20404 sgd_solver.cpp:106] Iteration 3400, lr = 0.000802918
I0816 20:14:40.236798 20404 solver.cpp:228] Iteration 3410, loss = 0.820973
I0816 20:14:40.236977 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:14:40.236994 20404 solver.cpp:244]     Train net output #1: loss = 0.820973 (* 1 = 0.820973 loss)
I0816 20:14:40.237006 20404 sgd_solver.cpp:106] Iteration 3410, lr = 0.000802469
I0816 20:15:15.364296 20404 solver.cpp:228] Iteration 3420, loss = 0.820178
I0816 20:15:15.364475 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:15:15.364490 20404 solver.cpp:244]     Train net output #1: loss = 0.820178 (* 1 = 0.820178 loss)
I0816 20:15:15.364502 20404 sgd_solver.cpp:106] Iteration 3420, lr = 0.000802021
I0816 20:15:50.496304 20404 solver.cpp:228] Iteration 3430, loss = 0.821079
I0816 20:15:50.496496 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:15:50.496516 20404 solver.cpp:244]     Train net output #1: loss = 0.821079 (* 1 = 0.821079 loss)
I0816 20:15:50.496531 20404 sgd_solver.cpp:106] Iteration 3430, lr = 0.000801573
I0816 20:16:22.119504 20404 solver.cpp:337] Iteration 3440, Testing net (#0)
I0816 20:16:56.995800 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:16:56.995990 20404 solver.cpp:404]     Test net output #1: loss = 0.670477 (* 1 = 0.670477 loss)
I0816 20:17:00.504642 20404 solver.cpp:228] Iteration 3440, loss = 0.82076
I0816 20:17:00.504681 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:17:00.504696 20404 solver.cpp:244]     Train net output #1: loss = 0.82076 (* 1 = 0.82076 loss)
I0816 20:17:00.504709 20404 sgd_solver.cpp:106] Iteration 3440, lr = 0.000801126
I0816 20:17:35.612864 20404 solver.cpp:228] Iteration 3450, loss = 0.820044
I0816 20:17:35.613046 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0816 20:17:35.613061 20404 solver.cpp:244]     Train net output #1: loss = 0.820044 (* 1 = 0.820044 loss)
I0816 20:17:35.613075 20404 sgd_solver.cpp:106] Iteration 3450, lr = 0.000800679
I0816 20:18:10.737073 20404 solver.cpp:228] Iteration 3460, loss = 0.820084
I0816 20:18:10.737247 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:18:10.737263 20404 solver.cpp:244]     Train net output #1: loss = 0.820084 (* 1 = 0.820084 loss)
I0816 20:18:10.737277 20404 sgd_solver.cpp:106] Iteration 3460, lr = 0.000800233
I0816 20:18:45.862717 20404 solver.cpp:228] Iteration 3470, loss = 0.821391
I0816 20:18:45.862897 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:18:45.862913 20404 solver.cpp:244]     Train net output #1: loss = 0.821391 (* 1 = 0.821391 loss)
I0816 20:18:45.862926 20404 sgd_solver.cpp:106] Iteration 3470, lr = 0.000799787
I0816 20:19:17.487192 20404 solver.cpp:337] Iteration 3480, Testing net (#0)
I0816 20:19:52.379717 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:19:52.379895 20404 solver.cpp:404]     Test net output #1: loss = 0.670633 (* 1 = 0.670633 loss)
I0816 20:19:55.872802 20404 solver.cpp:228] Iteration 3480, loss = 0.820565
I0816 20:19:55.872854 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:19:55.872869 20404 solver.cpp:244]     Train net output #1: loss = 0.820565 (* 1 = 0.820565 loss)
I0816 20:19:55.872880 20404 sgd_solver.cpp:106] Iteration 3480, lr = 0.000799342
I0816 20:20:31.003237 20404 solver.cpp:228] Iteration 3490, loss = 0.820283
I0816 20:20:31.003422 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:20:31.003437 20404 solver.cpp:244]     Train net output #1: loss = 0.820283 (* 1 = 0.820283 loss)
I0816 20:20:31.003450 20404 sgd_solver.cpp:106] Iteration 3490, lr = 0.000798898
I0816 20:21:06.133319 20404 solver.cpp:228] Iteration 3500, loss = 0.820277
I0816 20:21:06.133496 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:21:06.133512 20404 solver.cpp:244]     Train net output #1: loss = 0.820277 (* 1 = 0.820277 loss)
I0816 20:21:06.133525 20404 sgd_solver.cpp:106] Iteration 3500, lr = 0.000798454
I0816 20:21:41.249694 20404 solver.cpp:228] Iteration 3510, loss = 0.820097
I0816 20:21:41.249877 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:21:41.249892 20404 solver.cpp:244]     Train net output #1: loss = 0.820097 (* 1 = 0.820097 loss)
I0816 20:21:41.249904 20404 sgd_solver.cpp:106] Iteration 3510, lr = 0.00079801
I0816 20:22:12.864271 20404 solver.cpp:337] Iteration 3520, Testing net (#0)
I0816 20:22:47.743810 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:22:47.743999 20404 solver.cpp:404]     Test net output #1: loss = 0.670614 (* 1 = 0.670614 loss)
I0816 20:22:51.237593 20404 solver.cpp:228] Iteration 3520, loss = 0.820589
I0816 20:22:51.237644 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:22:51.237658 20404 solver.cpp:244]     Train net output #1: loss = 0.820589 (* 1 = 0.820589 loss)
I0816 20:22:51.237670 20404 sgd_solver.cpp:106] Iteration 3520, lr = 0.000797568
I0816 20:23:26.335237 20404 solver.cpp:228] Iteration 3530, loss = 0.82018
I0816 20:23:26.335412 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:23:26.335427 20404 solver.cpp:244]     Train net output #1: loss = 0.82018 (* 1 = 0.82018 loss)
I0816 20:23:26.335440 20404 sgd_solver.cpp:106] Iteration 3530, lr = 0.000797125
I0816 20:24:01.471457 20404 solver.cpp:228] Iteration 3540, loss = 0.820148
I0816 20:24:01.471624 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:24:01.471640 20404 solver.cpp:244]     Train net output #1: loss = 0.820148 (* 1 = 0.820148 loss)
I0816 20:24:01.471653 20404 sgd_solver.cpp:106] Iteration 3540, lr = 0.000796684
I0816 20:24:36.612916 20404 solver.cpp:228] Iteration 3550, loss = 0.821732
I0816 20:24:36.613096 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:24:36.613112 20404 solver.cpp:244]     Train net output #1: loss = 0.821732 (* 1 = 0.821732 loss)
I0816 20:24:36.613124 20404 sgd_solver.cpp:106] Iteration 3550, lr = 0.000796243
I0816 20:25:08.233500 20404 solver.cpp:337] Iteration 3560, Testing net (#0)
I0816 20:25:43.090445 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:25:43.090620 20404 solver.cpp:404]     Test net output #1: loss = 0.670753 (* 1 = 0.670753 loss)
I0816 20:25:46.594322 20404 solver.cpp:228] Iteration 3560, loss = 0.820417
I0816 20:25:46.594367 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:25:46.594384 20404 solver.cpp:244]     Train net output #1: loss = 0.820417 (* 1 = 0.820417 loss)
I0816 20:25:46.594410 20404 sgd_solver.cpp:106] Iteration 3560, lr = 0.000795802
I0816 20:26:21.740126 20404 solver.cpp:228] Iteration 3570, loss = 0.820721
I0816 20:26:21.740303 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:26:21.740324 20404 solver.cpp:244]     Train net output #1: loss = 0.820721 (* 1 = 0.820721 loss)
I0816 20:26:21.740339 20404 sgd_solver.cpp:106] Iteration 3570, lr = 0.000795363
I0816 20:26:56.872756 20404 solver.cpp:228] Iteration 3580, loss = 0.820931
I0816 20:26:56.872866 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:26:56.872881 20404 solver.cpp:244]     Train net output #1: loss = 0.820931 (* 1 = 0.820931 loss)
I0816 20:26:56.872895 20404 sgd_solver.cpp:106] Iteration 3580, lr = 0.000794923
I0816 20:27:31.987771 20404 solver.cpp:228] Iteration 3590, loss = 0.820349
I0816 20:27:31.987949 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:27:31.987964 20404 solver.cpp:244]     Train net output #1: loss = 0.820349 (* 1 = 0.820349 loss)
I0816 20:27:31.987977 20404 sgd_solver.cpp:106] Iteration 3590, lr = 0.000794485
I0816 20:28:03.622767 20404 solver.cpp:337] Iteration 3600, Testing net (#0)
I0816 20:28:38.514719 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:28:38.514892 20404 solver.cpp:404]     Test net output #1: loss = 0.670555 (* 1 = 0.670555 loss)
I0816 20:28:42.017236 20404 solver.cpp:228] Iteration 3600, loss = 0.820677
I0816 20:28:42.017287 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:28:42.017302 20404 solver.cpp:244]     Train net output #1: loss = 0.820677 (* 1 = 0.820677 loss)
I0816 20:28:42.017313 20404 sgd_solver.cpp:106] Iteration 3600, lr = 0.000794046
I0816 20:29:17.146761 20404 solver.cpp:228] Iteration 3610, loss = 0.820068
I0816 20:29:17.146946 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:29:17.146965 20404 solver.cpp:244]     Train net output #1: loss = 0.820068 (* 1 = 0.820068 loss)
I0816 20:29:17.146981 20404 sgd_solver.cpp:106] Iteration 3610, lr = 0.000793609
I0816 20:29:52.299640 20404 solver.cpp:228] Iteration 3620, loss = 0.820538
I0816 20:29:52.299821 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:29:52.299837 20404 solver.cpp:244]     Train net output #1: loss = 0.820538 (* 1 = 0.820538 loss)
I0816 20:29:52.299849 20404 sgd_solver.cpp:106] Iteration 3620, lr = 0.000793172
I0816 20:30:27.438086 20404 solver.cpp:228] Iteration 3630, loss = 0.820545
I0816 20:30:27.438264 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:30:27.438279 20404 solver.cpp:244]     Train net output #1: loss = 0.820545 (* 1 = 0.820545 loss)
I0816 20:30:27.438292 20404 sgd_solver.cpp:106] Iteration 3630, lr = 0.000792735
I0816 20:30:59.074825 20404 solver.cpp:337] Iteration 3640, Testing net (#0)
I0816 20:31:33.961311 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:31:33.961489 20404 solver.cpp:404]     Test net output #1: loss = 0.670121 (* 1 = 0.670121 loss)
I0816 20:31:37.459506 20404 solver.cpp:228] Iteration 3640, loss = 0.821237
I0816 20:31:37.459556 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:31:37.459571 20404 solver.cpp:244]     Train net output #1: loss = 0.821237 (* 1 = 0.821237 loss)
I0816 20:31:37.459583 20404 sgd_solver.cpp:106] Iteration 3640, lr = 0.000792299
I0816 20:32:12.599310 20404 solver.cpp:228] Iteration 3650, loss = 0.820024
I0816 20:32:12.599491 20404 solver.cpp:244]     Train net output #0: accuracy = 0.84
I0816 20:32:12.599506 20404 solver.cpp:244]     Train net output #1: loss = 0.820024 (* 1 = 0.820024 loss)
I0816 20:32:12.599519 20404 sgd_solver.cpp:106] Iteration 3650, lr = 0.000791864
I0816 20:32:47.739497 20404 solver.cpp:228] Iteration 3660, loss = 0.820816
I0816 20:32:47.739671 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:32:47.739687 20404 solver.cpp:244]     Train net output #1: loss = 0.820816 (* 1 = 0.820816 loss)
I0816 20:32:47.739701 20404 sgd_solver.cpp:106] Iteration 3660, lr = 0.000791429
I0816 20:33:22.845324 20404 solver.cpp:228] Iteration 3670, loss = 0.820317
I0816 20:33:22.845502 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:33:22.845518 20404 solver.cpp:244]     Train net output #1: loss = 0.820317 (* 1 = 0.820317 loss)
I0816 20:33:22.845530 20404 sgd_solver.cpp:106] Iteration 3670, lr = 0.000790995
I0816 20:33:54.490978 20404 solver.cpp:337] Iteration 3680, Testing net (#0)
I0816 20:34:29.366307 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 20:34:29.366474 20404 solver.cpp:404]     Test net output #1: loss = 0.670293 (* 1 = 0.670293 loss)
I0816 20:34:32.870378 20404 solver.cpp:228] Iteration 3680, loss = 0.821763
I0816 20:34:32.870429 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:34:32.870445 20404 solver.cpp:244]     Train net output #1: loss = 0.821763 (* 1 = 0.821763 loss)
I0816 20:34:32.870456 20404 sgd_solver.cpp:106] Iteration 3680, lr = 0.000790561
I0816 20:35:08.017982 20404 solver.cpp:228] Iteration 3690, loss = 0.820418
I0816 20:35:08.018159 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:35:08.018175 20404 solver.cpp:244]     Train net output #1: loss = 0.820418 (* 1 = 0.820418 loss)
I0816 20:35:08.018187 20404 sgd_solver.cpp:106] Iteration 3690, lr = 0.000790128
I0816 20:35:43.145001 20404 solver.cpp:228] Iteration 3700, loss = 0.820704
I0816 20:35:43.145195 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:35:43.145211 20404 solver.cpp:244]     Train net output #1: loss = 0.820704 (* 1 = 0.820704 loss)
I0816 20:35:43.145225 20404 sgd_solver.cpp:106] Iteration 3700, lr = 0.000789695
I0816 20:36:18.284658 20404 solver.cpp:228] Iteration 3710, loss = 0.820907
I0816 20:36:18.284842 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:36:18.284858 20404 solver.cpp:244]     Train net output #1: loss = 0.820907 (* 1 = 0.820907 loss)
I0816 20:36:18.284871 20404 sgd_solver.cpp:106] Iteration 3710, lr = 0.000789263
I0816 20:36:49.914067 20404 solver.cpp:337] Iteration 3720, Testing net (#0)
I0816 20:37:24.792103 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:37:24.792268 20404 solver.cpp:404]     Test net output #1: loss = 0.671706 (* 1 = 0.671706 loss)
I0816 20:37:28.291702 20404 solver.cpp:228] Iteration 3720, loss = 0.820354
I0816 20:37:28.291752 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:37:28.291767 20404 solver.cpp:244]     Train net output #1: loss = 0.820354 (* 1 = 0.820354 loss)
I0816 20:37:28.291779 20404 sgd_solver.cpp:106] Iteration 3720, lr = 0.000788832
I0816 20:38:03.419601 20404 solver.cpp:228] Iteration 3730, loss = 0.82087
I0816 20:38:03.419771 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:38:03.419787 20404 solver.cpp:244]     Train net output #1: loss = 0.82087 (* 1 = 0.82087 loss)
I0816 20:38:03.419800 20404 sgd_solver.cpp:106] Iteration 3730, lr = 0.000788401
I0816 20:38:38.558367 20404 solver.cpp:228] Iteration 3740, loss = 0.820529
I0816 20:38:38.558580 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:38:38.558596 20404 solver.cpp:244]     Train net output #1: loss = 0.820529 (* 1 = 0.820529 loss)
I0816 20:38:38.558609 20404 sgd_solver.cpp:106] Iteration 3740, lr = 0.000787971
I0816 20:39:13.701323 20404 solver.cpp:228] Iteration 3750, loss = 0.820136
I0816 20:39:13.701498 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:39:13.701514 20404 solver.cpp:244]     Train net output #1: loss = 0.820136 (* 1 = 0.820136 loss)
I0816 20:39:13.701525 20404 sgd_solver.cpp:106] Iteration 3750, lr = 0.000787541
I0816 20:39:45.328208 20404 solver.cpp:337] Iteration 3760, Testing net (#0)
I0816 20:40:20.209211 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:40:20.209385 20404 solver.cpp:404]     Test net output #1: loss = 0.670439 (* 1 = 0.670439 loss)
I0816 20:40:23.710013 20404 solver.cpp:228] Iteration 3760, loss = 0.82084
I0816 20:40:23.710067 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:40:23.710081 20404 solver.cpp:244]     Train net output #1: loss = 0.82084 (* 1 = 0.82084 loss)
I0816 20:40:23.710093 20404 sgd_solver.cpp:106] Iteration 3760, lr = 0.000787111
I0816 20:40:58.830878 20404 solver.cpp:228] Iteration 3770, loss = 0.820396
I0816 20:40:58.831055 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:40:58.831070 20404 solver.cpp:244]     Train net output #1: loss = 0.820396 (* 1 = 0.820396 loss)
I0816 20:40:58.831084 20404 sgd_solver.cpp:106] Iteration 3770, lr = 0.000786683
I0816 20:41:33.958664 20404 solver.cpp:228] Iteration 3780, loss = 0.820707
I0816 20:41:33.958845 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:41:33.958861 20404 solver.cpp:244]     Train net output #1: loss = 0.820707 (* 1 = 0.820707 loss)
I0816 20:41:33.958874 20404 sgd_solver.cpp:106] Iteration 3780, lr = 0.000786254
I0816 20:42:09.093652 20404 solver.cpp:228] Iteration 3790, loss = 0.820985
I0816 20:42:09.093832 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:42:09.093848 20404 solver.cpp:244]     Train net output #1: loss = 0.820985 (* 1 = 0.820985 loss)
I0816 20:42:09.093860 20404 sgd_solver.cpp:106] Iteration 3790, lr = 0.000785827
I0816 20:42:40.740136 20404 solver.cpp:337] Iteration 3800, Testing net (#0)
I0816 20:43:15.611004 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 20:43:15.611169 20404 solver.cpp:404]     Test net output #1: loss = 0.671055 (* 1 = 0.671055 loss)
I0816 20:43:19.114786 20404 solver.cpp:228] Iteration 3800, loss = 0.822732
I0816 20:43:19.114838 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:43:19.114852 20404 solver.cpp:244]     Train net output #1: loss = 0.822732 (* 1 = 0.822732 loss)
I0816 20:43:19.114864 20404 sgd_solver.cpp:106] Iteration 3800, lr = 0.0007854
I0816 20:43:54.227762 20404 solver.cpp:228] Iteration 3810, loss = 0.820116
I0816 20:43:54.227996 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:43:54.228011 20404 solver.cpp:244]     Train net output #1: loss = 0.820116 (* 1 = 0.820116 loss)
I0816 20:43:54.228024 20404 sgd_solver.cpp:106] Iteration 3810, lr = 0.000784973
I0816 20:44:29.365550 20404 solver.cpp:228] Iteration 3820, loss = 0.82055
I0816 20:44:29.365653 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:44:29.365672 20404 solver.cpp:244]     Train net output #1: loss = 0.82055 (* 1 = 0.82055 loss)
I0816 20:44:29.365687 20404 sgd_solver.cpp:106] Iteration 3820, lr = 0.000784547
I0816 20:45:04.496711 20404 solver.cpp:228] Iteration 3830, loss = 0.822024
I0816 20:45:04.496803 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:45:04.496819 20404 solver.cpp:244]     Train net output #1: loss = 0.822024 (* 1 = 0.822024 loss)
I0816 20:45:04.496831 20404 sgd_solver.cpp:106] Iteration 3830, lr = 0.000784122
I0816 20:45:36.122571 20404 solver.cpp:337] Iteration 3840, Testing net (#0)
I0816 20:46:10.999138 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 20:46:10.999325 20404 solver.cpp:404]     Test net output #1: loss = 0.67077 (* 1 = 0.67077 loss)
I0816 20:46:14.501348 20404 solver.cpp:228] Iteration 3840, loss = 0.822382
I0816 20:46:14.501390 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:46:14.501407 20404 solver.cpp:244]     Train net output #1: loss = 0.822382 (* 1 = 0.822382 loss)
I0816 20:46:14.501432 20404 sgd_solver.cpp:106] Iteration 3840, lr = 0.000783697
I0816 20:46:49.635303 20404 solver.cpp:228] Iteration 3850, loss = 0.820102
I0816 20:46:49.635505 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:46:49.635524 20404 solver.cpp:244]     Train net output #1: loss = 0.820102 (* 1 = 0.820102 loss)
I0816 20:46:49.635538 20404 sgd_solver.cpp:106] Iteration 3850, lr = 0.000783272
I0816 20:47:24.789266 20404 solver.cpp:228] Iteration 3860, loss = 0.821313
I0816 20:47:24.789433 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:47:24.789449 20404 solver.cpp:244]     Train net output #1: loss = 0.821313 (* 1 = 0.821313 loss)
I0816 20:47:24.789463 20404 sgd_solver.cpp:106] Iteration 3860, lr = 0.000782848
I0816 20:47:59.929357 20404 solver.cpp:228] Iteration 3870, loss = 0.820658
I0816 20:47:59.929448 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:47:59.929464 20404 solver.cpp:244]     Train net output #1: loss = 0.820658 (* 1 = 0.820658 loss)
I0816 20:47:59.929476 20404 sgd_solver.cpp:106] Iteration 3870, lr = 0.000782425
I0816 20:48:31.582792 20404 solver.cpp:337] Iteration 3880, Testing net (#0)
I0816 20:49:06.466672 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 20:49:06.466838 20404 solver.cpp:404]     Test net output #1: loss = 0.670248 (* 1 = 0.670248 loss)
I0816 20:49:09.962390 20404 solver.cpp:228] Iteration 3880, loss = 0.821729
I0816 20:49:09.962440 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:49:09.962455 20404 solver.cpp:244]     Train net output #1: loss = 0.821729 (* 1 = 0.821729 loss)
I0816 20:49:09.962466 20404 sgd_solver.cpp:106] Iteration 3880, lr = 0.000782002
I0816 20:49:45.077833 20404 solver.cpp:228] Iteration 3890, loss = 0.82092
I0816 20:49:45.078012 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:49:45.078028 20404 solver.cpp:244]     Train net output #1: loss = 0.82092 (* 1 = 0.82092 loss)
I0816 20:49:45.078042 20404 sgd_solver.cpp:106] Iteration 3890, lr = 0.00078158
I0816 20:50:20.209240 20404 solver.cpp:228] Iteration 3900, loss = 0.820086
I0816 20:50:20.209419 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:50:20.209434 20404 solver.cpp:244]     Train net output #1: loss = 0.820086 (* 1 = 0.820086 loss)
I0816 20:50:20.209446 20404 sgd_solver.cpp:106] Iteration 3900, lr = 0.000781158
I0816 20:50:55.332660 20404 solver.cpp:228] Iteration 3910, loss = 0.820996
I0816 20:50:55.332844 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:50:55.332859 20404 solver.cpp:244]     Train net output #1: loss = 0.820996 (* 1 = 0.820996 loss)
I0816 20:50:55.332872 20404 sgd_solver.cpp:106] Iteration 3910, lr = 0.000780737
I0816 20:51:26.965590 20404 solver.cpp:337] Iteration 3920, Testing net (#0)
I0816 20:52:01.841190 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:52:01.841362 20404 solver.cpp:404]     Test net output #1: loss = 0.671635 (* 1 = 0.671635 loss)
I0816 20:52:05.336566 20404 solver.cpp:228] Iteration 3920, loss = 0.820301
I0816 20:52:05.336618 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:52:05.336632 20404 solver.cpp:244]     Train net output #1: loss = 0.820301 (* 1 = 0.820301 loss)
I0816 20:52:05.336644 20404 sgd_solver.cpp:106] Iteration 3920, lr = 0.000780316
I0816 20:52:40.471745 20404 solver.cpp:228] Iteration 3930, loss = 0.822132
I0816 20:52:40.471959 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:52:40.471976 20404 solver.cpp:244]     Train net output #1: loss = 0.822132 (* 1 = 0.822132 loss)
I0816 20:52:40.471988 20404 sgd_solver.cpp:106] Iteration 3930, lr = 0.000779896
I0816 20:53:15.614364 20404 solver.cpp:228] Iteration 3940, loss = 0.821317
I0816 20:53:15.614460 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:53:15.614475 20404 solver.cpp:244]     Train net output #1: loss = 0.821317 (* 1 = 0.821317 loss)
I0816 20:53:15.614486 20404 sgd_solver.cpp:106] Iteration 3940, lr = 0.000779476
I0816 20:53:50.764951 20404 solver.cpp:228] Iteration 3950, loss = 0.82032
I0816 20:53:50.765132 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:53:50.765148 20404 solver.cpp:244]     Train net output #1: loss = 0.82032 (* 1 = 0.82032 loss)
I0816 20:53:50.765161 20404 sgd_solver.cpp:106] Iteration 3950, lr = 0.000779057
I0816 20:54:22.397069 20404 solver.cpp:337] Iteration 3960, Testing net (#0)
I0816 20:54:57.288095 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 20:54:57.288177 20404 solver.cpp:404]     Test net output #1: loss = 0.670401 (* 1 = 0.670401 loss)
I0816 20:55:00.790318 20404 solver.cpp:228] Iteration 3960, loss = 0.821945
I0816 20:55:00.790369 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:55:00.790383 20404 solver.cpp:244]     Train net output #1: loss = 0.821945 (* 1 = 0.821945 loss)
I0816 20:55:00.790395 20404 sgd_solver.cpp:106] Iteration 3960, lr = 0.000778639
I0816 20:55:35.924720 20404 solver.cpp:228] Iteration 3970, loss = 0.821083
I0816 20:55:35.924955 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:55:35.924971 20404 solver.cpp:244]     Train net output #1: loss = 0.821083 (* 1 = 0.821083 loss)
I0816 20:55:35.924983 20404 sgd_solver.cpp:106] Iteration 3970, lr = 0.000778221
I0816 20:56:11.036592 20404 solver.cpp:228] Iteration 3980, loss = 0.8204
I0816 20:56:11.036762 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:56:11.036778 20404 solver.cpp:244]     Train net output #1: loss = 0.8204 (* 1 = 0.8204 loss)
I0816 20:56:11.036792 20404 sgd_solver.cpp:106] Iteration 3980, lr = 0.000777803
I0816 20:56:46.169769 20404 solver.cpp:228] Iteration 3990, loss = 0.820278
I0816 20:56:46.169947 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:56:46.169963 20404 solver.cpp:244]     Train net output #1: loss = 0.820278 (* 1 = 0.820278 loss)
I0816 20:56:46.169975 20404 sgd_solver.cpp:106] Iteration 3990, lr = 0.000777386
I0816 20:57:17.804965 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_4000.caffemodel
I0816 20:57:28.822329 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_4000.solverstate
I0816 20:57:30.883208 20404 solver.cpp:337] Iteration 4000, Testing net (#0)
I0816 20:58:05.551617 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 20:58:05.551795 20404 solver.cpp:404]     Test net output #1: loss = 0.671654 (* 1 = 0.671654 loss)
I0816 20:58:09.033074 20404 solver.cpp:228] Iteration 4000, loss = 0.820305
I0816 20:58:09.033118 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:58:09.033133 20404 solver.cpp:244]     Train net output #1: loss = 0.820305 (* 1 = 0.820305 loss)
I0816 20:58:09.033146 20404 sgd_solver.cpp:106] Iteration 4000, lr = 0.00077697
I0816 20:58:43.918063 20404 solver.cpp:228] Iteration 4010, loss = 0.820391
I0816 20:58:43.918241 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:58:43.918261 20404 solver.cpp:244]     Train net output #1: loss = 0.820391 (* 1 = 0.820391 loss)
I0816 20:58:43.918272 20404 sgd_solver.cpp:106] Iteration 4010, lr = 0.000776554
I0816 20:59:18.811126 20404 solver.cpp:228] Iteration 4020, loss = 0.820195
I0816 20:59:18.811318 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 20:59:18.811333 20404 solver.cpp:244]     Train net output #1: loss = 0.820195 (* 1 = 0.820195 loss)
I0816 20:59:18.811345 20404 sgd_solver.cpp:106] Iteration 4020, lr = 0.000776138
I0816 20:59:53.695505 20404 solver.cpp:228] Iteration 4030, loss = 0.82156
I0816 20:59:53.695708 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 20:59:53.695729 20404 solver.cpp:244]     Train net output #1: loss = 0.82156 (* 1 = 0.82156 loss)
I0816 20:59:53.695741 20404 sgd_solver.cpp:106] Iteration 4030, lr = 0.000775723
I0816 21:00:25.115187 20404 solver.cpp:337] Iteration 4040, Testing net (#0)
I0816 21:00:59.781325 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:00:59.781497 20404 solver.cpp:404]     Test net output #1: loss = 0.671116 (* 1 = 0.671116 loss)
I0816 21:01:03.262565 20404 solver.cpp:228] Iteration 4040, loss = 0.820034
I0816 21:01:03.262609 20404 solver.cpp:244]     Train net output #0: accuracy = 0.67
I0816 21:01:03.262626 20404 solver.cpp:244]     Train net output #1: loss = 0.820034 (* 1 = 0.820034 loss)
I0816 21:01:03.262651 20404 sgd_solver.cpp:106] Iteration 4040, lr = 0.000775309
I0816 21:01:38.145376 20404 solver.cpp:228] Iteration 4050, loss = 0.820531
I0816 21:01:38.145561 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:01:38.145576 20404 solver.cpp:244]     Train net output #1: loss = 0.820531 (* 1 = 0.820531 loss)
I0816 21:01:38.145589 20404 sgd_solver.cpp:106] Iteration 4050, lr = 0.000774895
I0816 21:02:13.037581 20404 solver.cpp:228] Iteration 4060, loss = 0.820385
I0816 21:02:13.037761 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:02:13.037781 20404 solver.cpp:244]     Train net output #1: loss = 0.820385 (* 1 = 0.820385 loss)
I0816 21:02:13.037794 20404 sgd_solver.cpp:106] Iteration 4060, lr = 0.000774481
I0816 21:02:47.927743 20404 solver.cpp:228] Iteration 4070, loss = 0.820311
I0816 21:02:47.927925 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:02:47.927942 20404 solver.cpp:244]     Train net output #1: loss = 0.820311 (* 1 = 0.820311 loss)
I0816 21:02:47.927953 20404 sgd_solver.cpp:106] Iteration 4070, lr = 0.000774069
I0816 21:03:19.344002 20404 solver.cpp:337] Iteration 4080, Testing net (#0)
I0816 21:03:54.012543 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:03:54.012708 20404 solver.cpp:404]     Test net output #1: loss = 0.6714 (* 1 = 0.6714 loss)
I0816 21:03:57.473609 20404 solver.cpp:228] Iteration 4080, loss = 0.820162
I0816 21:03:57.473660 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:03:57.473675 20404 solver.cpp:244]     Train net output #1: loss = 0.820162 (* 1 = 0.820162 loss)
I0816 21:03:57.473686 20404 sgd_solver.cpp:106] Iteration 4080, lr = 0.000773656
I0816 21:04:32.351425 20404 solver.cpp:228] Iteration 4090, loss = 0.821658
I0816 21:04:32.351609 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:04:32.351625 20404 solver.cpp:244]     Train net output #1: loss = 0.821658 (* 1 = 0.821658 loss)
I0816 21:04:32.351637 20404 sgd_solver.cpp:106] Iteration 4090, lr = 0.000773244
I0816 21:05:07.251548 20404 solver.cpp:228] Iteration 4100, loss = 0.820021
I0816 21:05:07.251724 20404 solver.cpp:244]     Train net output #0: accuracy = 0.86
I0816 21:05:07.251739 20404 solver.cpp:244]     Train net output #1: loss = 0.820021 (* 1 = 0.820021 loss)
I0816 21:05:07.251752 20404 sgd_solver.cpp:106] Iteration 4100, lr = 0.000772833
I0816 21:05:42.137029 20404 solver.cpp:228] Iteration 4110, loss = 0.820392
I0816 21:05:42.137207 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:05:42.137223 20404 solver.cpp:244]     Train net output #1: loss = 0.820392 (* 1 = 0.820392 loss)
I0816 21:05:42.137235 20404 sgd_solver.cpp:106] Iteration 4110, lr = 0.000772422
I0816 21:06:13.556445 20404 solver.cpp:337] Iteration 4120, Testing net (#0)
I0816 21:06:48.221699 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:06:48.221873 20404 solver.cpp:404]     Test net output #1: loss = 0.670319 (* 1 = 0.670319 loss)
I0816 21:06:51.698456 20404 solver.cpp:228] Iteration 4120, loss = 0.821049
I0816 21:06:51.698506 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:06:51.698520 20404 solver.cpp:244]     Train net output #1: loss = 0.821049 (* 1 = 0.821049 loss)
I0816 21:06:51.698532 20404 sgd_solver.cpp:106] Iteration 4120, lr = 0.000772012
I0816 21:07:26.582007 20404 solver.cpp:228] Iteration 4130, loss = 0.821121
I0816 21:07:26.582176 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:07:26.582193 20404 solver.cpp:244]     Train net output #1: loss = 0.821121 (* 1 = 0.821121 loss)
I0816 21:07:26.582206 20404 sgd_solver.cpp:106] Iteration 4130, lr = 0.000771602
I0816 21:08:01.477283 20404 solver.cpp:228] Iteration 4140, loss = 0.82018
I0816 21:08:01.477461 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:08:01.477478 20404 solver.cpp:244]     Train net output #1: loss = 0.82018 (* 1 = 0.82018 loss)
I0816 21:08:01.477491 20404 sgd_solver.cpp:106] Iteration 4140, lr = 0.000771193
I0816 21:08:36.353037 20404 solver.cpp:228] Iteration 4150, loss = 0.820254
I0816 21:08:36.353219 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:08:36.353233 20404 solver.cpp:244]     Train net output #1: loss = 0.820254 (* 1 = 0.820254 loss)
I0816 21:08:36.353245 20404 sgd_solver.cpp:106] Iteration 4150, lr = 0.000770784
I0816 21:09:07.768525 20404 solver.cpp:337] Iteration 4160, Testing net (#0)
I0816 21:09:42.399950 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:09:42.400125 20404 solver.cpp:404]     Test net output #1: loss = 0.670785 (* 1 = 0.670785 loss)
I0816 21:09:45.877997 20404 solver.cpp:228] Iteration 4160, loss = 0.820459
I0816 21:09:45.878049 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:09:45.878064 20404 solver.cpp:244]     Train net output #1: loss = 0.820459 (* 1 = 0.820459 loss)
I0816 21:09:45.878077 20404 sgd_solver.cpp:106] Iteration 4160, lr = 0.000770376
I0816 21:10:20.771286 20404 solver.cpp:228] Iteration 4170, loss = 0.820453
I0816 21:10:20.771468 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:10:20.771487 20404 solver.cpp:244]     Train net output #1: loss = 0.820453 (* 1 = 0.820453 loss)
I0816 21:10:20.771500 20404 sgd_solver.cpp:106] Iteration 4170, lr = 0.000769968
I0816 21:10:55.639523 20404 solver.cpp:228] Iteration 4180, loss = 0.821485
I0816 21:10:55.639595 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:10:55.639610 20404 solver.cpp:244]     Train net output #1: loss = 0.821485 (* 1 = 0.821485 loss)
I0816 21:10:55.639621 20404 sgd_solver.cpp:106] Iteration 4180, lr = 0.000769561
I0816 21:11:30.551262 20404 solver.cpp:228] Iteration 4190, loss = 0.820859
I0816 21:11:30.551434 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:11:30.551450 20404 solver.cpp:244]     Train net output #1: loss = 0.820859 (* 1 = 0.820859 loss)
I0816 21:11:30.551461 20404 sgd_solver.cpp:106] Iteration 4190, lr = 0.000769154
I0816 21:12:01.984474 20404 solver.cpp:337] Iteration 4200, Testing net (#0)
I0816 21:12:36.644577 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:12:36.644749 20404 solver.cpp:404]     Test net output #1: loss = 0.670431 (* 1 = 0.670431 loss)
I0816 21:12:40.118489 20404 solver.cpp:228] Iteration 4200, loss = 0.820917
I0816 21:12:40.118541 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:12:40.118554 20404 solver.cpp:244]     Train net output #1: loss = 0.820917 (* 1 = 0.820917 loss)
I0816 21:12:40.118567 20404 sgd_solver.cpp:106] Iteration 4200, lr = 0.000768748
I0816 21:13:15.000984 20404 solver.cpp:228] Iteration 4210, loss = 0.821201
I0816 21:13:15.001160 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:13:15.001175 20404 solver.cpp:244]     Train net output #1: loss = 0.821201 (* 1 = 0.821201 loss)
I0816 21:13:15.001188 20404 sgd_solver.cpp:106] Iteration 4210, lr = 0.000768342
I0816 21:13:49.896363 20404 solver.cpp:228] Iteration 4220, loss = 0.821574
I0816 21:13:49.896541 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:13:49.896558 20404 solver.cpp:244]     Train net output #1: loss = 0.821574 (* 1 = 0.821574 loss)
I0816 21:13:49.896570 20404 sgd_solver.cpp:106] Iteration 4220, lr = 0.000767937
I0816 21:14:24.808990 20404 solver.cpp:228] Iteration 4230, loss = 0.820702
I0816 21:14:24.809207 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:14:24.809223 20404 solver.cpp:244]     Train net output #1: loss = 0.820702 (* 1 = 0.820702 loss)
I0816 21:14:24.809236 20404 sgd_solver.cpp:106] Iteration 4230, lr = 0.000767532
I0816 21:14:56.252944 20404 solver.cpp:337] Iteration 4240, Testing net (#0)
I0816 21:15:30.913941 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:15:30.914111 20404 solver.cpp:404]     Test net output #1: loss = 0.670919 (* 1 = 0.670919 loss)
I0816 21:15:34.392725 20404 solver.cpp:228] Iteration 4240, loss = 0.8203
I0816 21:15:34.392776 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:15:34.392789 20404 solver.cpp:244]     Train net output #1: loss = 0.8203 (* 1 = 0.8203 loss)
I0816 21:15:34.392802 20404 sgd_solver.cpp:106] Iteration 4240, lr = 0.000767127
I0816 21:16:09.280387 20404 solver.cpp:228] Iteration 4250, loss = 0.820568
I0816 21:16:09.280562 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:16:09.280577 20404 solver.cpp:244]     Train net output #1: loss = 0.820568 (* 1 = 0.820568 loss)
I0816 21:16:09.280589 20404 sgd_solver.cpp:106] Iteration 4250, lr = 0.000766724
I0816 21:16:44.196848 20404 solver.cpp:228] Iteration 4260, loss = 0.821016
I0816 21:16:44.197023 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:16:44.197038 20404 solver.cpp:244]     Train net output #1: loss = 0.821016 (* 1 = 0.821016 loss)
I0816 21:16:44.197052 20404 sgd_solver.cpp:106] Iteration 4260, lr = 0.00076632
I0816 21:17:19.103397 20404 solver.cpp:228] Iteration 4270, loss = 0.820292
I0816 21:17:19.103575 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:17:19.103591 20404 solver.cpp:244]     Train net output #1: loss = 0.820292 (* 1 = 0.820292 loss)
I0816 21:17:19.103603 20404 sgd_solver.cpp:106] Iteration 4270, lr = 0.000765918
I0816 21:17:50.524940 20404 solver.cpp:337] Iteration 4280, Testing net (#0)
I0816 21:18:25.177479 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:18:25.177670 20404 solver.cpp:404]     Test net output #1: loss = 0.672233 (* 1 = 0.672233 loss)
I0816 21:18:28.651304 20404 solver.cpp:228] Iteration 4280, loss = 0.820618
I0816 21:18:28.651355 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:18:28.651370 20404 solver.cpp:244]     Train net output #1: loss = 0.820618 (* 1 = 0.820618 loss)
I0816 21:18:28.651381 20404 sgd_solver.cpp:106] Iteration 4280, lr = 0.000765515
I0816 21:19:03.539496 20404 solver.cpp:228] Iteration 4290, loss = 0.820855
I0816 21:19:03.539669 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:19:03.539685 20404 solver.cpp:244]     Train net output #1: loss = 0.820855 (* 1 = 0.820855 loss)
I0816 21:19:03.539698 20404 sgd_solver.cpp:106] Iteration 4290, lr = 0.000765113
I0816 21:19:38.419844 20404 solver.cpp:228] Iteration 4300, loss = 0.820113
I0816 21:19:38.420025 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:19:38.420042 20404 solver.cpp:244]     Train net output #1: loss = 0.820113 (* 1 = 0.820113 loss)
I0816 21:19:38.420054 20404 sgd_solver.cpp:106] Iteration 4300, lr = 0.000764712
I0816 21:20:13.338315 20404 solver.cpp:228] Iteration 4310, loss = 0.820111
I0816 21:20:13.338495 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:20:13.338513 20404 solver.cpp:244]     Train net output #1: loss = 0.820111 (* 1 = 0.820111 loss)
I0816 21:20:13.338526 20404 sgd_solver.cpp:106] Iteration 4310, lr = 0.000764311
I0816 21:20:44.765569 20404 solver.cpp:337] Iteration 4320, Testing net (#0)
I0816 21:21:19.432801 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:21:19.432979 20404 solver.cpp:404]     Test net output #1: loss = 0.671463 (* 1 = 0.671463 loss)
I0816 21:21:22.909107 20404 solver.cpp:228] Iteration 4320, loss = 0.820183
I0816 21:21:22.909159 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:21:22.909173 20404 solver.cpp:244]     Train net output #1: loss = 0.820183 (* 1 = 0.820183 loss)
I0816 21:21:22.909185 20404 sgd_solver.cpp:106] Iteration 4320, lr = 0.000763911
I0816 21:21:57.780519 20404 solver.cpp:228] Iteration 4330, loss = 0.820067
I0816 21:21:57.780731 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:21:57.780746 20404 solver.cpp:244]     Train net output #1: loss = 0.820067 (* 1 = 0.820067 loss)
I0816 21:21:57.780760 20404 sgd_solver.cpp:106] Iteration 4330, lr = 0.000763511
I0816 21:22:32.691841 20404 solver.cpp:228] Iteration 4340, loss = 0.820808
I0816 21:22:32.692013 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:22:32.692029 20404 solver.cpp:244]     Train net output #1: loss = 0.820808 (* 1 = 0.820808 loss)
I0816 21:22:32.692042 20404 sgd_solver.cpp:106] Iteration 4340, lr = 0.000763112
I0816 21:23:07.588224 20404 solver.cpp:228] Iteration 4350, loss = 0.820114
I0816 21:23:07.588399 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:23:07.588416 20404 solver.cpp:244]     Train net output #1: loss = 0.820114 (* 1 = 0.820114 loss)
I0816 21:23:07.588428 20404 sgd_solver.cpp:106] Iteration 4350, lr = 0.000762713
I0816 21:23:38.983837 20404 solver.cpp:337] Iteration 4360, Testing net (#0)
I0816 21:24:13.640280 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:24:13.640385 20404 solver.cpp:404]     Test net output #1: loss = 0.670585 (* 1 = 0.670585 loss)
I0816 21:24:17.117058 20404 solver.cpp:228] Iteration 4360, loss = 0.820738
I0816 21:24:17.117107 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:24:17.117122 20404 solver.cpp:244]     Train net output #1: loss = 0.820738 (* 1 = 0.820738 loss)
I0816 21:24:17.117135 20404 sgd_solver.cpp:106] Iteration 4360, lr = 0.000762315
I0816 21:24:51.998028 20404 solver.cpp:228] Iteration 4370, loss = 0.820146
I0816 21:24:51.998203 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:24:51.998219 20404 solver.cpp:244]     Train net output #1: loss = 0.820146 (* 1 = 0.820146 loss)
I0816 21:24:51.998231 20404 sgd_solver.cpp:106] Iteration 4370, lr = 0.000761917
I0816 21:25:26.907241 20404 solver.cpp:228] Iteration 4380, loss = 0.820281
I0816 21:25:26.907343 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:25:26.907359 20404 solver.cpp:244]     Train net output #1: loss = 0.820281 (* 1 = 0.820281 loss)
I0816 21:25:26.907371 20404 sgd_solver.cpp:106] Iteration 4380, lr = 0.000761519
I0816 21:26:01.791913 20404 solver.cpp:228] Iteration 4390, loss = 0.820023
I0816 21:26:01.792093 20404 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0816 21:26:01.792110 20404 solver.cpp:244]     Train net output #1: loss = 0.820023 (* 1 = 0.820023 loss)
I0816 21:26:01.792125 20404 sgd_solver.cpp:106] Iteration 4390, lr = 0.000761122
I0816 21:26:33.207698 20404 solver.cpp:337] Iteration 4400, Testing net (#0)
I0816 21:27:07.870676 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:27:07.870775 20404 solver.cpp:404]     Test net output #1: loss = 0.671181 (* 1 = 0.671181 loss)
I0816 21:27:11.351341 20404 solver.cpp:228] Iteration 4400, loss = 0.820021
I0816 21:27:11.351392 20404 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0816 21:27:11.351407 20404 solver.cpp:244]     Train net output #1: loss = 0.820021 (* 1 = 0.820021 loss)
I0816 21:27:11.351418 20404 sgd_solver.cpp:106] Iteration 4400, lr = 0.000760726
I0816 21:27:46.228896 20404 solver.cpp:228] Iteration 4410, loss = 0.820061
I0816 21:27:46.229079 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:27:46.229095 20404 solver.cpp:244]     Train net output #1: loss = 0.820061 (* 1 = 0.820061 loss)
I0816 21:27:46.229107 20404 sgd_solver.cpp:106] Iteration 4410, lr = 0.00076033
I0816 21:28:21.121877 20404 solver.cpp:228] Iteration 4420, loss = 0.820192
I0816 21:28:21.122076 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:28:21.122092 20404 solver.cpp:244]     Train net output #1: loss = 0.820192 (* 1 = 0.820192 loss)
I0816 21:28:21.122108 20404 sgd_solver.cpp:106] Iteration 4420, lr = 0.000759934
I0816 21:28:56.009104 20404 solver.cpp:228] Iteration 4430, loss = 0.820297
I0816 21:28:56.009186 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:28:56.009201 20404 solver.cpp:244]     Train net output #1: loss = 0.820297 (* 1 = 0.820297 loss)
I0816 21:28:56.009212 20404 sgd_solver.cpp:106] Iteration 4430, lr = 0.000759539
I0816 21:29:27.419471 20404 solver.cpp:337] Iteration 4440, Testing net (#0)
I0816 21:30:02.075968 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:30:02.076140 20404 solver.cpp:404]     Test net output #1: loss = 0.672222 (* 1 = 0.672222 loss)
I0816 21:30:05.541296 20404 solver.cpp:228] Iteration 4440, loss = 0.820606
I0816 21:30:05.541347 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:30:05.541362 20404 solver.cpp:244]     Train net output #1: loss = 0.820606 (* 1 = 0.820606 loss)
I0816 21:30:05.541373 20404 sgd_solver.cpp:106] Iteration 4440, lr = 0.000759145
I0816 21:30:40.430914 20404 solver.cpp:228] Iteration 4450, loss = 0.821705
I0816 21:30:40.431095 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:30:40.431112 20404 solver.cpp:244]     Train net output #1: loss = 0.821705 (* 1 = 0.821705 loss)
I0816 21:30:40.431125 20404 sgd_solver.cpp:106] Iteration 4450, lr = 0.000758751
I0816 21:31:15.324002 20404 solver.cpp:228] Iteration 4460, loss = 0.822068
I0816 21:31:15.324182 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:31:15.324201 20404 solver.cpp:244]     Train net output #1: loss = 0.822068 (* 1 = 0.822068 loss)
I0816 21:31:15.324216 20404 sgd_solver.cpp:106] Iteration 4460, lr = 0.000758357
I0816 21:31:50.239737 20404 solver.cpp:228] Iteration 4470, loss = 0.820184
I0816 21:31:50.239928 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:31:50.239943 20404 solver.cpp:244]     Train net output #1: loss = 0.820184 (* 1 = 0.820184 loss)
I0816 21:31:50.239955 20404 sgd_solver.cpp:106] Iteration 4470, lr = 0.000757964
I0816 21:32:21.669060 20404 solver.cpp:337] Iteration 4480, Testing net (#0)
I0816 21:32:56.333417 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:32:56.333593 20404 solver.cpp:404]     Test net output #1: loss = 0.670915 (* 1 = 0.670915 loss)
I0816 21:32:59.813052 20404 solver.cpp:228] Iteration 4480, loss = 0.820325
I0816 21:32:59.813102 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:32:59.813118 20404 solver.cpp:244]     Train net output #1: loss = 0.820325 (* 1 = 0.820325 loss)
I0816 21:32:59.813130 20404 sgd_solver.cpp:106] Iteration 4480, lr = 0.000757571
I0816 21:33:34.720495 20404 solver.cpp:228] Iteration 4490, loss = 0.82028
I0816 21:33:34.720666 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:33:34.720682 20404 solver.cpp:244]     Train net output #1: loss = 0.82028 (* 1 = 0.82028 loss)
I0816 21:33:34.720695 20404 sgd_solver.cpp:106] Iteration 4490, lr = 0.000757179
I0816 21:34:09.611783 20404 solver.cpp:228] Iteration 4500, loss = 0.820652
I0816 21:34:09.611973 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:34:09.611987 20404 solver.cpp:244]     Train net output #1: loss = 0.820652 (* 1 = 0.820652 loss)
I0816 21:34:09.611999 20404 sgd_solver.cpp:106] Iteration 4500, lr = 0.000756788
I0816 21:34:44.496414 20404 solver.cpp:228] Iteration 4510, loss = 0.820018
I0816 21:34:44.496598 20404 solver.cpp:244]     Train net output #0: accuracy = 0.8
I0816 21:34:44.496613 20404 solver.cpp:244]     Train net output #1: loss = 0.820018 (* 1 = 0.820018 loss)
I0816 21:34:44.496625 20404 sgd_solver.cpp:106] Iteration 4510, lr = 0.000756396
I0816 21:35:15.899087 20404 solver.cpp:337] Iteration 4520, Testing net (#0)
I0816 21:35:50.541234 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:35:50.541424 20404 solver.cpp:404]     Test net output #1: loss = 0.671766 (* 1 = 0.671766 loss)
I0816 21:35:54.017201 20404 solver.cpp:228] Iteration 4520, loss = 0.820347
I0816 21:35:54.017253 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:35:54.017267 20404 solver.cpp:244]     Train net output #1: loss = 0.820347 (* 1 = 0.820347 loss)
I0816 21:35:54.017279 20404 sgd_solver.cpp:106] Iteration 4520, lr = 0.000756006
I0816 21:36:28.884985 20404 solver.cpp:228] Iteration 4530, loss = 0.820397
I0816 21:36:28.885181 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:36:28.885197 20404 solver.cpp:244]     Train net output #1: loss = 0.820397 (* 1 = 0.820397 loss)
I0816 21:36:28.885210 20404 sgd_solver.cpp:106] Iteration 4530, lr = 0.000755615
I0816 21:37:03.790742 20404 solver.cpp:228] Iteration 4540, loss = 0.821071
I0816 21:37:03.790926 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:37:03.790942 20404 solver.cpp:244]     Train net output #1: loss = 0.821071 (* 1 = 0.821071 loss)
I0816 21:37:03.790956 20404 sgd_solver.cpp:106] Iteration 4540, lr = 0.000755226
I0816 21:37:38.684861 20404 solver.cpp:228] Iteration 4550, loss = 0.82004
I0816 21:37:38.685034 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:37:38.685050 20404 solver.cpp:244]     Train net output #1: loss = 0.82004 (* 1 = 0.82004 loss)
I0816 21:37:38.685062 20404 sgd_solver.cpp:106] Iteration 4550, lr = 0.000754836
I0816 21:38:10.113723 20404 solver.cpp:337] Iteration 4560, Testing net (#0)
I0816 21:38:44.780994 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:38:44.781169 20404 solver.cpp:404]     Test net output #1: loss = 0.670458 (* 1 = 0.670458 loss)
I0816 21:38:48.259075 20404 solver.cpp:228] Iteration 4560, loss = 0.820918
I0816 21:38:48.259125 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:38:48.259140 20404 solver.cpp:244]     Train net output #1: loss = 0.820918 (* 1 = 0.820918 loss)
I0816 21:38:48.259151 20404 sgd_solver.cpp:106] Iteration 4560, lr = 0.000754447
I0816 21:39:23.139955 20404 solver.cpp:228] Iteration 4570, loss = 0.820054
I0816 21:39:23.140127 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:39:23.140146 20404 solver.cpp:244]     Train net output #1: loss = 0.820054 (* 1 = 0.820054 loss)
I0816 21:39:23.140158 20404 sgd_solver.cpp:106] Iteration 4570, lr = 0.000754059
I0816 21:39:58.031038 20404 solver.cpp:228] Iteration 4580, loss = 0.820537
I0816 21:39:58.031220 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:39:58.031236 20404 solver.cpp:244]     Train net output #1: loss = 0.820537 (* 1 = 0.820537 loss)
I0816 21:39:58.031250 20404 sgd_solver.cpp:106] Iteration 4580, lr = 0.000753671
I0816 21:40:32.905866 20404 solver.cpp:228] Iteration 4590, loss = 0.820398
I0816 21:40:32.906050 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:40:32.906066 20404 solver.cpp:244]     Train net output #1: loss = 0.820398 (* 1 = 0.820398 loss)
I0816 21:40:32.906078 20404 sgd_solver.cpp:106] Iteration 4590, lr = 0.000753284
I0816 21:41:04.320168 20404 solver.cpp:337] Iteration 4600, Testing net (#0)
I0816 21:41:38.971518 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:41:38.971618 20404 solver.cpp:404]     Test net output #1: loss = 0.670367 (* 1 = 0.670367 loss)
I0816 21:41:42.452052 20404 solver.cpp:228] Iteration 4600, loss = 0.821038
I0816 21:41:42.452105 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:41:42.452119 20404 solver.cpp:244]     Train net output #1: loss = 0.821038 (* 1 = 0.821038 loss)
I0816 21:41:42.452131 20404 sgd_solver.cpp:106] Iteration 4600, lr = 0.000752897
I0816 21:42:17.321804 20404 solver.cpp:228] Iteration 4610, loss = 0.820071
I0816 21:42:17.321981 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:42:17.321997 20404 solver.cpp:244]     Train net output #1: loss = 0.820071 (* 1 = 0.820071 loss)
I0816 21:42:17.322010 20404 sgd_solver.cpp:106] Iteration 4610, lr = 0.00075251
I0816 21:42:52.215543 20404 solver.cpp:228] Iteration 4620, loss = 0.820432
I0816 21:42:52.215759 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:42:52.215775 20404 solver.cpp:244]     Train net output #1: loss = 0.820432 (* 1 = 0.820432 loss)
I0816 21:42:52.215803 20404 sgd_solver.cpp:106] Iteration 4620, lr = 0.000752124
I0816 21:43:27.112386 20404 solver.cpp:228] Iteration 4630, loss = 0.820364
I0816 21:43:27.112574 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:43:27.112591 20404 solver.cpp:244]     Train net output #1: loss = 0.820364 (* 1 = 0.820364 loss)
I0816 21:43:27.112602 20404 sgd_solver.cpp:106] Iteration 4630, lr = 0.000751738
I0816 21:43:58.554080 20404 solver.cpp:337] Iteration 4640, Testing net (#0)
I0816 21:44:33.210527 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:44:33.210701 20404 solver.cpp:404]     Test net output #1: loss = 0.671547 (* 1 = 0.671547 loss)
I0816 21:44:36.683887 20404 solver.cpp:228] Iteration 4640, loss = 0.820215
I0816 21:44:36.683945 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:44:36.683959 20404 solver.cpp:244]     Train net output #1: loss = 0.820215 (* 1 = 0.820215 loss)
I0816 21:44:36.683971 20404 sgd_solver.cpp:106] Iteration 4640, lr = 0.000751353
I0816 21:45:11.595890 20404 solver.cpp:228] Iteration 4650, loss = 0.820265
I0816 21:45:11.596065 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:45:11.596081 20404 solver.cpp:244]     Train net output #1: loss = 0.820265 (* 1 = 0.820265 loss)
I0816 21:45:11.596096 20404 sgd_solver.cpp:106] Iteration 4650, lr = 0.000750969
I0816 21:45:46.499441 20404 solver.cpp:228] Iteration 4660, loss = 0.821664
I0816 21:45:46.499617 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:45:46.499634 20404 solver.cpp:244]     Train net output #1: loss = 0.821664 (* 1 = 0.821664 loss)
I0816 21:45:46.499646 20404 sgd_solver.cpp:106] Iteration 4660, lr = 0.000750584
I0816 21:46:21.422431 20404 solver.cpp:228] Iteration 4670, loss = 0.820428
I0816 21:46:21.422608 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:46:21.422624 20404 solver.cpp:244]     Train net output #1: loss = 0.820428 (* 1 = 0.820428 loss)
I0816 21:46:21.422638 20404 sgd_solver.cpp:106] Iteration 4670, lr = 0.000750201
I0816 21:46:52.835062 20404 solver.cpp:337] Iteration 4680, Testing net (#0)
I0816 21:47:27.482100 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:47:27.482275 20404 solver.cpp:404]     Test net output #1: loss = 0.670633 (* 1 = 0.670633 loss)
I0816 21:47:30.950455 20404 solver.cpp:228] Iteration 4680, loss = 0.820706
I0816 21:47:30.950505 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:47:30.950520 20404 solver.cpp:244]     Train net output #1: loss = 0.820706 (* 1 = 0.820706 loss)
I0816 21:47:30.950532 20404 sgd_solver.cpp:106] Iteration 4680, lr = 0.000749817
I0816 21:48:05.806097 20404 solver.cpp:228] Iteration 4690, loss = 0.8209
I0816 21:48:05.806268 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:48:05.806288 20404 solver.cpp:244]     Train net output #1: loss = 0.8209 (* 1 = 0.8209 loss)
I0816 21:48:05.806303 20404 sgd_solver.cpp:106] Iteration 4690, lr = 0.000749435
I0816 21:48:40.697077 20404 solver.cpp:228] Iteration 4700, loss = 0.820305
I0816 21:48:40.697255 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:48:40.697274 20404 solver.cpp:244]     Train net output #1: loss = 0.820305 (* 1 = 0.820305 loss)
I0816 21:48:40.697289 20404 sgd_solver.cpp:106] Iteration 4700, lr = 0.000749052
I0816 21:49:15.594333 20404 solver.cpp:228] Iteration 4710, loss = 0.820958
I0816 21:49:15.594496 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:49:15.594580 20404 solver.cpp:244]     Train net output #1: loss = 0.820958 (* 1 = 0.820958 loss)
I0816 21:49:15.594645 20404 sgd_solver.cpp:106] Iteration 4710, lr = 0.00074867
I0816 21:49:47.006244 20404 solver.cpp:337] Iteration 4720, Testing net (#0)
I0816 21:50:21.660679 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:50:21.660881 20404 solver.cpp:404]     Test net output #1: loss = 0.670552 (* 1 = 0.670552 loss)
I0816 21:50:25.138681 20404 solver.cpp:228] Iteration 4720, loss = 0.820815
I0816 21:50:25.138810 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:50:25.138851 20404 solver.cpp:244]     Train net output #1: loss = 0.820815 (* 1 = 0.820815 loss)
I0816 21:50:25.138885 20404 sgd_solver.cpp:106] Iteration 4720, lr = 0.000748289
I0816 21:51:00.015100 20404 solver.cpp:228] Iteration 4730, loss = 0.8206
I0816 21:51:00.015287 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:51:00.015302 20404 solver.cpp:244]     Train net output #1: loss = 0.8206 (* 1 = 0.8206 loss)
I0816 21:51:00.015316 20404 sgd_solver.cpp:106] Iteration 4730, lr = 0.000747908
I0816 21:51:34.908766 20404 solver.cpp:228] Iteration 4740, loss = 0.820571
I0816 21:51:34.908946 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:51:34.908960 20404 solver.cpp:244]     Train net output #1: loss = 0.820571 (* 1 = 0.820571 loss)
I0816 21:51:34.908973 20404 sgd_solver.cpp:106] Iteration 4740, lr = 0.000747527
I0816 21:52:09.819432 20404 solver.cpp:228] Iteration 4750, loss = 0.821261
I0816 21:52:09.819607 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:52:09.819622 20404 solver.cpp:244]     Train net output #1: loss = 0.821261 (* 1 = 0.821261 loss)
I0816 21:52:09.819634 20404 sgd_solver.cpp:106] Iteration 4750, lr = 0.000747147
I0816 21:52:41.258290 20404 solver.cpp:337] Iteration 4760, Testing net (#0)
I0816 21:53:15.920461 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:53:15.920631 20404 solver.cpp:404]     Test net output #1: loss = 0.671358 (* 1 = 0.671358 loss)
I0816 21:53:19.392884 20404 solver.cpp:228] Iteration 4760, loss = 0.820108
I0816 21:53:19.392935 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:53:19.392951 20404 solver.cpp:244]     Train net output #1: loss = 0.820108 (* 1 = 0.820108 loss)
I0816 21:53:19.392962 20404 sgd_solver.cpp:106] Iteration 4760, lr = 0.000746767
I0816 21:53:54.291918 20404 solver.cpp:228] Iteration 4770, loss = 0.821119
I0816 21:53:54.292080 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:53:54.292098 20404 solver.cpp:244]     Train net output #1: loss = 0.821119 (* 1 = 0.821119 loss)
I0816 21:53:54.292115 20404 sgd_solver.cpp:106] Iteration 4770, lr = 0.000746388
I0816 21:54:29.199081 20404 solver.cpp:228] Iteration 4780, loss = 0.822501
I0816 21:54:29.199265 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:54:29.199285 20404 solver.cpp:244]     Train net output #1: loss = 0.822501 (* 1 = 0.822501 loss)
I0816 21:54:29.199298 20404 sgd_solver.cpp:106] Iteration 4780, lr = 0.000746009
I0816 21:55:04.106178 20404 solver.cpp:228] Iteration 4790, loss = 0.820697
I0816 21:55:04.106353 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:55:04.106369 20404 solver.cpp:244]     Train net output #1: loss = 0.820697 (* 1 = 0.820697 loss)
I0816 21:55:04.106382 20404 sgd_solver.cpp:106] Iteration 4790, lr = 0.000745631
I0816 21:55:35.524886 20404 solver.cpp:337] Iteration 4800, Testing net (#0)
I0816 21:56:10.176039 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:56:10.176213 20404 solver.cpp:404]     Test net output #1: loss = 0.670334 (* 1 = 0.670334 loss)
I0816 21:56:13.653630 20404 solver.cpp:228] Iteration 4800, loss = 0.821102
I0816 21:56:13.653683 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:56:13.653697 20404 solver.cpp:244]     Train net output #1: loss = 0.821102 (* 1 = 0.821102 loss)
I0816 21:56:13.653708 20404 sgd_solver.cpp:106] Iteration 4800, lr = 0.000745253
I0816 21:56:48.533221 20404 solver.cpp:228] Iteration 4810, loss = 0.820457
I0816 21:56:48.533398 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:56:48.533414 20404 solver.cpp:244]     Train net output #1: loss = 0.820457 (* 1 = 0.820457 loss)
I0816 21:56:48.533427 20404 sgd_solver.cpp:106] Iteration 4810, lr = 0.000744876
I0816 21:57:23.433778 20404 solver.cpp:228] Iteration 4820, loss = 0.820047
I0816 21:57:23.433917 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0816 21:57:23.433933 20404 solver.cpp:244]     Train net output #1: loss = 0.820047 (* 1 = 0.820047 loss)
I0816 21:57:23.433944 20404 sgd_solver.cpp:106] Iteration 4820, lr = 0.000744499
I0816 21:57:58.336551 20404 solver.cpp:228] Iteration 4830, loss = 0.820506
I0816 21:57:58.336740 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 21:57:58.336756 20404 solver.cpp:244]     Train net output #1: loss = 0.820506 (* 1 = 0.820506 loss)
I0816 21:57:58.336768 20404 sgd_solver.cpp:106] Iteration 4830, lr = 0.000744122
I0816 21:58:29.766309 20404 solver.cpp:337] Iteration 4840, Testing net (#0)
I0816 21:59:04.425314 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 21:59:04.425487 20404 solver.cpp:404]     Test net output #1: loss = 0.670866 (* 1 = 0.670866 loss)
I0816 21:59:07.900184 20404 solver.cpp:228] Iteration 4840, loss = 0.820425
I0816 21:59:07.900235 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:59:07.900249 20404 solver.cpp:244]     Train net output #1: loss = 0.820425 (* 1 = 0.820425 loss)
I0816 21:59:07.900261 20404 sgd_solver.cpp:106] Iteration 4840, lr = 0.000743746
I0816 21:59:42.785254 20404 solver.cpp:228] Iteration 4850, loss = 0.821049
I0816 21:59:42.785432 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 21:59:42.785449 20404 solver.cpp:244]     Train net output #1: loss = 0.821049 (* 1 = 0.821049 loss)
I0816 21:59:42.785461 20404 sgd_solver.cpp:106] Iteration 4850, lr = 0.00074337
I0816 22:00:17.692240 20404 solver.cpp:228] Iteration 4860, loss = 0.820057
I0816 22:00:17.692409 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:00:17.692426 20404 solver.cpp:244]     Train net output #1: loss = 0.820057 (* 1 = 0.820057 loss)
I0816 22:00:17.692438 20404 sgd_solver.cpp:106] Iteration 4860, lr = 0.000742995
I0816 22:00:52.584024 20404 solver.cpp:228] Iteration 4870, loss = 0.820417
I0816 22:00:52.584123 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:00:52.584138 20404 solver.cpp:244]     Train net output #1: loss = 0.820417 (* 1 = 0.820417 loss)
I0816 22:00:52.584151 20404 sgd_solver.cpp:106] Iteration 4870, lr = 0.00074262
I0816 22:01:23.995299 20404 solver.cpp:337] Iteration 4880, Testing net (#0)
I0816 22:01:58.654592 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:01:58.654687 20404 solver.cpp:404]     Test net output #1: loss = 0.671797 (* 1 = 0.671797 loss)
I0816 22:02:02.133708 20404 solver.cpp:228] Iteration 4880, loss = 0.820347
I0816 22:02:02.133762 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:02:02.133777 20404 solver.cpp:244]     Train net output #1: loss = 0.820347 (* 1 = 0.820347 loss)
I0816 22:02:02.133788 20404 sgd_solver.cpp:106] Iteration 4880, lr = 0.000742246
I0816 22:02:37.013716 20404 solver.cpp:228] Iteration 4890, loss = 0.820201
I0816 22:02:37.013890 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:02:37.013906 20404 solver.cpp:244]     Train net output #1: loss = 0.820201 (* 1 = 0.820201 loss)
I0816 22:02:37.013918 20404 sgd_solver.cpp:106] Iteration 4890, lr = 0.000741872
I0816 22:03:11.904886 20404 solver.cpp:228] Iteration 4900, loss = 0.820048
I0816 22:03:11.905069 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:03:11.905086 20404 solver.cpp:244]     Train net output #1: loss = 0.820048 (* 1 = 0.820048 loss)
I0816 22:03:11.905097 20404 sgd_solver.cpp:106] Iteration 4900, lr = 0.000741499
I0816 22:03:46.790405 20404 solver.cpp:228] Iteration 4910, loss = 0.820688
I0816 22:03:46.790581 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:03:46.790599 20404 solver.cpp:244]     Train net output #1: loss = 0.820688 (* 1 = 0.820688 loss)
I0816 22:03:46.790611 20404 sgd_solver.cpp:106] Iteration 4910, lr = 0.000741126
I0816 22:04:18.193403 20404 solver.cpp:337] Iteration 4920, Testing net (#0)
I0816 22:04:52.848904 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:04:52.849081 20404 solver.cpp:404]     Test net output #1: loss = 0.671493 (* 1 = 0.671493 loss)
I0816 22:04:56.325523 20404 solver.cpp:228] Iteration 4920, loss = 0.820171
I0816 22:04:56.325575 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:04:56.325588 20404 solver.cpp:244]     Train net output #1: loss = 0.820171 (* 1 = 0.820171 loss)
I0816 22:04:56.325600 20404 sgd_solver.cpp:106] Iteration 4920, lr = 0.000740753
I0816 22:05:31.204632 20404 solver.cpp:228] Iteration 4930, loss = 0.820391
I0816 22:05:31.204799 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:05:31.204818 20404 solver.cpp:244]     Train net output #1: loss = 0.820391 (* 1 = 0.820391 loss)
I0816 22:05:31.204831 20404 sgd_solver.cpp:106] Iteration 4930, lr = 0.000740381
I0816 22:06:06.087148 20404 solver.cpp:228] Iteration 4940, loss = 0.821455
I0816 22:06:06.087316 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:06:06.087333 20404 solver.cpp:244]     Train net output #1: loss = 0.821455 (* 1 = 0.821455 loss)
I0816 22:06:06.087345 20404 sgd_solver.cpp:106] Iteration 4940, lr = 0.000740009
I0816 22:06:40.998014 20404 solver.cpp:228] Iteration 4950, loss = 0.820182
I0816 22:06:40.998178 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:06:40.998198 20404 solver.cpp:244]     Train net output #1: loss = 0.820182 (* 1 = 0.820182 loss)
I0816 22:06:40.998214 20404 sgd_solver.cpp:106] Iteration 4950, lr = 0.000739638
I0816 22:07:12.428009 20404 solver.cpp:337] Iteration 4960, Testing net (#0)
I0816 22:07:47.078249 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:07:47.078424 20404 solver.cpp:404]     Test net output #1: loss = 0.670256 (* 1 = 0.670256 loss)
I0816 22:07:50.558073 20404 solver.cpp:228] Iteration 4960, loss = 0.821215
I0816 22:07:50.558123 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:07:50.558137 20404 solver.cpp:244]     Train net output #1: loss = 0.821215 (* 1 = 0.821215 loss)
I0816 22:07:50.558149 20404 sgd_solver.cpp:106] Iteration 4960, lr = 0.000739267
I0816 22:08:25.448606 20404 solver.cpp:228] Iteration 4970, loss = 0.820676
I0816 22:08:25.448778 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:08:25.448794 20404 solver.cpp:244]     Train net output #1: loss = 0.820676 (* 1 = 0.820676 loss)
I0816 22:08:25.448807 20404 sgd_solver.cpp:106] Iteration 4970, lr = 0.000738897
I0816 22:09:00.351774 20404 solver.cpp:228] Iteration 4980, loss = 0.820747
I0816 22:09:00.351945 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:09:00.351961 20404 solver.cpp:244]     Train net output #1: loss = 0.820747 (* 1 = 0.820747 loss)
I0816 22:09:00.351974 20404 sgd_solver.cpp:106] Iteration 4980, lr = 0.000738527
I0816 22:09:35.245597 20404 solver.cpp:228] Iteration 4990, loss = 0.821036
I0816 22:09:35.245777 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:09:35.245792 20404 solver.cpp:244]     Train net output #1: loss = 0.821036 (* 1 = 0.821036 loss)
I0816 22:09:35.245805 20404 sgd_solver.cpp:106] Iteration 4990, lr = 0.000738157
I0816 22:10:06.649631 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_5000.caffemodel
I0816 22:10:16.174304 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_5000.solverstate
I0816 22:10:18.045250 20404 solver.cpp:337] Iteration 5000, Testing net (#0)
I0816 22:10:52.682098 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:10:52.682278 20404 solver.cpp:404]     Test net output #1: loss = 0.670122 (* 1 = 0.670122 loss)
I0816 22:10:56.153069 20404 solver.cpp:228] Iteration 5000, loss = 0.821394
I0816 22:10:56.153120 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:10:56.153134 20404 solver.cpp:244]     Train net output #1: loss = 0.821394 (* 1 = 0.821394 loss)
I0816 22:10:56.153146 20404 sgd_solver.cpp:106] Iteration 5000, lr = 0.000737788
I0816 22:11:31.035279 20404 solver.cpp:228] Iteration 5010, loss = 0.820574
I0816 22:11:31.035493 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:11:31.035509 20404 solver.cpp:244]     Train net output #1: loss = 0.820574 (* 1 = 0.820574 loss)
I0816 22:11:31.035521 20404 sgd_solver.cpp:106] Iteration 5010, lr = 0.000737419
I0816 22:12:05.941772 20404 solver.cpp:228] Iteration 5020, loss = 0.820194
I0816 22:12:05.941957 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:12:05.941973 20404 solver.cpp:244]     Train net output #1: loss = 0.820194 (* 1 = 0.820194 loss)
I0816 22:12:05.941985 20404 sgd_solver.cpp:106] Iteration 5020, lr = 0.000737051
I0816 22:12:40.846061 20404 solver.cpp:228] Iteration 5030, loss = 0.820575
I0816 22:12:40.846237 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:12:40.846253 20404 solver.cpp:244]     Train net output #1: loss = 0.820575 (* 1 = 0.820575 loss)
I0816 22:12:40.846266 20404 sgd_solver.cpp:106] Iteration 5030, lr = 0.000736683
I0816 22:13:12.254333 20404 solver.cpp:337] Iteration 5040, Testing net (#0)
I0816 22:13:46.906038 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:13:46.906209 20404 solver.cpp:404]     Test net output #1: loss = 0.670528 (* 1 = 0.670528 loss)
I0816 22:13:50.386842 20404 solver.cpp:228] Iteration 5040, loss = 0.820881
I0816 22:13:50.386893 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:13:50.386909 20404 solver.cpp:244]     Train net output #1: loss = 0.820881 (* 1 = 0.820881 loss)
I0816 22:13:50.386920 20404 sgd_solver.cpp:106] Iteration 5040, lr = 0.000736316
I0816 22:14:25.289535 20404 solver.cpp:228] Iteration 5050, loss = 0.820195
I0816 22:14:25.289623 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:14:25.289638 20404 solver.cpp:244]     Train net output #1: loss = 0.820195 (* 1 = 0.820195 loss)
I0816 22:14:25.289650 20404 sgd_solver.cpp:106] Iteration 5050, lr = 0.000735949
I0816 22:15:00.157222 20404 solver.cpp:228] Iteration 5060, loss = 0.820621
I0816 22:15:00.157321 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:15:00.157336 20404 solver.cpp:244]     Train net output #1: loss = 0.820621 (* 1 = 0.820621 loss)
I0816 22:15:00.157348 20404 sgd_solver.cpp:106] Iteration 5060, lr = 0.000735582
I0816 22:15:35.064262 20404 solver.cpp:228] Iteration 5070, loss = 0.820731
I0816 22:15:35.064443 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:15:35.064461 20404 solver.cpp:244]     Train net output #1: loss = 0.820731 (* 1 = 0.820731 loss)
I0816 22:15:35.064476 20404 sgd_solver.cpp:106] Iteration 5070, lr = 0.000735216
I0816 22:16:06.491675 20404 solver.cpp:337] Iteration 5080, Testing net (#0)
I0816 22:16:41.142629 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:16:41.142802 20404 solver.cpp:404]     Test net output #1: loss = 0.671197 (* 1 = 0.671197 loss)
I0816 22:16:44.617893 20404 solver.cpp:228] Iteration 5080, loss = 0.820036
I0816 22:16:44.617944 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0816 22:16:44.617959 20404 solver.cpp:244]     Train net output #1: loss = 0.820036 (* 1 = 0.820036 loss)
I0816 22:16:44.617970 20404 sgd_solver.cpp:106] Iteration 5080, lr = 0.000734851
I0816 22:17:19.500524 20404 solver.cpp:228] Iteration 5090, loss = 0.820156
I0816 22:17:19.500705 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:17:19.500725 20404 solver.cpp:244]     Train net output #1: loss = 0.820156 (* 1 = 0.820156 loss)
I0816 22:17:19.500740 20404 sgd_solver.cpp:106] Iteration 5090, lr = 0.000734485
I0816 22:17:54.403362 20404 solver.cpp:228] Iteration 5100, loss = 0.820501
I0816 22:17:54.403544 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:17:54.403563 20404 solver.cpp:244]     Train net output #1: loss = 0.820501 (* 1 = 0.820501 loss)
I0816 22:17:54.403578 20404 sgd_solver.cpp:106] Iteration 5100, lr = 0.00073412
I0816 22:18:29.296401 20404 solver.cpp:228] Iteration 5110, loss = 0.820574
I0816 22:18:29.296607 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:18:29.296625 20404 solver.cpp:244]     Train net output #1: loss = 0.820574 (* 1 = 0.820574 loss)
I0816 22:18:29.296660 20404 sgd_solver.cpp:106] Iteration 5110, lr = 0.000733756
I0816 22:19:00.701634 20404 solver.cpp:337] Iteration 5120, Testing net (#0)
I0816 22:19:35.345353 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:19:35.345533 20404 solver.cpp:404]     Test net output #1: loss = 0.670676 (* 1 = 0.670676 loss)
I0816 22:19:38.822095 20404 solver.cpp:228] Iteration 5120, loss = 0.820699
I0816 22:19:38.822140 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:19:38.822170 20404 solver.cpp:244]     Train net output #1: loss = 0.820699 (* 1 = 0.820699 loss)
I0816 22:19:38.822185 20404 sgd_solver.cpp:106] Iteration 5120, lr = 0.000733392
I0816 22:20:13.729887 20404 solver.cpp:228] Iteration 5130, loss = 0.820515
I0816 22:20:13.730087 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:20:13.730162 20404 solver.cpp:244]     Train net output #1: loss = 0.820515 (* 1 = 0.820515 loss)
I0816 22:20:13.730200 20404 sgd_solver.cpp:106] Iteration 5130, lr = 0.000733028
I0816 22:20:48.626890 20404 solver.cpp:228] Iteration 5140, loss = 0.820504
I0816 22:20:48.627064 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:20:48.627082 20404 solver.cpp:244]     Train net output #1: loss = 0.820504 (* 1 = 0.820504 loss)
I0816 22:20:48.627097 20404 sgd_solver.cpp:106] Iteration 5140, lr = 0.000732665
I0816 22:21:23.526382 20404 solver.cpp:228] Iteration 5150, loss = 0.821226
I0816 22:21:23.526551 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:21:23.526571 20404 solver.cpp:244]     Train net output #1: loss = 0.821226 (* 1 = 0.821226 loss)
I0816 22:21:23.526587 20404 sgd_solver.cpp:106] Iteration 5150, lr = 0.000732303
I0816 22:21:54.947213 20404 solver.cpp:337] Iteration 5160, Testing net (#0)
I0816 22:22:29.602301 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:22:29.602469 20404 solver.cpp:404]     Test net output #1: loss = 0.671354 (* 1 = 0.671354 loss)
I0816 22:22:33.082821 20404 solver.cpp:228] Iteration 5160, loss = 0.820085
I0816 22:22:33.082875 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:22:33.082890 20404 solver.cpp:244]     Train net output #1: loss = 0.820085 (* 1 = 0.820085 loss)
I0816 22:22:33.082902 20404 sgd_solver.cpp:106] Iteration 5160, lr = 0.00073194
I0816 22:23:07.963754 20404 solver.cpp:228] Iteration 5170, loss = 0.821096
I0816 22:23:07.963860 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:23:07.963876 20404 solver.cpp:244]     Train net output #1: loss = 0.821096 (* 1 = 0.821096 loss)
I0816 22:23:07.963887 20404 sgd_solver.cpp:106] Iteration 5170, lr = 0.000731578
I0816 22:23:42.843961 20404 solver.cpp:228] Iteration 5180, loss = 0.821199
I0816 22:23:42.844135 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:23:42.844151 20404 solver.cpp:244]     Train net output #1: loss = 0.821199 (* 1 = 0.821199 loss)
I0816 22:23:42.844162 20404 sgd_solver.cpp:106] Iteration 5180, lr = 0.000731217
I0816 22:24:17.742518 20404 solver.cpp:228] Iteration 5190, loss = 0.820056
I0816 22:24:17.742681 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:24:17.742696 20404 solver.cpp:244]     Train net output #1: loss = 0.820056 (* 1 = 0.820056 loss)
I0816 22:24:17.742707 20404 sgd_solver.cpp:106] Iteration 5190, lr = 0.000730856
I0816 22:24:49.173238 20404 solver.cpp:337] Iteration 5200, Testing net (#0)
I0816 22:25:23.845803 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:25:23.845906 20404 solver.cpp:404]     Test net output #1: loss = 0.671969 (* 1 = 0.671969 loss)
I0816 22:25:27.322680 20404 solver.cpp:228] Iteration 5200, loss = 0.820427
I0816 22:25:27.322726 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:25:27.322743 20404 solver.cpp:244]     Train net output #1: loss = 0.820427 (* 1 = 0.820427 loss)
I0816 22:25:27.322769 20404 sgd_solver.cpp:106] Iteration 5200, lr = 0.000730495
I0816 22:26:02.189211 20404 solver.cpp:228] Iteration 5210, loss = 0.820369
I0816 22:26:02.189424 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:26:02.189441 20404 solver.cpp:244]     Train net output #1: loss = 0.820369 (* 1 = 0.820369 loss)
I0816 22:26:02.189453 20404 sgd_solver.cpp:106] Iteration 5210, lr = 0.000730135
I0816 22:26:37.089720 20404 solver.cpp:228] Iteration 5220, loss = 0.820232
I0816 22:26:37.089905 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:26:37.089921 20404 solver.cpp:244]     Train net output #1: loss = 0.820232 (* 1 = 0.820232 loss)
I0816 22:26:37.089933 20404 sgd_solver.cpp:106] Iteration 5220, lr = 0.000729775
I0816 22:27:12.006510 20404 solver.cpp:228] Iteration 5230, loss = 0.820114
I0816 22:27:12.006685 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:27:12.006700 20404 solver.cpp:244]     Train net output #1: loss = 0.820114 (* 1 = 0.820114 loss)
I0816 22:27:12.006712 20404 sgd_solver.cpp:106] Iteration 5230, lr = 0.000729416
I0816 22:27:43.424576 20404 solver.cpp:337] Iteration 5240, Testing net (#0)
I0816 22:28:18.067215 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:28:18.067387 20404 solver.cpp:404]     Test net output #1: loss = 0.671761 (* 1 = 0.671761 loss)
I0816 22:28:21.547456 20404 solver.cpp:228] Iteration 5240, loss = 0.820314
I0816 22:28:21.547509 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:28:21.547524 20404 solver.cpp:244]     Train net output #1: loss = 0.820314 (* 1 = 0.820314 loss)
I0816 22:28:21.547536 20404 sgd_solver.cpp:106] Iteration 5240, lr = 0.000729057
I0816 22:28:56.426810 20404 solver.cpp:228] Iteration 5250, loss = 0.820728
I0816 22:28:56.426985 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:28:56.427001 20404 solver.cpp:244]     Train net output #1: loss = 0.820728 (* 1 = 0.820728 loss)
I0816 22:28:56.427014 20404 sgd_solver.cpp:106] Iteration 5250, lr = 0.000728698
I0816 22:29:31.308859 20404 solver.cpp:228] Iteration 5260, loss = 0.82079
I0816 22:29:31.309046 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:29:31.309062 20404 solver.cpp:244]     Train net output #1: loss = 0.82079 (* 1 = 0.82079 loss)
I0816 22:29:31.309073 20404 sgd_solver.cpp:106] Iteration 5260, lr = 0.00072834
I0816 22:30:06.204762 20404 solver.cpp:228] Iteration 5270, loss = 0.820349
I0816 22:30:06.204932 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:30:06.204948 20404 solver.cpp:244]     Train net output #1: loss = 0.820349 (* 1 = 0.820349 loss)
I0816 22:30:06.204960 20404 sgd_solver.cpp:106] Iteration 5270, lr = 0.000727982
I0816 22:30:37.632308 20404 solver.cpp:337] Iteration 5280, Testing net (#0)
I0816 22:31:12.293103 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:31:12.293280 20404 solver.cpp:404]     Test net output #1: loss = 0.671757 (* 1 = 0.671757 loss)
I0816 22:31:15.767117 20404 solver.cpp:228] Iteration 5280, loss = 0.820302
I0816 22:31:15.767166 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:31:15.767181 20404 solver.cpp:244]     Train net output #1: loss = 0.820302 (* 1 = 0.820302 loss)
I0816 22:31:15.767194 20404 sgd_solver.cpp:106] Iteration 5280, lr = 0.000727625
I0816 22:31:50.659345 20404 solver.cpp:228] Iteration 5290, loss = 0.820392
I0816 22:31:50.659528 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:31:50.659548 20404 solver.cpp:244]     Train net output #1: loss = 0.820392 (* 1 = 0.820392 loss)
I0816 22:31:50.659562 20404 sgd_solver.cpp:106] Iteration 5290, lr = 0.000727268
I0816 22:32:25.547421 20404 solver.cpp:228] Iteration 5300, loss = 0.821443
I0816 22:32:25.547538 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:32:25.547557 20404 solver.cpp:244]     Train net output #1: loss = 0.821443 (* 1 = 0.821443 loss)
I0816 22:32:25.547574 20404 sgd_solver.cpp:106] Iteration 5300, lr = 0.000726911
I0816 22:33:00.462131 20404 solver.cpp:228] Iteration 5310, loss = 0.82009
I0816 22:33:00.462342 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:33:00.462358 20404 solver.cpp:244]     Train net output #1: loss = 0.82009 (* 1 = 0.82009 loss)
I0816 22:33:00.462394 20404 sgd_solver.cpp:106] Iteration 5310, lr = 0.000726555
I0816 22:33:31.874475 20404 solver.cpp:337] Iteration 5320, Testing net (#0)
I0816 22:34:06.531289 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:34:06.531390 20404 solver.cpp:404]     Test net output #1: loss = 0.67064 (* 1 = 0.67064 loss)
I0816 22:34:10.004323 20404 solver.cpp:228] Iteration 5320, loss = 0.820763
I0816 22:34:10.004379 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:34:10.004393 20404 solver.cpp:244]     Train net output #1: loss = 0.820763 (* 1 = 0.820763 loss)
I0816 22:34:10.004406 20404 sgd_solver.cpp:106] Iteration 5320, lr = 0.000726199
I0816 22:34:44.884941 20404 solver.cpp:228] Iteration 5330, loss = 0.820445
I0816 22:34:44.885116 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:34:44.885135 20404 solver.cpp:244]     Train net output #1: loss = 0.820445 (* 1 = 0.820445 loss)
I0816 22:34:44.885148 20404 sgd_solver.cpp:106] Iteration 5330, lr = 0.000725844
I0816 22:35:19.769294 20404 solver.cpp:228] Iteration 5340, loss = 0.820059
I0816 22:35:19.769469 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:35:19.769484 20404 solver.cpp:244]     Train net output #1: loss = 0.820059 (* 1 = 0.820059 loss)
I0816 22:35:19.769495 20404 sgd_solver.cpp:106] Iteration 5340, lr = 0.000725489
I0816 22:35:54.657140 20404 solver.cpp:228] Iteration 5350, loss = 0.820117
I0816 22:35:54.657307 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:35:54.657323 20404 solver.cpp:244]     Train net output #1: loss = 0.820117 (* 1 = 0.820117 loss)
I0816 22:35:54.657335 20404 sgd_solver.cpp:106] Iteration 5350, lr = 0.000725135
I0816 22:36:26.071090 20404 solver.cpp:337] Iteration 5360, Testing net (#0)
I0816 22:37:00.735795 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:37:00.735980 20404 solver.cpp:404]     Test net output #1: loss = 0.671926 (* 1 = 0.671926 loss)
I0816 22:37:04.217335 20404 solver.cpp:228] Iteration 5360, loss = 0.820396
I0816 22:37:04.217386 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:37:04.217401 20404 solver.cpp:244]     Train net output #1: loss = 0.820396 (* 1 = 0.820396 loss)
I0816 22:37:04.217413 20404 sgd_solver.cpp:106] Iteration 5360, lr = 0.000724781
I0816 22:37:39.119570 20404 solver.cpp:228] Iteration 5370, loss = 0.820714
I0816 22:37:39.119746 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:37:39.119762 20404 solver.cpp:244]     Train net output #1: loss = 0.820714 (* 1 = 0.820714 loss)
I0816 22:37:39.119774 20404 sgd_solver.cpp:106] Iteration 5370, lr = 0.000724427
I0816 22:38:13.996377 20404 solver.cpp:228] Iteration 5380, loss = 0.821354
I0816 22:38:13.996474 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:38:13.996490 20404 solver.cpp:244]     Train net output #1: loss = 0.821354 (* 1 = 0.821354 loss)
I0816 22:38:13.996501 20404 sgd_solver.cpp:106] Iteration 5380, lr = 0.000724074
I0816 22:38:48.866907 20404 solver.cpp:228] Iteration 5390, loss = 0.820417
I0816 22:38:48.867089 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:38:48.867103 20404 solver.cpp:244]     Train net output #1: loss = 0.820417 (* 1 = 0.820417 loss)
I0816 22:38:48.867115 20404 sgd_solver.cpp:106] Iteration 5390, lr = 0.000723721
I0816 22:39:20.281886 20404 solver.cpp:337] Iteration 5400, Testing net (#0)
I0816 22:39:54.938207 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:39:54.938388 20404 solver.cpp:404]     Test net output #1: loss = 0.671622 (* 1 = 0.671622 loss)
I0816 22:39:58.417008 20404 solver.cpp:228] Iteration 5400, loss = 0.820224
I0816 22:39:58.417062 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:39:58.417075 20404 solver.cpp:244]     Train net output #1: loss = 0.820224 (* 1 = 0.820224 loss)
I0816 22:39:58.417086 20404 sgd_solver.cpp:106] Iteration 5400, lr = 0.000723368
I0816 22:40:33.302657 20404 solver.cpp:228] Iteration 5410, loss = 0.820554
I0816 22:40:33.302803 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:40:33.302819 20404 solver.cpp:244]     Train net output #1: loss = 0.820554 (* 1 = 0.820554 loss)
I0816 22:40:33.302831 20404 sgd_solver.cpp:106] Iteration 5410, lr = 0.000723016
I0816 22:41:08.191992 20404 solver.cpp:228] Iteration 5420, loss = 0.821942
I0816 22:41:08.192076 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:41:08.192095 20404 solver.cpp:244]     Train net output #1: loss = 0.821942 (* 1 = 0.821942 loss)
I0816 22:41:08.192109 20404 sgd_solver.cpp:106] Iteration 5420, lr = 0.000722665
I0816 22:41:43.061094 20404 solver.cpp:228] Iteration 5430, loss = 0.822396
I0816 22:41:43.061269 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:41:43.061288 20404 solver.cpp:244]     Train net output #1: loss = 0.822396 (* 1 = 0.822396 loss)
I0816 22:41:43.061305 20404 sgd_solver.cpp:106] Iteration 5430, lr = 0.000722313
I0816 22:42:14.495223 20404 solver.cpp:337] Iteration 5440, Testing net (#0)
I0816 22:42:49.131064 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:42:49.131165 20404 solver.cpp:404]     Test net output #1: loss = 0.671149 (* 1 = 0.671149 loss)
I0816 22:42:52.611801 20404 solver.cpp:228] Iteration 5440, loss = 0.820128
I0816 22:42:52.611855 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:42:52.611871 20404 solver.cpp:244]     Train net output #1: loss = 0.820128 (* 1 = 0.820128 loss)
I0816 22:42:52.611882 20404 sgd_solver.cpp:106] Iteration 5440, lr = 0.000721962
I0816 22:43:27.501762 20404 solver.cpp:228] Iteration 5450, loss = 0.820942
I0816 22:43:27.501935 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:43:27.501950 20404 solver.cpp:244]     Train net output #1: loss = 0.820942 (* 1 = 0.820942 loss)
I0816 22:43:27.501963 20404 sgd_solver.cpp:106] Iteration 5450, lr = 0.000721612
I0816 22:44:02.417737 20404 solver.cpp:228] Iteration 5460, loss = 0.820031
I0816 22:44:02.417912 20404 solver.cpp:244]     Train net output #0: accuracy = 0.67
I0816 22:44:02.417927 20404 solver.cpp:244]     Train net output #1: loss = 0.820031 (* 1 = 0.820031 loss)
I0816 22:44:02.417939 20404 sgd_solver.cpp:106] Iteration 5460, lr = 0.000721262
I0816 22:44:37.303946 20404 solver.cpp:228] Iteration 5470, loss = 0.820901
I0816 22:44:37.304122 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:44:37.304141 20404 solver.cpp:244]     Train net output #1: loss = 0.820901 (* 1 = 0.820901 loss)
I0816 22:44:37.304153 20404 sgd_solver.cpp:106] Iteration 5470, lr = 0.000720912
I0816 22:45:08.723948 20404 solver.cpp:337] Iteration 5480, Testing net (#0)
I0816 22:45:43.375177 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:45:43.375268 20404 solver.cpp:404]     Test net output #1: loss = 0.672081 (* 1 = 0.672081 loss)
I0816 22:45:46.849756 20404 solver.cpp:228] Iteration 5480, loss = 0.820478
I0816 22:45:46.849812 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:45:46.849827 20404 solver.cpp:244]     Train net output #1: loss = 0.820478 (* 1 = 0.820478 loss)
I0816 22:45:46.849838 20404 sgd_solver.cpp:106] Iteration 5480, lr = 0.000720563
I0816 22:46:21.728325 20404 solver.cpp:228] Iteration 5490, loss = 0.820453
I0816 22:46:21.728497 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:46:21.728512 20404 solver.cpp:244]     Train net output #1: loss = 0.820453 (* 1 = 0.820453 loss)
I0816 22:46:21.728524 20404 sgd_solver.cpp:106] Iteration 5490, lr = 0.000720214
I0816 22:46:56.617064 20404 solver.cpp:228] Iteration 5500, loss = 0.820329
I0816 22:46:56.617247 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:46:56.617264 20404 solver.cpp:244]     Train net output #1: loss = 0.820329 (* 1 = 0.820329 loss)
I0816 22:46:56.617276 20404 sgd_solver.cpp:106] Iteration 5500, lr = 0.000719865
I0816 22:47:31.494635 20404 solver.cpp:228] Iteration 5510, loss = 0.820392
I0816 22:47:31.494844 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:47:31.494860 20404 solver.cpp:244]     Train net output #1: loss = 0.820392 (* 1 = 0.820392 loss)
I0816 22:47:31.494873 20404 sgd_solver.cpp:106] Iteration 5510, lr = 0.000719517
I0816 22:48:02.919800 20404 solver.cpp:337] Iteration 5520, Testing net (#0)
I0816 22:48:37.578492 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:48:37.578673 20404 solver.cpp:404]     Test net output #1: loss = 0.670999 (* 1 = 0.670999 loss)
I0816 22:48:41.045922 20404 solver.cpp:228] Iteration 5520, loss = 0.820329
I0816 22:48:41.045974 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:48:41.045989 20404 solver.cpp:244]     Train net output #1: loss = 0.820329 (* 1 = 0.820329 loss)
I0816 22:48:41.046000 20404 sgd_solver.cpp:106] Iteration 5520, lr = 0.000719169
I0816 22:49:15.929910 20404 solver.cpp:228] Iteration 5530, loss = 0.820151
I0816 22:49:15.930086 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:49:15.930102 20404 solver.cpp:244]     Train net output #1: loss = 0.820151 (* 1 = 0.820151 loss)
I0816 22:49:15.930114 20404 sgd_solver.cpp:106] Iteration 5530, lr = 0.000718822
I0816 22:49:50.836680 20404 solver.cpp:228] Iteration 5540, loss = 0.820799
I0816 22:49:50.836858 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:49:50.836874 20404 solver.cpp:244]     Train net output #1: loss = 0.820799 (* 1 = 0.820799 loss)
I0816 22:49:50.836887 20404 sgd_solver.cpp:106] Iteration 5540, lr = 0.000718475
I0816 22:50:25.739334 20404 solver.cpp:228] Iteration 5550, loss = 0.820325
I0816 22:50:25.739512 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:50:25.739527 20404 solver.cpp:244]     Train net output #1: loss = 0.820325 (* 1 = 0.820325 loss)
I0816 22:50:25.739539 20404 sgd_solver.cpp:106] Iteration 5550, lr = 0.000718129
I0816 22:50:57.164017 20404 solver.cpp:337] Iteration 5560, Testing net (#0)
I0816 22:51:31.818758 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0816 22:51:31.818930 20404 solver.cpp:404]     Test net output #1: loss = 0.670137 (* 1 = 0.670137 loss)
I0816 22:51:35.295356 20404 solver.cpp:228] Iteration 5560, loss = 0.821778
I0816 22:51:35.295406 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:51:35.295420 20404 solver.cpp:244]     Train net output #1: loss = 0.821778 (* 1 = 0.821778 loss)
I0816 22:51:35.295433 20404 sgd_solver.cpp:106] Iteration 5560, lr = 0.000717782
I0816 22:52:10.203364 20404 solver.cpp:228] Iteration 5570, loss = 0.821049
I0816 22:52:10.203459 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:52:10.203475 20404 solver.cpp:244]     Train net output #1: loss = 0.821049 (* 1 = 0.821049 loss)
I0816 22:52:10.203488 20404 sgd_solver.cpp:106] Iteration 5570, lr = 0.000717437
I0816 22:52:45.114004 20404 solver.cpp:228] Iteration 5580, loss = 0.820347
I0816 22:52:45.114183 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:52:45.114199 20404 solver.cpp:244]     Train net output #1: loss = 0.820347 (* 1 = 0.820347 loss)
I0816 22:52:45.114212 20404 sgd_solver.cpp:106] Iteration 5580, lr = 0.000717091
I0816 22:53:20.023397 20404 solver.cpp:228] Iteration 5590, loss = 0.820131
I0816 22:53:20.023583 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:53:20.023599 20404 solver.cpp:244]     Train net output #1: loss = 0.820131 (* 1 = 0.820131 loss)
I0816 22:53:20.023612 20404 sgd_solver.cpp:106] Iteration 5590, lr = 0.000716746
I0816 22:53:51.424410 20404 solver.cpp:337] Iteration 5600, Testing net (#0)
I0816 22:54:26.079831 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:54:26.080010 20404 solver.cpp:404]     Test net output #1: loss = 0.670364 (* 1 = 0.670364 loss)
I0816 22:54:29.553781 20404 solver.cpp:228] Iteration 5600, loss = 0.821145
I0816 22:54:29.553836 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:54:29.553851 20404 solver.cpp:244]     Train net output #1: loss = 0.821145 (* 1 = 0.821145 loss)
I0816 22:54:29.553864 20404 sgd_solver.cpp:106] Iteration 5600, lr = 0.000716402
I0816 22:55:04.427896 20404 solver.cpp:228] Iteration 5610, loss = 0.820231
I0816 22:55:04.428107 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:55:04.428123 20404 solver.cpp:244]     Train net output #1: loss = 0.820231 (* 1 = 0.820231 loss)
I0816 22:55:04.428135 20404 sgd_solver.cpp:106] Iteration 5610, lr = 0.000716057
I0816 22:55:39.293700 20404 solver.cpp:228] Iteration 5620, loss = 0.820322
I0816 22:55:39.293882 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:55:39.293897 20404 solver.cpp:244]     Train net output #1: loss = 0.820322 (* 1 = 0.820322 loss)
I0816 22:55:39.293910 20404 sgd_solver.cpp:106] Iteration 5620, lr = 0.000715714
I0816 22:56:14.203291 20404 solver.cpp:228] Iteration 5630, loss = 0.820258
I0816 22:56:14.203466 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:56:14.203482 20404 solver.cpp:244]     Train net output #1: loss = 0.820258 (* 1 = 0.820258 loss)
I0816 22:56:14.203495 20404 sgd_solver.cpp:106] Iteration 5630, lr = 0.00071537
I0816 22:56:45.616739 20404 solver.cpp:337] Iteration 5640, Testing net (#0)
I0816 22:57:20.275040 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 22:57:20.275221 20404 solver.cpp:404]     Test net output #1: loss = 0.670888 (* 1 = 0.670888 loss)
I0816 22:57:23.752243 20404 solver.cpp:228] Iteration 5640, loss = 0.820479
I0816 22:57:23.752295 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:57:23.752310 20404 solver.cpp:244]     Train net output #1: loss = 0.820479 (* 1 = 0.820479 loss)
I0816 22:57:23.752321 20404 sgd_solver.cpp:106] Iteration 5640, lr = 0.000715027
I0816 22:57:58.636121 20404 solver.cpp:228] Iteration 5650, loss = 0.820969
I0816 22:57:58.636278 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 22:57:58.636294 20404 solver.cpp:244]     Train net output #1: loss = 0.820969 (* 1 = 0.820969 loss)
I0816 22:57:58.636307 20404 sgd_solver.cpp:106] Iteration 5650, lr = 0.000714684
I0816 22:58:33.547405 20404 solver.cpp:228] Iteration 5660, loss = 0.820077
I0816 22:58:33.547569 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:58:33.547585 20404 solver.cpp:244]     Train net output #1: loss = 0.820077 (* 1 = 0.820077 loss)
I0816 22:58:33.547597 20404 sgd_solver.cpp:106] Iteration 5660, lr = 0.000714342
I0816 22:59:08.444145 20404 solver.cpp:228] Iteration 5670, loss = 0.820217
I0816 22:59:08.444324 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 22:59:08.444339 20404 solver.cpp:244]     Train net output #1: loss = 0.820217 (* 1 = 0.820217 loss)
I0816 22:59:08.444352 20404 sgd_solver.cpp:106] Iteration 5670, lr = 0.000714
I0816 22:59:39.845772 20404 solver.cpp:337] Iteration 5680, Testing net (#0)
I0816 23:00:14.497634 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:00:14.497797 20404 solver.cpp:404]     Test net output #1: loss = 0.671609 (* 1 = 0.671609 loss)
I0816 23:00:17.975399 20404 solver.cpp:228] Iteration 5680, loss = 0.820204
I0816 23:00:17.975440 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:00:17.975455 20404 solver.cpp:244]     Train net output #1: loss = 0.820204 (* 1 = 0.820204 loss)
I0816 23:00:17.975466 20404 sgd_solver.cpp:106] Iteration 5680, lr = 0.000713659
I0816 23:00:52.863287 20404 solver.cpp:228] Iteration 5690, loss = 0.820262
I0816 23:00:52.863471 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:00:52.863487 20404 solver.cpp:244]     Train net output #1: loss = 0.820262 (* 1 = 0.820262 loss)
I0816 23:00:52.863498 20404 sgd_solver.cpp:106] Iteration 5690, lr = 0.000713317
I0816 23:01:27.748231 20404 solver.cpp:228] Iteration 5700, loss = 0.82027
I0816 23:01:27.748313 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:01:27.748327 20404 solver.cpp:244]     Train net output #1: loss = 0.82027 (* 1 = 0.82027 loss)
I0816 23:01:27.748339 20404 sgd_solver.cpp:106] Iteration 5700, lr = 0.000712977
I0816 23:02:02.624841 20404 solver.cpp:228] Iteration 5710, loss = 0.821064
I0816 23:02:02.625031 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:02:02.625051 20404 solver.cpp:244]     Train net output #1: loss = 0.821064 (* 1 = 0.821064 loss)
I0816 23:02:02.625066 20404 sgd_solver.cpp:106] Iteration 5710, lr = 0.000712636
I0816 23:02:34.031023 20404 solver.cpp:337] Iteration 5720, Testing net (#0)
I0816 23:03:08.681846 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:03:08.682013 20404 solver.cpp:404]     Test net output #1: loss = 0.670866 (* 1 = 0.670866 loss)
I0816 23:03:12.160979 20404 solver.cpp:228] Iteration 5720, loss = 0.820516
I0816 23:03:12.161033 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:03:12.161048 20404 solver.cpp:244]     Train net output #1: loss = 0.820516 (* 1 = 0.820516 loss)
I0816 23:03:12.161061 20404 sgd_solver.cpp:106] Iteration 5720, lr = 0.000712296
I0816 23:03:47.050751 20404 solver.cpp:228] Iteration 5730, loss = 0.820961
I0816 23:03:47.050940 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:03:47.050956 20404 solver.cpp:244]     Train net output #1: loss = 0.820961 (* 1 = 0.820961 loss)
I0816 23:03:47.050967 20404 sgd_solver.cpp:106] Iteration 5730, lr = 0.000711957
I0816 23:04:21.961779 20404 solver.cpp:228] Iteration 5740, loss = 0.821427
I0816 23:04:21.961875 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:04:21.961891 20404 solver.cpp:244]     Train net output #1: loss = 0.821427 (* 1 = 0.821427 loss)
I0816 23:04:21.961904 20404 sgd_solver.cpp:106] Iteration 5740, lr = 0.000711617
I0816 23:04:56.851908 20404 solver.cpp:228] Iteration 5750, loss = 0.820133
I0816 23:04:56.852083 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:04:56.852098 20404 solver.cpp:244]     Train net output #1: loss = 0.820133 (* 1 = 0.820133 loss)
I0816 23:04:56.852111 20404 sgd_solver.cpp:106] Iteration 5750, lr = 0.000711278
I0816 23:05:28.264729 20404 solver.cpp:337] Iteration 5760, Testing net (#0)
I0816 23:06:02.902629 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:06:02.902802 20404 solver.cpp:404]     Test net output #1: loss = 0.670283 (* 1 = 0.670283 loss)
I0816 23:06:06.377243 20404 solver.cpp:228] Iteration 5760, loss = 0.821263
I0816 23:06:06.377287 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:06:06.377302 20404 solver.cpp:244]     Train net output #1: loss = 0.821263 (* 1 = 0.821263 loss)
I0816 23:06:06.377315 20404 sgd_solver.cpp:106] Iteration 5760, lr = 0.00071094
I0816 23:06:41.262557 20404 solver.cpp:228] Iteration 5770, loss = 0.820759
I0816 23:06:41.262742 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:06:41.262756 20404 solver.cpp:244]     Train net output #1: loss = 0.820759 (* 1 = 0.820759 loss)
I0816 23:06:41.262768 20404 sgd_solver.cpp:106] Iteration 5770, lr = 0.000710602
I0816 23:07:16.151254 20404 solver.cpp:228] Iteration 5780, loss = 0.820834
I0816 23:07:16.151434 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:07:16.151450 20404 solver.cpp:244]     Train net output #1: loss = 0.820834 (* 1 = 0.820834 loss)
I0816 23:07:16.151463 20404 sgd_solver.cpp:106] Iteration 5780, lr = 0.000710264
I0816 23:07:51.052629 20404 solver.cpp:228] Iteration 5790, loss = 0.821109
I0816 23:07:51.052803 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:07:51.052819 20404 solver.cpp:244]     Train net output #1: loss = 0.821109 (* 1 = 0.821109 loss)
I0816 23:07:51.052831 20404 sgd_solver.cpp:106] Iteration 5790, lr = 0.000709927
I0816 23:08:22.479198 20404 solver.cpp:337] Iteration 5800, Testing net (#0)
I0816 23:08:57.140947 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:08:57.141130 20404 solver.cpp:404]     Test net output #1: loss = 0.670137 (* 1 = 0.670137 loss)
I0816 23:09:00.618243 20404 solver.cpp:228] Iteration 5800, loss = 0.821456
I0816 23:09:00.618294 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:09:00.618309 20404 solver.cpp:244]     Train net output #1: loss = 0.821456 (* 1 = 0.821456 loss)
I0816 23:09:00.618320 20404 sgd_solver.cpp:106] Iteration 5800, lr = 0.00070959
I0816 23:09:35.507810 20404 solver.cpp:228] Iteration 5810, loss = 0.820677
I0816 23:09:35.508033 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:09:35.508049 20404 solver.cpp:244]     Train net output #1: loss = 0.820677 (* 1 = 0.820677 loss)
I0816 23:09:35.508061 20404 sgd_solver.cpp:106] Iteration 5810, lr = 0.000709253
I0816 23:10:10.410909 20404 solver.cpp:228] Iteration 5820, loss = 0.820322
I0816 23:10:10.411084 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:10:10.411100 20404 solver.cpp:244]     Train net output #1: loss = 0.820322 (* 1 = 0.820322 loss)
I0816 23:10:10.411113 20404 sgd_solver.cpp:106] Iteration 5820, lr = 0.000708917
I0816 23:10:45.308957 20404 solver.cpp:228] Iteration 5830, loss = 0.820502
I0816 23:10:45.309145 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:10:45.309161 20404 solver.cpp:244]     Train net output #1: loss = 0.820502 (* 1 = 0.820502 loss)
I0816 23:10:45.309173 20404 sgd_solver.cpp:106] Iteration 5830, lr = 0.000708581
I0816 23:11:16.718443 20404 solver.cpp:337] Iteration 5840, Testing net (#0)
I0816 23:11:51.371263 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:11:51.371363 20404 solver.cpp:404]     Test net output #1: loss = 0.67022 (* 1 = 0.67022 loss)
I0816 23:11:54.847973 20404 solver.cpp:228] Iteration 5840, loss = 0.821355
I0816 23:11:54.848023 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:11:54.848037 20404 solver.cpp:244]     Train net output #1: loss = 0.821355 (* 1 = 0.821355 loss)
I0816 23:11:54.848049 20404 sgd_solver.cpp:106] Iteration 5840, lr = 0.000708245
I0816 23:12:29.768149 20404 solver.cpp:228] Iteration 5850, loss = 0.820172
I0816 23:12:29.768329 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:12:29.768344 20404 solver.cpp:244]     Train net output #1: loss = 0.820172 (* 1 = 0.820172 loss)
I0816 23:12:29.768357 20404 sgd_solver.cpp:106] Iteration 5850, lr = 0.00070791
I0816 23:13:04.677906 20404 solver.cpp:228] Iteration 5860, loss = 0.820417
I0816 23:13:04.678079 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:13:04.678095 20404 solver.cpp:244]     Train net output #1: loss = 0.820417 (* 1 = 0.820417 loss)
I0816 23:13:04.678107 20404 sgd_solver.cpp:106] Iteration 5860, lr = 0.000707575
I0816 23:13:39.569787 20404 solver.cpp:228] Iteration 5870, loss = 0.82138
I0816 23:13:39.569968 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:13:39.569983 20404 solver.cpp:244]     Train net output #1: loss = 0.82138 (* 1 = 0.82138 loss)
I0816 23:13:39.569996 20404 sgd_solver.cpp:106] Iteration 5870, lr = 0.000707241
I0816 23:14:10.980633 20404 solver.cpp:337] Iteration 5880, Testing net (#0)
I0816 23:14:45.624475 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:14:45.624647 20404 solver.cpp:404]     Test net output #1: loss = 0.671225 (* 1 = 0.671225 loss)
I0816 23:14:49.095852 20404 solver.cpp:228] Iteration 5880, loss = 0.820074
I0816 23:14:49.095902 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:14:49.095916 20404 solver.cpp:244]     Train net output #1: loss = 0.820074 (* 1 = 0.820074 loss)
I0816 23:14:49.095928 20404 sgd_solver.cpp:106] Iteration 5880, lr = 0.000706907
I0816 23:15:23.999915 20404 solver.cpp:228] Iteration 5890, loss = 0.820985
I0816 23:15:24.000094 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:15:24.000111 20404 solver.cpp:244]     Train net output #1: loss = 0.820985 (* 1 = 0.820985 loss)
I0816 23:15:24.000123 20404 sgd_solver.cpp:106] Iteration 5890, lr = 0.000706573
I0816 23:15:58.884696 20404 solver.cpp:228] Iteration 5900, loss = 0.820027
I0816 23:15:58.884915 20404 solver.cpp:244]     Train net output #0: accuracy = 0.73
I0816 23:15:58.884932 20404 solver.cpp:244]     Train net output #1: loss = 0.820027 (* 1 = 0.820027 loss)
I0816 23:15:58.884944 20404 sgd_solver.cpp:106] Iteration 5900, lr = 0.00070624
I0816 23:16:33.765269 20404 solver.cpp:228] Iteration 5910, loss = 0.820369
I0816 23:16:33.765355 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:16:33.765370 20404 solver.cpp:244]     Train net output #1: loss = 0.820369 (* 1 = 0.820369 loss)
I0816 23:16:33.765382 20404 sgd_solver.cpp:106] Iteration 5910, lr = 0.000705907
I0816 23:17:05.202258 20404 solver.cpp:337] Iteration 5920, Testing net (#0)
I0816 23:17:39.856868 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:17:39.857040 20404 solver.cpp:404]     Test net output #1: loss = 0.671745 (* 1 = 0.671745 loss)
I0816 23:17:43.328341 20404 solver.cpp:228] Iteration 5920, loss = 0.820267
I0816 23:17:43.328380 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:17:43.328395 20404 solver.cpp:244]     Train net output #1: loss = 0.820267 (* 1 = 0.820267 loss)
I0816 23:17:43.328408 20404 sgd_solver.cpp:106] Iteration 5920, lr = 0.000705574
I0816 23:18:18.223182 20404 solver.cpp:228] Iteration 5930, loss = 0.82012
I0816 23:18:18.223368 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:18:18.223384 20404 solver.cpp:244]     Train net output #1: loss = 0.82012 (* 1 = 0.82012 loss)
I0816 23:18:18.223397 20404 sgd_solver.cpp:106] Iteration 5930, lr = 0.000705242
I0816 23:18:53.100762 20404 solver.cpp:228] Iteration 5940, loss = 0.821533
I0816 23:18:53.100847 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:18:53.100862 20404 solver.cpp:244]     Train net output #1: loss = 0.821533 (* 1 = 0.821533 loss)
I0816 23:18:53.100874 20404 sgd_solver.cpp:106] Iteration 5940, lr = 0.00070491
I0816 23:19:27.983072 20404 solver.cpp:228] Iteration 5950, loss = 0.820116
I0816 23:19:27.983217 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:19:27.983237 20404 solver.cpp:244]     Train net output #1: loss = 0.820116 (* 1 = 0.820116 loss)
I0816 23:19:27.983253 20404 sgd_solver.cpp:106] Iteration 5950, lr = 0.000704579
I0816 23:19:59.408222 20404 solver.cpp:337] Iteration 5960, Testing net (#0)
I0816 23:20:34.066834 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:20:34.067004 20404 solver.cpp:404]     Test net output #1: loss = 0.670513 (* 1 = 0.670513 loss)
I0816 23:20:37.539165 20404 solver.cpp:228] Iteration 5960, loss = 0.820995
I0816 23:20:37.539216 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:20:37.539230 20404 solver.cpp:244]     Train net output #1: loss = 0.820995 (* 1 = 0.820995 loss)
I0816 23:20:37.539242 20404 sgd_solver.cpp:106] Iteration 5960, lr = 0.000704248
I0816 23:21:12.427284 20404 solver.cpp:228] Iteration 5970, loss = 0.820113
I0816 23:21:12.427461 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:21:12.427477 20404 solver.cpp:244]     Train net output #1: loss = 0.820113 (* 1 = 0.820113 loss)
I0816 23:21:12.427489 20404 sgd_solver.cpp:106] Iteration 5970, lr = 0.000703917
I0816 23:21:47.326721 20404 solver.cpp:228] Iteration 5980, loss = 0.820271
I0816 23:21:47.326894 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:21:47.326910 20404 solver.cpp:244]     Train net output #1: loss = 0.820271 (* 1 = 0.820271 loss)
I0816 23:21:47.326923 20404 sgd_solver.cpp:106] Iteration 5980, lr = 0.000703586
I0816 23:22:22.209226 20404 solver.cpp:228] Iteration 5990, loss = 0.820264
I0816 23:22:22.209409 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:22:22.209425 20404 solver.cpp:244]     Train net output #1: loss = 0.820264 (* 1 = 0.820264 loss)
I0816 23:22:22.209437 20404 sgd_solver.cpp:106] Iteration 5990, lr = 0.000703256
I0816 23:22:53.613641 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_6000.caffemodel
I0816 23:23:03.130305 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_6000.solverstate
I0816 23:23:04.907294 20404 solver.cpp:337] Iteration 6000, Testing net (#0)
I0816 23:23:39.551067 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:23:39.551302 20404 solver.cpp:404]     Test net output #1: loss = 0.671163 (* 1 = 0.671163 loss)
I0816 23:23:43.013422 20404 solver.cpp:228] Iteration 6000, loss = 0.820165
I0816 23:23:43.013473 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:23:43.013487 20404 solver.cpp:244]     Train net output #1: loss = 0.820165 (* 1 = 0.820165 loss)
I0816 23:23:43.013499 20404 sgd_solver.cpp:106] Iteration 6000, lr = 0.000702927
I0816 23:24:17.900507 20404 solver.cpp:228] Iteration 6010, loss = 0.821508
I0816 23:24:17.900699 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:24:17.900719 20404 solver.cpp:244]     Train net output #1: loss = 0.821508 (* 1 = 0.821508 loss)
I0816 23:24:17.900734 20404 sgd_solver.cpp:106] Iteration 6010, lr = 0.000702597
I0816 23:24:52.781533 20404 solver.cpp:228] Iteration 6020, loss = 0.820325
I0816 23:24:52.781703 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:24:52.781719 20404 solver.cpp:244]     Train net output #1: loss = 0.820325 (* 1 = 0.820325 loss)
I0816 23:24:52.781733 20404 sgd_solver.cpp:106] Iteration 6020, lr = 0.000702268
I0816 23:25:27.684528 20404 solver.cpp:228] Iteration 6030, loss = 0.820566
I0816 23:25:27.684702 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:25:27.684718 20404 solver.cpp:244]     Train net output #1: loss = 0.820566 (* 1 = 0.820566 loss)
I0816 23:25:27.684731 20404 sgd_solver.cpp:106] Iteration 6030, lr = 0.00070194
I0816 23:25:59.091403 20404 solver.cpp:337] Iteration 6040, Testing net (#0)
I0816 23:26:33.752300 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:26:33.752477 20404 solver.cpp:404]     Test net output #1: loss = 0.670714 (* 1 = 0.670714 loss)
I0816 23:26:37.233979 20404 solver.cpp:228] Iteration 6040, loss = 0.820738
I0816 23:26:37.234031 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:26:37.234045 20404 solver.cpp:244]     Train net output #1: loss = 0.820738 (* 1 = 0.820738 loss)
I0816 23:26:37.234057 20404 sgd_solver.cpp:106] Iteration 6040, lr = 0.000701612
I0816 23:27:12.117429 20404 solver.cpp:228] Iteration 6050, loss = 0.820319
I0816 23:27:12.117615 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:27:12.117631 20404 solver.cpp:244]     Train net output #1: loss = 0.820319 (* 1 = 0.820319 loss)
I0816 23:27:12.117643 20404 sgd_solver.cpp:106] Iteration 6050, lr = 0.000701284
I0816 23:27:47.003661 20404 solver.cpp:228] Iteration 6060, loss = 0.820832
I0816 23:27:47.003831 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:27:47.003847 20404 solver.cpp:244]     Train net output #1: loss = 0.820832 (* 1 = 0.820832 loss)
I0816 23:27:47.003859 20404 sgd_solver.cpp:106] Iteration 6060, lr = 0.000700956
I0816 23:28:21.893468 20404 solver.cpp:228] Iteration 6070, loss = 0.820065
I0816 23:28:21.893641 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:28:21.893656 20404 solver.cpp:244]     Train net output #1: loss = 0.820065 (* 1 = 0.820065 loss)
I0816 23:28:21.893669 20404 sgd_solver.cpp:106] Iteration 6070, lr = 0.000700629
I0816 23:28:53.313057 20404 solver.cpp:337] Iteration 6080, Testing net (#0)
I0816 23:29:27.941263 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:29:27.941434 20404 solver.cpp:404]     Test net output #1: loss = 0.671593 (* 1 = 0.671593 loss)
I0816 23:29:31.415681 20404 solver.cpp:228] Iteration 6080, loss = 0.820183
I0816 23:29:31.415736 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:29:31.415751 20404 solver.cpp:244]     Train net output #1: loss = 0.820183 (* 1 = 0.820183 loss)
I0816 23:29:31.415763 20404 sgd_solver.cpp:106] Iteration 6080, lr = 0.000700302
I0816 23:30:06.297955 20404 solver.cpp:228] Iteration 6090, loss = 0.820303
I0816 23:30:06.298171 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:30:06.298185 20404 solver.cpp:244]     Train net output #1: loss = 0.820303 (* 1 = 0.820303 loss)
I0816 23:30:06.298214 20404 sgd_solver.cpp:106] Iteration 6090, lr = 0.000699976
I0816 23:30:41.199681 20404 solver.cpp:228] Iteration 6100, loss = 0.820855
I0816 23:30:41.199862 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:30:41.199877 20404 solver.cpp:244]     Train net output #1: loss = 0.820855 (* 1 = 0.820855 loss)
I0816 23:30:41.199889 20404 sgd_solver.cpp:106] Iteration 6100, lr = 0.00069965
I0816 23:31:16.103441 20404 solver.cpp:228] Iteration 6110, loss = 0.820229
I0816 23:31:16.103621 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:31:16.103637 20404 solver.cpp:244]     Train net output #1: loss = 0.820229 (* 1 = 0.820229 loss)
I0816 23:31:16.103651 20404 sgd_solver.cpp:106] Iteration 6110, lr = 0.000699324
I0816 23:31:47.525600 20404 solver.cpp:337] Iteration 6120, Testing net (#0)
I0816 23:32:22.192944 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:32:22.193116 20404 solver.cpp:404]     Test net output #1: loss = 0.67178 (* 1 = 0.67178 loss)
I0816 23:32:25.675195 20404 solver.cpp:228] Iteration 6120, loss = 0.820282
I0816 23:32:25.675247 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:32:25.675262 20404 solver.cpp:244]     Train net output #1: loss = 0.820282 (* 1 = 0.820282 loss)
I0816 23:32:25.675282 20404 sgd_solver.cpp:106] Iteration 6120, lr = 0.000698999
I0816 23:33:00.567065 20404 solver.cpp:228] Iteration 6130, loss = 0.820775
I0816 23:33:00.567250 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:33:00.567266 20404 solver.cpp:244]     Train net output #1: loss = 0.820775 (* 1 = 0.820775 loss)
I0816 23:33:00.567282 20404 sgd_solver.cpp:106] Iteration 6130, lr = 0.000698673
I0816 23:33:35.484047 20404 solver.cpp:228] Iteration 6140, loss = 0.82003
I0816 23:33:35.484226 20404 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0816 23:33:35.484241 20404 solver.cpp:244]     Train net output #1: loss = 0.82003 (* 1 = 0.82003 loss)
I0816 23:33:35.484253 20404 sgd_solver.cpp:106] Iteration 6140, lr = 0.000698349
I0816 23:34:10.375505 20404 solver.cpp:228] Iteration 6150, loss = 0.82065
I0816 23:34:10.375687 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:34:10.375702 20404 solver.cpp:244]     Train net output #1: loss = 0.82065 (* 1 = 0.82065 loss)
I0816 23:34:10.375715 20404 sgd_solver.cpp:106] Iteration 6150, lr = 0.000698024
I0816 23:34:41.787076 20404 solver.cpp:337] Iteration 6160, Testing net (#0)
I0816 23:35:16.440069 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:35:16.440244 20404 solver.cpp:404]     Test net output #1: loss = 0.67169 (* 1 = 0.67169 loss)
I0816 23:35:19.909595 20404 solver.cpp:228] Iteration 6160, loss = 0.820228
I0816 23:35:19.909651 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:35:19.909665 20404 solver.cpp:244]     Train net output #1: loss = 0.820228 (* 1 = 0.820228 loss)
I0816 23:35:19.909678 20404 sgd_solver.cpp:106] Iteration 6160, lr = 0.0006977
I0816 23:35:54.812211 20404 solver.cpp:228] Iteration 6170, loss = 0.820146
I0816 23:35:54.812392 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:35:54.812407 20404 solver.cpp:244]     Train net output #1: loss = 0.820146 (* 1 = 0.820146 loss)
I0816 23:35:54.812419 20404 sgd_solver.cpp:106] Iteration 6170, lr = 0.000697377
I0816 23:36:29.716099 20404 solver.cpp:228] Iteration 6180, loss = 0.820522
I0816 23:36:29.716269 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:36:29.716284 20404 solver.cpp:244]     Train net output #1: loss = 0.820522 (* 1 = 0.820522 loss)
I0816 23:36:29.716297 20404 sgd_solver.cpp:106] Iteration 6180, lr = 0.000697054
I0816 23:37:04.578086 20404 solver.cpp:228] Iteration 6190, loss = 0.821276
I0816 23:37:04.578269 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:37:04.578285 20404 solver.cpp:244]     Train net output #1: loss = 0.821276 (* 1 = 0.821276 loss)
I0816 23:37:04.578297 20404 sgd_solver.cpp:106] Iteration 6190, lr = 0.000696731
I0816 23:37:35.983929 20404 solver.cpp:337] Iteration 6200, Testing net (#0)
I0816 23:38:10.637687 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:38:10.637786 20404 solver.cpp:404]     Test net output #1: loss = 0.671207 (* 1 = 0.671207 loss)
I0816 23:38:14.117224 20404 solver.cpp:228] Iteration 6200, loss = 0.820127
I0816 23:38:14.117278 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:38:14.117293 20404 solver.cpp:244]     Train net output #1: loss = 0.820127 (* 1 = 0.820127 loss)
I0816 23:38:14.117305 20404 sgd_solver.cpp:106] Iteration 6200, lr = 0.000696408
I0816 23:38:48.997334 20404 solver.cpp:228] Iteration 6210, loss = 0.820118
I0816 23:38:48.997514 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:38:48.997529 20404 solver.cpp:244]     Train net output #1: loss = 0.820118 (* 1 = 0.820118 loss)
I0816 23:38:48.997540 20404 sgd_solver.cpp:106] Iteration 6210, lr = 0.000696086
I0816 23:39:23.893631 20404 solver.cpp:228] Iteration 6220, loss = 0.82065
I0816 23:39:23.893728 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:39:23.893743 20404 solver.cpp:244]     Train net output #1: loss = 0.82065 (* 1 = 0.82065 loss)
I0816 23:39:23.893754 20404 sgd_solver.cpp:106] Iteration 6220, lr = 0.000695764
I0816 23:39:58.793124 20404 solver.cpp:228] Iteration 6230, loss = 0.820065
I0816 23:39:58.793223 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:39:58.793238 20404 solver.cpp:244]     Train net output #1: loss = 0.820065 (* 1 = 0.820065 loss)
I0816 23:39:58.793251 20404 sgd_solver.cpp:106] Iteration 6230, lr = 0.000695442
I0816 23:40:30.220252 20404 solver.cpp:337] Iteration 6240, Testing net (#0)
I0816 23:41:04.857594 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:41:04.857769 20404 solver.cpp:404]     Test net output #1: loss = 0.67109 (* 1 = 0.67109 loss)
I0816 23:41:08.330431 20404 solver.cpp:228] Iteration 6240, loss = 0.820275
I0816 23:41:08.330473 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:41:08.330492 20404 solver.cpp:244]     Train net output #1: loss = 0.820275 (* 1 = 0.820275 loss)
I0816 23:41:08.330516 20404 sgd_solver.cpp:106] Iteration 6240, lr = 0.000695121
I0816 23:41:43.212430 20404 solver.cpp:228] Iteration 6250, loss = 0.820169
I0816 23:41:43.212608 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:41:43.212627 20404 solver.cpp:244]     Train net output #1: loss = 0.820169 (* 1 = 0.820169 loss)
I0816 23:41:43.212642 20404 sgd_solver.cpp:106] Iteration 6250, lr = 0.0006948
I0816 23:42:18.112882 20404 solver.cpp:228] Iteration 6260, loss = 0.820203
I0816 23:42:18.113061 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:42:18.113076 20404 solver.cpp:244]     Train net output #1: loss = 0.820203 (* 1 = 0.820203 loss)
I0816 23:42:18.113090 20404 sgd_solver.cpp:106] Iteration 6260, lr = 0.00069448
I0816 23:42:53.035882 20404 solver.cpp:228] Iteration 6270, loss = 0.820175
I0816 23:42:53.036065 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:42:53.036083 20404 solver.cpp:244]     Train net output #1: loss = 0.820175 (* 1 = 0.820175 loss)
I0816 23:42:53.036098 20404 sgd_solver.cpp:106] Iteration 6270, lr = 0.00069416
I0816 23:43:24.438168 20404 solver.cpp:337] Iteration 6280, Testing net (#0)
I0816 23:43:59.079478 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:43:59.079650 20404 solver.cpp:404]     Test net output #1: loss = 0.671299 (* 1 = 0.671299 loss)
I0816 23:44:02.565042 20404 solver.cpp:228] Iteration 6280, loss = 0.820024
I0816 23:44:02.565090 20404 solver.cpp:244]     Train net output #0: accuracy = 0.77
I0816 23:44:02.565104 20404 solver.cpp:244]     Train net output #1: loss = 0.820024 (* 1 = 0.820024 loss)
I0816 23:44:02.565116 20404 sgd_solver.cpp:106] Iteration 6280, lr = 0.00069384
I0816 23:44:37.449452 20404 solver.cpp:228] Iteration 6290, loss = 0.820349
I0816 23:44:37.449676 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:44:37.449692 20404 solver.cpp:244]     Train net output #1: loss = 0.820349 (* 1 = 0.820349 loss)
I0816 23:44:37.449707 20404 sgd_solver.cpp:106] Iteration 6290, lr = 0.00069352
I0816 23:45:12.332808 20404 solver.cpp:228] Iteration 6300, loss = 0.820239
I0816 23:45:12.332989 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:45:12.333005 20404 solver.cpp:244]     Train net output #1: loss = 0.820239 (* 1 = 0.820239 loss)
I0816 23:45:12.333017 20404 sgd_solver.cpp:106] Iteration 6300, lr = 0.000693201
I0816 23:45:47.220403 20404 solver.cpp:228] Iteration 6310, loss = 0.820502
I0816 23:45:47.220592 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:45:47.220607 20404 solver.cpp:244]     Train net output #1: loss = 0.820502 (* 1 = 0.820502 loss)
I0816 23:45:47.220619 20404 sgd_solver.cpp:106] Iteration 6310, lr = 0.000692882
I0816 23:46:18.649394 20404 solver.cpp:337] Iteration 6320, Testing net (#0)
I0816 23:46:53.299724 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:46:53.299901 20404 solver.cpp:404]     Test net output #1: loss = 0.670633 (* 1 = 0.670633 loss)
I0816 23:46:56.771667 20404 solver.cpp:228] Iteration 6320, loss = 0.820865
I0816 23:46:56.771719 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:46:56.771734 20404 solver.cpp:244]     Train net output #1: loss = 0.820865 (* 1 = 0.820865 loss)
I0816 23:46:56.771745 20404 sgd_solver.cpp:106] Iteration 6320, lr = 0.000692564
I0816 23:47:31.660506 20404 solver.cpp:228] Iteration 6330, loss = 0.820223
I0816 23:47:31.660673 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:47:31.660688 20404 solver.cpp:244]     Train net output #1: loss = 0.820223 (* 1 = 0.820223 loss)
I0816 23:47:31.660701 20404 sgd_solver.cpp:106] Iteration 6330, lr = 0.000692246
I0816 23:48:06.572201 20404 solver.cpp:228] Iteration 6340, loss = 0.820559
I0816 23:48:06.572394 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:48:06.572410 20404 solver.cpp:244]     Train net output #1: loss = 0.820559 (* 1 = 0.820559 loss)
I0816 23:48:06.572423 20404 sgd_solver.cpp:106] Iteration 6340, lr = 0.000691928
I0816 23:48:41.463917 20404 solver.cpp:228] Iteration 6350, loss = 0.820723
I0816 23:48:41.464020 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:48:41.464036 20404 solver.cpp:244]     Train net output #1: loss = 0.820723 (* 1 = 0.820723 loss)
I0816 23:48:41.464049 20404 sgd_solver.cpp:106] Iteration 6350, lr = 0.000691611
I0816 23:49:12.906149 20404 solver.cpp:337] Iteration 6360, Testing net (#0)
I0816 23:49:47.538795 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:49:47.538985 20404 solver.cpp:404]     Test net output #1: loss = 0.671253 (* 1 = 0.671253 loss)
I0816 23:49:51.012826 20404 solver.cpp:228] Iteration 6360, loss = 0.820078
I0816 23:49:51.012879 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:49:51.012894 20404 solver.cpp:244]     Train net output #1: loss = 0.820078 (* 1 = 0.820078 loss)
I0816 23:49:51.012905 20404 sgd_solver.cpp:106] Iteration 6360, lr = 0.000691294
I0816 23:50:25.904301 20404 solver.cpp:228] Iteration 6370, loss = 0.820398
I0816 23:50:25.904476 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:50:25.904492 20404 solver.cpp:244]     Train net output #1: loss = 0.820398 (* 1 = 0.820398 loss)
I0816 23:50:25.904505 20404 sgd_solver.cpp:106] Iteration 6370, lr = 0.000690977
I0816 23:51:00.805420 20404 solver.cpp:228] Iteration 6380, loss = 0.821395
I0816 23:51:00.805601 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:51:00.805618 20404 solver.cpp:244]     Train net output #1: loss = 0.821395 (* 1 = 0.821395 loss)
I0816 23:51:00.805629 20404 sgd_solver.cpp:106] Iteration 6380, lr = 0.00069066
I0816 23:51:35.674896 20404 solver.cpp:228] Iteration 6390, loss = 0.820047
I0816 23:51:35.675107 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0816 23:51:35.675122 20404 solver.cpp:244]     Train net output #1: loss = 0.820047 (* 1 = 0.820047 loss)
I0816 23:51:35.675135 20404 sgd_solver.cpp:106] Iteration 6390, lr = 0.000690344
I0816 23:52:07.099284 20404 solver.cpp:337] Iteration 6400, Testing net (#0)
I0816 23:52:41.735771 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:52:41.735945 20404 solver.cpp:404]     Test net output #1: loss = 0.670903 (* 1 = 0.670903 loss)
I0816 23:52:45.215648 20404 solver.cpp:228] Iteration 6400, loss = 0.820527
I0816 23:52:45.215699 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:52:45.215714 20404 solver.cpp:244]     Train net output #1: loss = 0.820527 (* 1 = 0.820527 loss)
I0816 23:52:45.215726 20404 sgd_solver.cpp:106] Iteration 6400, lr = 0.000690029
I0816 23:53:20.114321 20404 solver.cpp:228] Iteration 6410, loss = 0.821184
I0816 23:53:20.114490 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:53:20.114506 20404 solver.cpp:244]     Train net output #1: loss = 0.821184 (* 1 = 0.821184 loss)
I0816 23:53:20.114518 20404 sgd_solver.cpp:106] Iteration 6410, lr = 0.000689713
I0816 23:53:55.016852 20404 solver.cpp:228] Iteration 6420, loss = 0.820069
I0816 23:53:55.017027 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:53:55.017046 20404 solver.cpp:244]     Train net output #1: loss = 0.820069 (* 1 = 0.820069 loss)
I0816 23:53:55.017061 20404 sgd_solver.cpp:106] Iteration 6420, lr = 0.000689398
I0816 23:54:29.924513 20404 solver.cpp:228] Iteration 6430, loss = 0.820773
I0816 23:54:29.924685 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:54:29.924700 20404 solver.cpp:244]     Train net output #1: loss = 0.820773 (* 1 = 0.820773 loss)
I0816 23:54:29.924712 20404 sgd_solver.cpp:106] Iteration 6430, lr = 0.000689083
I0816 23:55:01.356839 20404 solver.cpp:337] Iteration 6440, Testing net (#0)
I0816 23:55:36.011262 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:55:36.011436 20404 solver.cpp:404]     Test net output #1: loss = 0.672038 (* 1 = 0.672038 loss)
I0816 23:55:39.486955 20404 solver.cpp:228] Iteration 6440, loss = 0.820417
I0816 23:55:39.487007 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:55:39.487021 20404 solver.cpp:244]     Train net output #1: loss = 0.820417 (* 1 = 0.820417 loss)
I0816 23:55:39.487033 20404 sgd_solver.cpp:106] Iteration 6440, lr = 0.000688769
I0816 23:56:14.377769 20404 solver.cpp:228] Iteration 6450, loss = 0.82122
I0816 23:56:14.377948 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:56:14.377965 20404 solver.cpp:244]     Train net output #1: loss = 0.82122 (* 1 = 0.82122 loss)
I0816 23:56:14.377981 20404 sgd_solver.cpp:106] Iteration 6450, lr = 0.000688455
I0816 23:56:49.254775 20404 solver.cpp:228] Iteration 6460, loss = 0.822207
I0816 23:56:49.254952 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:56:49.254971 20404 solver.cpp:244]     Train net output #1: loss = 0.822207 (* 1 = 0.822207 loss)
I0816 23:56:49.254987 20404 sgd_solver.cpp:106] Iteration 6460, lr = 0.000688141
I0816 23:57:24.138247 20404 solver.cpp:228] Iteration 6470, loss = 0.820258
I0816 23:57:24.138438 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0816 23:57:24.138458 20404 solver.cpp:244]     Train net output #1: loss = 0.820258 (* 1 = 0.820258 loss)
I0816 23:57:24.138475 20404 sgd_solver.cpp:106] Iteration 6470, lr = 0.000687828
I0816 23:57:55.571857 20404 solver.cpp:337] Iteration 6480, Testing net (#0)
I0816 23:58:30.230365 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0816 23:58:30.230545 20404 solver.cpp:404]     Test net output #1: loss = 0.67065 (* 1 = 0.67065 loss)
I0816 23:58:33.714232 20404 solver.cpp:228] Iteration 6480, loss = 0.820859
I0816 23:58:33.714277 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:58:33.714306 20404 solver.cpp:244]     Train net output #1: loss = 0.820859 (* 1 = 0.820859 loss)
I0816 23:58:33.714321 20404 sgd_solver.cpp:106] Iteration 6480, lr = 0.000687515
I0816 23:59:08.610363 20404 solver.cpp:228] Iteration 6490, loss = 0.822266
I0816 23:59:08.610508 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:59:08.610525 20404 solver.cpp:244]     Train net output #1: loss = 0.822266 (* 1 = 0.822266 loss)
I0816 23:59:08.610538 20404 sgd_solver.cpp:106] Iteration 6490, lr = 0.000687202
I0816 23:59:43.501507 20404 solver.cpp:228] Iteration 6500, loss = 0.820632
I0816 23:59:43.501703 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0816 23:59:43.501725 20404 solver.cpp:244]     Train net output #1: loss = 0.820632 (* 1 = 0.820632 loss)
I0816 23:59:43.501741 20404 sgd_solver.cpp:106] Iteration 6500, lr = 0.00068689
I0817 00:00:18.398892 20404 solver.cpp:228] Iteration 6510, loss = 0.820889
I0817 00:00:18.399067 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:00:18.399081 20404 solver.cpp:244]     Train net output #1: loss = 0.820889 (* 1 = 0.820889 loss)
I0817 00:00:18.399094 20404 sgd_solver.cpp:106] Iteration 6510, lr = 0.000686578
I0817 00:00:49.811962 20404 solver.cpp:337] Iteration 6520, Testing net (#0)
I0817 00:01:24.474864 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0817 00:01:24.475042 20404 solver.cpp:404]     Test net output #1: loss = 0.670288 (* 1 = 0.670288 loss)
I0817 00:01:27.949460 20404 solver.cpp:228] Iteration 6520, loss = 0.822059
I0817 00:01:27.949512 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:01:27.949527 20404 solver.cpp:244]     Train net output #1: loss = 0.822059 (* 1 = 0.822059 loss)
I0817 00:01:27.949539 20404 sgd_solver.cpp:106] Iteration 6520, lr = 0.000686266
I0817 00:02:02.818631 20404 solver.cpp:228] Iteration 6530, loss = 0.821803
I0817 00:02:02.818806 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:02:02.818821 20404 solver.cpp:244]     Train net output #1: loss = 0.821803 (* 1 = 0.821803 loss)
I0817 00:02:02.818835 20404 sgd_solver.cpp:106] Iteration 6530, lr = 0.000685955
I0817 00:02:37.706245 20404 solver.cpp:228] Iteration 6540, loss = 0.821758
I0817 00:02:37.706418 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:02:37.706434 20404 solver.cpp:244]     Train net output #1: loss = 0.821758 (* 1 = 0.821758 loss)
I0817 00:02:37.706447 20404 sgd_solver.cpp:106] Iteration 6540, lr = 0.000685644
I0817 00:03:12.616701 20404 solver.cpp:228] Iteration 6550, loss = 0.821787
I0817 00:03:12.616875 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:03:12.616891 20404 solver.cpp:244]     Train net output #1: loss = 0.821787 (* 1 = 0.821787 loss)
I0817 00:03:12.616904 20404 sgd_solver.cpp:106] Iteration 6550, lr = 0.000685333
I0817 00:03:44.014585 20404 solver.cpp:337] Iteration 6560, Testing net (#0)
I0817 00:04:18.654744 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0817 00:04:18.654924 20404 solver.cpp:404]     Test net output #1: loss = 0.67011 (* 1 = 0.67011 loss)
I0817 00:04:22.136198 20404 solver.cpp:228] Iteration 6560, loss = 0.82184
I0817 00:04:22.136250 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:04:22.136263 20404 solver.cpp:244]     Train net output #1: loss = 0.82184 (* 1 = 0.82184 loss)
I0817 00:04:22.136276 20404 sgd_solver.cpp:106] Iteration 6560, lr = 0.000685022
I0817 00:04:57.026119 20404 solver.cpp:228] Iteration 6570, loss = 0.821903
I0817 00:04:57.026307 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:04:57.026325 20404 solver.cpp:244]     Train net output #1: loss = 0.821903 (* 1 = 0.821903 loss)
I0817 00:04:57.026338 20404 sgd_solver.cpp:106] Iteration 6570, lr = 0.000684712
I0817 00:05:31.922994 20404 solver.cpp:228] Iteration 6580, loss = 0.821971
I0817 00:05:31.923171 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:05:31.923185 20404 solver.cpp:244]     Train net output #1: loss = 0.821971 (* 1 = 0.821971 loss)
I0817 00:05:31.923198 20404 sgd_solver.cpp:106] Iteration 6580, lr = 0.000684403
I0817 00:06:06.808866 20404 solver.cpp:228] Iteration 6590, loss = 0.82204
I0817 00:06:06.809015 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:06:06.809031 20404 solver.cpp:244]     Train net output #1: loss = 0.82204 (* 1 = 0.82204 loss)
I0817 00:06:06.809043 20404 sgd_solver.cpp:106] Iteration 6590, lr = 0.000684093
I0817 00:06:38.224306 20404 solver.cpp:337] Iteration 6600, Testing net (#0)
I0817 00:07:12.880524 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0817 00:07:12.880694 20404 solver.cpp:404]     Test net output #1: loss = 0.670316 (* 1 = 0.670316 loss)
I0817 00:07:16.352622 20404 solver.cpp:228] Iteration 6600, loss = 0.822108
I0817 00:07:16.352674 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:07:16.352689 20404 solver.cpp:244]     Train net output #1: loss = 0.822108 (* 1 = 0.822108 loss)
I0817 00:07:16.352700 20404 sgd_solver.cpp:106] Iteration 6600, lr = 0.000683784
I0817 00:07:51.233042 20404 solver.cpp:228] Iteration 6610, loss = 0.821712
I0817 00:07:51.233229 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:07:51.233245 20404 solver.cpp:244]     Train net output #1: loss = 0.821712 (* 1 = 0.821712 loss)
I0817 00:07:51.233258 20404 sgd_solver.cpp:106] Iteration 6610, lr = 0.000683475
I0817 00:08:26.121531 20404 solver.cpp:228] Iteration 6620, loss = 0.820087
I0817 00:08:26.121712 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:08:26.121728 20404 solver.cpp:244]     Train net output #1: loss = 0.820087 (* 1 = 0.820087 loss)
I0817 00:08:26.121742 20404 sgd_solver.cpp:106] Iteration 6620, lr = 0.000683167
I0817 00:09:01.024694 20404 solver.cpp:228] Iteration 6630, loss = 0.820416
I0817 00:09:01.024878 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:09:01.024894 20404 solver.cpp:244]     Train net output #1: loss = 0.820416 (* 1 = 0.820416 loss)
I0817 00:09:01.024907 20404 sgd_solver.cpp:106] Iteration 6630, lr = 0.000682859
I0817 00:09:32.453465 20404 solver.cpp:337] Iteration 6640, Testing net (#0)
I0817 00:10:07.104439 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:10:07.104610 20404 solver.cpp:404]     Test net output #1: loss = 0.671003 (* 1 = 0.671003 loss)
I0817 00:10:10.581634 20404 solver.cpp:228] Iteration 6640, loss = 0.820428
I0817 00:10:10.581687 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:10:10.581702 20404 solver.cpp:244]     Train net output #1: loss = 0.820428 (* 1 = 0.820428 loss)
I0817 00:10:10.581714 20404 sgd_solver.cpp:106] Iteration 6640, lr = 0.000682551
I0817 00:10:45.465312 20404 solver.cpp:228] Iteration 6650, loss = 0.821217
I0817 00:10:45.465494 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:10:45.465510 20404 solver.cpp:244]     Train net output #1: loss = 0.821217 (* 1 = 0.821217 loss)
I0817 00:10:45.465523 20404 sgd_solver.cpp:106] Iteration 6650, lr = 0.000682243
I0817 00:11:20.342422 20404 solver.cpp:228] Iteration 6660, loss = 0.82003
I0817 00:11:20.342595 20404 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0817 00:11:20.342610 20404 solver.cpp:244]     Train net output #1: loss = 0.82003 (* 1 = 0.82003 loss)
I0817 00:11:20.342622 20404 sgd_solver.cpp:106] Iteration 6660, lr = 0.000681936
I0817 00:11:55.227330 20404 solver.cpp:228] Iteration 6670, loss = 0.820919
I0817 00:11:55.227506 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:11:55.227525 20404 solver.cpp:244]     Train net output #1: loss = 0.820919 (* 1 = 0.820919 loss)
I0817 00:11:55.227537 20404 sgd_solver.cpp:106] Iteration 6670, lr = 0.000681629
I0817 00:12:26.634570 20404 solver.cpp:337] Iteration 6680, Testing net (#0)
I0817 00:13:01.274036 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:13:01.274221 20404 solver.cpp:404]     Test net output #1: loss = 0.671497 (* 1 = 0.671497 loss)
I0817 00:13:04.755364 20404 solver.cpp:228] Iteration 6680, loss = 0.820101
I0817 00:13:04.755415 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:13:04.755430 20404 solver.cpp:244]     Train net output #1: loss = 0.820101 (* 1 = 0.820101 loss)
I0817 00:13:04.755442 20404 sgd_solver.cpp:106] Iteration 6680, lr = 0.000681323
I0817 00:13:39.642840 20404 solver.cpp:228] Iteration 6690, loss = 0.820497
I0817 00:13:39.643051 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:13:39.643069 20404 solver.cpp:244]     Train net output #1: loss = 0.820497 (* 1 = 0.820497 loss)
I0817 00:13:39.643080 20404 sgd_solver.cpp:106] Iteration 6690, lr = 0.000681017
I0817 00:14:14.530606 20404 solver.cpp:228] Iteration 6700, loss = 0.820037
I0817 00:14:14.530789 20404 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0817 00:14:14.530805 20404 solver.cpp:244]     Train net output #1: loss = 0.820037 (* 1 = 0.820037 loss)
I0817 00:14:14.530817 20404 sgd_solver.cpp:106] Iteration 6700, lr = 0.000680711
I0817 00:14:49.415590 20404 solver.cpp:228] Iteration 6710, loss = 0.820055
I0817 00:14:49.415766 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:14:49.415781 20404 solver.cpp:244]     Train net output #1: loss = 0.820055 (* 1 = 0.820055 loss)
I0817 00:14:49.415793 20404 sgd_solver.cpp:106] Iteration 6710, lr = 0.000680405
I0817 00:15:20.804950 20404 solver.cpp:337] Iteration 6720, Testing net (#0)
I0817 00:15:55.462016 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:15:55.462121 20404 solver.cpp:404]     Test net output #1: loss = 0.671008 (* 1 = 0.671008 loss)
I0817 00:15:58.939579 20404 solver.cpp:228] Iteration 6720, loss = 0.820429
I0817 00:15:58.939621 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:15:58.939651 20404 solver.cpp:244]     Train net output #1: loss = 0.820429 (* 1 = 0.820429 loss)
I0817 00:15:58.939664 20404 sgd_solver.cpp:106] Iteration 6720, lr = 0.0006801
I0817 00:16:33.813457 20404 solver.cpp:228] Iteration 6730, loss = 0.820583
I0817 00:16:33.813634 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:16:33.813654 20404 solver.cpp:244]     Train net output #1: loss = 0.820583 (* 1 = 0.820583 loss)
I0817 00:16:33.813666 20404 sgd_solver.cpp:106] Iteration 6730, lr = 0.000679795
I0817 00:17:08.702519 20404 solver.cpp:228] Iteration 6740, loss = 0.820781
I0817 00:17:08.702694 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:17:08.702710 20404 solver.cpp:244]     Train net output #1: loss = 0.820781 (* 1 = 0.820781 loss)
I0817 00:17:08.702723 20404 sgd_solver.cpp:106] Iteration 6740, lr = 0.000679491
I0817 00:17:43.584188 20404 solver.cpp:228] Iteration 6750, loss = 0.822219
I0817 00:17:43.584365 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:17:43.584381 20404 solver.cpp:244]     Train net output #1: loss = 0.822219 (* 1 = 0.822219 loss)
I0817 00:17:43.584394 20404 sgd_solver.cpp:106] Iteration 6750, lr = 0.000679186
I0817 00:18:15.014081 20404 solver.cpp:337] Iteration 6760, Testing net (#0)
I0817 00:18:49.674877 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:18:49.675047 20404 solver.cpp:404]     Test net output #1: loss = 0.670797 (* 1 = 0.670797 loss)
I0817 00:18:53.154988 20404 solver.cpp:228] Iteration 6760, loss = 0.820703
I0817 00:18:53.155038 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:18:53.155053 20404 solver.cpp:244]     Train net output #1: loss = 0.820703 (* 1 = 0.820703 loss)
I0817 00:18:53.155066 20404 sgd_solver.cpp:106] Iteration 6760, lr = 0.000678882
I0817 00:19:28.059891 20404 solver.cpp:228] Iteration 6770, loss = 0.82038
I0817 00:19:28.060071 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:19:28.060087 20404 solver.cpp:244]     Train net output #1: loss = 0.82038 (* 1 = 0.82038 loss)
I0817 00:19:28.060101 20404 sgd_solver.cpp:106] Iteration 6770, lr = 0.000678579
I0817 00:20:02.972568 20404 solver.cpp:228] Iteration 6780, loss = 0.820223
I0817 00:20:02.972671 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:20:02.972686 20404 solver.cpp:244]     Train net output #1: loss = 0.820223 (* 1 = 0.820223 loss)
I0817 00:20:02.972697 20404 sgd_solver.cpp:106] Iteration 6780, lr = 0.000678275
I0817 00:20:37.889256 20404 solver.cpp:228] Iteration 6790, loss = 0.820041
I0817 00:20:37.889458 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:20:37.889474 20404 solver.cpp:244]     Train net output #1: loss = 0.820041 (* 1 = 0.820041 loss)
I0817 00:20:37.889487 20404 sgd_solver.cpp:106] Iteration 6790, lr = 0.000677972
I0817 00:21:09.294730 20404 solver.cpp:337] Iteration 6800, Testing net (#0)
I0817 00:21:43.942474 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:21:43.942644 20404 solver.cpp:404]     Test net output #1: loss = 0.671039 (* 1 = 0.671039 loss)
I0817 00:21:47.420835 20404 solver.cpp:228] Iteration 6800, loss = 0.820398
I0817 00:21:47.420888 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:21:47.420902 20404 solver.cpp:244]     Train net output #1: loss = 0.820398 (* 1 = 0.820398 loss)
I0817 00:21:47.420915 20404 sgd_solver.cpp:106] Iteration 6800, lr = 0.00067767
I0817 00:22:22.313370 20404 solver.cpp:228] Iteration 6810, loss = 0.821006
I0817 00:22:22.313549 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:22:22.313567 20404 solver.cpp:244]     Train net output #1: loss = 0.821006 (* 1 = 0.821006 loss)
I0817 00:22:22.313580 20404 sgd_solver.cpp:106] Iteration 6810, lr = 0.000677367
I0817 00:22:57.215639 20404 solver.cpp:228] Iteration 6820, loss = 0.8212
I0817 00:22:57.215817 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:22:57.215832 20404 solver.cpp:244]     Train net output #1: loss = 0.8212 (* 1 = 0.8212 loss)
I0817 00:22:57.215845 20404 sgd_solver.cpp:106] Iteration 6820, lr = 0.000677065
I0817 00:23:32.103276 20404 solver.cpp:228] Iteration 6830, loss = 0.820026
I0817 00:23:32.103446 20404 solver.cpp:244]     Train net output #0: accuracy = 0.81
I0817 00:23:32.103462 20404 solver.cpp:244]     Train net output #1: loss = 0.820026 (* 1 = 0.820026 loss)
I0817 00:23:32.103474 20404 sgd_solver.cpp:106] Iteration 6830, lr = 0.000676764
I0817 00:24:03.509593 20404 solver.cpp:337] Iteration 6840, Testing net (#0)
I0817 00:24:38.165994 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:24:38.166162 20404 solver.cpp:404]     Test net output #1: loss = 0.671082 (* 1 = 0.671082 loss)
I0817 00:24:41.641852 20404 solver.cpp:228] Iteration 6840, loss = 0.820346
I0817 00:24:41.641903 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:24:41.641918 20404 solver.cpp:244]     Train net output #1: loss = 0.820346 (* 1 = 0.820346 loss)
I0817 00:24:41.641929 20404 sgd_solver.cpp:106] Iteration 6840, lr = 0.000676462
I0817 00:25:16.517089 20404 solver.cpp:228] Iteration 6850, loss = 0.820027
I0817 00:25:16.517267 20404 solver.cpp:244]     Train net output #0: accuracy = 0.76
I0817 00:25:16.517283 20404 solver.cpp:244]     Train net output #1: loss = 0.820027 (* 1 = 0.820027 loss)
I0817 00:25:16.517297 20404 sgd_solver.cpp:106] Iteration 6850, lr = 0.000676161
I0817 00:25:51.412788 20404 solver.cpp:228] Iteration 6860, loss = 0.820129
I0817 00:25:51.412969 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:25:51.412984 20404 solver.cpp:244]     Train net output #1: loss = 0.820129 (* 1 = 0.820129 loss)
I0817 00:25:51.412997 20404 sgd_solver.cpp:106] Iteration 6860, lr = 0.00067586
I0817 00:26:26.317528 20404 solver.cpp:228] Iteration 6870, loss = 0.820774
I0817 00:26:26.317703 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:26:26.317718 20404 solver.cpp:244]     Train net output #1: loss = 0.820774 (* 1 = 0.820774 loss)
I0817 00:26:26.317731 20404 sgd_solver.cpp:106] Iteration 6870, lr = 0.00067556
I0817 00:26:57.721148 20404 solver.cpp:337] Iteration 6880, Testing net (#0)
I0817 00:27:32.359647 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:27:32.359740 20404 solver.cpp:404]     Test net output #1: loss = 0.670846 (* 1 = 0.670846 loss)
I0817 00:27:35.836500 20404 solver.cpp:228] Iteration 6880, loss = 0.820653
I0817 00:27:35.836540 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:27:35.836555 20404 solver.cpp:244]     Train net output #1: loss = 0.820653 (* 1 = 0.820653 loss)
I0817 00:27:35.836567 20404 sgd_solver.cpp:106] Iteration 6880, lr = 0.00067526
I0817 00:28:10.720052 20404 solver.cpp:228] Iteration 6890, loss = 0.821177
I0817 00:28:10.720264 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:28:10.720284 20404 solver.cpp:244]     Train net output #1: loss = 0.821177 (* 1 = 0.821177 loss)
I0817 00:28:10.720296 20404 sgd_solver.cpp:106] Iteration 6890, lr = 0.00067496
I0817 00:28:45.597338 20404 solver.cpp:228] Iteration 6900, loss = 0.822023
I0817 00:28:45.597442 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:28:45.597457 20404 solver.cpp:244]     Train net output #1: loss = 0.822023 (* 1 = 0.822023 loss)
I0817 00:28:45.597470 20404 sgd_solver.cpp:106] Iteration 6900, lr = 0.00067466
I0817 00:29:20.488507 20404 solver.cpp:228] Iteration 6910, loss = 0.820205
I0817 00:29:20.488682 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:29:20.488698 20404 solver.cpp:244]     Train net output #1: loss = 0.820205 (* 1 = 0.820205 loss)
I0817 00:29:20.488710 20404 sgd_solver.cpp:106] Iteration 6910, lr = 0.000674361
I0817 00:29:51.900329 20404 solver.cpp:337] Iteration 6920, Testing net (#0)
I0817 00:30:26.557220 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:30:26.557381 20404 solver.cpp:404]     Test net output #1: loss = 0.671873 (* 1 = 0.671873 loss)
I0817 00:30:30.032536 20404 solver.cpp:228] Iteration 6920, loss = 0.820299
I0817 00:30:30.032588 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:30:30.032603 20404 solver.cpp:244]     Train net output #1: loss = 0.820299 (* 1 = 0.820299 loss)
I0817 00:30:30.032613 20404 sgd_solver.cpp:106] Iteration 6920, lr = 0.000674062
I0817 00:31:04.925168 20404 solver.cpp:228] Iteration 6930, loss = 0.820934
I0817 00:31:04.925254 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:31:04.925268 20404 solver.cpp:244]     Train net output #1: loss = 0.820934 (* 1 = 0.820934 loss)
I0817 00:31:04.925281 20404 sgd_solver.cpp:106] Iteration 6930, lr = 0.000673763
I0817 00:31:39.842717 20404 solver.cpp:228] Iteration 6940, loss = 0.820122
I0817 00:31:39.842918 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:31:39.842934 20404 solver.cpp:244]     Train net output #1: loss = 0.820122 (* 1 = 0.820122 loss)
I0817 00:31:39.842947 20404 sgd_solver.cpp:106] Iteration 6940, lr = 0.000673465
I0817 00:32:14.731688 20404 solver.cpp:228] Iteration 6950, loss = 0.820277
I0817 00:32:14.731873 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:32:14.731887 20404 solver.cpp:244]     Train net output #1: loss = 0.820277 (* 1 = 0.820277 loss)
I0817 00:32:14.731899 20404 sgd_solver.cpp:106] Iteration 6950, lr = 0.000673167
I0817 00:32:46.154180 20404 solver.cpp:337] Iteration 6960, Testing net (#0)
I0817 00:33:20.802109 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:33:20.802285 20404 solver.cpp:404]     Test net output #1: loss = 0.671832 (* 1 = 0.671832 loss)
I0817 00:33:24.277668 20404 solver.cpp:228] Iteration 6960, loss = 0.820277
I0817 00:33:24.277719 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:33:24.277734 20404 solver.cpp:244]     Train net output #1: loss = 0.820277 (* 1 = 0.820277 loss)
I0817 00:33:24.277745 20404 sgd_solver.cpp:106] Iteration 6960, lr = 0.000672869
I0817 00:33:59.166412 20404 solver.cpp:228] Iteration 6970, loss = 0.82127
I0817 00:33:59.166594 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:33:59.166610 20404 solver.cpp:244]     Train net output #1: loss = 0.82127 (* 1 = 0.82127 loss)
I0817 00:33:59.166622 20404 sgd_solver.cpp:106] Iteration 6970, lr = 0.000672572
I0817 00:34:34.037292 20404 solver.cpp:228] Iteration 6980, loss = 0.8207
I0817 00:34:34.037475 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:34:34.037492 20404 solver.cpp:244]     Train net output #1: loss = 0.8207 (* 1 = 0.8207 loss)
I0817 00:34:34.037503 20404 sgd_solver.cpp:106] Iteration 6980, lr = 0.000672275
I0817 00:35:08.926383 20404 solver.cpp:228] Iteration 6990, loss = 0.820047
I0817 00:35:08.926602 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 00:35:08.926620 20404 solver.cpp:244]     Train net output #1: loss = 0.820047 (* 1 = 0.820047 loss)
I0817 00:35:08.926635 20404 sgd_solver.cpp:106] Iteration 6990, lr = 0.000671978
I0817 00:35:40.340217 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_7000.caffemodel
I0817 00:35:51.526268 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_7000.solverstate
I0817 00:35:53.441720 20404 solver.cpp:337] Iteration 7000, Testing net (#0)
I0817 00:36:28.082924 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:36:28.083096 20404 solver.cpp:404]     Test net output #1: loss = 0.670619 (* 1 = 0.670619 loss)
I0817 00:36:31.557917 20404 solver.cpp:228] Iteration 7000, loss = 0.82095
I0817 00:36:31.557961 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:36:31.557981 20404 solver.cpp:244]     Train net output #1: loss = 0.82095 (* 1 = 0.82095 loss)
I0817 00:36:31.557996 20404 sgd_solver.cpp:106] Iteration 7000, lr = 0.000671681
I0817 00:37:06.464756 20404 solver.cpp:228] Iteration 7010, loss = 0.820577
I0817 00:37:06.464943 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:37:06.464958 20404 solver.cpp:244]     Train net output #1: loss = 0.820577 (* 1 = 0.820577 loss)
I0817 00:37:06.464970 20404 sgd_solver.cpp:106] Iteration 7010, lr = 0.000671385
I0817 00:37:41.348680 20404 solver.cpp:228] Iteration 7020, loss = 0.820884
I0817 00:37:41.348861 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:37:41.348880 20404 solver.cpp:244]     Train net output #1: loss = 0.820884 (* 1 = 0.820884 loss)
I0817 00:37:41.348894 20404 sgd_solver.cpp:106] Iteration 7020, lr = 0.000671089
I0817 00:38:16.258311 20404 solver.cpp:228] Iteration 7030, loss = 0.82088
I0817 00:38:16.258498 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:38:16.258517 20404 solver.cpp:244]     Train net output #1: loss = 0.82088 (* 1 = 0.82088 loss)
I0817 00:38:16.258533 20404 sgd_solver.cpp:106] Iteration 7030, lr = 0.000670794
I0817 00:38:47.653947 20404 solver.cpp:337] Iteration 7040, Testing net (#0)
I0817 00:39:22.293771 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:39:22.293952 20404 solver.cpp:404]     Test net output #1: loss = 0.671611 (* 1 = 0.671611 loss)
I0817 00:39:25.773341 20404 solver.cpp:228] Iteration 7040, loss = 0.820152
I0817 00:39:25.773385 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:39:25.773404 20404 solver.cpp:244]     Train net output #1: loss = 0.820152 (* 1 = 0.820152 loss)
I0817 00:39:25.773430 20404 sgd_solver.cpp:106] Iteration 7040, lr = 0.000670499
I0817 00:40:00.686256 20404 solver.cpp:228] Iteration 7050, loss = 0.820024
I0817 00:40:00.686439 20404 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0817 00:40:00.686457 20404 solver.cpp:244]     Train net output #1: loss = 0.820024 (* 1 = 0.820024 loss)
I0817 00:40:00.686473 20404 sgd_solver.cpp:106] Iteration 7050, lr = 0.000670204
I0817 00:40:35.572284 20404 solver.cpp:228] Iteration 7060, loss = 0.82008
I0817 00:40:35.572464 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:40:35.572479 20404 solver.cpp:244]     Train net output #1: loss = 0.82008 (* 1 = 0.82008 loss)
I0817 00:40:35.572491 20404 sgd_solver.cpp:106] Iteration 7060, lr = 0.000669909
I0817 00:41:10.473394 20404 solver.cpp:228] Iteration 7070, loss = 0.820814
I0817 00:41:10.473567 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:41:10.473582 20404 solver.cpp:244]     Train net output #1: loss = 0.820814 (* 1 = 0.820814 loss)
I0817 00:41:10.473594 20404 sgd_solver.cpp:106] Iteration 7070, lr = 0.000669615
I0817 00:41:41.894333 20404 solver.cpp:337] Iteration 7080, Testing net (#0)
I0817 00:42:16.553289 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:42:16.553465 20404 solver.cpp:404]     Test net output #1: loss = 0.671082 (* 1 = 0.671082 loss)
I0817 00:42:20.032912 20404 solver.cpp:228] Iteration 7080, loss = 0.820365
I0817 00:42:20.032963 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:42:20.032977 20404 solver.cpp:244]     Train net output #1: loss = 0.820365 (* 1 = 0.820365 loss)
I0817 00:42:20.032989 20404 sgd_solver.cpp:106] Iteration 7080, lr = 0.000669321
I0817 00:42:54.910075 20404 solver.cpp:228] Iteration 7090, loss = 0.820966
I0817 00:42:54.910254 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:42:54.910269 20404 solver.cpp:244]     Train net output #1: loss = 0.820966 (* 1 = 0.820966 loss)
I0817 00:42:54.910280 20404 sgd_solver.cpp:106] Iteration 7090, lr = 0.000669027
I0817 00:43:29.808096 20404 solver.cpp:228] Iteration 7100, loss = 0.820921
I0817 00:43:29.808261 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:43:29.808276 20404 solver.cpp:244]     Train net output #1: loss = 0.820921 (* 1 = 0.820921 loss)
I0817 00:43:29.808290 20404 sgd_solver.cpp:106] Iteration 7100, lr = 0.000668733
I0817 00:44:04.707679 20404 solver.cpp:228] Iteration 7110, loss = 0.820138
I0817 00:44:04.707777 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:44:04.707795 20404 solver.cpp:244]     Train net output #1: loss = 0.820138 (* 1 = 0.820138 loss)
I0817 00:44:04.707810 20404 sgd_solver.cpp:106] Iteration 7110, lr = 0.00066844
I0817 00:44:36.113379 20404 solver.cpp:337] Iteration 7120, Testing net (#0)
I0817 00:45:10.751250 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:45:10.751426 20404 solver.cpp:404]     Test net output #1: loss = 0.671278 (* 1 = 0.671278 loss)
I0817 00:45:14.233340 20404 solver.cpp:228] Iteration 7120, loss = 0.820123
I0817 00:45:14.233392 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:45:14.233407 20404 solver.cpp:244]     Train net output #1: loss = 0.820123 (* 1 = 0.820123 loss)
I0817 00:45:14.233419 20404 sgd_solver.cpp:106] Iteration 7120, lr = 0.000668147
I0817 00:45:49.111429 20404 solver.cpp:228] Iteration 7130, loss = 0.820094
I0817 00:45:49.111606 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:45:49.111623 20404 solver.cpp:244]     Train net output #1: loss = 0.820094 (* 1 = 0.820094 loss)
I0817 00:45:49.111635 20404 sgd_solver.cpp:106] Iteration 7130, lr = 0.000667855
I0817 00:46:24.011132 20404 solver.cpp:228] Iteration 7140, loss = 0.820395
I0817 00:46:24.011322 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:46:24.011339 20404 solver.cpp:244]     Train net output #1: loss = 0.820395 (* 1 = 0.820395 loss)
I0817 00:46:24.011351 20404 sgd_solver.cpp:106] Iteration 7140, lr = 0.000667562
I0817 00:46:58.918841 20404 solver.cpp:228] Iteration 7150, loss = 0.820111
I0817 00:46:58.918995 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:46:58.919010 20404 solver.cpp:244]     Train net output #1: loss = 0.820111 (* 1 = 0.820111 loss)
I0817 00:46:58.919023 20404 sgd_solver.cpp:106] Iteration 7150, lr = 0.000667271
I0817 00:47:30.334600 20404 solver.cpp:337] Iteration 7160, Testing net (#0)
I0817 00:48:04.976491 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:48:04.976668 20404 solver.cpp:404]     Test net output #1: loss = 0.671795 (* 1 = 0.671795 loss)
I0817 00:48:08.455602 20404 solver.cpp:228] Iteration 7160, loss = 0.820252
I0817 00:48:08.455652 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:48:08.455667 20404 solver.cpp:244]     Train net output #1: loss = 0.820252 (* 1 = 0.820252 loss)
I0817 00:48:08.455678 20404 sgd_solver.cpp:106] Iteration 7160, lr = 0.000666979
I0817 00:48:43.334825 20404 solver.cpp:228] Iteration 7170, loss = 0.820047
I0817 00:48:43.335005 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 00:48:43.335019 20404 solver.cpp:244]     Train net output #1: loss = 0.820047 (* 1 = 0.820047 loss)
I0817 00:48:43.335031 20404 sgd_solver.cpp:106] Iteration 7170, lr = 0.000666687
I0817 00:49:18.220208 20404 solver.cpp:228] Iteration 7180, loss = 0.820168
I0817 00:49:18.220425 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:49:18.220441 20404 solver.cpp:244]     Train net output #1: loss = 0.820168 (* 1 = 0.820168 loss)
I0817 00:49:18.220453 20404 sgd_solver.cpp:106] Iteration 7180, lr = 0.000666396
I0817 00:49:53.109026 20404 solver.cpp:228] Iteration 7190, loss = 0.820449
I0817 00:49:53.109115 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:49:53.109130 20404 solver.cpp:244]     Train net output #1: loss = 0.820449 (* 1 = 0.820449 loss)
I0817 00:49:53.109143 20404 sgd_solver.cpp:106] Iteration 7190, lr = 0.000666106
I0817 00:50:24.529003 20404 solver.cpp:337] Iteration 7200, Testing net (#0)
I0817 00:50:59.184111 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:50:59.184291 20404 solver.cpp:404]     Test net output #1: loss = 0.670988 (* 1 = 0.670988 loss)
I0817 00:51:02.660629 20404 solver.cpp:228] Iteration 7200, loss = 0.820496
I0817 00:51:02.660670 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:51:02.660684 20404 solver.cpp:244]     Train net output #1: loss = 0.820496 (* 1 = 0.820496 loss)
I0817 00:51:02.660696 20404 sgd_solver.cpp:106] Iteration 7200, lr = 0.000665815
I0817 00:51:37.540019 20404 solver.cpp:228] Iteration 7210, loss = 0.820814
I0817 00:51:37.540192 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:51:37.540208 20404 solver.cpp:244]     Train net output #1: loss = 0.820814 (* 1 = 0.820814 loss)
I0817 00:51:37.540220 20404 sgd_solver.cpp:106] Iteration 7210, lr = 0.000665525
I0817 00:52:12.428155 20404 solver.cpp:228] Iteration 7220, loss = 0.820406
I0817 00:52:12.428329 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:52:12.428345 20404 solver.cpp:244]     Train net output #1: loss = 0.820406 (* 1 = 0.820406 loss)
I0817 00:52:12.428357 20404 sgd_solver.cpp:106] Iteration 7220, lr = 0.000665235
I0817 00:52:47.323779 20404 solver.cpp:228] Iteration 7230, loss = 0.821093
I0817 00:52:47.323951 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:52:47.323966 20404 solver.cpp:244]     Train net output #1: loss = 0.821093 (* 1 = 0.821093 loss)
I0817 00:52:47.323979 20404 sgd_solver.cpp:106] Iteration 7230, lr = 0.000664946
I0817 00:53:18.739725 20404 solver.cpp:337] Iteration 7240, Testing net (#0)
I0817 00:53:53.410604 20404 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0817 00:53:53.410775 20404 solver.cpp:404]     Test net output #1: loss = 0.670232 (* 1 = 0.670232 loss)
I0817 00:53:56.890300 20404 solver.cpp:228] Iteration 7240, loss = 0.822056
I0817 00:53:56.890352 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:53:56.890367 20404 solver.cpp:244]     Train net output #1: loss = 0.822056 (* 1 = 0.822056 loss)
I0817 00:53:56.890377 20404 sgd_solver.cpp:106] Iteration 7240, lr = 0.000664656
I0817 00:54:31.790182 20404 solver.cpp:228] Iteration 7250, loss = 0.820244
I0817 00:54:31.790361 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:54:31.790377 20404 solver.cpp:244]     Train net output #1: loss = 0.820244 (* 1 = 0.820244 loss)
I0817 00:54:31.790390 20404 sgd_solver.cpp:106] Iteration 7250, lr = 0.000664367
I0817 00:55:06.686614 20404 solver.cpp:228] Iteration 7260, loss = 0.82018
I0817 00:55:06.686781 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 00:55:06.686797 20404 solver.cpp:244]     Train net output #1: loss = 0.82018 (* 1 = 0.82018 loss)
I0817 00:55:06.686810 20404 sgd_solver.cpp:106] Iteration 7260, lr = 0.000664079
I0817 00:55:41.564857 20404 solver.cpp:228] Iteration 7270, loss = 0.820467
I0817 00:55:41.565037 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:55:41.565053 20404 solver.cpp:244]     Train net output #1: loss = 0.820467 (* 1 = 0.820467 loss)
I0817 00:55:41.565065 20404 sgd_solver.cpp:106] Iteration 7270, lr = 0.00066379
I0817 00:56:12.978756 20404 solver.cpp:337] Iteration 7280, Testing net (#0)
I0817 00:56:47.630249 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:56:47.630422 20404 solver.cpp:404]     Test net output #1: loss = 0.67127 (* 1 = 0.67127 loss)
I0817 00:56:51.105674 20404 solver.cpp:228] Iteration 7280, loss = 0.820142
I0817 00:56:51.105726 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:56:51.105739 20404 solver.cpp:244]     Train net output #1: loss = 0.820142 (* 1 = 0.820142 loss)
I0817 00:56:51.105751 20404 sgd_solver.cpp:106] Iteration 7280, lr = 0.000663502
I0817 00:57:25.995852 20404 solver.cpp:228] Iteration 7290, loss = 0.820078
I0817 00:57:25.996028 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:57:25.996044 20404 solver.cpp:244]     Train net output #1: loss = 0.820078 (* 1 = 0.820078 loss)
I0817 00:57:25.996057 20404 sgd_solver.cpp:106] Iteration 7290, lr = 0.000663214
I0817 00:58:00.898671 20404 solver.cpp:228] Iteration 7300, loss = 0.820219
I0817 00:58:00.898771 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:58:00.898787 20404 solver.cpp:244]     Train net output #1: loss = 0.820219 (* 1 = 0.820219 loss)
I0817 00:58:00.898799 20404 sgd_solver.cpp:106] Iteration 7300, lr = 0.000662927
I0817 00:58:35.811110 20404 solver.cpp:228] Iteration 7310, loss = 0.820828
I0817 00:58:35.811214 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:58:35.811233 20404 solver.cpp:244]     Train net output #1: loss = 0.820828 (* 1 = 0.820828 loss)
I0817 00:58:35.811249 20404 sgd_solver.cpp:106] Iteration 7310, lr = 0.000662639
I0817 00:59:07.238339 20404 solver.cpp:337] Iteration 7320, Testing net (#0)
I0817 00:59:41.888049 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 00:59:41.888226 20404 solver.cpp:404]     Test net output #1: loss = 0.671293 (* 1 = 0.671293 loss)
I0817 00:59:45.365716 20404 solver.cpp:228] Iteration 7320, loss = 0.820116
I0817 00:59:45.365767 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 00:59:45.365780 20404 solver.cpp:244]     Train net output #1: loss = 0.820116 (* 1 = 0.820116 loss)
I0817 00:59:45.365792 20404 sgd_solver.cpp:106] Iteration 7320, lr = 0.000662352
I0817 01:00:20.239042 20404 solver.cpp:228] Iteration 7330, loss = 0.82045
I0817 01:00:20.239223 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:00:20.239238 20404 solver.cpp:244]     Train net output #1: loss = 0.82045 (* 1 = 0.82045 loss)
I0817 01:00:20.239251 20404 sgd_solver.cpp:106] Iteration 7330, lr = 0.000662066
I0817 01:00:55.154580 20404 solver.cpp:228] Iteration 7340, loss = 0.820228
I0817 01:00:55.154755 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:00:55.154777 20404 solver.cpp:244]     Train net output #1: loss = 0.820228 (* 1 = 0.820228 loss)
I0817 01:00:55.154788 20404 sgd_solver.cpp:106] Iteration 7340, lr = 0.000661779
I0817 01:01:30.035481 20404 solver.cpp:228] Iteration 7350, loss = 0.820186
I0817 01:01:30.035656 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:01:30.035672 20404 solver.cpp:244]     Train net output #1: loss = 0.820186 (* 1 = 0.820186 loss)
I0817 01:01:30.035686 20404 sgd_solver.cpp:106] Iteration 7350, lr = 0.000661493
I0817 01:02:01.449837 20404 solver.cpp:337] Iteration 7360, Testing net (#0)
I0817 01:02:36.109769 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:02:36.109880 20404 solver.cpp:404]     Test net output #1: loss = 0.670845 (* 1 = 0.670845 loss)
I0817 01:02:39.586707 20404 solver.cpp:228] Iteration 7360, loss = 0.820686
I0817 01:02:39.586758 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:02:39.586772 20404 solver.cpp:244]     Train net output #1: loss = 0.820686 (* 1 = 0.820686 loss)
I0817 01:02:39.586784 20404 sgd_solver.cpp:106] Iteration 7360, lr = 0.000661207
I0817 01:03:14.485090 20404 solver.cpp:228] Iteration 7370, loss = 0.822192
I0817 01:03:14.485280 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:03:14.485296 20404 solver.cpp:244]     Train net output #1: loss = 0.822192 (* 1 = 0.822192 loss)
I0817 01:03:14.485307 20404 sgd_solver.cpp:106] Iteration 7370, lr = 0.000660922
I0817 01:03:49.363773 20404 solver.cpp:228] Iteration 7380, loss = 0.820727
I0817 01:03:49.363987 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:03:49.364003 20404 solver.cpp:244]     Train net output #1: loss = 0.820727 (* 1 = 0.820727 loss)
I0817 01:03:49.364015 20404 sgd_solver.cpp:106] Iteration 7380, lr = 0.000660637
I0817 01:04:24.276438 20404 solver.cpp:228] Iteration 7390, loss = 0.820167
I0817 01:04:24.276532 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:04:24.276547 20404 solver.cpp:244]     Train net output #1: loss = 0.820167 (* 1 = 0.820167 loss)
I0817 01:04:24.276558 20404 sgd_solver.cpp:106] Iteration 7390, lr = 0.000660352
I0817 01:04:55.691027 20404 solver.cpp:337] Iteration 7400, Testing net (#0)
I0817 01:05:30.331573 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:05:30.331743 20404 solver.cpp:404]     Test net output #1: loss = 0.671762 (* 1 = 0.671762 loss)
I0817 01:05:33.810473 20404 solver.cpp:228] Iteration 7400, loss = 0.820224
I0817 01:05:33.810524 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:05:33.810539 20404 solver.cpp:244]     Train net output #1: loss = 0.820224 (* 1 = 0.820224 loss)
I0817 01:05:33.810550 20404 sgd_solver.cpp:106] Iteration 7400, lr = 0.000660067
I0817 01:06:08.698570 20404 solver.cpp:228] Iteration 7410, loss = 0.820979
I0817 01:06:08.698751 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:06:08.698767 20404 solver.cpp:244]     Train net output #1: loss = 0.820979 (* 1 = 0.820979 loss)
I0817 01:06:08.698781 20404 sgd_solver.cpp:106] Iteration 7410, lr = 0.000659783
I0817 01:06:43.589017 20404 solver.cpp:228] Iteration 7420, loss = 0.820975
I0817 01:06:43.589186 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:06:43.589201 20404 solver.cpp:244]     Train net output #1: loss = 0.820975 (* 1 = 0.820975 loss)
I0817 01:06:43.589215 20404 sgd_solver.cpp:106] Iteration 7420, lr = 0.000659499
I0817 01:07:18.475919 20404 solver.cpp:228] Iteration 7430, loss = 0.820099
I0817 01:07:18.476100 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:07:18.476116 20404 solver.cpp:244]     Train net output #1: loss = 0.820099 (* 1 = 0.820099 loss)
I0817 01:07:18.476128 20404 sgd_solver.cpp:106] Iteration 7430, lr = 0.000659215
I0817 01:07:49.876273 20404 solver.cpp:337] Iteration 7440, Testing net (#0)
I0817 01:08:24.531093 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:08:24.531263 20404 solver.cpp:404]     Test net output #1: loss = 0.671554 (* 1 = 0.671554 loss)
I0817 01:08:28.007903 20404 solver.cpp:228] Iteration 7440, loss = 0.820103
I0817 01:08:28.007953 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:08:28.007967 20404 solver.cpp:244]     Train net output #1: loss = 0.820103 (* 1 = 0.820103 loss)
I0817 01:08:28.007980 20404 sgd_solver.cpp:106] Iteration 7440, lr = 0.000658931
I0817 01:09:02.907907 20404 solver.cpp:228] Iteration 7450, loss = 0.820292
I0817 01:09:02.907989 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:09:02.908004 20404 solver.cpp:244]     Train net output #1: loss = 0.820292 (* 1 = 0.820292 loss)
I0817 01:09:02.908015 20404 sgd_solver.cpp:106] Iteration 7450, lr = 0.000658648
I0817 01:09:37.807930 20404 solver.cpp:228] Iteration 7460, loss = 0.820265
I0817 01:09:37.808109 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:09:37.808125 20404 solver.cpp:244]     Train net output #1: loss = 0.820265 (* 1 = 0.820265 loss)
I0817 01:09:37.808137 20404 sgd_solver.cpp:106] Iteration 7460, lr = 0.000658365
I0817 01:10:12.696219 20404 solver.cpp:228] Iteration 7470, loss = 0.82054
I0817 01:10:12.696316 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:10:12.696331 20404 solver.cpp:244]     Train net output #1: loss = 0.82054 (* 1 = 0.82054 loss)
I0817 01:10:12.696344 20404 sgd_solver.cpp:106] Iteration 7470, lr = 0.000658082
I0817 01:10:44.123989 20404 solver.cpp:337] Iteration 7480, Testing net (#0)
I0817 01:11:18.744536 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:11:18.744717 20404 solver.cpp:404]     Test net output #1: loss = 0.671425 (* 1 = 0.671425 loss)
I0817 01:11:22.220921 20404 solver.cpp:228] Iteration 7480, loss = 0.820034
I0817 01:11:22.220963 20404 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0817 01:11:22.220981 20404 solver.cpp:244]     Train net output #1: loss = 0.820034 (* 1 = 0.820034 loss)
I0817 01:11:22.220995 20404 sgd_solver.cpp:106] Iteration 7480, lr = 0.0006578
I0817 01:11:57.115165 20404 solver.cpp:228] Iteration 7490, loss = 0.820063
I0817 01:11:57.115340 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:11:57.115355 20404 solver.cpp:244]     Train net output #1: loss = 0.820063 (* 1 = 0.820063 loss)
I0817 01:11:57.115368 20404 sgd_solver.cpp:106] Iteration 7490, lr = 0.000657518
I0817 01:12:31.986100 20404 solver.cpp:228] Iteration 7500, loss = 0.820039
I0817 01:12:31.986285 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 01:12:31.986301 20404 solver.cpp:244]     Train net output #1: loss = 0.820039 (* 1 = 0.820039 loss)
I0817 01:12:31.986313 20404 sgd_solver.cpp:106] Iteration 7500, lr = 0.000657236
I0817 01:13:06.845329 20404 solver.cpp:228] Iteration 7510, loss = 0.820768
I0817 01:13:06.845500 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:13:06.845516 20404 solver.cpp:244]     Train net output #1: loss = 0.820768 (* 1 = 0.820768 loss)
I0817 01:13:06.845528 20404 sgd_solver.cpp:106] Iteration 7510, lr = 0.000656955
I0817 01:13:38.261700 20404 solver.cpp:337] Iteration 7520, Testing net (#0)
I0817 01:14:12.887699 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:14:12.887878 20404 solver.cpp:404]     Test net output #1: loss = 0.671169 (* 1 = 0.671169 loss)
I0817 01:14:16.362644 20404 solver.cpp:228] Iteration 7520, loss = 0.820287
I0817 01:14:16.362696 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:14:16.362710 20404 solver.cpp:244]     Train net output #1: loss = 0.820287 (* 1 = 0.820287 loss)
I0817 01:14:16.362723 20404 sgd_solver.cpp:106] Iteration 7520, lr = 0.000656673
I0817 01:14:51.253248 20404 solver.cpp:228] Iteration 7530, loss = 0.820499
I0817 01:14:51.253427 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:14:51.253443 20404 solver.cpp:244]     Train net output #1: loss = 0.820499 (* 1 = 0.820499 loss)
I0817 01:14:51.253454 20404 sgd_solver.cpp:106] Iteration 7530, lr = 0.000656392
I0817 01:15:26.155812 20404 solver.cpp:228] Iteration 7540, loss = 0.820694
I0817 01:15:26.155910 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:15:26.155925 20404 solver.cpp:244]     Train net output #1: loss = 0.820694 (* 1 = 0.820694 loss)
I0817 01:15:26.155936 20404 sgd_solver.cpp:106] Iteration 7540, lr = 0.000656112
I0817 01:16:01.069552 20404 solver.cpp:228] Iteration 7550, loss = 0.820081
I0817 01:16:01.069723 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:16:01.069739 20404 solver.cpp:244]     Train net output #1: loss = 0.820081 (* 1 = 0.820081 loss)
I0817 01:16:01.069752 20404 sgd_solver.cpp:106] Iteration 7550, lr = 0.000655831
I0817 01:16:32.477380 20404 solver.cpp:337] Iteration 7560, Testing net (#0)
I0817 01:17:07.121093 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:17:07.121260 20404 solver.cpp:404]     Test net output #1: loss = 0.671595 (* 1 = 0.671595 loss)
I0817 01:17:10.597112 20404 solver.cpp:228] Iteration 7560, loss = 0.820126
I0817 01:17:10.597165 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:17:10.597179 20404 solver.cpp:244]     Train net output #1: loss = 0.820126 (* 1 = 0.820126 loss)
I0817 01:17:10.597193 20404 sgd_solver.cpp:106] Iteration 7560, lr = 0.000655551
I0817 01:17:45.472332 20404 solver.cpp:228] Iteration 7570, loss = 0.821106
I0817 01:17:45.472525 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:17:45.472542 20404 solver.cpp:244]     Train net output #1: loss = 0.821106 (* 1 = 0.821106 loss)
I0817 01:17:45.472553 20404 sgd_solver.cpp:106] Iteration 7570, lr = 0.000655271
I0817 01:18:20.351057 20404 solver.cpp:228] Iteration 7580, loss = 0.820556
I0817 01:18:20.351239 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:18:20.351254 20404 solver.cpp:244]     Train net output #1: loss = 0.820556 (* 1 = 0.820556 loss)
I0817 01:18:20.351266 20404 sgd_solver.cpp:106] Iteration 7580, lr = 0.000654992
I0817 01:18:55.251101 20404 solver.cpp:228] Iteration 7590, loss = 0.820604
I0817 01:18:55.251193 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:18:55.251207 20404 solver.cpp:244]     Train net output #1: loss = 0.820604 (* 1 = 0.820604 loss)
I0817 01:18:55.251219 20404 sgd_solver.cpp:106] Iteration 7590, lr = 0.000654712
I0817 01:19:26.666623 20404 solver.cpp:337] Iteration 7600, Testing net (#0)
I0817 01:20:01.306951 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:20:01.307121 20404 solver.cpp:404]     Test net output #1: loss = 0.670734 (* 1 = 0.670734 loss)
I0817 01:20:04.788187 20404 solver.cpp:228] Iteration 7600, loss = 0.820846
I0817 01:20:04.788238 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:20:04.788251 20404 solver.cpp:244]     Train net output #1: loss = 0.820846 (* 1 = 0.820846 loss)
I0817 01:20:04.788262 20404 sgd_solver.cpp:106] Iteration 7600, lr = 0.000654434
I0817 01:20:39.676017 20404 solver.cpp:228] Iteration 7610, loss = 0.821159
I0817 01:20:39.676120 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:20:39.676136 20404 solver.cpp:244]     Train net output #1: loss = 0.821159 (* 1 = 0.821159 loss)
I0817 01:20:39.676147 20404 sgd_solver.cpp:106] Iteration 7610, lr = 0.000654155
I0817 01:21:14.558395 20404 solver.cpp:228] Iteration 7620, loss = 0.820461
I0817 01:21:14.558491 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:21:14.558506 20404 solver.cpp:244]     Train net output #1: loss = 0.820461 (* 1 = 0.820461 loss)
I0817 01:21:14.558518 20404 sgd_solver.cpp:106] Iteration 7620, lr = 0.000653876
I0817 01:21:49.457376 20404 solver.cpp:228] Iteration 7630, loss = 0.820146
I0817 01:21:49.457543 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:21:49.457558 20404 solver.cpp:244]     Train net output #1: loss = 0.820146 (* 1 = 0.820146 loss)
I0817 01:21:49.457571 20404 sgd_solver.cpp:106] Iteration 7630, lr = 0.000653598
I0817 01:22:20.898524 20404 solver.cpp:337] Iteration 7640, Testing net (#0)
I0817 01:22:55.580199 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:22:55.580368 20404 solver.cpp:404]     Test net output #1: loss = 0.67227 (* 1 = 0.67227 loss)
I0817 01:22:59.061638 20404 solver.cpp:228] Iteration 7640, loss = 0.820503
I0817 01:22:59.061678 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:22:59.061693 20404 solver.cpp:244]     Train net output #1: loss = 0.820503 (* 1 = 0.820503 loss)
I0817 01:22:59.061705 20404 sgd_solver.cpp:106] Iteration 7640, lr = 0.00065332
I0817 01:23:33.930738 20404 solver.cpp:228] Iteration 7650, loss = 0.820746
I0817 01:23:33.930845 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:23:33.930860 20404 solver.cpp:244]     Train net output #1: loss = 0.820746 (* 1 = 0.820746 loss)
I0817 01:23:33.930871 20404 sgd_solver.cpp:106] Iteration 7650, lr = 0.000653043
I0817 01:24:08.827739 20404 solver.cpp:228] Iteration 7660, loss = 0.820161
I0817 01:24:08.827913 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:24:08.827929 20404 solver.cpp:244]     Train net output #1: loss = 0.820161 (* 1 = 0.820161 loss)
I0817 01:24:08.827942 20404 sgd_solver.cpp:106] Iteration 7660, lr = 0.000652765
I0817 01:24:43.713063 20404 solver.cpp:228] Iteration 7670, loss = 0.820537
I0817 01:24:43.713240 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:24:43.713255 20404 solver.cpp:244]     Train net output #1: loss = 0.820537 (* 1 = 0.820537 loss)
I0817 01:24:43.713268 20404 sgd_solver.cpp:106] Iteration 7670, lr = 0.000652488
I0817 01:25:15.139003 20404 solver.cpp:337] Iteration 7680, Testing net (#0)
I0817 01:25:49.812187 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:25:49.812356 20404 solver.cpp:404]     Test net output #1: loss = 0.670905 (* 1 = 0.670905 loss)
I0817 01:25:53.295358 20404 solver.cpp:228] Iteration 7680, loss = 0.820629
I0817 01:25:53.295408 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:25:53.295423 20404 solver.cpp:244]     Train net output #1: loss = 0.820629 (* 1 = 0.820629 loss)
I0817 01:25:53.295435 20404 sgd_solver.cpp:106] Iteration 7680, lr = 0.000652211
I0817 01:26:28.174406 20404 solver.cpp:228] Iteration 7690, loss = 0.820037
I0817 01:26:28.174578 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 01:26:28.174594 20404 solver.cpp:244]     Train net output #1: loss = 0.820037 (* 1 = 0.820037 loss)
I0817 01:26:28.174607 20404 sgd_solver.cpp:106] Iteration 7690, lr = 0.000651935
I0817 01:27:03.055842 20404 solver.cpp:228] Iteration 7700, loss = 0.820133
I0817 01:27:03.055990 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:27:03.056006 20404 solver.cpp:244]     Train net output #1: loss = 0.820133 (* 1 = 0.820133 loss)
I0817 01:27:03.056018 20404 sgd_solver.cpp:106] Iteration 7700, lr = 0.000651659
I0817 01:27:37.959170 20404 solver.cpp:228] Iteration 7710, loss = 0.82107
I0817 01:27:37.959285 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:27:37.959300 20404 solver.cpp:244]     Train net output #1: loss = 0.82107 (* 1 = 0.82107 loss)
I0817 01:27:37.959313 20404 sgd_solver.cpp:106] Iteration 7710, lr = 0.000651383
I0817 01:28:09.378314 20404 solver.cpp:337] Iteration 7720, Testing net (#0)
I0817 01:28:44.046561 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:28:44.046737 20404 solver.cpp:404]     Test net output #1: loss = 0.671529 (* 1 = 0.671529 loss)
I0817 01:28:47.522989 20404 solver.cpp:228] Iteration 7720, loss = 0.820087
I0817 01:28:47.523041 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:28:47.523056 20404 solver.cpp:244]     Train net output #1: loss = 0.820087 (* 1 = 0.820087 loss)
I0817 01:28:47.523067 20404 sgd_solver.cpp:106] Iteration 7720, lr = 0.000651107
I0817 01:29:22.440317 20404 solver.cpp:228] Iteration 7730, loss = 0.820549
I0817 01:29:22.440502 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:29:22.440517 20404 solver.cpp:244]     Train net output #1: loss = 0.820549 (* 1 = 0.820549 loss)
I0817 01:29:22.440529 20404 sgd_solver.cpp:106] Iteration 7730, lr = 0.000650831
I0817 01:29:57.350775 20404 solver.cpp:228] Iteration 7740, loss = 0.820155
I0817 01:29:57.350953 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:29:57.350972 20404 solver.cpp:244]     Train net output #1: loss = 0.820155 (* 1 = 0.820155 loss)
I0817 01:29:57.350987 20404 sgd_solver.cpp:106] Iteration 7740, lr = 0.000650556
I0817 01:30:32.242559 20404 solver.cpp:228] Iteration 7750, loss = 0.820296
I0817 01:30:32.242736 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:30:32.242753 20404 solver.cpp:244]     Train net output #1: loss = 0.820296 (* 1 = 0.820296 loss)
I0817 01:30:32.242764 20404 sgd_solver.cpp:106] Iteration 7750, lr = 0.000650281
I0817 01:31:03.657218 20404 solver.cpp:337] Iteration 7760, Testing net (#0)
I0817 01:31:38.300123 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:31:38.300293 20404 solver.cpp:404]     Test net output #1: loss = 0.671092 (* 1 = 0.671092 loss)
I0817 01:31:41.782208 20404 solver.cpp:228] Iteration 7760, loss = 0.820396
I0817 01:31:41.782260 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:31:41.782274 20404 solver.cpp:244]     Train net output #1: loss = 0.820396 (* 1 = 0.820396 loss)
I0817 01:31:41.782285 20404 sgd_solver.cpp:106] Iteration 7760, lr = 0.000650007
I0817 01:32:16.655988 20404 solver.cpp:228] Iteration 7770, loss = 0.820036
I0817 01:32:16.656193 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:32:16.656209 20404 solver.cpp:244]     Train net output #1: loss = 0.820036 (* 1 = 0.820036 loss)
I0817 01:32:16.656221 20404 sgd_solver.cpp:106] Iteration 7770, lr = 0.000649732
I0817 01:32:51.554617 20404 solver.cpp:228] Iteration 7780, loss = 0.820406
I0817 01:32:51.554801 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:32:51.554818 20404 solver.cpp:244]     Train net output #1: loss = 0.820406 (* 1 = 0.820406 loss)
I0817 01:32:51.554831 20404 sgd_solver.cpp:106] Iteration 7780, lr = 0.000649458
I0817 01:33:26.464709 20404 solver.cpp:228] Iteration 7790, loss = 0.820454
I0817 01:33:26.464890 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:33:26.464908 20404 solver.cpp:244]     Train net output #1: loss = 0.820454 (* 1 = 0.820454 loss)
I0817 01:33:26.464921 20404 sgd_solver.cpp:106] Iteration 7790, lr = 0.000649184
I0817 01:33:57.878423 20404 solver.cpp:337] Iteration 7800, Testing net (#0)
I0817 01:34:32.520246 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:34:32.520421 20404 solver.cpp:404]     Test net output #1: loss = 0.670454 (* 1 = 0.670454 loss)
I0817 01:34:35.995932 20404 solver.cpp:228] Iteration 7800, loss = 0.821215
I0817 01:34:35.995985 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:34:35.996001 20404 solver.cpp:244]     Train net output #1: loss = 0.821215 (* 1 = 0.821215 loss)
I0817 01:34:35.996012 20404 sgd_solver.cpp:106] Iteration 7800, lr = 0.000648911
I0817 01:35:10.872395 20404 solver.cpp:228] Iteration 7810, loss = 0.820048
I0817 01:35:10.872577 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 01:35:10.872593 20404 solver.cpp:244]     Train net output #1: loss = 0.820048 (* 1 = 0.820048 loss)
I0817 01:35:10.872606 20404 sgd_solver.cpp:106] Iteration 7810, lr = 0.000648638
I0817 01:35:45.771752 20404 solver.cpp:228] Iteration 7820, loss = 0.820516
I0817 01:35:45.771925 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:35:45.771941 20404 solver.cpp:244]     Train net output #1: loss = 0.820516 (* 1 = 0.820516 loss)
I0817 01:35:45.771955 20404 sgd_solver.cpp:106] Iteration 7820, lr = 0.000648364
I0817 01:36:20.677009 20404 solver.cpp:228] Iteration 7830, loss = 0.820764
I0817 01:36:20.677184 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:36:20.677199 20404 solver.cpp:244]     Train net output #1: loss = 0.820764 (* 1 = 0.820764 loss)
I0817 01:36:20.677212 20404 sgd_solver.cpp:106] Iteration 7830, lr = 0.000648092
I0817 01:36:52.084285 20404 solver.cpp:337] Iteration 7840, Testing net (#0)
I0817 01:37:26.732273 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:37:26.732383 20404 solver.cpp:404]     Test net output #1: loss = 0.671805 (* 1 = 0.671805 loss)
I0817 01:37:30.208251 20404 solver.cpp:228] Iteration 7840, loss = 0.820237
I0817 01:37:30.208302 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:37:30.208315 20404 solver.cpp:244]     Train net output #1: loss = 0.820237 (* 1 = 0.820237 loss)
I0817 01:37:30.208328 20404 sgd_solver.cpp:106] Iteration 7840, lr = 0.000647819
I0817 01:38:05.066874 20404 solver.cpp:228] Iteration 7850, loss = 0.820699
I0817 01:38:05.067050 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:38:05.067065 20404 solver.cpp:244]     Train net output #1: loss = 0.820699 (* 1 = 0.820699 loss)
I0817 01:38:05.067078 20404 sgd_solver.cpp:106] Iteration 7850, lr = 0.000647547
I0817 01:38:39.976840 20404 solver.cpp:228] Iteration 7860, loss = 0.820243
I0817 01:38:39.977011 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:38:39.977031 20404 solver.cpp:244]     Train net output #1: loss = 0.820243 (* 1 = 0.820243 loss)
I0817 01:38:39.977043 20404 sgd_solver.cpp:106] Iteration 7860, lr = 0.000647275
I0817 01:39:14.876905 20404 solver.cpp:228] Iteration 7870, loss = 0.821698
I0817 01:39:14.877113 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:39:14.877132 20404 solver.cpp:244]     Train net output #1: loss = 0.821698 (* 1 = 0.821698 loss)
I0817 01:39:14.877146 20404 sgd_solver.cpp:106] Iteration 7870, lr = 0.000647003
I0817 01:39:46.287793 20404 solver.cpp:337] Iteration 7880, Testing net (#0)
I0817 01:40:20.938315 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:40:20.938494 20404 solver.cpp:404]     Test net output #1: loss = 0.67057 (* 1 = 0.67057 loss)
I0817 01:40:24.416474 20404 solver.cpp:228] Iteration 7880, loss = 0.82107
I0817 01:40:24.416525 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:40:24.416539 20404 solver.cpp:244]     Train net output #1: loss = 0.82107 (* 1 = 0.82107 loss)
I0817 01:40:24.416551 20404 sgd_solver.cpp:106] Iteration 7880, lr = 0.000646732
I0817 01:40:59.304641 20404 solver.cpp:228] Iteration 7890, loss = 0.820232
I0817 01:40:59.304811 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:40:59.304826 20404 solver.cpp:244]     Train net output #1: loss = 0.820232 (* 1 = 0.820232 loss)
I0817 01:40:59.304838 20404 sgd_solver.cpp:106] Iteration 7890, lr = 0.000646461
I0817 01:41:34.189788 20404 solver.cpp:228] Iteration 7900, loss = 0.821594
I0817 01:41:34.189879 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:41:34.189894 20404 solver.cpp:244]     Train net output #1: loss = 0.821594 (* 1 = 0.821594 loss)
I0817 01:41:34.189906 20404 sgd_solver.cpp:106] Iteration 7900, lr = 0.00064619
I0817 01:42:09.097448 20404 solver.cpp:228] Iteration 7910, loss = 0.820929
I0817 01:42:09.097626 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:42:09.097642 20404 solver.cpp:244]     Train net output #1: loss = 0.820929 (* 1 = 0.820929 loss)
I0817 01:42:09.097654 20404 sgd_solver.cpp:106] Iteration 7910, lr = 0.000645919
I0817 01:42:40.503657 20404 solver.cpp:337] Iteration 7920, Testing net (#0)
I0817 01:43:15.154806 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:43:15.154968 20404 solver.cpp:404]     Test net output #1: loss = 0.671928 (* 1 = 0.671928 loss)
I0817 01:43:18.626688 20404 solver.cpp:228] Iteration 7920, loss = 0.820307
I0817 01:43:18.626727 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:43:18.626742 20404 solver.cpp:244]     Train net output #1: loss = 0.820307 (* 1 = 0.820307 loss)
I0817 01:43:18.626754 20404 sgd_solver.cpp:106] Iteration 7920, lr = 0.000645649
I0817 01:43:53.508106 20404 solver.cpp:228] Iteration 7930, loss = 0.820124
I0817 01:43:53.508285 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:43:53.508303 20404 solver.cpp:244]     Train net output #1: loss = 0.820124 (* 1 = 0.820124 loss)
I0817 01:43:53.508319 20404 sgd_solver.cpp:106] Iteration 7930, lr = 0.000645379
I0817 01:44:28.396539 20404 solver.cpp:228] Iteration 7940, loss = 0.821223
I0817 01:44:28.396711 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:44:28.396726 20404 solver.cpp:244]     Train net output #1: loss = 0.821223 (* 1 = 0.821223 loss)
I0817 01:44:28.396739 20404 sgd_solver.cpp:106] Iteration 7940, lr = 0.000645109
I0817 01:45:03.288888 20404 solver.cpp:228] Iteration 7950, loss = 0.820022
I0817 01:45:03.289042 20404 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0817 01:45:03.289063 20404 solver.cpp:244]     Train net output #1: loss = 0.820022 (* 1 = 0.820022 loss)
I0817 01:45:03.289079 20404 sgd_solver.cpp:106] Iteration 7950, lr = 0.00064484
I0817 01:45:34.683466 20404 solver.cpp:337] Iteration 7960, Testing net (#0)
I0817 01:46:09.331940 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:46:09.332113 20404 solver.cpp:404]     Test net output #1: loss = 0.671321 (* 1 = 0.671321 loss)
I0817 01:46:12.804621 20404 solver.cpp:228] Iteration 7960, loss = 0.820115
I0817 01:46:12.804666 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:46:12.804684 20404 solver.cpp:244]     Train net output #1: loss = 0.820115 (* 1 = 0.820115 loss)
I0817 01:46:12.804709 20404 sgd_solver.cpp:106] Iteration 7960, lr = 0.00064457
I0817 01:46:47.700464 20404 solver.cpp:228] Iteration 7970, loss = 0.820411
I0817 01:46:47.700680 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:46:47.700700 20404 solver.cpp:244]     Train net output #1: loss = 0.820411 (* 1 = 0.820411 loss)
I0817 01:46:47.700716 20404 sgd_solver.cpp:106] Iteration 7970, lr = 0.000644301
I0817 01:47:22.573343 20404 solver.cpp:228] Iteration 7980, loss = 0.820528
I0817 01:47:22.573523 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:47:22.573542 20404 solver.cpp:244]     Train net output #1: loss = 0.820528 (* 1 = 0.820528 loss)
I0817 01:47:22.573559 20404 sgd_solver.cpp:106] Iteration 7980, lr = 0.000644032
I0817 01:47:57.469144 20404 solver.cpp:228] Iteration 7990, loss = 0.820052
I0817 01:47:57.469331 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:47:57.469352 20404 solver.cpp:244]     Train net output #1: loss = 0.820052 (* 1 = 0.820052 loss)
I0817 01:47:57.469365 20404 sgd_solver.cpp:106] Iteration 7990, lr = 0.000643764
I0817 01:48:28.881436 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_8000.caffemodel
I0817 01:48:38.578336 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_8000.solverstate
I0817 01:48:39.994143 20404 solver.cpp:337] Iteration 8000, Testing net (#0)
I0817 01:49:14.608644 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:49:14.608825 20404 solver.cpp:404]     Test net output #1: loss = 0.671709 (* 1 = 0.671709 loss)
I0817 01:49:18.084097 20404 solver.cpp:228] Iteration 8000, loss = 0.82018
I0817 01:49:18.084151 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:49:18.084167 20404 solver.cpp:244]     Train net output #1: loss = 0.82018 (* 1 = 0.82018 loss)
I0817 01:49:18.084178 20404 sgd_solver.cpp:106] Iteration 8000, lr = 0.000643496
I0817 01:49:52.965749 20404 solver.cpp:228] Iteration 8010, loss = 0.820254
I0817 01:49:52.965929 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:49:52.965945 20404 solver.cpp:244]     Train net output #1: loss = 0.820254 (* 1 = 0.820254 loss)
I0817 01:49:52.965956 20404 sgd_solver.cpp:106] Iteration 8010, lr = 0.000643228
I0817 01:50:27.866086 20404 solver.cpp:228] Iteration 8020, loss = 0.820151
I0817 01:50:27.866266 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:50:27.866281 20404 solver.cpp:244]     Train net output #1: loss = 0.820151 (* 1 = 0.820151 loss)
I0817 01:50:27.866292 20404 sgd_solver.cpp:106] Iteration 8020, lr = 0.00064296
I0817 01:51:02.770191 20404 solver.cpp:228] Iteration 8030, loss = 0.820445
I0817 01:51:02.770364 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:51:02.770380 20404 solver.cpp:244]     Train net output #1: loss = 0.820445 (* 1 = 0.820445 loss)
I0817 01:51:02.770395 20404 sgd_solver.cpp:106] Iteration 8030, lr = 0.000642692
I0817 01:51:34.171365 20404 solver.cpp:337] Iteration 8040, Testing net (#0)
I0817 01:52:08.839082 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:52:08.839254 20404 solver.cpp:404]     Test net output #1: loss = 0.671075 (* 1 = 0.671075 loss)
I0817 01:52:12.316428 20404 solver.cpp:228] Iteration 8040, loss = 0.820435
I0817 01:52:12.316479 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:52:12.316493 20404 solver.cpp:244]     Train net output #1: loss = 0.820435 (* 1 = 0.820435 loss)
I0817 01:52:12.316505 20404 sgd_solver.cpp:106] Iteration 8040, lr = 0.000642425
I0817 01:52:47.199061 20404 solver.cpp:228] Iteration 8050, loss = 0.820845
I0817 01:52:47.199232 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:52:47.199249 20404 solver.cpp:244]     Train net output #1: loss = 0.820845 (* 1 = 0.820845 loss)
I0817 01:52:47.199260 20404 sgd_solver.cpp:106] Iteration 8050, lr = 0.000642158
I0817 01:53:22.118594 20404 solver.cpp:228] Iteration 8060, loss = 0.820747
I0817 01:53:22.118806 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:53:22.118824 20404 solver.cpp:244]     Train net output #1: loss = 0.820747 (* 1 = 0.820747 loss)
I0817 01:53:22.118839 20404 sgd_solver.cpp:106] Iteration 8060, lr = 0.000641892
I0817 01:53:57.020766 20404 solver.cpp:228] Iteration 8070, loss = 0.821373
I0817 01:53:57.020951 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:53:57.020965 20404 solver.cpp:244]     Train net output #1: loss = 0.821373 (* 1 = 0.821373 loss)
I0817 01:53:57.020978 20404 sgd_solver.cpp:106] Iteration 8070, lr = 0.000641625
I0817 01:54:28.449188 20404 solver.cpp:337] Iteration 8080, Testing net (#0)
I0817 01:55:03.118420 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:55:03.118602 20404 solver.cpp:404]     Test net output #1: loss = 0.670918 (* 1 = 0.670918 loss)
I0817 01:55:06.592988 20404 solver.cpp:228] Iteration 8080, loss = 0.820639
I0817 01:55:06.593037 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:55:06.593052 20404 solver.cpp:244]     Train net output #1: loss = 0.820639 (* 1 = 0.820639 loss)
I0817 01:55:06.593063 20404 sgd_solver.cpp:106] Iteration 8080, lr = 0.000641359
I0817 01:55:41.485407 20404 solver.cpp:228] Iteration 8090, loss = 0.820229
I0817 01:55:41.485579 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:55:41.485594 20404 solver.cpp:244]     Train net output #1: loss = 0.820229 (* 1 = 0.820229 loss)
I0817 01:55:41.485606 20404 sgd_solver.cpp:106] Iteration 8090, lr = 0.000641093
I0817 01:56:16.377810 20404 solver.cpp:228] Iteration 8100, loss = 0.820776
I0817 01:56:16.377975 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:56:16.377990 20404 solver.cpp:244]     Train net output #1: loss = 0.820776 (* 1 = 0.820776 loss)
I0817 01:56:16.378002 20404 sgd_solver.cpp:106] Iteration 8100, lr = 0.000640827
I0817 01:56:51.289273 20404 solver.cpp:228] Iteration 8110, loss = 0.820637
I0817 01:56:51.289443 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:56:51.289458 20404 solver.cpp:244]     Train net output #1: loss = 0.820637 (* 1 = 0.820637 loss)
I0817 01:56:51.289469 20404 sgd_solver.cpp:106] Iteration 8110, lr = 0.000640562
I0817 01:57:22.698263 20404 solver.cpp:337] Iteration 8120, Testing net (#0)
I0817 01:57:57.351169 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 01:57:57.351261 20404 solver.cpp:404]     Test net output #1: loss = 0.671282 (* 1 = 0.671282 loss)
I0817 01:58:00.839222 20404 solver.cpp:228] Iteration 8120, loss = 0.820177
I0817 01:58:00.839277 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:58:00.839290 20404 solver.cpp:244]     Train net output #1: loss = 0.820177 (* 1 = 0.820177 loss)
I0817 01:58:00.839303 20404 sgd_solver.cpp:106] Iteration 8120, lr = 0.000640297
I0817 01:58:35.732054 20404 solver.cpp:228] Iteration 8130, loss = 0.820222
I0817 01:58:35.732229 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:58:35.732244 20404 solver.cpp:244]     Train net output #1: loss = 0.820222 (* 1 = 0.820222 loss)
I0817 01:58:35.732257 20404 sgd_solver.cpp:106] Iteration 8130, lr = 0.000640032
I0817 01:59:10.653406 20404 solver.cpp:228] Iteration 8140, loss = 0.820415
I0817 01:59:10.653515 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 01:59:10.653534 20404 solver.cpp:244]     Train net output #1: loss = 0.820415 (* 1 = 0.820415 loss)
I0817 01:59:10.653549 20404 sgd_solver.cpp:106] Iteration 8140, lr = 0.000639767
I0817 01:59:45.535123 20404 solver.cpp:228] Iteration 8150, loss = 0.820516
I0817 01:59:45.535305 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 01:59:45.535327 20404 solver.cpp:244]     Train net output #1: loss = 0.820516 (* 1 = 0.820516 loss)
I0817 01:59:45.535342 20404 sgd_solver.cpp:106] Iteration 8150, lr = 0.000639503
I0817 02:00:16.959952 20404 solver.cpp:337] Iteration 8160, Testing net (#0)
I0817 02:00:51.606497 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:00:51.606709 20404 solver.cpp:404]     Test net output #1: loss = 0.670561 (* 1 = 0.670561 loss)
I0817 02:00:55.086832 20404 solver.cpp:228] Iteration 8160, loss = 0.821097
I0817 02:00:55.086881 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:00:55.086896 20404 solver.cpp:244]     Train net output #1: loss = 0.821097 (* 1 = 0.821097 loss)
I0817 02:00:55.086908 20404 sgd_solver.cpp:106] Iteration 8160, lr = 0.000639239
I0817 02:01:29.980072 20404 solver.cpp:228] Iteration 8170, loss = 0.820379
I0817 02:01:29.980190 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:01:29.980208 20404 solver.cpp:244]     Train net output #1: loss = 0.820379 (* 1 = 0.820379 loss)
I0817 02:01:29.980223 20404 sgd_solver.cpp:106] Iteration 8170, lr = 0.000638975
I0817 02:02:04.882913 20404 solver.cpp:228] Iteration 8180, loss = 0.820209
I0817 02:02:04.883095 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:02:04.883114 20404 solver.cpp:244]     Train net output #1: loss = 0.820209 (* 1 = 0.820209 loss)
I0817 02:02:04.883129 20404 sgd_solver.cpp:106] Iteration 8180, lr = 0.000638711
I0817 02:02:39.778348 20404 solver.cpp:228] Iteration 8190, loss = 0.820477
I0817 02:02:39.778457 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:02:39.778476 20404 solver.cpp:244]     Train net output #1: loss = 0.820477 (* 1 = 0.820477 loss)
I0817 02:02:39.778491 20404 sgd_solver.cpp:106] Iteration 8190, lr = 0.000638448
I0817 02:03:11.192425 20404 solver.cpp:337] Iteration 8200, Testing net (#0)
I0817 02:03:45.832175 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:03:45.832270 20404 solver.cpp:404]     Test net output #1: loss = 0.671042 (* 1 = 0.671042 loss)
I0817 02:03:49.313546 20404 solver.cpp:228] Iteration 8200, loss = 0.820484
I0817 02:03:49.313588 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:03:49.313606 20404 solver.cpp:244]     Train net output #1: loss = 0.820484 (* 1 = 0.820484 loss)
I0817 02:03:49.313632 20404 sgd_solver.cpp:106] Iteration 8200, lr = 0.000638185
I0817 02:04:24.220739 20404 solver.cpp:228] Iteration 8210, loss = 0.820054
I0817 02:04:24.220922 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 02:04:24.220938 20404 solver.cpp:244]     Train net output #1: loss = 0.820054 (* 1 = 0.820054 loss)
I0817 02:04:24.220950 20404 sgd_solver.cpp:106] Iteration 8210, lr = 0.000637922
I0817 02:04:59.110502 20404 solver.cpp:228] Iteration 8220, loss = 0.820046
I0817 02:04:59.110684 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:04:59.110700 20404 solver.cpp:244]     Train net output #1: loss = 0.820046 (* 1 = 0.820046 loss)
I0817 02:04:59.110713 20404 sgd_solver.cpp:106] Iteration 8220, lr = 0.000637659
I0817 02:05:34.024565 20404 solver.cpp:228] Iteration 8230, loss = 0.82063
I0817 02:05:34.024672 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:05:34.024688 20404 solver.cpp:244]     Train net output #1: loss = 0.82063 (* 1 = 0.82063 loss)
I0817 02:05:34.024700 20404 sgd_solver.cpp:106] Iteration 8230, lr = 0.000637397
I0817 02:06:05.463423 20404 solver.cpp:337] Iteration 8240, Testing net (#0)
I0817 02:06:40.121585 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:06:40.121680 20404 solver.cpp:404]     Test net output #1: loss = 0.670953 (* 1 = 0.670953 loss)
I0817 02:06:43.604295 20404 solver.cpp:228] Iteration 8240, loss = 0.82061
I0817 02:06:43.604346 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:06:43.604360 20404 solver.cpp:244]     Train net output #1: loss = 0.82061 (* 1 = 0.82061 loss)
I0817 02:06:43.604372 20404 sgd_solver.cpp:106] Iteration 8240, lr = 0.000637135
I0817 02:07:18.503080 20404 solver.cpp:228] Iteration 8250, loss = 0.820378
I0817 02:07:18.503260 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:07:18.503280 20404 solver.cpp:244]     Train net output #1: loss = 0.820378 (* 1 = 0.820378 loss)
I0817 02:07:18.503293 20404 sgd_solver.cpp:106] Iteration 8250, lr = 0.000636873
I0817 02:07:53.409072 20404 solver.cpp:228] Iteration 8260, loss = 0.82007
I0817 02:07:53.409283 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:07:53.409301 20404 solver.cpp:244]     Train net output #1: loss = 0.82007 (* 1 = 0.82007 loss)
I0817 02:07:53.409313 20404 sgd_solver.cpp:106] Iteration 8260, lr = 0.000636611
I0817 02:08:28.326045 20404 solver.cpp:228] Iteration 8270, loss = 0.820128
I0817 02:08:28.326230 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:08:28.326244 20404 solver.cpp:244]     Train net output #1: loss = 0.820128 (* 1 = 0.820128 loss)
I0817 02:08:28.326256 20404 sgd_solver.cpp:106] Iteration 8270, lr = 0.00063635
I0817 02:08:59.741317 20404 solver.cpp:337] Iteration 8280, Testing net (#0)
I0817 02:09:34.394448 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:09:34.394561 20404 solver.cpp:404]     Test net output #1: loss = 0.671906 (* 1 = 0.671906 loss)
I0817 02:09:37.881155 20404 solver.cpp:228] Iteration 8280, loss = 0.820282
I0817 02:09:37.881206 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:09:37.881219 20404 solver.cpp:244]     Train net output #1: loss = 0.820282 (* 1 = 0.820282 loss)
I0817 02:09:37.881232 20404 sgd_solver.cpp:106] Iteration 8280, lr = 0.000636089
I0817 02:10:12.791940 20404 solver.cpp:228] Iteration 8290, loss = 0.820869
I0817 02:10:12.792109 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:10:12.792124 20404 solver.cpp:244]     Train net output #1: loss = 0.820869 (* 1 = 0.820869 loss)
I0817 02:10:12.792136 20404 sgd_solver.cpp:106] Iteration 8290, lr = 0.000635828
I0817 02:10:47.713167 20404 solver.cpp:228] Iteration 8300, loss = 0.82004
I0817 02:10:47.713348 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:10:47.713364 20404 solver.cpp:244]     Train net output #1: loss = 0.82004 (* 1 = 0.82004 loss)
I0817 02:10:47.713376 20404 sgd_solver.cpp:106] Iteration 8300, lr = 0.000635568
I0817 02:11:22.610451 20404 solver.cpp:228] Iteration 8310, loss = 0.82072
I0817 02:11:22.610631 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:11:22.610646 20404 solver.cpp:244]     Train net output #1: loss = 0.82072 (* 1 = 0.82072 loss)
I0817 02:11:22.610659 20404 sgd_solver.cpp:106] Iteration 8310, lr = 0.000635307
I0817 02:11:54.021139 20404 solver.cpp:337] Iteration 8320, Testing net (#0)
I0817 02:12:28.681007 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:12:28.681176 20404 solver.cpp:404]     Test net output #1: loss = 0.671504 (* 1 = 0.671504 loss)
I0817 02:12:32.164106 20404 solver.cpp:228] Iteration 8320, loss = 0.820049
I0817 02:12:32.164156 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:12:32.164170 20404 solver.cpp:244]     Train net output #1: loss = 0.820049 (* 1 = 0.820049 loss)
I0817 02:12:32.164182 20404 sgd_solver.cpp:106] Iteration 8320, lr = 0.000635047
I0817 02:13:07.058511 20404 solver.cpp:228] Iteration 8330, loss = 0.820432
I0817 02:13:07.058686 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:13:07.058701 20404 solver.cpp:244]     Train net output #1: loss = 0.820432 (* 1 = 0.820432 loss)
I0817 02:13:07.058713 20404 sgd_solver.cpp:106] Iteration 8330, lr = 0.000634787
I0817 02:13:41.953549 20404 solver.cpp:228] Iteration 8340, loss = 0.820325
I0817 02:13:41.953728 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:13:41.953747 20404 solver.cpp:244]     Train net output #1: loss = 0.820325 (* 1 = 0.820325 loss)
I0817 02:13:41.953763 20404 sgd_solver.cpp:106] Iteration 8340, lr = 0.000634528
I0817 02:14:16.844051 20404 solver.cpp:228] Iteration 8350, loss = 0.820845
I0817 02:14:16.844229 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:14:16.844249 20404 solver.cpp:244]     Train net output #1: loss = 0.820845 (* 1 = 0.820845 loss)
I0817 02:14:16.844264 20404 sgd_solver.cpp:106] Iteration 8350, lr = 0.000634268
I0817 02:14:48.245249 20404 solver.cpp:337] Iteration 8360, Testing net (#0)
I0817 02:15:22.906925 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:15:22.907109 20404 solver.cpp:404]     Test net output #1: loss = 0.6715 (* 1 = 0.6715 loss)
I0817 02:15:26.383157 20404 solver.cpp:228] Iteration 8360, loss = 0.820053
I0817 02:15:26.383201 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:15:26.383219 20404 solver.cpp:244]     Train net output #1: loss = 0.820053 (* 1 = 0.820053 loss)
I0817 02:15:26.383244 20404 sgd_solver.cpp:106] Iteration 8360, lr = 0.000634009
I0817 02:16:01.243597 20404 solver.cpp:228] Iteration 8370, loss = 0.820336
I0817 02:16:01.243767 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:16:01.243787 20404 solver.cpp:244]     Train net output #1: loss = 0.820336 (* 1 = 0.820336 loss)
I0817 02:16:01.243798 20404 sgd_solver.cpp:106] Iteration 8370, lr = 0.00063375
I0817 02:16:36.155591 20404 solver.cpp:228] Iteration 8380, loss = 0.820275
I0817 02:16:36.155772 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:16:36.155788 20404 solver.cpp:244]     Train net output #1: loss = 0.820275 (* 1 = 0.820275 loss)
I0817 02:16:36.155802 20404 sgd_solver.cpp:106] Iteration 8380, lr = 0.000633492
I0817 02:17:11.052654 20404 solver.cpp:228] Iteration 8390, loss = 0.820158
I0817 02:17:11.052830 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:17:11.052846 20404 solver.cpp:244]     Train net output #1: loss = 0.820158 (* 1 = 0.820158 loss)
I0817 02:17:11.052858 20404 sgd_solver.cpp:106] Iteration 8390, lr = 0.000633233
I0817 02:17:42.481626 20404 solver.cpp:337] Iteration 8400, Testing net (#0)
I0817 02:18:17.123154 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:18:17.123256 20404 solver.cpp:404]     Test net output #1: loss = 0.670884 (* 1 = 0.670884 loss)
I0817 02:18:20.601224 20404 solver.cpp:228] Iteration 8400, loss = 0.820622
I0817 02:18:20.601265 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:18:20.601280 20404 solver.cpp:244]     Train net output #1: loss = 0.820622 (* 1 = 0.820622 loss)
I0817 02:18:20.601292 20404 sgd_solver.cpp:106] Iteration 8400, lr = 0.000632975
I0817 02:18:55.496536 20404 solver.cpp:228] Iteration 8410, loss = 0.820062
I0817 02:18:55.496634 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:18:55.496647 20404 solver.cpp:244]     Train net output #1: loss = 0.820062 (* 1 = 0.820062 loss)
I0817 02:18:55.496660 20404 sgd_solver.cpp:106] Iteration 8410, lr = 0.000632717
I0817 02:19:30.385769 20404 solver.cpp:228] Iteration 8420, loss = 0.821413
I0817 02:19:30.385951 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:19:30.385969 20404 solver.cpp:244]     Train net output #1: loss = 0.821413 (* 1 = 0.821413 loss)
I0817 02:19:30.385983 20404 sgd_solver.cpp:106] Iteration 8420, lr = 0.00063246
I0817 02:20:05.289297 20404 solver.cpp:228] Iteration 8430, loss = 0.820671
I0817 02:20:05.289477 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:20:05.289492 20404 solver.cpp:244]     Train net output #1: loss = 0.820671 (* 1 = 0.820671 loss)
I0817 02:20:05.289505 20404 sgd_solver.cpp:106] Iteration 8430, lr = 0.000632202
I0817 02:20:36.715658 20404 solver.cpp:337] Iteration 8440, Testing net (#0)
I0817 02:21:11.369228 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:21:11.369446 20404 solver.cpp:404]     Test net output #1: loss = 0.671482 (* 1 = 0.671482 loss)
I0817 02:21:14.849319 20404 solver.cpp:228] Iteration 8440, loss = 0.820083
I0817 02:21:14.849360 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:21:14.849375 20404 solver.cpp:244]     Train net output #1: loss = 0.820083 (* 1 = 0.820083 loss)
I0817 02:21:14.849386 20404 sgd_solver.cpp:106] Iteration 8440, lr = 0.000631945
I0817 02:21:49.749632 20404 solver.cpp:228] Iteration 8450, loss = 0.820672
I0817 02:21:49.749815 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:21:49.749830 20404 solver.cpp:244]     Train net output #1: loss = 0.820672 (* 1 = 0.820672 loss)
I0817 02:21:49.749845 20404 sgd_solver.cpp:106] Iteration 8450, lr = 0.000631688
I0817 02:22:24.650548 20404 solver.cpp:228] Iteration 8460, loss = 0.820297
I0817 02:22:24.650763 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:22:24.650779 20404 solver.cpp:244]     Train net output #1: loss = 0.820297 (* 1 = 0.820297 loss)
I0817 02:22:24.650812 20404 sgd_solver.cpp:106] Iteration 8460, lr = 0.000631432
I0817 02:22:59.546010 20404 solver.cpp:228] Iteration 8470, loss = 0.820297
I0817 02:22:59.546197 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:22:59.546216 20404 solver.cpp:244]     Train net output #1: loss = 0.820297 (* 1 = 0.820297 loss)
I0817 02:22:59.546231 20404 sgd_solver.cpp:106] Iteration 8470, lr = 0.000631175
I0817 02:23:30.960621 20404 solver.cpp:337] Iteration 8480, Testing net (#0)
I0817 02:24:05.615360 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:24:05.615525 20404 solver.cpp:404]     Test net output #1: loss = 0.67137 (* 1 = 0.67137 loss)
I0817 02:24:09.087060 20404 solver.cpp:228] Iteration 8480, loss = 0.820021
I0817 02:24:09.087112 20404 solver.cpp:244]     Train net output #0: accuracy = 0.84
I0817 02:24:09.087126 20404 solver.cpp:244]     Train net output #1: loss = 0.820021 (* 1 = 0.820021 loss)
I0817 02:24:09.087138 20404 sgd_solver.cpp:106] Iteration 8480, lr = 0.000630919
I0817 02:24:43.984521 20404 solver.cpp:228] Iteration 8490, loss = 0.820347
I0817 02:24:43.984624 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:24:43.984640 20404 solver.cpp:244]     Train net output #1: loss = 0.820347 (* 1 = 0.820347 loss)
I0817 02:24:43.984653 20404 sgd_solver.cpp:106] Iteration 8490, lr = 0.000630663
I0817 02:25:18.895153 20404 solver.cpp:228] Iteration 8500, loss = 0.820313
I0817 02:25:18.895241 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:25:18.895256 20404 solver.cpp:244]     Train net output #1: loss = 0.820313 (* 1 = 0.820313 loss)
I0817 02:25:18.895269 20404 sgd_solver.cpp:106] Iteration 8500, lr = 0.000630407
I0817 02:25:53.781250 20404 solver.cpp:228] Iteration 8510, loss = 0.820198
I0817 02:25:53.781426 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:25:53.781441 20404 solver.cpp:244]     Train net output #1: loss = 0.820198 (* 1 = 0.820198 loss)
I0817 02:25:53.781455 20404 sgd_solver.cpp:106] Iteration 8510, lr = 0.000630152
I0817 02:26:25.219178 20404 solver.cpp:337] Iteration 8520, Testing net (#0)
I0817 02:26:59.909668 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:26:59.909839 20404 solver.cpp:404]     Test net output #1: loss = 0.671346 (* 1 = 0.671346 loss)
I0817 02:27:03.393311 20404 solver.cpp:228] Iteration 8520, loss = 0.820031
I0817 02:27:03.393354 20404 solver.cpp:244]     Train net output #0: accuracy = 0.67
I0817 02:27:03.393373 20404 solver.cpp:244]     Train net output #1: loss = 0.820031 (* 1 = 0.820031 loss)
I0817 02:27:03.393398 20404 sgd_solver.cpp:106] Iteration 8520, lr = 0.000629897
I0817 02:27:38.277079 20404 solver.cpp:228] Iteration 8530, loss = 0.820629
I0817 02:27:38.277259 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:27:38.277277 20404 solver.cpp:244]     Train net output #1: loss = 0.820629 (* 1 = 0.820629 loss)
I0817 02:27:38.277292 20404 sgd_solver.cpp:106] Iteration 8530, lr = 0.000629642
I0817 02:28:13.157089 20404 solver.cpp:228] Iteration 8540, loss = 0.822025
I0817 02:28:13.157271 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:28:13.157291 20404 solver.cpp:244]     Train net output #1: loss = 0.822025 (* 1 = 0.822025 loss)
I0817 02:28:13.157306 20404 sgd_solver.cpp:106] Iteration 8540, lr = 0.000629387
I0817 02:28:48.051545 20404 solver.cpp:228] Iteration 8550, loss = 0.820506
I0817 02:28:48.051731 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:28:48.051750 20404 solver.cpp:244]     Train net output #1: loss = 0.820506 (* 1 = 0.820506 loss)
I0817 02:28:48.051765 20404 sgd_solver.cpp:106] Iteration 8550, lr = 0.000629132
I0817 02:29:19.490525 20404 solver.cpp:337] Iteration 8560, Testing net (#0)
I0817 02:29:54.141121 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:29:54.141216 20404 solver.cpp:404]     Test net output #1: loss = 0.670757 (* 1 = 0.670757 loss)
I0817 02:29:57.622756 20404 solver.cpp:228] Iteration 8560, loss = 0.820779
I0817 02:29:57.622808 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:29:57.622828 20404 solver.cpp:244]     Train net output #1: loss = 0.820779 (* 1 = 0.820779 loss)
I0817 02:29:57.622843 20404 sgd_solver.cpp:106] Iteration 8560, lr = 0.000628878
I0817 02:30:32.530097 20404 solver.cpp:228] Iteration 8570, loss = 0.821491
I0817 02:30:32.530277 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:30:32.530297 20404 solver.cpp:244]     Train net output #1: loss = 0.821491 (* 1 = 0.821491 loss)
I0817 02:30:32.530311 20404 sgd_solver.cpp:106] Iteration 8570, lr = 0.000628624
I0817 02:31:07.418076 20404 solver.cpp:228] Iteration 8580, loss = 0.82013
I0817 02:31:07.418263 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:31:07.418282 20404 solver.cpp:244]     Train net output #1: loss = 0.82013 (* 1 = 0.82013 loss)
I0817 02:31:07.418298 20404 sgd_solver.cpp:106] Iteration 8580, lr = 0.00062837
I0817 02:31:42.317564 20404 solver.cpp:228] Iteration 8590, loss = 0.820056
I0817 02:31:42.317747 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 02:31:42.317766 20404 solver.cpp:244]     Train net output #1: loss = 0.820056 (* 1 = 0.820056 loss)
I0817 02:31:42.317782 20404 sgd_solver.cpp:106] Iteration 8590, lr = 0.000628117
I0817 02:32:13.753073 20404 solver.cpp:337] Iteration 8600, Testing net (#0)
I0817 02:32:48.426499 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:32:48.426672 20404 solver.cpp:404]     Test net output #1: loss = 0.671501 (* 1 = 0.671501 loss)
I0817 02:32:51.895088 20404 solver.cpp:228] Iteration 8600, loss = 0.820091
I0817 02:32:51.895135 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:32:51.895153 20404 solver.cpp:244]     Train net output #1: loss = 0.820091 (* 1 = 0.820091 loss)
I0817 02:32:51.895169 20404 sgd_solver.cpp:106] Iteration 8600, lr = 0.000627864
I0817 02:33:26.795900 20404 solver.cpp:228] Iteration 8610, loss = 0.820515
I0817 02:33:26.796077 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:33:26.796095 20404 solver.cpp:244]     Train net output #1: loss = 0.820515 (* 1 = 0.820515 loss)
I0817 02:33:26.796110 20404 sgd_solver.cpp:106] Iteration 8610, lr = 0.000627611
I0817 02:34:01.708489 20404 solver.cpp:228] Iteration 8620, loss = 0.820148
I0817 02:34:01.708571 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:34:01.708586 20404 solver.cpp:244]     Train net output #1: loss = 0.820148 (* 1 = 0.820148 loss)
I0817 02:34:01.708600 20404 sgd_solver.cpp:106] Iteration 8620, lr = 0.000627358
I0817 02:34:36.600373 20404 solver.cpp:228] Iteration 8630, loss = 0.820279
I0817 02:34:36.600477 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:34:36.600493 20404 solver.cpp:244]     Train net output #1: loss = 0.820279 (* 1 = 0.820279 loss)
I0817 02:34:36.600507 20404 sgd_solver.cpp:106] Iteration 8630, lr = 0.000627105
I0817 02:35:08.022444 20404 solver.cpp:337] Iteration 8640, Testing net (#0)
I0817 02:35:42.667727 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:35:42.667902 20404 solver.cpp:404]     Test net output #1: loss = 0.671032 (* 1 = 0.671032 loss)
I0817 02:35:46.147179 20404 solver.cpp:228] Iteration 8640, loss = 0.820431
I0817 02:35:46.147233 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:35:46.147246 20404 solver.cpp:244]     Train net output #1: loss = 0.820431 (* 1 = 0.820431 loss)
I0817 02:35:46.147258 20404 sgd_solver.cpp:106] Iteration 8640, lr = 0.000626853
I0817 02:36:21.025651 20404 solver.cpp:228] Iteration 8650, loss = 0.820317
I0817 02:36:21.025823 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:36:21.025840 20404 solver.cpp:244]     Train net output #1: loss = 0.820317 (* 1 = 0.820317 loss)
I0817 02:36:21.025851 20404 sgd_solver.cpp:106] Iteration 8650, lr = 0.000626601
I0817 02:36:55.938210 20404 solver.cpp:228] Iteration 8660, loss = 0.821298
I0817 02:36:55.938402 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:36:55.938421 20404 solver.cpp:244]     Train net output #1: loss = 0.821298 (* 1 = 0.821298 loss)
I0817 02:36:55.938433 20404 sgd_solver.cpp:106] Iteration 8660, lr = 0.000626349
I0817 02:37:30.826537 20404 solver.cpp:228] Iteration 8670, loss = 0.820408
I0817 02:37:30.826712 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:37:30.826731 20404 solver.cpp:244]     Train net output #1: loss = 0.820408 (* 1 = 0.820408 loss)
I0817 02:37:30.826745 20404 sgd_solver.cpp:106] Iteration 8670, lr = 0.000626097
I0817 02:38:02.250244 20404 solver.cpp:337] Iteration 8680, Testing net (#0)
I0817 02:38:36.891723 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:38:36.891894 20404 solver.cpp:404]     Test net output #1: loss = 0.670994 (* 1 = 0.670994 loss)
I0817 02:38:40.365000 20404 solver.cpp:228] Iteration 8680, loss = 0.82048
I0817 02:38:40.365048 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:38:40.365062 20404 solver.cpp:244]     Train net output #1: loss = 0.82048 (* 1 = 0.82048 loss)
I0817 02:38:40.365074 20404 sgd_solver.cpp:106] Iteration 8680, lr = 0.000625846
I0817 02:39:15.273263 20404 solver.cpp:228] Iteration 8690, loss = 0.82105
I0817 02:39:15.273442 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:39:15.273458 20404 solver.cpp:244]     Train net output #1: loss = 0.82105 (* 1 = 0.82105 loss)
I0817 02:39:15.273469 20404 sgd_solver.cpp:106] Iteration 8690, lr = 0.000625595
I0817 02:39:50.182899 20404 solver.cpp:228] Iteration 8700, loss = 0.820062
I0817 02:39:50.183079 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:39:50.183094 20404 solver.cpp:244]     Train net output #1: loss = 0.820062 (* 1 = 0.820062 loss)
I0817 02:39:50.183105 20404 sgd_solver.cpp:106] Iteration 8700, lr = 0.000625344
I0817 02:40:25.081756 20404 solver.cpp:228] Iteration 8710, loss = 0.820455
I0817 02:40:25.081933 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:40:25.081949 20404 solver.cpp:244]     Train net output #1: loss = 0.820455 (* 1 = 0.820455 loss)
I0817 02:40:25.081962 20404 sgd_solver.cpp:106] Iteration 8710, lr = 0.000625093
I0817 02:40:56.508075 20404 solver.cpp:337] Iteration 8720, Testing net (#0)
I0817 02:41:31.167018 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:41:31.167191 20404 solver.cpp:404]     Test net output #1: loss = 0.671007 (* 1 = 0.671007 loss)
I0817 02:41:34.651175 20404 solver.cpp:228] Iteration 8720, loss = 0.820468
I0817 02:41:34.651226 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:41:34.651240 20404 solver.cpp:244]     Train net output #1: loss = 0.820468 (* 1 = 0.820468 loss)
I0817 02:41:34.651252 20404 sgd_solver.cpp:106] Iteration 8720, lr = 0.000624843
I0817 02:42:09.532542 20404 solver.cpp:228] Iteration 8730, loss = 0.820615
I0817 02:42:09.532721 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:42:09.532737 20404 solver.cpp:244]     Train net output #1: loss = 0.820615 (* 1 = 0.820615 loss)
I0817 02:42:09.532749 20404 sgd_solver.cpp:106] Iteration 8730, lr = 0.000624592
I0817 02:42:44.433485 20404 solver.cpp:228] Iteration 8740, loss = 0.821393
I0817 02:42:44.433668 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:42:44.433684 20404 solver.cpp:244]     Train net output #1: loss = 0.821393 (* 1 = 0.821393 loss)
I0817 02:42:44.433696 20404 sgd_solver.cpp:106] Iteration 8740, lr = 0.000624342
I0817 02:43:19.319596 20404 solver.cpp:228] Iteration 8750, loss = 0.820091
I0817 02:43:19.319769 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:43:19.319784 20404 solver.cpp:244]     Train net output #1: loss = 0.820091 (* 1 = 0.820091 loss)
I0817 02:43:19.319797 20404 sgd_solver.cpp:106] Iteration 8750, lr = 0.000624093
I0817 02:43:50.746809 20404 solver.cpp:337] Iteration 8760, Testing net (#0)
I0817 02:44:25.400440 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:44:25.400621 20404 solver.cpp:404]     Test net output #1: loss = 0.670923 (* 1 = 0.670923 loss)
I0817 02:44:28.874619 20404 solver.cpp:228] Iteration 8760, loss = 0.820575
I0817 02:44:28.874661 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:44:28.874676 20404 solver.cpp:244]     Train net output #1: loss = 0.820575 (* 1 = 0.820575 loss)
I0817 02:44:28.874687 20404 sgd_solver.cpp:106] Iteration 8760, lr = 0.000623843
I0817 02:45:03.766049 20404 solver.cpp:228] Iteration 8770, loss = 0.8209
I0817 02:45:03.766219 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:45:03.766234 20404 solver.cpp:244]     Train net output #1: loss = 0.8209 (* 1 = 0.8209 loss)
I0817 02:45:03.766247 20404 sgd_solver.cpp:106] Iteration 8770, lr = 0.000623594
I0817 02:45:38.627259 20404 solver.cpp:228] Iteration 8780, loss = 0.820214
I0817 02:45:38.627434 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:45:38.627449 20404 solver.cpp:244]     Train net output #1: loss = 0.820214 (* 1 = 0.820214 loss)
I0817 02:45:38.627461 20404 sgd_solver.cpp:106] Iteration 8780, lr = 0.000623345
I0817 02:46:13.515310 20404 solver.cpp:228] Iteration 8790, loss = 0.821127
I0817 02:46:13.515480 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:46:13.515496 20404 solver.cpp:244]     Train net output #1: loss = 0.821127 (* 1 = 0.821127 loss)
I0817 02:46:13.515508 20404 sgd_solver.cpp:106] Iteration 8790, lr = 0.000623096
I0817 02:46:44.927355 20404 solver.cpp:337] Iteration 8800, Testing net (#0)
I0817 02:47:19.587704 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:47:19.587903 20404 solver.cpp:404]     Test net output #1: loss = 0.670742 (* 1 = 0.670742 loss)
I0817 02:47:23.067806 20404 solver.cpp:228] Iteration 8800, loss = 0.820806
I0817 02:47:23.067857 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:47:23.067869 20404 solver.cpp:244]     Train net output #1: loss = 0.820806 (* 1 = 0.820806 loss)
I0817 02:47:23.067881 20404 sgd_solver.cpp:106] Iteration 8800, lr = 0.000622847
I0817 02:47:57.949118 20404 solver.cpp:228] Iteration 8810, loss = 0.820911
I0817 02:47:57.949311 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:47:57.949328 20404 solver.cpp:244]     Train net output #1: loss = 0.820911 (* 1 = 0.820911 loss)
I0817 02:47:57.949340 20404 sgd_solver.cpp:106] Iteration 8810, lr = 0.000622599
I0817 02:48:32.865547 20404 solver.cpp:228] Iteration 8820, loss = 0.821167
I0817 02:48:32.865722 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:48:32.865738 20404 solver.cpp:244]     Train net output #1: loss = 0.821167 (* 1 = 0.821167 loss)
I0817 02:48:32.865751 20404 sgd_solver.cpp:106] Iteration 8820, lr = 0.000622351
I0817 02:49:07.775202 20404 solver.cpp:228] Iteration 8830, loss = 0.820504
I0817 02:49:07.775383 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:49:07.775400 20404 solver.cpp:244]     Train net output #1: loss = 0.820504 (* 1 = 0.820504 loss)
I0817 02:49:07.775413 20404 sgd_solver.cpp:106] Iteration 8830, lr = 0.000622103
I0817 02:49:39.175456 20404 solver.cpp:337] Iteration 8840, Testing net (#0)
I0817 02:50:13.816040 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:50:13.816220 20404 solver.cpp:404]     Test net output #1: loss = 0.671217 (* 1 = 0.671217 loss)
I0817 02:50:17.300740 20404 solver.cpp:228] Iteration 8840, loss = 0.820204
I0817 02:50:17.300794 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:50:17.300809 20404 solver.cpp:244]     Train net output #1: loss = 0.820204 (* 1 = 0.820204 loss)
I0817 02:50:17.300822 20404 sgd_solver.cpp:106] Iteration 8840, lr = 0.000621855
I0817 02:50:52.177403 20404 solver.cpp:228] Iteration 8850, loss = 0.820438
I0817 02:50:52.177613 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:50:52.177628 20404 solver.cpp:244]     Train net output #1: loss = 0.820438 (* 1 = 0.820438 loss)
I0817 02:50:52.177639 20404 sgd_solver.cpp:106] Iteration 8850, lr = 0.000621608
I0817 02:51:27.080040 20404 solver.cpp:228] Iteration 8860, loss = 0.820759
I0817 02:51:27.080138 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:51:27.080157 20404 solver.cpp:244]     Train net output #1: loss = 0.820759 (* 1 = 0.820759 loss)
I0817 02:51:27.080173 20404 sgd_solver.cpp:106] Iteration 8860, lr = 0.000621361
I0817 02:52:01.968325 20404 solver.cpp:228] Iteration 8870, loss = 0.820215
I0817 02:52:01.968508 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:52:01.968528 20404 solver.cpp:244]     Train net output #1: loss = 0.820215 (* 1 = 0.820215 loss)
I0817 02:52:01.968545 20404 sgd_solver.cpp:106] Iteration 8870, lr = 0.000621114
I0817 02:52:33.366760 20404 solver.cpp:337] Iteration 8880, Testing net (#0)
I0817 02:53:07.996875 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:53:07.997059 20404 solver.cpp:404]     Test net output #1: loss = 0.672198 (* 1 = 0.672198 loss)
I0817 02:53:11.476940 20404 solver.cpp:228] Iteration 8880, loss = 0.820474
I0817 02:53:11.476992 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:53:11.477006 20404 solver.cpp:244]     Train net output #1: loss = 0.820474 (* 1 = 0.820474 loss)
I0817 02:53:11.477018 20404 sgd_solver.cpp:106] Iteration 8880, lr = 0.000620867
I0817 02:53:46.371294 20404 solver.cpp:228] Iteration 8890, loss = 0.820658
I0817 02:53:46.371474 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:53:46.371490 20404 solver.cpp:244]     Train net output #1: loss = 0.820658 (* 1 = 0.820658 loss)
I0817 02:53:46.371502 20404 sgd_solver.cpp:106] Iteration 8890, lr = 0.00062062
I0817 02:54:21.274687 20404 solver.cpp:228] Iteration 8900, loss = 0.820103
I0817 02:54:21.274863 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:54:21.274879 20404 solver.cpp:244]     Train net output #1: loss = 0.820103 (* 1 = 0.820103 loss)
I0817 02:54:21.274891 20404 sgd_solver.cpp:106] Iteration 8900, lr = 0.000620374
I0817 02:54:56.164321 20404 solver.cpp:228] Iteration 8910, loss = 0.820154
I0817 02:54:56.164504 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:54:56.164518 20404 solver.cpp:244]     Train net output #1: loss = 0.820154 (* 1 = 0.820154 loss)
I0817 02:54:56.164530 20404 sgd_solver.cpp:106] Iteration 8910, lr = 0.000620128
I0817 02:55:27.574219 20404 solver.cpp:337] Iteration 8920, Testing net (#0)
I0817 02:56:02.224077 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:56:02.224262 20404 solver.cpp:404]     Test net output #1: loss = 0.670918 (* 1 = 0.670918 loss)
I0817 02:56:05.704884 20404 solver.cpp:228] Iteration 8920, loss = 0.820592
I0817 02:56:05.704938 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:56:05.704953 20404 solver.cpp:244]     Train net output #1: loss = 0.820592 (* 1 = 0.820592 loss)
I0817 02:56:05.704964 20404 sgd_solver.cpp:106] Iteration 8920, lr = 0.000619882
I0817 02:56:40.600772 20404 solver.cpp:228] Iteration 8930, loss = 0.82012
I0817 02:56:40.600951 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:56:40.600966 20404 solver.cpp:244]     Train net output #1: loss = 0.82012 (* 1 = 0.82012 loss)
I0817 02:56:40.600978 20404 sgd_solver.cpp:106] Iteration 8930, lr = 0.000619637
I0817 02:57:15.473767 20404 solver.cpp:228] Iteration 8940, loss = 0.820223
I0817 02:57:15.473948 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:57:15.473963 20404 solver.cpp:244]     Train net output #1: loss = 0.820223 (* 1 = 0.820223 loss)
I0817 02:57:15.473975 20404 sgd_solver.cpp:106] Iteration 8940, lr = 0.000619391
I0817 02:57:50.357182 20404 solver.cpp:228] Iteration 8950, loss = 0.820208
I0817 02:57:50.357367 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:57:50.357381 20404 solver.cpp:244]     Train net output #1: loss = 0.820208 (* 1 = 0.820208 loss)
I0817 02:57:50.357393 20404 sgd_solver.cpp:106] Iteration 8950, lr = 0.000619146
I0817 02:58:21.759348 20404 solver.cpp:337] Iteration 8960, Testing net (#0)
I0817 02:58:56.401520 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 02:58:56.401710 20404 solver.cpp:404]     Test net output #1: loss = 0.67101 (* 1 = 0.67101 loss)
I0817 02:58:59.885350 20404 solver.cpp:228] Iteration 8960, loss = 0.820475
I0817 02:58:59.885402 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 02:58:59.885416 20404 solver.cpp:244]     Train net output #1: loss = 0.820475 (* 1 = 0.820475 loss)
I0817 02:58:59.885428 20404 sgd_solver.cpp:106] Iteration 8960, lr = 0.000618901
I0817 02:59:34.769898 20404 solver.cpp:228] Iteration 8970, loss = 0.820279
I0817 02:59:34.769996 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 02:59:34.770015 20404 solver.cpp:244]     Train net output #1: loss = 0.820279 (* 1 = 0.820279 loss)
I0817 02:59:34.770030 20404 sgd_solver.cpp:106] Iteration 8970, lr = 0.000618656
I0817 03:00:09.644204 20404 solver.cpp:228] Iteration 8980, loss = 0.82151
I0817 03:00:09.644372 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:00:09.644388 20404 solver.cpp:244]     Train net output #1: loss = 0.82151 (* 1 = 0.82151 loss)
I0817 03:00:09.644402 20404 sgd_solver.cpp:106] Iteration 8980, lr = 0.000618412
I0817 03:00:44.541100 20404 solver.cpp:228] Iteration 8990, loss = 0.820937
I0817 03:00:44.541201 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:00:44.541218 20404 solver.cpp:244]     Train net output #1: loss = 0.820937 (* 1 = 0.820937 loss)
I0817 03:00:44.541231 20404 sgd_solver.cpp:106] Iteration 8990, lr = 0.000618168
I0817 03:01:15.961623 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_9000.caffemodel
I0817 03:01:26.854280 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_9000.solverstate
I0817 03:01:28.653939 20404 solver.cpp:337] Iteration 9000, Testing net (#0)
I0817 03:02:03.311931 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:02:03.312105 20404 solver.cpp:404]     Test net output #1: loss = 0.671805 (* 1 = 0.671805 loss)
I0817 03:02:06.786134 20404 solver.cpp:228] Iteration 9000, loss = 0.820246
I0817 03:02:06.786188 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:02:06.786203 20404 solver.cpp:244]     Train net output #1: loss = 0.820246 (* 1 = 0.820246 loss)
I0817 03:02:06.786216 20404 sgd_solver.cpp:106] Iteration 9000, lr = 0.000617924
I0817 03:02:41.676748 20404 solver.cpp:228] Iteration 9010, loss = 0.821494
I0817 03:02:41.676918 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:02:41.676934 20404 solver.cpp:244]     Train net output #1: loss = 0.821494 (* 1 = 0.821494 loss)
I0817 03:02:41.676947 20404 sgd_solver.cpp:106] Iteration 9010, lr = 0.00061768
I0817 03:03:16.563261 20404 solver.cpp:228] Iteration 9020, loss = 0.820914
I0817 03:03:16.563441 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:03:16.563460 20404 solver.cpp:244]     Train net output #1: loss = 0.820914 (* 1 = 0.820914 loss)
I0817 03:03:16.563473 20404 sgd_solver.cpp:106] Iteration 9020, lr = 0.000617436
I0817 03:03:51.468353 20404 solver.cpp:228] Iteration 9030, loss = 0.820255
I0817 03:03:51.468544 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:03:51.468562 20404 solver.cpp:244]     Train net output #1: loss = 0.820255 (* 1 = 0.820255 loss)
I0817 03:03:51.468576 20404 sgd_solver.cpp:106] Iteration 9030, lr = 0.000617193
I0817 03:04:22.861811 20404 solver.cpp:337] Iteration 9040, Testing net (#0)
I0817 03:04:57.492864 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:04:57.493038 20404 solver.cpp:404]     Test net output #1: loss = 0.671216 (* 1 = 0.671216 loss)
I0817 03:05:00.973690 20404 solver.cpp:228] Iteration 9040, loss = 0.820216
I0817 03:05:00.973742 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:05:00.973757 20404 solver.cpp:244]     Train net output #1: loss = 0.820216 (* 1 = 0.820216 loss)
I0817 03:05:00.973767 20404 sgd_solver.cpp:106] Iteration 9040, lr = 0.00061695
I0817 03:05:35.876896 20404 solver.cpp:228] Iteration 9050, loss = 0.820029
I0817 03:05:35.877110 20404 solver.cpp:244]     Train net output #0: accuracy = 0.86
I0817 03:05:35.877126 20404 solver.cpp:244]     Train net output #1: loss = 0.820029 (* 1 = 0.820029 loss)
I0817 03:05:35.877138 20404 sgd_solver.cpp:106] Iteration 9050, lr = 0.000616707
I0817 03:06:10.782912 20404 solver.cpp:228] Iteration 9060, loss = 0.820733
I0817 03:06:10.783097 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:06:10.783112 20404 solver.cpp:244]     Train net output #1: loss = 0.820733 (* 1 = 0.820733 loss)
I0817 03:06:10.783123 20404 sgd_solver.cpp:106] Iteration 9060, lr = 0.000616464
I0817 03:06:45.687546 20404 solver.cpp:228] Iteration 9070, loss = 0.820616
I0817 03:06:45.687719 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:06:45.687736 20404 solver.cpp:244]     Train net output #1: loss = 0.820616 (* 1 = 0.820616 loss)
I0817 03:06:45.687748 20404 sgd_solver.cpp:106] Iteration 9070, lr = 0.000616222
I0817 03:07:17.109911 20404 solver.cpp:337] Iteration 9080, Testing net (#0)
I0817 03:07:51.748680 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:07:51.748855 20404 solver.cpp:404]     Test net output #1: loss = 0.671753 (* 1 = 0.671753 loss)
I0817 03:07:55.224828 20404 solver.cpp:228] Iteration 9080, loss = 0.820221
I0817 03:07:55.224880 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:07:55.224895 20404 solver.cpp:244]     Train net output #1: loss = 0.820221 (* 1 = 0.820221 loss)
I0817 03:07:55.224906 20404 sgd_solver.cpp:106] Iteration 9080, lr = 0.000615979
I0817 03:08:30.103261 20404 solver.cpp:228] Iteration 9090, loss = 0.820102
I0817 03:08:30.103443 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:08:30.103459 20404 solver.cpp:244]     Train net output #1: loss = 0.820102 (* 1 = 0.820102 loss)
I0817 03:08:30.103471 20404 sgd_solver.cpp:106] Iteration 9090, lr = 0.000615737
I0817 03:09:04.994951 20404 solver.cpp:228] Iteration 9100, loss = 0.820455
I0817 03:09:04.995132 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:09:04.995147 20404 solver.cpp:244]     Train net output #1: loss = 0.820455 (* 1 = 0.820455 loss)
I0817 03:09:04.995160 20404 sgd_solver.cpp:106] Iteration 9100, lr = 0.000615496
I0817 03:09:39.909116 20404 solver.cpp:228] Iteration 9110, loss = 0.821236
I0817 03:09:39.909284 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:09:39.909301 20404 solver.cpp:244]     Train net output #1: loss = 0.821236 (* 1 = 0.821236 loss)
I0817 03:09:39.909312 20404 sgd_solver.cpp:106] Iteration 9110, lr = 0.000615254
I0817 03:10:11.330219 20404 solver.cpp:337] Iteration 9120, Testing net (#0)
I0817 03:10:46.000205 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:10:46.000380 20404 solver.cpp:404]     Test net output #1: loss = 0.671329 (* 1 = 0.671329 loss)
I0817 03:10:49.477670 20404 solver.cpp:228] Iteration 9120, loss = 0.820078
I0817 03:10:49.477721 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:10:49.477735 20404 solver.cpp:244]     Train net output #1: loss = 0.820078 (* 1 = 0.820078 loss)
I0817 03:10:49.477747 20404 sgd_solver.cpp:106] Iteration 9120, lr = 0.000615013
I0817 03:11:24.361625 20404 solver.cpp:228] Iteration 9130, loss = 0.820654
I0817 03:11:24.361795 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:11:24.361811 20404 solver.cpp:244]     Train net output #1: loss = 0.820654 (* 1 = 0.820654 loss)
I0817 03:11:24.361824 20404 sgd_solver.cpp:106] Iteration 9130, lr = 0.000614772
I0817 03:11:59.259991 20404 solver.cpp:228] Iteration 9140, loss = 0.820449
I0817 03:11:59.260164 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:11:59.260179 20404 solver.cpp:244]     Train net output #1: loss = 0.820449 (* 1 = 0.820449 loss)
I0817 03:11:59.260192 20404 sgd_solver.cpp:106] Iteration 9140, lr = 0.000614531
I0817 03:12:34.159610 20404 solver.cpp:228] Iteration 9150, loss = 0.820165
I0817 03:12:34.159814 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:12:34.159832 20404 solver.cpp:244]     Train net output #1: loss = 0.820165 (* 1 = 0.820165 loss)
I0817 03:12:34.159843 20404 sgd_solver.cpp:106] Iteration 9150, lr = 0.00061429
I0817 03:13:05.585039 20404 solver.cpp:337] Iteration 9160, Testing net (#0)
I0817 03:13:40.223619 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:13:40.223821 20404 solver.cpp:404]     Test net output #1: loss = 0.671501 (* 1 = 0.671501 loss)
I0817 03:13:43.699229 20404 solver.cpp:228] Iteration 9160, loss = 0.820077
I0817 03:13:43.699281 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:13:43.699301 20404 solver.cpp:244]     Train net output #1: loss = 0.820077 (* 1 = 0.820077 loss)
I0817 03:13:43.699326 20404 sgd_solver.cpp:106] Iteration 9160, lr = 0.00061405
I0817 03:14:18.602742 20404 solver.cpp:228] Iteration 9170, loss = 0.820273
I0817 03:14:18.602917 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:14:18.602936 20404 solver.cpp:244]     Train net output #1: loss = 0.820273 (* 1 = 0.820273 loss)
I0817 03:14:18.602948 20404 sgd_solver.cpp:106] Iteration 9170, lr = 0.000613809
I0817 03:14:53.489331 20404 solver.cpp:228] Iteration 9180, loss = 0.820058
I0817 03:14:53.489506 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:14:53.489521 20404 solver.cpp:244]     Train net output #1: loss = 0.820058 (* 1 = 0.820058 loss)
I0817 03:14:53.489534 20404 sgd_solver.cpp:106] Iteration 9180, lr = 0.000613569
I0817 03:15:28.368528 20404 solver.cpp:228] Iteration 9190, loss = 0.820096
I0817 03:15:28.368705 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:15:28.368719 20404 solver.cpp:244]     Train net output #1: loss = 0.820096 (* 1 = 0.820096 loss)
I0817 03:15:28.368732 20404 sgd_solver.cpp:106] Iteration 9190, lr = 0.000613329
I0817 03:15:59.797164 20404 solver.cpp:337] Iteration 9200, Testing net (#0)
I0817 03:16:34.431689 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:16:34.431860 20404 solver.cpp:404]     Test net output #1: loss = 0.671084 (* 1 = 0.671084 loss)
I0817 03:16:37.914211 20404 solver.cpp:228] Iteration 9200, loss = 0.820388
I0817 03:16:37.914250 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:16:37.914265 20404 solver.cpp:244]     Train net output #1: loss = 0.820388 (* 1 = 0.820388 loss)
I0817 03:16:37.914278 20404 sgd_solver.cpp:106] Iteration 9200, lr = 0.00061309
I0817 03:17:12.808764 20404 solver.cpp:228] Iteration 9210, loss = 0.820713
I0817 03:17:12.808944 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:17:12.808962 20404 solver.cpp:244]     Train net output #1: loss = 0.820713 (* 1 = 0.820713 loss)
I0817 03:17:12.808975 20404 sgd_solver.cpp:106] Iteration 9210, lr = 0.00061285
I0817 03:17:47.713161 20404 solver.cpp:228] Iteration 9220, loss = 0.82004
I0817 03:17:47.713332 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:17:47.713347 20404 solver.cpp:244]     Train net output #1: loss = 0.82004 (* 1 = 0.82004 loss)
I0817 03:17:47.713361 20404 sgd_solver.cpp:106] Iteration 9220, lr = 0.000612611
I0817 03:18:22.609627 20404 solver.cpp:228] Iteration 9230, loss = 0.820124
I0817 03:18:22.609800 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:18:22.609817 20404 solver.cpp:244]     Train net output #1: loss = 0.820124 (* 1 = 0.820124 loss)
I0817 03:18:22.609829 20404 sgd_solver.cpp:106] Iteration 9230, lr = 0.000612372
I0817 03:18:54.023418 20404 solver.cpp:337] Iteration 9240, Testing net (#0)
I0817 03:19:28.671263 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:19:28.671434 20404 solver.cpp:404]     Test net output #1: loss = 0.671567 (* 1 = 0.671567 loss)
I0817 03:19:32.151510 20404 solver.cpp:228] Iteration 9240, loss = 0.820118
I0817 03:19:32.151562 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:19:32.151576 20404 solver.cpp:244]     Train net output #1: loss = 0.820118 (* 1 = 0.820118 loss)
I0817 03:19:32.151588 20404 sgd_solver.cpp:106] Iteration 9240, lr = 0.000612134
I0817 03:20:07.046396 20404 solver.cpp:228] Iteration 9250, loss = 0.820548
I0817 03:20:07.046617 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:20:07.046633 20404 solver.cpp:244]     Train net output #1: loss = 0.820548 (* 1 = 0.820548 loss)
I0817 03:20:07.046645 20404 sgd_solver.cpp:106] Iteration 9250, lr = 0.000611895
I0817 03:20:41.931918 20404 solver.cpp:228] Iteration 9260, loss = 0.820071
I0817 03:20:41.932097 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:20:41.932112 20404 solver.cpp:244]     Train net output #1: loss = 0.820071 (* 1 = 0.820071 loss)
I0817 03:20:41.932124 20404 sgd_solver.cpp:106] Iteration 9260, lr = 0.000611657
I0817 03:21:16.821913 20404 solver.cpp:228] Iteration 9270, loss = 0.820423
I0817 03:21:16.822083 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:21:16.822098 20404 solver.cpp:244]     Train net output #1: loss = 0.820423 (* 1 = 0.820423 loss)
I0817 03:21:16.822111 20404 sgd_solver.cpp:106] Iteration 9270, lr = 0.000611419
I0817 03:21:48.238744 20404 solver.cpp:337] Iteration 9280, Testing net (#0)
I0817 03:22:22.892561 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:22:22.892729 20404 solver.cpp:404]     Test net output #1: loss = 0.671158 (* 1 = 0.671158 loss)
I0817 03:22:26.368610 20404 solver.cpp:228] Iteration 9280, loss = 0.8203
I0817 03:22:26.368664 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:22:26.368680 20404 solver.cpp:244]     Train net output #1: loss = 0.8203 (* 1 = 0.8203 loss)
I0817 03:22:26.368692 20404 sgd_solver.cpp:106] Iteration 9280, lr = 0.000611181
I0817 03:23:01.239164 20404 solver.cpp:228] Iteration 9290, loss = 0.820796
I0817 03:23:01.239338 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:23:01.239354 20404 solver.cpp:244]     Train net output #1: loss = 0.820796 (* 1 = 0.820796 loss)
I0817 03:23:01.239367 20404 sgd_solver.cpp:106] Iteration 9290, lr = 0.000610943
I0817 03:23:36.152890 20404 solver.cpp:228] Iteration 9300, loss = 0.820049
I0817 03:23:36.153069 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:23:36.153085 20404 solver.cpp:244]     Train net output #1: loss = 0.820049 (* 1 = 0.820049 loss)
I0817 03:23:36.153097 20404 sgd_solver.cpp:106] Iteration 9300, lr = 0.000610706
I0817 03:24:11.024224 20404 solver.cpp:228] Iteration 9310, loss = 0.820319
I0817 03:24:11.024399 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:24:11.024415 20404 solver.cpp:244]     Train net output #1: loss = 0.820319 (* 1 = 0.820319 loss)
I0817 03:24:11.024427 20404 sgd_solver.cpp:106] Iteration 9310, lr = 0.000610469
I0817 03:24:42.441383 20404 solver.cpp:337] Iteration 9320, Testing net (#0)
I0817 03:25:17.080183 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:25:17.080351 20404 solver.cpp:404]     Test net output #1: loss = 0.671838 (* 1 = 0.671838 loss)
I0817 03:25:20.559803 20404 solver.cpp:228] Iteration 9320, loss = 0.820267
I0817 03:25:20.559855 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:25:20.559870 20404 solver.cpp:244]     Train net output #1: loss = 0.820267 (* 1 = 0.820267 loss)
I0817 03:25:20.559880 20404 sgd_solver.cpp:106] Iteration 9320, lr = 0.000610232
I0817 03:25:55.454864 20404 solver.cpp:228] Iteration 9330, loss = 0.82015
I0817 03:25:55.455045 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:25:55.455065 20404 solver.cpp:244]     Train net output #1: loss = 0.82015 (* 1 = 0.82015 loss)
I0817 03:25:55.455077 20404 sgd_solver.cpp:106] Iteration 9330, lr = 0.000609995
I0817 03:26:30.357429 20404 solver.cpp:228] Iteration 9340, loss = 0.820054
I0817 03:26:30.357532 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:26:30.357548 20404 solver.cpp:244]     Train net output #1: loss = 0.820054 (* 1 = 0.820054 loss)
I0817 03:26:30.357560 20404 sgd_solver.cpp:106] Iteration 9340, lr = 0.000609758
I0817 03:27:05.236276 20404 solver.cpp:228] Iteration 9350, loss = 0.8203
I0817 03:27:05.236493 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:27:05.236510 20404 solver.cpp:244]     Train net output #1: loss = 0.8203 (* 1 = 0.8203 loss)
I0817 03:27:05.236521 20404 sgd_solver.cpp:106] Iteration 9350, lr = 0.000609522
I0817 03:27:36.638118 20404 solver.cpp:337] Iteration 9360, Testing net (#0)
I0817 03:28:11.301147 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:28:11.301327 20404 solver.cpp:404]     Test net output #1: loss = 0.671901 (* 1 = 0.671901 loss)
I0817 03:28:14.773707 20404 solver.cpp:228] Iteration 9360, loss = 0.820298
I0817 03:28:14.773758 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:28:14.773772 20404 solver.cpp:244]     Train net output #1: loss = 0.820298 (* 1 = 0.820298 loss)
I0817 03:28:14.773783 20404 sgd_solver.cpp:106] Iteration 9360, lr = 0.000609286
I0817 03:28:49.656584 20404 solver.cpp:228] Iteration 9370, loss = 0.820574
I0817 03:28:49.656752 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:28:49.656769 20404 solver.cpp:244]     Train net output #1: loss = 0.820574 (* 1 = 0.820574 loss)
I0817 03:28:49.656782 20404 sgd_solver.cpp:106] Iteration 9370, lr = 0.00060905
I0817 03:29:24.538745 20404 solver.cpp:228] Iteration 9380, loss = 0.820157
I0817 03:29:24.538861 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:29:24.538877 20404 solver.cpp:244]     Train net output #1: loss = 0.820157 (* 1 = 0.820157 loss)
I0817 03:29:24.538890 20404 sgd_solver.cpp:106] Iteration 9380, lr = 0.000608814
I0817 03:29:59.443449 20404 solver.cpp:228] Iteration 9390, loss = 0.820021
I0817 03:29:59.443625 20404 solver.cpp:244]     Train net output #0: accuracy = 0.8
I0817 03:29:59.443640 20404 solver.cpp:244]     Train net output #1: loss = 0.820021 (* 1 = 0.820021 loss)
I0817 03:29:59.443653 20404 sgd_solver.cpp:106] Iteration 9390, lr = 0.000608579
I0817 03:30:30.851444 20404 solver.cpp:337] Iteration 9400, Testing net (#0)
I0817 03:31:05.495950 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:31:05.496045 20404 solver.cpp:404]     Test net output #1: loss = 0.670763 (* 1 = 0.670763 loss)
I0817 03:31:08.969516 20404 solver.cpp:228] Iteration 9400, loss = 0.820808
I0817 03:31:08.969568 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:31:08.969581 20404 solver.cpp:244]     Train net output #1: loss = 0.820808 (* 1 = 0.820808 loss)
I0817 03:31:08.969594 20404 sgd_solver.cpp:106] Iteration 9400, lr = 0.000608343
I0817 03:31:43.857647 20404 solver.cpp:228] Iteration 9410, loss = 0.821132
I0817 03:31:43.857748 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:31:43.857767 20404 solver.cpp:244]     Train net output #1: loss = 0.821132 (* 1 = 0.821132 loss)
I0817 03:31:43.857782 20404 sgd_solver.cpp:106] Iteration 9410, lr = 0.000608108
I0817 03:32:18.747530 20404 solver.cpp:228] Iteration 9420, loss = 0.820523
I0817 03:32:18.747611 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:32:18.747630 20404 solver.cpp:244]     Train net output #1: loss = 0.820523 (* 1 = 0.820523 loss)
I0817 03:32:18.747653 20404 sgd_solver.cpp:106] Iteration 9420, lr = 0.000607873
I0817 03:32:53.645365 20404 solver.cpp:228] Iteration 9430, loss = 0.820165
I0817 03:32:53.645460 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:32:53.645485 20404 solver.cpp:244]     Train net output #1: loss = 0.820165 (* 1 = 0.820165 loss)
I0817 03:32:53.645504 20404 sgd_solver.cpp:106] Iteration 9430, lr = 0.000607639
I0817 03:33:25.051378 20404 solver.cpp:337] Iteration 9440, Testing net (#0)
I0817 03:33:59.718822 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:33:59.718999 20404 solver.cpp:404]     Test net output #1: loss = 0.671525 (* 1 = 0.671525 loss)
I0817 03:34:03.204466 20404 solver.cpp:228] Iteration 9440, loss = 0.820085
I0817 03:34:03.204511 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:34:03.204530 20404 solver.cpp:244]     Train net output #1: loss = 0.820085 (* 1 = 0.820085 loss)
I0817 03:34:03.204545 20404 sgd_solver.cpp:106] Iteration 9440, lr = 0.000607404
I0817 03:34:38.063426 20404 solver.cpp:228] Iteration 9450, loss = 0.820332
I0817 03:34:38.063632 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:34:38.063647 20404 solver.cpp:244]     Train net output #1: loss = 0.820332 (* 1 = 0.820332 loss)
I0817 03:34:38.063676 20404 sgd_solver.cpp:106] Iteration 9450, lr = 0.00060717
I0817 03:35:12.949640 20404 solver.cpp:228] Iteration 9460, loss = 0.820081
I0817 03:35:12.949821 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:35:12.949839 20404 solver.cpp:244]     Train net output #1: loss = 0.820081 (* 1 = 0.820081 loss)
I0817 03:35:12.949854 20404 sgd_solver.cpp:106] Iteration 9460, lr = 0.000606936
I0817 03:35:47.831014 20404 solver.cpp:228] Iteration 9470, loss = 0.82019
I0817 03:35:47.831197 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:35:47.831214 20404 solver.cpp:244]     Train net output #1: loss = 0.82019 (* 1 = 0.82019 loss)
I0817 03:35:47.831229 20404 sgd_solver.cpp:106] Iteration 9470, lr = 0.000606702
I0817 03:36:19.248245 20404 solver.cpp:337] Iteration 9480, Testing net (#0)
I0817 03:36:53.890537 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:36:53.890705 20404 solver.cpp:404]     Test net output #1: loss = 0.671777 (* 1 = 0.671777 loss)
I0817 03:36:57.363338 20404 solver.cpp:228] Iteration 9480, loss = 0.820229
I0817 03:36:57.363389 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:36:57.363402 20404 solver.cpp:244]     Train net output #1: loss = 0.820229 (* 1 = 0.820229 loss)
I0817 03:36:57.363414 20404 sgd_solver.cpp:106] Iteration 9480, lr = 0.000606469
I0817 03:37:32.227731 20404 solver.cpp:228] Iteration 9490, loss = 0.820069
I0817 03:37:32.227907 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:37:32.227927 20404 solver.cpp:244]     Train net output #1: loss = 0.820069 (* 1 = 0.820069 loss)
I0817 03:37:32.227939 20404 sgd_solver.cpp:106] Iteration 9490, lr = 0.000606235
I0817 03:38:07.126763 20404 solver.cpp:228] Iteration 9500, loss = 0.820267
I0817 03:38:07.126940 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:38:07.126958 20404 solver.cpp:244]     Train net output #1: loss = 0.820267 (* 1 = 0.820267 loss)
I0817 03:38:07.126971 20404 sgd_solver.cpp:106] Iteration 9500, lr = 0.000606002
I0817 03:38:42.037103 20404 solver.cpp:228] Iteration 9510, loss = 0.820284
I0817 03:38:42.037282 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:38:42.037298 20404 solver.cpp:244]     Train net output #1: loss = 0.820284 (* 1 = 0.820284 loss)
I0817 03:38:42.037310 20404 sgd_solver.cpp:106] Iteration 9510, lr = 0.000605769
I0817 03:39:13.462316 20404 solver.cpp:337] Iteration 9520, Testing net (#0)
I0817 03:39:48.126922 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:39:48.127092 20404 solver.cpp:404]     Test net output #1: loss = 0.670728 (* 1 = 0.670728 loss)
I0817 03:39:51.609493 20404 solver.cpp:228] Iteration 9520, loss = 0.820855
I0817 03:39:51.609546 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:39:51.609561 20404 solver.cpp:244]     Train net output #1: loss = 0.820855 (* 1 = 0.820855 loss)
I0817 03:39:51.609573 20404 sgd_solver.cpp:106] Iteration 9520, lr = 0.000605536
I0817 03:40:26.507122 20404 solver.cpp:228] Iteration 9530, loss = 0.820026
I0817 03:40:26.507323 20404 solver.cpp:244]     Train net output #0: accuracy = 0.71
I0817 03:40:26.507339 20404 solver.cpp:244]     Train net output #1: loss = 0.820026 (* 1 = 0.820026 loss)
I0817 03:40:26.507351 20404 sgd_solver.cpp:106] Iteration 9530, lr = 0.000605304
I0817 03:41:01.410481 20404 solver.cpp:228] Iteration 9540, loss = 0.820194
I0817 03:41:01.410634 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:41:01.410653 20404 solver.cpp:244]     Train net output #1: loss = 0.820194 (* 1 = 0.820194 loss)
I0817 03:41:01.410670 20404 sgd_solver.cpp:106] Iteration 9540, lr = 0.000605071
I0817 03:41:36.312175 20404 solver.cpp:228] Iteration 9550, loss = 0.820421
I0817 03:41:36.312360 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:41:36.312374 20404 solver.cpp:244]     Train net output #1: loss = 0.820421 (* 1 = 0.820421 loss)
I0817 03:41:36.312387 20404 sgd_solver.cpp:106] Iteration 9550, lr = 0.000604839
I0817 03:42:07.725842 20404 solver.cpp:337] Iteration 9560, Testing net (#0)
I0817 03:42:42.374891 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:42:42.375067 20404 solver.cpp:404]     Test net output #1: loss = 0.671077 (* 1 = 0.671077 loss)
I0817 03:42:45.846719 20404 solver.cpp:228] Iteration 9560, loss = 0.820409
I0817 03:42:45.846771 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:42:45.846784 20404 solver.cpp:244]     Train net output #1: loss = 0.820409 (* 1 = 0.820409 loss)
I0817 03:42:45.846796 20404 sgd_solver.cpp:106] Iteration 9560, lr = 0.000604607
I0817 03:43:20.744695 20404 solver.cpp:228] Iteration 9570, loss = 0.820245
I0817 03:43:20.744799 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:43:20.744814 20404 solver.cpp:244]     Train net output #1: loss = 0.820245 (* 1 = 0.820245 loss)
I0817 03:43:20.744827 20404 sgd_solver.cpp:106] Iteration 9570, lr = 0.000604376
I0817 03:43:55.643488 20404 solver.cpp:228] Iteration 9580, loss = 0.820712
I0817 03:43:55.643666 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:43:55.643684 20404 solver.cpp:244]     Train net output #1: loss = 0.820712 (* 1 = 0.820712 loss)
I0817 03:43:55.643697 20404 sgd_solver.cpp:106] Iteration 9580, lr = 0.000604144
I0817 03:44:30.563323 20404 solver.cpp:228] Iteration 9590, loss = 0.821056
I0817 03:44:30.563496 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:44:30.563511 20404 solver.cpp:244]     Train net output #1: loss = 0.821056 (* 1 = 0.821056 loss)
I0817 03:44:30.563525 20404 sgd_solver.cpp:106] Iteration 9590, lr = 0.000603913
I0817 03:45:01.982005 20404 solver.cpp:337] Iteration 9600, Testing net (#0)
I0817 03:45:36.646152 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:45:36.646322 20404 solver.cpp:404]     Test net output #1: loss = 0.671033 (* 1 = 0.671033 loss)
I0817 03:45:40.120199 20404 solver.cpp:228] Iteration 9600, loss = 0.820469
I0817 03:45:40.120249 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:45:40.120265 20404 solver.cpp:244]     Train net output #1: loss = 0.820469 (* 1 = 0.820469 loss)
I0817 03:45:40.120276 20404 sgd_solver.cpp:106] Iteration 9600, lr = 0.000603682
I0817 03:46:15.010257 20404 solver.cpp:228] Iteration 9610, loss = 0.820157
I0817 03:46:15.010433 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:46:15.010448 20404 solver.cpp:244]     Train net output #1: loss = 0.820157 (* 1 = 0.820157 loss)
I0817 03:46:15.010460 20404 sgd_solver.cpp:106] Iteration 9610, lr = 0.000603451
I0817 03:46:49.930042 20404 solver.cpp:228] Iteration 9620, loss = 0.820466
I0817 03:46:49.930150 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:46:49.930166 20404 solver.cpp:244]     Train net output #1: loss = 0.820466 (* 1 = 0.820466 loss)
I0817 03:46:49.930178 20404 sgd_solver.cpp:106] Iteration 9620, lr = 0.00060322
I0817 03:47:24.823961 20404 solver.cpp:228] Iteration 9630, loss = 0.820122
I0817 03:47:24.824136 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:47:24.824154 20404 solver.cpp:244]     Train net output #1: loss = 0.820122 (* 1 = 0.820122 loss)
I0817 03:47:24.824167 20404 sgd_solver.cpp:106] Iteration 9630, lr = 0.00060299
I0817 03:47:56.258036 20404 solver.cpp:337] Iteration 9640, Testing net (#0)
I0817 03:48:30.894116 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:48:30.894318 20404 solver.cpp:404]     Test net output #1: loss = 0.670901 (* 1 = 0.670901 loss)
I0817 03:48:34.367744 20404 solver.cpp:228] Iteration 9640, loss = 0.820642
I0817 03:48:34.367794 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:48:34.367808 20404 solver.cpp:244]     Train net output #1: loss = 0.820642 (* 1 = 0.820642 loss)
I0817 03:48:34.367820 20404 sgd_solver.cpp:106] Iteration 9640, lr = 0.000602759
I0817 03:49:09.265102 20404 solver.cpp:228] Iteration 9650, loss = 0.820453
I0817 03:49:09.265285 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:49:09.265300 20404 solver.cpp:244]     Train net output #1: loss = 0.820453 (* 1 = 0.820453 loss)
I0817 03:49:09.265311 20404 sgd_solver.cpp:106] Iteration 9650, lr = 0.000602529
I0817 03:49:44.128540 20404 solver.cpp:228] Iteration 9660, loss = 0.820088
I0817 03:49:44.128707 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:49:44.128723 20404 solver.cpp:244]     Train net output #1: loss = 0.820088 (* 1 = 0.820088 loss)
I0817 03:49:44.128736 20404 sgd_solver.cpp:106] Iteration 9660, lr = 0.000602299
I0817 03:50:19.022114 20404 solver.cpp:228] Iteration 9670, loss = 0.820119
I0817 03:50:19.022296 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:50:19.022312 20404 solver.cpp:244]     Train net output #1: loss = 0.820119 (* 1 = 0.820119 loss)
I0817 03:50:19.022325 20404 sgd_solver.cpp:106] Iteration 9670, lr = 0.00060207
I0817 03:50:50.426605 20404 solver.cpp:337] Iteration 9680, Testing net (#0)
I0817 03:51:25.071166 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:51:25.071336 20404 solver.cpp:404]     Test net output #1: loss = 0.671853 (* 1 = 0.671853 loss)
I0817 03:51:28.546975 20404 solver.cpp:228] Iteration 9680, loss = 0.820267
I0817 03:51:28.547019 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:51:28.547037 20404 solver.cpp:244]     Train net output #1: loss = 0.820267 (* 1 = 0.820267 loss)
I0817 03:51:28.547052 20404 sgd_solver.cpp:106] Iteration 9680, lr = 0.00060184
I0817 03:52:03.422600 20404 solver.cpp:228] Iteration 9690, loss = 0.820792
I0817 03:52:03.422706 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:52:03.422720 20404 solver.cpp:244]     Train net output #1: loss = 0.820792 (* 1 = 0.820792 loss)
I0817 03:52:03.422734 20404 sgd_solver.cpp:106] Iteration 9690, lr = 0.000601611
I0817 03:52:38.319866 20404 solver.cpp:228] Iteration 9700, loss = 0.820047
I0817 03:52:38.319963 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:52:38.319979 20404 solver.cpp:244]     Train net output #1: loss = 0.820047 (* 1 = 0.820047 loss)
I0817 03:52:38.319991 20404 sgd_solver.cpp:106] Iteration 9700, lr = 0.000601382
I0817 03:53:13.230469 20404 solver.cpp:228] Iteration 9710, loss = 0.820659
I0817 03:53:13.230576 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:53:13.230597 20404 solver.cpp:244]     Train net output #1: loss = 0.820659 (* 1 = 0.820659 loss)
I0817 03:53:13.230612 20404 sgd_solver.cpp:106] Iteration 9710, lr = 0.000601153
I0817 03:53:44.646733 20404 solver.cpp:337] Iteration 9720, Testing net (#0)
I0817 03:54:19.311859 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:54:19.311949 20404 solver.cpp:404]     Test net output #1: loss = 0.671481 (* 1 = 0.671481 loss)
I0817 03:54:22.788378 20404 solver.cpp:228] Iteration 9720, loss = 0.820053
I0817 03:54:22.788429 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:54:22.788444 20404 solver.cpp:244]     Train net output #1: loss = 0.820053 (* 1 = 0.820053 loss)
I0817 03:54:22.788455 20404 sgd_solver.cpp:106] Iteration 9720, lr = 0.000600924
I0817 03:54:57.657121 20404 solver.cpp:228] Iteration 9730, loss = 0.820406
I0817 03:54:57.657292 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:54:57.657307 20404 solver.cpp:244]     Train net output #1: loss = 0.820406 (* 1 = 0.820406 loss)
I0817 03:54:57.657320 20404 sgd_solver.cpp:106] Iteration 9730, lr = 0.000600696
I0817 03:55:32.574383 20404 solver.cpp:228] Iteration 9740, loss = 0.820292
I0817 03:55:32.574599 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:55:32.574616 20404 solver.cpp:244]     Train net output #1: loss = 0.820292 (* 1 = 0.820292 loss)
I0817 03:55:32.574647 20404 sgd_solver.cpp:106] Iteration 9740, lr = 0.000600468
I0817 03:56:07.476624 20404 solver.cpp:228] Iteration 9750, loss = 0.820778
I0817 03:56:07.476809 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 03:56:07.476825 20404 solver.cpp:244]     Train net output #1: loss = 0.820778 (* 1 = 0.820778 loss)
I0817 03:56:07.476838 20404 sgd_solver.cpp:106] Iteration 9750, lr = 0.00060024
I0817 03:56:38.893568 20404 solver.cpp:337] Iteration 9760, Testing net (#0)
I0817 03:57:13.559762 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 03:57:13.559936 20404 solver.cpp:404]     Test net output #1: loss = 0.671474 (* 1 = 0.671474 loss)
I0817 03:57:17.035562 20404 solver.cpp:228] Iteration 9760, loss = 0.820052
I0817 03:57:17.035614 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:57:17.035627 20404 solver.cpp:244]     Train net output #1: loss = 0.820052 (* 1 = 0.820052 loss)
I0817 03:57:17.035640 20404 sgd_solver.cpp:106] Iteration 9760, lr = 0.000600012
I0817 03:57:51.914116 20404 solver.cpp:228] Iteration 9770, loss = 0.820315
I0817 03:57:51.914299 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:57:51.914314 20404 solver.cpp:244]     Train net output #1: loss = 0.820315 (* 1 = 0.820315 loss)
I0817 03:57:51.914327 20404 sgd_solver.cpp:106] Iteration 9770, lr = 0.000599784
I0817 03:58:26.815090 20404 solver.cpp:228] Iteration 9780, loss = 0.820262
I0817 03:58:26.815264 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:58:26.815289 20404 solver.cpp:244]     Train net output #1: loss = 0.820262 (* 1 = 0.820262 loss)
I0817 03:58:26.815302 20404 sgd_solver.cpp:106] Iteration 9780, lr = 0.000599557
I0817 03:59:01.706522 20404 solver.cpp:228] Iteration 9790, loss = 0.820143
I0817 03:59:01.706687 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 03:59:01.706707 20404 solver.cpp:244]     Train net output #1: loss = 0.820143 (* 1 = 0.820143 loss)
I0817 03:59:01.706720 20404 sgd_solver.cpp:106] Iteration 9790, lr = 0.00059933
I0817 03:59:33.111414 20404 solver.cpp:337] Iteration 9800, Testing net (#0)
I0817 04:00:07.778080 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:00:07.778250 20404 solver.cpp:404]     Test net output #1: loss = 0.67121 (* 1 = 0.67121 loss)
I0817 04:00:11.256965 20404 solver.cpp:228] Iteration 9800, loss = 0.820259
I0817 04:00:11.257017 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:00:11.257031 20404 solver.cpp:244]     Train net output #1: loss = 0.820259 (* 1 = 0.820259 loss)
I0817 04:00:11.257043 20404 sgd_solver.cpp:106] Iteration 9800, lr = 0.000599102
I0817 04:00:46.128585 20404 solver.cpp:228] Iteration 9810, loss = 0.820821
I0817 04:00:46.128767 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:00:46.128782 20404 solver.cpp:244]     Train net output #1: loss = 0.820821 (* 1 = 0.820821 loss)
I0817 04:00:46.128793 20404 sgd_solver.cpp:106] Iteration 9810, lr = 0.000598876
I0817 04:01:21.028877 20404 solver.cpp:228] Iteration 9820, loss = 0.820431
I0817 04:01:21.029055 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:01:21.029072 20404 solver.cpp:244]     Train net output #1: loss = 0.820431 (* 1 = 0.820431 loss)
I0817 04:01:21.029083 20404 sgd_solver.cpp:106] Iteration 9820, lr = 0.000598649
I0817 04:01:55.939425 20404 solver.cpp:228] Iteration 9830, loss = 0.821153
I0817 04:01:55.939522 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:01:55.939538 20404 solver.cpp:244]     Train net output #1: loss = 0.821153 (* 1 = 0.821153 loss)
I0817 04:01:55.939549 20404 sgd_solver.cpp:106] Iteration 9830, lr = 0.000598423
I0817 04:02:27.377109 20404 solver.cpp:337] Iteration 9840, Testing net (#0)
I0817 04:03:02.025480 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:03:02.025660 20404 solver.cpp:404]     Test net output #1: loss = 0.671389 (* 1 = 0.671389 loss)
I0817 04:03:05.503321 20404 solver.cpp:228] Iteration 9840, loss = 0.820037
I0817 04:03:05.503371 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 04:03:05.503384 20404 solver.cpp:244]     Train net output #1: loss = 0.820037 (* 1 = 0.820037 loss)
I0817 04:03:05.503396 20404 sgd_solver.cpp:106] Iteration 9840, lr = 0.000598196
I0817 04:03:40.398411 20404 solver.cpp:228] Iteration 9850, loss = 0.820194
I0817 04:03:40.398586 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:03:40.398602 20404 solver.cpp:244]     Train net output #1: loss = 0.820194 (* 1 = 0.820194 loss)
I0817 04:03:40.398614 20404 sgd_solver.cpp:106] Iteration 9850, lr = 0.00059797
I0817 04:04:15.299865 20404 solver.cpp:228] Iteration 9860, loss = 0.820065
I0817 04:04:15.300051 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:04:15.300066 20404 solver.cpp:244]     Train net output #1: loss = 0.820065 (* 1 = 0.820065 loss)
I0817 04:04:15.300079 20404 sgd_solver.cpp:106] Iteration 9860, lr = 0.000597744
I0817 04:04:50.181148 20404 solver.cpp:228] Iteration 9870, loss = 0.8207
I0817 04:04:50.181332 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:04:50.181351 20404 solver.cpp:244]     Train net output #1: loss = 0.8207 (* 1 = 0.8207 loss)
I0817 04:04:50.181367 20404 sgd_solver.cpp:106] Iteration 9870, lr = 0.000597519
I0817 04:05:21.621748 20404 solver.cpp:337] Iteration 9880, Testing net (#0)
I0817 04:05:56.250164 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:05:56.250334 20404 solver.cpp:404]     Test net output #1: loss = 0.671363 (* 1 = 0.671363 loss)
I0817 04:05:59.731528 20404 solver.cpp:228] Iteration 9880, loss = 0.820053
I0817 04:05:59.731580 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 04:05:59.731595 20404 solver.cpp:244]     Train net output #1: loss = 0.820053 (* 1 = 0.820053 loss)
I0817 04:05:59.731607 20404 sgd_solver.cpp:106] Iteration 9880, lr = 0.000597293
I0817 04:06:34.638340 20404 solver.cpp:228] Iteration 9890, loss = 0.820207
I0817 04:06:34.638514 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:06:34.638530 20404 solver.cpp:244]     Train net output #1: loss = 0.820207 (* 1 = 0.820207 loss)
I0817 04:06:34.638541 20404 sgd_solver.cpp:106] Iteration 9890, lr = 0.000597068
I0817 04:07:09.540613 20404 solver.cpp:228] Iteration 9900, loss = 0.820114
I0817 04:07:09.540778 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:07:09.540793 20404 solver.cpp:244]     Train net output #1: loss = 0.820114 (* 1 = 0.820114 loss)
I0817 04:07:09.540805 20404 sgd_solver.cpp:106] Iteration 9900, lr = 0.000596843
I0817 04:07:44.409276 20404 solver.cpp:228] Iteration 9910, loss = 0.821032
I0817 04:07:44.409454 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:07:44.409471 20404 solver.cpp:244]     Train net output #1: loss = 0.821032 (* 1 = 0.821032 loss)
I0817 04:07:44.409482 20404 sgd_solver.cpp:106] Iteration 9910, lr = 0.000596618
I0817 04:08:15.829368 20404 solver.cpp:337] Iteration 9920, Testing net (#0)
I0817 04:08:50.463091 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:08:50.463261 20404 solver.cpp:404]     Test net output #1: loss = 0.671486 (* 1 = 0.671486 loss)
I0817 04:08:53.939101 20404 solver.cpp:228] Iteration 9920, loss = 0.820056
I0817 04:08:53.939148 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:08:53.939163 20404 solver.cpp:244]     Train net output #1: loss = 0.820056 (* 1 = 0.820056 loss)
I0817 04:08:53.939175 20404 sgd_solver.cpp:106] Iteration 9920, lr = 0.000596394
I0817 04:09:28.812750 20404 solver.cpp:228] Iteration 9930, loss = 0.820191
I0817 04:09:28.812852 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:09:28.812876 20404 solver.cpp:244]     Train net output #1: loss = 0.820191 (* 1 = 0.820191 loss)
I0817 04:09:28.812893 20404 sgd_solver.cpp:106] Iteration 9930, lr = 0.000596169
I0817 04:10:03.717923 20404 solver.cpp:228] Iteration 9940, loss = 0.820214
I0817 04:10:03.718116 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:10:03.718130 20404 solver.cpp:244]     Train net output #1: loss = 0.820214 (* 1 = 0.820214 loss)
I0817 04:10:03.718143 20404 sgd_solver.cpp:106] Iteration 9940, lr = 0.000595945
I0817 04:10:38.617671 20404 solver.cpp:228] Iteration 9950, loss = 0.820028
I0817 04:10:38.617841 20404 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0817 04:10:38.617854 20404 solver.cpp:244]     Train net output #1: loss = 0.820028 (* 1 = 0.820028 loss)
I0817 04:10:38.617866 20404 sgd_solver.cpp:106] Iteration 9950, lr = 0.000595721
I0817 04:11:10.053359 20404 solver.cpp:337] Iteration 9960, Testing net (#0)
I0817 04:11:44.699766 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:11:44.699946 20404 solver.cpp:404]     Test net output #1: loss = 0.671239 (* 1 = 0.671239 loss)
I0817 04:11:48.178040 20404 solver.cpp:228] Iteration 9960, loss = 0.820219
I0817 04:11:48.178089 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:11:48.178103 20404 solver.cpp:244]     Train net output #1: loss = 0.820219 (* 1 = 0.820219 loss)
I0817 04:11:48.178114 20404 sgd_solver.cpp:106] Iteration 9960, lr = 0.000595497
I0817 04:12:23.073807 20404 solver.cpp:228] Iteration 9970, loss = 0.82007
I0817 04:12:23.073987 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:12:23.074002 20404 solver.cpp:244]     Train net output #1: loss = 0.82007 (* 1 = 0.82007 loss)
I0817 04:12:23.074014 20404 sgd_solver.cpp:106] Iteration 9970, lr = 0.000595273
I0817 04:12:57.951349 20404 solver.cpp:228] Iteration 9980, loss = 0.82033
I0817 04:12:57.951441 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:12:57.951457 20404 solver.cpp:244]     Train net output #1: loss = 0.82033 (* 1 = 0.82033 loss)
I0817 04:12:57.951468 20404 sgd_solver.cpp:106] Iteration 9980, lr = 0.00059505
I0817 04:13:32.824743 20404 solver.cpp:228] Iteration 9990, loss = 0.820023
I0817 04:13:32.824923 20404 solver.cpp:244]     Train net output #0: accuracy = 0.83
I0817 04:13:32.824939 20404 solver.cpp:244]     Train net output #1: loss = 0.820023 (* 1 = 0.820023 loss)
I0817 04:13:32.824951 20404 sgd_solver.cpp:106] Iteration 9990, lr = 0.000594827
I0817 04:14:04.245219 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_10000.caffemodel
I0817 04:14:13.978384 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_10000.solverstate
I0817 04:14:15.602231 20404 solver.cpp:337] Iteration 10000, Testing net (#0)
I0817 04:14:50.251165 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:14:50.251341 20404 solver.cpp:404]     Test net output #1: loss = 0.671249 (* 1 = 0.671249 loss)
I0817 04:14:53.728138 20404 solver.cpp:228] Iteration 10000, loss = 0.820203
I0817 04:14:53.728190 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:14:53.728204 20404 solver.cpp:244]     Train net output #1: loss = 0.820203 (* 1 = 0.820203 loss)
I0817 04:14:53.728216 20404 sgd_solver.cpp:106] Iteration 10000, lr = 0.000594604
I0817 04:15:28.636415 20404 solver.cpp:228] Iteration 10010, loss = 0.820117
I0817 04:15:28.636582 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:15:28.636596 20404 solver.cpp:244]     Train net output #1: loss = 0.820117 (* 1 = 0.820117 loss)
I0817 04:15:28.636610 20404 sgd_solver.cpp:106] Iteration 10010, lr = 0.000594381
I0817 04:16:03.528373 20404 solver.cpp:228] Iteration 10020, loss = 0.82071
I0817 04:16:03.528468 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:16:03.528482 20404 solver.cpp:244]     Train net output #1: loss = 0.82071 (* 1 = 0.82071 loss)
I0817 04:16:03.528494 20404 sgd_solver.cpp:106] Iteration 10020, lr = 0.000594158
I0817 04:16:38.416015 20404 solver.cpp:228] Iteration 10030, loss = 0.820042
I0817 04:16:38.416142 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 04:16:38.416158 20404 solver.cpp:244]     Train net output #1: loss = 0.820042 (* 1 = 0.820042 loss)
I0817 04:16:38.416170 20404 sgd_solver.cpp:106] Iteration 10030, lr = 0.000593936
I0817 04:17:09.838588 20404 solver.cpp:337] Iteration 10040, Testing net (#0)
I0817 04:17:44.481389 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:17:44.481562 20404 solver.cpp:404]     Test net output #1: loss = 0.672201 (* 1 = 0.672201 loss)
I0817 04:17:47.958494 20404 solver.cpp:228] Iteration 10040, loss = 0.820448
I0817 04:17:47.958545 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:17:47.958559 20404 solver.cpp:244]     Train net output #1: loss = 0.820448 (* 1 = 0.820448 loss)
I0817 04:17:47.958571 20404 sgd_solver.cpp:106] Iteration 10040, lr = 0.000593713
I0817 04:18:22.853046 20404 solver.cpp:228] Iteration 10050, loss = 0.820658
I0817 04:18:22.853225 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:18:22.853245 20404 solver.cpp:244]     Train net output #1: loss = 0.820658 (* 1 = 0.820658 loss)
I0817 04:18:22.853256 20404 sgd_solver.cpp:106] Iteration 10050, lr = 0.000593491
I0817 04:18:57.751348 20404 solver.cpp:228] Iteration 10060, loss = 0.820383
I0817 04:18:57.751525 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:18:57.751543 20404 solver.cpp:244]     Train net output #1: loss = 0.820383 (* 1 = 0.820383 loss)
I0817 04:18:57.751559 20404 sgd_solver.cpp:106] Iteration 10060, lr = 0.000593269
I0817 04:19:32.627033 20404 solver.cpp:228] Iteration 10070, loss = 0.820109
I0817 04:19:32.627209 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:19:32.627225 20404 solver.cpp:244]     Train net output #1: loss = 0.820109 (* 1 = 0.820109 loss)
I0817 04:19:32.627238 20404 sgd_solver.cpp:106] Iteration 10070, lr = 0.000593048
I0817 04:20:04.040014 20404 solver.cpp:337] Iteration 10080, Testing net (#0)
I0817 04:20:38.684130 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:20:38.684306 20404 solver.cpp:404]     Test net output #1: loss = 0.671241 (* 1 = 0.671241 loss)
I0817 04:20:42.158627 20404 solver.cpp:228] Iteration 10080, loss = 0.820217
I0817 04:20:42.158682 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:20:42.158696 20404 solver.cpp:244]     Train net output #1: loss = 0.820217 (* 1 = 0.820217 loss)
I0817 04:20:42.158709 20404 sgd_solver.cpp:106] Iteration 10080, lr = 0.000592826
I0817 04:21:17.023367 20404 solver.cpp:228] Iteration 10090, loss = 0.820631
I0817 04:21:17.023470 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:21:17.023485 20404 solver.cpp:244]     Train net output #1: loss = 0.820631 (* 1 = 0.820631 loss)
I0817 04:21:17.023499 20404 sgd_solver.cpp:106] Iteration 10090, lr = 0.000592605
I0817 04:21:51.927492 20404 solver.cpp:228] Iteration 10100, loss = 0.820485
I0817 04:21:51.927664 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:21:51.927680 20404 solver.cpp:244]     Train net output #1: loss = 0.820485 (* 1 = 0.820485 loss)
I0817 04:21:51.927692 20404 sgd_solver.cpp:106] Iteration 10100, lr = 0.000592384
I0817 04:22:26.816316 20404 solver.cpp:228] Iteration 10110, loss = 0.820555
I0817 04:22:26.816401 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:22:26.816414 20404 solver.cpp:244]     Train net output #1: loss = 0.820555 (* 1 = 0.820555 loss)
I0817 04:22:26.816426 20404 sgd_solver.cpp:106] Iteration 10110, lr = 0.000592163
I0817 04:22:58.241168 20404 solver.cpp:337] Iteration 10120, Testing net (#0)
I0817 04:23:32.888320 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:23:32.888500 20404 solver.cpp:404]     Test net output #1: loss = 0.671383 (* 1 = 0.671383 loss)
I0817 04:23:36.370766 20404 solver.cpp:228] Iteration 10120, loss = 0.820038
I0817 04:23:36.370818 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 04:23:36.370832 20404 solver.cpp:244]     Train net output #1: loss = 0.820038 (* 1 = 0.820038 loss)
I0817 04:23:36.370844 20404 sgd_solver.cpp:106] Iteration 10120, lr = 0.000591942
I0817 04:24:11.255305 20404 solver.cpp:228] Iteration 10130, loss = 0.821239
I0817 04:24:11.255502 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:24:11.255519 20404 solver.cpp:244]     Train net output #1: loss = 0.821239 (* 1 = 0.821239 loss)
I0817 04:24:11.255532 20404 sgd_solver.cpp:106] Iteration 10130, lr = 0.000591721
I0817 04:24:46.130100 20404 solver.cpp:228] Iteration 10140, loss = 0.820413
I0817 04:24:46.130327 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:24:46.130344 20404 solver.cpp:244]     Train net output #1: loss = 0.820413 (* 1 = 0.820413 loss)
I0817 04:24:46.130357 20404 sgd_solver.cpp:106] Iteration 10140, lr = 0.000591501
I0817 04:25:20.987293 20404 solver.cpp:228] Iteration 10150, loss = 0.820109
I0817 04:25:20.987485 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:25:20.987504 20404 solver.cpp:244]     Train net output #1: loss = 0.820109 (* 1 = 0.820109 loss)
I0817 04:25:20.987520 20404 sgd_solver.cpp:106] Iteration 10150, lr = 0.000591281
I0817 04:25:52.398675 20404 solver.cpp:337] Iteration 10160, Testing net (#0)
I0817 04:26:27.072973 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:26:27.073148 20404 solver.cpp:404]     Test net output #1: loss = 0.671123 (* 1 = 0.671123 loss)
I0817 04:26:30.540895 20404 solver.cpp:228] Iteration 10160, loss = 0.820373
I0817 04:26:30.540947 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:26:30.540961 20404 solver.cpp:244]     Train net output #1: loss = 0.820373 (* 1 = 0.820373 loss)
I0817 04:26:30.540972 20404 sgd_solver.cpp:106] Iteration 10160, lr = 0.000591061
I0817 04:27:05.420219 20404 solver.cpp:228] Iteration 10170, loss = 0.820384
I0817 04:27:05.420395 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:27:05.420410 20404 solver.cpp:244]     Train net output #1: loss = 0.820384 (* 1 = 0.820384 loss)
I0817 04:27:05.420423 20404 sgd_solver.cpp:106] Iteration 10170, lr = 0.000590841
I0817 04:27:40.307974 20404 solver.cpp:228] Iteration 10180, loss = 0.820392
I0817 04:27:40.308151 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:27:40.308166 20404 solver.cpp:244]     Train net output #1: loss = 0.820392 (* 1 = 0.820392 loss)
I0817 04:27:40.308177 20404 sgd_solver.cpp:106] Iteration 10180, lr = 0.000590621
I0817 04:28:15.198436 20404 solver.cpp:228] Iteration 10190, loss = 0.820075
I0817 04:28:15.198619 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:28:15.198635 20404 solver.cpp:244]     Train net output #1: loss = 0.820075 (* 1 = 0.820075 loss)
I0817 04:28:15.198647 20404 sgd_solver.cpp:106] Iteration 10190, lr = 0.000590402
I0817 04:28:46.611126 20404 solver.cpp:337] Iteration 10200, Testing net (#0)
I0817 04:29:21.251008 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:29:21.251168 20404 solver.cpp:404]     Test net output #1: loss = 0.671792 (* 1 = 0.671792 loss)
I0817 04:29:24.730860 20404 solver.cpp:228] Iteration 10200, loss = 0.820228
I0817 04:29:24.730912 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:29:24.730926 20404 solver.cpp:244]     Train net output #1: loss = 0.820228 (* 1 = 0.820228 loss)
I0817 04:29:24.730937 20404 sgd_solver.cpp:106] Iteration 10200, lr = 0.000590183
I0817 04:29:59.589141 20404 solver.cpp:228] Iteration 10210, loss = 0.820332
I0817 04:29:59.589313 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:29:59.589329 20404 solver.cpp:244]     Train net output #1: loss = 0.820332 (* 1 = 0.820332 loss)
I0817 04:29:59.589341 20404 sgd_solver.cpp:106] Iteration 10210, lr = 0.000589964
I0817 04:30:34.474156 20404 solver.cpp:228] Iteration 10220, loss = 0.820638
I0817 04:30:34.474294 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:30:34.474310 20404 solver.cpp:244]     Train net output #1: loss = 0.820638 (* 1 = 0.820638 loss)
I0817 04:30:34.474323 20404 sgd_solver.cpp:106] Iteration 10220, lr = 0.000589745
I0817 04:31:09.353842 20404 solver.cpp:228] Iteration 10230, loss = 0.820397
I0817 04:31:09.354053 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:31:09.354068 20404 solver.cpp:244]     Train net output #1: loss = 0.820397 (* 1 = 0.820397 loss)
I0817 04:31:09.354101 20404 sgd_solver.cpp:106] Iteration 10230, lr = 0.000589526
I0817 04:31:40.764447 20404 solver.cpp:337] Iteration 10240, Testing net (#0)
I0817 04:32:15.396750 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:32:15.396922 20404 solver.cpp:404]     Test net output #1: loss = 0.671386 (* 1 = 0.671386 loss)
I0817 04:32:18.866739 20404 solver.cpp:228] Iteration 10240, loss = 0.820042
I0817 04:32:18.866791 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 04:32:18.866804 20404 solver.cpp:244]     Train net output #1: loss = 0.820042 (* 1 = 0.820042 loss)
I0817 04:32:18.866816 20404 sgd_solver.cpp:106] Iteration 10240, lr = 0.000589308
I0817 04:32:53.775339 20404 solver.cpp:228] Iteration 10250, loss = 0.820386
I0817 04:32:53.775518 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:32:53.775534 20404 solver.cpp:244]     Train net output #1: loss = 0.820386 (* 1 = 0.820386 loss)
I0817 04:32:53.775547 20404 sgd_solver.cpp:106] Iteration 10250, lr = 0.000589089
I0817 04:33:28.687160 20404 solver.cpp:228] Iteration 10260, loss = 0.820958
I0817 04:33:28.687263 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:33:28.687285 20404 solver.cpp:244]     Train net output #1: loss = 0.820958 (* 1 = 0.820958 loss)
I0817 04:33:28.687297 20404 sgd_solver.cpp:106] Iteration 10260, lr = 0.000588871
I0817 04:34:03.591886 20404 solver.cpp:228] Iteration 10270, loss = 0.820367
I0817 04:34:03.591986 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:34:03.592000 20404 solver.cpp:244]     Train net output #1: loss = 0.820367 (* 1 = 0.820367 loss)
I0817 04:34:03.592012 20404 sgd_solver.cpp:106] Iteration 10270, lr = 0.000588653
I0817 04:34:34.995640 20404 solver.cpp:337] Iteration 10280, Testing net (#0)
I0817 04:35:09.667716 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:35:09.667876 20404 solver.cpp:404]     Test net output #1: loss = 0.670521 (* 1 = 0.670521 loss)
I0817 04:35:13.146724 20404 solver.cpp:228] Iteration 10280, loss = 0.821136
I0817 04:35:13.146775 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:35:13.146790 20404 solver.cpp:244]     Train net output #1: loss = 0.821136 (* 1 = 0.821136 loss)
I0817 04:35:13.146801 20404 sgd_solver.cpp:106] Iteration 10280, lr = 0.000588436
I0817 04:35:48.036526 20404 solver.cpp:228] Iteration 10290, loss = 0.820157
I0817 04:35:48.036710 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:35:48.036725 20404 solver.cpp:244]     Train net output #1: loss = 0.820157 (* 1 = 0.820157 loss)
I0817 04:35:48.036737 20404 sgd_solver.cpp:106] Iteration 10290, lr = 0.000588218
I0817 04:36:22.921741 20404 solver.cpp:228] Iteration 10300, loss = 0.820335
I0817 04:36:22.921922 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:36:22.921937 20404 solver.cpp:244]     Train net output #1: loss = 0.820335 (* 1 = 0.820335 loss)
I0817 04:36:22.921949 20404 sgd_solver.cpp:106] Iteration 10300, lr = 0.000588001
I0817 04:36:57.813660 20404 solver.cpp:228] Iteration 10310, loss = 0.82088
I0817 04:36:57.813834 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:36:57.813849 20404 solver.cpp:244]     Train net output #1: loss = 0.82088 (* 1 = 0.82088 loss)
I0817 04:36:57.813861 20404 sgd_solver.cpp:106] Iteration 10310, lr = 0.000587784
I0817 04:37:29.239001 20404 solver.cpp:337] Iteration 10320, Testing net (#0)
I0817 04:38:03.879891 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:38:03.880066 20404 solver.cpp:404]     Test net output #1: loss = 0.671613 (* 1 = 0.671613 loss)
I0817 04:38:07.356621 20404 solver.cpp:228] Iteration 10320, loss = 0.820121
I0817 04:38:07.356681 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:38:07.356695 20404 solver.cpp:244]     Train net output #1: loss = 0.820121 (* 1 = 0.820121 loss)
I0817 04:38:07.356708 20404 sgd_solver.cpp:106] Iteration 10320, lr = 0.000587567
I0817 04:38:42.256237 20404 solver.cpp:228] Iteration 10330, loss = 0.821021
I0817 04:38:42.256438 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:38:42.256453 20404 solver.cpp:244]     Train net output #1: loss = 0.821021 (* 1 = 0.821021 loss)
I0817 04:38:42.256466 20404 sgd_solver.cpp:106] Iteration 10330, lr = 0.00058735
I0817 04:39:17.168007 20404 solver.cpp:228] Iteration 10340, loss = 0.82066
I0817 04:39:17.168184 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:39:17.168200 20404 solver.cpp:244]     Train net output #1: loss = 0.82066 (* 1 = 0.82066 loss)
I0817 04:39:17.168211 20404 sgd_solver.cpp:106] Iteration 10340, lr = 0.000587133
I0817 04:39:52.050995 20404 solver.cpp:228] Iteration 10350, loss = 0.820739
I0817 04:39:52.051093 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:39:52.051108 20404 solver.cpp:244]     Train net output #1: loss = 0.820739 (* 1 = 0.820739 loss)
I0817 04:39:52.051120 20404 sgd_solver.cpp:106] Iteration 10350, lr = 0.000586917
I0817 04:40:23.467447 20404 solver.cpp:337] Iteration 10360, Testing net (#0)
I0817 04:40:58.135565 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:40:58.135660 20404 solver.cpp:404]     Test net output #1: loss = 0.670657 (* 1 = 0.670657 loss)
I0817 04:41:01.618537 20404 solver.cpp:228] Iteration 10360, loss = 0.820973
I0817 04:41:01.618588 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:41:01.618602 20404 solver.cpp:244]     Train net output #1: loss = 0.820973 (* 1 = 0.820973 loss)
I0817 04:41:01.618614 20404 sgd_solver.cpp:106] Iteration 10360, lr = 0.000586701
I0817 04:41:36.523964 20404 solver.cpp:228] Iteration 10370, loss = 0.820791
I0817 04:41:36.524132 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:41:36.524152 20404 solver.cpp:244]     Train net output #1: loss = 0.820791 (* 1 = 0.820791 loss)
I0817 04:41:36.524168 20404 sgd_solver.cpp:106] Iteration 10370, lr = 0.000586485
I0817 04:42:11.419263 20404 solver.cpp:228] Iteration 10380, loss = 0.821592
I0817 04:42:11.419448 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:42:11.419467 20404 solver.cpp:244]     Train net output #1: loss = 0.821592 (* 1 = 0.821592 loss)
I0817 04:42:11.419482 20404 sgd_solver.cpp:106] Iteration 10380, lr = 0.000586269
I0817 04:42:46.287358 20404 solver.cpp:228] Iteration 10390, loss = 0.820204
I0817 04:42:46.287458 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:42:46.287475 20404 solver.cpp:244]     Train net output #1: loss = 0.820204 (* 1 = 0.820204 loss)
I0817 04:42:46.287488 20404 sgd_solver.cpp:106] Iteration 10390, lr = 0.000586053
I0817 04:43:17.698889 20404 solver.cpp:337] Iteration 10400, Testing net (#0)
I0817 04:43:52.362802 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:43:52.362993 20404 solver.cpp:404]     Test net output #1: loss = 0.671043 (* 1 = 0.671043 loss)
I0817 04:43:55.841390 20404 solver.cpp:228] Iteration 10400, loss = 0.820478
I0817 04:43:55.841442 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:43:55.841456 20404 solver.cpp:244]     Train net output #1: loss = 0.820478 (* 1 = 0.820478 loss)
I0817 04:43:55.841469 20404 sgd_solver.cpp:106] Iteration 10400, lr = 0.000585838
I0817 04:44:30.742331 20404 solver.cpp:228] Iteration 10410, loss = 0.820869
I0817 04:44:30.742516 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:44:30.742532 20404 solver.cpp:244]     Train net output #1: loss = 0.820869 (* 1 = 0.820869 loss)
I0817 04:44:30.742543 20404 sgd_solver.cpp:106] Iteration 10410, lr = 0.000585623
I0817 04:45:05.637447 20404 solver.cpp:228] Iteration 10420, loss = 0.821014
I0817 04:45:05.637629 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:45:05.637645 20404 solver.cpp:244]     Train net output #1: loss = 0.821014 (* 1 = 0.821014 loss)
I0817 04:45:05.637657 20404 sgd_solver.cpp:106] Iteration 10420, lr = 0.000585407
I0817 04:45:40.541774 20404 solver.cpp:228] Iteration 10430, loss = 0.82002
I0817 04:45:40.541895 20404 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0817 04:45:40.541911 20404 solver.cpp:244]     Train net output #1: loss = 0.82002 (* 1 = 0.82002 loss)
I0817 04:45:40.541923 20404 sgd_solver.cpp:106] Iteration 10430, lr = 0.000585193
I0817 04:46:11.956480 20404 solver.cpp:337] Iteration 10440, Testing net (#0)
I0817 04:46:46.579629 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:46:46.579733 20404 solver.cpp:404]     Test net output #1: loss = 0.671065 (* 1 = 0.671065 loss)
I0817 04:46:50.058739 20404 solver.cpp:228] Iteration 10440, loss = 0.820451
I0817 04:46:50.058791 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:46:50.058805 20404 solver.cpp:244]     Train net output #1: loss = 0.820451 (* 1 = 0.820451 loss)
I0817 04:46:50.058817 20404 sgd_solver.cpp:106] Iteration 10440, lr = 0.000584978
I0817 04:47:24.935395 20404 solver.cpp:228] Iteration 10450, loss = 0.820628
I0817 04:47:24.935571 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:47:24.935587 20404 solver.cpp:244]     Train net output #1: loss = 0.820628 (* 1 = 0.820628 loss)
I0817 04:47:24.935600 20404 sgd_solver.cpp:106] Iteration 10450, lr = 0.000584763
I0817 04:47:59.818400 20404 solver.cpp:228] Iteration 10460, loss = 0.820191
I0817 04:47:59.818579 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:47:59.818596 20404 solver.cpp:244]     Train net output #1: loss = 0.820191 (* 1 = 0.820191 loss)
I0817 04:47:59.818608 20404 sgd_solver.cpp:106] Iteration 10460, lr = 0.000584549
I0817 04:48:34.712507 20404 solver.cpp:228] Iteration 10470, loss = 0.821228
I0817 04:48:34.712690 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:48:34.712705 20404 solver.cpp:244]     Train net output #1: loss = 0.821228 (* 1 = 0.821228 loss)
I0817 04:48:34.712718 20404 sgd_solver.cpp:106] Iteration 10470, lr = 0.000584335
I0817 04:49:06.147845 20404 solver.cpp:337] Iteration 10480, Testing net (#0)
I0817 04:49:40.804858 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:49:40.805034 20404 solver.cpp:404]     Test net output #1: loss = 0.671187 (* 1 = 0.671187 loss)
I0817 04:49:44.281204 20404 solver.cpp:228] Iteration 10480, loss = 0.820299
I0817 04:49:44.281255 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:49:44.281270 20404 solver.cpp:244]     Train net output #1: loss = 0.820299 (* 1 = 0.820299 loss)
I0817 04:49:44.281282 20404 sgd_solver.cpp:106] Iteration 10480, lr = 0.000584121
I0817 04:50:19.173388 20404 solver.cpp:228] Iteration 10490, loss = 0.820495
I0817 04:50:19.173576 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:50:19.173595 20404 solver.cpp:244]     Train net output #1: loss = 0.820495 (* 1 = 0.820495 loss)
I0817 04:50:19.173611 20404 sgd_solver.cpp:106] Iteration 10490, lr = 0.000583907
I0817 04:50:54.036347 20404 solver.cpp:228] Iteration 10500, loss = 0.82064
I0817 04:50:54.036528 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:50:54.036548 20404 solver.cpp:244]     Train net output #1: loss = 0.82064 (* 1 = 0.82064 loss)
I0817 04:50:54.036563 20404 sgd_solver.cpp:106] Iteration 10500, lr = 0.000583693
I0817 04:51:28.945953 20404 solver.cpp:228] Iteration 10510, loss = 0.820229
I0817 04:51:28.946064 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:51:28.946079 20404 solver.cpp:244]     Train net output #1: loss = 0.820229 (* 1 = 0.820229 loss)
I0817 04:51:28.946091 20404 sgd_solver.cpp:106] Iteration 10510, lr = 0.00058348
I0817 04:52:00.358244 20404 solver.cpp:337] Iteration 10520, Testing net (#0)
I0817 04:52:35.018034 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:52:35.018216 20404 solver.cpp:404]     Test net output #1: loss = 0.671162 (* 1 = 0.671162 loss)
I0817 04:52:38.492560 20404 solver.cpp:228] Iteration 10520, loss = 0.820329
I0817 04:52:38.492611 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:52:38.492625 20404 solver.cpp:244]     Train net output #1: loss = 0.820329 (* 1 = 0.820329 loss)
I0817 04:52:38.492637 20404 sgd_solver.cpp:106] Iteration 10520, lr = 0.000583266
I0817 04:53:13.384544 20404 solver.cpp:228] Iteration 10530, loss = 0.820023
I0817 04:53:13.384760 20404 solver.cpp:244]     Train net output #0: accuracy = 0.79
I0817 04:53:13.384778 20404 solver.cpp:244]     Train net output #1: loss = 0.820023 (* 1 = 0.820023 loss)
I0817 04:53:13.384789 20404 sgd_solver.cpp:106] Iteration 10530, lr = 0.000583053
I0817 04:53:48.275046 20404 solver.cpp:228] Iteration 10540, loss = 0.820052
I0817 04:53:48.275230 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:53:48.275245 20404 solver.cpp:244]     Train net output #1: loss = 0.820052 (* 1 = 0.820052 loss)
I0817 04:53:48.275259 20404 sgd_solver.cpp:106] Iteration 10540, lr = 0.00058284
I0817 04:54:23.153359 20404 solver.cpp:228] Iteration 10550, loss = 0.820102
I0817 04:54:23.153455 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:54:23.153470 20404 solver.cpp:244]     Train net output #1: loss = 0.820102 (* 1 = 0.820102 loss)
I0817 04:54:23.153482 20404 sgd_solver.cpp:106] Iteration 10550, lr = 0.000582628
I0817 04:54:54.568037 20404 solver.cpp:337] Iteration 10560, Testing net (#0)
I0817 04:55:29.214475 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:55:29.214646 20404 solver.cpp:404]     Test net output #1: loss = 0.671354 (* 1 = 0.671354 loss)
I0817 04:55:32.688110 20404 solver.cpp:228] Iteration 10560, loss = 0.820084
I0817 04:55:32.688161 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:55:32.688175 20404 solver.cpp:244]     Train net output #1: loss = 0.820084 (* 1 = 0.820084 loss)
I0817 04:55:32.688186 20404 sgd_solver.cpp:106] Iteration 10560, lr = 0.000582415
I0817 04:56:07.587469 20404 solver.cpp:228] Iteration 10570, loss = 0.820168
I0817 04:56:07.587560 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:56:07.587575 20404 solver.cpp:244]     Train net output #1: loss = 0.820168 (* 1 = 0.820168 loss)
I0817 04:56:07.587589 20404 sgd_solver.cpp:106] Iteration 10570, lr = 0.000582203
I0817 04:56:42.471096 20404 solver.cpp:228] Iteration 10580, loss = 0.820107
I0817 04:56:42.471287 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 04:56:42.471303 20404 solver.cpp:244]     Train net output #1: loss = 0.820107 (* 1 = 0.820107 loss)
I0817 04:56:42.471315 20404 sgd_solver.cpp:106] Iteration 10580, lr = 0.000581991
I0817 04:57:17.363147 20404 solver.cpp:228] Iteration 10590, loss = 0.820343
I0817 04:57:17.363335 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:57:17.363351 20404 solver.cpp:244]     Train net output #1: loss = 0.820343 (* 1 = 0.820343 loss)
I0817 04:57:17.363363 20404 sgd_solver.cpp:106] Iteration 10590, lr = 0.000581779
I0817 04:57:48.785780 20404 solver.cpp:337] Iteration 10600, Testing net (#0)
I0817 04:58:23.416821 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 04:58:23.417001 20404 solver.cpp:404]     Test net output #1: loss = 0.671652 (* 1 = 0.671652 loss)
I0817 04:58:26.895925 20404 solver.cpp:228] Iteration 10600, loss = 0.820144
I0817 04:58:26.895978 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:58:26.895992 20404 solver.cpp:244]     Train net output #1: loss = 0.820144 (* 1 = 0.820144 loss)
I0817 04:58:26.896004 20404 sgd_solver.cpp:106] Iteration 10600, lr = 0.000581567
I0817 04:59:01.792593 20404 solver.cpp:228] Iteration 10610, loss = 0.820375
I0817 04:59:01.792685 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:59:01.792700 20404 solver.cpp:244]     Train net output #1: loss = 0.820375 (* 1 = 0.820375 loss)
I0817 04:59:01.792711 20404 sgd_solver.cpp:106] Iteration 10610, lr = 0.000581355
I0817 04:59:36.661221 20404 solver.cpp:228] Iteration 10620, loss = 0.820363
I0817 04:59:36.661428 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 04:59:36.661443 20404 solver.cpp:244]     Train net output #1: loss = 0.820363 (* 1 = 0.820363 loss)
I0817 04:59:36.661455 20404 sgd_solver.cpp:106] Iteration 10620, lr = 0.000581144
I0817 05:00:11.543169 20404 solver.cpp:228] Iteration 10630, loss = 0.820112
I0817 05:00:11.543345 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:00:11.543361 20404 solver.cpp:244]     Train net output #1: loss = 0.820112 (* 1 = 0.820112 loss)
I0817 05:00:11.543373 20404 sgd_solver.cpp:106] Iteration 10630, lr = 0.000580932
I0817 05:00:42.946979 20404 solver.cpp:337] Iteration 10640, Testing net (#0)
I0817 05:01:17.594812 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:01:17.594976 20404 solver.cpp:404]     Test net output #1: loss = 0.67088 (* 1 = 0.67088 loss)
I0817 05:01:21.066612 20404 solver.cpp:228] Iteration 10640, loss = 0.820694
I0817 05:01:21.066665 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:01:21.066680 20404 solver.cpp:244]     Train net output #1: loss = 0.820694 (* 1 = 0.820694 loss)
I0817 05:01:21.066694 20404 sgd_solver.cpp:106] Iteration 10640, lr = 0.000580721
I0817 05:01:55.967778 20404 solver.cpp:228] Iteration 10650, loss = 0.820021
I0817 05:01:55.967864 20404 solver.cpp:244]     Train net output #0: accuracy = 0.8
I0817 05:01:55.967878 20404 solver.cpp:244]     Train net output #1: loss = 0.820021 (* 1 = 0.820021 loss)
I0817 05:01:55.967890 20404 sgd_solver.cpp:106] Iteration 10650, lr = 0.00058051
I0817 05:02:30.860363 20404 solver.cpp:228] Iteration 10660, loss = 0.820367
I0817 05:02:30.860532 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:02:30.860551 20404 solver.cpp:244]     Train net output #1: loss = 0.820367 (* 1 = 0.820367 loss)
I0817 05:02:30.860563 20404 sgd_solver.cpp:106] Iteration 10660, lr = 0.0005803
I0817 05:03:05.755923 20404 solver.cpp:228] Iteration 10670, loss = 0.820343
I0817 05:03:05.756094 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:03:05.756109 20404 solver.cpp:244]     Train net output #1: loss = 0.820343 (* 1 = 0.820343 loss)
I0817 05:03:05.756121 20404 sgd_solver.cpp:106] Iteration 10670, lr = 0.000580089
I0817 05:03:37.186722 20404 solver.cpp:337] Iteration 10680, Testing net (#0)
I0817 05:04:11.819401 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:04:11.819569 20404 solver.cpp:404]     Test net output #1: loss = 0.670794 (* 1 = 0.670794 loss)
I0817 05:04:15.300721 20404 solver.cpp:228] Iteration 10680, loss = 0.820807
I0817 05:04:15.300776 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:04:15.300789 20404 solver.cpp:244]     Train net output #1: loss = 0.820807 (* 1 = 0.820807 loss)
I0817 05:04:15.300802 20404 sgd_solver.cpp:106] Iteration 10680, lr = 0.000579879
I0817 05:04:50.182374 20404 solver.cpp:228] Iteration 10690, loss = 0.82002
I0817 05:04:50.182545 20404 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0817 05:04:50.182561 20404 solver.cpp:244]     Train net output #1: loss = 0.82002 (* 1 = 0.82002 loss)
I0817 05:04:50.182574 20404 sgd_solver.cpp:106] Iteration 10690, lr = 0.000579668
I0817 05:05:25.070631 20404 solver.cpp:228] Iteration 10700, loss = 0.820095
I0817 05:05:25.070806 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:05:25.070824 20404 solver.cpp:244]     Train net output #1: loss = 0.820095 (* 1 = 0.820095 loss)
I0817 05:05:25.070837 20404 sgd_solver.cpp:106] Iteration 10700, lr = 0.000579458
I0817 05:05:59.983481 20404 solver.cpp:228] Iteration 10710, loss = 0.820589
I0817 05:05:59.983659 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:05:59.983675 20404 solver.cpp:244]     Train net output #1: loss = 0.820589 (* 1 = 0.820589 loss)
I0817 05:05:59.983686 20404 sgd_solver.cpp:106] Iteration 10710, lr = 0.000579249
I0817 05:06:31.411375 20404 solver.cpp:337] Iteration 10720, Testing net (#0)
I0817 05:07:06.039233 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:07:06.039433 20404 solver.cpp:404]     Test net output #1: loss = 0.671874 (* 1 = 0.671874 loss)
I0817 05:07:09.517817 20404 solver.cpp:228] Iteration 10720, loss = 0.820262
I0817 05:07:09.517869 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:07:09.517884 20404 solver.cpp:244]     Train net output #1: loss = 0.820262 (* 1 = 0.820262 loss)
I0817 05:07:09.517895 20404 sgd_solver.cpp:106] Iteration 10720, lr = 0.000579039
I0817 05:07:44.418220 20404 solver.cpp:228] Iteration 10730, loss = 0.820072
I0817 05:07:44.418321 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:07:44.418335 20404 solver.cpp:244]     Train net output #1: loss = 0.820072 (* 1 = 0.820072 loss)
I0817 05:07:44.418349 20404 sgd_solver.cpp:106] Iteration 10730, lr = 0.000578829
I0817 05:08:19.313493 20404 solver.cpp:228] Iteration 10740, loss = 0.820154
I0817 05:08:19.313678 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:08:19.313693 20404 solver.cpp:244]     Train net output #1: loss = 0.820154 (* 1 = 0.820154 loss)
I0817 05:08:19.313704 20404 sgd_solver.cpp:106] Iteration 10740, lr = 0.00057862
I0817 05:08:54.206269 20404 solver.cpp:228] Iteration 10750, loss = 0.820253
I0817 05:08:54.206444 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:08:54.206459 20404 solver.cpp:244]     Train net output #1: loss = 0.820253 (* 1 = 0.820253 loss)
I0817 05:08:54.206472 20404 sgd_solver.cpp:106] Iteration 10750, lr = 0.000578411
I0817 05:09:25.603708 20404 solver.cpp:337] Iteration 10760, Testing net (#0)
I0817 05:10:00.231595 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:10:00.231770 20404 solver.cpp:404]     Test net output #1: loss = 0.671953 (* 1 = 0.671953 loss)
I0817 05:10:03.711802 20404 solver.cpp:228] Iteration 10760, loss = 0.820311
I0817 05:10:03.711855 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:10:03.711869 20404 solver.cpp:244]     Train net output #1: loss = 0.820311 (* 1 = 0.820311 loss)
I0817 05:10:03.711882 20404 sgd_solver.cpp:106] Iteration 10760, lr = 0.000578202
I0817 05:10:38.579592 20404 solver.cpp:228] Iteration 10770, loss = 0.820974
I0817 05:10:38.579772 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:10:38.579787 20404 solver.cpp:244]     Train net output #1: loss = 0.820974 (* 1 = 0.820974 loss)
I0817 05:10:38.579799 20404 sgd_solver.cpp:106] Iteration 10770, lr = 0.000577993
I0817 05:11:13.485940 20404 solver.cpp:228] Iteration 10780, loss = 0.820141
I0817 05:11:13.486109 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:11:13.486124 20404 solver.cpp:244]     Train net output #1: loss = 0.820141 (* 1 = 0.820141 loss)
I0817 05:11:13.486136 20404 sgd_solver.cpp:106] Iteration 10780, lr = 0.000577784
I0817 05:11:48.387358 20404 solver.cpp:228] Iteration 10790, loss = 0.820181
I0817 05:11:48.387536 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:11:48.387550 20404 solver.cpp:244]     Train net output #1: loss = 0.820181 (* 1 = 0.820181 loss)
I0817 05:11:48.387563 20404 sgd_solver.cpp:106] Iteration 10790, lr = 0.000577576
I0817 05:12:19.816519 20404 solver.cpp:337] Iteration 10800, Testing net (#0)
I0817 05:12:54.475013 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:12:54.475183 20404 solver.cpp:404]     Test net output #1: loss = 0.67081 (* 1 = 0.67081 loss)
I0817 05:12:57.953955 20404 solver.cpp:228] Iteration 10800, loss = 0.820786
I0817 05:12:57.954008 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:12:57.954022 20404 solver.cpp:244]     Train net output #1: loss = 0.820786 (* 1 = 0.820786 loss)
I0817 05:12:57.954035 20404 sgd_solver.cpp:106] Iteration 10800, lr = 0.000577368
I0817 05:13:32.827993 20404 solver.cpp:228] Iteration 10810, loss = 0.820747
I0817 05:13:32.828168 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:13:32.828183 20404 solver.cpp:244]     Train net output #1: loss = 0.820747 (* 1 = 0.820747 loss)
I0817 05:13:32.828196 20404 sgd_solver.cpp:106] Iteration 10810, lr = 0.00057716
I0817 05:14:07.717376 20404 solver.cpp:228] Iteration 10820, loss = 0.820124
I0817 05:14:07.717581 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:14:07.717597 20404 solver.cpp:244]     Train net output #1: loss = 0.820124 (* 1 = 0.820124 loss)
I0817 05:14:07.717609 20404 sgd_solver.cpp:106] Iteration 10820, lr = 0.000576952
I0817 05:14:42.617050 20404 solver.cpp:228] Iteration 10830, loss = 0.820029
I0817 05:14:42.617233 20404 solver.cpp:244]     Train net output #0: accuracy = 0.91
I0817 05:14:42.617249 20404 solver.cpp:244]     Train net output #1: loss = 0.820029 (* 1 = 0.820029 loss)
I0817 05:14:42.617260 20404 sgd_solver.cpp:106] Iteration 10830, lr = 0.000576744
I0817 05:15:14.031817 20404 solver.cpp:337] Iteration 10840, Testing net (#0)
I0817 05:15:48.678431 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:15:48.678611 20404 solver.cpp:404]     Test net output #1: loss = 0.671585 (* 1 = 0.671585 loss)
I0817 05:15:52.151248 20404 solver.cpp:228] Iteration 10840, loss = 0.820101
I0817 05:15:52.151295 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:15:52.151314 20404 solver.cpp:244]     Train net output #1: loss = 0.820101 (* 1 = 0.820101 loss)
I0817 05:15:52.151338 20404 sgd_solver.cpp:106] Iteration 10840, lr = 0.000576536
I0817 05:16:27.032490 20404 solver.cpp:228] Iteration 10850, loss = 0.821101
I0817 05:16:27.032680 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:16:27.032698 20404 solver.cpp:244]     Train net output #1: loss = 0.821101 (* 1 = 0.821101 loss)
I0817 05:16:27.032718 20404 sgd_solver.cpp:106] Iteration 10850, lr = 0.000576329
I0817 05:17:01.928740 20404 solver.cpp:228] Iteration 10860, loss = 0.820071
I0817 05:17:01.928829 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:17:01.928848 20404 solver.cpp:244]     Train net output #1: loss = 0.820071 (* 1 = 0.820071 loss)
I0817 05:17:01.928874 20404 sgd_solver.cpp:106] Iteration 10860, lr = 0.000576122
I0817 05:17:36.827685 20404 solver.cpp:228] Iteration 10870, loss = 0.820042
I0817 05:17:36.827870 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 05:17:36.827890 20404 solver.cpp:244]     Train net output #1: loss = 0.820042 (* 1 = 0.820042 loss)
I0817 05:17:36.827905 20404 sgd_solver.cpp:106] Iteration 10870, lr = 0.000575915
I0817 05:18:08.248857 20404 solver.cpp:337] Iteration 10880, Testing net (#0)
I0817 05:18:42.914610 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:18:42.914788 20404 solver.cpp:404]     Test net output #1: loss = 0.671438 (* 1 = 0.671438 loss)
I0817 05:18:46.389216 20404 solver.cpp:228] Iteration 10880, loss = 0.820025
I0817 05:18:46.389268 20404 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0817 05:18:46.389282 20404 solver.cpp:244]     Train net output #1: loss = 0.820025 (* 1 = 0.820025 loss)
I0817 05:18:46.389294 20404 sgd_solver.cpp:106] Iteration 10880, lr = 0.000575708
I0817 05:19:21.293920 20404 solver.cpp:228] Iteration 10890, loss = 0.82041
I0817 05:19:21.294093 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:19:21.294108 20404 solver.cpp:244]     Train net output #1: loss = 0.82041 (* 1 = 0.82041 loss)
I0817 05:19:21.294121 20404 sgd_solver.cpp:106] Iteration 10890, lr = 0.000575501
I0817 05:19:56.195541 20404 solver.cpp:228] Iteration 10900, loss = 0.820587
I0817 05:19:56.195626 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:19:56.195642 20404 solver.cpp:244]     Train net output #1: loss = 0.820587 (* 1 = 0.820587 loss)
I0817 05:19:56.195654 20404 sgd_solver.cpp:106] Iteration 10900, lr = 0.000575295
I0817 05:20:31.106937 20404 solver.cpp:228] Iteration 10910, loss = 0.820076
I0817 05:20:31.107111 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:20:31.107126 20404 solver.cpp:244]     Train net output #1: loss = 0.820076 (* 1 = 0.820076 loss)
I0817 05:20:31.107138 20404 sgd_solver.cpp:106] Iteration 10910, lr = 0.000575088
I0817 05:21:02.527892 20404 solver.cpp:337] Iteration 10920, Testing net (#0)
I0817 05:21:37.171593 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:21:37.171772 20404 solver.cpp:404]     Test net output #1: loss = 0.671613 (* 1 = 0.671613 loss)
I0817 05:21:40.650250 20404 solver.cpp:228] Iteration 10920, loss = 0.820117
I0817 05:21:40.650302 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:21:40.650316 20404 solver.cpp:244]     Train net output #1: loss = 0.820117 (* 1 = 0.820117 loss)
I0817 05:21:40.650328 20404 sgd_solver.cpp:106] Iteration 10920, lr = 0.000574882
I0817 05:22:15.556291 20404 solver.cpp:228] Iteration 10930, loss = 0.820732
I0817 05:22:15.556473 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:22:15.556488 20404 solver.cpp:244]     Train net output #1: loss = 0.820732 (* 1 = 0.820732 loss)
I0817 05:22:15.556500 20404 sgd_solver.cpp:106] Iteration 10930, lr = 0.000574676
I0817 05:22:50.443814 20404 solver.cpp:228] Iteration 10940, loss = 0.820753
I0817 05:22:50.443994 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:22:50.444010 20404 solver.cpp:244]     Train net output #1: loss = 0.820753 (* 1 = 0.820753 loss)
I0817 05:22:50.444023 20404 sgd_solver.cpp:106] Iteration 10940, lr = 0.00057447
I0817 05:23:25.354264 20404 solver.cpp:228] Iteration 10950, loss = 0.820494
I0817 05:23:25.354440 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:23:25.354455 20404 solver.cpp:244]     Train net output #1: loss = 0.820494 (* 1 = 0.820494 loss)
I0817 05:23:25.354468 20404 sgd_solver.cpp:106] Iteration 10950, lr = 0.000574265
I0817 05:23:56.765892 20404 solver.cpp:337] Iteration 10960, Testing net (#0)
I0817 05:24:31.410178 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:24:31.410341 20404 solver.cpp:404]     Test net output #1: loss = 0.671747 (* 1 = 0.671747 loss)
I0817 05:24:34.888695 20404 solver.cpp:228] Iteration 10960, loss = 0.820191
I0817 05:24:34.888746 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:24:34.888761 20404 solver.cpp:244]     Train net output #1: loss = 0.820191 (* 1 = 0.820191 loss)
I0817 05:24:34.888772 20404 sgd_solver.cpp:106] Iteration 10960, lr = 0.000574059
I0817 05:25:09.774065 20404 solver.cpp:228] Iteration 10970, loss = 0.820697
I0817 05:25:09.774240 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:25:09.774255 20404 solver.cpp:244]     Train net output #1: loss = 0.820697 (* 1 = 0.820697 loss)
I0817 05:25:09.774266 20404 sgd_solver.cpp:106] Iteration 10970, lr = 0.000573854
I0817 05:25:44.684629 20404 solver.cpp:228] Iteration 10980, loss = 0.820095
I0817 05:25:44.684806 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:25:44.684821 20404 solver.cpp:244]     Train net output #1: loss = 0.820095 (* 1 = 0.820095 loss)
I0817 05:25:44.684834 20404 sgd_solver.cpp:106] Iteration 10980, lr = 0.000573649
I0817 05:26:19.595008 20404 solver.cpp:228] Iteration 10990, loss = 0.820236
I0817 05:26:19.595188 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:26:19.595202 20404 solver.cpp:244]     Train net output #1: loss = 0.820236 (* 1 = 0.820236 loss)
I0817 05:26:19.595214 20404 sgd_solver.cpp:106] Iteration 10990, lr = 0.000573444
I0817 05:26:50.981439 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_11000.caffemodel
I0817 05:27:00.370389 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_11000.solverstate
I0817 05:27:02.391598 20404 solver.cpp:337] Iteration 11000, Testing net (#0)
I0817 05:27:37.049471 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:27:37.049641 20404 solver.cpp:404]     Test net output #1: loss = 0.671322 (* 1 = 0.671322 loss)
I0817 05:27:40.531323 20404 solver.cpp:228] Iteration 11000, loss = 0.820141
I0817 05:27:40.531373 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:27:40.531388 20404 solver.cpp:244]     Train net output #1: loss = 0.820141 (* 1 = 0.820141 loss)
I0817 05:27:40.531399 20404 sgd_solver.cpp:106] Iteration 11000, lr = 0.000573239
I0817 05:28:15.407829 20404 solver.cpp:228] Iteration 11010, loss = 0.820148
I0817 05:28:15.408051 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:28:15.408066 20404 solver.cpp:244]     Train net output #1: loss = 0.820148 (* 1 = 0.820148 loss)
I0817 05:28:15.408079 20404 sgd_solver.cpp:106] Iteration 11010, lr = 0.000573034
I0817 05:28:50.305497 20404 solver.cpp:228] Iteration 11020, loss = 0.820975
I0817 05:28:50.305678 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:28:50.305693 20404 solver.cpp:244]     Train net output #1: loss = 0.820975 (* 1 = 0.820975 loss)
I0817 05:28:50.305706 20404 sgd_solver.cpp:106] Iteration 11020, lr = 0.00057283
I0817 05:29:25.205730 20404 solver.cpp:228] Iteration 11030, loss = 0.82064
I0817 05:29:25.205902 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:29:25.205917 20404 solver.cpp:244]     Train net output #1: loss = 0.82064 (* 1 = 0.82064 loss)
I0817 05:29:25.205930 20404 sgd_solver.cpp:106] Iteration 11030, lr = 0.000572625
I0817 05:29:56.616760 20404 solver.cpp:337] Iteration 11040, Testing net (#0)
I0817 05:30:31.262163 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:30:31.262259 20404 solver.cpp:404]     Test net output #1: loss = 0.67086 (* 1 = 0.67086 loss)
I0817 05:30:34.738732 20404 solver.cpp:228] Iteration 11040, loss = 0.820718
I0817 05:30:34.738782 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:30:34.738797 20404 solver.cpp:244]     Train net output #1: loss = 0.820718 (* 1 = 0.820718 loss)
I0817 05:30:34.738808 20404 sgd_solver.cpp:106] Iteration 11040, lr = 0.000572421
I0817 05:31:09.648167 20404 solver.cpp:228] Iteration 11050, loss = 0.820947
I0817 05:31:09.648346 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:31:09.648362 20404 solver.cpp:244]     Train net output #1: loss = 0.820947 (* 1 = 0.820947 loss)
I0817 05:31:09.648375 20404 sgd_solver.cpp:106] Iteration 11050, lr = 0.000572217
I0817 05:31:44.540246 20404 solver.cpp:228] Iteration 11060, loss = 0.820715
I0817 05:31:44.540421 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:31:44.540436 20404 solver.cpp:244]     Train net output #1: loss = 0.820715 (* 1 = 0.820715 loss)
I0817 05:31:44.540448 20404 sgd_solver.cpp:106] Iteration 11060, lr = 0.000572013
I0817 05:32:19.434227 20404 solver.cpp:228] Iteration 11070, loss = 0.820137
I0817 05:32:19.434408 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:32:19.434423 20404 solver.cpp:244]     Train net output #1: loss = 0.820137 (* 1 = 0.820137 loss)
I0817 05:32:19.434435 20404 sgd_solver.cpp:106] Iteration 11070, lr = 0.00057181
I0817 05:32:50.828424 20404 solver.cpp:337] Iteration 11080, Testing net (#0)
I0817 05:33:25.488493 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:33:25.488664 20404 solver.cpp:404]     Test net output #1: loss = 0.671913 (* 1 = 0.671913 loss)
I0817 05:33:28.965119 20404 solver.cpp:228] Iteration 11080, loss = 0.820287
I0817 05:33:28.965172 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:33:28.965185 20404 solver.cpp:244]     Train net output #1: loss = 0.820287 (* 1 = 0.820287 loss)
I0817 05:33:28.965198 20404 sgd_solver.cpp:106] Iteration 11080, lr = 0.000571606
I0817 05:34:03.835191 20404 solver.cpp:228] Iteration 11090, loss = 0.820205
I0817 05:34:03.835368 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:34:03.835384 20404 solver.cpp:244]     Train net output #1: loss = 0.820205 (* 1 = 0.820205 loss)
I0817 05:34:03.835397 20404 sgd_solver.cpp:106] Iteration 11090, lr = 0.000571403
I0817 05:34:38.713320 20404 solver.cpp:228] Iteration 11100, loss = 0.82006
I0817 05:34:38.713493 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:34:38.713508 20404 solver.cpp:244]     Train net output #1: loss = 0.82006 (* 1 = 0.82006 loss)
I0817 05:34:38.713521 20404 sgd_solver.cpp:106] Iteration 11100, lr = 0.0005712
I0817 05:35:13.622570 20404 solver.cpp:228] Iteration 11110, loss = 0.820512
I0817 05:35:13.622789 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:35:13.622805 20404 solver.cpp:244]     Train net output #1: loss = 0.820512 (* 1 = 0.820512 loss)
I0817 05:35:13.622818 20404 sgd_solver.cpp:106] Iteration 11110, lr = 0.000570997
I0817 05:35:45.043514 20404 solver.cpp:337] Iteration 11120, Testing net (#0)
I0817 05:36:19.686399 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:36:19.686575 20404 solver.cpp:404]     Test net output #1: loss = 0.671422 (* 1 = 0.671422 loss)
I0817 05:36:23.165315 20404 solver.cpp:228] Iteration 11120, loss = 0.820022
I0817 05:36:23.165365 20404 solver.cpp:244]     Train net output #0: accuracy = 0.79
I0817 05:36:23.165380 20404 solver.cpp:244]     Train net output #1: loss = 0.820022 (* 1 = 0.820022 loss)
I0817 05:36:23.165391 20404 sgd_solver.cpp:106] Iteration 11120, lr = 0.000570794
I0817 05:36:58.045815 20404 solver.cpp:228] Iteration 11130, loss = 0.820521
I0817 05:36:58.045980 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:36:58.045996 20404 solver.cpp:244]     Train net output #1: loss = 0.820521 (* 1 = 0.820521 loss)
I0817 05:36:58.046008 20404 sgd_solver.cpp:106] Iteration 11130, lr = 0.000570592
I0817 05:37:32.938582 20404 solver.cpp:228] Iteration 11140, loss = 0.820103
I0817 05:37:32.938768 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:37:32.938784 20404 solver.cpp:244]     Train net output #1: loss = 0.820103 (* 1 = 0.820103 loss)
I0817 05:37:32.938796 20404 sgd_solver.cpp:106] Iteration 11140, lr = 0.000570389
I0817 05:38:07.846575 20404 solver.cpp:228] Iteration 11150, loss = 0.820443
I0817 05:38:07.846758 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:38:07.846774 20404 solver.cpp:244]     Train net output #1: loss = 0.820443 (* 1 = 0.820443 loss)
I0817 05:38:07.846786 20404 sgd_solver.cpp:106] Iteration 11150, lr = 0.000570187
I0817 05:38:39.283869 20404 solver.cpp:337] Iteration 11160, Testing net (#0)
I0817 05:39:13.926225 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:39:13.926394 20404 solver.cpp:404]     Test net output #1: loss = 0.671055 (* 1 = 0.671055 loss)
I0817 05:39:17.401617 20404 solver.cpp:228] Iteration 11160, loss = 0.820473
I0817 05:39:17.401669 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:39:17.401684 20404 solver.cpp:244]     Train net output #1: loss = 0.820473 (* 1 = 0.820473 loss)
I0817 05:39:17.401695 20404 sgd_solver.cpp:106] Iteration 11160, lr = 0.000569985
I0817 05:39:52.275547 20404 solver.cpp:228] Iteration 11170, loss = 0.82004
I0817 05:39:52.275719 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:39:52.275734 20404 solver.cpp:244]     Train net output #1: loss = 0.82004 (* 1 = 0.82004 loss)
I0817 05:39:52.275746 20404 sgd_solver.cpp:106] Iteration 11170, lr = 0.000569783
I0817 05:40:27.145650 20404 solver.cpp:228] Iteration 11180, loss = 0.820588
I0817 05:40:27.145805 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:40:27.145838 20404 solver.cpp:244]     Train net output #1: loss = 0.820588 (* 1 = 0.820588 loss)
I0817 05:40:27.145859 20404 sgd_solver.cpp:106] Iteration 11180, lr = 0.000569581
I0817 05:41:02.042768 20404 solver.cpp:228] Iteration 11190, loss = 0.82009
I0817 05:41:02.042940 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:41:02.042958 20404 solver.cpp:244]     Train net output #1: loss = 0.82009 (* 1 = 0.82009 loss)
I0817 05:41:02.042969 20404 sgd_solver.cpp:106] Iteration 11190, lr = 0.000569379
I0817 05:41:33.448828 20404 solver.cpp:337] Iteration 11200, Testing net (#0)
I0817 05:42:08.078526 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:42:08.078697 20404 solver.cpp:404]     Test net output #1: loss = 0.671672 (* 1 = 0.671672 loss)
I0817 05:42:11.556967 20404 solver.cpp:228] Iteration 11200, loss = 0.820149
I0817 05:42:11.557020 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:42:11.557034 20404 solver.cpp:244]     Train net output #1: loss = 0.820149 (* 1 = 0.820149 loss)
I0817 05:42:11.557047 20404 sgd_solver.cpp:106] Iteration 11200, lr = 0.000569178
I0817 05:42:46.441689 20404 solver.cpp:228] Iteration 11210, loss = 0.820605
I0817 05:42:46.441905 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:42:46.441921 20404 solver.cpp:244]     Train net output #1: loss = 0.820605 (* 1 = 0.820605 loss)
I0817 05:42:46.441936 20404 sgd_solver.cpp:106] Iteration 11210, lr = 0.000568977
I0817 05:43:21.333139 20404 solver.cpp:228] Iteration 11220, loss = 0.820059
I0817 05:43:21.333325 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:43:21.333343 20404 solver.cpp:244]     Train net output #1: loss = 0.820059 (* 1 = 0.820059 loss)
I0817 05:43:21.333358 20404 sgd_solver.cpp:106] Iteration 11220, lr = 0.000568776
I0817 05:43:56.219606 20404 solver.cpp:228] Iteration 11230, loss = 0.820142
I0817 05:43:56.219781 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:43:56.219800 20404 solver.cpp:244]     Train net output #1: loss = 0.820142 (* 1 = 0.820142 loss)
I0817 05:43:56.219815 20404 sgd_solver.cpp:106] Iteration 11230, lr = 0.000568575
I0817 05:44:27.630580 20404 solver.cpp:337] Iteration 11240, Testing net (#0)
I0817 05:45:02.264660 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:45:02.264829 20404 solver.cpp:404]     Test net output #1: loss = 0.671875 (* 1 = 0.671875 loss)
I0817 05:45:05.741493 20404 solver.cpp:228] Iteration 11240, loss = 0.820265
I0817 05:45:05.741536 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:45:05.741554 20404 solver.cpp:244]     Train net output #1: loss = 0.820265 (* 1 = 0.820265 loss)
I0817 05:45:05.741578 20404 sgd_solver.cpp:106] Iteration 11240, lr = 0.000568374
I0817 05:45:40.594514 20404 solver.cpp:228] Iteration 11250, loss = 0.820639
I0817 05:45:40.594602 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:45:40.594621 20404 solver.cpp:244]     Train net output #1: loss = 0.820639 (* 1 = 0.820639 loss)
I0817 05:45:40.594645 20404 sgd_solver.cpp:106] Iteration 11250, lr = 0.000568173
I0817 05:46:15.488237 20404 solver.cpp:228] Iteration 11260, loss = 0.82031
I0817 05:46:15.488343 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:46:15.488361 20404 solver.cpp:244]     Train net output #1: loss = 0.82031 (* 1 = 0.82031 loss)
I0817 05:46:15.488375 20404 sgd_solver.cpp:106] Iteration 11260, lr = 0.000567973
I0817 05:46:50.359782 20404 solver.cpp:228] Iteration 11270, loss = 0.820156
I0817 05:46:50.359962 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:46:50.359980 20404 solver.cpp:244]     Train net output #1: loss = 0.820156 (* 1 = 0.820156 loss)
I0817 05:46:50.359998 20404 sgd_solver.cpp:106] Iteration 11270, lr = 0.000567773
I0817 05:47:21.769129 20404 solver.cpp:337] Iteration 11280, Testing net (#0)
I0817 05:47:56.420683 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:47:56.420856 20404 solver.cpp:404]     Test net output #1: loss = 0.67151 (* 1 = 0.67151 loss)
I0817 05:47:59.899915 20404 solver.cpp:228] Iteration 11280, loss = 0.820062
I0817 05:47:59.899967 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:47:59.899981 20404 solver.cpp:244]     Train net output #1: loss = 0.820062 (* 1 = 0.820062 loss)
I0817 05:47:59.899992 20404 sgd_solver.cpp:106] Iteration 11280, lr = 0.000567572
I0817 05:48:34.802520 20404 solver.cpp:228] Iteration 11290, loss = 0.820264
I0817 05:48:34.802697 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:48:34.802717 20404 solver.cpp:244]     Train net output #1: loss = 0.820264 (* 1 = 0.820264 loss)
I0817 05:48:34.802729 20404 sgd_solver.cpp:106] Iteration 11290, lr = 0.000567372
I0817 05:49:09.703440 20404 solver.cpp:228] Iteration 11300, loss = 0.820828
I0817 05:49:09.703616 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:49:09.703632 20404 solver.cpp:244]     Train net output #1: loss = 0.820828 (* 1 = 0.820828 loss)
I0817 05:49:09.703644 20404 sgd_solver.cpp:106] Iteration 11300, lr = 0.000567173
I0817 05:49:44.585110 20404 solver.cpp:228] Iteration 11310, loss = 0.820074
I0817 05:49:44.585320 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:49:44.585336 20404 solver.cpp:244]     Train net output #1: loss = 0.820074 (* 1 = 0.820074 loss)
I0817 05:49:44.585348 20404 sgd_solver.cpp:106] Iteration 11310, lr = 0.000566973
I0817 05:50:16.007266 20404 solver.cpp:337] Iteration 11320, Testing net (#0)
I0817 05:50:50.662466 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:50:50.662642 20404 solver.cpp:404]     Test net output #1: loss = 0.671761 (* 1 = 0.671761 loss)
I0817 05:50:54.136829 20404 solver.cpp:228] Iteration 11320, loss = 0.820198
I0817 05:50:54.136873 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:50:54.136890 20404 solver.cpp:244]     Train net output #1: loss = 0.820198 (* 1 = 0.820198 loss)
I0817 05:50:54.136904 20404 sgd_solver.cpp:106] Iteration 11320, lr = 0.000566774
I0817 05:51:29.009253 20404 solver.cpp:228] Iteration 11330, loss = 0.820197
I0817 05:51:29.009433 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:51:29.009452 20404 solver.cpp:244]     Train net output #1: loss = 0.820197 (* 1 = 0.820197 loss)
I0817 05:51:29.009465 20404 sgd_solver.cpp:106] Iteration 11330, lr = 0.000566574
I0817 05:52:03.903489 20404 solver.cpp:228] Iteration 11340, loss = 0.820224
I0817 05:52:03.903659 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:52:03.903676 20404 solver.cpp:244]     Train net output #1: loss = 0.820224 (* 1 = 0.820224 loss)
I0817 05:52:03.903687 20404 sgd_solver.cpp:106] Iteration 11340, lr = 0.000566375
I0817 05:52:38.773181 20404 solver.cpp:228] Iteration 11350, loss = 0.820056
I0817 05:52:38.773368 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:52:38.773383 20404 solver.cpp:244]     Train net output #1: loss = 0.820056 (* 1 = 0.820056 loss)
I0817 05:52:38.773396 20404 sgd_solver.cpp:106] Iteration 11350, lr = 0.000566176
I0817 05:53:10.203464 20404 solver.cpp:337] Iteration 11360, Testing net (#0)
I0817 05:53:44.847894 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:53:44.848074 20404 solver.cpp:404]     Test net output #1: loss = 0.671622 (* 1 = 0.671622 loss)
I0817 05:53:48.315361 20404 solver.cpp:228] Iteration 11360, loss = 0.820125
I0817 05:53:48.315417 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:53:48.315430 20404 solver.cpp:244]     Train net output #1: loss = 0.820125 (* 1 = 0.820125 loss)
I0817 05:53:48.315441 20404 sgd_solver.cpp:106] Iteration 11360, lr = 0.000565977
I0817 05:54:23.179121 20404 solver.cpp:228] Iteration 11370, loss = 0.82013
I0817 05:54:23.179314 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:54:23.179333 20404 solver.cpp:244]     Train net output #1: loss = 0.82013 (* 1 = 0.82013 loss)
I0817 05:54:23.179345 20404 sgd_solver.cpp:106] Iteration 11370, lr = 0.000565779
I0817 05:54:58.075677 20404 solver.cpp:228] Iteration 11380, loss = 0.820462
I0817 05:54:58.075857 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:54:58.075873 20404 solver.cpp:244]     Train net output #1: loss = 0.820462 (* 1 = 0.820462 loss)
I0817 05:54:58.075886 20404 sgd_solver.cpp:106] Iteration 11380, lr = 0.00056558
I0817 05:55:32.961701 20404 solver.cpp:228] Iteration 11390, loss = 0.820113
I0817 05:55:32.961833 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:55:32.961849 20404 solver.cpp:244]     Train net output #1: loss = 0.820113 (* 1 = 0.820113 loss)
I0817 05:55:32.961861 20404 sgd_solver.cpp:106] Iteration 11390, lr = 0.000565382
I0817 05:56:04.389284 20404 solver.cpp:337] Iteration 11400, Testing net (#0)
I0817 05:56:39.045971 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:56:39.046145 20404 solver.cpp:404]     Test net output #1: loss = 0.670581 (* 1 = 0.670581 loss)
I0817 05:56:42.528225 20404 solver.cpp:228] Iteration 11400, loss = 0.821084
I0817 05:56:42.528275 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:56:42.528290 20404 solver.cpp:244]     Train net output #1: loss = 0.821084 (* 1 = 0.821084 loss)
I0817 05:56:42.528301 20404 sgd_solver.cpp:106] Iteration 11400, lr = 0.000565184
I0817 05:57:17.402848 20404 solver.cpp:228] Iteration 11410, loss = 0.820084
I0817 05:57:17.403067 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 05:57:17.403086 20404 solver.cpp:244]     Train net output #1: loss = 0.820084 (* 1 = 0.820084 loss)
I0817 05:57:17.403097 20404 sgd_solver.cpp:106] Iteration 11410, lr = 0.000564986
I0817 05:57:52.294948 20404 solver.cpp:228] Iteration 11420, loss = 0.820254
I0817 05:57:52.295125 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:57:52.295140 20404 solver.cpp:244]     Train net output #1: loss = 0.820254 (* 1 = 0.820254 loss)
I0817 05:57:52.295151 20404 sgd_solver.cpp:106] Iteration 11420, lr = 0.000564788
I0817 05:58:27.189785 20404 solver.cpp:228] Iteration 11430, loss = 0.820192
I0817 05:58:27.189973 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:58:27.189992 20404 solver.cpp:244]     Train net output #1: loss = 0.820192 (* 1 = 0.820192 loss)
I0817 05:58:27.190007 20404 sgd_solver.cpp:106] Iteration 11430, lr = 0.00056459
I0817 05:58:58.595000 20404 solver.cpp:337] Iteration 11440, Testing net (#0)
I0817 05:59:33.240757 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 05:59:33.240941 20404 solver.cpp:404]     Test net output #1: loss = 0.671575 (* 1 = 0.671575 loss)
I0817 05:59:36.718289 20404 solver.cpp:228] Iteration 11440, loss = 0.820094
I0817 05:59:36.718340 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 05:59:36.718354 20404 solver.cpp:244]     Train net output #1: loss = 0.820094 (* 1 = 0.820094 loss)
I0817 05:59:36.718365 20404 sgd_solver.cpp:106] Iteration 11440, lr = 0.000564393
I0817 06:00:11.609045 20404 solver.cpp:228] Iteration 11450, loss = 0.82108
I0817 06:00:11.609226 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:00:11.609243 20404 solver.cpp:244]     Train net output #1: loss = 0.82108 (* 1 = 0.82108 loss)
I0817 06:00:11.609256 20404 sgd_solver.cpp:106] Iteration 11450, lr = 0.000564195
I0817 06:00:46.501284 20404 solver.cpp:228] Iteration 11460, loss = 0.820028
I0817 06:00:46.501459 20404 solver.cpp:244]     Train net output #0: accuracy = 0.92
I0817 06:00:46.501476 20404 solver.cpp:244]     Train net output #1: loss = 0.820028 (* 1 = 0.820028 loss)
I0817 06:00:46.501487 20404 sgd_solver.cpp:106] Iteration 11460, lr = 0.000563998
I0817 06:01:21.385339 20404 solver.cpp:228] Iteration 11470, loss = 0.820083
I0817 06:01:21.385524 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:01:21.385538 20404 solver.cpp:244]     Train net output #1: loss = 0.820083 (* 1 = 0.820083 loss)
I0817 06:01:21.385551 20404 sgd_solver.cpp:106] Iteration 11470, lr = 0.000563801
I0817 06:01:52.802222 20404 solver.cpp:337] Iteration 11480, Testing net (#0)
I0817 06:02:27.450968 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:02:27.451041 20404 solver.cpp:404]     Test net output #1: loss = 0.671638 (* 1 = 0.671638 loss)
I0817 06:02:30.926252 20404 solver.cpp:228] Iteration 11480, loss = 0.820126
I0817 06:02:30.926304 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:02:30.926318 20404 solver.cpp:244]     Train net output #1: loss = 0.820126 (* 1 = 0.820126 loss)
I0817 06:02:30.926329 20404 sgd_solver.cpp:106] Iteration 11480, lr = 0.000563604
I0817 06:03:05.797873 20404 solver.cpp:228] Iteration 11490, loss = 0.821188
I0817 06:03:05.798054 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:03:05.798070 20404 solver.cpp:244]     Train net output #1: loss = 0.821188 (* 1 = 0.821188 loss)
I0817 06:03:05.798084 20404 sgd_solver.cpp:106] Iteration 11490, lr = 0.000563408
I0817 06:03:40.677335 20404 solver.cpp:228] Iteration 11500, loss = 0.82021
I0817 06:03:40.677470 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:03:40.677486 20404 solver.cpp:244]     Train net output #1: loss = 0.82021 (* 1 = 0.82021 loss)
I0817 06:03:40.677500 20404 sgd_solver.cpp:106] Iteration 11500, lr = 0.000563211
I0817 06:04:15.575834 20404 solver.cpp:228] Iteration 11510, loss = 0.820178
I0817 06:04:15.576017 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:04:15.576033 20404 solver.cpp:244]     Train net output #1: loss = 0.820178 (* 1 = 0.820178 loss)
I0817 06:04:15.576046 20404 sgd_solver.cpp:106] Iteration 11510, lr = 0.000563015
I0817 06:04:47.004261 20404 solver.cpp:337] Iteration 11520, Testing net (#0)
I0817 06:05:21.652015 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:05:21.652194 20404 solver.cpp:404]     Test net output #1: loss = 0.671759 (* 1 = 0.671759 loss)
I0817 06:05:25.124469 20404 solver.cpp:228] Iteration 11520, loss = 0.820196
I0817 06:05:25.124522 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:05:25.124536 20404 solver.cpp:244]     Train net output #1: loss = 0.820196 (* 1 = 0.820196 loss)
I0817 06:05:25.124548 20404 sgd_solver.cpp:106] Iteration 11520, lr = 0.000562818
I0817 06:06:00.023416 20404 solver.cpp:228] Iteration 11530, loss = 0.820583
I0817 06:06:00.023598 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:06:00.023615 20404 solver.cpp:244]     Train net output #1: loss = 0.820583 (* 1 = 0.820583 loss)
I0817 06:06:00.023627 20404 sgd_solver.cpp:106] Iteration 11530, lr = 0.000562622
I0817 06:06:34.886744 20404 solver.cpp:228] Iteration 11540, loss = 0.820207
I0817 06:06:34.886926 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:06:34.886941 20404 solver.cpp:244]     Train net output #1: loss = 0.820207 (* 1 = 0.820207 loss)
I0817 06:06:34.886955 20404 sgd_solver.cpp:106] Iteration 11540, lr = 0.000562427
I0817 06:07:09.783097 20404 solver.cpp:228] Iteration 11550, loss = 0.821416
I0817 06:07:09.783282 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:07:09.783300 20404 solver.cpp:244]     Train net output #1: loss = 0.821416 (* 1 = 0.821416 loss)
I0817 06:07:09.783315 20404 sgd_solver.cpp:106] Iteration 11550, lr = 0.000562231
I0817 06:07:41.181049 20404 solver.cpp:337] Iteration 11560, Testing net (#0)
I0817 06:08:15.839886 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:08:15.840061 20404 solver.cpp:404]     Test net output #1: loss = 0.67073 (* 1 = 0.67073 loss)
I0817 06:08:19.322871 20404 solver.cpp:228] Iteration 11560, loss = 0.820902
I0817 06:08:19.322922 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:08:19.322937 20404 solver.cpp:244]     Train net output #1: loss = 0.820902 (* 1 = 0.820902 loss)
I0817 06:08:19.322948 20404 sgd_solver.cpp:106] Iteration 11560, lr = 0.000562035
I0817 06:08:54.209110 20404 solver.cpp:228] Iteration 11570, loss = 0.820195
I0817 06:08:54.209282 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:08:54.209300 20404 solver.cpp:244]     Train net output #1: loss = 0.820195 (* 1 = 0.820195 loss)
I0817 06:08:54.209313 20404 sgd_solver.cpp:106] Iteration 11570, lr = 0.00056184
I0817 06:09:29.072059 20404 solver.cpp:228] Iteration 11580, loss = 0.821345
I0817 06:09:29.072156 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:09:29.072171 20404 solver.cpp:244]     Train net output #1: loss = 0.821345 (* 1 = 0.821345 loss)
I0817 06:09:29.072183 20404 sgd_solver.cpp:106] Iteration 11580, lr = 0.000561644
I0817 06:10:03.963081 20404 solver.cpp:228] Iteration 11590, loss = 0.820794
I0817 06:10:03.963265 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:10:03.963285 20404 solver.cpp:244]     Train net output #1: loss = 0.820794 (* 1 = 0.820794 loss)
I0817 06:10:03.963300 20404 sgd_solver.cpp:106] Iteration 11590, lr = 0.000561449
I0817 06:10:35.377308 20404 solver.cpp:337] Iteration 11600, Testing net (#0)
I0817 06:11:10.026099 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:11:10.026310 20404 solver.cpp:404]     Test net output #1: loss = 0.67185 (* 1 = 0.67185 loss)
I0817 06:11:13.501423 20404 solver.cpp:228] Iteration 11600, loss = 0.820243
I0817 06:11:13.501467 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:11:13.501485 20404 solver.cpp:244]     Train net output #1: loss = 0.820243 (* 1 = 0.820243 loss)
I0817 06:11:13.501510 20404 sgd_solver.cpp:106] Iteration 11600, lr = 0.000561254
I0817 06:11:48.390924 20404 solver.cpp:228] Iteration 11610, loss = 0.82028
I0817 06:11:48.391111 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:11:48.391130 20404 solver.cpp:244]     Train net output #1: loss = 0.82028 (* 1 = 0.82028 loss)
I0817 06:11:48.391145 20404 sgd_solver.cpp:106] Iteration 11610, lr = 0.00056106
I0817 06:12:23.279518 20404 solver.cpp:228] Iteration 11620, loss = 0.820296
I0817 06:12:23.279672 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:12:23.279692 20404 solver.cpp:244]     Train net output #1: loss = 0.820296 (* 1 = 0.820296 loss)
I0817 06:12:23.279707 20404 sgd_solver.cpp:106] Iteration 11620, lr = 0.000560865
I0817 06:12:58.148453 20404 solver.cpp:228] Iteration 11630, loss = 0.821064
I0817 06:12:58.148640 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:12:58.148659 20404 solver.cpp:244]     Train net output #1: loss = 0.821064 (* 1 = 0.821064 loss)
I0817 06:12:58.148674 20404 sgd_solver.cpp:106] Iteration 11630, lr = 0.00056067
I0817 06:13:29.556448 20404 solver.cpp:337] Iteration 11640, Testing net (#0)
I0817 06:14:04.202752 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:14:04.202937 20404 solver.cpp:404]     Test net output #1: loss = 0.671252 (* 1 = 0.671252 loss)
I0817 06:14:07.679407 20404 solver.cpp:228] Iteration 11640, loss = 0.820238
I0817 06:14:07.679461 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:14:07.679474 20404 solver.cpp:244]     Train net output #1: loss = 0.820238 (* 1 = 0.820238 loss)
I0817 06:14:07.679486 20404 sgd_solver.cpp:106] Iteration 11640, lr = 0.000560476
I0817 06:14:42.573106 20404 solver.cpp:228] Iteration 11650, loss = 0.820442
I0817 06:14:42.573266 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:14:42.573282 20404 solver.cpp:244]     Train net output #1: loss = 0.820442 (* 1 = 0.820442 loss)
I0817 06:14:42.573293 20404 sgd_solver.cpp:106] Iteration 11650, lr = 0.000560282
I0817 06:15:17.462476 20404 solver.cpp:228] Iteration 11660, loss = 0.820588
I0817 06:15:17.462656 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:15:17.462671 20404 solver.cpp:244]     Train net output #1: loss = 0.820588 (* 1 = 0.820588 loss)
I0817 06:15:17.462683 20404 sgd_solver.cpp:106] Iteration 11660, lr = 0.000560088
I0817 06:15:52.359127 20404 solver.cpp:228] Iteration 11670, loss = 0.820224
I0817 06:15:52.359303 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:15:52.359319 20404 solver.cpp:244]     Train net output #1: loss = 0.820224 (* 1 = 0.820224 loss)
I0817 06:15:52.359331 20404 sgd_solver.cpp:106] Iteration 11670, lr = 0.000559894
I0817 06:16:23.775662 20404 solver.cpp:337] Iteration 11680, Testing net (#0)
I0817 06:16:58.434878 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:16:58.435055 20404 solver.cpp:404]     Test net output #1: loss = 0.671326 (* 1 = 0.671326 loss)
I0817 06:17:01.916115 20404 solver.cpp:228] Iteration 11680, loss = 0.820141
I0817 06:17:01.916162 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:17:01.916177 20404 solver.cpp:244]     Train net output #1: loss = 0.820141 (* 1 = 0.820141 loss)
I0817 06:17:01.916188 20404 sgd_solver.cpp:106] Iteration 11680, lr = 0.0005597
I0817 06:17:36.805837 20404 solver.cpp:228] Iteration 11690, loss = 0.820263
I0817 06:17:36.806015 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:17:36.806031 20404 solver.cpp:244]     Train net output #1: loss = 0.820263 (* 1 = 0.820263 loss)
I0817 06:17:36.806043 20404 sgd_solver.cpp:106] Iteration 11690, lr = 0.000559507
I0817 06:18:11.695636 20404 solver.cpp:228] Iteration 11700, loss = 0.82012
I0817 06:18:11.695878 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:18:11.695894 20404 solver.cpp:244]     Train net output #1: loss = 0.82012 (* 1 = 0.82012 loss)
I0817 06:18:11.695905 20404 sgd_solver.cpp:106] Iteration 11700, lr = 0.000559313
I0817 06:18:46.590737 20404 solver.cpp:228] Iteration 11710, loss = 0.820213
I0817 06:18:46.590924 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:18:46.590944 20404 solver.cpp:244]     Train net output #1: loss = 0.820213 (* 1 = 0.820213 loss)
I0817 06:18:46.590958 20404 sgd_solver.cpp:106] Iteration 11710, lr = 0.00055912
I0817 06:19:17.997681 20404 solver.cpp:337] Iteration 11720, Testing net (#0)
I0817 06:19:52.636840 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:19:52.637011 20404 solver.cpp:404]     Test net output #1: loss = 0.671408 (* 1 = 0.671408 loss)
I0817 06:19:56.110033 20404 solver.cpp:228] Iteration 11720, loss = 0.820044
I0817 06:19:56.110085 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 06:19:56.110098 20404 solver.cpp:244]     Train net output #1: loss = 0.820044 (* 1 = 0.820044 loss)
I0817 06:19:56.110110 20404 sgd_solver.cpp:106] Iteration 11720, lr = 0.000558927
I0817 06:20:31.000756 20404 solver.cpp:228] Iteration 11730, loss = 0.820406
I0817 06:20:31.000938 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:20:31.000953 20404 solver.cpp:244]     Train net output #1: loss = 0.820406 (* 1 = 0.820406 loss)
I0817 06:20:31.000965 20404 sgd_solver.cpp:106] Iteration 11730, lr = 0.000558734
I0817 06:21:05.912271 20404 solver.cpp:228] Iteration 11740, loss = 0.820632
I0817 06:21:05.912457 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:21:05.912473 20404 solver.cpp:244]     Train net output #1: loss = 0.820632 (* 1 = 0.820632 loss)
I0817 06:21:05.912485 20404 sgd_solver.cpp:106] Iteration 11740, lr = 0.000558541
I0817 06:21:40.789682 20404 solver.cpp:228] Iteration 11750, loss = 0.820462
I0817 06:21:40.789870 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:21:40.789886 20404 solver.cpp:244]     Train net output #1: loss = 0.820462 (* 1 = 0.820462 loss)
I0817 06:21:40.789897 20404 sgd_solver.cpp:106] Iteration 11750, lr = 0.000558349
I0817 06:22:12.191138 20404 solver.cpp:337] Iteration 11760, Testing net (#0)
I0817 06:22:46.833586 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:22:46.833758 20404 solver.cpp:404]     Test net output #1: loss = 0.671764 (* 1 = 0.671764 loss)
I0817 06:22:50.306037 20404 solver.cpp:228] Iteration 11760, loss = 0.820199
I0817 06:22:50.306082 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:22:50.306099 20404 solver.cpp:244]     Train net output #1: loss = 0.820199 (* 1 = 0.820199 loss)
I0817 06:22:50.306124 20404 sgd_solver.cpp:106] Iteration 11760, lr = 0.000558156
I0817 06:23:25.204931 20404 solver.cpp:228] Iteration 11770, loss = 0.821249
I0817 06:23:25.205111 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:23:25.205129 20404 solver.cpp:244]     Train net output #1: loss = 0.821249 (* 1 = 0.821249 loss)
I0817 06:23:25.205142 20404 sgd_solver.cpp:106] Iteration 11770, lr = 0.000557964
I0817 06:24:00.079675 20404 solver.cpp:228] Iteration 11780, loss = 0.820578
I0817 06:24:00.079746 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:24:00.079764 20404 solver.cpp:244]     Train net output #1: loss = 0.820578 (* 1 = 0.820578 loss)
I0817 06:24:00.079779 20404 sgd_solver.cpp:106] Iteration 11780, lr = 0.000557772
I0817 06:24:34.987447 20404 solver.cpp:228] Iteration 11790, loss = 0.820139
I0817 06:24:34.987622 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:24:34.987642 20404 solver.cpp:244]     Train net output #1: loss = 0.820139 (* 1 = 0.820139 loss)
I0817 06:24:34.987653 20404 sgd_solver.cpp:106] Iteration 11790, lr = 0.00055758
I0817 06:25:06.409736 20404 solver.cpp:337] Iteration 11800, Testing net (#0)
I0817 06:25:41.062582 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:25:41.062664 20404 solver.cpp:404]     Test net output #1: loss = 0.671443 (* 1 = 0.671443 loss)
I0817 06:25:44.542279 20404 solver.cpp:228] Iteration 11800, loss = 0.820019
I0817 06:25:44.542331 20404 solver.cpp:244]     Train net output #0: accuracy = 0.84
I0817 06:25:44.542346 20404 solver.cpp:244]     Train net output #1: loss = 0.820019 (* 1 = 0.820019 loss)
I0817 06:25:44.542357 20404 sgd_solver.cpp:106] Iteration 11800, lr = 0.000557388
I0817 06:26:19.430033 20404 solver.cpp:228] Iteration 11810, loss = 0.820167
I0817 06:26:19.430217 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:26:19.430233 20404 solver.cpp:244]     Train net output #1: loss = 0.820167 (* 1 = 0.820167 loss)
I0817 06:26:19.430245 20404 sgd_solver.cpp:106] Iteration 11810, lr = 0.000557196
I0817 06:26:54.327013 20404 solver.cpp:228] Iteration 11820, loss = 0.820023
I0817 06:26:54.327193 20404 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0817 06:26:54.327208 20404 solver.cpp:244]     Train net output #1: loss = 0.820023 (* 1 = 0.820023 loss)
I0817 06:26:54.327221 20404 sgd_solver.cpp:106] Iteration 11820, lr = 0.000557005
I0817 06:27:29.224794 20404 solver.cpp:228] Iteration 11830, loss = 0.820106
I0817 06:27:29.224967 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:27:29.224982 20404 solver.cpp:244]     Train net output #1: loss = 0.820106 (* 1 = 0.820106 loss)
I0817 06:27:29.224994 20404 sgd_solver.cpp:106] Iteration 11830, lr = 0.000556813
I0817 06:28:00.642588 20404 solver.cpp:337] Iteration 11840, Testing net (#0)
I0817 06:28:35.285991 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:28:35.286167 20404 solver.cpp:404]     Test net output #1: loss = 0.671425 (* 1 = 0.671425 loss)
I0817 06:28:38.763886 20404 solver.cpp:228] Iteration 11840, loss = 0.82003
I0817 06:28:38.763937 20404 solver.cpp:244]     Train net output #0: accuracy = 0.74
I0817 06:28:38.763952 20404 solver.cpp:244]     Train net output #1: loss = 0.82003 (* 1 = 0.82003 loss)
I0817 06:28:38.763962 20404 sgd_solver.cpp:106] Iteration 11840, lr = 0.000556622
I0817 06:29:13.658040 20404 solver.cpp:228] Iteration 11850, loss = 0.820119
I0817 06:29:13.658212 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:29:13.658227 20404 solver.cpp:244]     Train net output #1: loss = 0.820119 (* 1 = 0.820119 loss)
I0817 06:29:13.658239 20404 sgd_solver.cpp:106] Iteration 11850, lr = 0.000556431
I0817 06:29:48.561187 20404 solver.cpp:228] Iteration 11860, loss = 0.82087
I0817 06:29:48.561354 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:29:48.561370 20404 solver.cpp:244]     Train net output #1: loss = 0.82087 (* 1 = 0.82087 loss)
I0817 06:29:48.561386 20404 sgd_solver.cpp:106] Iteration 11860, lr = 0.00055624
I0817 06:30:23.469239 20404 solver.cpp:228] Iteration 11870, loss = 0.820094
I0817 06:30:23.469393 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:30:23.469409 20404 solver.cpp:244]     Train net output #1: loss = 0.820094 (* 1 = 0.820094 loss)
I0817 06:30:23.469421 20404 sgd_solver.cpp:106] Iteration 11870, lr = 0.00055605
I0817 06:30:54.905071 20404 solver.cpp:337] Iteration 11880, Testing net (#0)
I0817 06:31:29.552075 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:31:29.552175 20404 solver.cpp:404]     Test net output #1: loss = 0.670646 (* 1 = 0.670646 loss)
I0817 06:31:33.031009 20404 solver.cpp:228] Iteration 11880, loss = 0.821014
I0817 06:31:33.031059 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:31:33.031074 20404 solver.cpp:244]     Train net output #1: loss = 0.821014 (* 1 = 0.821014 loss)
I0817 06:31:33.031085 20404 sgd_solver.cpp:106] Iteration 11880, lr = 0.000555859
I0817 06:32:07.899847 20404 solver.cpp:228] Iteration 11890, loss = 0.820679
I0817 06:32:07.900028 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:32:07.900044 20404 solver.cpp:244]     Train net output #1: loss = 0.820679 (* 1 = 0.820679 loss)
I0817 06:32:07.900056 20404 sgd_solver.cpp:106] Iteration 11890, lr = 0.000555668
I0817 06:32:42.802181 20404 solver.cpp:228] Iteration 11900, loss = 0.820753
I0817 06:32:42.802397 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:32:42.802413 20404 solver.cpp:244]     Train net output #1: loss = 0.820753 (* 1 = 0.820753 loss)
I0817 06:32:42.802425 20404 sgd_solver.cpp:106] Iteration 11900, lr = 0.000555478
I0817 06:33:17.708807 20404 solver.cpp:228] Iteration 11910, loss = 0.820973
I0817 06:33:17.708982 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:33:17.708997 20404 solver.cpp:244]     Train net output #1: loss = 0.820973 (* 1 = 0.820973 loss)
I0817 06:33:17.709010 20404 sgd_solver.cpp:106] Iteration 11910, lr = 0.000555288
I0817 06:33:49.123677 20404 solver.cpp:337] Iteration 11920, Testing net (#0)
I0817 06:34:23.781585 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:34:23.781754 20404 solver.cpp:404]     Test net output #1: loss = 0.671126 (* 1 = 0.671126 loss)
I0817 06:34:27.253945 20404 solver.cpp:228] Iteration 11920, loss = 0.820398
I0817 06:34:27.253995 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:34:27.254009 20404 solver.cpp:244]     Train net output #1: loss = 0.820398 (* 1 = 0.820398 loss)
I0817 06:34:27.254021 20404 sgd_solver.cpp:106] Iteration 11920, lr = 0.000555098
I0817 06:35:02.137442 20404 solver.cpp:228] Iteration 11930, loss = 0.820143
I0817 06:35:02.137617 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:35:02.137634 20404 solver.cpp:244]     Train net output #1: loss = 0.820143 (* 1 = 0.820143 loss)
I0817 06:35:02.137645 20404 sgd_solver.cpp:106] Iteration 11930, lr = 0.000554908
I0817 06:35:37.025487 20404 solver.cpp:228] Iteration 11940, loss = 0.820399
I0817 06:35:37.025596 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:35:37.025611 20404 solver.cpp:244]     Train net output #1: loss = 0.820399 (* 1 = 0.820399 loss)
I0817 06:35:37.025624 20404 sgd_solver.cpp:106] Iteration 11940, lr = 0.000554718
I0817 06:36:11.926245 20404 solver.cpp:228] Iteration 11950, loss = 0.820635
I0817 06:36:11.926426 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:36:11.926445 20404 solver.cpp:244]     Train net output #1: loss = 0.820635 (* 1 = 0.820635 loss)
I0817 06:36:11.926458 20404 sgd_solver.cpp:106] Iteration 11950, lr = 0.000554529
I0817 06:36:43.348564 20404 solver.cpp:337] Iteration 11960, Testing net (#0)
I0817 06:37:18.020308 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:37:18.020480 20404 solver.cpp:404]     Test net output #1: loss = 0.671313 (* 1 = 0.671313 loss)
I0817 06:37:21.495014 20404 solver.cpp:228] Iteration 11960, loss = 0.82016
I0817 06:37:21.495069 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:37:21.495082 20404 solver.cpp:244]     Train net output #1: loss = 0.82016 (* 1 = 0.82016 loss)
I0817 06:37:21.495095 20404 sgd_solver.cpp:106] Iteration 11960, lr = 0.000554339
I0817 06:37:56.372771 20404 solver.cpp:228] Iteration 11970, loss = 0.820427
I0817 06:37:56.372949 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:37:56.372964 20404 solver.cpp:244]     Train net output #1: loss = 0.820427 (* 1 = 0.820427 loss)
I0817 06:37:56.372977 20404 sgd_solver.cpp:106] Iteration 11970, lr = 0.00055415
I0817 06:38:31.285992 20404 solver.cpp:228] Iteration 11980, loss = 0.820549
I0817 06:38:31.286169 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:38:31.286185 20404 solver.cpp:244]     Train net output #1: loss = 0.820549 (* 1 = 0.820549 loss)
I0817 06:38:31.286196 20404 sgd_solver.cpp:106] Iteration 11980, lr = 0.000553961
I0817 06:39:06.167879 20404 solver.cpp:228] Iteration 11990, loss = 0.820068
I0817 06:39:06.168058 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:39:06.168074 20404 solver.cpp:244]     Train net output #1: loss = 0.820068 (* 1 = 0.820068 loss)
I0817 06:39:06.168087 20404 sgd_solver.cpp:106] Iteration 11990, lr = 0.000553772
I0817 06:39:37.597003 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_12000.caffemodel
I0817 06:39:47.554407 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_12000.solverstate
I0817 06:39:49.359079 20404 solver.cpp:337] Iteration 12000, Testing net (#0)
I0817 06:40:23.998145 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:40:23.998242 20404 solver.cpp:404]     Test net output #1: loss = 0.671127 (* 1 = 0.671127 loss)
I0817 06:40:27.479518 20404 solver.cpp:228] Iteration 12000, loss = 0.820401
I0817 06:40:27.479570 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:40:27.479585 20404 solver.cpp:244]     Train net output #1: loss = 0.820401 (* 1 = 0.820401 loss)
I0817 06:40:27.479596 20404 sgd_solver.cpp:106] Iteration 12000, lr = 0.000553583
I0817 06:41:02.369475 20404 solver.cpp:228] Iteration 12010, loss = 0.820164
I0817 06:41:02.369639 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:41:02.369655 20404 solver.cpp:244]     Train net output #1: loss = 0.820164 (* 1 = 0.820164 loss)
I0817 06:41:02.369668 20404 sgd_solver.cpp:106] Iteration 12010, lr = 0.000553395
I0817 06:41:37.294436 20404 solver.cpp:228] Iteration 12020, loss = 0.820746
I0817 06:41:37.294615 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:41:37.294631 20404 solver.cpp:244]     Train net output #1: loss = 0.820746 (* 1 = 0.820746 loss)
I0817 06:41:37.294644 20404 sgd_solver.cpp:106] Iteration 12020, lr = 0.000553206
I0817 06:42:12.200209 20404 solver.cpp:228] Iteration 12030, loss = 0.821573
I0817 06:42:12.200374 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:42:12.200390 20404 solver.cpp:244]     Train net output #1: loss = 0.821573 (* 1 = 0.821573 loss)
I0817 06:42:12.200402 20404 sgd_solver.cpp:106] Iteration 12030, lr = 0.000553018
I0817 06:42:43.624511 20404 solver.cpp:337] Iteration 12040, Testing net (#0)
I0817 06:43:18.298069 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:43:18.298243 20404 solver.cpp:404]     Test net output #1: loss = 0.671201 (* 1 = 0.671201 loss)
I0817 06:43:21.769999 20404 solver.cpp:228] Iteration 12040, loss = 0.820308
I0817 06:43:21.770052 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:43:21.770067 20404 solver.cpp:244]     Train net output #1: loss = 0.820308 (* 1 = 0.820308 loss)
I0817 06:43:21.770078 20404 sgd_solver.cpp:106] Iteration 12040, lr = 0.00055283
I0817 06:43:56.654667 20404 solver.cpp:228] Iteration 12050, loss = 0.820582
I0817 06:43:56.654846 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:43:56.654861 20404 solver.cpp:244]     Train net output #1: loss = 0.820582 (* 1 = 0.820582 loss)
I0817 06:43:56.654875 20404 sgd_solver.cpp:106] Iteration 12050, lr = 0.000552642
I0817 06:44:31.547847 20404 solver.cpp:228] Iteration 12060, loss = 0.821738
I0817 06:44:31.548022 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:44:31.548038 20404 solver.cpp:244]     Train net output #1: loss = 0.821738 (* 1 = 0.821738 loss)
I0817 06:44:31.548051 20404 sgd_solver.cpp:106] Iteration 12060, lr = 0.000552454
I0817 06:45:06.445639 20404 solver.cpp:228] Iteration 12070, loss = 0.821255
I0817 06:45:06.445812 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:45:06.445827 20404 solver.cpp:244]     Train net output #1: loss = 0.821255 (* 1 = 0.821255 loss)
I0817 06:45:06.445840 20404 sgd_solver.cpp:106] Iteration 12070, lr = 0.000552266
I0817 06:45:37.883044 20404 solver.cpp:337] Iteration 12080, Testing net (#0)
I0817 06:46:12.530625 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:46:12.530796 20404 solver.cpp:404]     Test net output #1: loss = 0.670848 (* 1 = 0.670848 loss)
I0817 06:46:16.004979 20404 solver.cpp:228] Iteration 12080, loss = 0.820768
I0817 06:46:16.005030 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:46:16.005044 20404 solver.cpp:244]     Train net output #1: loss = 0.820768 (* 1 = 0.820768 loss)
I0817 06:46:16.005056 20404 sgd_solver.cpp:106] Iteration 12080, lr = 0.000552078
I0817 06:46:50.893774 20404 solver.cpp:228] Iteration 12090, loss = 0.820239
I0817 06:46:50.893988 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:46:50.894004 20404 solver.cpp:244]     Train net output #1: loss = 0.820239 (* 1 = 0.820239 loss)
I0817 06:46:50.894016 20404 sgd_solver.cpp:106] Iteration 12090, lr = 0.000551891
I0817 06:47:25.791802 20404 solver.cpp:228] Iteration 12100, loss = 0.820094
I0817 06:47:25.791983 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:47:25.791998 20404 solver.cpp:244]     Train net output #1: loss = 0.820094 (* 1 = 0.820094 loss)
I0817 06:47:25.792011 20404 sgd_solver.cpp:106] Iteration 12100, lr = 0.000551704
I0817 06:48:00.687592 20404 solver.cpp:228] Iteration 12110, loss = 0.820117
I0817 06:48:00.687767 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:48:00.687785 20404 solver.cpp:244]     Train net output #1: loss = 0.820117 (* 1 = 0.820117 loss)
I0817 06:48:00.687798 20404 sgd_solver.cpp:106] Iteration 12110, lr = 0.000551516
I0817 06:48:32.079092 20404 solver.cpp:337] Iteration 12120, Testing net (#0)
I0817 06:49:06.723218 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:49:06.723389 20404 solver.cpp:404]     Test net output #1: loss = 0.67132 (* 1 = 0.67132 loss)
I0817 06:49:10.205353 20404 solver.cpp:228] Iteration 12120, loss = 0.820164
I0817 06:49:10.205404 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:49:10.205418 20404 solver.cpp:244]     Train net output #1: loss = 0.820164 (* 1 = 0.820164 loss)
I0817 06:49:10.205430 20404 sgd_solver.cpp:106] Iteration 12120, lr = 0.000551329
I0817 06:49:45.074632 20404 solver.cpp:228] Iteration 12130, loss = 0.820175
I0817 06:49:45.074800 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:49:45.074817 20404 solver.cpp:244]     Train net output #1: loss = 0.820175 (* 1 = 0.820175 loss)
I0817 06:49:45.074831 20404 sgd_solver.cpp:106] Iteration 12130, lr = 0.000551143
I0817 06:50:19.970888 20404 solver.cpp:228] Iteration 12140, loss = 0.820725
I0817 06:50:19.971125 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:50:19.971144 20404 solver.cpp:244]     Train net output #1: loss = 0.820725 (* 1 = 0.820725 loss)
I0817 06:50:19.971158 20404 sgd_solver.cpp:106] Iteration 12140, lr = 0.000550956
I0817 06:50:54.874187 20404 solver.cpp:228] Iteration 12150, loss = 0.82159
I0817 06:50:54.874361 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:50:54.874379 20404 solver.cpp:244]     Train net output #1: loss = 0.82159 (* 1 = 0.82159 loss)
I0817 06:50:54.874394 20404 sgd_solver.cpp:106] Iteration 12150, lr = 0.000550769
I0817 06:51:26.304558 20404 solver.cpp:337] Iteration 12160, Testing net (#0)
I0817 06:52:00.945888 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:52:00.946059 20404 solver.cpp:404]     Test net output #1: loss = 0.671181 (* 1 = 0.671181 loss)
I0817 06:52:04.421759 20404 solver.cpp:228] Iteration 12160, loss = 0.820347
I0817 06:52:04.421805 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:52:04.421823 20404 solver.cpp:244]     Train net output #1: loss = 0.820347 (* 1 = 0.820347 loss)
I0817 06:52:04.421849 20404 sgd_solver.cpp:106] Iteration 12160, lr = 0.000550583
I0817 06:52:39.305526 20404 solver.cpp:228] Iteration 12170, loss = 0.820623
I0817 06:52:39.305701 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:52:39.305716 20404 solver.cpp:244]     Train net output #1: loss = 0.820623 (* 1 = 0.820623 loss)
I0817 06:52:39.305729 20404 sgd_solver.cpp:106] Iteration 12170, lr = 0.000550397
I0817 06:53:14.202138 20404 solver.cpp:228] Iteration 12180, loss = 0.82158
I0817 06:53:14.202242 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:53:14.202257 20404 solver.cpp:244]     Train net output #1: loss = 0.82158 (* 1 = 0.82158 loss)
I0817 06:53:14.202270 20404 sgd_solver.cpp:106] Iteration 12180, lr = 0.00055021
I0817 06:53:49.121507 20404 solver.cpp:228] Iteration 12190, loss = 0.821473
I0817 06:53:49.121721 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:53:49.121740 20404 solver.cpp:244]     Train net output #1: loss = 0.821473 (* 1 = 0.821473 loss)
I0817 06:53:49.121772 20404 sgd_solver.cpp:106] Iteration 12190, lr = 0.000550025
I0817 06:54:20.544939 20404 solver.cpp:337] Iteration 12200, Testing net (#0)
I0817 06:54:55.187296 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:54:55.187387 20404 solver.cpp:404]     Test net output #1: loss = 0.670299 (* 1 = 0.670299 loss)
I0817 06:54:58.667443 20404 solver.cpp:228] Iteration 12200, loss = 0.821475
I0817 06:54:58.667495 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:54:58.667508 20404 solver.cpp:244]     Train net output #1: loss = 0.821475 (* 1 = 0.821475 loss)
I0817 06:54:58.667520 20404 sgd_solver.cpp:106] Iteration 12200, lr = 0.000549839
I0817 06:55:33.565527 20404 solver.cpp:228] Iteration 12210, loss = 0.821519
I0817 06:55:33.565634 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:55:33.565650 20404 solver.cpp:244]     Train net output #1: loss = 0.821519 (* 1 = 0.821519 loss)
I0817 06:55:33.565662 20404 sgd_solver.cpp:106] Iteration 12210, lr = 0.000549653
I0817 06:56:08.453766 20404 solver.cpp:228] Iteration 12220, loss = 0.821575
I0817 06:56:08.453948 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:56:08.453963 20404 solver.cpp:244]     Train net output #1: loss = 0.821575 (* 1 = 0.821575 loss)
I0817 06:56:08.453975 20404 sgd_solver.cpp:106] Iteration 12220, lr = 0.000549467
I0817 06:56:43.363240 20404 solver.cpp:228] Iteration 12230, loss = 0.821434
I0817 06:56:43.363425 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:56:43.363440 20404 solver.cpp:244]     Train net output #1: loss = 0.821434 (* 1 = 0.821434 loss)
I0817 06:56:43.363453 20404 sgd_solver.cpp:106] Iteration 12230, lr = 0.000549282
I0817 06:57:14.785137 20404 solver.cpp:337] Iteration 12240, Testing net (#0)
I0817 06:57:49.435626 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 06:57:49.435807 20404 solver.cpp:404]     Test net output #1: loss = 0.670714 (* 1 = 0.670714 loss)
I0817 06:57:52.912159 20404 solver.cpp:228] Iteration 12240, loss = 0.82095
I0817 06:57:52.912215 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:57:52.912230 20404 solver.cpp:244]     Train net output #1: loss = 0.82095 (* 1 = 0.82095 loss)
I0817 06:57:52.912242 20404 sgd_solver.cpp:106] Iteration 12240, lr = 0.000549097
I0817 06:58:27.828208 20404 solver.cpp:228] Iteration 12250, loss = 0.820321
I0817 06:58:27.828388 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 06:58:27.828408 20404 solver.cpp:244]     Train net output #1: loss = 0.820321 (* 1 = 0.820321 loss)
I0817 06:58:27.828420 20404 sgd_solver.cpp:106] Iteration 12250, lr = 0.000548912
I0817 06:59:02.715541 20404 solver.cpp:228] Iteration 12260, loss = 0.820036
I0817 06:59:02.715711 20404 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0817 06:59:02.715726 20404 solver.cpp:244]     Train net output #1: loss = 0.820036 (* 1 = 0.820036 loss)
I0817 06:59:02.715739 20404 sgd_solver.cpp:106] Iteration 12260, lr = 0.000548727
I0817 06:59:37.613301 20404 solver.cpp:228] Iteration 12270, loss = 0.820853
I0817 06:59:37.613477 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 06:59:37.613493 20404 solver.cpp:244]     Train net output #1: loss = 0.820853 (* 1 = 0.820853 loss)
I0817 06:59:37.613505 20404 sgd_solver.cpp:106] Iteration 12270, lr = 0.000548542
I0817 07:00:09.047106 20404 solver.cpp:337] Iteration 12280, Testing net (#0)
I0817 07:00:43.714999 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:00:43.715172 20404 solver.cpp:404]     Test net output #1: loss = 0.671283 (* 1 = 0.671283 loss)
I0817 07:00:47.195600 20404 solver.cpp:228] Iteration 12280, loss = 0.82022
I0817 07:00:47.195652 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:00:47.195664 20404 solver.cpp:244]     Train net output #1: loss = 0.82022 (* 1 = 0.82022 loss)
I0817 07:00:47.195677 20404 sgd_solver.cpp:106] Iteration 12280, lr = 0.000548357
I0817 07:01:22.085660 20404 solver.cpp:228] Iteration 12290, loss = 0.820479
I0817 07:01:22.085875 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:01:22.085889 20404 solver.cpp:244]     Train net output #1: loss = 0.820479 (* 1 = 0.820479 loss)
I0817 07:01:22.085901 20404 sgd_solver.cpp:106] Iteration 12290, lr = 0.000548173
I0817 07:01:56.973263 20404 solver.cpp:228] Iteration 12300, loss = 0.820647
I0817 07:01:56.973451 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:01:56.973469 20404 solver.cpp:244]     Train net output #1: loss = 0.820647 (* 1 = 0.820647 loss)
I0817 07:01:56.973484 20404 sgd_solver.cpp:106] Iteration 12300, lr = 0.000547988
I0817 07:02:31.843396 20404 solver.cpp:228] Iteration 12310, loss = 0.820352
I0817 07:02:31.843577 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:02:31.843596 20404 solver.cpp:244]     Train net output #1: loss = 0.820352 (* 1 = 0.820352 loss)
I0817 07:02:31.843611 20404 sgd_solver.cpp:106] Iteration 12310, lr = 0.000547804
I0817 07:03:03.253175 20404 solver.cpp:337] Iteration 12320, Testing net (#0)
I0817 07:03:37.897471 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:03:37.897645 20404 solver.cpp:404]     Test net output #1: loss = 0.670878 (* 1 = 0.670878 loss)
I0817 07:03:41.372231 20404 solver.cpp:228] Iteration 12320, loss = 0.82074
I0817 07:03:41.372285 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:03:41.372299 20404 solver.cpp:244]     Train net output #1: loss = 0.82074 (* 1 = 0.82074 loss)
I0817 07:03:41.372310 20404 sgd_solver.cpp:106] Iteration 12320, lr = 0.00054762
I0817 07:04:16.262819 20404 solver.cpp:228] Iteration 12330, loss = 0.82012
I0817 07:04:16.262918 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:04:16.262933 20404 solver.cpp:244]     Train net output #1: loss = 0.82012 (* 1 = 0.82012 loss)
I0817 07:04:16.262945 20404 sgd_solver.cpp:106] Iteration 12330, lr = 0.000547436
I0817 07:04:51.166223 20404 solver.cpp:228] Iteration 12340, loss = 0.820213
I0817 07:04:51.166321 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:04:51.166335 20404 solver.cpp:244]     Train net output #1: loss = 0.820213 (* 1 = 0.820213 loss)
I0817 07:04:51.166348 20404 sgd_solver.cpp:106] Iteration 12340, lr = 0.000547252
I0817 07:05:26.085603 20404 solver.cpp:228] Iteration 12350, loss = 0.821078
I0817 07:05:26.085716 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:05:26.085733 20404 solver.cpp:244]     Train net output #1: loss = 0.821078 (* 1 = 0.821078 loss)
I0817 07:05:26.085748 20404 sgd_solver.cpp:106] Iteration 12350, lr = 0.000547069
I0817 07:05:57.502558 20404 solver.cpp:337] Iteration 12360, Testing net (#0)
I0817 07:06:32.155827 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:06:32.155995 20404 solver.cpp:404]     Test net output #1: loss = 0.671355 (* 1 = 0.671355 loss)
I0817 07:06:35.623318 20404 solver.cpp:228] Iteration 12360, loss = 0.82013
I0817 07:06:35.623360 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:06:35.623375 20404 solver.cpp:244]     Train net output #1: loss = 0.82013 (* 1 = 0.82013 loss)
I0817 07:06:35.623388 20404 sgd_solver.cpp:106] Iteration 12360, lr = 0.000546885
I0817 07:07:10.493152 20404 solver.cpp:228] Iteration 12370, loss = 0.820426
I0817 07:07:10.493324 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:07:10.493340 20404 solver.cpp:244]     Train net output #1: loss = 0.820426 (* 1 = 0.820426 loss)
I0817 07:07:10.493352 20404 sgd_solver.cpp:106] Iteration 12370, lr = 0.000546702
I0817 07:07:45.387011 20404 solver.cpp:228] Iteration 12380, loss = 0.820638
I0817 07:07:45.387203 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:07:45.387223 20404 solver.cpp:244]     Train net output #1: loss = 0.820638 (* 1 = 0.820638 loss)
I0817 07:07:45.387234 20404 sgd_solver.cpp:106] Iteration 12380, lr = 0.000546519
I0817 07:08:20.275709 20404 solver.cpp:228] Iteration 12390, loss = 0.820238
I0817 07:08:20.275851 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:08:20.275866 20404 solver.cpp:244]     Train net output #1: loss = 0.820238 (* 1 = 0.820238 loss)
I0817 07:08:20.275879 20404 sgd_solver.cpp:106] Iteration 12390, lr = 0.000546336
I0817 07:08:51.679605 20404 solver.cpp:337] Iteration 12400, Testing net (#0)
I0817 07:09:26.342602 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:09:26.342773 20404 solver.cpp:404]     Test net output #1: loss = 0.671958 (* 1 = 0.671958 loss)
I0817 07:09:29.818059 20404 solver.cpp:228] Iteration 12400, loss = 0.820294
I0817 07:09:29.818111 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:09:29.818125 20404 solver.cpp:244]     Train net output #1: loss = 0.820294 (* 1 = 0.820294 loss)
I0817 07:09:29.818136 20404 sgd_solver.cpp:106] Iteration 12400, lr = 0.000546153
I0817 07:10:04.706526 20404 solver.cpp:228] Iteration 12410, loss = 0.820411
I0817 07:10:04.706732 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:10:04.706748 20404 solver.cpp:244]     Train net output #1: loss = 0.820411 (* 1 = 0.820411 loss)
I0817 07:10:04.706760 20404 sgd_solver.cpp:106] Iteration 12410, lr = 0.00054597
I0817 07:10:39.593348 20404 solver.cpp:228] Iteration 12420, loss = 0.82018
I0817 07:10:39.593516 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:10:39.593533 20404 solver.cpp:244]     Train net output #1: loss = 0.82018 (* 1 = 0.82018 loss)
I0817 07:10:39.593544 20404 sgd_solver.cpp:106] Iteration 12420, lr = 0.000545787
I0817 07:11:14.496208 20404 solver.cpp:228] Iteration 12430, loss = 0.820049
I0817 07:11:14.496397 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:11:14.496412 20404 solver.cpp:244]     Train net output #1: loss = 0.820049 (* 1 = 0.820049 loss)
I0817 07:11:14.496425 20404 sgd_solver.cpp:106] Iteration 12430, lr = 0.000545605
I0817 07:11:45.914387 20404 solver.cpp:337] Iteration 12440, Testing net (#0)
I0817 07:12:20.572124 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:12:20.572293 20404 solver.cpp:404]     Test net output #1: loss = 0.671573 (* 1 = 0.671573 loss)
I0817 07:12:24.046439 20404 solver.cpp:228] Iteration 12440, loss = 0.820077
I0817 07:12:24.046490 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:12:24.046504 20404 solver.cpp:244]     Train net output #1: loss = 0.820077 (* 1 = 0.820077 loss)
I0817 07:12:24.046516 20404 sgd_solver.cpp:106] Iteration 12440, lr = 0.000545422
I0817 07:12:58.944396 20404 solver.cpp:228] Iteration 12450, loss = 0.820197
I0817 07:12:58.944494 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:12:58.944509 20404 solver.cpp:244]     Train net output #1: loss = 0.820197 (* 1 = 0.820197 loss)
I0817 07:12:58.944521 20404 sgd_solver.cpp:106] Iteration 12450, lr = 0.00054524
I0817 07:13:33.822302 20404 solver.cpp:228] Iteration 12460, loss = 0.820121
I0817 07:13:33.822398 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:13:33.822417 20404 solver.cpp:244]     Train net output #1: loss = 0.820121 (* 1 = 0.820121 loss)
I0817 07:13:33.822432 20404 sgd_solver.cpp:106] Iteration 12460, lr = 0.000545058
I0817 07:14:08.720993 20404 solver.cpp:228] Iteration 12470, loss = 0.820503
I0817 07:14:08.721091 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:14:08.721112 20404 solver.cpp:244]     Train net output #1: loss = 0.820503 (* 1 = 0.820503 loss)
I0817 07:14:08.721125 20404 sgd_solver.cpp:106] Iteration 12470, lr = 0.000544876
I0817 07:14:40.125708 20404 solver.cpp:337] Iteration 12480, Testing net (#0)
I0817 07:15:14.745260 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:15:14.745467 20404 solver.cpp:404]     Test net output #1: loss = 0.671848 (* 1 = 0.671848 loss)
I0817 07:15:18.208680 20404 solver.cpp:228] Iteration 12480, loss = 0.820226
I0817 07:15:18.208730 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:15:18.208745 20404 solver.cpp:244]     Train net output #1: loss = 0.820226 (* 1 = 0.820226 loss)
I0817 07:15:18.208757 20404 sgd_solver.cpp:106] Iteration 12480, lr = 0.000544694
I0817 07:15:53.091845 20404 solver.cpp:228] Iteration 12490, loss = 0.821217
I0817 07:15:53.092030 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:15:53.092047 20404 solver.cpp:244]     Train net output #1: loss = 0.821217 (* 1 = 0.821217 loss)
I0817 07:15:53.092062 20404 sgd_solver.cpp:106] Iteration 12490, lr = 0.000544513
I0817 07:16:27.982702 20404 solver.cpp:228] Iteration 12500, loss = 0.820553
I0817 07:16:27.982875 20404 solver.cpp:244]     Train net output #0: accuracy = 0.59
I0817 07:16:27.982894 20404 solver.cpp:244]     Train net output #1: loss = 0.820553 (* 1 = 0.820553 loss)
I0817 07:16:27.982909 20404 sgd_solver.cpp:106] Iteration 12500, lr = 0.000544331
I0817 07:17:02.860843 20404 solver.cpp:228] Iteration 12510, loss = 0.820247
I0817 07:17:02.860946 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:17:02.860961 20404 solver.cpp:244]     Train net output #1: loss = 0.820247 (* 1 = 0.820247 loss)
I0817 07:17:02.860973 20404 sgd_solver.cpp:106] Iteration 12510, lr = 0.00054415
I0817 07:17:34.299105 20404 solver.cpp:337] Iteration 12520, Testing net (#0)
I0817 07:18:08.967568 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:18:08.967751 20404 solver.cpp:404]     Test net output #1: loss = 0.671197 (* 1 = 0.671197 loss)
I0817 07:18:12.444579 20404 solver.cpp:228] Iteration 12520, loss = 0.820226
I0817 07:18:12.444629 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:18:12.444643 20404 solver.cpp:244]     Train net output #1: loss = 0.820226 (* 1 = 0.820226 loss)
I0817 07:18:12.444655 20404 sgd_solver.cpp:106] Iteration 12520, lr = 0.000543969
I0817 07:18:47.311396 20404 solver.cpp:228] Iteration 12530, loss = 0.820058
I0817 07:18:47.311578 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:18:47.311594 20404 solver.cpp:244]     Train net output #1: loss = 0.820058 (* 1 = 0.820058 loss)
I0817 07:18:47.311605 20404 sgd_solver.cpp:106] Iteration 12530, lr = 0.000543787
I0817 07:19:22.224378 20404 solver.cpp:228] Iteration 12540, loss = 0.820518
I0817 07:19:22.224474 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:19:22.224489 20404 solver.cpp:244]     Train net output #1: loss = 0.820518 (* 1 = 0.820518 loss)
I0817 07:19:22.224503 20404 sgd_solver.cpp:106] Iteration 12540, lr = 0.000543606
I0817 07:19:57.103808 20404 solver.cpp:228] Iteration 12550, loss = 0.82023
I0817 07:19:57.103983 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:19:57.103999 20404 solver.cpp:244]     Train net output #1: loss = 0.82023 (* 1 = 0.82023 loss)
I0817 07:19:57.104012 20404 sgd_solver.cpp:106] Iteration 12550, lr = 0.000543426
I0817 07:20:28.535795 20404 solver.cpp:337] Iteration 12560, Testing net (#0)
I0817 07:21:03.215606 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:21:03.215775 20404 solver.cpp:404]     Test net output #1: loss = 0.671146 (* 1 = 0.671146 loss)
I0817 07:21:06.694486 20404 solver.cpp:228] Iteration 12560, loss = 0.82023
I0817 07:21:06.694538 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:21:06.694553 20404 solver.cpp:244]     Train net output #1: loss = 0.82023 (* 1 = 0.82023 loss)
I0817 07:21:06.694564 20404 sgd_solver.cpp:106] Iteration 12560, lr = 0.000543245
I0817 07:21:41.593524 20404 solver.cpp:228] Iteration 12570, loss = 0.820009
I0817 07:21:41.593700 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:21:41.593716 20404 solver.cpp:244]     Train net output #1: loss = 0.820009 (* 1 = 0.820009 loss)
I0817 07:21:41.593727 20404 sgd_solver.cpp:106] Iteration 12570, lr = 0.000543064
I0817 07:22:16.467847 20404 solver.cpp:228] Iteration 12580, loss = 0.820317
I0817 07:22:16.468063 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:22:16.468083 20404 solver.cpp:244]     Train net output #1: loss = 0.820317 (* 1 = 0.820317 loss)
I0817 07:22:16.468098 20404 sgd_solver.cpp:106] Iteration 12580, lr = 0.000542884
I0817 07:22:51.343474 20404 solver.cpp:228] Iteration 12590, loss = 0.819992
I0817 07:22:51.343621 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:22:51.343636 20404 solver.cpp:244]     Train net output #1: loss = 0.819992 (* 1 = 0.819992 loss)
I0817 07:22:51.343650 20404 sgd_solver.cpp:106] Iteration 12590, lr = 0.000542704
I0817 07:23:22.758249 20404 solver.cpp:337] Iteration 12600, Testing net (#0)
I0817 07:23:57.424113 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:23:57.424207 20404 solver.cpp:404]     Test net output #1: loss = 0.671368 (* 1 = 0.671368 loss)
I0817 07:24:00.908687 20404 solver.cpp:228] Iteration 12600, loss = 0.819772
I0817 07:24:00.908740 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:24:00.908754 20404 solver.cpp:244]     Train net output #1: loss = 0.819772 (* 1 = 0.819772 loss)
I0817 07:24:00.908767 20404 sgd_solver.cpp:106] Iteration 12600, lr = 0.000542524
I0817 07:24:35.798452 20404 solver.cpp:228] Iteration 12610, loss = 0.819542
I0817 07:24:35.798542 20404 solver.cpp:244]     Train net output #0: accuracy = 0.97
I0817 07:24:35.798557 20404 solver.cpp:244]     Train net output #1: loss = 0.819542 (* 1 = 0.819542 loss)
I0817 07:24:35.798568 20404 sgd_solver.cpp:106] Iteration 12610, lr = 0.000542344
I0817 07:25:10.706774 20404 solver.cpp:228] Iteration 12620, loss = 0.819876
I0817 07:25:10.706943 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:25:10.706959 20404 solver.cpp:244]     Train net output #1: loss = 0.819876 (* 1 = 0.819876 loss)
I0817 07:25:10.706971 20404 sgd_solver.cpp:106] Iteration 12620, lr = 0.000542164
I0817 07:25:45.596988 20404 solver.cpp:228] Iteration 12630, loss = 0.819529
I0817 07:25:45.597057 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:25:45.597071 20404 solver.cpp:244]     Train net output #1: loss = 0.819529 (* 1 = 0.819529 loss)
I0817 07:25:45.597084 20404 sgd_solver.cpp:106] Iteration 12630, lr = 0.000541984
I0817 07:26:17.008108 20404 solver.cpp:337] Iteration 12640, Testing net (#0)
I0817 07:26:51.666340 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:26:51.666504 20404 solver.cpp:404]     Test net output #1: loss = 0.672124 (* 1 = 0.672124 loss)
I0817 07:26:55.144094 20404 solver.cpp:228] Iteration 12640, loss = 0.819824
I0817 07:26:55.144147 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:26:55.144161 20404 solver.cpp:244]     Train net output #1: loss = 0.819824 (* 1 = 0.819824 loss)
I0817 07:26:55.144172 20404 sgd_solver.cpp:106] Iteration 12640, lr = 0.000541805
I0817 07:27:30.009738 20404 solver.cpp:228] Iteration 12650, loss = 0.819888
I0817 07:27:30.009907 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 07:27:30.009922 20404 solver.cpp:244]     Train net output #1: loss = 0.819888 (* 1 = 0.819888 loss)
I0817 07:27:30.009934 20404 sgd_solver.cpp:106] Iteration 12650, lr = 0.000541625
I0817 07:28:04.921535 20404 solver.cpp:228] Iteration 12660, loss = 0.820215
I0817 07:28:04.921705 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 07:28:04.921720 20404 solver.cpp:244]     Train net output #1: loss = 0.820215 (* 1 = 0.820215 loss)
I0817 07:28:04.921732 20404 sgd_solver.cpp:106] Iteration 12660, lr = 0.000541446
I0817 07:28:39.792367 20404 solver.cpp:228] Iteration 12670, loss = 0.819418
I0817 07:28:39.792541 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:28:39.792560 20404 solver.cpp:244]     Train net output #1: loss = 0.819418 (* 1 = 0.819418 loss)
I0817 07:28:39.792572 20404 sgd_solver.cpp:106] Iteration 12670, lr = 0.000541267
I0817 07:29:11.195597 20404 solver.cpp:337] Iteration 12680, Testing net (#0)
I0817 07:29:45.836669 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:29:45.836845 20404 solver.cpp:404]     Test net output #1: loss = 0.671339 (* 1 = 0.671339 loss)
I0817 07:29:49.314885 20404 solver.cpp:228] Iteration 12680, loss = 0.819722
I0817 07:29:49.314937 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:29:49.314952 20404 solver.cpp:244]     Train net output #1: loss = 0.819722 (* 1 = 0.819722 loss)
I0817 07:29:49.314963 20404 sgd_solver.cpp:106] Iteration 12680, lr = 0.000541088
I0817 07:30:24.196205 20404 solver.cpp:228] Iteration 12690, loss = 0.819352
I0817 07:30:24.196379 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:30:24.196394 20404 solver.cpp:244]     Train net output #1: loss = 0.819352 (* 1 = 0.819352 loss)
I0817 07:30:24.196408 20404 sgd_solver.cpp:106] Iteration 12690, lr = 0.000540909
I0817 07:30:59.100522 20404 solver.cpp:228] Iteration 12700, loss = 0.820165
I0817 07:30:59.100700 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:30:59.100715 20404 solver.cpp:244]     Train net output #1: loss = 0.820165 (* 1 = 0.820165 loss)
I0817 07:30:59.100728 20404 sgd_solver.cpp:106] Iteration 12700, lr = 0.00054073
I0817 07:31:34.013420 20404 solver.cpp:228] Iteration 12710, loss = 0.819491
I0817 07:31:34.013607 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 07:31:34.013622 20404 solver.cpp:244]     Train net output #1: loss = 0.819491 (* 1 = 0.819491 loss)
I0817 07:31:34.013635 20404 sgd_solver.cpp:106] Iteration 12710, lr = 0.000540552
I0817 07:32:05.416815 20404 solver.cpp:337] Iteration 12720, Testing net (#0)
I0817 07:32:40.046105 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:32:40.046283 20404 solver.cpp:404]     Test net output #1: loss = 0.671459 (* 1 = 0.671459 loss)
I0817 07:32:43.525060 20404 solver.cpp:228] Iteration 12720, loss = 0.819502
I0817 07:32:43.525107 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:32:43.525126 20404 solver.cpp:244]     Train net output #1: loss = 0.819502 (* 1 = 0.819502 loss)
I0817 07:32:43.525141 20404 sgd_solver.cpp:106] Iteration 12720, lr = 0.000540373
I0817 07:33:18.404855 20404 solver.cpp:228] Iteration 12730, loss = 0.819594
I0817 07:33:18.405036 20404 solver.cpp:244]     Train net output #0: accuracy = 0.6
I0817 07:33:18.405055 20404 solver.cpp:244]     Train net output #1: loss = 0.819594 (* 1 = 0.819594 loss)
I0817 07:33:18.405071 20404 sgd_solver.cpp:106] Iteration 12730, lr = 0.000540195
I0817 07:33:53.294438 20404 solver.cpp:228] Iteration 12740, loss = 0.819775
I0817 07:33:53.294615 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:33:53.294632 20404 solver.cpp:244]     Train net output #1: loss = 0.819775 (* 1 = 0.819775 loss)
I0817 07:33:53.294644 20404 sgd_solver.cpp:106] Iteration 12740, lr = 0.000540017
I0817 07:34:28.194375 20404 solver.cpp:228] Iteration 12750, loss = 0.82031
I0817 07:34:28.194555 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:34:28.194569 20404 solver.cpp:244]     Train net output #1: loss = 0.82031 (* 1 = 0.82031 loss)
I0817 07:34:28.194581 20404 sgd_solver.cpp:106] Iteration 12750, lr = 0.000539839
I0817 07:34:59.621747 20404 solver.cpp:337] Iteration 12760, Testing net (#0)
I0817 07:35:34.270500 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:35:34.270679 20404 solver.cpp:404]     Test net output #1: loss = 0.670548 (* 1 = 0.670548 loss)
I0817 07:35:37.752431 20404 solver.cpp:228] Iteration 12760, loss = 0.820208
I0817 07:35:37.752478 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 07:35:37.752497 20404 solver.cpp:244]     Train net output #1: loss = 0.820208 (* 1 = 0.820208 loss)
I0817 07:35:37.752513 20404 sgd_solver.cpp:106] Iteration 12760, lr = 0.000539661
I0817 07:36:12.646119 20404 solver.cpp:228] Iteration 12770, loss = 0.819482
I0817 07:36:12.646297 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:36:12.646317 20404 solver.cpp:244]     Train net output #1: loss = 0.819482 (* 1 = 0.819482 loss)
I0817 07:36:12.646332 20404 sgd_solver.cpp:106] Iteration 12770, lr = 0.000539483
I0817 07:36:47.543552 20404 solver.cpp:228] Iteration 12780, loss = 0.819057
I0817 07:36:47.543772 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 07:36:47.543789 20404 solver.cpp:244]     Train net output #1: loss = 0.819057 (* 1 = 0.819057 loss)
I0817 07:36:47.543802 20404 sgd_solver.cpp:106] Iteration 12780, lr = 0.000539305
I0817 07:37:22.440603 20404 solver.cpp:228] Iteration 12790, loss = 0.819511
I0817 07:37:22.440788 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:37:22.440803 20404 solver.cpp:244]     Train net output #1: loss = 0.819511 (* 1 = 0.819511 loss)
I0817 07:37:22.440814 20404 sgd_solver.cpp:106] Iteration 12790, lr = 0.000539128
I0817 07:37:53.842735 20404 solver.cpp:337] Iteration 12800, Testing net (#0)
I0817 07:38:28.508890 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:38:28.509064 20404 solver.cpp:404]     Test net output #1: loss = 0.672058 (* 1 = 0.672058 loss)
I0817 07:38:31.978153 20404 solver.cpp:228] Iteration 12800, loss = 0.819144
I0817 07:38:31.978204 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:38:31.978217 20404 solver.cpp:244]     Train net output #1: loss = 0.819144 (* 1 = 0.819144 loss)
I0817 07:38:31.978229 20404 sgd_solver.cpp:106] Iteration 12800, lr = 0.00053895
I0817 07:39:06.853760 20404 solver.cpp:228] Iteration 12810, loss = 0.819166
I0817 07:39:06.853945 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 07:39:06.853960 20404 solver.cpp:244]     Train net output #1: loss = 0.819166 (* 1 = 0.819166 loss)
I0817 07:39:06.853973 20404 sgd_solver.cpp:106] Iteration 12810, lr = 0.000538773
I0817 07:39:41.736444 20404 solver.cpp:228] Iteration 12820, loss = 0.819319
I0817 07:39:41.736624 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 07:39:41.736644 20404 solver.cpp:244]     Train net output #1: loss = 0.819319 (* 1 = 0.819319 loss)
I0817 07:39:41.736659 20404 sgd_solver.cpp:106] Iteration 12820, lr = 0.000538596
I0817 07:40:16.625216 20404 solver.cpp:228] Iteration 12830, loss = 0.8192
I0817 07:40:16.625397 20404 solver.cpp:244]     Train net output #0: accuracy = 0.71
I0817 07:40:16.625416 20404 solver.cpp:244]     Train net output #1: loss = 0.8192 (* 1 = 0.8192 loss)
I0817 07:40:16.625432 20404 sgd_solver.cpp:106] Iteration 12830, lr = 0.000538419
I0817 07:40:48.049154 20404 solver.cpp:337] Iteration 12840, Testing net (#0)
I0817 07:41:22.699508 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:41:22.699694 20404 solver.cpp:404]     Test net output #1: loss = 0.671994 (* 1 = 0.671994 loss)
I0817 07:41:26.178215 20404 solver.cpp:228] Iteration 12840, loss = 0.819368
I0817 07:41:26.178273 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:41:26.178288 20404 solver.cpp:244]     Train net output #1: loss = 0.819368 (* 1 = 0.819368 loss)
I0817 07:41:26.178300 20404 sgd_solver.cpp:106] Iteration 12840, lr = 0.000538242
I0817 07:42:01.081076 20404 solver.cpp:228] Iteration 12850, loss = 0.818934
I0817 07:42:01.081260 20404 solver.cpp:244]     Train net output #0: accuracy = 0.87
I0817 07:42:01.081276 20404 solver.cpp:244]     Train net output #1: loss = 0.818934 (* 1 = 0.818934 loss)
I0817 07:42:01.081290 20404 sgd_solver.cpp:106] Iteration 12850, lr = 0.000538066
I0817 07:42:35.972491 20404 solver.cpp:228] Iteration 12860, loss = 0.819724
I0817 07:42:35.972658 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 07:42:35.972674 20404 solver.cpp:244]     Train net output #1: loss = 0.819724 (* 1 = 0.819724 loss)
I0817 07:42:35.972687 20404 sgd_solver.cpp:106] Iteration 12860, lr = 0.000537889
I0817 07:43:10.848449 20404 solver.cpp:228] Iteration 12870, loss = 0.818899
I0817 07:43:10.848610 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 07:43:10.848625 20404 solver.cpp:244]     Train net output #1: loss = 0.818899 (* 1 = 0.818899 loss)
I0817 07:43:10.848637 20404 sgd_solver.cpp:106] Iteration 12870, lr = 0.000537713
I0817 07:43:42.243190 20404 solver.cpp:337] Iteration 12880, Testing net (#0)
I0817 07:44:16.886795 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:44:16.886970 20404 solver.cpp:404]     Test net output #1: loss = 0.671463 (* 1 = 0.671463 loss)
I0817 07:44:20.360541 20404 solver.cpp:228] Iteration 12880, loss = 0.819272
I0817 07:44:20.360602 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 07:44:20.360616 20404 solver.cpp:244]     Train net output #1: loss = 0.819272 (* 1 = 0.819272 loss)
I0817 07:44:20.360630 20404 sgd_solver.cpp:106] Iteration 12880, lr = 0.000537537
I0817 07:44:55.241284 20404 solver.cpp:228] Iteration 12890, loss = 0.81903
I0817 07:44:55.241466 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 07:44:55.241482 20404 solver.cpp:244]     Train net output #1: loss = 0.81903 (* 1 = 0.81903 loss)
I0817 07:44:55.241493 20404 sgd_solver.cpp:106] Iteration 12890, lr = 0.00053736
I0817 07:45:30.147908 20404 solver.cpp:228] Iteration 12900, loss = 0.819131
I0817 07:45:30.148087 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:45:30.148103 20404 solver.cpp:244]     Train net output #1: loss = 0.819131 (* 1 = 0.819131 loss)
I0817 07:45:30.148115 20404 sgd_solver.cpp:106] Iteration 12900, lr = 0.000537184
I0817 07:46:05.031520 20404 solver.cpp:228] Iteration 12910, loss = 0.818991
I0817 07:46:05.031692 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:46:05.031708 20404 solver.cpp:244]     Train net output #1: loss = 0.818991 (* 1 = 0.818991 loss)
I0817 07:46:05.031720 20404 sgd_solver.cpp:106] Iteration 12910, lr = 0.000537009
I0817 07:46:36.423724 20404 solver.cpp:337] Iteration 12920, Testing net (#0)
I0817 07:47:11.069615 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:47:11.069787 20404 solver.cpp:404]     Test net output #1: loss = 0.670949 (* 1 = 0.670949 loss)
I0817 07:47:14.547646 20404 solver.cpp:228] Iteration 12920, loss = 0.819679
I0817 07:47:14.547688 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 07:47:14.547703 20404 solver.cpp:244]     Train net output #1: loss = 0.819679 (* 1 = 0.819679 loss)
I0817 07:47:14.547714 20404 sgd_solver.cpp:106] Iteration 12920, lr = 0.000536833
I0817 07:47:49.432005 20404 solver.cpp:228] Iteration 12930, loss = 0.819768
I0817 07:47:49.432196 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 07:47:49.432214 20404 solver.cpp:244]     Train net output #1: loss = 0.819768 (* 1 = 0.819768 loss)
I0817 07:47:49.432225 20404 sgd_solver.cpp:106] Iteration 12930, lr = 0.000536657
I0817 07:48:24.332639 20404 solver.cpp:228] Iteration 12940, loss = 0.818731
I0817 07:48:24.332824 20404 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0817 07:48:24.332840 20404 solver.cpp:244]     Train net output #1: loss = 0.818731 (* 1 = 0.818731 loss)
I0817 07:48:24.332852 20404 sgd_solver.cpp:106] Iteration 12940, lr = 0.000536482
I0817 07:48:59.222112 20404 solver.cpp:228] Iteration 12950, loss = 0.819356
I0817 07:48:59.222295 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 07:48:59.222309 20404 solver.cpp:244]     Train net output #1: loss = 0.819356 (* 1 = 0.819356 loss)
I0817 07:48:59.222322 20404 sgd_solver.cpp:106] Iteration 12950, lr = 0.000536306
I0817 07:49:30.640768 20404 solver.cpp:337] Iteration 12960, Testing net (#0)
I0817 07:50:05.283112 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:50:05.283306 20404 solver.cpp:404]     Test net output #1: loss = 0.672157 (* 1 = 0.672157 loss)
I0817 07:50:08.760512 20404 solver.cpp:228] Iteration 12960, loss = 0.819033
I0817 07:50:08.760565 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:50:08.760578 20404 solver.cpp:244]     Train net output #1: loss = 0.819033 (* 1 = 0.819033 loss)
I0817 07:50:08.760589 20404 sgd_solver.cpp:106] Iteration 12960, lr = 0.000536131
I0817 07:50:43.642920 20404 solver.cpp:228] Iteration 12970, loss = 0.818891
I0817 07:50:43.643136 20404 solver.cpp:244]     Train net output #0: accuracy = 0.72
I0817 07:50:43.643154 20404 solver.cpp:244]     Train net output #1: loss = 0.818891 (* 1 = 0.818891 loss)
I0817 07:50:43.643167 20404 sgd_solver.cpp:106] Iteration 12970, lr = 0.000535956
I0817 07:51:18.546667 20404 solver.cpp:228] Iteration 12980, loss = 0.819243
I0817 07:51:18.546852 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 07:51:18.546867 20404 solver.cpp:244]     Train net output #1: loss = 0.819243 (* 1 = 0.819243 loss)
I0817 07:51:18.546880 20404 sgd_solver.cpp:106] Iteration 12980, lr = 0.000535781
I0817 07:51:53.444727 20404 solver.cpp:228] Iteration 12990, loss = 0.819441
I0817 07:51:53.444905 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 07:51:53.444924 20404 solver.cpp:244]     Train net output #1: loss = 0.819441 (* 1 = 0.819441 loss)
I0817 07:51:53.444936 20404 sgd_solver.cpp:106] Iteration 12990, lr = 0.000535606
I0817 07:52:24.872344 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_13000.caffemodel
I0817 07:52:36.010356 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_13000.solverstate
I0817 07:52:37.686949 20404 solver.cpp:337] Iteration 13000, Testing net (#0)
I0817 07:53:12.322628 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:53:12.322811 20404 solver.cpp:404]     Test net output #1: loss = 0.671542 (* 1 = 0.671542 loss)
I0817 07:53:15.799476 20404 solver.cpp:228] Iteration 13000, loss = 0.818839
I0817 07:53:15.799528 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 07:53:15.799542 20404 solver.cpp:244]     Train net output #1: loss = 0.818839 (* 1 = 0.818839 loss)
I0817 07:53:15.799553 20404 sgd_solver.cpp:106] Iteration 13000, lr = 0.000535432
I0817 07:53:50.677855 20404 solver.cpp:228] Iteration 13010, loss = 0.819119
I0817 07:53:50.678035 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:53:50.678050 20404 solver.cpp:244]     Train net output #1: loss = 0.819119 (* 1 = 0.819119 loss)
I0817 07:53:50.678063 20404 sgd_solver.cpp:106] Iteration 13010, lr = 0.000535257
I0817 07:54:25.562723 20404 solver.cpp:228] Iteration 13020, loss = 0.818733
I0817 07:54:25.562897 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:54:25.562913 20404 solver.cpp:244]     Train net output #1: loss = 0.818733 (* 1 = 0.818733 loss)
I0817 07:54:25.562925 20404 sgd_solver.cpp:106] Iteration 13020, lr = 0.000535083
I0817 07:55:00.456774 20404 solver.cpp:228] Iteration 13030, loss = 0.818953
I0817 07:55:00.456959 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:55:00.456974 20404 solver.cpp:244]     Train net output #1: loss = 0.818953 (* 1 = 0.818953 loss)
I0817 07:55:00.456985 20404 sgd_solver.cpp:106] Iteration 13030, lr = 0.000534909
I0817 07:55:31.863751 20404 solver.cpp:337] Iteration 13040, Testing net (#0)
I0817 07:56:06.498134 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:56:06.498307 20404 solver.cpp:404]     Test net output #1: loss = 0.671349 (* 1 = 0.671349 loss)
I0817 07:56:09.965680 20404 solver.cpp:228] Iteration 13040, loss = 0.819154
I0817 07:56:09.965733 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:56:09.965747 20404 solver.cpp:244]     Train net output #1: loss = 0.819154 (* 1 = 0.819154 loss)
I0817 07:56:09.965759 20404 sgd_solver.cpp:106] Iteration 13040, lr = 0.000534734
I0817 07:56:44.854806 20404 solver.cpp:228] Iteration 13050, loss = 0.819298
I0817 07:56:44.854976 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 07:56:44.854991 20404 solver.cpp:244]     Train net output #1: loss = 0.819298 (* 1 = 0.819298 loss)
I0817 07:56:44.855003 20404 sgd_solver.cpp:106] Iteration 13050, lr = 0.00053456
I0817 07:57:19.764139 20404 solver.cpp:228] Iteration 13060, loss = 0.818627
I0817 07:57:19.764309 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 07:57:19.764324 20404 solver.cpp:244]     Train net output #1: loss = 0.818627 (* 1 = 0.818627 loss)
I0817 07:57:19.764338 20404 sgd_solver.cpp:106] Iteration 13060, lr = 0.000534387
I0817 07:57:54.652132 20404 solver.cpp:228] Iteration 13070, loss = 0.819319
I0817 07:57:54.652348 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 07:57:54.652364 20404 solver.cpp:244]     Train net output #1: loss = 0.819319 (* 1 = 0.819319 loss)
I0817 07:57:54.652376 20404 sgd_solver.cpp:106] Iteration 13070, lr = 0.000534213
I0817 07:58:26.073218 20404 solver.cpp:337] Iteration 13080, Testing net (#0)
I0817 07:59:00.732341 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 07:59:00.732522 20404 solver.cpp:404]     Test net output #1: loss = 0.670981 (* 1 = 0.670981 loss)
I0817 07:59:04.204846 20404 solver.cpp:228] Iteration 13080, loss = 0.819533
I0817 07:59:04.204900 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 07:59:04.204915 20404 solver.cpp:244]     Train net output #1: loss = 0.819533 (* 1 = 0.819533 loss)
I0817 07:59:04.204926 20404 sgd_solver.cpp:106] Iteration 13080, lr = 0.000534039
I0817 07:59:39.096820 20404 solver.cpp:228] Iteration 13090, loss = 0.818618
I0817 07:59:39.096992 20404 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0817 07:59:39.097007 20404 solver.cpp:244]     Train net output #1: loss = 0.818618 (* 1 = 0.818618 loss)
I0817 07:59:39.097020 20404 sgd_solver.cpp:106] Iteration 13090, lr = 0.000533866
I0817 08:00:13.967258 20404 solver.cpp:228] Iteration 13100, loss = 0.818891
I0817 08:00:13.967435 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:00:13.967452 20404 solver.cpp:244]     Train net output #1: loss = 0.818891 (* 1 = 0.818891 loss)
I0817 08:00:13.967463 20404 sgd_solver.cpp:106] Iteration 13100, lr = 0.000533692
I0817 08:00:48.853793 20404 solver.cpp:228] Iteration 13110, loss = 0.818717
I0817 08:00:48.853967 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:00:48.853982 20404 solver.cpp:244]     Train net output #1: loss = 0.818717 (* 1 = 0.818717 loss)
I0817 08:00:48.853994 20404 sgd_solver.cpp:106] Iteration 13110, lr = 0.000533519
I0817 08:01:20.275240 20404 solver.cpp:337] Iteration 13120, Testing net (#0)
I0817 08:01:54.931337 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:01:54.931502 20404 solver.cpp:404]     Test net output #1: loss = 0.67155 (* 1 = 0.67155 loss)
I0817 08:01:58.407843 20404 solver.cpp:228] Iteration 13120, loss = 0.818934
I0817 08:01:58.407893 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 08:01:58.407908 20404 solver.cpp:244]     Train net output #1: loss = 0.818934 (* 1 = 0.818934 loss)
I0817 08:01:58.407919 20404 sgd_solver.cpp:106] Iteration 13120, lr = 0.000533346
I0817 08:02:33.295352 20404 solver.cpp:228] Iteration 13130, loss = 0.818682
I0817 08:02:33.295439 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:02:33.295454 20404 solver.cpp:244]     Train net output #1: loss = 0.818682 (* 1 = 0.818682 loss)
I0817 08:02:33.295466 20404 sgd_solver.cpp:106] Iteration 13130, lr = 0.000533173
I0817 08:03:08.179869 20404 solver.cpp:228] Iteration 13140, loss = 0.81868
I0817 08:03:08.180047 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:03:08.180063 20404 solver.cpp:244]     Train net output #1: loss = 0.81868 (* 1 = 0.81868 loss)
I0817 08:03:08.180075 20404 sgd_solver.cpp:106] Iteration 13140, lr = 0.000533
I0817 08:03:43.083456 20404 solver.cpp:228] Iteration 13150, loss = 0.81843
I0817 08:03:43.083644 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:03:43.083660 20404 solver.cpp:244]     Train net output #1: loss = 0.81843 (* 1 = 0.81843 loss)
I0817 08:03:43.083673 20404 sgd_solver.cpp:106] Iteration 13150, lr = 0.000532828
I0817 08:04:14.489827 20404 solver.cpp:337] Iteration 13160, Testing net (#0)
I0817 08:04:49.086441 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:04:49.086616 20404 solver.cpp:404]     Test net output #1: loss = 0.6715 (* 1 = 0.6715 loss)
I0817 08:04:52.558898 20404 solver.cpp:228] Iteration 13160, loss = 0.81898
I0817 08:04:52.558960 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:04:52.558977 20404 solver.cpp:244]     Train net output #1: loss = 0.81898 (* 1 = 0.81898 loss)
I0817 08:04:52.558991 20404 sgd_solver.cpp:106] Iteration 13160, lr = 0.000532655
I0817 08:05:27.392979 20404 solver.cpp:228] Iteration 13170, loss = 0.81873
I0817 08:05:27.393111 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:05:27.393126 20404 solver.cpp:244]     Train net output #1: loss = 0.81873 (* 1 = 0.81873 loss)
I0817 08:05:27.393138 20404 sgd_solver.cpp:106] Iteration 13170, lr = 0.000532483
I0817 08:06:02.273277 20404 solver.cpp:228] Iteration 13180, loss = 0.818539
I0817 08:06:02.273453 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 08:06:02.273469 20404 solver.cpp:244]     Train net output #1: loss = 0.818539 (* 1 = 0.818539 loss)
I0817 08:06:02.273481 20404 sgd_solver.cpp:106] Iteration 13180, lr = 0.00053231
I0817 08:06:37.151577 20404 solver.cpp:228] Iteration 13190, loss = 0.819816
I0817 08:06:37.151762 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 08:06:37.151777 20404 solver.cpp:244]     Train net output #1: loss = 0.819816 (* 1 = 0.819816 loss)
I0817 08:06:37.151790 20404 sgd_solver.cpp:106] Iteration 13190, lr = 0.000532138
I0817 08:07:08.557618 20404 solver.cpp:337] Iteration 13200, Testing net (#0)
I0817 08:07:43.200696 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:07:43.200867 20404 solver.cpp:404]     Test net output #1: loss = 0.671921 (* 1 = 0.671921 loss)
I0817 08:07:46.681692 20404 solver.cpp:228] Iteration 13200, loss = 0.818489
I0817 08:07:46.681741 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:07:46.681756 20404 solver.cpp:244]     Train net output #1: loss = 0.818489 (* 1 = 0.818489 loss)
I0817 08:07:46.681767 20404 sgd_solver.cpp:106] Iteration 13200, lr = 0.000531966
I0817 08:08:21.582487 20404 solver.cpp:228] Iteration 13210, loss = 0.818722
I0817 08:08:21.582666 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:08:21.582682 20404 solver.cpp:244]     Train net output #1: loss = 0.818722 (* 1 = 0.818722 loss)
I0817 08:08:21.582695 20404 sgd_solver.cpp:106] Iteration 13210, lr = 0.000531794
I0817 08:08:56.471668 20404 solver.cpp:228] Iteration 13220, loss = 0.818508
I0817 08:08:56.471846 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 08:08:56.471861 20404 solver.cpp:244]     Train net output #1: loss = 0.818508 (* 1 = 0.818508 loss)
I0817 08:08:56.471874 20404 sgd_solver.cpp:106] Iteration 13220, lr = 0.000531622
I0817 08:09:31.334755 20404 solver.cpp:228] Iteration 13230, loss = 0.818703
I0817 08:09:31.335000 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:09:31.335018 20404 solver.cpp:244]     Train net output #1: loss = 0.818703 (* 1 = 0.818703 loss)
I0817 08:09:31.335033 20404 sgd_solver.cpp:106] Iteration 13230, lr = 0.000531451
I0817 08:10:02.754221 20404 solver.cpp:337] Iteration 13240, Testing net (#0)
I0817 08:10:37.399639 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:10:37.399727 20404 solver.cpp:404]     Test net output #1: loss = 0.671812 (* 1 = 0.671812 loss)
I0817 08:10:40.880404 20404 solver.cpp:228] Iteration 13240, loss = 0.818475
I0817 08:10:40.880455 20404 solver.cpp:244]     Train net output #0: accuracy = 0.74
I0817 08:10:40.880470 20404 solver.cpp:244]     Train net output #1: loss = 0.818475 (* 1 = 0.818475 loss)
I0817 08:10:40.880481 20404 sgd_solver.cpp:106] Iteration 13240, lr = 0.000531279
I0817 08:11:15.762765 20404 solver.cpp:228] Iteration 13250, loss = 0.818556
I0817 08:11:15.762945 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:11:15.762961 20404 solver.cpp:244]     Train net output #1: loss = 0.818556 (* 1 = 0.818556 loss)
I0817 08:11:15.762974 20404 sgd_solver.cpp:106] Iteration 13250, lr = 0.000531108
I0817 08:11:50.651126 20404 solver.cpp:228] Iteration 13260, loss = 0.818824
I0817 08:11:50.651232 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:11:50.651247 20404 solver.cpp:244]     Train net output #1: loss = 0.818824 (* 1 = 0.818824 loss)
I0817 08:11:50.651258 20404 sgd_solver.cpp:106] Iteration 13260, lr = 0.000530937
I0817 08:12:25.501845 20404 solver.cpp:228] Iteration 13270, loss = 0.81833
I0817 08:12:25.502061 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 08:12:25.502081 20404 solver.cpp:244]     Train net output #1: loss = 0.81833 (* 1 = 0.81833 loss)
I0817 08:12:25.502094 20404 sgd_solver.cpp:106] Iteration 13270, lr = 0.000530766
I0817 08:12:56.919589 20404 solver.cpp:337] Iteration 13280, Testing net (#0)
I0817 08:13:31.573894 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:13:31.574071 20404 solver.cpp:404]     Test net output #1: loss = 0.672302 (* 1 = 0.672302 loss)
I0817 08:13:35.053324 20404 solver.cpp:228] Iteration 13280, loss = 0.818722
I0817 08:13:35.053375 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:13:35.053388 20404 solver.cpp:244]     Train net output #1: loss = 0.818722 (* 1 = 0.818722 loss)
I0817 08:13:35.053401 20404 sgd_solver.cpp:106] Iteration 13280, lr = 0.000530595
I0817 08:14:09.929651 20404 solver.cpp:228] Iteration 13290, loss = 0.818854
I0817 08:14:09.929831 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:14:09.929849 20404 solver.cpp:244]     Train net output #1: loss = 0.818854 (* 1 = 0.818854 loss)
I0817 08:14:09.929862 20404 sgd_solver.cpp:106] Iteration 13290, lr = 0.000530424
I0817 08:14:44.835021 20404 solver.cpp:228] Iteration 13300, loss = 0.818965
I0817 08:14:44.835192 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:14:44.835209 20404 solver.cpp:244]     Train net output #1: loss = 0.818965 (* 1 = 0.818965 loss)
I0817 08:14:44.835222 20404 sgd_solver.cpp:106] Iteration 13300, lr = 0.000530253
I0817 08:15:19.733119 20404 solver.cpp:228] Iteration 13310, loss = 0.819869
I0817 08:15:19.733295 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 08:15:19.733311 20404 solver.cpp:244]     Train net output #1: loss = 0.819869 (* 1 = 0.819869 loss)
I0817 08:15:19.733324 20404 sgd_solver.cpp:106] Iteration 13310, lr = 0.000530082
I0817 08:15:51.147876 20404 solver.cpp:337] Iteration 13320, Testing net (#0)
I0817 08:16:25.787607 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:16:25.787776 20404 solver.cpp:404]     Test net output #1: loss = 0.671388 (* 1 = 0.671388 loss)
I0817 08:16:29.267664 20404 solver.cpp:228] Iteration 13320, loss = 0.818717
I0817 08:16:29.267716 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 08:16:29.267730 20404 solver.cpp:244]     Train net output #1: loss = 0.818717 (* 1 = 0.818717 loss)
I0817 08:16:29.267742 20404 sgd_solver.cpp:106] Iteration 13320, lr = 0.000529912
I0817 08:17:04.147194 20404 solver.cpp:228] Iteration 13330, loss = 0.818349
I0817 08:17:04.147368 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:17:04.147388 20404 solver.cpp:244]     Train net output #1: loss = 0.818349 (* 1 = 0.818349 loss)
I0817 08:17:04.147400 20404 sgd_solver.cpp:106] Iteration 13330, lr = 0.000529741
I0817 08:17:39.047356 20404 solver.cpp:228] Iteration 13340, loss = 0.818598
I0817 08:17:39.047534 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:17:39.047549 20404 solver.cpp:244]     Train net output #1: loss = 0.818598 (* 1 = 0.818598 loss)
I0817 08:17:39.047561 20404 sgd_solver.cpp:106] Iteration 13340, lr = 0.000529571
I0817 08:18:13.957805 20404 solver.cpp:228] Iteration 13350, loss = 0.818547
I0817 08:18:13.957974 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:18:13.957990 20404 solver.cpp:244]     Train net output #1: loss = 0.818547 (* 1 = 0.818547 loss)
I0817 08:18:13.958003 20404 sgd_solver.cpp:106] Iteration 13350, lr = 0.000529401
I0817 08:18:45.362133 20404 solver.cpp:337] Iteration 13360, Testing net (#0)
I0817 08:19:20.019474 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:19:20.019672 20404 solver.cpp:404]     Test net output #1: loss = 0.671738 (* 1 = 0.671738 loss)
I0817 08:19:23.484534 20404 solver.cpp:228] Iteration 13360, loss = 0.818482
I0817 08:19:23.484592 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:19:23.484606 20404 solver.cpp:244]     Train net output #1: loss = 0.818482 (* 1 = 0.818482 loss)
I0817 08:19:23.484619 20404 sgd_solver.cpp:106] Iteration 13360, lr = 0.000529231
I0817 08:19:58.360630 20404 solver.cpp:228] Iteration 13370, loss = 0.81932
I0817 08:19:58.360803 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:19:58.360819 20404 solver.cpp:244]     Train net output #1: loss = 0.81932 (* 1 = 0.81932 loss)
I0817 08:19:58.360831 20404 sgd_solver.cpp:106] Iteration 13370, lr = 0.000529061
I0817 08:20:33.258770 20404 solver.cpp:228] Iteration 13380, loss = 0.818316
I0817 08:20:33.258944 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:20:33.258960 20404 solver.cpp:244]     Train net output #1: loss = 0.818316 (* 1 = 0.818316 loss)
I0817 08:20:33.258971 20404 sgd_solver.cpp:106] Iteration 13380, lr = 0.000528892
I0817 08:21:08.136349 20404 solver.cpp:228] Iteration 13390, loss = 0.818523
I0817 08:21:08.136512 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:21:08.136526 20404 solver.cpp:244]     Train net output #1: loss = 0.818523 (* 1 = 0.818523 loss)
I0817 08:21:08.136539 20404 sgd_solver.cpp:106] Iteration 13390, lr = 0.000528722
I0817 08:21:39.558974 20404 solver.cpp:337] Iteration 13400, Testing net (#0)
I0817 08:22:14.206830 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:22:14.207003 20404 solver.cpp:404]     Test net output #1: loss = 0.672352 (* 1 = 0.672352 loss)
I0817 08:22:17.689069 20404 solver.cpp:228] Iteration 13400, loss = 0.818692
I0817 08:22:17.689123 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:22:17.689138 20404 solver.cpp:244]     Train net output #1: loss = 0.818692 (* 1 = 0.818692 loss)
I0817 08:22:17.689151 20404 sgd_solver.cpp:106] Iteration 13400, lr = 0.000528553
I0817 08:22:52.562774 20404 solver.cpp:228] Iteration 13410, loss = 0.818255
I0817 08:22:52.562944 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:22:52.562959 20404 solver.cpp:244]     Train net output #1: loss = 0.818255 (* 1 = 0.818255 loss)
I0817 08:22:52.562973 20404 sgd_solver.cpp:106] Iteration 13410, lr = 0.000528383
I0817 08:23:27.436064 20404 solver.cpp:228] Iteration 13420, loss = 0.818755
I0817 08:23:27.436245 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:23:27.436264 20404 solver.cpp:244]     Train net output #1: loss = 0.818755 (* 1 = 0.818755 loss)
I0817 08:23:27.436280 20404 sgd_solver.cpp:106] Iteration 13420, lr = 0.000528214
I0817 08:24:02.330832 20404 solver.cpp:228] Iteration 13430, loss = 0.819083
I0817 08:24:02.331012 20404 solver.cpp:244]     Train net output #0: accuracy = 0.61
I0817 08:24:02.331032 20404 solver.cpp:244]     Train net output #1: loss = 0.819083 (* 1 = 0.819083 loss)
I0817 08:24:02.331048 20404 sgd_solver.cpp:106] Iteration 13430, lr = 0.000528045
I0817 08:24:33.757459 20404 solver.cpp:337] Iteration 13440, Testing net (#0)
I0817 08:25:08.415321 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:25:08.415406 20404 solver.cpp:404]     Test net output #1: loss = 0.672387 (* 1 = 0.672387 loss)
I0817 08:25:11.893640 20404 solver.cpp:228] Iteration 13440, loss = 0.818226
I0817 08:25:11.893692 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:25:11.893705 20404 solver.cpp:244]     Train net output #1: loss = 0.818226 (* 1 = 0.818226 loss)
I0817 08:25:11.893717 20404 sgd_solver.cpp:106] Iteration 13440, lr = 0.000527876
I0817 08:25:46.779269 20404 solver.cpp:228] Iteration 13450, loss = 0.818723
I0817 08:25:46.779448 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:25:46.779466 20404 solver.cpp:244]     Train net output #1: loss = 0.818723 (* 1 = 0.818723 loss)
I0817 08:25:46.779479 20404 sgd_solver.cpp:106] Iteration 13450, lr = 0.000527707
I0817 08:26:21.670481 20404 solver.cpp:228] Iteration 13460, loss = 0.818881
I0817 08:26:21.670691 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:26:21.670706 20404 solver.cpp:244]     Train net output #1: loss = 0.818881 (* 1 = 0.818881 loss)
I0817 08:26:21.670718 20404 sgd_solver.cpp:106] Iteration 13460, lr = 0.000527538
I0817 08:26:56.555140 20404 solver.cpp:228] Iteration 13470, loss = 0.818962
I0817 08:26:56.555322 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:26:56.555338 20404 solver.cpp:244]     Train net output #1: loss = 0.818962 (* 1 = 0.818962 loss)
I0817 08:26:56.555351 20404 sgd_solver.cpp:106] Iteration 13470, lr = 0.00052737
I0817 08:27:27.969638 20404 solver.cpp:337] Iteration 13480, Testing net (#0)
I0817 08:28:02.620007 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:28:02.620182 20404 solver.cpp:404]     Test net output #1: loss = 0.671892 (* 1 = 0.671892 loss)
I0817 08:28:06.089902 20404 solver.cpp:228] Iteration 13480, loss = 0.818182
I0817 08:28:06.089951 20404 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0817 08:28:06.089967 20404 solver.cpp:244]     Train net output #1: loss = 0.818182 (* 1 = 0.818182 loss)
I0817 08:28:06.089978 20404 sgd_solver.cpp:106] Iteration 13480, lr = 0.000527201
I0817 08:28:40.971810 20404 solver.cpp:228] Iteration 13490, loss = 0.81898
I0817 08:28:40.971992 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 08:28:40.972007 20404 solver.cpp:244]     Train net output #1: loss = 0.81898 (* 1 = 0.81898 loss)
I0817 08:28:40.972020 20404 sgd_solver.cpp:106] Iteration 13490, lr = 0.000527033
I0817 08:29:15.873198 20404 solver.cpp:228] Iteration 13500, loss = 0.818115
I0817 08:29:15.873373 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:29:15.873389 20404 solver.cpp:244]     Train net output #1: loss = 0.818115 (* 1 = 0.818115 loss)
I0817 08:29:15.873401 20404 sgd_solver.cpp:106] Iteration 13500, lr = 0.000526865
I0817 08:29:50.751005 20404 solver.cpp:228] Iteration 13510, loss = 0.818135
I0817 08:29:50.751183 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:29:50.751197 20404 solver.cpp:244]     Train net output #1: loss = 0.818135 (* 1 = 0.818135 loss)
I0817 08:29:50.751210 20404 sgd_solver.cpp:106] Iteration 13510, lr = 0.000526697
I0817 08:30:22.179905 20404 solver.cpp:337] Iteration 13520, Testing net (#0)
I0817 08:30:56.832763 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:30:56.832931 20404 solver.cpp:404]     Test net output #1: loss = 0.672094 (* 1 = 0.672094 loss)
I0817 08:31:00.311070 20404 solver.cpp:228] Iteration 13520, loss = 0.818363
I0817 08:31:00.311121 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:31:00.311136 20404 solver.cpp:244]     Train net output #1: loss = 0.818363 (* 1 = 0.818363 loss)
I0817 08:31:00.311147 20404 sgd_solver.cpp:106] Iteration 13520, lr = 0.000526529
I0817 08:31:35.162448 20404 solver.cpp:228] Iteration 13530, loss = 0.818659
I0817 08:31:35.162632 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:31:35.162648 20404 solver.cpp:244]     Train net output #1: loss = 0.818659 (* 1 = 0.818659 loss)
I0817 08:31:35.162662 20404 sgd_solver.cpp:106] Iteration 13530, lr = 0.000526361
I0817 08:32:10.070157 20404 solver.cpp:228] Iteration 13540, loss = 0.817822
I0817 08:32:10.070336 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:32:10.070353 20404 solver.cpp:244]     Train net output #1: loss = 0.817822 (* 1 = 0.817822 loss)
I0817 08:32:10.070364 20404 sgd_solver.cpp:106] Iteration 13540, lr = 0.000526193
I0817 08:32:44.958246 20404 solver.cpp:228] Iteration 13550, loss = 0.818225
I0817 08:32:44.958358 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 08:32:44.958374 20404 solver.cpp:244]     Train net output #1: loss = 0.818225 (* 1 = 0.818225 loss)
I0817 08:32:44.958385 20404 sgd_solver.cpp:106] Iteration 13550, lr = 0.000526026
I0817 08:33:16.376823 20404 solver.cpp:337] Iteration 13560, Testing net (#0)
I0817 08:33:51.021500 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:33:51.021682 20404 solver.cpp:404]     Test net output #1: loss = 0.671999 (* 1 = 0.671999 loss)
I0817 08:33:54.501339 20404 solver.cpp:228] Iteration 13560, loss = 0.818229
I0817 08:33:54.501396 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:33:54.501410 20404 solver.cpp:244]     Train net output #1: loss = 0.818229 (* 1 = 0.818229 loss)
I0817 08:33:54.501423 20404 sgd_solver.cpp:106] Iteration 13560, lr = 0.000525858
I0817 08:34:29.387111 20404 solver.cpp:228] Iteration 13570, loss = 0.818374
I0817 08:34:29.387289 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:34:29.387305 20404 solver.cpp:244]     Train net output #1: loss = 0.818374 (* 1 = 0.818374 loss)
I0817 08:34:29.387316 20404 sgd_solver.cpp:106] Iteration 13570, lr = 0.000525691
I0817 08:35:04.276664 20404 solver.cpp:228] Iteration 13580, loss = 0.817795
I0817 08:35:04.276767 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:35:04.276782 20404 solver.cpp:244]     Train net output #1: loss = 0.817795 (* 1 = 0.817795 loss)
I0817 08:35:04.276793 20404 sgd_solver.cpp:106] Iteration 13580, lr = 0.000525524
I0817 08:35:39.161407 20404 solver.cpp:228] Iteration 13590, loss = 0.818479
I0817 08:35:39.161590 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 08:35:39.161607 20404 solver.cpp:244]     Train net output #1: loss = 0.818479 (* 1 = 0.818479 loss)
I0817 08:35:39.161619 20404 sgd_solver.cpp:106] Iteration 13590, lr = 0.000525356
I0817 08:36:10.581743 20404 solver.cpp:337] Iteration 13600, Testing net (#0)
I0817 08:36:45.232219 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:36:45.232332 20404 solver.cpp:404]     Test net output #1: loss = 0.6717 (* 1 = 0.6717 loss)
I0817 08:36:48.700480 20404 solver.cpp:228] Iteration 13600, loss = 0.818337
I0817 08:36:48.700525 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:36:48.700543 20404 solver.cpp:244]     Train net output #1: loss = 0.818337 (* 1 = 0.818337 loss)
I0817 08:36:48.700568 20404 sgd_solver.cpp:106] Iteration 13600, lr = 0.000525189
I0817 08:37:23.590775 20404 solver.cpp:228] Iteration 13610, loss = 0.818313
I0817 08:37:23.590960 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:37:23.590978 20404 solver.cpp:244]     Train net output #1: loss = 0.818313 (* 1 = 0.818313 loss)
I0817 08:37:23.590993 20404 sgd_solver.cpp:106] Iteration 13610, lr = 0.000525023
I0817 08:37:58.505347 20404 solver.cpp:228] Iteration 13620, loss = 0.818632
I0817 08:37:58.505511 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:37:58.505530 20404 solver.cpp:244]     Train net output #1: loss = 0.818632 (* 1 = 0.818632 loss)
I0817 08:37:58.505547 20404 sgd_solver.cpp:106] Iteration 13620, lr = 0.000524856
I0817 08:38:33.391599 20404 solver.cpp:228] Iteration 13630, loss = 0.818249
I0817 08:38:33.391772 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:38:33.391788 20404 solver.cpp:244]     Train net output #1: loss = 0.818249 (* 1 = 0.818249 loss)
I0817 08:38:33.391799 20404 sgd_solver.cpp:106] Iteration 13630, lr = 0.000524689
I0817 08:39:04.802991 20404 solver.cpp:337] Iteration 13640, Testing net (#0)
I0817 08:39:39.475039 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:39:39.475208 20404 solver.cpp:404]     Test net output #1: loss = 0.672294 (* 1 = 0.672294 loss)
I0817 08:39:42.949362 20404 solver.cpp:228] Iteration 13640, loss = 0.818174
I0817 08:39:42.949412 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:39:42.949426 20404 solver.cpp:244]     Train net output #1: loss = 0.818174 (* 1 = 0.818174 loss)
I0817 08:39:42.949439 20404 sgd_solver.cpp:106] Iteration 13640, lr = 0.000524523
I0817 08:40:17.839092 20404 solver.cpp:228] Iteration 13650, loss = 0.818148
I0817 08:40:17.839265 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:40:17.839292 20404 solver.cpp:244]     Train net output #1: loss = 0.818148 (* 1 = 0.818148 loss)
I0817 08:40:17.839303 20404 sgd_solver.cpp:106] Iteration 13650, lr = 0.000524356
I0817 08:40:52.733373 20404 solver.cpp:228] Iteration 13660, loss = 0.818181
I0817 08:40:52.733587 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 08:40:52.733603 20404 solver.cpp:244]     Train net output #1: loss = 0.818181 (* 1 = 0.818181 loss)
I0817 08:40:52.733618 20404 sgd_solver.cpp:106] Iteration 13660, lr = 0.00052419
I0817 08:41:27.634929 20404 solver.cpp:228] Iteration 13670, loss = 0.818171
I0817 08:41:27.635030 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:41:27.635045 20404 solver.cpp:244]     Train net output #1: loss = 0.818171 (* 1 = 0.818171 loss)
I0817 08:41:27.635056 20404 sgd_solver.cpp:106] Iteration 13670, lr = 0.000524024
I0817 08:41:59.042222 20404 solver.cpp:337] Iteration 13680, Testing net (#0)
I0817 08:42:33.676048 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:42:33.676215 20404 solver.cpp:404]     Test net output #1: loss = 0.671441 (* 1 = 0.671441 loss)
I0817 08:42:37.156610 20404 solver.cpp:228] Iteration 13680, loss = 0.818837
I0817 08:42:37.156663 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:42:37.156678 20404 solver.cpp:244]     Train net output #1: loss = 0.818837 (* 1 = 0.818837 loss)
I0817 08:42:37.156689 20404 sgd_solver.cpp:106] Iteration 13680, lr = 0.000523858
I0817 08:43:12.060067 20404 solver.cpp:228] Iteration 13690, loss = 0.818256
I0817 08:43:12.060248 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:43:12.060263 20404 solver.cpp:244]     Train net output #1: loss = 0.818256 (* 1 = 0.818256 loss)
I0817 08:43:12.060276 20404 sgd_solver.cpp:106] Iteration 13690, lr = 0.000523692
I0817 08:43:46.954545 20404 solver.cpp:228] Iteration 13700, loss = 0.818734
I0817 08:43:46.954720 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:43:46.954736 20404 solver.cpp:244]     Train net output #1: loss = 0.818734 (* 1 = 0.818734 loss)
I0817 08:43:46.954749 20404 sgd_solver.cpp:106] Iteration 13700, lr = 0.000523527
I0817 08:44:21.830248 20404 solver.cpp:228] Iteration 13710, loss = 0.817801
I0817 08:44:21.830428 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:44:21.830443 20404 solver.cpp:244]     Train net output #1: loss = 0.817801 (* 1 = 0.817801 loss)
I0817 08:44:21.830456 20404 sgd_solver.cpp:106] Iteration 13710, lr = 0.000523361
I0817 08:44:53.250414 20404 solver.cpp:337] Iteration 13720, Testing net (#0)
I0817 08:45:27.895125 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:45:27.895304 20404 solver.cpp:404]     Test net output #1: loss = 0.67189 (* 1 = 0.67189 loss)
I0817 08:45:31.376015 20404 solver.cpp:228] Iteration 13720, loss = 0.818214
I0817 08:45:31.376061 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:45:31.376080 20404 solver.cpp:244]     Train net output #1: loss = 0.818214 (* 1 = 0.818214 loss)
I0817 08:45:31.376096 20404 sgd_solver.cpp:106] Iteration 13720, lr = 0.000523195
I0817 08:46:06.269318 20404 solver.cpp:228] Iteration 13730, loss = 0.8181
I0817 08:46:06.269521 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:46:06.269562 20404 solver.cpp:244]     Train net output #1: loss = 0.8181 (* 1 = 0.8181 loss)
I0817 08:46:06.269579 20404 sgd_solver.cpp:106] Iteration 13730, lr = 0.00052303
I0817 08:46:41.170379 20404 solver.cpp:228] Iteration 13740, loss = 0.817844
I0817 08:46:41.170567 20404 solver.cpp:244]     Train net output #0: accuracy = 0.68
I0817 08:46:41.170586 20404 solver.cpp:244]     Train net output #1: loss = 0.817844 (* 1 = 0.817844 loss)
I0817 08:46:41.170601 20404 sgd_solver.cpp:106] Iteration 13740, lr = 0.000522865
I0817 08:47:16.062358 20404 solver.cpp:228] Iteration 13750, loss = 0.818186
I0817 08:47:16.062551 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:47:16.062569 20404 solver.cpp:244]     Train net output #1: loss = 0.818186 (* 1 = 0.818186 loss)
I0817 08:47:16.062584 20404 sgd_solver.cpp:106] Iteration 13750, lr = 0.0005227
I0817 08:47:47.459545 20404 solver.cpp:337] Iteration 13760, Testing net (#0)
I0817 08:48:22.084777 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:48:22.084967 20404 solver.cpp:404]     Test net output #1: loss = 0.671761 (* 1 = 0.671761 loss)
I0817 08:48:25.561494 20404 solver.cpp:228] Iteration 13760, loss = 0.81808
I0817 08:48:25.561547 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:48:25.561560 20404 solver.cpp:244]     Train net output #1: loss = 0.81808 (* 1 = 0.81808 loss)
I0817 08:48:25.561573 20404 sgd_solver.cpp:106] Iteration 13760, lr = 0.000522535
I0817 08:49:00.447069 20404 solver.cpp:228] Iteration 13770, loss = 0.818191
I0817 08:49:00.447260 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:49:00.447280 20404 solver.cpp:244]     Train net output #1: loss = 0.818191 (* 1 = 0.818191 loss)
I0817 08:49:00.447293 20404 sgd_solver.cpp:106] Iteration 13770, lr = 0.00052237
I0817 08:49:35.338574 20404 solver.cpp:228] Iteration 13780, loss = 0.818276
I0817 08:49:35.338752 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:49:35.338768 20404 solver.cpp:244]     Train net output #1: loss = 0.818276 (* 1 = 0.818276 loss)
I0817 08:49:35.338779 20404 sgd_solver.cpp:106] Iteration 13780, lr = 0.000522205
I0817 08:50:10.235971 20404 solver.cpp:228] Iteration 13790, loss = 0.818056
I0817 08:50:10.236148 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:50:10.236165 20404 solver.cpp:244]     Train net output #1: loss = 0.818056 (* 1 = 0.818056 loss)
I0817 08:50:10.236177 20404 sgd_solver.cpp:106] Iteration 13790, lr = 0.00052204
I0817 08:50:41.638422 20404 solver.cpp:337] Iteration 13800, Testing net (#0)
I0817 08:51:16.287621 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:51:16.287796 20404 solver.cpp:404]     Test net output #1: loss = 0.671945 (* 1 = 0.671945 loss)
I0817 08:51:19.759924 20404 solver.cpp:228] Iteration 13800, loss = 0.817943
I0817 08:51:19.759974 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 08:51:19.759989 20404 solver.cpp:244]     Train net output #1: loss = 0.817943 (* 1 = 0.817943 loss)
I0817 08:51:19.760000 20404 sgd_solver.cpp:106] Iteration 13800, lr = 0.000521876
I0817 08:51:54.632701 20404 solver.cpp:228] Iteration 13810, loss = 0.81842
I0817 08:51:54.632885 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 08:51:54.632900 20404 solver.cpp:244]     Train net output #1: loss = 0.81842 (* 1 = 0.81842 loss)
I0817 08:51:54.632913 20404 sgd_solver.cpp:106] Iteration 13810, lr = 0.000521712
I0817 08:52:29.510378 20404 solver.cpp:228] Iteration 13820, loss = 0.818085
I0817 08:52:29.510607 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:52:29.510627 20404 solver.cpp:244]     Train net output #1: loss = 0.818085 (* 1 = 0.818085 loss)
I0817 08:52:29.510642 20404 sgd_solver.cpp:106] Iteration 13820, lr = 0.000521547
I0817 08:53:04.398967 20404 solver.cpp:228] Iteration 13830, loss = 0.818475
I0817 08:53:04.399142 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:53:04.399161 20404 solver.cpp:244]     Train net output #1: loss = 0.818475 (* 1 = 0.818475 loss)
I0817 08:53:04.399175 20404 sgd_solver.cpp:106] Iteration 13830, lr = 0.000521383
I0817 08:53:35.795742 20404 solver.cpp:337] Iteration 13840, Testing net (#0)
I0817 08:54:10.441301 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:54:10.441467 20404 solver.cpp:404]     Test net output #1: loss = 0.671596 (* 1 = 0.671596 loss)
I0817 08:54:13.921257 20404 solver.cpp:228] Iteration 13840, loss = 0.818293
I0817 08:54:13.921303 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 08:54:13.921319 20404 solver.cpp:244]     Train net output #1: loss = 0.818293 (* 1 = 0.818293 loss)
I0817 08:54:13.921344 20404 sgd_solver.cpp:106] Iteration 13840, lr = 0.000521219
I0817 08:54:48.802065 20404 solver.cpp:228] Iteration 13850, loss = 0.818215
I0817 08:54:48.802273 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:54:48.802294 20404 solver.cpp:244]     Train net output #1: loss = 0.818215 (* 1 = 0.818215 loss)
I0817 08:54:48.802309 20404 sgd_solver.cpp:106] Iteration 13850, lr = 0.000521055
I0817 08:55:23.697721 20404 solver.cpp:228] Iteration 13860, loss = 0.817933
I0817 08:55:23.697904 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 08:55:23.697927 20404 solver.cpp:244]     Train net output #1: loss = 0.817933 (* 1 = 0.817933 loss)
I0817 08:55:23.697943 20404 sgd_solver.cpp:106] Iteration 13860, lr = 0.000520891
I0817 08:55:58.587577 20404 solver.cpp:228] Iteration 13870, loss = 0.8179
I0817 08:55:58.587769 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:55:58.587785 20404 solver.cpp:244]     Train net output #1: loss = 0.8179 (* 1 = 0.8179 loss)
I0817 08:55:58.587797 20404 sgd_solver.cpp:106] Iteration 13870, lr = 0.000520728
I0817 08:56:30.009357 20404 solver.cpp:337] Iteration 13880, Testing net (#0)
I0817 08:57:04.625931 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:57:04.626111 20404 solver.cpp:404]     Test net output #1: loss = 0.671567 (* 1 = 0.671567 loss)
I0817 08:57:08.103569 20404 solver.cpp:228] Iteration 13880, loss = 0.818262
I0817 08:57:08.103611 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:57:08.103626 20404 solver.cpp:244]     Train net output #1: loss = 0.818262 (* 1 = 0.818262 loss)
I0817 08:57:08.103639 20404 sgd_solver.cpp:106] Iteration 13880, lr = 0.000520564
I0817 08:57:42.983867 20404 solver.cpp:228] Iteration 13890, loss = 0.81837
I0817 08:57:42.984040 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:57:42.984056 20404 solver.cpp:244]     Train net output #1: loss = 0.81837 (* 1 = 0.81837 loss)
I0817 08:57:42.984069 20404 sgd_solver.cpp:106] Iteration 13890, lr = 0.000520401
I0817 08:58:17.862149 20404 solver.cpp:228] Iteration 13900, loss = 0.817854
I0817 08:58:17.862328 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 08:58:17.862344 20404 solver.cpp:244]     Train net output #1: loss = 0.817854 (* 1 = 0.817854 loss)
I0817 08:58:17.862355 20404 sgd_solver.cpp:106] Iteration 13900, lr = 0.000520237
I0817 08:58:52.768522 20404 solver.cpp:228] Iteration 13910, loss = 0.818474
I0817 08:58:52.768630 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 08:58:52.768646 20404 solver.cpp:244]     Train net output #1: loss = 0.818474 (* 1 = 0.818474 loss)
I0817 08:58:52.768657 20404 sgd_solver.cpp:106] Iteration 13910, lr = 0.000520074
I0817 08:59:24.165480 20404 solver.cpp:337] Iteration 13920, Testing net (#0)
I0817 08:59:58.818063 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 08:59:58.818239 20404 solver.cpp:404]     Test net output #1: loss = 0.672073 (* 1 = 0.672073 loss)
I0817 09:00:02.298317 20404 solver.cpp:228] Iteration 13920, loss = 0.817912
I0817 09:00:02.298368 20404 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0817 09:00:02.298383 20404 solver.cpp:244]     Train net output #1: loss = 0.817912 (* 1 = 0.817912 loss)
I0817 09:00:02.298395 20404 sgd_solver.cpp:106] Iteration 13920, lr = 0.000519911
I0817 09:00:37.186568 20404 solver.cpp:228] Iteration 13930, loss = 0.818268
I0817 09:00:37.186750 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:00:37.186766 20404 solver.cpp:244]     Train net output #1: loss = 0.818268 (* 1 = 0.818268 loss)
I0817 09:00:37.186779 20404 sgd_solver.cpp:106] Iteration 13930, lr = 0.000519748
I0817 09:01:12.081061 20404 solver.cpp:228] Iteration 13940, loss = 0.81777
I0817 09:01:12.081243 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:01:12.081259 20404 solver.cpp:244]     Train net output #1: loss = 0.81777 (* 1 = 0.81777 loss)
I0817 09:01:12.081272 20404 sgd_solver.cpp:106] Iteration 13940, lr = 0.000519585
I0817 09:01:46.970978 20404 solver.cpp:228] Iteration 13950, loss = 0.818079
I0817 09:01:46.971158 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:01:46.971173 20404 solver.cpp:244]     Train net output #1: loss = 0.818079 (* 1 = 0.818079 loss)
I0817 09:01:46.971185 20404 sgd_solver.cpp:106] Iteration 13950, lr = 0.000519423
I0817 09:02:18.376441 20404 solver.cpp:337] Iteration 13960, Testing net (#0)
I0817 09:02:53.033720 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:02:53.033896 20404 solver.cpp:404]     Test net output #1: loss = 0.672215 (* 1 = 0.672215 loss)
I0817 09:02:56.507328 20404 solver.cpp:228] Iteration 13960, loss = 0.818103
I0817 09:02:56.507377 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:02:56.507391 20404 solver.cpp:244]     Train net output #1: loss = 0.818103 (* 1 = 0.818103 loss)
I0817 09:02:56.507403 20404 sgd_solver.cpp:106] Iteration 13960, lr = 0.00051926
I0817 09:03:31.388125 20404 solver.cpp:228] Iteration 13970, loss = 0.818229
I0817 09:03:31.388301 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:03:31.388319 20404 solver.cpp:244]     Train net output #1: loss = 0.818229 (* 1 = 0.818229 loss)
I0817 09:03:31.388330 20404 sgd_solver.cpp:106] Iteration 13970, lr = 0.000519098
I0817 09:04:06.288154 20404 solver.cpp:228] Iteration 13980, loss = 0.818242
I0817 09:04:06.288256 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:04:06.288272 20404 solver.cpp:244]     Train net output #1: loss = 0.818242 (* 1 = 0.818242 loss)
I0817 09:04:06.288285 20404 sgd_solver.cpp:106] Iteration 13980, lr = 0.000518935
I0817 09:04:41.194555 20404 solver.cpp:228] Iteration 13990, loss = 0.818582
I0817 09:04:41.194737 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:04:41.194753 20404 solver.cpp:244]     Train net output #1: loss = 0.818582 (* 1 = 0.818582 loss)
I0817 09:04:41.194766 20404 sgd_solver.cpp:106] Iteration 13990, lr = 0.000518773
I0817 09:05:12.600330 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_14000.caffemodel
I0817 09:05:21.766321 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_14000.solverstate
I0817 09:05:23.513731 20404 solver.cpp:337] Iteration 14000, Testing net (#0)
I0817 09:05:58.130947 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:05:58.131116 20404 solver.cpp:404]     Test net output #1: loss = 0.672062 (* 1 = 0.672062 loss)
I0817 09:06:01.614045 20404 solver.cpp:228] Iteration 14000, loss = 0.817686
I0817 09:06:01.614095 20404 solver.cpp:244]     Train net output #0: accuracy = 0.73
I0817 09:06:01.614110 20404 solver.cpp:244]     Train net output #1: loss = 0.817686 (* 1 = 0.817686 loss)
I0817 09:06:01.614121 20404 sgd_solver.cpp:106] Iteration 14000, lr = 0.000518611
I0817 09:06:36.507658 20404 solver.cpp:228] Iteration 14010, loss = 0.817575
I0817 09:06:36.507830 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:06:36.507844 20404 solver.cpp:244]     Train net output #1: loss = 0.817575 (* 1 = 0.817575 loss)
I0817 09:06:36.507858 20404 sgd_solver.cpp:106] Iteration 14010, lr = 0.000518449
I0817 09:07:11.417943 20404 solver.cpp:228] Iteration 14020, loss = 0.817833
I0817 09:07:11.418037 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:07:11.418052 20404 solver.cpp:244]     Train net output #1: loss = 0.817833 (* 1 = 0.817833 loss)
I0817 09:07:11.418066 20404 sgd_solver.cpp:106] Iteration 14020, lr = 0.000518287
I0817 09:07:46.309134 20404 solver.cpp:228] Iteration 14030, loss = 0.817683
I0817 09:07:46.309309 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:07:46.309324 20404 solver.cpp:244]     Train net output #1: loss = 0.817683 (* 1 = 0.817683 loss)
I0817 09:07:46.309336 20404 sgd_solver.cpp:106] Iteration 14030, lr = 0.000518125
I0817 09:08:17.731086 20404 solver.cpp:337] Iteration 14040, Testing net (#0)
I0817 09:08:52.366921 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:08:52.367096 20404 solver.cpp:404]     Test net output #1: loss = 0.672294 (* 1 = 0.672294 loss)
I0817 09:08:55.844292 20404 solver.cpp:228] Iteration 14040, loss = 0.817797
I0817 09:08:55.844343 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:08:55.844358 20404 solver.cpp:244]     Train net output #1: loss = 0.817797 (* 1 = 0.817797 loss)
I0817 09:08:55.844369 20404 sgd_solver.cpp:106] Iteration 14040, lr = 0.000517964
I0817 09:09:30.746570 20404 solver.cpp:228] Iteration 14050, loss = 0.817646
I0817 09:09:30.746780 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:09:30.746795 20404 solver.cpp:244]     Train net output #1: loss = 0.817646 (* 1 = 0.817646 loss)
I0817 09:09:30.746809 20404 sgd_solver.cpp:106] Iteration 14050, lr = 0.000517802
I0817 09:10:05.635931 20404 solver.cpp:228] Iteration 14060, loss = 0.818407
I0817 09:10:05.636111 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:10:05.636126 20404 solver.cpp:244]     Train net output #1: loss = 0.818407 (* 1 = 0.818407 loss)
I0817 09:10:05.636138 20404 sgd_solver.cpp:106] Iteration 14060, lr = 0.000517641
I0817 09:10:40.534785 20404 solver.cpp:228] Iteration 14070, loss = 0.818327
I0817 09:10:40.534957 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:10:40.534973 20404 solver.cpp:244]     Train net output #1: loss = 0.818327 (* 1 = 0.818327 loss)
I0817 09:10:40.534986 20404 sgd_solver.cpp:106] Iteration 14070, lr = 0.000517479
I0817 09:11:11.948678 20404 solver.cpp:337] Iteration 14080, Testing net (#0)
I0817 09:11:46.596638 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:11:46.596822 20404 solver.cpp:404]     Test net output #1: loss = 0.672291 (* 1 = 0.672291 loss)
I0817 09:11:50.067567 20404 solver.cpp:228] Iteration 14080, loss = 0.81782
I0817 09:11:50.067620 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:11:50.067632 20404 solver.cpp:244]     Train net output #1: loss = 0.81782 (* 1 = 0.81782 loss)
I0817 09:11:50.067643 20404 sgd_solver.cpp:106] Iteration 14080, lr = 0.000517318
I0817 09:12:24.944161 20404 solver.cpp:228] Iteration 14090, loss = 0.817639
I0817 09:12:24.944339 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:12:24.944355 20404 solver.cpp:244]     Train net output #1: loss = 0.817639 (* 1 = 0.817639 loss)
I0817 09:12:24.944366 20404 sgd_solver.cpp:106] Iteration 14090, lr = 0.000517157
I0817 09:12:59.841470 20404 solver.cpp:228] Iteration 14100, loss = 0.817768
I0817 09:12:59.841650 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:12:59.841665 20404 solver.cpp:244]     Train net output #1: loss = 0.817768 (* 1 = 0.817768 loss)
I0817 09:12:59.841677 20404 sgd_solver.cpp:106] Iteration 14100, lr = 0.000516996
I0817 09:13:34.739828 20404 solver.cpp:228] Iteration 14110, loss = 0.817399
I0817 09:13:34.739917 20404 solver.cpp:244]     Train net output #0: accuracy = 0.77
I0817 09:13:34.739931 20404 solver.cpp:244]     Train net output #1: loss = 0.817399 (* 1 = 0.817399 loss)
I0817 09:13:34.739943 20404 sgd_solver.cpp:106] Iteration 14110, lr = 0.000516835
I0817 09:14:06.156770 20404 solver.cpp:337] Iteration 14120, Testing net (#0)
I0817 09:14:40.783854 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:14:40.783959 20404 solver.cpp:404]     Test net output #1: loss = 0.67158 (* 1 = 0.67158 loss)
I0817 09:14:44.253844 20404 solver.cpp:228] Iteration 14120, loss = 0.817948
I0817 09:14:44.253888 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 09:14:44.253917 20404 solver.cpp:244]     Train net output #1: loss = 0.817948 (* 1 = 0.817948 loss)
I0817 09:14:44.253932 20404 sgd_solver.cpp:106] Iteration 14120, lr = 0.000516675
I0817 09:15:19.110184 20404 solver.cpp:228] Iteration 14130, loss = 0.817858
I0817 09:15:19.110291 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:15:19.110309 20404 solver.cpp:244]     Train net output #1: loss = 0.817858 (* 1 = 0.817858 loss)
I0817 09:15:19.110321 20404 sgd_solver.cpp:106] Iteration 14130, lr = 0.000516514
I0817 09:15:53.996302 20404 solver.cpp:228] Iteration 14140, loss = 0.817842
I0817 09:15:53.996397 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:15:53.996413 20404 solver.cpp:244]     Train net output #1: loss = 0.817842 (* 1 = 0.817842 loss)
I0817 09:15:53.996425 20404 sgd_solver.cpp:106] Iteration 14140, lr = 0.000516353
I0817 09:16:28.893921 20404 solver.cpp:228] Iteration 14150, loss = 0.81793
I0817 09:16:28.894121 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 09:16:28.894137 20404 solver.cpp:244]     Train net output #1: loss = 0.81793 (* 1 = 0.81793 loss)
I0817 09:16:28.894155 20404 sgd_solver.cpp:106] Iteration 14150, lr = 0.000516193
I0817 09:17:00.289122 20404 solver.cpp:337] Iteration 14160, Testing net (#0)
I0817 09:17:34.926990 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:17:34.927165 20404 solver.cpp:404]     Test net output #1: loss = 0.672296 (* 1 = 0.672296 loss)
I0817 09:17:38.405357 20404 solver.cpp:228] Iteration 14160, loss = 0.817301
I0817 09:17:38.405410 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:17:38.405423 20404 solver.cpp:244]     Train net output #1: loss = 0.817301 (* 1 = 0.817301 loss)
I0817 09:17:38.405434 20404 sgd_solver.cpp:106] Iteration 14160, lr = 0.000516033
I0817 09:18:13.288806 20404 solver.cpp:228] Iteration 14170, loss = 0.817526
I0817 09:18:13.288976 20404 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0817 09:18:13.288991 20404 solver.cpp:244]     Train net output #1: loss = 0.817526 (* 1 = 0.817526 loss)
I0817 09:18:13.289005 20404 sgd_solver.cpp:106] Iteration 14170, lr = 0.000515873
I0817 09:18:48.193265 20404 solver.cpp:228] Iteration 14180, loss = 0.817635
I0817 09:18:48.193439 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:18:48.193454 20404 solver.cpp:244]     Train net output #1: loss = 0.817635 (* 1 = 0.817635 loss)
I0817 09:18:48.193466 20404 sgd_solver.cpp:106] Iteration 14180, lr = 0.000515713
I0817 09:19:23.092978 20404 solver.cpp:228] Iteration 14190, loss = 0.817734
I0817 09:19:23.093156 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 09:19:23.093173 20404 solver.cpp:244]     Train net output #1: loss = 0.817734 (* 1 = 0.817734 loss)
I0817 09:19:23.093184 20404 sgd_solver.cpp:106] Iteration 14190, lr = 0.000515553
I0817 09:19:54.499357 20404 solver.cpp:337] Iteration 14200, Testing net (#0)
I0817 09:20:29.156289 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:20:29.156461 20404 solver.cpp:404]     Test net output #1: loss = 0.671968 (* 1 = 0.671968 loss)
I0817 09:20:32.632944 20404 solver.cpp:228] Iteration 14200, loss = 0.817647
I0817 09:20:32.632997 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:20:32.633010 20404 solver.cpp:244]     Train net output #1: loss = 0.817647 (* 1 = 0.817647 loss)
I0817 09:20:32.633023 20404 sgd_solver.cpp:106] Iteration 14200, lr = 0.000515393
I0817 09:21:07.513725 20404 solver.cpp:228] Iteration 14210, loss = 0.817595
I0817 09:21:07.513900 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:21:07.513916 20404 solver.cpp:244]     Train net output #1: loss = 0.817595 (* 1 = 0.817595 loss)
I0817 09:21:07.513928 20404 sgd_solver.cpp:106] Iteration 14210, lr = 0.000515233
I0817 09:21:42.385063 20404 solver.cpp:228] Iteration 14220, loss = 0.817454
I0817 09:21:42.385241 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:21:42.385257 20404 solver.cpp:244]     Train net output #1: loss = 0.817454 (* 1 = 0.817454 loss)
I0817 09:21:42.385270 20404 sgd_solver.cpp:106] Iteration 14220, lr = 0.000515074
I0817 09:22:17.274157 20404 solver.cpp:228] Iteration 14230, loss = 0.818074
I0817 09:22:17.274330 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:22:17.274346 20404 solver.cpp:244]     Train net output #1: loss = 0.818074 (* 1 = 0.818074 loss)
I0817 09:22:17.274359 20404 sgd_solver.cpp:106] Iteration 14230, lr = 0.000514914
I0817 09:22:48.693806 20404 solver.cpp:337] Iteration 14240, Testing net (#0)
I0817 09:23:23.339120 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:23:23.339210 20404 solver.cpp:404]     Test net output #1: loss = 0.672466 (* 1 = 0.672466 loss)
I0817 09:23:26.821856 20404 solver.cpp:228] Iteration 14240, loss = 0.817512
I0817 09:23:26.821907 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:23:26.821919 20404 solver.cpp:244]     Train net output #1: loss = 0.817512 (* 1 = 0.817512 loss)
I0817 09:23:26.821931 20404 sgd_solver.cpp:106] Iteration 14240, lr = 0.000514755
I0817 09:24:01.691496 20404 solver.cpp:228] Iteration 14250, loss = 0.817445
I0817 09:24:01.691710 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:24:01.691725 20404 solver.cpp:244]     Train net output #1: loss = 0.817445 (* 1 = 0.817445 loss)
I0817 09:24:01.691737 20404 sgd_solver.cpp:106] Iteration 14250, lr = 0.000514596
I0817 09:24:36.582921 20404 solver.cpp:228] Iteration 14260, loss = 0.817306
I0817 09:24:36.583104 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:24:36.583120 20404 solver.cpp:244]     Train net output #1: loss = 0.817306 (* 1 = 0.817306 loss)
I0817 09:24:36.583132 20404 sgd_solver.cpp:106] Iteration 14260, lr = 0.000514437
I0817 09:25:11.975488 20404 solver.cpp:228] Iteration 14270, loss = 0.817254
I0817 09:25:11.975695 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:25:11.975711 20404 solver.cpp:244]     Train net output #1: loss = 0.817254 (* 1 = 0.817254 loss)
I0817 09:25:11.975723 20404 sgd_solver.cpp:106] Iteration 14270, lr = 0.000514278
I0817 09:25:43.680222 20404 solver.cpp:337] Iteration 14280, Testing net (#0)
I0817 09:26:18.949467 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:26:18.949633 20404 solver.cpp:404]     Test net output #1: loss = 0.671911 (* 1 = 0.671911 loss)
I0817 09:26:22.407244 20404 solver.cpp:228] Iteration 14280, loss = 0.817392
I0817 09:26:22.407299 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:26:22.407312 20404 solver.cpp:244]     Train net output #1: loss = 0.817392 (* 1 = 0.817392 loss)
I0817 09:26:22.407325 20404 sgd_solver.cpp:106] Iteration 14280, lr = 0.000514119
I0817 09:26:57.214725 20404 solver.cpp:228] Iteration 14290, loss = 0.817911
I0817 09:26:57.214901 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 09:26:57.214917 20404 solver.cpp:244]     Train net output #1: loss = 0.817911 (* 1 = 0.817911 loss)
I0817 09:26:57.214931 20404 sgd_solver.cpp:106] Iteration 14290, lr = 0.00051396
I0817 09:27:32.022742 20404 solver.cpp:228] Iteration 14300, loss = 0.81775
I0817 09:27:32.022919 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:27:32.022934 20404 solver.cpp:244]     Train net output #1: loss = 0.81775 (* 1 = 0.81775 loss)
I0817 09:27:32.022946 20404 sgd_solver.cpp:106] Iteration 14300, lr = 0.000513801
I0817 09:28:06.845039 20404 solver.cpp:228] Iteration 14310, loss = 0.817221
I0817 09:28:06.845217 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:28:06.845233 20404 solver.cpp:244]     Train net output #1: loss = 0.817221 (* 1 = 0.817221 loss)
I0817 09:28:06.845247 20404 sgd_solver.cpp:106] Iteration 14310, lr = 0.000513643
I0817 09:28:38.187621 20404 solver.cpp:337] Iteration 14320, Testing net (#0)
I0817 09:29:13.909276 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:29:13.909471 20404 solver.cpp:404]     Test net output #1: loss = 0.672635 (* 1 = 0.672635 loss)
I0817 09:29:17.410266 20404 solver.cpp:228] Iteration 14320, loss = 0.81773
I0817 09:29:17.410311 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:29:17.410329 20404 solver.cpp:244]     Train net output #1: loss = 0.81773 (* 1 = 0.81773 loss)
I0817 09:29:17.410344 20404 sgd_solver.cpp:106] Iteration 14320, lr = 0.000513485
I0817 09:29:52.627352 20404 solver.cpp:228] Iteration 14330, loss = 0.817136
I0817 09:29:52.627825 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 09:29:52.627843 20404 solver.cpp:244]     Train net output #1: loss = 0.817136 (* 1 = 0.817136 loss)
I0817 09:29:52.627861 20404 sgd_solver.cpp:106] Iteration 14330, lr = 0.000513326
I0817 09:30:27.537875 20404 solver.cpp:228] Iteration 14340, loss = 0.817405
I0817 09:30:27.538103 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:30:27.538120 20404 solver.cpp:244]     Train net output #1: loss = 0.817405 (* 1 = 0.817405 loss)
I0817 09:30:27.538132 20404 sgd_solver.cpp:106] Iteration 14340, lr = 0.000513168
I0817 09:31:02.321490 20404 solver.cpp:228] Iteration 14350, loss = 0.817863
I0817 09:31:02.321671 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:31:02.321686 20404 solver.cpp:244]     Train net output #1: loss = 0.817863 (* 1 = 0.817863 loss)
I0817 09:31:02.321699 20404 sgd_solver.cpp:106] Iteration 14350, lr = 0.00051301
I0817 09:31:33.650259 20404 solver.cpp:337] Iteration 14360, Testing net (#0)
I0817 09:32:08.262115 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:32:08.262284 20404 solver.cpp:404]     Test net output #1: loss = 0.672498 (* 1 = 0.672498 loss)
I0817 09:32:11.723803 20404 solver.cpp:228] Iteration 14360, loss = 0.817277
I0817 09:32:11.723855 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:32:11.723868 20404 solver.cpp:244]     Train net output #1: loss = 0.817277 (* 1 = 0.817277 loss)
I0817 09:32:11.723881 20404 sgd_solver.cpp:106] Iteration 14360, lr = 0.000512852
I0817 09:32:47.445556 20404 solver.cpp:228] Iteration 14370, loss = 0.817365
I0817 09:32:47.445729 20404 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0817 09:32:47.445745 20404 solver.cpp:244]     Train net output #1: loss = 0.817365 (* 1 = 0.817365 loss)
I0817 09:32:47.445758 20404 sgd_solver.cpp:106] Iteration 14370, lr = 0.000512694
I0817 09:33:22.595530 20404 solver.cpp:228] Iteration 14380, loss = 0.817618
I0817 09:33:22.595700 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:33:22.595734 20404 solver.cpp:244]     Train net output #1: loss = 0.817618 (* 1 = 0.817618 loss)
I0817 09:33:22.595772 20404 sgd_solver.cpp:106] Iteration 14380, lr = 0.000512536
I0817 09:33:57.984158 20404 solver.cpp:228] Iteration 14390, loss = 0.817344
I0817 09:33:57.984343 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:33:57.984359 20404 solver.cpp:244]     Train net output #1: loss = 0.817344 (* 1 = 0.817344 loss)
I0817 09:33:57.984371 20404 sgd_solver.cpp:106] Iteration 14390, lr = 0.000512379
I0817 09:34:29.326534 20404 solver.cpp:337] Iteration 14400, Testing net (#0)
I0817 09:35:04.038648 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:35:04.038821 20404 solver.cpp:404]     Test net output #1: loss = 0.672056 (* 1 = 0.672056 loss)
I0817 09:35:07.499297 20404 solver.cpp:228] Iteration 14400, loss = 0.816756
I0817 09:35:07.499348 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 09:35:07.499362 20404 solver.cpp:244]     Train net output #1: loss = 0.816756 (* 1 = 0.816756 loss)
I0817 09:35:07.499374 20404 sgd_solver.cpp:106] Iteration 14400, lr = 0.000512221
I0817 09:35:42.376920 20404 solver.cpp:228] Iteration 14410, loss = 0.817517
I0817 09:35:42.377106 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:35:42.377121 20404 solver.cpp:244]     Train net output #1: loss = 0.817517 (* 1 = 0.817517 loss)
I0817 09:35:42.377135 20404 sgd_solver.cpp:106] Iteration 14410, lr = 0.000512064
I0817 09:36:17.171466 20404 solver.cpp:228] Iteration 14420, loss = 0.817356
I0817 09:36:17.171638 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:36:17.171653 20404 solver.cpp:244]     Train net output #1: loss = 0.817356 (* 1 = 0.817356 loss)
I0817 09:36:17.171666 20404 sgd_solver.cpp:106] Iteration 14420, lr = 0.000511907
I0817 09:36:52.306567 20404 solver.cpp:228] Iteration 14430, loss = 0.817838
I0817 09:36:52.306674 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:36:52.306690 20404 solver.cpp:244]     Train net output #1: loss = 0.817838 (* 1 = 0.817838 loss)
I0817 09:36:52.306704 20404 sgd_solver.cpp:106] Iteration 14430, lr = 0.00051175
I0817 09:37:23.705054 20404 solver.cpp:337] Iteration 14440, Testing net (#0)
I0817 09:37:58.268816 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:37:58.269004 20404 solver.cpp:404]     Test net output #1: loss = 0.672135 (* 1 = 0.672135 loss)
I0817 09:38:01.734968 20404 solver.cpp:228] Iteration 14440, loss = 0.817124
I0817 09:38:01.735018 20404 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0817 09:38:01.735033 20404 solver.cpp:244]     Train net output #1: loss = 0.817124 (* 1 = 0.817124 loss)
I0817 09:38:01.735044 20404 sgd_solver.cpp:106] Iteration 14440, lr = 0.000511592
I0817 09:38:36.524910 20404 solver.cpp:228] Iteration 14450, loss = 0.817316
I0817 09:38:36.525089 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:38:36.525105 20404 solver.cpp:244]     Train net output #1: loss = 0.817316 (* 1 = 0.817316 loss)
I0817 09:38:36.525117 20404 sgd_solver.cpp:106] Iteration 14450, lr = 0.000511436
I0817 09:39:11.451541 20404 solver.cpp:228] Iteration 14460, loss = 0.817312
I0817 09:39:11.451731 20404 solver.cpp:244]     Train net output #0: accuracy = 0.9
I0817 09:39:11.451747 20404 solver.cpp:244]     Train net output #1: loss = 0.817312 (* 1 = 0.817312 loss)
I0817 09:39:11.451761 20404 sgd_solver.cpp:106] Iteration 14460, lr = 0.000511279
I0817 09:39:46.260992 20404 solver.cpp:228] Iteration 14470, loss = 0.816921
I0817 09:39:46.261173 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 09:39:46.261193 20404 solver.cpp:244]     Train net output #1: loss = 0.816921 (* 1 = 0.816921 loss)
I0817 09:39:46.261209 20404 sgd_solver.cpp:106] Iteration 14470, lr = 0.000511122
I0817 09:40:17.594491 20404 solver.cpp:337] Iteration 14480, Testing net (#0)
I0817 09:40:52.155055 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:40:52.155226 20404 solver.cpp:404]     Test net output #1: loss = 0.672408 (* 1 = 0.672408 loss)
I0817 09:40:55.615456 20404 solver.cpp:228] Iteration 14480, loss = 0.817654
I0817 09:40:55.615496 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:40:55.615512 20404 solver.cpp:244]     Train net output #1: loss = 0.817654 (* 1 = 0.817654 loss)
I0817 09:40:55.615525 20404 sgd_solver.cpp:106] Iteration 14480, lr = 0.000510965
I0817 09:41:30.433074 20404 solver.cpp:228] Iteration 14490, loss = 0.817223
I0817 09:41:30.433188 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:41:30.433207 20404 solver.cpp:244]     Train net output #1: loss = 0.817223 (* 1 = 0.817223 loss)
I0817 09:41:30.433223 20404 sgd_solver.cpp:106] Iteration 14490, lr = 0.000510809
I0817 09:42:05.264421 20404 solver.cpp:228] Iteration 14500, loss = 0.817021
I0817 09:42:05.264606 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 09:42:05.264622 20404 solver.cpp:244]     Train net output #1: loss = 0.817021 (* 1 = 0.817021 loss)
I0817 09:42:05.264636 20404 sgd_solver.cpp:106] Iteration 14500, lr = 0.000510653
I0817 09:42:40.129317 20404 solver.cpp:228] Iteration 14510, loss = 0.816809
I0817 09:42:40.129503 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:42:40.129519 20404 solver.cpp:244]     Train net output #1: loss = 0.816809 (* 1 = 0.816809 loss)
I0817 09:42:40.129531 20404 sgd_solver.cpp:106] Iteration 14510, lr = 0.000510496
I0817 09:43:11.722334 20404 solver.cpp:337] Iteration 14520, Testing net (#0)
I0817 09:43:46.280496 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:43:46.280676 20404 solver.cpp:404]     Test net output #1: loss = 0.67182 (* 1 = 0.67182 loss)
I0817 09:43:49.744349 20404 solver.cpp:228] Iteration 14520, loss = 0.817407
I0817 09:43:49.744398 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:43:49.744413 20404 solver.cpp:244]     Train net output #1: loss = 0.817407 (* 1 = 0.817407 loss)
I0817 09:43:49.744426 20404 sgd_solver.cpp:106] Iteration 14520, lr = 0.00051034
I0817 09:44:24.523752 20404 solver.cpp:228] Iteration 14530, loss = 0.817168
I0817 09:44:24.523936 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:44:24.523952 20404 solver.cpp:244]     Train net output #1: loss = 0.817168 (* 1 = 0.817168 loss)
I0817 09:44:24.523964 20404 sgd_solver.cpp:106] Iteration 14530, lr = 0.000510184
I0817 09:44:59.292532 20404 solver.cpp:228] Iteration 14540, loss = 0.817469
I0817 09:44:59.292738 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:44:59.292757 20404 solver.cpp:244]     Train net output #1: loss = 0.817469 (* 1 = 0.817469 loss)
I0817 09:44:59.292773 20404 sgd_solver.cpp:106] Iteration 14540, lr = 0.000510028
I0817 09:45:34.096832 20404 solver.cpp:228] Iteration 14550, loss = 0.817363
I0817 09:45:34.096918 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 09:45:34.096935 20404 solver.cpp:244]     Train net output #1: loss = 0.817363 (* 1 = 0.817363 loss)
I0817 09:45:34.096947 20404 sgd_solver.cpp:106] Iteration 14550, lr = 0.000509872
I0817 09:46:05.446665 20404 solver.cpp:337] Iteration 14560, Testing net (#0)
I0817 09:46:40.028962 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:46:40.029135 20404 solver.cpp:404]     Test net output #1: loss = 0.672298 (* 1 = 0.672298 loss)
I0817 09:46:43.494110 20404 solver.cpp:228] Iteration 14560, loss = 0.817387
I0817 09:46:43.494163 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:46:43.494177 20404 solver.cpp:244]     Train net output #1: loss = 0.817387 (* 1 = 0.817387 loss)
I0817 09:46:43.494190 20404 sgd_solver.cpp:106] Iteration 14560, lr = 0.000509717
I0817 09:47:18.292945 20404 solver.cpp:228] Iteration 14570, loss = 0.81718
I0817 09:47:18.293128 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:47:18.293143 20404 solver.cpp:244]     Train net output #1: loss = 0.81718 (* 1 = 0.81718 loss)
I0817 09:47:18.293155 20404 sgd_solver.cpp:106] Iteration 14570, lr = 0.000509561
I0817 09:47:53.092769 20404 solver.cpp:228] Iteration 14580, loss = 0.817374
I0817 09:47:53.092869 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 09:47:53.092883 20404 solver.cpp:244]     Train net output #1: loss = 0.817374 (* 1 = 0.817374 loss)
I0817 09:47:53.092896 20404 sgd_solver.cpp:106] Iteration 14580, lr = 0.000509406
I0817 09:48:27.904964 20404 solver.cpp:228] Iteration 14590, loss = 0.816913
I0817 09:48:27.905146 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:48:27.905163 20404 solver.cpp:244]     Train net output #1: loss = 0.816913 (* 1 = 0.816913 loss)
I0817 09:48:27.905175 20404 sgd_solver.cpp:106] Iteration 14590, lr = 0.00050925
I0817 09:48:59.241523 20404 solver.cpp:337] Iteration 14600, Testing net (#0)
I0817 09:49:33.811681 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:49:33.811863 20404 solver.cpp:404]     Test net output #1: loss = 0.671583 (* 1 = 0.671583 loss)
I0817 09:49:37.272109 20404 solver.cpp:228] Iteration 14600, loss = 0.816991
I0817 09:49:37.272159 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:49:37.272173 20404 solver.cpp:244]     Train net output #1: loss = 0.816991 (* 1 = 0.816991 loss)
I0817 09:49:37.272186 20404 sgd_solver.cpp:106] Iteration 14600, lr = 0.000509095
I0817 09:50:12.079969 20404 solver.cpp:228] Iteration 14610, loss = 0.81667
I0817 09:50:12.080153 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:50:12.080169 20404 solver.cpp:244]     Train net output #1: loss = 0.81667 (* 1 = 0.81667 loss)
I0817 09:50:12.080183 20404 sgd_solver.cpp:106] Iteration 14610, lr = 0.00050894
I0817 09:50:46.890251 20404 solver.cpp:228] Iteration 14620, loss = 0.816788
I0817 09:50:46.890430 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:50:46.890446 20404 solver.cpp:244]     Train net output #1: loss = 0.816788 (* 1 = 0.816788 loss)
I0817 09:50:46.890458 20404 sgd_solver.cpp:106] Iteration 14620, lr = 0.000508785
I0817 09:51:21.686967 20404 solver.cpp:228] Iteration 14630, loss = 0.817436
I0817 09:51:21.687150 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:51:21.687167 20404 solver.cpp:244]     Train net output #1: loss = 0.817436 (* 1 = 0.817436 loss)
I0817 09:51:21.687180 20404 sgd_solver.cpp:106] Iteration 14630, lr = 0.00050863
I0817 09:51:52.997395 20404 solver.cpp:337] Iteration 14640, Testing net (#0)
I0817 09:52:27.567041 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:52:27.567222 20404 solver.cpp:404]     Test net output #1: loss = 0.672642 (* 1 = 0.672642 loss)
I0817 09:52:31.027757 20404 solver.cpp:228] Iteration 14640, loss = 0.816987
I0817 09:52:31.027812 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:52:31.027825 20404 solver.cpp:244]     Train net output #1: loss = 0.816987 (* 1 = 0.816987 loss)
I0817 09:52:31.027837 20404 sgd_solver.cpp:106] Iteration 14640, lr = 0.000508475
I0817 09:53:05.837059 20404 solver.cpp:228] Iteration 14650, loss = 0.816956
I0817 09:53:05.837245 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:53:05.837262 20404 solver.cpp:244]     Train net output #1: loss = 0.816956 (* 1 = 0.816956 loss)
I0817 09:53:05.837275 20404 sgd_solver.cpp:106] Iteration 14650, lr = 0.00050832
I0817 09:53:40.621115 20404 solver.cpp:228] Iteration 14660, loss = 0.81725
I0817 09:53:40.621295 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:53:40.621311 20404 solver.cpp:244]     Train net output #1: loss = 0.81725 (* 1 = 0.81725 loss)
I0817 09:53:40.621325 20404 sgd_solver.cpp:106] Iteration 14660, lr = 0.000508166
I0817 09:54:15.418086 20404 solver.cpp:228] Iteration 14670, loss = 0.816972
I0817 09:54:15.418357 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 09:54:15.418376 20404 solver.cpp:244]     Train net output #1: loss = 0.816972 (* 1 = 0.816972 loss)
I0817 09:54:15.418391 20404 sgd_solver.cpp:106] Iteration 14670, lr = 0.000508011
I0817 09:54:46.741979 20404 solver.cpp:337] Iteration 14680, Testing net (#0)
I0817 09:55:21.308257 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:55:21.308356 20404 solver.cpp:404]     Test net output #1: loss = 0.67223 (* 1 = 0.67223 loss)
I0817 09:55:24.774617 20404 solver.cpp:228] Iteration 14680, loss = 0.816932
I0817 09:55:24.774672 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:55:24.774687 20404 solver.cpp:244]     Train net output #1: loss = 0.816932 (* 1 = 0.816932 loss)
I0817 09:55:24.774698 20404 sgd_solver.cpp:106] Iteration 14680, lr = 0.000507857
I0817 09:55:59.600693 20404 solver.cpp:228] Iteration 14690, loss = 0.817329
I0817 09:55:59.600811 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:55:59.600826 20404 solver.cpp:244]     Train net output #1: loss = 0.817329 (* 1 = 0.817329 loss)
I0817 09:55:59.600839 20404 sgd_solver.cpp:106] Iteration 14690, lr = 0.000507702
I0817 09:56:34.414167 20404 solver.cpp:228] Iteration 14700, loss = 0.817312
I0817 09:56:34.414340 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 09:56:34.414355 20404 solver.cpp:244]     Train net output #1: loss = 0.817312 (* 1 = 0.817312 loss)
I0817 09:56:34.414368 20404 sgd_solver.cpp:106] Iteration 14700, lr = 0.000507548
I0817 09:57:09.214290 20404 solver.cpp:228] Iteration 14710, loss = 0.817128
I0817 09:57:09.214467 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 09:57:09.214483 20404 solver.cpp:244]     Train net output #1: loss = 0.817128 (* 1 = 0.817128 loss)
I0817 09:57:09.214495 20404 sgd_solver.cpp:106] Iteration 14710, lr = 0.000507394
I0817 09:57:40.553617 20404 solver.cpp:337] Iteration 14720, Testing net (#0)
I0817 09:58:15.095427 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 09:58:15.095510 20404 solver.cpp:404]     Test net output #1: loss = 0.671457 (* 1 = 0.671457 loss)
I0817 09:58:18.562253 20404 solver.cpp:228] Iteration 14720, loss = 0.817236
I0817 09:58:18.562305 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 09:58:18.562320 20404 solver.cpp:244]     Train net output #1: loss = 0.817236 (* 1 = 0.817236 loss)
I0817 09:58:18.562332 20404 sgd_solver.cpp:106] Iteration 14720, lr = 0.00050724
I0817 09:58:53.353276 20404 solver.cpp:228] Iteration 14730, loss = 0.817513
I0817 09:58:53.353366 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 09:58:53.353381 20404 solver.cpp:244]     Train net output #1: loss = 0.817513 (* 1 = 0.817513 loss)
I0817 09:58:53.353394 20404 sgd_solver.cpp:106] Iteration 14730, lr = 0.000507086
I0817 09:59:28.186897 20404 solver.cpp:228] Iteration 14740, loss = 0.81634
I0817 09:59:28.187109 20404 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0817 09:59:28.187127 20404 solver.cpp:244]     Train net output #1: loss = 0.81634 (* 1 = 0.81634 loss)
I0817 09:59:28.187140 20404 sgd_solver.cpp:106] Iteration 14740, lr = 0.000506933
I0817 10:00:02.995857 20404 solver.cpp:228] Iteration 14750, loss = 0.816669
I0817 10:00:02.996031 20404 solver.cpp:244]     Train net output #0: accuracy = 0.71
I0817 10:00:02.996047 20404 solver.cpp:244]     Train net output #1: loss = 0.816669 (* 1 = 0.816669 loss)
I0817 10:00:02.996060 20404 sgd_solver.cpp:106] Iteration 14750, lr = 0.000506779
I0817 10:00:34.305268 20404 solver.cpp:337] Iteration 14760, Testing net (#0)
I0817 10:01:08.864778 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:01:08.864944 20404 solver.cpp:404]     Test net output #1: loss = 0.672232 (* 1 = 0.672232 loss)
I0817 10:01:12.328976 20404 solver.cpp:228] Iteration 14760, loss = 0.816699
I0817 10:01:12.329030 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:01:12.329044 20404 solver.cpp:244]     Train net output #1: loss = 0.816699 (* 1 = 0.816699 loss)
I0817 10:01:12.329056 20404 sgd_solver.cpp:106] Iteration 14760, lr = 0.000506626
I0817 10:01:47.133338 20404 solver.cpp:228] Iteration 14770, loss = 0.816716
I0817 10:01:47.133441 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:01:47.133460 20404 solver.cpp:244]     Train net output #1: loss = 0.816716 (* 1 = 0.816716 loss)
I0817 10:01:47.133476 20404 sgd_solver.cpp:106] Iteration 14770, lr = 0.000506472
I0817 10:02:21.946094 20404 solver.cpp:228] Iteration 14780, loss = 0.816264
I0817 10:02:21.946190 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:02:21.946207 20404 solver.cpp:244]     Train net output #1: loss = 0.816264 (* 1 = 0.816264 loss)
I0817 10:02:21.946218 20404 sgd_solver.cpp:106] Iteration 14780, lr = 0.000506319
I0817 10:02:56.758301 20404 solver.cpp:228] Iteration 14790, loss = 0.817028
I0817 10:02:56.758401 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:02:56.758416 20404 solver.cpp:244]     Train net output #1: loss = 0.817028 (* 1 = 0.817028 loss)
I0817 10:02:56.758429 20404 sgd_solver.cpp:106] Iteration 14790, lr = 0.000506166
I0817 10:03:28.097785 20404 solver.cpp:337] Iteration 14800, Testing net (#0)
I0817 10:04:02.648953 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:04:02.649133 20404 solver.cpp:404]     Test net output #1: loss = 0.672244 (* 1 = 0.672244 loss)
I0817 10:04:06.114755 20404 solver.cpp:228] Iteration 14800, loss = 0.816744
I0817 10:04:06.114809 20404 solver.cpp:244]     Train net output #0: accuracy = 0.96
I0817 10:04:06.114825 20404 solver.cpp:244]     Train net output #1: loss = 0.816744 (* 1 = 0.816744 loss)
I0817 10:04:06.114836 20404 sgd_solver.cpp:106] Iteration 14800, lr = 0.000506013
I0817 10:04:40.918390 20404 solver.cpp:228] Iteration 14810, loss = 0.816583
I0817 10:04:40.918566 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:04:40.918581 20404 solver.cpp:244]     Train net output #1: loss = 0.816583 (* 1 = 0.816583 loss)
I0817 10:04:40.918593 20404 sgd_solver.cpp:106] Iteration 14810, lr = 0.00050586
I0817 10:05:15.722157 20404 solver.cpp:228] Iteration 14820, loss = 0.816891
I0817 10:05:15.722331 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:05:15.722345 20404 solver.cpp:244]     Train net output #1: loss = 0.816891 (* 1 = 0.816891 loss)
I0817 10:05:15.722358 20404 sgd_solver.cpp:106] Iteration 14820, lr = 0.000505707
I0817 10:05:50.529474 20404 solver.cpp:228] Iteration 14830, loss = 0.81679
I0817 10:05:50.529659 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:05:50.529675 20404 solver.cpp:244]     Train net output #1: loss = 0.81679 (* 1 = 0.81679 loss)
I0817 10:05:50.529687 20404 sgd_solver.cpp:106] Iteration 14830, lr = 0.000505554
I0817 10:06:21.879199 20404 solver.cpp:337] Iteration 14840, Testing net (#0)
I0817 10:06:56.435752 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:06:56.435925 20404 solver.cpp:404]     Test net output #1: loss = 0.672426 (* 1 = 0.672426 loss)
I0817 10:06:59.897495 20404 solver.cpp:228] Iteration 14840, loss = 0.816859
I0817 10:06:59.897547 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:06:59.897562 20404 solver.cpp:244]     Train net output #1: loss = 0.816859 (* 1 = 0.816859 loss)
I0817 10:06:59.897573 20404 sgd_solver.cpp:106] Iteration 14840, lr = 0.000505401
I0817 10:07:34.691479 20404 solver.cpp:228] Iteration 14850, loss = 0.817167
I0817 10:07:34.691656 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:07:34.691673 20404 solver.cpp:244]     Train net output #1: loss = 0.817167 (* 1 = 0.817167 loss)
I0817 10:07:34.691685 20404 sgd_solver.cpp:106] Iteration 14850, lr = 0.000505249
I0817 10:08:09.471406 20404 solver.cpp:228] Iteration 14860, loss = 0.81659
I0817 10:08:09.471575 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:08:09.471591 20404 solver.cpp:244]     Train net output #1: loss = 0.81659 (* 1 = 0.81659 loss)
I0817 10:08:09.471604 20404 sgd_solver.cpp:106] Iteration 14860, lr = 0.000505096
I0817 10:08:44.289459 20404 solver.cpp:228] Iteration 14870, loss = 0.816586
I0817 10:08:44.289628 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:08:44.289644 20404 solver.cpp:244]     Train net output #1: loss = 0.816586 (* 1 = 0.816586 loss)
I0817 10:08:44.289656 20404 sgd_solver.cpp:106] Iteration 14870, lr = 0.000504944
I0817 10:09:15.606046 20404 solver.cpp:337] Iteration 14880, Testing net (#0)
I0817 10:09:50.175148 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:09:50.175334 20404 solver.cpp:404]     Test net output #1: loss = 0.672073 (* 1 = 0.672073 loss)
I0817 10:09:53.643023 20404 solver.cpp:228] Iteration 14880, loss = 0.816463
I0817 10:09:53.643076 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:09:53.643091 20404 solver.cpp:244]     Train net output #1: loss = 0.816463 (* 1 = 0.816463 loss)
I0817 10:09:53.643103 20404 sgd_solver.cpp:106] Iteration 14880, lr = 0.000504792
I0817 10:10:28.433631 20404 solver.cpp:228] Iteration 14890, loss = 0.816533
I0817 10:10:28.433727 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 10:10:28.433743 20404 solver.cpp:244]     Train net output #1: loss = 0.816533 (* 1 = 0.816533 loss)
I0817 10:10:28.433755 20404 sgd_solver.cpp:106] Iteration 14890, lr = 0.00050464
I0817 10:11:03.239626 20404 solver.cpp:228] Iteration 14900, loss = 0.816504
I0817 10:11:03.239711 20404 solver.cpp:244]     Train net output #0: accuracy = 0.69
I0817 10:11:03.239727 20404 solver.cpp:244]     Train net output #1: loss = 0.816504 (* 1 = 0.816504 loss)
I0817 10:11:03.239739 20404 sgd_solver.cpp:106] Iteration 14900, lr = 0.000504488
I0817 10:11:38.034799 20404 solver.cpp:228] Iteration 14910, loss = 0.816706
I0817 10:11:38.034979 20404 solver.cpp:244]     Train net output #0: accuracy = 0.87
I0817 10:11:38.034996 20404 solver.cpp:244]     Train net output #1: loss = 0.816706 (* 1 = 0.816706 loss)
I0817 10:11:38.035008 20404 sgd_solver.cpp:106] Iteration 14910, lr = 0.000504336
I0817 10:12:09.357059 20404 solver.cpp:337] Iteration 14920, Testing net (#0)
I0817 10:12:43.903743 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:12:43.903905 20404 solver.cpp:404]     Test net output #1: loss = 0.672139 (* 1 = 0.672139 loss)
I0817 10:12:47.369853 20404 solver.cpp:228] Iteration 14920, loss = 0.816363
I0817 10:12:47.369895 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:12:47.369910 20404 solver.cpp:244]     Train net output #1: loss = 0.816363 (* 1 = 0.816363 loss)
I0817 10:12:47.369925 20404 sgd_solver.cpp:106] Iteration 14920, lr = 0.000504184
I0817 10:13:22.156815 20404 solver.cpp:228] Iteration 14930, loss = 0.81655
I0817 10:13:22.157023 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:13:22.157039 20404 solver.cpp:244]     Train net output #1: loss = 0.81655 (* 1 = 0.81655 loss)
I0817 10:13:22.157052 20404 sgd_solver.cpp:106] Iteration 14930, lr = 0.000504032
I0817 10:13:57.328595 20404 solver.cpp:228] Iteration 14940, loss = 0.816155
I0817 10:13:57.328773 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:13:57.328789 20404 solver.cpp:244]     Train net output #1: loss = 0.816155 (* 1 = 0.816155 loss)
I0817 10:13:57.328802 20404 sgd_solver.cpp:106] Iteration 14940, lr = 0.000503881
I0817 10:14:32.143903 20404 solver.cpp:228] Iteration 14950, loss = 0.816672
I0817 10:14:32.144076 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:14:32.144093 20404 solver.cpp:244]     Train net output #1: loss = 0.816672 (* 1 = 0.816672 loss)
I0817 10:14:32.144105 20404 sgd_solver.cpp:106] Iteration 14950, lr = 0.000503729
I0817 10:15:03.483896 20404 solver.cpp:337] Iteration 14960, Testing net (#0)
I0817 10:15:38.002069 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:15:38.002243 20404 solver.cpp:404]     Test net output #1: loss = 0.67164 (* 1 = 0.67164 loss)
I0817 10:15:41.470532 20404 solver.cpp:228] Iteration 14960, loss = 0.817118
I0817 10:15:41.470574 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:15:41.470589 20404 solver.cpp:244]     Train net output #1: loss = 0.817118 (* 1 = 0.817118 loss)
I0817 10:15:41.470602 20404 sgd_solver.cpp:106] Iteration 14960, lr = 0.000503578
I0817 10:16:16.279266 20404 solver.cpp:228] Iteration 14970, loss = 0.816335
I0817 10:16:16.279399 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:16:16.279415 20404 solver.cpp:244]     Train net output #1: loss = 0.816335 (* 1 = 0.816335 loss)
I0817 10:16:16.279428 20404 sgd_solver.cpp:106] Iteration 14970, lr = 0.000503427
I0817 10:16:51.087306 20404 solver.cpp:228] Iteration 14980, loss = 0.816581
I0817 10:16:51.087404 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:16:51.087420 20404 solver.cpp:244]     Train net output #1: loss = 0.816581 (* 1 = 0.816581 loss)
I0817 10:16:51.087433 20404 sgd_solver.cpp:106] Iteration 14980, lr = 0.000503275
I0817 10:17:25.894790 20404 solver.cpp:228] Iteration 14990, loss = 0.818269
I0817 10:17:25.894968 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:17:25.894985 20404 solver.cpp:244]     Train net output #1: loss = 0.818269 (* 1 = 0.818269 loss)
I0817 10:17:25.894999 20404 sgd_solver.cpp:106] Iteration 14990, lr = 0.000503124
I0817 10:17:57.210937 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_15000.caffemodel
I0817 10:18:17.802794 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_15000.solverstate
I0817 10:18:19.498152 20404 solver.cpp:337] Iteration 15000, Testing net (#0)
I0817 10:18:54.027767 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:18:54.027947 20404 solver.cpp:404]     Test net output #1: loss = 0.671118 (* 1 = 0.671118 loss)
I0817 10:18:57.486222 20404 solver.cpp:228] Iteration 15000, loss = 0.817623
I0817 10:18:57.486263 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:18:57.486281 20404 solver.cpp:244]     Train net output #1: loss = 0.817623 (* 1 = 0.817623 loss)
I0817 10:18:57.486295 20404 sgd_solver.cpp:106] Iteration 15000, lr = 0.000502973
I0817 10:19:32.258780 20404 solver.cpp:228] Iteration 15010, loss = 0.81729
I0817 10:19:32.258965 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:19:32.258985 20404 solver.cpp:244]     Train net output #1: loss = 0.81729 (* 1 = 0.81729 loss)
I0817 10:19:32.258997 20404 sgd_solver.cpp:106] Iteration 15010, lr = 0.000502823
I0817 10:20:07.045496 20404 solver.cpp:228] Iteration 15020, loss = 0.817213
I0817 10:20:07.045670 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:20:07.045691 20404 solver.cpp:244]     Train net output #1: loss = 0.817213 (* 1 = 0.817213 loss)
I0817 10:20:07.045704 20404 sgd_solver.cpp:106] Iteration 15020, lr = 0.000502672
I0817 10:20:41.947919 20404 solver.cpp:228] Iteration 15030, loss = 0.816112
I0817 10:20:41.948127 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:20:41.948144 20404 solver.cpp:244]     Train net output #1: loss = 0.816112 (* 1 = 0.816112 loss)
I0817 10:20:41.948158 20404 sgd_solver.cpp:106] Iteration 15030, lr = 0.000502521
I0817 10:21:13.505116 20404 solver.cpp:337] Iteration 15040, Testing net (#0)
I0817 10:21:48.312546 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:21:48.312724 20404 solver.cpp:404]     Test net output #1: loss = 0.672042 (* 1 = 0.672042 loss)
I0817 10:21:51.801313 20404 solver.cpp:228] Iteration 15040, loss = 0.816066
I0817 10:21:51.801357 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:21:51.801385 20404 solver.cpp:244]     Train net output #1: loss = 0.816066 (* 1 = 0.816066 loss)
I0817 10:21:51.801401 20404 sgd_solver.cpp:106] Iteration 15040, lr = 0.000502371
I0817 10:22:26.813326 20404 solver.cpp:228] Iteration 15050, loss = 0.816341
I0817 10:22:26.813513 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:22:26.813529 20404 solver.cpp:244]     Train net output #1: loss = 0.816341 (* 1 = 0.816341 loss)
I0817 10:22:26.813541 20404 sgd_solver.cpp:106] Iteration 15050, lr = 0.00050222
I0817 10:23:01.819427 20404 solver.cpp:228] Iteration 15060, loss = 0.816554
I0817 10:23:01.819592 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:23:01.819607 20404 solver.cpp:244]     Train net output #1: loss = 0.816554 (* 1 = 0.816554 loss)
I0817 10:23:01.819620 20404 sgd_solver.cpp:106] Iteration 15060, lr = 0.00050207
I0817 10:23:36.856580 20404 solver.cpp:228] Iteration 15070, loss = 0.816566
I0817 10:23:36.856763 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:23:36.856778 20404 solver.cpp:244]     Train net output #1: loss = 0.816566 (* 1 = 0.816566 loss)
I0817 10:23:36.856791 20404 sgd_solver.cpp:106] Iteration 15070, lr = 0.00050192
I0817 10:24:08.390410 20404 solver.cpp:337] Iteration 15080, Testing net (#0)
I0817 10:24:43.168514 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:24:43.168690 20404 solver.cpp:404]     Test net output #1: loss = 0.672036 (* 1 = 0.672036 loss)
I0817 10:24:46.655246 20404 solver.cpp:228] Iteration 15080, loss = 0.816887
I0817 10:24:46.655300 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:24:46.655315 20404 solver.cpp:244]     Train net output #1: loss = 0.816887 (* 1 = 0.816887 loss)
I0817 10:24:46.655328 20404 sgd_solver.cpp:106] Iteration 15080, lr = 0.00050177
I0817 10:25:21.665182 20404 solver.cpp:228] Iteration 15090, loss = 0.816435
I0817 10:25:21.665354 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:25:21.665369 20404 solver.cpp:244]     Train net output #1: loss = 0.816435 (* 1 = 0.816435 loss)
I0817 10:25:21.665383 20404 sgd_solver.cpp:106] Iteration 15090, lr = 0.00050162
I0817 10:25:56.708545 20404 solver.cpp:228] Iteration 15100, loss = 0.81625
I0817 10:25:56.708714 20404 solver.cpp:244]     Train net output #0: accuracy = 0.95
I0817 10:25:56.708729 20404 solver.cpp:244]     Train net output #1: loss = 0.81625 (* 1 = 0.81625 loss)
I0817 10:25:56.708742 20404 sgd_solver.cpp:106] Iteration 15100, lr = 0.00050147
I0817 10:26:31.745383 20404 solver.cpp:228] Iteration 15110, loss = 0.8159
I0817 10:26:31.745483 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:26:31.745501 20404 solver.cpp:244]     Train net output #1: loss = 0.8159 (* 1 = 0.8159 loss)
I0817 10:26:31.745517 20404 sgd_solver.cpp:106] Iteration 15110, lr = 0.00050132
I0817 10:27:03.298089 20404 solver.cpp:337] Iteration 15120, Testing net (#0)
I0817 10:27:38.084133 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:27:38.084311 20404 solver.cpp:404]     Test net output #1: loss = 0.672008 (* 1 = 0.672008 loss)
I0817 10:27:41.569736 20404 solver.cpp:228] Iteration 15120, loss = 0.816861
I0817 10:27:41.569779 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:27:41.569797 20404 solver.cpp:244]     Train net output #1: loss = 0.816861 (* 1 = 0.816861 loss)
I0817 10:27:41.569813 20404 sgd_solver.cpp:106] Iteration 15120, lr = 0.00050117
I0817 10:28:16.614696 20404 solver.cpp:228] Iteration 15130, loss = 0.816113
I0817 10:28:16.614910 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:28:16.614931 20404 solver.cpp:244]     Train net output #1: loss = 0.816113 (* 1 = 0.816113 loss)
I0817 10:28:16.614946 20404 sgd_solver.cpp:106] Iteration 15130, lr = 0.000501021
I0817 10:28:51.656888 20404 solver.cpp:228] Iteration 15140, loss = 0.816271
I0817 10:28:51.657081 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:28:51.657100 20404 solver.cpp:244]     Train net output #1: loss = 0.816271 (* 1 = 0.816271 loss)
I0817 10:28:51.657117 20404 sgd_solver.cpp:106] Iteration 15140, lr = 0.000500871
I0817 10:29:26.715301 20404 solver.cpp:228] Iteration 15150, loss = 0.816308
I0817 10:29:26.715473 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:29:26.715492 20404 solver.cpp:244]     Train net output #1: loss = 0.816308 (* 1 = 0.816308 loss)
I0817 10:29:26.715508 20404 sgd_solver.cpp:106] Iteration 15150, lr = 0.000500722
I0817 10:29:58.293581 20404 solver.cpp:337] Iteration 15160, Testing net (#0)
I0817 10:30:33.095499 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:30:33.095676 20404 solver.cpp:404]     Test net output #1: loss = 0.672279 (* 1 = 0.672279 loss)
I0817 10:30:36.584597 20404 solver.cpp:228] Iteration 15160, loss = 0.81597
I0817 10:30:36.584648 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:30:36.584662 20404 solver.cpp:244]     Train net output #1: loss = 0.81597 (* 1 = 0.81597 loss)
I0817 10:30:36.584674 20404 sgd_solver.cpp:106] Iteration 15160, lr = 0.000500573
I0817 10:31:11.613322 20404 solver.cpp:228] Iteration 15170, loss = 0.816848
I0817 10:31:11.613498 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:31:11.613514 20404 solver.cpp:244]     Train net output #1: loss = 0.816848 (* 1 = 0.816848 loss)
I0817 10:31:11.613528 20404 sgd_solver.cpp:106] Iteration 15170, lr = 0.000500423
I0817 10:31:46.658772 20404 solver.cpp:228] Iteration 15180, loss = 0.816111
I0817 10:31:46.658874 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:31:46.658890 20404 solver.cpp:244]     Train net output #1: loss = 0.816111 (* 1 = 0.816111 loss)
I0817 10:31:46.658902 20404 sgd_solver.cpp:106] Iteration 15180, lr = 0.000500274
I0817 10:32:21.689218 20404 solver.cpp:228] Iteration 15190, loss = 0.816857
I0817 10:32:21.689400 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:32:21.689416 20404 solver.cpp:244]     Train net output #1: loss = 0.816857 (* 1 = 0.816857 loss)
I0817 10:32:21.689429 20404 sgd_solver.cpp:106] Iteration 15190, lr = 0.000500125
I0817 10:32:53.223932 20404 solver.cpp:337] Iteration 15200, Testing net (#0)
I0817 10:33:28.022766 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:33:28.022850 20404 solver.cpp:404]     Test net output #1: loss = 0.672255 (* 1 = 0.672255 loss)
I0817 10:33:31.510843 20404 solver.cpp:228] Iteration 15200, loss = 0.816327
I0817 10:33:31.510885 20404 solver.cpp:244]     Train net output #0: accuracy = 0.99
I0817 10:33:31.510900 20404 solver.cpp:244]     Train net output #1: loss = 0.816327 (* 1 = 0.816327 loss)
I0817 10:33:31.510913 20404 sgd_solver.cpp:106] Iteration 15200, lr = 0.000499977
I0817 10:34:06.553959 20404 solver.cpp:228] Iteration 15210, loss = 0.816165
I0817 10:34:06.554127 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:34:06.554143 20404 solver.cpp:244]     Train net output #1: loss = 0.816165 (* 1 = 0.816165 loss)
I0817 10:34:06.554157 20404 sgd_solver.cpp:106] Iteration 15210, lr = 0.000499828
I0817 10:34:41.617662 20404 solver.cpp:228] Iteration 15220, loss = 0.815426
I0817 10:34:41.617871 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:34:41.617887 20404 solver.cpp:244]     Train net output #1: loss = 0.815426 (* 1 = 0.815426 loss)
I0817 10:34:41.617899 20404 sgd_solver.cpp:106] Iteration 15220, lr = 0.000499679
I0817 10:35:16.683984 20404 solver.cpp:228] Iteration 15230, loss = 0.816205
I0817 10:35:16.684155 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:35:16.684171 20404 solver.cpp:244]     Train net output #1: loss = 0.816205 (* 1 = 0.816205 loss)
I0817 10:35:16.684190 20404 sgd_solver.cpp:106] Iteration 15230, lr = 0.000499531
I0817 10:35:48.247522 20404 solver.cpp:337] Iteration 15240, Testing net (#0)
I0817 10:36:23.047618 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:36:23.047791 20404 solver.cpp:404]     Test net output #1: loss = 0.671757 (* 1 = 0.671757 loss)
I0817 10:36:26.534562 20404 solver.cpp:228] Iteration 15240, loss = 0.816591
I0817 10:36:26.534616 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:36:26.534631 20404 solver.cpp:244]     Train net output #1: loss = 0.816591 (* 1 = 0.816591 loss)
I0817 10:36:26.534643 20404 sgd_solver.cpp:106] Iteration 15240, lr = 0.000499382
I0817 10:37:01.554888 20404 solver.cpp:228] Iteration 15250, loss = 0.815532
I0817 10:37:01.555055 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:37:01.555070 20404 solver.cpp:244]     Train net output #1: loss = 0.815532 (* 1 = 0.815532 loss)
I0817 10:37:01.555084 20404 sgd_solver.cpp:106] Iteration 15250, lr = 0.000499234
I0817 10:37:36.615691 20404 solver.cpp:228] Iteration 15260, loss = 0.81574
I0817 10:37:36.615872 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:37:36.615888 20404 solver.cpp:244]     Train net output #1: loss = 0.81574 (* 1 = 0.81574 loss)
I0817 10:37:36.615901 20404 sgd_solver.cpp:106] Iteration 15260, lr = 0.000499086
I0817 10:38:11.690412 20404 solver.cpp:228] Iteration 15270, loss = 0.816847
I0817 10:38:11.690585 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:38:11.690605 20404 solver.cpp:244]     Train net output #1: loss = 0.816847 (* 1 = 0.816847 loss)
I0817 10:38:11.690618 20404 sgd_solver.cpp:106] Iteration 15270, lr = 0.000498937
I0817 10:38:43.250543 20404 solver.cpp:337] Iteration 15280, Testing net (#0)
I0817 10:39:18.039180 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:39:18.039433 20404 solver.cpp:404]     Test net output #1: loss = 0.672535 (* 1 = 0.672535 loss)
I0817 10:39:21.529711 20404 solver.cpp:228] Iteration 15280, loss = 0.816257
I0817 10:39:21.529762 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:39:21.529774 20404 solver.cpp:244]     Train net output #1: loss = 0.816257 (* 1 = 0.816257 loss)
I0817 10:39:21.529786 20404 sgd_solver.cpp:106] Iteration 15280, lr = 0.000498789
I0817 10:39:56.580242 20404 solver.cpp:228] Iteration 15290, loss = 0.8167
I0817 10:39:56.580425 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:39:56.580445 20404 solver.cpp:244]     Train net output #1: loss = 0.8167 (* 1 = 0.8167 loss)
I0817 10:39:56.580457 20404 sgd_solver.cpp:106] Iteration 15290, lr = 0.000498642
I0817 10:40:31.621359 20404 solver.cpp:228] Iteration 15300, loss = 0.816293
I0817 10:40:31.621448 20404 solver.cpp:244]     Train net output #0: accuracy = 0.66
I0817 10:40:31.621466 20404 solver.cpp:244]     Train net output #1: loss = 0.816293 (* 1 = 0.816293 loss)
I0817 10:40:31.621489 20404 sgd_solver.cpp:106] Iteration 15300, lr = 0.000498494
I0817 10:41:06.630870 20404 solver.cpp:228] Iteration 15310, loss = 0.81607
I0817 10:41:06.630944 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:41:06.630962 20404 solver.cpp:244]     Train net output #1: loss = 0.81607 (* 1 = 0.81607 loss)
I0817 10:41:06.630988 20404 sgd_solver.cpp:106] Iteration 15310, lr = 0.000498346
I0817 10:41:38.188655 20404 solver.cpp:337] Iteration 15320, Testing net (#0)
I0817 10:42:12.985914 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:42:12.986130 20404 solver.cpp:404]     Test net output #1: loss = 0.671943 (* 1 = 0.671943 loss)
I0817 10:42:16.477623 20404 solver.cpp:228] Iteration 15320, loss = 0.816205
I0817 10:42:16.477668 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:42:16.477685 20404 solver.cpp:244]     Train net output #1: loss = 0.816205 (* 1 = 0.816205 loss)
I0817 10:42:16.477710 20404 sgd_solver.cpp:106] Iteration 15320, lr = 0.000498198
I0817 10:42:51.552058 20404 solver.cpp:228] Iteration 15330, loss = 0.816809
I0817 10:42:51.552242 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:42:51.552261 20404 solver.cpp:244]     Train net output #1: loss = 0.816809 (* 1 = 0.816809 loss)
I0817 10:42:51.552274 20404 sgd_solver.cpp:106] Iteration 15330, lr = 0.000498051
I0817 10:43:26.595191 20404 solver.cpp:228] Iteration 15340, loss = 0.816455
I0817 10:43:26.595294 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:43:26.595309 20404 solver.cpp:244]     Train net output #1: loss = 0.816455 (* 1 = 0.816455 loss)
I0817 10:43:26.595322 20404 sgd_solver.cpp:106] Iteration 15340, lr = 0.000497903
I0817 10:44:01.642945 20404 solver.cpp:228] Iteration 15350, loss = 0.816448
I0817 10:44:01.643121 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:44:01.643136 20404 solver.cpp:244]     Train net output #1: loss = 0.816448 (* 1 = 0.816448 loss)
I0817 10:44:01.643147 20404 sgd_solver.cpp:106] Iteration 15350, lr = 0.000497756
I0817 10:44:33.203539 20404 solver.cpp:337] Iteration 15360, Testing net (#0)
I0817 10:45:08.015382 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:45:08.015486 20404 solver.cpp:404]     Test net output #1: loss = 0.672208 (* 1 = 0.672208 loss)
I0817 10:45:11.504170 20404 solver.cpp:228] Iteration 15360, loss = 0.815228
I0817 10:45:11.504214 20404 solver.cpp:244]     Train net output #0: accuracy = 0.94
I0817 10:45:11.504231 20404 solver.cpp:244]     Train net output #1: loss = 0.815228 (* 1 = 0.815228 loss)
I0817 10:45:11.504256 20404 sgd_solver.cpp:106] Iteration 15360, lr = 0.000497609
I0817 10:45:46.562811 20404 solver.cpp:228] Iteration 15370, loss = 0.816835
I0817 10:45:46.562997 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:45:46.563016 20404 solver.cpp:244]     Train net output #1: loss = 0.816835 (* 1 = 0.816835 loss)
I0817 10:45:46.563033 20404 sgd_solver.cpp:106] Iteration 15370, lr = 0.000497462
I0817 10:46:21.619388 20404 solver.cpp:228] Iteration 15380, loss = 0.816362
I0817 10:46:21.619565 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:46:21.619585 20404 solver.cpp:244]     Train net output #1: loss = 0.816362 (* 1 = 0.816362 loss)
I0817 10:46:21.619599 20404 sgd_solver.cpp:106] Iteration 15380, lr = 0.000497315
I0817 10:46:56.670616 20404 solver.cpp:228] Iteration 15390, loss = 0.817191
I0817 10:46:56.670711 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:46:56.670727 20404 solver.cpp:244]     Train net output #1: loss = 0.817191 (* 1 = 0.817191 loss)
I0817 10:46:56.670740 20404 sgd_solver.cpp:106] Iteration 15390, lr = 0.000497168
I0817 10:47:28.217067 20404 solver.cpp:337] Iteration 15400, Testing net (#0)
I0817 10:48:03.031034 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:48:03.031111 20404 solver.cpp:404]     Test net output #1: loss = 0.672447 (* 1 = 0.672447 loss)
I0817 10:48:06.520710 20404 solver.cpp:228] Iteration 15400, loss = 0.815574
I0817 10:48:06.520761 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:48:06.520776 20404 solver.cpp:244]     Train net output #1: loss = 0.815574 (* 1 = 0.815574 loss)
I0817 10:48:06.520789 20404 sgd_solver.cpp:106] Iteration 15400, lr = 0.000497021
I0817 10:48:41.544589 20404 solver.cpp:228] Iteration 15410, loss = 0.815644
I0817 10:48:41.544769 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:48:41.544785 20404 solver.cpp:244]     Train net output #1: loss = 0.815644 (* 1 = 0.815644 loss)
I0817 10:48:41.544797 20404 sgd_solver.cpp:106] Iteration 15410, lr = 0.000496874
I0817 10:49:16.604703 20404 solver.cpp:228] Iteration 15420, loss = 0.815987
I0817 10:49:16.604851 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:49:16.604867 20404 solver.cpp:244]     Train net output #1: loss = 0.815987 (* 1 = 0.815987 loss)
I0817 10:49:16.604881 20404 sgd_solver.cpp:106] Iteration 15420, lr = 0.000496728
I0817 10:49:51.623224 20404 solver.cpp:228] Iteration 15430, loss = 0.816104
I0817 10:49:51.623404 20404 solver.cpp:244]     Train net output #0: accuracy = 0.73
I0817 10:49:51.623420 20404 solver.cpp:244]     Train net output #1: loss = 0.816104 (* 1 = 0.816104 loss)
I0817 10:49:51.623432 20404 sgd_solver.cpp:106] Iteration 15430, lr = 0.000496581
I0817 10:50:23.167220 20404 solver.cpp:337] Iteration 15440, Testing net (#0)
I0817 10:50:57.954231 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:50:57.954324 20404 solver.cpp:404]     Test net output #1: loss = 0.672481 (* 1 = 0.672481 loss)
I0817 10:51:01.436326 20404 solver.cpp:228] Iteration 15440, loss = 0.816138
I0817 10:51:01.436375 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:51:01.436389 20404 solver.cpp:244]     Train net output #1: loss = 0.816138 (* 1 = 0.816138 loss)
I0817 10:51:01.436401 20404 sgd_solver.cpp:106] Iteration 15440, lr = 0.000496435
I0817 10:51:36.426486 20404 solver.cpp:228] Iteration 15450, loss = 0.81579
I0817 10:51:36.426672 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:51:36.426688 20404 solver.cpp:244]     Train net output #1: loss = 0.81579 (* 1 = 0.81579 loss)
I0817 10:51:36.426700 20404 sgd_solver.cpp:106] Iteration 15450, lr = 0.000496288
I0817 10:52:11.477025 20404 solver.cpp:228] Iteration 15460, loss = 0.815607
I0817 10:52:11.477202 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:52:11.477218 20404 solver.cpp:244]     Train net output #1: loss = 0.815607 (* 1 = 0.815607 loss)
I0817 10:52:11.477231 20404 sgd_solver.cpp:106] Iteration 15460, lr = 0.000496142
I0817 10:52:46.521968 20404 solver.cpp:228] Iteration 15470, loss = 0.816118
I0817 10:52:46.522148 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:52:46.522164 20404 solver.cpp:244]     Train net output #1: loss = 0.816118 (* 1 = 0.816118 loss)
I0817 10:52:46.522177 20404 sgd_solver.cpp:106] Iteration 15470, lr = 0.000495996
I0817 10:53:18.078321 20404 solver.cpp:337] Iteration 15480, Testing net (#0)
I0817 10:53:52.861585 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:53:52.861754 20404 solver.cpp:404]     Test net output #1: loss = 0.672487 (* 1 = 0.672487 loss)
I0817 10:53:56.351765 20404 solver.cpp:228] Iteration 15480, loss = 0.815297
I0817 10:53:56.351805 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:53:56.351819 20404 solver.cpp:244]     Train net output #1: loss = 0.815297 (* 1 = 0.815297 loss)
I0817 10:53:56.351832 20404 sgd_solver.cpp:106] Iteration 15480, lr = 0.00049585
I0817 10:54:31.394873 20404 solver.cpp:228] Iteration 15490, loss = 0.816064
I0817 10:54:31.395061 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 10:54:31.395079 20404 solver.cpp:244]     Train net output #1: loss = 0.816064 (* 1 = 0.816064 loss)
I0817 10:54:31.395094 20404 sgd_solver.cpp:106] Iteration 15490, lr = 0.000495704
I0817 10:55:06.434922 20404 solver.cpp:228] Iteration 15500, loss = 0.815574
I0817 10:55:06.435113 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:55:06.435132 20404 solver.cpp:244]     Train net output #1: loss = 0.815574 (* 1 = 0.815574 loss)
I0817 10:55:06.435148 20404 sgd_solver.cpp:106] Iteration 15500, lr = 0.000495558
I0817 10:55:41.489020 20404 solver.cpp:228] Iteration 15510, loss = 0.816196
I0817 10:55:41.489200 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:55:41.489218 20404 solver.cpp:244]     Train net output #1: loss = 0.816196 (* 1 = 0.816196 loss)
I0817 10:55:41.489233 20404 sgd_solver.cpp:106] Iteration 15510, lr = 0.000495413
I0817 10:56:13.062186 20404 solver.cpp:337] Iteration 15520, Testing net (#0)
I0817 10:56:47.873123 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:56:47.873298 20404 solver.cpp:404]     Test net output #1: loss = 0.671763 (* 1 = 0.671763 loss)
I0817 10:56:51.361279 20404 solver.cpp:228] Iteration 15520, loss = 0.815666
I0817 10:56:51.361328 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 10:56:51.361342 20404 solver.cpp:244]     Train net output #1: loss = 0.815666 (* 1 = 0.815666 loss)
I0817 10:56:51.361356 20404 sgd_solver.cpp:106] Iteration 15520, lr = 0.000495267
I0817 10:57:26.382141 20404 solver.cpp:228] Iteration 15530, loss = 0.815678
I0817 10:57:26.382328 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:57:26.382342 20404 solver.cpp:244]     Train net output #1: loss = 0.815678 (* 1 = 0.815678 loss)
I0817 10:57:26.382355 20404 sgd_solver.cpp:106] Iteration 15530, lr = 0.000495122
I0817 10:58:01.442297 20404 solver.cpp:228] Iteration 15540, loss = 0.816161
I0817 10:58:01.442483 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 10:58:01.442500 20404 solver.cpp:244]     Train net output #1: loss = 0.816161 (* 1 = 0.816161 loss)
I0817 10:58:01.442514 20404 sgd_solver.cpp:106] Iteration 15540, lr = 0.000494976
I0817 10:58:36.488286 20404 solver.cpp:228] Iteration 15550, loss = 0.815491
I0817 10:58:36.488472 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 10:58:36.488490 20404 solver.cpp:244]     Train net output #1: loss = 0.815491 (* 1 = 0.815491 loss)
I0817 10:58:36.488505 20404 sgd_solver.cpp:106] Iteration 15550, lr = 0.000494831
I0817 10:59:08.013109 20404 solver.cpp:337] Iteration 15560, Testing net (#0)
I0817 10:59:42.807860 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 10:59:42.807973 20404 solver.cpp:404]     Test net output #1: loss = 0.671515 (* 1 = 0.671515 loss)
I0817 10:59:46.299372 20404 solver.cpp:228] Iteration 15560, loss = 0.816073
I0817 10:59:46.299417 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 10:59:46.299435 20404 solver.cpp:244]     Train net output #1: loss = 0.816073 (* 1 = 0.816073 loss)
I0817 10:59:46.299463 20404 sgd_solver.cpp:106] Iteration 15560, lr = 0.000494686
I0817 11:00:21.341581 20404 solver.cpp:228] Iteration 15570, loss = 0.816308
I0817 11:00:21.341758 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:00:21.341774 20404 solver.cpp:244]     Train net output #1: loss = 0.816308 (* 1 = 0.816308 loss)
I0817 11:00:21.341789 20404 sgd_solver.cpp:106] Iteration 15570, lr = 0.000494541
I0817 11:00:56.351244 20404 solver.cpp:228] Iteration 15580, loss = 0.817168
I0817 11:00:56.351423 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:00:56.351438 20404 solver.cpp:244]     Train net output #1: loss = 0.817168 (* 1 = 0.817168 loss)
I0817 11:00:56.351451 20404 sgd_solver.cpp:106] Iteration 15580, lr = 0.000494396
I0817 11:01:31.387025 20404 solver.cpp:228] Iteration 15590, loss = 0.81641
I0817 11:01:31.387189 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:01:31.387205 20404 solver.cpp:244]     Train net output #1: loss = 0.81641 (* 1 = 0.81641 loss)
I0817 11:01:31.387218 20404 sgd_solver.cpp:106] Iteration 15590, lr = 0.000494251
I0817 11:02:02.933673 20404 solver.cpp:337] Iteration 15600, Testing net (#0)
I0817 11:02:37.715998 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:02:37.716172 20404 solver.cpp:404]     Test net output #1: loss = 0.672067 (* 1 = 0.672067 loss)
I0817 11:02:41.208519 20404 solver.cpp:228] Iteration 15600, loss = 0.815599
I0817 11:02:41.208570 20404 solver.cpp:244]     Train net output #0: accuracy = 0.81
I0817 11:02:41.208585 20404 solver.cpp:244]     Train net output #1: loss = 0.815599 (* 1 = 0.815599 loss)
I0817 11:02:41.208596 20404 sgd_solver.cpp:106] Iteration 15600, lr = 0.000494106
I0817 11:03:16.243412 20404 solver.cpp:228] Iteration 15610, loss = 0.815795
I0817 11:03:16.243597 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:03:16.243613 20404 solver.cpp:244]     Train net output #1: loss = 0.815795 (* 1 = 0.815795 loss)
I0817 11:03:16.243626 20404 sgd_solver.cpp:106] Iteration 15610, lr = 0.000493961
I0817 11:03:51.280917 20404 solver.cpp:228] Iteration 15620, loss = 0.815395
I0817 11:03:51.281138 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:03:51.281154 20404 solver.cpp:244]     Train net output #1: loss = 0.815395 (* 1 = 0.815395 loss)
I0817 11:03:51.281167 20404 sgd_solver.cpp:106] Iteration 15620, lr = 0.000493817
I0817 11:04:26.302549 20404 solver.cpp:228] Iteration 15630, loss = 0.815843
I0817 11:04:26.302736 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:04:26.302752 20404 solver.cpp:244]     Train net output #1: loss = 0.815843 (* 1 = 0.815843 loss)
I0817 11:04:26.302767 20404 sgd_solver.cpp:106] Iteration 15630, lr = 0.000493672
I0817 11:04:57.846989 20404 solver.cpp:337] Iteration 15640, Testing net (#0)
I0817 11:05:32.611722 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:05:32.611898 20404 solver.cpp:404]     Test net output #1: loss = 0.671684 (* 1 = 0.671684 loss)
I0817 11:05:36.102663 20404 solver.cpp:228] Iteration 15640, loss = 0.815759
I0817 11:05:36.102717 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:05:36.102732 20404 solver.cpp:244]     Train net output #1: loss = 0.815759 (* 1 = 0.815759 loss)
I0817 11:05:36.102744 20404 sgd_solver.cpp:106] Iteration 15640, lr = 0.000493528
I0817 11:06:11.120059 20404 solver.cpp:228] Iteration 15650, loss = 0.815683
I0817 11:06:11.120239 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 11:06:11.120256 20404 solver.cpp:244]     Train net output #1: loss = 0.815683 (* 1 = 0.815683 loss)
I0817 11:06:11.120270 20404 sgd_solver.cpp:106] Iteration 15650, lr = 0.000493383
I0817 11:06:46.130745 20404 solver.cpp:228] Iteration 15660, loss = 0.815517
I0817 11:06:46.130923 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:06:46.130939 20404 solver.cpp:244]     Train net output #1: loss = 0.815517 (* 1 = 0.815517 loss)
I0817 11:06:46.130952 20404 sgd_solver.cpp:106] Iteration 15660, lr = 0.000493239
I0817 11:07:21.163650 20404 solver.cpp:228] Iteration 15670, loss = 0.815798
I0817 11:07:21.163830 20404 solver.cpp:244]     Train net output #0: accuracy = 0.93
I0817 11:07:21.163846 20404 solver.cpp:244]     Train net output #1: loss = 0.815798 (* 1 = 0.815798 loss)
I0817 11:07:21.163858 20404 sgd_solver.cpp:106] Iteration 15670, lr = 0.000493095
I0817 11:07:52.706650 20404 solver.cpp:337] Iteration 15680, Testing net (#0)
I0817 11:08:27.499903 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:08:27.500082 20404 solver.cpp:404]     Test net output #1: loss = 0.672048 (* 1 = 0.672048 loss)
I0817 11:08:30.987061 20404 solver.cpp:228] Iteration 15680, loss = 0.815391
I0817 11:08:30.987114 20404 solver.cpp:244]     Train net output #0: accuracy = 0.77
I0817 11:08:30.987129 20404 solver.cpp:244]     Train net output #1: loss = 0.815391 (* 1 = 0.815391 loss)
I0817 11:08:30.987140 20404 sgd_solver.cpp:106] Iteration 15680, lr = 0.000492951
I0817 11:09:06.018112 20404 solver.cpp:228] Iteration 15690, loss = 0.815055
I0817 11:09:06.018297 20404 solver.cpp:244]     Train net output #0: accuracy = 0.7
I0817 11:09:06.018316 20404 solver.cpp:244]     Train net output #1: loss = 0.815055 (* 1 = 0.815055 loss)
I0817 11:09:06.018329 20404 sgd_solver.cpp:106] Iteration 15690, lr = 0.000492807
I0817 11:09:41.039109 20404 solver.cpp:228] Iteration 15700, loss = 0.815509
I0817 11:09:41.039295 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:09:41.039314 20404 solver.cpp:244]     Train net output #1: loss = 0.815509 (* 1 = 0.815509 loss)
I0817 11:09:41.039330 20404 sgd_solver.cpp:106] Iteration 15700, lr = 0.000492663
I0817 11:10:16.083446 20404 solver.cpp:228] Iteration 15710, loss = 0.815856
I0817 11:10:16.083525 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:10:16.083554 20404 solver.cpp:244]     Train net output #1: loss = 0.815856 (* 1 = 0.815856 loss)
I0817 11:10:16.083570 20404 sgd_solver.cpp:106] Iteration 15710, lr = 0.00049252
I0817 11:10:47.611641 20404 solver.cpp:337] Iteration 15720, Testing net (#0)
I0817 11:11:22.406179 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:11:22.406365 20404 solver.cpp:404]     Test net output #1: loss = 0.671681 (* 1 = 0.671681 loss)
I0817 11:11:25.894829 20404 solver.cpp:228] Iteration 15720, loss = 0.815716
I0817 11:11:25.894871 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:11:25.894901 20404 solver.cpp:244]     Train net output #1: loss = 0.815716 (* 1 = 0.815716 loss)
I0817 11:11:25.894917 20404 sgd_solver.cpp:106] Iteration 15720, lr = 0.000492376
I0817 11:12:00.921247 20404 solver.cpp:228] Iteration 15730, loss = 0.815475
I0817 11:12:00.921357 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:12:00.921377 20404 solver.cpp:244]     Train net output #1: loss = 0.815475 (* 1 = 0.815475 loss)
I0817 11:12:00.921393 20404 sgd_solver.cpp:106] Iteration 15730, lr = 0.000492232
I0817 11:12:35.955648 20404 solver.cpp:228] Iteration 15740, loss = 0.814919
I0817 11:12:35.955831 20404 solver.cpp:244]     Train net output #0: accuracy = 0.72
I0817 11:12:35.955850 20404 solver.cpp:244]     Train net output #1: loss = 0.814919 (* 1 = 0.814919 loss)
I0817 11:12:35.955867 20404 sgd_solver.cpp:106] Iteration 15740, lr = 0.000492089
I0817 11:13:10.982600 20404 solver.cpp:228] Iteration 15750, loss = 0.815109
I0817 11:13:10.982774 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 11:13:10.982789 20404 solver.cpp:244]     Train net output #1: loss = 0.815109 (* 1 = 0.815109 loss)
I0817 11:13:10.982802 20404 sgd_solver.cpp:106] Iteration 15750, lr = 0.000491946
I0817 11:13:42.940621 20404 solver.cpp:337] Iteration 15760, Testing net (#0)
I0817 11:14:17.837375 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:14:17.837553 20404 solver.cpp:404]     Test net output #1: loss = 0.672224 (* 1 = 0.672224 loss)
I0817 11:14:21.337592 20404 solver.cpp:228] Iteration 15760, loss = 0.814749
I0817 11:14:21.337644 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:14:21.337658 20404 solver.cpp:244]     Train net output #1: loss = 0.814749 (* 1 = 0.814749 loss)
I0817 11:14:21.337669 20404 sgd_solver.cpp:106] Iteration 15760, lr = 0.000491802
I0817 11:14:56.455368 20404 solver.cpp:228] Iteration 15770, loss = 0.815532
I0817 11:14:56.455545 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 11:14:56.455560 20404 solver.cpp:244]     Train net output #1: loss = 0.815532 (* 1 = 0.815532 loss)
I0817 11:14:56.455572 20404 sgd_solver.cpp:106] Iteration 15770, lr = 0.000491659
I0817 11:15:31.596916 20404 solver.cpp:228] Iteration 15780, loss = 0.815932
I0817 11:15:31.596999 20404 solver.cpp:244]     Train net output #0: accuracy = 0.78
I0817 11:15:31.597014 20404 solver.cpp:244]     Train net output #1: loss = 0.815932 (* 1 = 0.815932 loss)
I0817 11:15:31.597026 20404 sgd_solver.cpp:106] Iteration 15780, lr = 0.000491516
I0817 11:16:06.712235 20404 solver.cpp:228] Iteration 15790, loss = 0.815018
I0817 11:16:06.712421 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:16:06.712436 20404 solver.cpp:244]     Train net output #1: loss = 0.815018 (* 1 = 0.815018 loss)
I0817 11:16:06.712450 20404 sgd_solver.cpp:106] Iteration 15790, lr = 0.000491373
I0817 11:16:38.348620 20404 solver.cpp:337] Iteration 15800, Testing net (#0)
I0817 11:17:13.235879 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:17:13.236058 20404 solver.cpp:404]     Test net output #1: loss = 0.672235 (* 1 = 0.672235 loss)
I0817 11:17:16.738826 20404 solver.cpp:228] Iteration 15800, loss = 0.81509
I0817 11:17:16.738867 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:17:16.738896 20404 solver.cpp:244]     Train net output #1: loss = 0.81509 (* 1 = 0.81509 loss)
I0817 11:17:16.738911 20404 sgd_solver.cpp:106] Iteration 15800, lr = 0.00049123
I0817 11:17:51.872972 20404 solver.cpp:228] Iteration 15810, loss = 0.815054
I0817 11:17:51.873178 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:17:51.873194 20404 solver.cpp:244]     Train net output #1: loss = 0.815054 (* 1 = 0.815054 loss)
I0817 11:17:51.873206 20404 sgd_solver.cpp:106] Iteration 15810, lr = 0.000491088
I0817 11:18:26.985687 20404 solver.cpp:228] Iteration 15820, loss = 0.815592
I0817 11:18:26.985864 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:18:26.985880 20404 solver.cpp:244]     Train net output #1: loss = 0.815592 (* 1 = 0.815592 loss)
I0817 11:18:26.985893 20404 sgd_solver.cpp:106] Iteration 15820, lr = 0.000490945
I0817 11:19:02.132912 20404 solver.cpp:228] Iteration 15830, loss = 0.815349
I0817 11:19:02.133090 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:19:02.133108 20404 solver.cpp:244]     Train net output #1: loss = 0.815349 (* 1 = 0.815349 loss)
I0817 11:19:02.133124 20404 sgd_solver.cpp:106] Iteration 15830, lr = 0.000490802
I0817 11:19:33.764611 20404 solver.cpp:337] Iteration 15840, Testing net (#0)
I0817 11:20:08.664118 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:20:08.664294 20404 solver.cpp:404]     Test net output #1: loss = 0.671488 (* 1 = 0.671488 loss)
I0817 11:20:12.166062 20404 solver.cpp:228] Iteration 15840, loss = 0.815763
I0817 11:20:12.166105 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:20:12.166123 20404 solver.cpp:244]     Train net output #1: loss = 0.815763 (* 1 = 0.815763 loss)
I0817 11:20:12.166148 20404 sgd_solver.cpp:106] Iteration 15840, lr = 0.00049066
I0817 11:20:47.290109 20404 solver.cpp:228] Iteration 15850, loss = 0.815377
I0817 11:20:47.290294 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 11:20:47.290313 20404 solver.cpp:244]     Train net output #1: loss = 0.815377 (* 1 = 0.815377 loss)
I0817 11:20:47.290328 20404 sgd_solver.cpp:106] Iteration 15850, lr = 0.000490518
I0817 11:21:22.412395 20404 solver.cpp:228] Iteration 15860, loss = 0.815234
I0817 11:21:22.412581 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:21:22.412600 20404 solver.cpp:244]     Train net output #1: loss = 0.815234 (* 1 = 0.815234 loss)
I0817 11:21:22.412616 20404 sgd_solver.cpp:106] Iteration 15860, lr = 0.000490375
I0817 11:21:57.549649 20404 solver.cpp:228] Iteration 15870, loss = 0.815335
I0817 11:21:57.549834 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 11:21:57.549849 20404 solver.cpp:244]     Train net output #1: loss = 0.815335 (* 1 = 0.815335 loss)
I0817 11:21:57.549861 20404 sgd_solver.cpp:106] Iteration 15870, lr = 0.000490233
I0817 11:22:29.174654 20404 solver.cpp:337] Iteration 15880, Testing net (#0)
I0817 11:23:04.040814 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:23:04.040997 20404 solver.cpp:404]     Test net output #1: loss = 0.671541 (* 1 = 0.671541 loss)
I0817 11:23:07.543876 20404 solver.cpp:228] Iteration 15880, loss = 0.815535
I0817 11:23:07.543926 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:23:07.543941 20404 solver.cpp:244]     Train net output #1: loss = 0.815535 (* 1 = 0.815535 loss)
I0817 11:23:07.543952 20404 sgd_solver.cpp:106] Iteration 15880, lr = 0.000490091
I0817 11:23:42.656074 20404 solver.cpp:228] Iteration 15890, loss = 0.814863
I0817 11:23:42.656182 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:23:42.656196 20404 solver.cpp:244]     Train net output #1: loss = 0.814863 (* 1 = 0.814863 loss)
I0817 11:23:42.656209 20404 sgd_solver.cpp:106] Iteration 15890, lr = 0.000489949
I0817 11:24:17.780429 20404 solver.cpp:228] Iteration 15900, loss = 0.814703
I0817 11:24:17.780539 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:24:17.780555 20404 solver.cpp:244]     Train net output #1: loss = 0.814703 (* 1 = 0.814703 loss)
I0817 11:24:17.780567 20404 sgd_solver.cpp:106] Iteration 15900, lr = 0.000489807
I0817 11:24:52.907172 20404 solver.cpp:228] Iteration 15910, loss = 0.815688
I0817 11:24:52.907389 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:24:52.907408 20404 solver.cpp:244]     Train net output #1: loss = 0.815688 (* 1 = 0.815688 loss)
I0817 11:24:52.907421 20404 sgd_solver.cpp:106] Iteration 15910, lr = 0.000489665
I0817 11:25:24.535588 20404 solver.cpp:337] Iteration 15920, Testing net (#0)
I0817 11:25:59.397620 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:25:59.397799 20404 solver.cpp:404]     Test net output #1: loss = 0.671643 (* 1 = 0.671643 loss)
I0817 11:26:02.907680 20404 solver.cpp:228] Iteration 15920, loss = 0.814857
I0817 11:26:02.907722 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 11:26:02.907737 20404 solver.cpp:244]     Train net output #1: loss = 0.814857 (* 1 = 0.814857 loss)
I0817 11:26:02.907750 20404 sgd_solver.cpp:106] Iteration 15920, lr = 0.000489524
I0817 11:26:38.015795 20404 solver.cpp:228] Iteration 15930, loss = 0.814768
I0817 11:26:38.015909 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:26:38.015924 20404 solver.cpp:244]     Train net output #1: loss = 0.814768 (* 1 = 0.814768 loss)
I0817 11:26:38.015936 20404 sgd_solver.cpp:106] Iteration 15930, lr = 0.000489382
I0817 11:27:13.147166 20404 solver.cpp:228] Iteration 15940, loss = 0.81579
I0817 11:27:13.147341 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 11:27:13.147361 20404 solver.cpp:244]     Train net output #1: loss = 0.81579 (* 1 = 0.81579 loss)
I0817 11:27:13.147374 20404 sgd_solver.cpp:106] Iteration 15940, lr = 0.000489241
I0817 11:27:48.274191 20404 solver.cpp:228] Iteration 15950, loss = 0.815981
I0817 11:27:48.274366 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:27:48.274381 20404 solver.cpp:244]     Train net output #1: loss = 0.815981 (* 1 = 0.815981 loss)
I0817 11:27:48.274394 20404 sgd_solver.cpp:106] Iteration 15950, lr = 0.000489099
I0817 11:28:19.902693 20404 solver.cpp:337] Iteration 15960, Testing net (#0)
I0817 11:28:54.773048 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:28:54.773226 20404 solver.cpp:404]     Test net output #1: loss = 0.672324 (* 1 = 0.672324 loss)
I0817 11:28:58.274123 20404 solver.cpp:228] Iteration 15960, loss = 0.815058
I0817 11:28:58.274178 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:28:58.274191 20404 solver.cpp:244]     Train net output #1: loss = 0.815058 (* 1 = 0.815058 loss)
I0817 11:28:58.274204 20404 sgd_solver.cpp:106] Iteration 15960, lr = 0.000488958
I0817 11:29:33.392809 20404 solver.cpp:228] Iteration 15970, loss = 0.81478
I0817 11:29:33.392904 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:29:33.392920 20404 solver.cpp:244]     Train net output #1: loss = 0.81478 (* 1 = 0.81478 loss)
I0817 11:29:33.392931 20404 sgd_solver.cpp:106] Iteration 15970, lr = 0.000488817
I0817 11:30:08.524962 20404 solver.cpp:228] Iteration 15980, loss = 0.815142
I0817 11:30:08.525138 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:30:08.525153 20404 solver.cpp:244]     Train net output #1: loss = 0.815142 (* 1 = 0.815142 loss)
I0817 11:30:08.525166 20404 sgd_solver.cpp:106] Iteration 15980, lr = 0.000488676
I0817 11:30:43.651571 20404 solver.cpp:228] Iteration 15990, loss = 0.815439
I0817 11:30:43.651747 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 11:30:43.651763 20404 solver.cpp:244]     Train net output #1: loss = 0.815439 (* 1 = 0.815439 loss)
I0817 11:30:43.651775 20404 sgd_solver.cpp:106] Iteration 15990, lr = 0.000488535
I0817 11:31:15.277544 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_16000.caffemodel
I0817 11:31:39.313276 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_16000.solverstate
I0817 11:31:41.180271 20404 solver.cpp:337] Iteration 16000, Testing net (#0)
I0817 11:32:15.799870 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:32:15.800045 20404 solver.cpp:404]     Test net output #1: loss = 0.671821 (* 1 = 0.671821 loss)
I0817 11:32:19.287216 20404 solver.cpp:228] Iteration 16000, loss = 0.815267
I0817 11:32:19.287263 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:32:19.287286 20404 solver.cpp:244]     Train net output #1: loss = 0.815267 (* 1 = 0.815267 loss)
I0817 11:32:19.287303 20404 sgd_solver.cpp:106] Iteration 16000, lr = 0.000488394
I0817 11:32:54.177494 20404 solver.cpp:228] Iteration 16010, loss = 0.814512
I0817 11:32:54.177599 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:32:54.177618 20404 solver.cpp:244]     Train net output #1: loss = 0.814512 (* 1 = 0.814512 loss)
I0817 11:32:54.177629 20404 sgd_solver.cpp:106] Iteration 16010, lr = 0.000488253
I0817 11:33:29.114083 20404 solver.cpp:228] Iteration 16020, loss = 0.81545
I0817 11:33:29.114270 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:33:29.114286 20404 solver.cpp:244]     Train net output #1: loss = 0.81545 (* 1 = 0.81545 loss)
I0817 11:33:29.114300 20404 sgd_solver.cpp:106] Iteration 16020, lr = 0.000488112
I0817 11:34:04.073566 20404 solver.cpp:228] Iteration 16030, loss = 0.814342
I0817 11:34:04.073743 20404 solver.cpp:244]     Train net output #0: accuracy = 0.88
I0817 11:34:04.073760 20404 solver.cpp:244]     Train net output #1: loss = 0.814342 (* 1 = 0.814342 loss)
I0817 11:34:04.073772 20404 sgd_solver.cpp:106] Iteration 16030, lr = 0.000487971
I0817 11:34:35.512212 20404 solver.cpp:337] Iteration 16040, Testing net (#0)
I0817 11:35:10.225431 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:35:10.225605 20404 solver.cpp:404]     Test net output #1: loss = 0.672194 (* 1 = 0.672194 loss)
I0817 11:35:13.699602 20404 solver.cpp:228] Iteration 16040, loss = 0.814855
I0817 11:35:13.699653 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:35:13.699668 20404 solver.cpp:244]     Train net output #1: loss = 0.814855 (* 1 = 0.814855 loss)
I0817 11:35:13.699681 20404 sgd_solver.cpp:106] Iteration 16040, lr = 0.000487831
I0817 11:35:48.666744 20404 solver.cpp:228] Iteration 16050, loss = 0.814847
I0817 11:35:48.666841 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:35:48.666859 20404 solver.cpp:244]     Train net output #1: loss = 0.814847 (* 1 = 0.814847 loss)
I0817 11:35:48.666874 20404 sgd_solver.cpp:106] Iteration 16050, lr = 0.00048769
I0817 11:36:23.621654 20404 solver.cpp:228] Iteration 16060, loss = 0.815618
I0817 11:36:23.621826 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:36:23.621841 20404 solver.cpp:244]     Train net output #1: loss = 0.815618 (* 1 = 0.815618 loss)
I0817 11:36:23.621855 20404 sgd_solver.cpp:106] Iteration 16060, lr = 0.00048755
I0817 11:36:58.563630 20404 solver.cpp:228] Iteration 16070, loss = 0.815156
I0817 11:36:58.563812 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:36:58.563827 20404 solver.cpp:244]     Train net output #1: loss = 0.815156 (* 1 = 0.815156 loss)
I0817 11:36:58.563839 20404 sgd_solver.cpp:106] Iteration 16070, lr = 0.00048741
I0817 11:37:30.036785 20404 solver.cpp:337] Iteration 16080, Testing net (#0)
I0817 11:38:04.749151 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:38:04.749320 20404 solver.cpp:404]     Test net output #1: loss = 0.672248 (* 1 = 0.672248 loss)
I0817 11:38:08.228354 20404 solver.cpp:228] Iteration 16080, loss = 0.814423
I0817 11:38:08.228395 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:38:08.228410 20404 solver.cpp:244]     Train net output #1: loss = 0.814423 (* 1 = 0.814423 loss)
I0817 11:38:08.228423 20404 sgd_solver.cpp:106] Iteration 16080, lr = 0.00048727
I0817 11:38:43.176933 20404 solver.cpp:228] Iteration 16090, loss = 0.815486
I0817 11:38:43.177111 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 11:38:43.177127 20404 solver.cpp:244]     Train net output #1: loss = 0.815486 (* 1 = 0.815486 loss)
I0817 11:38:43.177140 20404 sgd_solver.cpp:106] Iteration 16090, lr = 0.00048713
I0817 11:39:18.160331 20404 solver.cpp:228] Iteration 16100, loss = 0.815836
I0817 11:39:18.160545 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 11:39:18.160560 20404 solver.cpp:244]     Train net output #1: loss = 0.815836 (* 1 = 0.815836 loss)
I0817 11:39:18.160573 20404 sgd_solver.cpp:106] Iteration 16100, lr = 0.00048699
I0817 11:39:53.138134 20404 solver.cpp:228] Iteration 16110, loss = 0.81489
I0817 11:39:53.138236 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:39:53.138252 20404 solver.cpp:244]     Train net output #1: loss = 0.81489 (* 1 = 0.81489 loss)
I0817 11:39:53.138264 20404 sgd_solver.cpp:106] Iteration 16110, lr = 0.00048685
I0817 11:40:24.624127 20404 solver.cpp:337] Iteration 16120, Testing net (#0)
I0817 11:40:59.343502 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:40:59.343590 20404 solver.cpp:404]     Test net output #1: loss = 0.67236 (* 1 = 0.67236 loss)
I0817 11:41:02.831408 20404 solver.cpp:228] Iteration 16120, loss = 0.814302
I0817 11:41:02.831449 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:41:02.831467 20404 solver.cpp:244]     Train net output #1: loss = 0.814302 (* 1 = 0.814302 loss)
I0817 11:41:02.831493 20404 sgd_solver.cpp:106] Iteration 16120, lr = 0.00048671
I0817 11:41:37.790112 20404 solver.cpp:228] Iteration 16130, loss = 0.814966
I0817 11:41:37.790293 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:41:37.790313 20404 solver.cpp:244]     Train net output #1: loss = 0.814966 (* 1 = 0.814966 loss)
I0817 11:41:37.790328 20404 sgd_solver.cpp:106] Iteration 16130, lr = 0.00048657
I0817 11:42:12.735954 20404 solver.cpp:228] Iteration 16140, loss = 0.815152
I0817 11:42:12.736138 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:42:12.736153 20404 solver.cpp:244]     Train net output #1: loss = 0.815152 (* 1 = 0.815152 loss)
I0817 11:42:12.736166 20404 sgd_solver.cpp:106] Iteration 16140, lr = 0.000486431
I0817 11:42:47.690780 20404 solver.cpp:228] Iteration 16150, loss = 0.814527
I0817 11:42:47.690958 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:42:47.690975 20404 solver.cpp:244]     Train net output #1: loss = 0.814527 (* 1 = 0.814527 loss)
I0817 11:42:47.690990 20404 sgd_solver.cpp:106] Iteration 16150, lr = 0.000486291
I0817 11:43:19.166977 20404 solver.cpp:337] Iteration 16160, Testing net (#0)
I0817 11:43:53.891156 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:43:53.891336 20404 solver.cpp:404]     Test net output #1: loss = 0.672081 (* 1 = 0.672081 loss)
I0817 11:43:57.366475 20404 solver.cpp:228] Iteration 16160, loss = 0.814543
I0817 11:43:57.366518 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 11:43:57.366535 20404 solver.cpp:244]     Train net output #1: loss = 0.814543 (* 1 = 0.814543 loss)
I0817 11:43:57.366560 20404 sgd_solver.cpp:106] Iteration 16160, lr = 0.000486152
I0817 11:44:32.319476 20404 solver.cpp:228] Iteration 16170, loss = 0.814452
I0817 11:44:32.319664 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:44:32.319682 20404 solver.cpp:244]     Train net output #1: loss = 0.814452 (* 1 = 0.814452 loss)
I0817 11:44:32.319699 20404 sgd_solver.cpp:106] Iteration 16170, lr = 0.000486012
I0817 11:45:07.267700 20404 solver.cpp:228] Iteration 16180, loss = 0.81477
I0817 11:45:07.267874 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:45:07.267890 20404 solver.cpp:244]     Train net output #1: loss = 0.81477 (* 1 = 0.81477 loss)
I0817 11:45:07.267904 20404 sgd_solver.cpp:106] Iteration 16180, lr = 0.000485873
I0817 11:45:42.231511 20404 solver.cpp:228] Iteration 16190, loss = 0.815373
I0817 11:45:42.231691 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 11:45:42.231708 20404 solver.cpp:244]     Train net output #1: loss = 0.815373 (* 1 = 0.815373 loss)
I0817 11:45:42.231721 20404 sgd_solver.cpp:106] Iteration 16190, lr = 0.000485734
I0817 11:46:13.698470 20404 solver.cpp:337] Iteration 16200, Testing net (#0)
I0817 11:46:48.426576 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:46:48.426786 20404 solver.cpp:404]     Test net output #1: loss = 0.672359 (* 1 = 0.672359 loss)
I0817 11:46:51.904213 20404 solver.cpp:228] Iteration 16200, loss = 0.814402
I0817 11:46:51.904266 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:46:51.904280 20404 solver.cpp:244]     Train net output #1: loss = 0.814402 (* 1 = 0.814402 loss)
I0817 11:46:51.904292 20404 sgd_solver.cpp:106] Iteration 16200, lr = 0.000485595
I0817 11:47:26.849025 20404 solver.cpp:228] Iteration 16210, loss = 0.815379
I0817 11:47:26.849207 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:47:26.849227 20404 solver.cpp:244]     Train net output #1: loss = 0.815379 (* 1 = 0.815379 loss)
I0817 11:47:26.849241 20404 sgd_solver.cpp:106] Iteration 16210, lr = 0.000485456
I0817 11:48:01.817939 20404 solver.cpp:228] Iteration 16220, loss = 0.814672
I0817 11:48:01.818114 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 11:48:01.818132 20404 solver.cpp:244]     Train net output #1: loss = 0.814672 (* 1 = 0.814672 loss)
I0817 11:48:01.818145 20404 sgd_solver.cpp:106] Iteration 16220, lr = 0.000485317
I0817 11:48:36.783808 20404 solver.cpp:228] Iteration 16230, loss = 0.815073
I0817 11:48:36.783913 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:48:36.783928 20404 solver.cpp:244]     Train net output #1: loss = 0.815073 (* 1 = 0.815073 loss)
I0817 11:48:36.783941 20404 sgd_solver.cpp:106] Iteration 16230, lr = 0.000485178
I0817 11:49:08.250455 20404 solver.cpp:337] Iteration 16240, Testing net (#0)
I0817 11:49:42.933634 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:49:42.933753 20404 solver.cpp:404]     Test net output #1: loss = 0.672105 (* 1 = 0.672105 loss)
I0817 11:49:46.417378 20404 solver.cpp:228] Iteration 16240, loss = 0.814127
I0817 11:49:46.417433 20404 solver.cpp:244]     Train net output #0: accuracy = 0.66
I0817 11:49:46.417450 20404 solver.cpp:244]     Train net output #1: loss = 0.814127 (* 1 = 0.814127 loss)
I0817 11:49:46.417464 20404 sgd_solver.cpp:106] Iteration 16240, lr = 0.00048504
I0817 11:50:21.367837 20404 solver.cpp:228] Iteration 16250, loss = 0.814549
I0817 11:50:21.368006 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:50:21.368026 20404 solver.cpp:244]     Train net output #1: loss = 0.814549 (* 1 = 0.814549 loss)
I0817 11:50:21.368038 20404 sgd_solver.cpp:106] Iteration 16250, lr = 0.000484901
I0817 11:50:56.314415 20404 solver.cpp:228] Iteration 16260, loss = 0.814565
I0817 11:50:56.314596 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:50:56.314612 20404 solver.cpp:244]     Train net output #1: loss = 0.814565 (* 1 = 0.814565 loss)
I0817 11:50:56.314625 20404 sgd_solver.cpp:106] Iteration 16260, lr = 0.000484762
I0817 11:51:31.276993 20404 solver.cpp:228] Iteration 16270, loss = 0.814478
I0817 11:51:31.277087 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:51:31.277107 20404 solver.cpp:244]     Train net output #1: loss = 0.814478 (* 1 = 0.814478 loss)
I0817 11:51:31.277123 20404 sgd_solver.cpp:106] Iteration 16270, lr = 0.000484624
I0817 11:52:02.739118 20404 solver.cpp:337] Iteration 16280, Testing net (#0)
I0817 11:52:37.447482 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:52:37.447661 20404 solver.cpp:404]     Test net output #1: loss = 0.672257 (* 1 = 0.672257 loss)
I0817 11:52:40.930507 20404 solver.cpp:228] Iteration 16280, loss = 0.814843
I0817 11:52:40.930559 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:52:40.930573 20404 solver.cpp:244]     Train net output #1: loss = 0.814843 (* 1 = 0.814843 loss)
I0817 11:52:40.930585 20404 sgd_solver.cpp:106] Iteration 16280, lr = 0.000484486
I0817 11:53:15.879010 20404 solver.cpp:228] Iteration 16290, loss = 0.815034
I0817 11:53:15.879187 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:53:15.879204 20404 solver.cpp:244]     Train net output #1: loss = 0.815034 (* 1 = 0.815034 loss)
I0817 11:53:15.879215 20404 sgd_solver.cpp:106] Iteration 16290, lr = 0.000484348
I0817 11:53:50.822896 20404 solver.cpp:228] Iteration 16300, loss = 0.815542
I0817 11:53:50.823110 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 11:53:50.823127 20404 solver.cpp:244]     Train net output #1: loss = 0.815542 (* 1 = 0.815542 loss)
I0817 11:53:50.823138 20404 sgd_solver.cpp:106] Iteration 16300, lr = 0.000484209
I0817 11:54:25.765794 20404 solver.cpp:228] Iteration 16310, loss = 0.813718
I0817 11:54:25.765915 20404 solver.cpp:244]     Train net output #0: accuracy = 0.69
I0817 11:54:25.765930 20404 solver.cpp:244]     Train net output #1: loss = 0.813718 (* 1 = 0.813718 loss)
I0817 11:54:25.765943 20404 sgd_solver.cpp:106] Iteration 16310, lr = 0.000484071
I0817 11:54:57.215922 20404 solver.cpp:337] Iteration 16320, Testing net (#0)
I0817 11:55:31.915558 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:55:31.915637 20404 solver.cpp:404]     Test net output #1: loss = 0.672518 (* 1 = 0.672518 loss)
I0817 11:55:35.391877 20404 solver.cpp:228] Iteration 16320, loss = 0.815365
I0817 11:55:35.391919 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:55:35.391938 20404 solver.cpp:244]     Train net output #1: loss = 0.815365 (* 1 = 0.815365 loss)
I0817 11:55:35.391964 20404 sgd_solver.cpp:106] Iteration 16320, lr = 0.000483933
I0817 11:56:10.355952 20404 solver.cpp:228] Iteration 16330, loss = 0.814839
I0817 11:56:10.356129 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 11:56:10.356145 20404 solver.cpp:244]     Train net output #1: loss = 0.814839 (* 1 = 0.814839 loss)
I0817 11:56:10.356158 20404 sgd_solver.cpp:106] Iteration 16330, lr = 0.000483796
I0817 11:56:45.286480 20404 solver.cpp:228] Iteration 16340, loss = 0.815112
I0817 11:56:45.286659 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 11:56:45.286674 20404 solver.cpp:244]     Train net output #1: loss = 0.815112 (* 1 = 0.815112 loss)
I0817 11:56:45.286685 20404 sgd_solver.cpp:106] Iteration 16340, lr = 0.000483658
I0817 11:57:20.226006 20404 solver.cpp:228] Iteration 16350, loss = 0.814502
I0817 11:57:20.226179 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:57:20.226197 20404 solver.cpp:244]     Train net output #1: loss = 0.814502 (* 1 = 0.814502 loss)
I0817 11:57:20.226210 20404 sgd_solver.cpp:106] Iteration 16350, lr = 0.00048352
I0817 11:57:51.697556 20404 solver.cpp:337] Iteration 16360, Testing net (#0)
I0817 11:58:26.412305 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 11:58:26.412482 20404 solver.cpp:404]     Test net output #1: loss = 0.672187 (* 1 = 0.672187 loss)
I0817 11:58:29.893306 20404 solver.cpp:228] Iteration 16360, loss = 0.813943
I0817 11:58:29.893347 20404 solver.cpp:244]     Train net output #0: accuracy = 0.82
I0817 11:58:29.893365 20404 solver.cpp:244]     Train net output #1: loss = 0.813943 (* 1 = 0.813943 loss)
I0817 11:58:29.893390 20404 sgd_solver.cpp:106] Iteration 16360, lr = 0.000483383
I0817 11:59:04.842586 20404 solver.cpp:228] Iteration 16370, loss = 0.813919
I0817 11:59:04.842768 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 11:59:04.842783 20404 solver.cpp:244]     Train net output #1: loss = 0.813919 (* 1 = 0.813919 loss)
I0817 11:59:04.842795 20404 sgd_solver.cpp:106] Iteration 16370, lr = 0.000483245
I0817 11:59:39.776454 20404 solver.cpp:228] Iteration 16380, loss = 0.814194
I0817 11:59:39.776635 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 11:59:39.776651 20404 solver.cpp:244]     Train net output #1: loss = 0.814194 (* 1 = 0.814194 loss)
I0817 11:59:39.776664 20404 sgd_solver.cpp:106] Iteration 16380, lr = 0.000483108
I0817 12:00:14.733393 20404 solver.cpp:228] Iteration 16390, loss = 0.814068
I0817 12:00:14.733564 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 12:00:14.733579 20404 solver.cpp:244]     Train net output #1: loss = 0.814068 (* 1 = 0.814068 loss)
I0817 12:00:14.733592 20404 sgd_solver.cpp:106] Iteration 16390, lr = 0.00048297
I0817 12:00:46.193994 20404 solver.cpp:337] Iteration 16400, Testing net (#0)
I0817 12:01:20.904135 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:01:20.904239 20404 solver.cpp:404]     Test net output #1: loss = 0.67236 (* 1 = 0.67236 loss)
I0817 12:01:24.392382 20404 solver.cpp:228] Iteration 16400, loss = 0.814643
I0817 12:01:24.392433 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:01:24.392447 20404 solver.cpp:244]     Train net output #1: loss = 0.814643 (* 1 = 0.814643 loss)
I0817 12:01:24.392459 20404 sgd_solver.cpp:106] Iteration 16400, lr = 0.000482833
I0817 12:01:59.358829 20404 solver.cpp:228] Iteration 16410, loss = 0.814506
I0817 12:01:59.359014 20404 solver.cpp:244]     Train net output #0: accuracy = 0.66
I0817 12:01:59.359030 20404 solver.cpp:244]     Train net output #1: loss = 0.814506 (* 1 = 0.814506 loss)
I0817 12:01:59.359042 20404 sgd_solver.cpp:106] Iteration 16410, lr = 0.000482696
I0817 12:02:34.305011 20404 solver.cpp:228] Iteration 16420, loss = 0.814674
I0817 12:02:34.305184 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:02:34.305200 20404 solver.cpp:244]     Train net output #1: loss = 0.814674 (* 1 = 0.814674 loss)
I0817 12:02:34.305212 20404 sgd_solver.cpp:106] Iteration 16420, lr = 0.000482559
I0817 12:03:09.276355 20404 solver.cpp:228] Iteration 16430, loss = 0.81471
I0817 12:03:09.276535 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:03:09.276551 20404 solver.cpp:244]     Train net output #1: loss = 0.81471 (* 1 = 0.81471 loss)
I0817 12:03:09.276562 20404 sgd_solver.cpp:106] Iteration 16430, lr = 0.000482422
I0817 12:03:40.746932 20404 solver.cpp:337] Iteration 16440, Testing net (#0)
I0817 12:04:15.477190 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:04:15.477370 20404 solver.cpp:404]     Test net output #1: loss = 0.671981 (* 1 = 0.671981 loss)
I0817 12:04:18.956311 20404 solver.cpp:228] Iteration 16440, loss = 0.814365
I0817 12:04:18.956363 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:04:18.956378 20404 solver.cpp:244]     Train net output #1: loss = 0.814365 (* 1 = 0.814365 loss)
I0817 12:04:18.956390 20404 sgd_solver.cpp:106] Iteration 16440, lr = 0.000482285
I0817 12:04:53.901669 20404 solver.cpp:228] Iteration 16450, loss = 0.813596
I0817 12:04:53.901844 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:04:53.901860 20404 solver.cpp:244]     Train net output #1: loss = 0.813596 (* 1 = 0.813596 loss)
I0817 12:04:53.901872 20404 sgd_solver.cpp:106] Iteration 16450, lr = 0.000482148
I0817 12:05:28.858393 20404 solver.cpp:228] Iteration 16460, loss = 0.814307
I0817 12:05:28.858573 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:05:28.858590 20404 solver.cpp:244]     Train net output #1: loss = 0.814307 (* 1 = 0.814307 loss)
I0817 12:05:28.858603 20404 sgd_solver.cpp:106] Iteration 16460, lr = 0.000482012
I0817 12:06:03.815732 20404 solver.cpp:228] Iteration 16470, loss = 0.813789
I0817 12:06:03.815915 20404 solver.cpp:244]     Train net output #0: accuracy = 0.82
I0817 12:06:03.815932 20404 solver.cpp:244]     Train net output #1: loss = 0.813789 (* 1 = 0.813789 loss)
I0817 12:06:03.815944 20404 sgd_solver.cpp:106] Iteration 16470, lr = 0.000481875
I0817 12:06:35.302840 20404 solver.cpp:337] Iteration 16480, Testing net (#0)
I0817 12:07:10.025975 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:07:10.026082 20404 solver.cpp:404]     Test net output #1: loss = 0.672059 (* 1 = 0.672059 loss)
I0817 12:07:13.510931 20404 solver.cpp:228] Iteration 16480, loss = 0.814988
I0817 12:07:13.510979 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:07:13.510993 20404 solver.cpp:244]     Train net output #1: loss = 0.814988 (* 1 = 0.814988 loss)
I0817 12:07:13.511005 20404 sgd_solver.cpp:106] Iteration 16480, lr = 0.000481739
I0817 12:07:48.457558 20404 solver.cpp:228] Iteration 16490, loss = 0.814371
I0817 12:07:48.457739 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:07:48.457754 20404 solver.cpp:244]     Train net output #1: loss = 0.814371 (* 1 = 0.814371 loss)
I0817 12:07:48.457767 20404 sgd_solver.cpp:106] Iteration 16490, lr = 0.000481602
I0817 12:08:23.393334 20404 solver.cpp:228] Iteration 16500, loss = 0.813903
I0817 12:08:23.393452 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 12:08:23.393467 20404 solver.cpp:244]     Train net output #1: loss = 0.813903 (* 1 = 0.813903 loss)
I0817 12:08:23.393478 20404 sgd_solver.cpp:106] Iteration 16500, lr = 0.000481466
I0817 12:08:58.337347 20404 solver.cpp:228] Iteration 16510, loss = 0.814403
I0817 12:08:58.337594 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:08:58.337652 20404 solver.cpp:244]     Train net output #1: loss = 0.814403 (* 1 = 0.814403 loss)
I0817 12:08:58.337687 20404 sgd_solver.cpp:106] Iteration 16510, lr = 0.00048133
I0817 12:09:29.799294 20404 solver.cpp:337] Iteration 16520, Testing net (#0)
I0817 12:10:04.529227 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:10:04.529400 20404 solver.cpp:404]     Test net output #1: loss = 0.672086 (* 1 = 0.672086 loss)
I0817 12:10:08.012459 20404 solver.cpp:228] Iteration 16520, loss = 0.814615
I0817 12:10:08.012508 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:10:08.012523 20404 solver.cpp:244]     Train net output #1: loss = 0.814615 (* 1 = 0.814615 loss)
I0817 12:10:08.012536 20404 sgd_solver.cpp:106] Iteration 16520, lr = 0.000481194
I0817 12:10:42.978018 20404 solver.cpp:228] Iteration 16530, loss = 0.814219
I0817 12:10:42.978196 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 12:10:42.978211 20404 solver.cpp:244]     Train net output #1: loss = 0.814219 (* 1 = 0.814219 loss)
I0817 12:10:42.978224 20404 sgd_solver.cpp:106] Iteration 16530, lr = 0.000481058
I0817 12:11:17.923908 20404 solver.cpp:228] Iteration 16540, loss = 0.814409
I0817 12:11:17.924162 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:11:17.924213 20404 solver.cpp:244]     Train net output #1: loss = 0.814409 (* 1 = 0.814409 loss)
I0817 12:11:17.924232 20404 sgd_solver.cpp:106] Iteration 16540, lr = 0.000480922
I0817 12:11:52.882135 20404 solver.cpp:228] Iteration 16550, loss = 0.81436
I0817 12:11:52.882316 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:11:52.882331 20404 solver.cpp:244]     Train net output #1: loss = 0.81436 (* 1 = 0.81436 loss)
I0817 12:11:52.882344 20404 sgd_solver.cpp:106] Iteration 16550, lr = 0.000480786
I0817 12:12:24.363698 20404 solver.cpp:337] Iteration 16560, Testing net (#0)
I0817 12:12:59.089258 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:12:59.089435 20404 solver.cpp:404]     Test net output #1: loss = 0.671889 (* 1 = 0.671889 loss)
I0817 12:13:02.577461 20404 solver.cpp:228] Iteration 16560, loss = 0.814384
I0817 12:13:02.577512 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 12:13:02.577525 20404 solver.cpp:244]     Train net output #1: loss = 0.814384 (* 1 = 0.814384 loss)
I0817 12:13:02.577538 20404 sgd_solver.cpp:106] Iteration 16560, lr = 0.00048065
I0817 12:13:37.545989 20404 solver.cpp:228] Iteration 16570, loss = 0.814787
I0817 12:13:37.546162 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:13:37.546177 20404 solver.cpp:244]     Train net output #1: loss = 0.814787 (* 1 = 0.814787 loss)
I0817 12:13:37.546190 20404 sgd_solver.cpp:106] Iteration 16570, lr = 0.000480514
I0817 12:14:12.479737 20404 solver.cpp:228] Iteration 16580, loss = 0.814355
I0817 12:14:12.479918 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:14:12.479933 20404 solver.cpp:244]     Train net output #1: loss = 0.814355 (* 1 = 0.814355 loss)
I0817 12:14:12.479946 20404 sgd_solver.cpp:106] Iteration 16580, lr = 0.000480379
I0817 12:14:47.433765 20404 solver.cpp:228] Iteration 16590, loss = 0.813461
I0817 12:14:47.433948 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:14:47.433964 20404 solver.cpp:244]     Train net output #1: loss = 0.813461 (* 1 = 0.813461 loss)
I0817 12:14:47.433975 20404 sgd_solver.cpp:106] Iteration 16590, lr = 0.000480243
I0817 12:15:18.919997 20404 solver.cpp:337] Iteration 16600, Testing net (#0)
I0817 12:15:53.632375 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:15:53.632546 20404 solver.cpp:404]     Test net output #1: loss = 0.672301 (* 1 = 0.672301 loss)
I0817 12:15:57.118191 20404 solver.cpp:228] Iteration 16600, loss = 0.813899
I0817 12:15:57.118244 20404 solver.cpp:244]     Train net output #0: accuracy = 0.67
I0817 12:15:57.118258 20404 solver.cpp:244]     Train net output #1: loss = 0.813899 (* 1 = 0.813899 loss)
I0817 12:15:57.118270 20404 sgd_solver.cpp:106] Iteration 16600, lr = 0.000480108
I0817 12:16:32.075027 20404 solver.cpp:228] Iteration 16610, loss = 0.815151
I0817 12:16:32.075211 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:16:32.075227 20404 solver.cpp:244]     Train net output #1: loss = 0.815151 (* 1 = 0.815151 loss)
I0817 12:16:32.075239 20404 sgd_solver.cpp:106] Iteration 16610, lr = 0.000479973
I0817 12:17:07.007510 20404 solver.cpp:228] Iteration 16620, loss = 0.813191
I0817 12:17:07.007652 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 12:17:07.007673 20404 solver.cpp:244]     Train net output #1: loss = 0.813191 (* 1 = 0.813191 loss)
I0817 12:17:07.007688 20404 sgd_solver.cpp:106] Iteration 16620, lr = 0.000479837
I0817 12:17:41.926596 20404 solver.cpp:228] Iteration 16630, loss = 0.813405
I0817 12:17:41.926771 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:17:41.926786 20404 solver.cpp:244]     Train net output #1: loss = 0.813405 (* 1 = 0.813405 loss)
I0817 12:17:41.926800 20404 sgd_solver.cpp:106] Iteration 16630, lr = 0.000479702
I0817 12:18:13.399941 20404 solver.cpp:337] Iteration 16640, Testing net (#0)
I0817 12:18:48.110364 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:18:48.110538 20404 solver.cpp:404]     Test net output #1: loss = 0.671963 (* 1 = 0.671963 loss)
I0817 12:18:51.591905 20404 solver.cpp:228] Iteration 16640, loss = 0.813966
I0817 12:18:51.591956 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 12:18:51.591970 20404 solver.cpp:244]     Train net output #1: loss = 0.813966 (* 1 = 0.813966 loss)
I0817 12:18:51.591982 20404 sgd_solver.cpp:106] Iteration 16640, lr = 0.000479567
I0817 12:19:26.538805 20404 solver.cpp:228] Iteration 16650, loss = 0.814309
I0817 12:19:26.538969 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:19:26.538985 20404 solver.cpp:244]     Train net output #1: loss = 0.814309 (* 1 = 0.814309 loss)
I0817 12:19:26.538996 20404 sgd_solver.cpp:106] Iteration 16650, lr = 0.000479432
I0817 12:20:01.495028 20404 solver.cpp:228] Iteration 16660, loss = 0.813686
I0817 12:20:01.495203 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:20:01.495218 20404 solver.cpp:244]     Train net output #1: loss = 0.813686 (* 1 = 0.813686 loss)
I0817 12:20:01.495230 20404 sgd_solver.cpp:106] Iteration 16660, lr = 0.000479297
I0817 12:20:36.447734 20404 solver.cpp:228] Iteration 16670, loss = 0.814028
I0817 12:20:36.447912 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 12:20:36.447927 20404 solver.cpp:244]     Train net output #1: loss = 0.814028 (* 1 = 0.814028 loss)
I0817 12:20:36.447940 20404 sgd_solver.cpp:106] Iteration 16670, lr = 0.000479162
I0817 12:21:07.937011 20404 solver.cpp:337] Iteration 16680, Testing net (#0)
I0817 12:21:42.628159 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:21:42.628340 20404 solver.cpp:404]     Test net output #1: loss = 0.672176 (* 1 = 0.672176 loss)
I0817 12:21:46.111590 20404 solver.cpp:228] Iteration 16680, loss = 0.814055
I0817 12:21:46.111640 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:21:46.111654 20404 solver.cpp:244]     Train net output #1: loss = 0.814055 (* 1 = 0.814055 loss)
I0817 12:21:46.111666 20404 sgd_solver.cpp:106] Iteration 16680, lr = 0.000479028
I0817 12:22:21.066201 20404 solver.cpp:228] Iteration 16690, loss = 0.813598
I0817 12:22:21.066319 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:22:21.066334 20404 solver.cpp:244]     Train net output #1: loss = 0.813598 (* 1 = 0.813598 loss)
I0817 12:22:21.066346 20404 sgd_solver.cpp:106] Iteration 16690, lr = 0.000478893
I0817 12:22:56.032824 20404 solver.cpp:228] Iteration 16700, loss = 0.813528
I0817 12:22:56.032997 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:22:56.033016 20404 solver.cpp:244]     Train net output #1: loss = 0.813528 (* 1 = 0.813528 loss)
I0817 12:22:56.033030 20404 sgd_solver.cpp:106] Iteration 16700, lr = 0.000478759
I0817 12:23:30.985806 20404 solver.cpp:228] Iteration 16710, loss = 0.814367
I0817 12:23:30.985985 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:23:30.986001 20404 solver.cpp:244]     Train net output #1: loss = 0.814367 (* 1 = 0.814367 loss)
I0817 12:23:30.986013 20404 sgd_solver.cpp:106] Iteration 16710, lr = 0.000478624
I0817 12:24:02.457774 20404 solver.cpp:337] Iteration 16720, Testing net (#0)
I0817 12:24:37.164878 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:24:37.165052 20404 solver.cpp:404]     Test net output #1: loss = 0.672263 (* 1 = 0.672263 loss)
I0817 12:24:40.649894 20404 solver.cpp:228] Iteration 16720, loss = 0.814056
I0817 12:24:40.649946 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:24:40.649960 20404 solver.cpp:244]     Train net output #1: loss = 0.814056 (* 1 = 0.814056 loss)
I0817 12:24:40.649972 20404 sgd_solver.cpp:106] Iteration 16720, lr = 0.00047849
I0817 12:25:15.606336 20404 solver.cpp:228] Iteration 16730, loss = 0.814053
I0817 12:25:15.606513 20404 solver.cpp:244]     Train net output #0: accuracy = 0.67
I0817 12:25:15.606528 20404 solver.cpp:244]     Train net output #1: loss = 0.814053 (* 1 = 0.814053 loss)
I0817 12:25:15.606540 20404 sgd_solver.cpp:106] Iteration 16730, lr = 0.000478356
I0817 12:25:50.572873 20404 solver.cpp:228] Iteration 16740, loss = 0.813403
I0817 12:25:50.573037 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:25:50.573052 20404 solver.cpp:244]     Train net output #1: loss = 0.813403 (* 1 = 0.813403 loss)
I0817 12:25:50.573065 20404 sgd_solver.cpp:106] Iteration 16740, lr = 0.000478221
I0817 12:26:25.515053 20404 solver.cpp:228] Iteration 16750, loss = 0.814027
I0817 12:26:25.515148 20404 solver.cpp:244]     Train net output #0: accuracy = 0.67
I0817 12:26:25.515164 20404 solver.cpp:244]     Train net output #1: loss = 0.814027 (* 1 = 0.814027 loss)
I0817 12:26:25.515177 20404 sgd_solver.cpp:106] Iteration 16750, lr = 0.000478087
I0817 12:26:57.001473 20404 solver.cpp:337] Iteration 16760, Testing net (#0)
I0817 12:27:31.703694 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:27:31.703856 20404 solver.cpp:404]     Test net output #1: loss = 0.672674 (* 1 = 0.672674 loss)
I0817 12:27:35.182212 20404 solver.cpp:228] Iteration 16760, loss = 0.814277
I0817 12:27:35.182253 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:27:35.182271 20404 solver.cpp:244]     Train net output #1: loss = 0.814277 (* 1 = 0.814277 loss)
I0817 12:27:35.182284 20404 sgd_solver.cpp:106] Iteration 16760, lr = 0.000477953
I0817 12:28:10.154880 20404 solver.cpp:228] Iteration 16770, loss = 0.814377
I0817 12:28:10.155052 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:28:10.155068 20404 solver.cpp:244]     Train net output #1: loss = 0.814377 (* 1 = 0.814377 loss)
I0817 12:28:10.155081 20404 sgd_solver.cpp:106] Iteration 16770, lr = 0.000477819
I0817 12:28:45.105936 20404 solver.cpp:228] Iteration 16780, loss = 0.813664
I0817 12:28:45.106115 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:28:45.106130 20404 solver.cpp:244]     Train net output #1: loss = 0.813664 (* 1 = 0.813664 loss)
I0817 12:28:45.106142 20404 sgd_solver.cpp:106] Iteration 16780, lr = 0.000477686
I0817 12:29:20.055639 20404 solver.cpp:228] Iteration 16790, loss = 0.813107
I0817 12:29:20.055819 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 12:29:20.055835 20404 solver.cpp:244]     Train net output #1: loss = 0.813107 (* 1 = 0.813107 loss)
I0817 12:29:20.055846 20404 sgd_solver.cpp:106] Iteration 16790, lr = 0.000477552
I0817 12:29:51.527549 20404 solver.cpp:337] Iteration 16800, Testing net (#0)
I0817 12:30:26.249338 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:30:26.249510 20404 solver.cpp:404]     Test net output #1: loss = 0.672509 (* 1 = 0.672509 loss)
I0817 12:30:29.735174 20404 solver.cpp:228] Iteration 16800, loss = 0.813186
I0817 12:30:29.735227 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:30:29.735242 20404 solver.cpp:244]     Train net output #1: loss = 0.813186 (* 1 = 0.813186 loss)
I0817 12:30:29.735255 20404 sgd_solver.cpp:106] Iteration 16800, lr = 0.000477418
I0817 12:31:04.685904 20404 solver.cpp:228] Iteration 16810, loss = 0.8149
I0817 12:31:04.686079 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:31:04.686094 20404 solver.cpp:244]     Train net output #1: loss = 0.8149 (* 1 = 0.8149 loss)
I0817 12:31:04.686105 20404 sgd_solver.cpp:106] Iteration 16810, lr = 0.000477285
I0817 12:31:39.646646 20404 solver.cpp:228] Iteration 16820, loss = 0.813549
I0817 12:31:39.646827 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:31:39.646843 20404 solver.cpp:244]     Train net output #1: loss = 0.813549 (* 1 = 0.813549 loss)
I0817 12:31:39.646857 20404 sgd_solver.cpp:106] Iteration 16820, lr = 0.000477151
I0817 12:32:14.596834 20404 solver.cpp:228] Iteration 16830, loss = 0.814147
I0817 12:32:14.597012 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:32:14.597028 20404 solver.cpp:244]     Train net output #1: loss = 0.814147 (* 1 = 0.814147 loss)
I0817 12:32:14.597040 20404 sgd_solver.cpp:106] Iteration 16830, lr = 0.000477018
I0817 12:32:46.075768 20404 solver.cpp:337] Iteration 16840, Testing net (#0)
I0817 12:33:20.778506 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:33:20.778678 20404 solver.cpp:404]     Test net output #1: loss = 0.672331 (* 1 = 0.672331 loss)
I0817 12:33:24.264075 20404 solver.cpp:228] Iteration 16840, loss = 0.813673
I0817 12:33:24.264123 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:33:24.264137 20404 solver.cpp:244]     Train net output #1: loss = 0.813673 (* 1 = 0.813673 loss)
I0817 12:33:24.264149 20404 sgd_solver.cpp:106] Iteration 16840, lr = 0.000476884
I0817 12:33:59.189903 20404 solver.cpp:228] Iteration 16850, loss = 0.814256
I0817 12:33:59.190085 20404 solver.cpp:244]     Train net output #0: accuracy = 0.64
I0817 12:33:59.190100 20404 solver.cpp:244]     Train net output #1: loss = 0.814256 (* 1 = 0.814256 loss)
I0817 12:33:59.190114 20404 sgd_solver.cpp:106] Iteration 16850, lr = 0.000476751
I0817 12:34:34.138471 20404 solver.cpp:228] Iteration 16860, loss = 0.812994
I0817 12:34:34.138649 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:34:34.138664 20404 solver.cpp:244]     Train net output #1: loss = 0.812994 (* 1 = 0.812994 loss)
I0817 12:34:34.138677 20404 sgd_solver.cpp:106] Iteration 16860, lr = 0.000476618
I0817 12:35:09.104933 20404 solver.cpp:228] Iteration 16870, loss = 0.813385
I0817 12:35:09.105104 20404 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0817 12:35:09.105120 20404 solver.cpp:244]     Train net output #1: loss = 0.813385 (* 1 = 0.813385 loss)
I0817 12:35:09.105132 20404 sgd_solver.cpp:106] Iteration 16870, lr = 0.000476485
I0817 12:35:40.587973 20404 solver.cpp:337] Iteration 16880, Testing net (#0)
I0817 12:36:15.292184 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:36:15.292354 20404 solver.cpp:404]     Test net output #1: loss = 0.671958 (* 1 = 0.671958 loss)
I0817 12:36:18.780624 20404 solver.cpp:228] Iteration 16880, loss = 0.813295
I0817 12:36:18.780675 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:36:18.780689 20404 solver.cpp:244]     Train net output #1: loss = 0.813295 (* 1 = 0.813295 loss)
I0817 12:36:18.780701 20404 sgd_solver.cpp:106] Iteration 16880, lr = 0.000476352
I0817 12:36:53.722071 20404 solver.cpp:228] Iteration 16890, loss = 0.81249
I0817 12:36:53.722204 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:36:53.722220 20404 solver.cpp:244]     Train net output #1: loss = 0.81249 (* 1 = 0.81249 loss)
I0817 12:36:53.722234 20404 sgd_solver.cpp:106] Iteration 16890, lr = 0.000476219
I0817 12:37:28.675600 20404 solver.cpp:228] Iteration 16900, loss = 0.813286
I0817 12:37:28.675779 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:37:28.675794 20404 solver.cpp:244]     Train net output #1: loss = 0.813286 (* 1 = 0.813286 loss)
I0817 12:37:28.675807 20404 sgd_solver.cpp:106] Iteration 16900, lr = 0.000476086
I0817 12:38:03.645273 20404 solver.cpp:228] Iteration 16910, loss = 0.813925
I0817 12:38:03.645452 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:38:03.645467 20404 solver.cpp:244]     Train net output #1: loss = 0.813925 (* 1 = 0.813925 loss)
I0817 12:38:03.645479 20404 sgd_solver.cpp:106] Iteration 16910, lr = 0.000475954
I0817 12:38:35.096731 20404 solver.cpp:337] Iteration 16920, Testing net (#0)
I0817 12:39:09.837412 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:39:09.837585 20404 solver.cpp:404]     Test net output #1: loss = 0.672182 (* 1 = 0.672182 loss)
I0817 12:39:13.319870 20404 solver.cpp:228] Iteration 16920, loss = 0.813324
I0817 12:39:13.319919 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:39:13.319933 20404 solver.cpp:244]     Train net output #1: loss = 0.813324 (* 1 = 0.813324 loss)
I0817 12:39:13.319946 20404 sgd_solver.cpp:106] Iteration 16920, lr = 0.000475821
I0817 12:39:48.269489 20404 solver.cpp:228] Iteration 16930, loss = 0.813365
I0817 12:39:48.269609 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 12:39:48.269629 20404 solver.cpp:244]     Train net output #1: loss = 0.813365 (* 1 = 0.813365 loss)
I0817 12:39:48.269644 20404 sgd_solver.cpp:106] Iteration 16930, lr = 0.000475689
I0817 12:40:23.203379 20404 solver.cpp:228] Iteration 16940, loss = 0.813545
I0817 12:40:23.203550 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:40:23.203565 20404 solver.cpp:244]     Train net output #1: loss = 0.813545 (* 1 = 0.813545 loss)
I0817 12:40:23.203579 20404 sgd_solver.cpp:106] Iteration 16940, lr = 0.000475556
I0817 12:40:58.157876 20404 solver.cpp:228] Iteration 16950, loss = 0.813172
I0817 12:40:58.158058 20404 solver.cpp:244]     Train net output #0: accuracy = 0.83
I0817 12:40:58.158074 20404 solver.cpp:244]     Train net output #1: loss = 0.813172 (* 1 = 0.813172 loss)
I0817 12:40:58.158087 20404 sgd_solver.cpp:106] Iteration 16950, lr = 0.000475424
I0817 12:41:29.625767 20404 solver.cpp:337] Iteration 16960, Testing net (#0)
I0817 12:42:04.330198 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:42:04.330376 20404 solver.cpp:404]     Test net output #1: loss = 0.672713 (* 1 = 0.672713 loss)
I0817 12:42:07.813238 20404 solver.cpp:228] Iteration 16960, loss = 0.813203
I0817 12:42:07.813289 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:42:07.813303 20404 solver.cpp:244]     Train net output #1: loss = 0.813203 (* 1 = 0.813203 loss)
I0817 12:42:07.813314 20404 sgd_solver.cpp:106] Iteration 16960, lr = 0.000475292
I0817 12:42:42.745944 20404 solver.cpp:228] Iteration 16970, loss = 0.81361
I0817 12:42:42.747993 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 12:42:42.748013 20404 solver.cpp:244]     Train net output #1: loss = 0.81361 (* 1 = 0.81361 loss)
I0817 12:42:42.748025 20404 sgd_solver.cpp:106] Iteration 16970, lr = 0.000475159
I0817 12:43:17.694254 20404 solver.cpp:228] Iteration 16980, loss = 0.81268
I0817 12:43:17.694427 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:43:17.694447 20404 solver.cpp:244]     Train net output #1: loss = 0.81268 (* 1 = 0.81268 loss)
I0817 12:43:17.694461 20404 sgd_solver.cpp:106] Iteration 16980, lr = 0.000475027
I0817 12:43:52.645089 20404 solver.cpp:228] Iteration 16990, loss = 0.813914
I0817 12:43:52.645292 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 12:43:52.645310 20404 solver.cpp:244]     Train net output #1: loss = 0.813914 (* 1 = 0.813914 loss)
I0817 12:43:52.645329 20404 sgd_solver.cpp:106] Iteration 16990, lr = 0.000474895
I0817 12:44:24.127066 20404 solver.cpp:454] Snapshotting to binary proto file examples/scene/scene_iter_17000.caffemodel
I0817 12:44:35.818426 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/scene/scene_iter_17000.solverstate
I0817 12:44:37.676530 20404 solver.cpp:337] Iteration 17000, Testing net (#0)
I0817 12:45:12.344367 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:45:12.344542 20404 solver.cpp:404]     Test net output #1: loss = 0.671836 (* 1 = 0.671836 loss)
I0817 12:45:15.821355 20404 solver.cpp:228] Iteration 17000, loss = 0.814107
I0817 12:45:15.821406 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 12:45:15.821420 20404 solver.cpp:244]     Train net output #1: loss = 0.814107 (* 1 = 0.814107 loss)
I0817 12:45:15.821432 20404 sgd_solver.cpp:106] Iteration 17000, lr = 0.000474763
I0817 12:45:50.690874 20404 solver.cpp:228] Iteration 17010, loss = 0.813433
I0817 12:45:50.691056 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:45:50.691071 20404 solver.cpp:244]     Train net output #1: loss = 0.813433 (* 1 = 0.813433 loss)
I0817 12:45:50.691083 20404 sgd_solver.cpp:106] Iteration 17010, lr = 0.000474632
I0817 12:46:25.574391 20404 solver.cpp:228] Iteration 17020, loss = 0.813288
I0817 12:46:25.574569 20404 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0817 12:46:25.574585 20404 solver.cpp:244]     Train net output #1: loss = 0.813288 (* 1 = 0.813288 loss)
I0817 12:46:25.574597 20404 sgd_solver.cpp:106] Iteration 17020, lr = 0.0004745
I0817 12:47:00.475950 20404 solver.cpp:228] Iteration 17030, loss = 0.814192
I0817 12:47:00.476127 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 12:47:00.476143 20404 solver.cpp:244]     Train net output #1: loss = 0.814192 (* 1 = 0.814192 loss)
I0817 12:47:00.476156 20404 sgd_solver.cpp:106] Iteration 17030, lr = 0.000474368
I0817 12:47:31.894745 20404 solver.cpp:337] Iteration 17040, Testing net (#0)
I0817 12:48:06.533736 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:48:06.533915 20404 solver.cpp:404]     Test net output #1: loss = 0.672874 (* 1 = 0.672874 loss)
I0817 12:48:10.013937 20404 solver.cpp:228] Iteration 17040, loss = 0.813318
I0817 12:48:10.013990 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:48:10.014004 20404 solver.cpp:244]     Train net output #1: loss = 0.813318 (* 1 = 0.813318 loss)
I0817 12:48:10.014016 20404 sgd_solver.cpp:106] Iteration 17040, lr = 0.000474237
I0817 12:48:44.900449 20404 solver.cpp:228] Iteration 17050, loss = 0.812359
I0817 12:48:44.900626 20404 solver.cpp:244]     Train net output #0: accuracy = 0.89
I0817 12:48:44.900641 20404 solver.cpp:244]     Train net output #1: loss = 0.812359 (* 1 = 0.812359 loss)
I0817 12:48:44.900655 20404 sgd_solver.cpp:106] Iteration 17050, lr = 0.000474105
I0817 12:49:19.797909 20404 solver.cpp:228] Iteration 17060, loss = 0.81407
I0817 12:49:19.798055 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 12:49:19.798097 20404 solver.cpp:244]     Train net output #1: loss = 0.81407 (* 1 = 0.81407 loss)
I0817 12:49:19.798115 20404 sgd_solver.cpp:106] Iteration 17060, lr = 0.000473974
I0817 12:49:54.700811 20404 solver.cpp:228] Iteration 17070, loss = 0.813335
I0817 12:49:54.700992 20404 solver.cpp:244]     Train net output #0: accuracy = 0.65
I0817 12:49:54.701012 20404 solver.cpp:244]     Train net output #1: loss = 0.813335 (* 1 = 0.813335 loss)
I0817 12:49:54.701028 20404 sgd_solver.cpp:106] Iteration 17070, lr = 0.000473842
I0817 12:50:26.126031 20404 solver.cpp:337] Iteration 17080, Testing net (#0)
I0817 12:51:00.780961 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:51:00.781103 20404 solver.cpp:404]     Test net output #1: loss = 0.672895 (* 1 = 0.672895 loss)
I0817 12:51:04.255915 20404 solver.cpp:228] Iteration 17080, loss = 0.81321
I0817 12:51:04.255960 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:51:04.255988 20404 solver.cpp:244]     Train net output #1: loss = 0.81321 (* 1 = 0.81321 loss)
I0817 12:51:04.256006 20404 sgd_solver.cpp:106] Iteration 17080, lr = 0.000473711
I0817 12:51:39.161653 20404 solver.cpp:228] Iteration 17090, loss = 0.813466
I0817 12:51:39.161839 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 12:51:39.161854 20404 solver.cpp:244]     Train net output #1: loss = 0.813466 (* 1 = 0.813466 loss)
I0817 12:51:39.161866 20404 sgd_solver.cpp:106] Iteration 17090, lr = 0.00047358
I0817 12:52:14.056442 20404 solver.cpp:228] Iteration 17100, loss = 0.812896
I0817 12:52:14.056618 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:52:14.056634 20404 solver.cpp:244]     Train net output #1: loss = 0.812896 (* 1 = 0.812896 loss)
I0817 12:52:14.056648 20404 sgd_solver.cpp:106] Iteration 17100, lr = 0.000473449
I0817 12:52:48.938091 20404 solver.cpp:228] Iteration 17110, loss = 0.81331
I0817 12:52:48.938274 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:52:48.938290 20404 solver.cpp:244]     Train net output #1: loss = 0.81331 (* 1 = 0.81331 loss)
I0817 12:52:48.938302 20404 sgd_solver.cpp:106] Iteration 17110, lr = 0.000473318
I0817 12:53:20.362475 20404 solver.cpp:337] Iteration 17120, Testing net (#0)
I0817 12:53:55.030331 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:53:55.030421 20404 solver.cpp:404]     Test net output #1: loss = 0.672873 (* 1 = 0.672873 loss)
I0817 12:53:58.515254 20404 solver.cpp:228] Iteration 17120, loss = 0.812263
I0817 12:53:58.515300 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:53:58.515316 20404 solver.cpp:244]     Train net output #1: loss = 0.812263 (* 1 = 0.812263 loss)
I0817 12:53:58.515329 20404 sgd_solver.cpp:106] Iteration 17120, lr = 0.000473187
I0817 12:54:33.390862 20404 solver.cpp:228] Iteration 17130, loss = 0.813467
I0817 12:54:33.391034 20404 solver.cpp:244]     Train net output #0: accuracy = 0.69
I0817 12:54:33.391052 20404 solver.cpp:244]     Train net output #1: loss = 0.813467 (* 1 = 0.813467 loss)
I0817 12:54:33.391063 20404 sgd_solver.cpp:106] Iteration 17130, lr = 0.000473056
I0817 12:55:08.292237 20404 solver.cpp:228] Iteration 17140, loss = 0.814193
I0817 12:55:08.292407 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:55:08.292423 20404 solver.cpp:244]     Train net output #1: loss = 0.814193 (* 1 = 0.814193 loss)
I0817 12:55:08.292436 20404 sgd_solver.cpp:106] Iteration 17140, lr = 0.000472925
I0817 12:55:43.435292 20404 solver.cpp:228] Iteration 17150, loss = 0.812901
I0817 12:55:43.435405 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:55:43.435421 20404 solver.cpp:244]     Train net output #1: loss = 0.812901 (* 1 = 0.812901 loss)
I0817 12:55:43.435436 20404 sgd_solver.cpp:106] Iteration 17150, lr = 0.000472795
I0817 12:56:14.999191 20404 solver.cpp:337] Iteration 17160, Testing net (#0)
I0817 12:56:49.852030 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:56:49.852206 20404 solver.cpp:404]     Test net output #1: loss = 0.672768 (* 1 = 0.672768 loss)
I0817 12:56:53.315850 20404 solver.cpp:228] Iteration 17160, loss = 0.813643
I0817 12:56:53.315901 20404 solver.cpp:244]     Train net output #0: accuracy = 1
I0817 12:56:53.315914 20404 solver.cpp:244]     Train net output #1: loss = 0.813643 (* 1 = 0.813643 loss)
I0817 12:56:53.315927 20404 sgd_solver.cpp:106] Iteration 17160, lr = 0.000472664
I0817 12:57:28.145162 20404 solver.cpp:228] Iteration 17170, loss = 0.812455
I0817 12:57:28.145257 20404 solver.cpp:244]     Train net output #0: accuracy = 0.66
I0817 12:57:28.145272 20404 solver.cpp:244]     Train net output #1: loss = 0.812455 (* 1 = 0.812455 loss)
I0817 12:57:28.145285 20404 sgd_solver.cpp:106] Iteration 17170, lr = 0.000472534
I0817 12:58:02.953619 20404 solver.cpp:228] Iteration 17180, loss = 0.812312
I0817 12:58:02.953781 20404 solver.cpp:244]     Train net output #0: accuracy = 0.98
I0817 12:58:02.953797 20404 solver.cpp:244]     Train net output #1: loss = 0.812312 (* 1 = 0.812312 loss)
I0817 12:58:02.953811 20404 sgd_solver.cpp:106] Iteration 17180, lr = 0.000472403
I0817 12:58:37.750108 20404 solver.cpp:228] Iteration 17190, loss = 0.812562
I0817 12:58:37.750283 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 12:58:37.750299 20404 solver.cpp:244]     Train net output #1: loss = 0.812562 (* 1 = 0.812562 loss)
I0817 12:58:37.750313 20404 sgd_solver.cpp:106] Iteration 17190, lr = 0.000472273
I0817 12:59:09.391697 20404 solver.cpp:337] Iteration 17200, Testing net (#0)
I0817 12:59:44.036751 20404 solver.cpp:404]     Test net output #0: accuracy = 1
I0817 12:59:44.036926 20404 solver.cpp:404]     Test net output #1: loss = 0.672294 (* 1 = 0.672294 loss)
I0817 12:59:47.497999 20404 solver.cpp:228] Iteration 17200, loss = 0.813472
I0817 12:59:47.498042 20404 solver.cpp:244]     Train net output #0: accuracy = 0.63
I0817 12:59:47.498060 20404 solver.cpp:244]     Train net output #1: loss = 0.813472 (* 1 = 0.813472 loss)
I0817 12:59:47.498075 20404 sgd_solver.cpp:106] Iteration 17200, lr = 0.000472143
I0817 13:00:22.622337 20404 solver.cpp:228] Iteration 17210, loss = 0.812859
I0817 13:00:22.622522 20404 solver.cpp:244]     Train net output #0: accuracy = 0.62
I0817 13:00:22.622540 20404 solver.cpp:244]     Train net output #1: loss = 0.812859 (* 1 = 0.812859 loss)
I0817 13:00:22.622555 20404 sgd_solver.cpp:106] Iteration 17210, lr = 0.000472013
